[
    {
        "idx": 23625,
        "repo_name": "austinyu_ujson5",
        "url": "https://github.com/austinyu/ujson5",
        "description": "A fast JSON5 encoder/decoder for Python",
        "stars": 42,
        "forks": 9,
        "language": "python",
        "size": 1266,
        "created_at": "2025-02-07T22:23:19+00:00",
        "updated_at": "2025-04-15T23:00:24+00:00",
        "pypi_info": {
            "name": "ujson5",
            "version": "1.0.1",
            "url": "https://files.pythonhosted.org/packages/9b/ed/d3761b2b6d75399d3fa0528e72e88319eff63873d4c99fdc70afaabed521/ujson5-1.0.1.tar.gz"
        },
        "error": null,
        "judge_info": {
            "language": "python",
            "is_good_project": false,
            "reason": "",
            "python_file_num": 31,
            "comment_ratio": 0.2376823852823007,
            "pyfile_content_length": 159842,
            "pyfile_code_lines": 4729,
            "test_file_exist": true,
            "test_file_content_length": 42399,
            "pytest_framework": true,
            "test_case_num": 63,
            "metadata_path": [
                "pyproject.toml"
            ],
            "readme_content_length": 6351,
            "llm_reason": "The project `ujson5` is a strong candidate for an AI 'Build from Scratch' benchmark. \n**Positive aspects:**\n*   **Self-Contained & Independent:** The core functionality of parsing and serializing JSON5 data, along with its CLI, operates locally without requiring internet access, external APIs, or complex third-party services for its primary operations or testing. Its dependencies are standard Python features or simple pip-installable packages for development, not for the core runtime logic of the library itself.\n*   **Clear & Well-Defined Functionality:** The project aims to implement the JSON5 specification, which is a public and well-documented standard. The README clearly outlines its purpose and features, providing a good basis for the AI's task.\n*   **Testable & Verifiable Output:** The project boasts an extensive and well-structured test suite (covering JSON Test Suite, JSON5 specific examples, Big List of Naughty Strings, CLI, and detailed unit tests for lexer, decoder, and encoder components). This is invaluable for programmatically verifying the AI-rebuilt project's correctness and adherence to the JSON5 spec.\n*   **No Graphical User Interface (GUI):** The project is a library with an optional CLI, making interactions and testing straightforwardly scriptable.\n*   **Appropriate Complexity (Medium):** Implementing a JSON5 parser and serializer is a non-trivial task. It involves handling lexical analysis (comments, various string and number formats, identifiers) and parsing syntax rules (objects, arrays, trailing commas, etc.), and then serializing Python objects back to JSON5. This offers a meaningful challenge beyond simple scripts but is not excessively large or complex like rebuilding an entire operating system or a large-scale web framework. The codebase is modular (`lexer.py`, `decoder.py`, `encoder.py`).\n*   **Well-Understood Problem Domain:** JSON parsing and serialization are common and well-understood problems in software development.\n*   **Predominantly Code-Based Solution:** The task for the AI is to generate Python code for the library.\n\n**Negative aspects or concerns:**\n*   **Intrinsic Complexity of Parsers/Lexers:** While the JSON5 specification is defined, correctly implementing a robust lexer and parser that handles all edge cases and adheres to the spec (e.g., specific error reporting, performance considerations implied by 'DFA-based algorithms') can be intricate. This forms the core challenge.\n*   **Advanced Encoder Feature (TypedDict Comment Extraction):** The encoder includes a feature to extract comments from Python `TypedDict` definitions to include in the JSON5 output. This is a Python-specific enhancement that, while clever, relies on introspection and has Python version-specific behavior (full support for parent TypedDicts on 3.12+). Replicating this specific feature perfectly might be challenging for an AI without very detailed specifications or if it involves less common Python internal mechanisms. This part might need careful scoping in the benchmark instructions (e.g., specify a target Python version or simplify this requirement).\n\nOverall, `ujson5` is well-suited. The core task of implementing the JSON5 spec is clear and testable. The main challenge lies in the detailed implementation of the parsing and serialization logic, including all JSON5-specific features.",
            "llm_project_type": "JSON5 parser and serializer library with CLI",
            "llm_rating": 80,
            "llm_difficulty": "Medium"
        },
        "tests": {
            "repo_name": "austinyu_ujson5",
            "finish_test": true,
            "test_case_result": {
                "tests/test_benchmark.py::test_ujson5_benchmark[path0]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path1]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path2]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path3]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path4]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path5]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path6]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path7]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path8]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path9]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path10]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path11]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path12]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path13]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path14]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path15]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path16]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path17]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path18]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path19]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path20]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path21]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path22]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path23]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path24]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path25]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path26]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path27]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path28]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path29]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path30]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path31]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path32]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path33]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path34]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path35]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path36]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path37]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path38]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path39]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path40]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path41]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path42]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path43]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path44]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path45]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path46]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path47]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path48]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path49]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path50]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path51]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path52]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path53]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path54]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path55]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path56]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path57]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path58]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path59]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path60]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path61]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path62]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path63]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path64]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path65]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path66]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path67]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path68]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path69]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path70]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path71]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path72]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path73]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path74]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path75]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path76]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path77]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path78]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path79]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path80]": "skipped",
                "tests/test_benchmark.py::test_ujson5_benchmark[path81]": "skipped",
                "tests/test_blns.py::test_blns": "passed",
                "tests/test_cli.py::test_cli_version[--version]": "passed",
                "tests/test_cli.py::test_cli_version[-v]": "passed",
                "tests/test_cli.py::test_cli_info[--info]": "passed",
                "tests/test_cli.py::test_cli_info[-i]": "passed",
                "tests/test_cli.py::test_cli_stdout_correct": "passed",
                "tests/test_cli.py::test_cli_stdout_incorrect": "passed",
                "tests/test_cli.py::test_cli_no_target": "passed",
                "tests/test_cli.py::test_cli_stdin": "passed",
                "tests/test_cli.py::test_cli_invalid_path": "passed",
                "tests/test_cli.py::test_cli_output": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path0]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path1]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path2]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path3]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path4]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path5]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path6]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path7]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path8]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path9]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path10]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path11]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path12]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path13]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path14]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path15]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path16]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path17]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path18]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path19]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path20]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path21]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path22]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path23]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path24]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path25]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path26]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path27]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path28]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path29]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path30]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path31]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path32]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path33]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path34]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path35]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path36]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path37]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path38]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path39]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path40]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path41]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path42]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path43]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path44]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path45]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path46]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path47]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path48]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path49]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path50]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path51]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path52]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path53]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path54]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path55]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path56]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path57]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path58]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path59]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path60]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path61]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path62]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path63]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path64]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path65]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path66]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path67]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path68]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path69]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path70]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path71]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path72]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path73]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path74]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path75]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path76]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path77]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path78]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path79]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path80]": "passed",
                "tests/test_json5_examples.py::test_valid_examples[path81]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path0]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path1]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path2]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path3]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path4]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path5]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path6]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path7]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path8]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path9]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path10]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path11]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path12]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path13]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path14]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path15]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path16]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path17]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path18]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path19]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path20]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path21]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path22]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path23]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path24]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path25]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path26]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path27]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path28]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path29]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path30]": "passed",
                "tests/test_json5_examples.py::test_invalid_examples[path31]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path0]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path1]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path2]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path3]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path4]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path5]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path6]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path7]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path8]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path9]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path10]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path11]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path12]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path13]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path14]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path15]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path16]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path17]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path18]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path19]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path20]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path21]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path22]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path23]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path24]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path25]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path26]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path27]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path28]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path29]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path30]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path31]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path32]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path33]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path34]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path35]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path36]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path37]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path38]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path39]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path40]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path41]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path42]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path43]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path44]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path45]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path46]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path47]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path48]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path49]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path50]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path51]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path52]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path53]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path54]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path55]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path56]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path57]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path58]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path59]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path60]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path61]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path62]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path63]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path64]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path65]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path66]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path67]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path68]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path69]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path70]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path71]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path72]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path73]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path74]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path75]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path76]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path77]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path78]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path79]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path80]": "passed",
                "tests/test_json5_examples.py::test_dump_load_from_examples[path81]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path0]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path1]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path2]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path3]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path4]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path5]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path6]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path7]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path8]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path9]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path10]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path11]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path12]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path13]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path14]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path15]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path16]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path17]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path18]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path19]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path20]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path21]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path22]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path23]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path24]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path25]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path26]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path27]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path28]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path29]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path30]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path31]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path32]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path33]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path34]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path35]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path36]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path37]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path38]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path39]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path40]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path41]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path42]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path43]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path44]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path45]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path46]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path47]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path48]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path49]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path50]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path51]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path52]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path53]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path54]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path55]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path56]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path57]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path58]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path59]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path60]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path61]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path62]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path63]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path64]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path65]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path66]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path67]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path68]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path69]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path70]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path71]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path72]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path73]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path74]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path75]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path76]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path77]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path78]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path79]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path80]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path81]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path82]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path83]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path84]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path85]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path86]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path87]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path88]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path89]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path90]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path91]": "passed",
                "tests/test_json_test_suit.py::test_accepted_json[file_path92]": "passed",
                "tests/test_native_json_benchmark.py::test_json_checker_file[file_path0]": "passed",
                "tests/test_native_json_benchmark.py::test_json_checker_file[file_path1]": "passed",
                "tests/test_native_json_benchmark.py::test_json_checker_file[file_path2]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path0]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path1]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path2]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path3]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path4]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path5]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path6]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path7]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path8]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path9]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path10]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path11]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path12]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path13]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path14]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path15]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path16]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path17]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path18]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path19]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path20]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path21]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path22]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path23]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path24]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path25]": "passed",
                "tests/test_native_json_benchmark.py::test_round_trips[file_path26]": "passed",
                "tests/test_native_json_benchmark.py::test_loading_canada_file": "skipped",
                "tests/test_native_json_benchmark.py::test_loading_citm_catalog_file": "skipped",
                "tests/test_native_json_benchmark.py::test_loading_citm_twitter_file": "skipped",
                "tests/test_snapshots/test_snapshots.py::test_load_json5_from_alpha_snapshots": "passed",
                "tests/test_snapshots/test_snapshots.py::test_alpha_default": "passed",
                "tests/test_snapshots/test_snapshots.py::test_alpha_with_comments": "passed",
                "tests/test_snapshots/test_snapshots.py::test_alpha_no_comments": "passed",
                "tests/test_snapshots/test_snapshots.py::test_alpha_no_indent": "passed",
                "tests/test_snapshots/test_snapshots.py::test_alpha_7_indent": "passed",
                "tests/test_snapshots/test_snapshots.py::test_alpha_special_separators": "passed",
                "tests/test_snapshots/test_snapshots.py::test_alpha_with_trailing_comma": "passed",
                "tests/test_snapshots/test_snapshots.py::test_alpha_no_trailing_comma": "passed",
                "tests/test_unit_tests/test_comment_lexer.py::test_valid_comments[//-2]": "passed",
                "tests/test_unit_tests/test_comment_lexer.py::test_valid_comments[// some comment is here\\n new line-24]": "passed",
                "tests/test_unit_tests/test_comment_lexer.py::test_valid_comments[/* some comment is here */-26]": "passed",
                "tests/test_unit_tests/test_comment_lexer.py::test_valid_comments[/* some comment is here\\n new line */-36]": "passed",
                "tests/test_unit_tests/test_comment_lexer.py::test_valid_comments[/* some comment is here\\n new line */ new line-36]": "passed",
                "tests/test_unit_tests/test_comment_lexer.py::test_invalid_comments[/]": "passed",
                "tests/test_unit_tests/test_comment_lexer.py::test_invalid_comments[/*]": "passed",
                "tests/test_unit_tests/test_comment_lexer.py::test_invalid_comments[/* some comment is here]": "passed",
                "tests/test_unit_tests/test_comment_lexer.py::test_invalid_comments[/* some comment is here*]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads[null-None]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads[true-True]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads[false-False]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads[\"string\"-string]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads[\"string with \\\\\"escaped quotes\\\\\"\"-string with \"escaped quotes\"]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads[\"string with multiple \\\\\\nlines\"-string with multiple lines]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads[\"sig\\u03a3ma\"-sig\\u03a3ma]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads[123-123]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads[123.456-123.456]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads[0x23-35]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads[23e-2-0.23]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads[Infinity-inf]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads[NaN-nan]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads[-Infinity--inf]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads[-NaN-nan]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads[[1, 2, 3]-py_value15]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads[{\"key\": \"value\"}-py_value16]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads[{\"sig\\u03a3ma\": \"value\"}-py_value17]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads[{sig\\u03a3ma: \"value\"}-py_value18]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[null-None]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[true-True]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[false-False]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[\"string\"-string]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[\"string with \\\\\"escaped quotes\\\\\"\"-string with \"escaped quotes\"]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[\"string with multiple \\\\\\nlines\"-string with multiple lines]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[\"sig\\u03a3ma\"-sig\\u03a3ma]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[123-123]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[123.456-123.456]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[0x23-35]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[23e-2-0.23]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[Infinity-inf]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[NaN-nan]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[-Infinity--inf]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[-NaN-nan]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[[1, 2, 3]-py_value15]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[{\"key\": \"value\"}-py_value16]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[{\"sig\\u03a3ma\": \"value\"}-py_value17]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[{sig\\u03a3ma: \"value\"}-py_value18]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_composite_loads[{\\n            key: \"value\",\\n            \"key2\": 123,\\n            \"key3\": true,\\n            \"key4\": null,\\n            \"key5\": [1, 2, 3],\\n            key6: {\\n                \"nested\": \"object\"\\n            }\\n\\n         }\\n-py_value0]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_composite_loads[\\n{\\n  // comments\\n  unquoted: 'and you can quote me on that',\\n  singleQuotes: 'I can use \"double quotes\" here',\\n  lineBreaks: \"Look, Mom! \\\\\\nNo \\\\n's!\",\\n  hexadecimal: 0xdecaf,\\n  leadingDecimalPoint: .8675309, andTrailing: 8675309.,\\n  positiveSign: +1,\\n  trailingComma: 'in objects', andIn: ['arrays',],\\n  \"backwardsCompatible\": \"with JSON\",\\n  null_supported: null,\\n  infinities_supported: Infinity,\\n}\\n-py_value1]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_strict_mode[\"\\\\t\"]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_strict_mode[\"\\\\n\"]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_strict_mode[\"\\\\r\"]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_strict_mode[\"\\\\0\"]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[null 1]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{key:}[12, }{: 12}12}]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[12]]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{abc: abc}]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[:34]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[:{ab: 1232]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[1}]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[1:]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{1:]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[abc\\tdef]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{23]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[:]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[,]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[,11 11]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{abc: 12 def: 23}]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{'abc': 12 'def': 23}]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[[12, 23:]]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{abc: 12, 23: 465}]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[[12, 23, abc]]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[[:]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{\"abc\":]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{\"abc\":3,23]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[23,34]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{:\"abc\",]]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_object_hook[{\\n    key1: 1,\\n    \"key2\": 2,\\n    \"key3\": 3,\\n    \"key4\": 4,\\n    \"key5\": 5,\\n    key6: 6\\n}-<lambda>-py_value0]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_object_hook[3-<lambda>-3]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_object_pair_hook[{\\n    key6: 6,\\n    \"key3\": 3,\\n    \"key5\": 5,\\n    key1: 1,\\n    \"key2\": 2,\\n    \"key4\": 4,\\n}-<lambda>-py_value0]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_object_pair_hook[3-<lambda>-3]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_invalid_object_hook": "passed",
                "tests/test_unit_tests/test_decoder.py::test_custom_decoder": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[let]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[new]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[enum]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[if]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[export]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[case]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[catch]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[interface]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[class]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[implements]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[this]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[const]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[finally]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[try]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[throw]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[extends]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[import]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[with]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[delete]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[instanceof]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[yield]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[default]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[package]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[switch]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[private]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[function]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[while]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[super]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[static]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[for]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[return]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[protected]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[typeof]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[continue]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[do]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[void]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[debugger]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[break]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[in]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[public]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[var]": "passed",
                "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[else]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_valid_examples[string-\"string\"]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_valid_examples[123-123]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_valid_examples[123.456-123.456]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_valid_examples[2e+20-2e+20]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_valid_examples[inf-Infinity]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_valid_examples[-inf--Infinity]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_valid_examples[nan-NaN]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_valid_examples[True-true]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_valid_examples[False-false]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_valid_examples[None-null]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_valid_examples[py_obj10-[]]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_valid_examples[py_obj11-[1, 2, 3]]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_valid_examples[py_obj12-{}]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_valid_examples[py_obj13-{\"key\": \"value\"}]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_valid_examples[py_obj14-{\"key\": 123}]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_valid_examples[py_obj15-{\"string\": \"string\", \"int\": 123, \"float\": 123.456, \"true\": true, \"false\": false, \"null\": null, \"array\": [1, 2, 3, [1, 2]], \"heterogeneous\": [1, 1.323, \"string\", true, null, {\"key\": \"value\"}], \"object\": {\"key\": \"value\"}}]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_valid_examples[py_obj16-{\"12\": \"int key\", \"12.34\": \"float key\", \"true\": \"bool key\", \"false\": \"false key\", \"null\": \"null key\"}]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_indent[py_obj0-{\\n    \"val\": 1,\\n    \"array\": [\\n        1,\\n        2,\\n        3,\\n    ],\\n    \"obj\": {\\n        \"key\": \"value\",\\n    },\\n}]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_invalid_examples[py_obj0]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_invalid_examples[py_obj1]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_invalid_examples[py_obj2]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_skip_keys": "passed",
                "tests/test_unit_tests/test_encoder.py::test_nan_not_allowed[nan]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_nan_not_allowed[inf]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_nan_not_allowed[-inf]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_circular_ref": "passed",
                "tests/test_unit_tests/test_encoder.py::test_sort_keys": "passed",
                "tests/test_unit_tests/test_encoder.py::test_default_set": "passed",
                "tests/test_unit_tests/test_encoder.py::test_separators": "passed",
                "tests/test_unit_tests/test_encoder.py::test_replace_unicode": "passed",
                "tests/test_unit_tests/test_encoder.py::test_replace_ascii[Hello\\x80World-\"Hello\\\\u0080World\"]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_replace_ascii[Hello\\U0001f600World-\"Hello\\\\ud83d\\\\ude00World\"]": "passed",
                "tests/test_unit_tests/test_encoder.py::test_invalid_typed_dict_cls": "passed",
                "tests/test_unit_tests/test_encoder.py::test_quoted_key": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[a-0-1]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[A-0-1]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[_A-0-2]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[$A-0-2]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[\\\\uf3e9-0-6]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[a02a-0-4]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[_\\\\u0312}   -0-7]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[_\\\\u0312:   -0-7]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[_\\\\u0312[   -0-7]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[_\\\\u0312{   -0-7]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[_\\\\u0312]   -0-7]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[_\\\\u0312,   -0-7]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[\\U0001b2e3\\u1ddc-0-2]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[\\u3cf6\\u200d\\u200c-0-3]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[\\U00025024\\u1c52-0-2]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[\\u761c\\u2054-0-2]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\\\u22\\\\xab]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\\\u]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U0001182c]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U00011723]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u0d01]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U0001172a]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u1bf1]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U000e012a]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U00016f6d]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u20d9]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u0b57]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U00011081]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u0de9]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u1c44]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U000112f5]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u09ed]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U00011653]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\ua905]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\ua8d3]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U0001e141]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\uaa54]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U00011737]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u203f]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\ufe34]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\uff3f]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\ufe4f]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\ufe4d]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\ufe4e]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u2040]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\ufe33]": "passed",
                "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[A\\u2603]": "passed",
                "tests/test_unit_tests/test_lexer.py::test_lexer": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0_0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0_1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[3e2]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0e2]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123_0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456_0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.123_0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.123_0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99e10]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E+10_0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2e-3]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.0001_0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123e5]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.5E10_0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E+0  0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456e10  ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.001_0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123_1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.456_0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[7e10]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e+0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e-0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e10]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e+10]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e-10]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[12345678901234567890_0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2345678901234567890e+20]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x123ABC]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0XABCDEF0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123_0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123.456_0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+0_0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-0_0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+.123_0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-.434_0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[2323.0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[Infinity]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+Infinity]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-Infinity]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[NaN]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+NaN]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-NaN]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0_2]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0_3]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[3E2]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0E2]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123_2]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456_1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.123_1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.123_1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E10]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E+10_1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E-3]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.0001_1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123E5]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.5E10_1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E+0  1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456E10  ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.001_1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123_3]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.456_1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[7E10]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E+0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E-0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E10]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E+10]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E-10]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[12345678901234567890_1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2345678901234567890E+20]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X123ABC]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0XABCDEF1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123_1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123.456_1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+0_1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-0_1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+.123_1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-.434_1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[2323.1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0         ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0    0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[3e2        ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0e2   ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123        0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456         ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.123    ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.123        ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99e10  ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E+10       ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2e-3     ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.0001  ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123e5          ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.5E10          ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E+0         ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456e10          ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.001       ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123         0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.456      ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[7e10        ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e0    ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e+0    ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e-0 ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e10    ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e+10 ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e-10  ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[12345678901234567890       ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2345678901234567890e+20   ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x0        ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x1     ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x123ABC     ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0XABCDEF          ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123 ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123.456      ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+0 ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-0 ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+.123       ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-.434   ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[2323.          ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0    1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0     ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[3E2   ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0E2          ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123        1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456     ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.123       ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.123         ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E10         ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E+10  ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E-3      ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.0001     ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123E5  ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.5E10 ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E+0      ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456E10     ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.001 ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123         1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.456   ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[7E10         ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E0         ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E+0   ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E-0      ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E10         ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E+10      ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E-10   ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[12345678901234567890          ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2345678901234567890E+20      ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X0  ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X1       ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X123ABC     ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0XABCDEF   ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123       ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123.456          ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+0   ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-0          ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+.123      ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-.434 ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[2323. ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0            ,    ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0     ,         ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[3e2            , ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0e2      ,         ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123            , 0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456               ,        ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.123     ,]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.123           ,         ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99e10          ,         ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E+10             ,     ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2e-3           ,   ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.0001         ,        ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123e5                   ,          ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.5E10                   ,        ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E+0               , ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456e10                 ,     ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.001                 ,   ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123                   ,]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.456        ,  ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[7e10                 ,     ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e0        , ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e+0      ,       ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e-0       ,         ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e10         , ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e+10           ,       ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e-10  ,]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[12345678901234567890                 ,       ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2345678901234567890e+20         ,  ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x0              , ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x1             ,         ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x123ABC       , ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0XABCDEF          ,         ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123     ,         ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123.456          ,      ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+0   ,      ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-0 ,    ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+.123             , ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-.434            ,          ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[2323.                  ,         ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0       , ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0       ,    ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[3E2       ,  ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0E2              ,]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123        ,    ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456        ,     ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.123            ,       ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.123                  ,     ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E10             ,      ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E+10   ,        ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E-3      ,         ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.0001          ,]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123E5           , ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.5E10  , ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E+0          ,         ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456E10           , ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.001  ,        ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123            , 1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.456             ,        ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[7E10              ,        ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E0                ,          ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E+0     ,        ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E-0             ,          ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E10             ,    ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E+10              ,]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E-10           ,          ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[12345678901234567890                  ,          ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2345678901234567890E+20       ,     ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X0            ,    ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X1              ,       ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X123ABC        ,     ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0XABCDEF    ,  ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123               ,   ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123.456              ,          ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+0             ,     ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-0           ,        ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+.123      ,  ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-.434           , ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[2323.     ,  ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0    ,          ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0   ,   ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[3E2    ,  ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0E2      ,        ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123       ,         ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456    ,      ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.123     ,      ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.123    ,      ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E10        ,   ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E+10,     ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E-3   ,          ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.0001        ,      ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123E5       ,      ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.5E10       ,]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E+0      ,  ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456E10    ,     ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.001    ,          ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123      ,          ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.456         ,       ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[7E10        ,    ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E0       ,       ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E+0   ,     ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E-0         ,      ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E10        ,]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E+10     ,        ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E-10,    ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[12345678901234567890  ,   ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2345678901234567890E+20         ,   ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X0       ,  ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X1          ,]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X123ABC         ,       ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0XABCDEF ,]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123        ,      ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123.456     ,          ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+0,          ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-0 ,         ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+.123 ,       ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-.434,  ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[2323.    ,]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[    ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[00]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[0123_0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1.2.3_0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e+0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[.e2]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[. 123]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[4.5e ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[4.5e+ ]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[5.5.5]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[0d]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[2e9d]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[123a]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1.2.3_1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e2e3]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1..2]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1.2.3_2]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e+e]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e-.]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[0123_1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[00.123]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e 2]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[123abc]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1.23e10xyz]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[.]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[e0]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[e10]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e+1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e-]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[+]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1ek]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[e1]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[E]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[0x]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[0xG]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[0x1.23]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[0Xx]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[Inf]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[+Inf]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[Na]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-Na]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[infinity]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[InfinityHere]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[NaNHere]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[+InfinityHere]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-NaNHere]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[InfinitY]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[Nan]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[+InfinitY]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-Nan]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[nan]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[+infinity]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-infinity]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[+nan]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-nan]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[InfinityInfinity]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[NaNNad]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[NaNN]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[++]": "passed",
                "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-  -]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[''        \\r\\n]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[''     \\u2029]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['0'     \\u2029]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['[\\\\',]'        \\r]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['{}'     \\u2028]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['\\ua3b2'    \\u2028]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['\\u5232'      \\r\\n]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\''  \\r]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\\"'          \\u2029]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\\\\\'  \\u2028]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\b'        \\u2028]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\f'      \\n]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\t'      \\r\\n]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\v'       \\u2028]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\0'     \\r\\n]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\/'   \\n]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"\" \\n]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"\"         \\u2029]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"0\"       \\r]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"[\\\\',]\"        \\r]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"{}\"      \\u2029]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"\\ua3b2\"      \\u2028]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"\\u5232\"          \\u2029]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\'\"      \\u2028]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\\"\" \\u2028]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\\\\\\"          \\r\\n]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\b\"    \\n]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\f\"   \\u2028]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\t\"         \\n]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\v\"   \\u2029]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\0\" \\r]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\/\"          \\u2028]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings0-0]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings1-0]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings2-10]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings3-10]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings4-0]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings5-1]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings6-2]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings7-3]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings8-4]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings9-0]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings10-1]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings11-2]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings12-3]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings13-4]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_passage": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['no end single quote]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings[\"no end double quote]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings[\"no end quote and new line\\n]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings[no start quote]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['no end single quote at newline    \\\\]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['no end single quote at newline    \\\\  ']": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['chars after escape new line \\\\   ambiguous chars\\n]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['nothing after escape new line \\\\    ]": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['unknown escape sequence \\\\x']": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['invalid unicode escape sequence \\\\u']": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['invalid unicode escape sequence \\\\u01']": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['invalid unicode escape sequence \\\\u013l']": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['invalid hex escape sequence \\\\x']": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['invalid hex escape sequence \\\\x1']": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['invalid hex escape sequence \\\\xz']": "passed",
                "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['invalid escape sequence \\\\k']": "passed",
                "tests/test_version.py::test_version_consistency": "passed"
            },
            "success_count": 954,
            "failed_count": 0,
            "error_count": 0,
            "skipped_count": 85,
            "unknown_count": 0,
            "total_count": 1039,
            "success_rate": 0.9181905678537055,
            "coverage_report": {
                "covered_lines": 1027,
                "num_statements": 1030,
                "percent_covered": 99.27536231884058,
                "percent_covered_display": "99",
                "missing_lines": 3,
                "excluded_lines": 20,
                "num_branches": 488,
                "num_partial_branches": 8,
                "covered_branches": 480,
                "missing_branches": 8
            },
            "coverage_result": {}
        },
        "codelines_count": 4729,
        "codefiles_count": 31,
        "code_length": 159842,
        "test_files_count": 15,
        "test_code_length": 42399,
        "structure": [
            {
                "file": "tests/test_json_test_suit.py",
                "functions": [
                    {
                        "name": "test_accepted_json",
                        "docstring": "Any accepted JSON is a valid JSON5.",
                        "comments": null,
                        "args": [
                            "file_path"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_json5_examples.py",
                "functions": [
                    {
                        "name": "test_valid_examples",
                        "docstring": "Test valid JSON5 examples.",
                        "comments": null,
                        "args": [
                            "path"
                        ]
                    },
                    {
                        "name": "test_invalid_examples",
                        "docstring": "Test invalid JSON5 examples.",
                        "comments": null,
                        "args": [
                            "path"
                        ]
                    },
                    {
                        "name": "test_dump_load_from_examples",
                        "docstring": "Test valid JSON5 examples.",
                        "comments": null,
                        "args": [
                            "path",
                            "tmp_path"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/test_blns.py",
                "functions": [
                    {
                        "name": "test_blns",
                        "docstring": "Test for JSON checker files.",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_cli.py",
                "functions": [
                    {
                        "name": "test_cli_version",
                        "docstring": "Test version output.",
                        "comments": null,
                        "args": [
                            "arg"
                        ]
                    },
                    {
                        "name": "test_cli_info",
                        "docstring": "Test version info output.",
                        "comments": null,
                        "args": [
                            "arg"
                        ]
                    },
                    {
                        "name": "test_cli_stdout_correct",
                        "docstring": "Test stdout output.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_cli_stdout_incorrect",
                        "docstring": "Test stdout output.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_cli_no_target",
                        "docstring": "Test no target.",
                        "comments": null,
                        "args": [
                            "monkeypatch"
                        ]
                    },
                    {
                        "name": "test_cli_stdin",
                        "docstring": "Test reading from stdin with options.",
                        "comments": null,
                        "args": [
                            "monkeypatch"
                        ]
                    },
                    {
                        "name": "test_cli_invalid_path",
                        "docstring": "Test invalid path.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_cli_output",
                        "docstring": "Test output file.",
                        "comments": null,
                        "args": [
                            "tmp_path"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/example_consts.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/test_native_json_benchmark.py",
                "functions": [
                    {
                        "name": "test_json_checker_file",
                        "docstring": "Test for JSON checker files.",
                        "comments": null,
                        "args": [
                            "file_path"
                        ]
                    },
                    {
                        "name": "test_round_trips",
                        "docstring": "Test for loading and dumping.",
                        "comments": null,
                        "args": [
                            "file_path"
                        ]
                    },
                    {
                        "name": "test_loading_canada_file",
                        "docstring": "Test for loading large files.",
                        "comments": null,
                        "args": [
                            "benchmark"
                        ]
                    },
                    {
                        "name": "test_loading_citm_catalog_file",
                        "docstring": "Test for loading large files.",
                        "comments": null,
                        "args": [
                            "benchmark"
                        ]
                    },
                    {
                        "name": "test_loading_citm_twitter_file",
                        "docstring": "Test for loading large files.",
                        "comments": null,
                        "args": [
                            "benchmark"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_benchmark.py",
                "functions": [
                    {
                        "name": "test_ujson5_benchmark",
                        "docstring": "Test valid JSON5 examples.",
                        "comments": null,
                        "args": [
                            "path",
                            "benchmark"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_version.py",
                "functions": [
                    {
                        "name": "test_version_consistency",
                        "docstring": "Test that the version in the package is consistent with the version in the metadata.",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_snapshots/test_snapshots.py",
                "functions": [
                    {
                        "name": "test_load_json5_from_alpha_snapshots",
                        "docstring": "Test loading alpha snapshots.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_alpha_default",
                        "docstring": "Test dump consistency.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_alpha_with_comments",
                        "docstring": "Test dump consistency.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_alpha_no_comments",
                        "docstring": "Test dumping alpha without comments.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_alpha_no_indent",
                        "docstring": "Test dumping alpha without indent.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_alpha_7_indent",
                        "docstring": "Test dumping alpha with 7 indent.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_alpha_special_separators",
                        "docstring": "Test dumping alpha with special separators.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_alpha_with_trailing_comma",
                        "docstring": "Test dumping alpha with trailing comma.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_alpha_no_trailing_comma",
                        "docstring": "Test dumping alpha without trailing comma.",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_snapshots/snapshots.py",
                "functions": [],
                "classes": [
                    {
                        "name": "Courses",
                        "docstring": "Courses",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "ProjectConfig",
                        "docstring": "A configuration for a python project.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "Creature",
                        "docstring": "Creature",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "Property",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "Human",
                        "docstring": "Human",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/test_snapshots/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/test_snapshots/generate_snapshots.py",
                "functions": [
                    {
                        "name": "dump_alpha",
                        "docstring": "Dump json5 for alpha obj.",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_unit_tests/test_decoder.py",
                "functions": [
                    {
                        "name": "test_basic_loads",
                        "docstring": "Test basic JSON5 loads.",
                        "comments": null,
                        "args": [
                            "json5",
                            "py_value"
                        ]
                    },
                    {
                        "name": "test_basic_loads_raw",
                        "docstring": "Test basic JSON5 loads.",
                        "comments": null,
                        "args": [
                            "json5",
                            "py_value"
                        ]
                    },
                    {
                        "name": "test_composite_loads",
                        "docstring": "Test composite JSON5 loads.",
                        "comments": null,
                        "args": [
                            "json5",
                            "py_value"
                        ]
                    },
                    {
                        "name": "test_strict_mode",
                        "docstring": "Test composite JSON5 loads.",
                        "comments": null,
                        "args": [
                            "json5"
                        ]
                    },
                    {
                        "name": "test_invalid_loads",
                        "docstring": "Test invalid JSON5 loads.",
                        "comments": null,
                        "args": [
                            "json5"
                        ]
                    },
                    {
                        "name": "test_object_hook",
                        "docstring": "Test composite JSON5 loads.",
                        "comments": null,
                        "args": [
                            "json5",
                            "obj_hook",
                            "py_value"
                        ]
                    },
                    {
                        "name": "test_object_pair_hook",
                        "docstring": "Test composite JSON5 loads.",
                        "comments": null,
                        "args": [
                            "json5",
                            "obj_pairs_hook",
                            "py_value"
                        ]
                    },
                    {
                        "name": "test_invalid_object_hook",
                        "docstring": "Test invalid object hook.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_custom_decoder",
                        "docstring": "Test custom decoder.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_reserved_word_keys",
                        "docstring": "Test reserved word keys.",
                        "comments": null,
                        "args": [
                            "word"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "CustomDecoder",
                        "docstring": "Custom decoder class.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/test_unit_tests/test_string_lexer.py",
                "functions": [
                    {
                        "name": "test_valid_strings",
                        "docstring": "Test valid strings that do not escape to multiple lines.",
                        "comments": null,
                        "args": [
                            "text_string"
                        ]
                    },
                    {
                        "name": "test_valid_multiline_string",
                        "docstring": "Test valid strings that escape to multiple lines.",
                        "comments": null,
                        "args": [
                            "text_strings",
                            "spacing"
                        ]
                    },
                    {
                        "name": "test_passage",
                        "docstring": "Test a passage.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_invalid_strings",
                        "docstring": "Test invalid strings.",
                        "comments": null,
                        "args": [
                            "text_string"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_unit_tests/test_number_lexer.py",
                "functions": [
                    {
                        "name": "test_valid_numbers",
                        "docstring": "Test valid numbers.",
                        "comments": null,
                        "args": [
                            "text_number"
                        ]
                    },
                    {
                        "name": "test_invalid_invalid_numbers",
                        "docstring": "Test invalid numbers.",
                        "comments": null,
                        "args": [
                            "text_number"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_unit_tests/test_lexer.py",
                "functions": [
                    {
                        "name": "test_lexer",
                        "docstring": "Test lexer",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_unit_tests/test_encoder.py",
                "functions": [
                    {
                        "name": "test_valid_examples",
                        "docstring": "Test valid JSON5 examples.",
                        "comments": null,
                        "args": [
                            "py_obj",
                            "json5_obj"
                        ]
                    },
                    {
                        "name": "test_indent",
                        "docstring": "Test indent.",
                        "comments": null,
                        "args": [
                            "py_obj",
                            "json5_obj"
                        ]
                    },
                    {
                        "name": "test_invalid_examples",
                        "docstring": "Test invalid JSON5 examples.",
                        "comments": null,
                        "args": [
                            "py_obj"
                        ]
                    },
                    {
                        "name": "test_skip_keys",
                        "docstring": "Test skip keys.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_nan_not_allowed",
                        "docstring": "Test NaN not allowed.",
                        "comments": null,
                        "args": [
                            "py_obj"
                        ]
                    },
                    {
                        "name": "test_circular_ref",
                        "docstring": "Test circular reference.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_sort_keys",
                        "docstring": "Test sort keys.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_default_set",
                        "docstring": "Test default set.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_separators",
                        "docstring": "Test separators.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_replace_unicode",
                        "docstring": "Test unicode replacement",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_replace_ascii",
                        "docstring": "Test ASCII replacement",
                        "comments": null,
                        "args": [
                            "py_obj",
                            "json5_str"
                        ]
                    },
                    {
                        "name": "test_invalid_typed_dict_cls",
                        "docstring": "Test raise when TypedDict class is not valid.",
                        "comments": null,
                        "args": [
                            "tmp_path"
                        ]
                    },
                    {
                        "name": "test_quoted_key",
                        "docstring": "Test quoted key.",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": [
                    {
                        "name": "Custom",
                        "docstring": "Custom class.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/test_unit_tests/test_comment_lexer.py",
                "functions": [
                    {
                        "name": "test_valid_comments",
                        "docstring": "Test valid comments.",
                        "comments": null,
                        "args": [
                            "comment",
                            "end"
                        ]
                    },
                    {
                        "name": "test_invalid_comments",
                        "docstring": "Test invalid comments.",
                        "comments": null,
                        "args": [
                            "comment"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_unit_tests/test_identifier_lexer.py",
                "functions": [
                    {
                        "name": "test_valid_identifiers",
                        "docstring": "Test valid identifiers.",
                        "comments": null,
                        "args": [
                            "identifier",
                            "start",
                            "end"
                        ]
                    },
                    {
                        "name": "test_invalid_identifiers",
                        "docstring": "Test invalid identifiers.",
                        "comments": null,
                        "args": [
                            "identifier"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "src/ujson5/core.py",
                "functions": [
                    {
                        "name": "version_info",
                        "docstring": "Return complete version information for ujson5 and its dependencies.",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": [
                    {
                        "name": "JSON5DecodeError",
                        "docstring": "Subclass of ValueError with the following additional properties:\n\nmsg: The unformatted error message\ndoc: The JSON document being parsed\npos: The start index of doc where parsing failed\nlineno: The line corresponding to pos\ncolno: The column corresponding to pos",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": "Note that this exception is used from _json",
                                "args": [
                                    "self",
                                    "msg",
                                    "doc",
                                    "pos"
                                ]
                            },
                            {
                                "name": "__reduce__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__str__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "JSON5EncodeError",
                        "docstring": "Subclass of ValueError raised when encoding fails.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "Token",
                        "docstring": "Token representation",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "TokenResult",
                        "docstring": "Token result",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "src/ujson5/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "src/ujson5/cli.py",
                "functions": [
                    {
                        "name": "main",
                        "docstring": "main cli function",
                        "comments": null,
                        "args": [
                            "test_args"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "src/ujson5/err_msg.py",
                "functions": [],
                "classes": [
                    {
                        "name": "NumberDecoderErr",
                        "docstring": "Errors related to number lexer",
                        "comments": null,
                        "methods": [
                            {
                                "name": "unexpected_char_in_number",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "char"
                                ]
                            },
                            {
                                "name": "leading_zero_followed_by_digit",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "no_number",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "trailing_dot",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "trailing_exponent",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "trailing_exponent_sign",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "no_hex_digits",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "invalid_constant",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "expected",
                                    "actual"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "StringDecoderErr",
                        "docstring": "Errors related to string lexer",
                        "comments": null,
                        "methods": [
                            {
                                "name": "string_invalid_start",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "char"
                                ]
                            },
                            {
                                "name": "unexpected_end_of_string",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "unexpected_escape_sequence",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "char"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "IdentifierDecoderErr",
                        "docstring": "Errors related to identifier lexer",
                        "comments": null,
                        "methods": [
                            {
                                "name": "invalid_start",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "char"
                                ]
                            },
                            {
                                "name": "invalid_char",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "character"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "DecoderErr",
                        "docstring": "General parse errors",
                        "comments": null,
                        "methods": [
                            {
                                "name": "unexpected_eof",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "empty_json5",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "expecting_value",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "unexpected_identifier",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "expecting_property_name",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "tk_type"
                                ]
                            },
                            {
                                "name": "expecting_property_value",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "tk_type"
                                ]
                            },
                            {
                                "name": "unexpected_punctuation",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "actual"
                                ]
                            },
                            {
                                "name": "unexpected_colon_in_array",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "missing_key_with_colon",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "missing_comma",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "within"
                                ]
                            },
                            {
                                "name": "missing_colon",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "multiple_root",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "bad_string_continuation",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "invalid_control_char",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "invalid_object_hook",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "invalid_object_pairs_hook",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "reserved_word",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "word_str"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "EncoderErrors",
                        "docstring": "Encoder errors",
                        "comments": null,
                        "methods": [
                            {
                                "name": "circular_reference",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "float_out_of_range",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "obj"
                                ]
                            },
                            {
                                "name": "invalid_key_type",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "key"
                                ]
                            },
                            {
                                "name": "unable_to_encode",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "obj"
                                ]
                            },
                            {
                                "name": "invalid_typed_dict",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "obj"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "src/ujson5/lexer.py",
                "functions": [
                    {
                        "name": "simplify_escapes",
                        "docstring": "Simplify escape sequences in a string. This function replaces line\ncontinuation sequences with a newline character.\n\nArgs:\n    text: string with escape sequences\n\nReturns:\n    str: string with escape sequences simplified",
                        "comments": null,
                        "args": [
                            "text"
                        ]
                    },
                    {
                        "name": "_handle_unexpected_char",
                        "docstring": "Handle unexpected characters in a number token.\n\nArgs:\n    buffer (str): JSON5 document\n    idx (int): current index\n    char (str): unexpected character\n\nRaises:\n    JSON5DecodeError: if the character is unexpected",
                        "comments": null,
                        "args": [
                            "buffer",
                            "idx",
                            "char"
                        ]
                    },
                    {
                        "name": "tokenize_number",
                        "docstring": "Tokenize a number and return the token and the updated index.\n\nArgs:\n    buffer: JSON5 document\n    idx: current index. Must point to the start of the number\n\nReturns:\n    TokenResult: Token and updated index\n\nRaises:\n    JSON5DecodeError: if the number is invalid",
                        "comments": null,
                        "args": [
                            "buffer",
                            "idx"
                        ]
                    },
                    {
                        "name": "_escape_handler",
                        "docstring": "Handle escape sequences. There are a few case to consider:\n- Line continuation: `\\\\` followed by a newline character\n- Single character escape sequence: `\\\\` followed by a character in\n  consts.ESCAPE_SEQUENCE\n- Unicode escape sequence: `\\\\u` followed by 4 hexadecimal digits\n- Hexadecimal escape sequence: `\\\\x` followed by 2 hexadecimal digits\n\nArgs:\n    buffer: JSON5 document\n    idx: current index. Must point to the escape character\n\nReturns:\n    int: updated index\n\nRaises:\n    JSON5DecodeError: if the escape sequence is invalid",
                        "comments": null,
                        "args": [
                            "buffer",
                            "idx"
                        ]
                    },
                    {
                        "name": "tokenize_string",
                        "docstring": "Tokenize a string and return the token and the updated index.\n\nArgs:\n    buffer: JSON5 document\n    idx: current index. Must point to the opening quote\n\nReturns:\n    TokenResult: Token and updated index\n\nRaises:\n    JSON5DecodeError: if the string is invalid",
                        "comments": null,
                        "args": [
                            "buffer",
                            "idx"
                        ]
                    },
                    {
                        "name": "validate_identifier_start",
                        "docstring": "Validate the start of an identifier. An identifier must start with a\nletter, underscore or dollar sign. It can also start with a unicode escape\nsequence.\n\nArgs:\n    buffer: JSON5 document\n    idx: current index. Must point to the start of the identifier\n\nReturns:\n    int: updated index\n\nRaises:\n    JSON5DecodeError: if the identifier is invalid",
                        "comments": null,
                        "args": [
                            "buffer",
                            "idx"
                        ]
                    },
                    {
                        "name": "tokenize_identifier",
                        "docstring": "Tokenize an identifier and return the token and the updated index.\n\nArgs:\n    buffer: JSON5 document\n    idx: current index. Must point to the start of the identifier\n\nReturns:\n    TokenResult: Token and updated index\n\nRaises:\n    JSON5DecodeError: if the identifier is invalid",
                        "comments": null,
                        "args": [
                            "buffer",
                            "idx"
                        ]
                    },
                    {
                        "name": "validate_comment",
                        "docstring": "Validate a comment. An inline comment starts with `//` and ends with a\nnewline character. A block comment starts with `/*` and ends with `*/`.\n\nArgs:\n    buffer: JSON5 document\n    idx: current index. Must point to the start of the comment\n\nReturns:\n    int: updated index\n\nRaises:\n    JSON5DecodeError: if the comment is invalid",
                        "comments": null,
                        "args": [
                            "buffer",
                            "idx"
                        ]
                    },
                    {
                        "name": "tokenize",
                        "docstring": "Tokenize a JSON5 document.\n\nArgs:\n    buffer: JSON5 document\n\nReturns:\n    list[Token]: List of tokens\n\nRaises:\n    JSON5DecodeError: if the document is invalid",
                        "comments": null,
                        "args": [
                            "buffer"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "src/ujson5/consts.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "src/ujson5/decoder.py",
                "functions": [
                    {
                        "name": "loads",
                        "docstring": "Deserialize `json5_str` (a `str`, `bytes` or `bytearray` instance\ncontaining a JSON document) to a Python object.\n\nExample:\n```python\nimport ujson5\njson5_str = '{\"key\": \"value\"}'\nobj = ujson5.loads(json5_str)\n# obj == {'key': 'value'}\n```\n\nAll arguments except `json5_str` are keyword-only.\n\nArgs:\n    json5_str: The JSON5 string to be deserialized.\n    cls: If specified, must be a [`Json5Decoder`][ujson5.Json5Decoder] subclass. The `cls`\n        will be used to instantiate the decoder. If `cls` is not specified, the default\n        `Json5Decoder` will be used.\n    parse_float: if specified, will be called with the string of every JSON float to be\n        decoded. By default this is equivalent to float(num_str). This can be used to use\n        another datatype or parser for JSON floats (e.g. decimal.Decimal).\n    parse_int: if specified, will be called with the string of every JSON int to be\n        decoded. By default this is equivalent to int(num_str). This can be used to\n        use another datatype or parser for JSON integers (e.g. float).\n    parse_constant: if specified, will be called with one of the following strings:\n        '-Infinity', 'Infinity', 'NaN'. This can be used to raise an exception if invalid\n        JSON numbers are encountered.\n    strict: control characters will be allowed inside strings if `strict` is False.\n        Control characters in this context are those with character codes in the 0-31\n        range, including `'\\\\t'` (tab), `'\\\\n'`, `'\\\\r'` and `'\\\\0'`.\n    allow_reserved_words: if `True`, reserved words can be used as identifiers. Reserved\n        words are defined here https://262.ecma-international.org/5.1/#sec-7.6.1.\n        Default is `True`.\n    object_hook: an optional function that will be called with the result of any object\n        literal decode (a `dict`). The return value of `object_hook` will be used instead\n        of the `dict`. This feature can be used to implement custom decoders\n        (e.g. JSON-RPC class hinting).\n    object_pairs_hook: if specified will be called with the result of every JSON object\n        decoded with an ordered list of pairs.  The return value of `object_pairs_hook`\n        will be used instead of the `dict`. This feature can be used to implement\n        custom decoders. If `object_hook` is also defined, the `object_pairs_hook`\n        takes priority.",
                        "comments": null,
                        "args": [
                            "json5_str"
                        ]
                    },
                    {
                        "name": "load",
                        "docstring": "Deserialize `fp` (a `.read()`-supporting file-like object containing\na JSON document) to a Python object.\n\nExample:\n```python\nimport ujson5\nwith open('file.json5', 'r') as f:\n    obj = ujson5.load(f)\n```\n\nAll arguments except `file` are keyword-only.\n\nArgs:\n    file: A file-like object containing a JSON document.\n    cls: If specified, must be a [`Json5Decoder`][ujson5.Json5Decoder] subclass. The `cls`\n        will be used to instantiate the decoder. If `cls` is not specified, the default\n        `Json5Decoder` will be used.\n    parse_float: if specified, will be called with the string of every JSON float to be\n        decoded. By default this is equivalent to float(num_str). This can be used to use\n        another datatype or parser for JSON floats (e.g. decimal.Decimal).\n    parse_int: if specified, will be called with the string of every JSON int to be\n        decoded. By default this is equivalent to int(num_str). This can be used to\n        use another datatype or parser for JSON integers (e.g. float).\n    parse_constant: if specified, will be called with one of the following strings:\n        -Infinity, Infinity, NaN. This can be used to raise an exception if invalid\n        JSON numbers are encountered.\n    strict: control characters will be allowed inside strings if `strict` is False.\n        Control characters in this context are those with character codes in the 0-31\n        range, including `'\\\\t'` (tab), `'\\\\n'`, `'\\\\r'` and `'\\\\0'`.\n    allow_reserved_words: if `True`, reserved words can be used as identifiers. Reserved\n        words are defined here https://262.ecma-international.org/5.1/#sec-7.6.1.\n        Default is `True`.\n    object_hook: an optional function that will be called with the result of any object\n        literal decode (a `dict`). The return value of `object_hook` will be used instead\n        of the `dict`. This feature can be used to implement custom decoders\n        (e.g. JSON-RPC class hinting).\n    object_pairs_hook: if specified will be called with the result of every JSON object\n        decoded with an ordered list of pairs.  The return value of `object_pairs_hook`\n        will be used instead of the `dict`. This feature can be used to implement\n        custom decoders. If `object_hook` is also defined, the `object_pairs_hook`\n        takes priority.",
                        "comments": null,
                        "args": [
                            "input_file"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "Json5Decoder",
                        "docstring": "JSON5 decoder\n\nPerforms the following translations in decoding by default:\n\n| JSON          | Python            |\n|---------------|-------------------|\n| object        | dict              |\n| array         | list              |\n| string        | str               |\n| number (int)  | int               |\n| number (real) | float             |\n| true          | True              |\n| false         | False             |\n| null          | None              |\n\nIt also understands `NaN`, `Infinity`, and `-Infinity` as\ntheir corresponding `float` values, which is outside the JSON spec.\n\nExample:\n```python\nimport ujson5\njson5_str = '{\"key\": \"value\"}'\nobj = ujson5.Json5Decoder().decode(json5_str)\n# obj == {'key': 'value'}\n```\n\nArgs:\n    parse_float: if specified, will be called with the string of every JSON float to be\n        decoded. By default this is equivalent to float(num_str). This can be used to use\n        another datatype or parser for JSON floats (e.g. decimal.Decimal).\n    parse_int: if specified, will be called with the string of every JSON int to be\n        decoded. By default this is equivalent to int(num_str). This can be used to\n        use another datatype or parser for JSON integers (e.g. float).\n    parse_constant: if specified, will be called with one of the following strings:\n        -Infinity, Infinity, NaN. This can be used to raise an exception if invalid\n        JSON numbers are encountered.\n    strict: control characters will be allowed inside strings if `strict` is False.\n        Control characters in this context are those with character codes in the 0-31\n        range, including `'\\\\t'` (tab), `'\\\\n'`, `'\\\\r'` and `'\\\\0'`.\n    allow_reserved_words: if `True`, reserved words can be used as identifiers. Reserved\n        words are defined here https://262.ecma-international.org/5.1/#sec-7.6.1.\n        Default is `True`.\n    object_hook: an optional function that will be called with the result of any object\n        literal decode (a `dict`). The return value of `object_hook` will be used instead\n        of the `dict`. This feature can be used to implement custom decoders\n        (e.g. JSON-RPC class hinting).\n    object_pairs_hook: if specified will be called with the result of every JSON object\n        decoded with an ordered list of pairs.  The return value of `object_pairs_hook`\n        will be used instead of the `dict`. This feature can be used to implement\n        custom decoders. If `object_hook` is also defined, the `object_pairs_hook`\n        takes priority.\n\nRaises:\n    JSON5DecodeError: If the JSON5 string is invalid.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "decode",
                                "docstring": "Deserialize a JSON5 string to a Python object.\n\nArgs:\n    json5_str: The JSON5 string to be deserialized.\n\nReturns:\n    The Python object represented by the JSON5 string.\n\nRaises:\n    JSON5DecodeError: If the JSON5 string is invalid.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "json5_str"
                                ]
                            },
                            {
                                "name": "raw_decode",
                                "docstring": "Deserialize a JSON5 string to a Python object and return the index of the last\ncharacter parsed.\n\nArgs:\n    json5_str: The JSON5 string to be deserialized.\n\nReturns:\n    A tuple of the Python object represented by the JSON5 string and the index\n        of the last character parsed.\n\nRaises:\n    JSON5DecodeError: If the JSON5 string is invalid.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "json5_str"
                                ]
                            },
                            {
                                "name": "_parse_json5",
                                "docstring": "Parse a JSON5 string with tokens.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "json5_str",
                                    "tokens"
                                ]
                            },
                            {
                                "name": "_parse_number",
                                "docstring": "Parse a number.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "num_str"
                                ]
                            },
                            {
                                "name": "_parse_string",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "str_str",
                                    "json5_str",
                                    "str_start_idx"
                                ]
                            },
                            {
                                "name": "_parse_identifier",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "id_str"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "src/ujson5/encoder.py",
                "functions": [
                    {
                        "name": "extend_key_path",
                        "docstring": "Generate a unique name for each key in a composite dictionary by concatenating the\nbase path and the key\n\nArgs:\n    base_path: The base path\n    key: The key to be added to the base path\n\nReturns:\n    str: The extended key path",
                        "comments": null,
                        "args": [
                            "base_path",
                            "key"
                        ]
                    },
                    {
                        "name": "get_comments",
                        "docstring": "Extract comments from a TypedDict class\n\nWarning:\n    Comments extraction is currently only fully supported on Python 3.12+. On older\n    versions, the function will still work but will not extract all comments from the\n    parent TypedDicts.\n\nArgs:\n    typed_dict_cls: The TypedDict class\n\nReturns:\n    CommentsCache: A dictionary containing comments related to each TypedDict entry",
                        "comments": null,
                        "args": [
                            "typed_dict_cls"
                        ]
                    },
                    {
                        "name": "dumps",
                        "docstring": "Serialize `obj` to a JSON5 formatted `str`.\n\nExample:\n```python\nimport ujson5\nuser = {\"name\": \"John\", \"age\": 123, \"hobbies\": [\"tennis\", \"reading\"]}\nprint(ujson5.dumps(user))\n# Output: '{\"name\": \"John\", \"age\": 123, \"hobbies\": [\"tennis\", \"reading\"]}'\n```\n\nAll arguments except `obj` and `typed_dict_cls` are keyword-only arguments.\n\nArgs:\n    cls: The encoder class to be used. a custom [`JSON5Encoder`][ujson5.JSON5Encoder]\n        subclass (e.g. one that overrides the [`.default()`][ujson5.JSON5Encoder.default]\n        method to serialize additional types) can be provided. If None, the default\n        [`JSON5Encoder`][ujson5.JSON5Encoder] class will be used. Defaults to None.\n    default: A function that returns a serializable object when trying to encode an\n        unsupported object. If None, the default\n        [`.default()`][ujson5.JSON5Encoder.default] method will be used. Defaults to None.\n    skip_keys: If True, keys with unsupported types (anything other than str, int, float,\n        bool, or None) will be skipped. Otherwise, an exception will be raised.\n        Defaults to False.\n    ensure_ascii: If True, all non-ASCII characters will be escaped. Defaults to True.\n    check_circular: If True, circular references will be checked. This will introduce a\n        small performance hit. Defaults to True.\n    allow_nan: If True, NaN, Infinity, and -Infinity will be allowed. Otherwise, an\n        exception will be raised when trying to encode these values. Defaults to True.\n    indent: If not None, the output will be formatted with the given indent level.\n        Otherwise, the output will be compact. Defaults to None.\n    separators: A tuple containing the item separator and the key-value separator.\n        Defaults to None. If None, it will be set to (\", \", \": \") if indent is None,\n        and (\",\", \":\") if indent is not None.\n    sort_keys: If True, the keys will be sorted. Defaults to False.\n    key_quotation: The quotation style to be used for keys. Can be one of \"single\",\n        \"double\", or \"none\". If \"single\" or \"double\", the keys will be enclosed in\n        single or double quotes, respectively. If \"none\", the keys will not be enclosed\n        in quotes. Defaults to \"double\".\n    trailing_comma: If True, a trailing comma will be added to the last item in\n        a list or dictionary. If None, a trailing comma will be added if indent\n        is not None. Defaults to None.\n\nReturns:\n    str: The JSON5 formatted string representation of the Python object\n\nRaises:\n    JSON5EncodeError: If the object cannot be serialized",
                        "comments": null,
                        "args": [
                            "obj",
                            "typed_dict_cls"
                        ]
                    },
                    {
                        "name": "dump",
                        "docstring": "Serialize `obj` as a JSON formatted stream to `fp` (a `.write()`-supporting\nfile-like object).\n\nExample:\n```python\nimport ujson5\nuser = {\"name\": \"John\", \"age\": 123, \"hobbies\": [\"tennis\", \"reading\"]}\nwith open(\"user.json\", \"w\") as f:\n    ujson5.dump(user, f)\n```\n\nArgs:\n    cls: The encoder class to be used. a custom [`JSON5Encoder`][ujson5.JSON5Encoder]\n        subclass (e.g. one that overrides the [`.default()`][ujson5.JSON5Encoder.default]\n        method to serialize additional types) can be provided. If None, the default\n        [`JSON5Encoder`][ujson5.JSON5Encoder] class will be used. Defaults to None.\n    default: A function that returns a serializable object when trying to encode an\n        unsupported object. If None, the default\n        [`.default()`][ujson5.JSON5Encoder.default] method will be used. Defaults to None.\n    skip_keys: If True, keys with unsupported types (anything other than str, int, float,\n        bool, or None) will be skipped. Otherwise, an exception will be raised.\n        Defaults to False.\n    ensure_ascii: If True, all non-ASCII characters will be escaped. Defaults to True.\n    check_circular: If True, circular references will be checked. This will introduce a\n        small performance hit. Defaults to True.\n    allow_nan: If True, NaN, Infinity, and -Infinity will be allowed. Otherwise, an\n        exception will be raised when trying to encode these values. Defaults to True.\n    indent: If not None, the output will be formatted with the given indent level.\n        Otherwise, the output will be compact. Defaults to None.\n    separators: A tuple containing the item separator and the key-value separator.\n        Defaults to None. If None, it will be set to (\", \", \": \") if indent is None,\n        and (\",\", \":\") if indent is not None.\n    sort_keys: If True, the keys will be sorted. Defaults to False.\n    key_quotation: The quotation style to be used for keys. Can be one of \"single\",\n        \"double\", or \"none\". If \"single\" or \"double\", the keys will be enclosed in\n        single or double quotes, respectively. If \"none\", the keys will not be enclosed\n        in quotes. Defaults to \"double\".\n    trailing_comma: If True, a trailing comma will be added to the last item in\n        a list or dictionary. If None, a trailing comma will be added if indent\n        is not None. Defaults to None.\n\nReturns:\n    str: The JSON5 formatted string representation of the Python object\n\nRaises:\n    JSON5EncodeError: If the object cannot be serialized",
                        "comments": null,
                        "args": [
                            "obj",
                            "fp",
                            "typed_dict_cls"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "EntryComments",
                        "docstring": "Comments related to a TypedDict entry",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "JSON5Encoder",
                        "docstring": "JSON5 encoder class. This encoder is used to serialize Python objects to JSON5\nstrings. This class mirrors the standard library's JSONEncoder class, with the\naddition of a few extra options and features. This class will transform common data\nstructures according to this table:\n\n| Python            | JSON          |\n|-------------------|---------------|\n| dict              | object        |\n| list, tuple       | array         |\n| str               | string        |\n| int, float        | number        |\n| True              | true          |\n| False             | false         |\n| None              | null          |\n\nTo extend the encoder, subclass this class and override the\n[`.default()`][ujson5.JSON5Encoder.default] method, which will try to encode the\ndata structures that are not supported by default. The\n[`.default()`][ujson5.JSON5Encoder.default] method should return a serializable object.\nIf the [`.default()`][ujson5.JSON5Encoder.default] method is not overridden, the encoder\nwill raise a JSON5EncodeError when trying to encode an unsupported object. The overridden\n[`.default()`][ujson5.JSON5Encoder.default] method should also call the parent class's\n[`.default()`][ujson5.JSON5Encoder.default] method to handle the default encoding.\n\nThe constructor also takes in a `default` argument, which can be used to set a default\nfunction that will be called when trying to encode an unsupported object. This argument\nwill take precedence over the overridden\n[`.default()`][ujson5.JSON5Encoder.default] method.\n\n!!! warning\n    Comment extraction is currently only fully supported on Python 3.12+. On older\n    versions, the function will still work but will not extract all comments from the\n    parent TypedDicts.\n\nExample:\n```python\nimport ujson5\n\n\nclass MyEncoder(ujson5.JSON5Encoder):\n    def default(self, obj):\n        if isinstance(obj, set):  # (1)!\n            return list(obj)\n        return super().default(obj)  # (2)!\n\n\nuser = {\"name\": \"John\", \"age\": \"123\", \"hobbies\": {\"tennis\", \"reading\"}}\nprint(ujson5.dumps(user, cls=MyEncoder))\n# {\"name\": \"John\", \"age\": \"123\", \"hobbies\": [\"reading\", \"tennis\"]}\n```\n\n1. In this example, the encoder subclass `MyEncoder` overrides the\n[`.default()`][ujson5.JSON5Encoder.default] method to handle the serialization of sets.\nThe method returns a list of the set elements.\n2. It is recommended to call the parent class's [`.default()`][ujson5.JSON5Encoder.default]\nmethod to handle the default encoding.\n\nAll arguments are keyword-only arguments.\n\nArgs:\n    default: A function that returns a serializable object when trying to encode an\n        unsupported object. If None, the default`.default()` method will be used.\n        Defaults to None.\n    skip_keys: If True, keys with unsupported types (anything other than str, int, float,\n        bool, or None) will be skipped. Otherwise, an exception will be raised.\n        Defaults to False.\n    ensure_ascii: If True, all non-ASCII characters will be escaped. Defaults to True.\n    check_circular: If True, circular references will be checked. This will introduce a\n        small performance hit. Defaults to True.\n    allow_nan: If True, NaN, Infinity, and -Infinity will be allowed. Otherwise, an\n        exception will be raised when trying to encode these values. Defaults to True.\n    indent: If not None, the output will be formatted with the given indent level.\n        Otherwise, the output will be compact. Defaults to None.\n    separators: A tuple containing the item separator and the key-value separator.\n        Defaults to None. If None, it will be set to (\", \", \": \") if indent is None,\n        and (\",\", \":\") if indent is not None.\n    sort_keys: If True, the keys will be sorted. Defaults to False.\n    key_quotation: The quotation style to be used for keys. Can be one of \"single\",\n        \"double\", or \"none\". If \"single\" or \"double\", the keys will be enclosed in\n        single or double quotes, respectively. If \"none\", the keys will not be enclosed\n        in quotes. Defaults to \"double\".\n    trailing_comma: If True, a trailing comma will be added to the last item in\n        a list or dictionary. If None, a trailing comma will be added if indent\n        is not None. Defaults to None.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "encode",
                                "docstring": "Return a JSON5 string representation of a Python object.\n\nArgs:\n    obj: The Python object to be serialized\n    typed_dict_cls: A TypedDict class that will be used to extract comments from\n        the TypedDict entries. Defaults to None.\n\nReturns:\n    str: The JSON5 string representation of the Python object\n\nRaises:\n    JSON5EncodeError: If the TypedDict class is not a TypedDict subclass or if the\n        object cannot be serialized",
                                "comments": null,
                                "args": [
                                    "self",
                                    "obj",
                                    "typed_dict_cls"
                                ]
                            },
                            {
                                "name": "iterencode",
                                "docstring": "Encode the given object and yield each part of the JSON5 string representation\n\nArgs:\n    obj: The Python object to be serialized\n    typed_dict_cls: A TypedDict class that will be used to extract comments from\n        the TypedDict entries. Defaults to None.\n\nReturns:\n    Iterable[str]: An iterable of strings representing the JSON5 serialization of the\n        Python object\n\nRaises:\n    JSON5EncodeError: If the TypedDict class is not a TypedDict subclass or if the\n        object cannot be serialized",
                                "comments": null,
                                "args": [
                                    "self",
                                    "obj",
                                    "typed_dict_cls"
                                ]
                            },
                            {
                                "name": "default",
                                "docstring": "Override this method in a subclass to implement custom serialization\nfor objects that are not serializable by default. This method should return\na serializable object. If this method is not overridden, the encoder will\nraise a JSON5EncodeError when trying to encode an unsupported object.\n\nArgs:\n    obj: The object to be serialized that is not supported by default\n\nReturns:\n    Serializable: A serializable object\n\nRaises:\n    JSON5EncodeError: If the object cannot be serialized",
                                "comments": null,
                                "args": [
                                    "self",
                                    "obj"
                                ]
                            },
                            {
                                "name": "_encode_int",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "obj"
                                ]
                            },
                            {
                                "name": "_encode_float",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "obj"
                                ]
                            },
                            {
                                "name": "_encode_str",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "obj",
                                    "key_str"
                                ]
                            },
                            {
                                "name": "_iterencode",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "obj",
                                    "indent_level",
                                    "key_path"
                                ]
                            },
                            {
                                "name": "_iterencode_list",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "obj",
                                    "indent_level",
                                    "key_path"
                                ]
                            },
                            {
                                "name": "_iterencode_dict",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "obj",
                                    "indent_level",
                                    "key_path"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "release/push.py",
                "functions": [
                    {
                        "name": "get_latest_version_from_changelog",
                        "docstring": "Get the most recently listed version from the changelog.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "get_latest_release_notes_from_changelog",
                        "docstring": "Get the release notes for the latest version from the changelog.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "commit_and_push_changes",
                        "docstring": "Commit and push changes to a new branch.",
                        "comments": null,
                        "args": [
                            "rl_version"
                        ]
                    },
                    {
                        "name": "open_pull_request",
                        "docstring": "Open a pull request on GitHub.",
                        "comments": null,
                        "args": [
                            "rl_version"
                        ]
                    },
                    {
                        "name": "create_version_tag",
                        "docstring": "Create a version tag.",
                        "comments": null,
                        "args": [
                            "rl_version"
                        ]
                    },
                    {
                        "name": "create_github_release",
                        "docstring": "Create a new release on GitHub.",
                        "comments": null,
                        "args": [
                            "new_version",
                            "notes"
                        ]
                    },
                    {
                        "name": "create_github_release_draft",
                        "docstring": "Create a GitHub release draft.",
                        "comments": null,
                        "args": [
                            "rl_version",
                            "rl_release_notes"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "release/prepare.py",
                "functions": [
                    {
                        "name": "get_previous_version",
                        "docstring": "Get the latest git tag from the repository.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "update_version",
                        "docstring": "Update the version in the giving py version file.\nNote that both the arg `new_version` and the version in the file should be in the format\n\"X.Y.Z\" without the leading \"v\". The leading \"v\" will be added automatically.\n\nArgs:\n    new_version (str): The new version to set.\n\nReturns:\n    str: The old version.",
                        "comments": null,
                        "args": [
                            "new_version"
                        ]
                    },
                    {
                        "name": "get_notes",
                        "docstring": "Fetch auto-generated release notes from github.\n\nArgs:\n    new_version (str): The new version to set. Version without the leading \"v\".\n\nReturns:\n    str: The release notes.",
                        "comments": null,
                        "args": [
                            "new_version"
                        ]
                    },
                    {
                        "name": "update_changelog",
                        "docstring": "Generate release notes and prepend them to HISTORY.md.\nBoth versions should be in the format \"X.Y.Z\" without the leading \"v\".\n\nArgs:\n    old_version (str): The old version.\n    new_version (str): The new version to set.",
                        "comments": null,
                        "args": [
                            "old_version",
                            "new_version"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "release/shared.py",
                "functions": [
                    {
                        "name": "run_command",
                        "docstring": "Run a shell command and return the output.",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            }
        ],
        "test_cases": {
            "tests/test_benchmark.py::test_ujson5_benchmark[path0]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path0]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path1]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path1]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path2]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path2]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path3]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path3]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path4]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path4]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path5]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path5]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path6]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path6]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path7]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path7]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path8]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path8]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path9]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path9]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path10]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path10]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path11]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path11]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path12]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path12]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path13]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path13]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path14]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path14]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path15]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path15]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path16]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path16]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path17]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path17]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path18]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path18]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path19]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path19]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path20]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path20]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path21]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path21]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path22]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path22]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path23]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path23]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path24]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path24]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path25]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path25]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path26]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path26]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path27]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path27]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path28]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path28]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path29]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path29]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path30]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path30]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path31]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path31]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path32]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path32]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path33]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path33]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path34]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path34]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path35]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path35]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path36]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path36]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path37]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path37]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path38]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path38]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path39]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path39]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path40]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path40]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path41]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path41]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path42]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path42]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path43]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path43]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path44]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path44]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path45]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path45]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path46]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path46]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path47]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path47]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path48]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path48]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path49]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path49]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path50]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path50]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path51]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path51]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path52]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path52]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path53]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path53]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path54]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path54]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path55]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path55]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path56]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path56]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path57]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path57]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path58]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path58]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path59]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path59]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path60]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path60]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path61]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path61]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path62]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path62]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path63]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path63]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path64]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path64]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path65]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path65]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path66]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path66]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path67]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path67]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path68]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path68]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path69]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path69]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path70]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path70]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path71]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path71]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path72]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path72]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path73]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path73]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path74]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path74]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path75]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path75]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path76]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path76]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path77]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path77]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path78]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path78]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path79]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path79]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path80]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path80]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_benchmark.py::test_ujson5_benchmark[path81]": {
                "testid": "tests/test_benchmark.py::test_ujson5_benchmark[path81]",
                "result": "skipped",
                "test_implementation": "def test_ujson5_benchmark(path: str, benchmark) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(\n        os.path.join(example_consts.EXAMPLE_ROOT, \"arrays\", path), \"r\", encoding=\"utf8\"\n    ) as file:\n        content = file.read()\n    benchmark(ujson5.loads, content)"
            },
            "tests/test_blns.py::test_blns": {
                "testid": "tests/test_blns.py::test_blns",
                "result": "passed",
                "test_implementation": "def test_blns() -> None:\n    \"\"\"Test for JSON checker files.\"\"\"\n    with open(BLNS_PATH, \"r\", encoding=\"utf-8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_cli.py::test_cli_version[--version]": {
                "testid": "tests/test_cli.py::test_cli_version[--version]",
                "result": "passed",
                "test_implementation": "def test_cli_version(arg: str) -> None:\n    \"\"\"Test version output.\"\"\"\n    with redirect_stdout(io.StringIO()) as f:\n        cli.main([arg])\n    assert f.getvalue().strip() == ujson5.__version__"
            },
            "tests/test_cli.py::test_cli_version[-v]": {
                "testid": "tests/test_cli.py::test_cli_version[-v]",
                "result": "passed",
                "test_implementation": "def test_cli_version(arg: str) -> None:\n    \"\"\"Test version output.\"\"\"\n    with redirect_stdout(io.StringIO()) as f:\n        cli.main([arg])\n    assert f.getvalue().strip() == ujson5.__version__"
            },
            "tests/test_cli.py::test_cli_info[--info]": {
                "testid": "tests/test_cli.py::test_cli_info[--info]",
                "result": "passed",
                "test_implementation": "def test_cli_info(arg: str) -> None:\n    \"\"\"Test version info output.\"\"\"\n    with redirect_stdout(io.StringIO()) as f:\n        cli.main([arg])\n    assert f.getvalue().strip() == ujson5.version_info()"
            },
            "tests/test_cli.py::test_cli_info[-i]": {
                "testid": "tests/test_cli.py::test_cli_info[-i]",
                "result": "passed",
                "test_implementation": "def test_cli_info(arg: str) -> None:\n    \"\"\"Test version info output.\"\"\"\n    with redirect_stdout(io.StringIO()) as f:\n        cli.main([arg])\n    assert f.getvalue().strip() == ujson5.version_info()"
            },
            "tests/test_cli.py::test_cli_stdout_correct": {
                "testid": "tests/test_cli.py::test_cli_stdout_correct",
                "result": "passed",
                "test_implementation": "def test_cli_stdout_correct() -> None:\n    \"\"\"Test stdout output.\"\"\"\n    with redirect_stdout(io.StringIO()) as f:\n        cli.main([str(choice(example_consts.VALID_EXAMPLES))])\n    assert cli.JSON_CONVERTED in f.getvalue().strip()"
            },
            "tests/test_cli.py::test_cli_stdout_incorrect": {
                "testid": "tests/test_cli.py::test_cli_stdout_incorrect",
                "result": "passed",
                "test_implementation": "def test_cli_stdout_incorrect() -> None:\n    \"\"\"Test stdout output.\"\"\"\n    with redirect_stdout(io.StringIO()) as f:\n        cli.main([str(choice(example_consts.INVALID_EXAMPLES))])\n    assert cli.DECODING_ERROR in f.getvalue().strip()"
            },
            "tests/test_cli.py::test_cli_no_target": {
                "testid": "tests/test_cli.py::test_cli_no_target",
                "result": "passed",
                "test_implementation": "def test_cli_no_target(monkeypatch) -> None:\n    \"\"\"Test no target.\"\"\"\n    monkeypatch.setattr(\"sys.stdin.isatty\", lambda: True)\n    with redirect_stdout(io.StringIO()) as f:\n        cli.main([])\n    assert cli.ERR_NO_TARGET in f.getvalue().strip()"
            },
            "tests/test_cli.py::test_cli_stdin": {
                "testid": "tests/test_cli.py::test_cli_stdin",
                "result": "passed",
                "test_implementation": "def test_cli_stdin(monkeypatch) -> None:\n    \"\"\"Test reading from stdin with options.\"\"\"\n    monkeypatch.setattr(\"sys.stdin\", io.StringIO('{\"json\": \"obj\"}'))\n    with redirect_stdout(io.StringIO()) as f:\n        cli.main([\"--no-indent\"])\n    assert '{\"json\": \"obj\"}' in f.getvalue().strip()\n    assert cli.JSON_CONVERTED in f.getvalue().strip()\n\n    monkeypatch.setattr(\"sys.stdin\", io.StringIO('{\"json\": \"obj\"}'))\n    with redirect_stdout(io.StringIO()) as f:\n        cli.main([\"--compact\"])\n    assert '{\"json\":\"obj\"}' in f.getvalue().strip()\n    assert cli.JSON_CONVERTED in f.getvalue().strip()"
            },
            "tests/test_cli.py::test_cli_invalid_path": {
                "testid": "tests/test_cli.py::test_cli_invalid_path",
                "result": "passed",
                "test_implementation": "def test_cli_invalid_path() -> None:\n    \"\"\"Test invalid path.\"\"\"\n    with redirect_stdout(io.StringIO()) as f:\n        cli.main([str(choice(example_consts.INVALID_EXAMPLES).parent / \"wrong.json5\")])\n    assert cli.ERR_TARGET_NOT_EXIST in f.getvalue().strip()"
            },
            "tests/test_cli.py::test_cli_output": {
                "testid": "tests/test_cli.py::test_cli_output",
                "result": "passed",
                "test_implementation": "def test_cli_output(tmp_path: Path) -> None:\n    \"\"\"Test output file.\"\"\"\n    target: Path = choice(example_consts.VALID_EXAMPLES)\n    output: Path = tmp_path / \"output.json5\"\n    assert not output.exists()\n    cli.main([str(target), str(output)])\n    assert output.exists()"
            },
            "tests/test_json5_examples.py::test_valid_examples[path0]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path0]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path1]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path1]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path2]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path2]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path3]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path3]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path4]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path4]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path5]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path5]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path6]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path6]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path7]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path7]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path8]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path8]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path9]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path9]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path10]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path10]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path11]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path11]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path12]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path12]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path13]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path13]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path14]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path14]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path15]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path15]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path16]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path16]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path17]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path17]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path18]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path18]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path19]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path19]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path20]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path20]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path21]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path21]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path22]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path22]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path23]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path23]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path24]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path24]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path25]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path25]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path26]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path26]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path27]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path27]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path28]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path28]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path29]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path29]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path30]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path30]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path31]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path31]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path32]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path32]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path33]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path33]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path34]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path34]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path35]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path35]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path36]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path36]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path37]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path37]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path38]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path38]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path39]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path39]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path40]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path40]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path41]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path41]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path42]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path42]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path43]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path43]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path44]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path44]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path45]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path45]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path46]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path46]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path47]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path47]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path48]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path48]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path49]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path49]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path50]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path50]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path51]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path51]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path52]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path52]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path53]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path53]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path54]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path54]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path55]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path55]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path56]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path56]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path57]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path57]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path58]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path58]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path59]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path59]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path60]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path60]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path61]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path61]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path62]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path62]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path63]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path63]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path64]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path64]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path65]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path65]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path66]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path66]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path67]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path67]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path68]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path68]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path69]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path69]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path70]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path70]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path71]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path71]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path72]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path72]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path73]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path73]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path74]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path74]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path75]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path75]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path76]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path76]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path77]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path77]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path78]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path78]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path79]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path79]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path80]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path80]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_valid_examples[path81]": {
                "testid": "tests/test_json5_examples.py::test_valid_examples[path81]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(path: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path0]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path0]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path1]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path1]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path2]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path2]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path3]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path3]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path4]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path4]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path5]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path5]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path6]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path6]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path7]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path7]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path8]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path8]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path9]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path9]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path10]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path10]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path11]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path11]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path12]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path12]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path13]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path13]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path14]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path14]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path15]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path15]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path16]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path16]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path17]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path17]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path18]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path18]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path19]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path19]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path20]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path20]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path21]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path21]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path22]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path22]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path23]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path23]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path24]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path24]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path25]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path25]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path26]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path26]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path27]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path27]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path28]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path28]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path29]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path29]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path30]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path30]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_invalid_examples[path31]": {
                "testid": "tests/test_json5_examples.py::test_invalid_examples[path31]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(path: str) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with (\n        open(path, \"r\", encoding=\"utf8\") as file,\n        pytest.raises(ujson5.JSON5DecodeError),\n    ):\n        ujson5.load(file)"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path0]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path0]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path1]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path1]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path2]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path2]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path3]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path3]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path4]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path4]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path5]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path5]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path6]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path6]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path7]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path7]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path8]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path8]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path9]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path9]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path10]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path10]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path11]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path11]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path12]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path12]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path13]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path13]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path14]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path14]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path15]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path15]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path16]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path16]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path17]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path17]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path18]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path18]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path19]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path19]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path20]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path20]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path21]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path21]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path22]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path22]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path23]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path23]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path24]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path24]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path25]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path25]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path26]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path26]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path27]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path27]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path28]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path28]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path29]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path29]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path30]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path30]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path31]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path31]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path32]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path32]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path33]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path33]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path34]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path34]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path35]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path35]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path36]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path36]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path37]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path37]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path38]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path38]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path39]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path39]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path40]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path40]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path41]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path41]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path42]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path42]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path43]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path43]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path44]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path44]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path45]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path45]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path46]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path46]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path47]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path47]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path48]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path48]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path49]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path49]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path50]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path50]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path51]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path51]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path52]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path52]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path53]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path53]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path54]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path54]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path55]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path55]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path56]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path56]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path57]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path57]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path58]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path58]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path59]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path59]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path60]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path60]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path61]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path61]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path62]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path62]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path63]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path63]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path64]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path64]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path65]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path65]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path66]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path66]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path67]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path67]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path68]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path68]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path69]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path69]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path70]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path70]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path71]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path71]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path72]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path72]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path73]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path73]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path74]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path74]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path75]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path75]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path76]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path76]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path77]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path77]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path78]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path78]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path79]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path79]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path80]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path80]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json5_examples.py::test_dump_load_from_examples[path81]": {
                "testid": "tests/test_json5_examples.py::test_dump_load_from_examples[path81]",
                "result": "passed",
                "test_implementation": "def test_dump_load_from_examples(path: str, tmp_path: Path) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        py_obj = ujson5.load(file)\n    dump_path_config = tmp_path / \"dump_config.json5\"\n    dump_path_default = tmp_path / \"dump_default.json5\"\n    with open(path, \"r\", encoding=\"utf8\") as file:\n        orig_content: str = file.read()\n    non_ascii = bool(re.search(r\"[^\\x00-\\x7F]\", orig_content))\n    with open(dump_path_config, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file, indent=4, ensure_ascii=not non_ascii)\n\n    with open(dump_path_default, \"w\", encoding=\"utf8\") as file:\n        ujson5.dump(py_obj, file)\n\n    with open(dump_path_config, \"r\", encoding=\"utf8\") as file:\n        new_content = ujson5.load(file)\n\n    with open(dump_path_default, \"r\", encoding=\"utf8\") as file:\n        new_content_default = ujson5.load(file)\n\n    if str(py_obj) == \"nan\":\n        assert str(new_content) == \"nan\"\n        assert str(new_content_default) == \"nan\"\n        return\n    assert py_obj == new_content == new_content_default"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path0]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path0]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path1]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path1]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path2]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path2]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path3]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path3]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path4]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path4]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path5]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path5]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path6]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path6]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path7]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path7]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path8]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path8]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path9]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path9]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path10]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path10]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path11]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path11]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path12]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path12]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path13]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path13]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path14]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path14]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path15]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path15]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path16]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path16]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path17]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path17]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path18]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path18]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path19]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path19]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path20]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path20]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path21]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path21]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path22]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path22]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path23]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path23]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path24]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path24]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path25]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path25]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path26]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path26]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path27]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path27]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path28]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path28]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path29]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path29]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path30]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path30]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path31]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path31]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path32]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path32]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path33]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path33]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path34]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path34]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path35]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path35]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path36]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path36]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path37]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path37]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path38]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path38]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path39]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path39]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path40]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path40]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path41]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path41]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path42]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path42]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path43]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path43]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path44]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path44]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path45]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path45]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path46]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path46]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path47]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path47]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path48]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path48]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path49]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path49]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path50]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path50]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path51]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path51]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path52]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path52]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path53]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path53]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path54]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path54]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path55]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path55]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path56]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path56]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path57]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path57]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path58]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path58]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path59]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path59]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path60]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path60]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path61]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path61]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path62]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path62]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path63]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path63]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path64]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path64]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path65]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path65]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path66]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path66]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path67]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path67]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path68]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path68]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path69]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path69]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path70]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path70]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path71]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path71]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path72]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path72]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path73]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path73]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path74]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path74]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path75]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path75]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path76]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path76]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path77]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path77]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path78]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path78]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path79]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path79]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path80]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path80]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path81]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path81]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path82]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path82]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path83]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path83]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path84]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path84]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path85]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path85]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path86]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path86]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path87]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path87]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path88]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path88]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path89]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path89]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path90]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path90]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path91]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path91]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_json_test_suit.py::test_accepted_json[file_path92]": {
                "testid": "tests/test_json_test_suit.py::test_accepted_json[file_path92]",
                "result": "passed",
                "test_implementation": "def test_accepted_json(file_path: Path) -> None:\n    \"\"\"Any accepted JSON is a valid JSON5.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_native_json_benchmark.py::test_json_checker_file[file_path0]": {
                "testid": "tests/test_native_json_benchmark.py::test_json_checker_file[file_path0]",
                "result": "passed",
                "test_implementation": "def test_json_checker_file(file_path: Path) -> None:\n    \"\"\"Test for JSON checker files.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_native_json_benchmark.py::test_json_checker_file[file_path1]": {
                "testid": "tests/test_native_json_benchmark.py::test_json_checker_file[file_path1]",
                "result": "passed",
                "test_implementation": "def test_json_checker_file(file_path: Path) -> None:\n    \"\"\"Test for JSON checker files.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_native_json_benchmark.py::test_json_checker_file[file_path2]": {
                "testid": "tests/test_native_json_benchmark.py::test_json_checker_file[file_path2]",
                "result": "passed",
                "test_implementation": "def test_json_checker_file(file_path: Path) -> None:\n    \"\"\"Test for JSON checker files.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        ujson5.load(file, strict=False)"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path0]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path0]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path1]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path1]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path2]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path2]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path3]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path3]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path4]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path4]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path5]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path5]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path6]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path6]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path7]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path7]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path8]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path8]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path9]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path9]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path10]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path10]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path11]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path11]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path12]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path12]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path13]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path13]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path14]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path14]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path15]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path15]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path16]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path16]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path17]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path17]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path18]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path18]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path19]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path19]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path20]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path20]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path21]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path21]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path22]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path22]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path23]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path23]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path24]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path24]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path25]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path25]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_round_trips[file_path26]": {
                "testid": "tests/test_native_json_benchmark.py::test_round_trips[file_path26]",
                "result": "passed",
                "test_implementation": "def test_round_trips(file_path: Path) -> None:\n    \"\"\"Test for loading and dumping.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf8\") as file:\n        data = ujson5.load(file, strict=False)\n        assert data == ujson5.loads(ujson5.dumps(data))"
            },
            "tests/test_native_json_benchmark.py::test_loading_canada_file": {
                "testid": "tests/test_native_json_benchmark.py::test_loading_canada_file",
                "result": "skipped",
                "test_implementation": "def test_loading_canada_file(benchmark) -> None:  # pragma: no cover\n    \"\"\"Test for loading large files.\"\"\"\n    with open(BASE_FOLDER / \"canada.json\", \"r\", encoding=\"utf8\") as file:\n        content: str = file.read()\n    benchmark(ujson5.loads, content, strict=False)"
            },
            "tests/test_native_json_benchmark.py::test_loading_citm_catalog_file": {
                "testid": "tests/test_native_json_benchmark.py::test_loading_citm_catalog_file",
                "result": "skipped",
                "test_implementation": "def test_loading_citm_catalog_file(benchmark) -> None:  # pragma: no cover\n    \"\"\"Test for loading large files.\"\"\"\n    with open(BASE_FOLDER / \"citm_catalog.json\", \"r\", encoding=\"utf8\") as file:\n        content: str = file.read()\n    benchmark(ujson5.loads, content, strict=False)"
            },
            "tests/test_native_json_benchmark.py::test_loading_citm_twitter_file": {
                "testid": "tests/test_native_json_benchmark.py::test_loading_citm_twitter_file",
                "result": "skipped",
                "test_implementation": "def test_loading_citm_twitter_file(benchmark) -> None:  # pragma: no cover\n    \"\"\"Test for loading large files.\"\"\"\n    with open(BASE_FOLDER / \"twitter.json\", \"r\", encoding=\"utf8\") as file:\n        content: str = file.read()\n    benchmark(ujson5.loads, content, strict=False)"
            },
            "tests/test_snapshots/test_snapshots.py::test_load_json5_from_alpha_snapshots": {
                "testid": "tests/test_snapshots/test_snapshots.py::test_load_json5_from_alpha_snapshots",
                "result": "passed",
                "test_implementation": "def test_load_json5_from_alpha_snapshots():\n    \"\"\"Test loading alpha snapshots.\"\"\"\n    for snapshot_name in snapshots.SNAPSHOT_NAMES.values():\n        if snapshot_name == \"alpha_special_separators.json5\":\n            continue\n        with open(\n            snapshots.SNAPSHOTS_ROOT / snapshot_name, \"r\", encoding=\"utf8\"\n        ) as file:\n            assert ujson5.load(file) == snapshots.ALPHA"
            },
            "tests/test_snapshots/test_snapshots.py::test_alpha_default": {
                "testid": "tests/test_snapshots/test_snapshots.py::test_alpha_default",
                "result": "passed",
                "test_implementation": "def test_alpha_default():\n    \"\"\"Test dump consistency.\"\"\"\n    with open(\n        snapshots.SNAPSHOTS_ROOT / snapshots.SNAPSHOT_NAMES[\"alpha_default\"],\n        \"r\",\n        encoding=\"utf8\",\n    ) as file:\n        assert ujson5.dumps(snapshots.ALPHA) == file.read().strip()"
            },
            "tests/test_snapshots/test_snapshots.py::test_alpha_with_comments": {
                "testid": "tests/test_snapshots/test_snapshots.py::test_alpha_with_comments",
                "result": "passed",
                "test_implementation": "def test_alpha_with_comments():\n    \"\"\"Test dump consistency.\"\"\"\n    if sys.version_info < (3, 12):\n        # `__orig_bases__` is not available before Python 3.12,\n        # we will find a way to test this in the future\n        pytest.skip(\"Currently only support at least Python 3.12\")\n    with open(\n        snapshots.SNAPSHOTS_ROOT / snapshots.SNAPSHOT_NAMES[\"alpha_with_comments\"],\n        \"r\",\n        encoding=\"utf8\",\n    ) as file:\n        assert (\n            ujson5.dumps(\n                snapshots.ALPHA, snapshots.Human, indent=snapshots.DEFAULT_INDENT\n            )\n            == file.read().strip()\n        )"
            },
            "tests/test_snapshots/test_snapshots.py::test_alpha_no_comments": {
                "testid": "tests/test_snapshots/test_snapshots.py::test_alpha_no_comments",
                "result": "passed",
                "test_implementation": "def test_alpha_no_comments():\n    \"\"\"Test dumping alpha without comments.\"\"\"\n    with open(\n        snapshots.SNAPSHOTS_ROOT / snapshots.SNAPSHOT_NAMES[\"alpha_no_comments\"],\n        \"r\",\n        encoding=\"utf8\",\n    ) as file:\n        assert (\n            ujson5.dumps(snapshots.ALPHA, indent=snapshots.DEFAULT_INDENT)\n            == file.read().strip()\n        )"
            },
            "tests/test_snapshots/test_snapshots.py::test_alpha_no_indent": {
                "testid": "tests/test_snapshots/test_snapshots.py::test_alpha_no_indent",
                "result": "passed",
                "test_implementation": "def test_alpha_no_indent():\n    \"\"\"Test dumping alpha without indent.\"\"\"\n    with open(\n        snapshots.SNAPSHOTS_ROOT / snapshots.SNAPSHOT_NAMES[\"alpha_no_indent\"],\n        \"r\",\n        encoding=\"utf8\",\n    ) as file:\n        assert ujson5.dumps(snapshots.ALPHA) == file.read().strip()"
            },
            "tests/test_snapshots/test_snapshots.py::test_alpha_7_indent": {
                "testid": "tests/test_snapshots/test_snapshots.py::test_alpha_7_indent",
                "result": "passed",
                "test_implementation": "def test_alpha_7_indent():\n    \"\"\"Test dumping alpha with 7 indent.\"\"\"\n    with open(\n        snapshots.SNAPSHOTS_ROOT / snapshots.SNAPSHOT_NAMES[\"alpha_7_indent\"],\n        \"r\",\n        encoding=\"utf8\",\n    ) as file:\n        assert ujson5.dumps(snapshots.ALPHA, indent=7) == file.read().strip()"
            },
            "tests/test_snapshots/test_snapshots.py::test_alpha_special_separators": {
                "testid": "tests/test_snapshots/test_snapshots.py::test_alpha_special_separators",
                "result": "passed",
                "test_implementation": "def test_alpha_special_separators():\n    \"\"\"Test dumping alpha with special separators.\"\"\"\n    with open(\n        snapshots.SNAPSHOTS_ROOT / snapshots.SNAPSHOT_NAMES[\"alpha_special_separators\"],\n        \"r\",\n        encoding=\"utf8\",\n    ) as file:\n        assert (\n            ujson5.dumps(\n                snapshots.ALPHA, indent=snapshots.DEFAULT_INDENT, separators=(\"|\", \"->\")\n            )\n            == file.read().strip()\n        )"
            },
            "tests/test_snapshots/test_snapshots.py::test_alpha_with_trailing_comma": {
                "testid": "tests/test_snapshots/test_snapshots.py::test_alpha_with_trailing_comma",
                "result": "passed",
                "test_implementation": "def test_alpha_with_trailing_comma():\n    \"\"\"Test dumping alpha with trailing comma.\"\"\"\n    with open(\n        snapshots.SNAPSHOTS_ROOT\n        / snapshots.SNAPSHOT_NAMES[\"alpha_with_trailing_comma\"],\n        \"r\",\n        encoding=\"utf8\",\n    ) as file:\n        assert (\n            ujson5.dumps(\n                snapshots.ALPHA, indent=snapshots.DEFAULT_INDENT, trailing_comma=True\n            )\n            == file.read().strip()\n        )"
            },
            "tests/test_snapshots/test_snapshots.py::test_alpha_no_trailing_comma": {
                "testid": "tests/test_snapshots/test_snapshots.py::test_alpha_no_trailing_comma",
                "result": "passed",
                "test_implementation": "def test_alpha_no_trailing_comma():\n    \"\"\"Test dumping alpha without trailing comma.\"\"\"\n    with open(\n        snapshots.SNAPSHOTS_ROOT / snapshots.SNAPSHOT_NAMES[\"alpha_no_trailing_comma\"],\n        \"r\",\n        encoding=\"utf8\",\n    ) as file:\n        assert (\n            ujson5.dumps(\n                snapshots.ALPHA, indent=snapshots.DEFAULT_INDENT, trailing_comma=False\n            )\n            == file.read().strip()\n        )"
            },
            "tests/test_unit_tests/test_comment_lexer.py::test_valid_comments[//-2]": {
                "testid": "tests/test_unit_tests/test_comment_lexer.py::test_valid_comments[//-2]",
                "result": "passed",
                "test_implementation": "def test_valid_comments(comment: str, end: int) -> None:\n    \"\"\"Test valid comments.\"\"\"\n    idx = validate_comment(comment, 0)\n    assert idx == end"
            },
            "tests/test_unit_tests/test_comment_lexer.py::test_valid_comments[// some comment is here\\n new line-24]": {
                "testid": "tests/test_unit_tests/test_comment_lexer.py::test_valid_comments[// some comment is here\\n new line-24]",
                "result": "passed",
                "test_implementation": "def test_valid_comments(comment: str, end: int) -> None:\n    \"\"\"Test valid comments.\"\"\"\n    idx = validate_comment(comment, 0)\n    assert idx == end"
            },
            "tests/test_unit_tests/test_comment_lexer.py::test_valid_comments[/* some comment is here */-26]": {
                "testid": "tests/test_unit_tests/test_comment_lexer.py::test_valid_comments[/* some comment is here */-26]",
                "result": "passed",
                "test_implementation": "def test_valid_comments(comment: str, end: int) -> None:\n    \"\"\"Test valid comments.\"\"\"\n    idx = validate_comment(comment, 0)\n    assert idx == end"
            },
            "tests/test_unit_tests/test_comment_lexer.py::test_valid_comments[/* some comment is here\\n new line */-36]": {
                "testid": "tests/test_unit_tests/test_comment_lexer.py::test_valid_comments[/* some comment is here\\n new line */-36]",
                "result": "passed",
                "test_implementation": "def test_valid_comments(comment: str, end: int) -> None:\n    \"\"\"Test valid comments.\"\"\"\n    idx = validate_comment(comment, 0)\n    assert idx == end"
            },
            "tests/test_unit_tests/test_comment_lexer.py::test_valid_comments[/* some comment is here\\n new line */ new line-36]": {
                "testid": "tests/test_unit_tests/test_comment_lexer.py::test_valid_comments[/* some comment is here\\n new line */ new line-36]",
                "result": "passed",
                "test_implementation": "def test_valid_comments(comment: str, end: int) -> None:\n    \"\"\"Test valid comments.\"\"\"\n    idx = validate_comment(comment, 0)\n    assert idx == end"
            },
            "tests/test_unit_tests/test_comment_lexer.py::test_invalid_comments[/]": {
                "testid": "tests/test_unit_tests/test_comment_lexer.py::test_invalid_comments[/]",
                "result": "passed",
                "test_implementation": "def test_invalid_comments(comment: str) -> None:\n    \"\"\"Test invalid comments.\"\"\"\n    with pytest.raises(ValueError):\n        validate_comment(comment, 0)"
            },
            "tests/test_unit_tests/test_comment_lexer.py::test_invalid_comments[/*]": {
                "testid": "tests/test_unit_tests/test_comment_lexer.py::test_invalid_comments[/*]",
                "result": "passed",
                "test_implementation": "def test_invalid_comments(comment: str) -> None:\n    \"\"\"Test invalid comments.\"\"\"\n    with pytest.raises(ValueError):\n        validate_comment(comment, 0)"
            },
            "tests/test_unit_tests/test_comment_lexer.py::test_invalid_comments[/* some comment is here]": {
                "testid": "tests/test_unit_tests/test_comment_lexer.py::test_invalid_comments[/* some comment is here]",
                "result": "passed",
                "test_implementation": "def test_invalid_comments(comment: str) -> None:\n    \"\"\"Test invalid comments.\"\"\"\n    with pytest.raises(ValueError):\n        validate_comment(comment, 0)"
            },
            "tests/test_unit_tests/test_comment_lexer.py::test_invalid_comments[/* some comment is here*]": {
                "testid": "tests/test_unit_tests/test_comment_lexer.py::test_invalid_comments[/* some comment is here*]",
                "result": "passed",
                "test_implementation": "def test_invalid_comments(comment: str) -> None:\n    \"\"\"Test invalid comments.\"\"\"\n    with pytest.raises(ValueError):\n        validate_comment(comment, 0)"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads[null-None]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads[null-None]",
                "result": "passed",
                "test_implementation": "def test_basic_loads(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    loaded: Any = ujson5.loads(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads[true-True]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads[true-True]",
                "result": "passed",
                "test_implementation": "def test_basic_loads(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    loaded: Any = ujson5.loads(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads[false-False]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads[false-False]",
                "result": "passed",
                "test_implementation": "def test_basic_loads(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    loaded: Any = ujson5.loads(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads[\"string\"-string]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads[\"string\"-string]",
                "result": "passed",
                "test_implementation": "def test_basic_loads(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    loaded: Any = ujson5.loads(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads[\"string with \\\\\"escaped quotes\\\\\"\"-string with \"escaped quotes\"]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads[\"string with \\\\\"escaped quotes\\\\\"\"-string with \"escaped quotes\"]",
                "result": "passed",
                "test_implementation": "def test_basic_loads(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    loaded: Any = ujson5.loads(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads[\"string with multiple \\\\\\nlines\"-string with multiple lines]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads[\"string with multiple \\\\\\nlines\"-string with multiple lines]",
                "result": "passed",
                "test_implementation": "def test_basic_loads(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    loaded: Any = ujson5.loads(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads[\"sig\\u03a3ma\"-sig\\u03a3ma]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads[\"sig\\u03a3ma\"-sig\\u03a3ma]",
                "result": "passed",
                "test_implementation": "def test_basic_loads(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    loaded: Any = ujson5.loads(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads[123-123]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads[123-123]",
                "result": "passed",
                "test_implementation": "def test_basic_loads(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    loaded: Any = ujson5.loads(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads[123.456-123.456]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads[123.456-123.456]",
                "result": "passed",
                "test_implementation": "def test_basic_loads(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    loaded: Any = ujson5.loads(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads[0x23-35]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads[0x23-35]",
                "result": "passed",
                "test_implementation": "def test_basic_loads(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    loaded: Any = ujson5.loads(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads[23e-2-0.23]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads[23e-2-0.23]",
                "result": "passed",
                "test_implementation": "def test_basic_loads(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    loaded: Any = ujson5.loads(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads[Infinity-inf]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads[Infinity-inf]",
                "result": "passed",
                "test_implementation": "def test_basic_loads(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    loaded: Any = ujson5.loads(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads[NaN-nan]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads[NaN-nan]",
                "result": "passed",
                "test_implementation": "def test_basic_loads(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    loaded: Any = ujson5.loads(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads[-Infinity--inf]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads[-Infinity--inf]",
                "result": "passed",
                "test_implementation": "def test_basic_loads(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    loaded: Any = ujson5.loads(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads[-NaN-nan]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads[-NaN-nan]",
                "result": "passed",
                "test_implementation": "def test_basic_loads(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    loaded: Any = ujson5.loads(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads[[1, 2, 3]-py_value15]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads[[1, 2, 3]-py_value15]",
                "result": "passed",
                "test_implementation": "def test_basic_loads(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    loaded: Any = ujson5.loads(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads[{\"key\": \"value\"}-py_value16]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads[{\"key\": \"value\"}-py_value16]",
                "result": "passed",
                "test_implementation": "def test_basic_loads(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    loaded: Any = ujson5.loads(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads[{\"sig\\u03a3ma\": \"value\"}-py_value17]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads[{\"sig\\u03a3ma\": \"value\"}-py_value17]",
                "result": "passed",
                "test_implementation": "def test_basic_loads(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    loaded: Any = ujson5.loads(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads[{sig\\u03a3ma: \"value\"}-py_value18]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads[{sig\\u03a3ma: \"value\"}-py_value18]",
                "result": "passed",
                "test_implementation": "def test_basic_loads(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    loaded: Any = ujson5.loads(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[null-None]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[null-None]",
                "result": "passed",
                "test_implementation": "def test_basic_loads_raw(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    str_len: int = len(json5)\n    json5 += \" \" * randint(1, 10)\n    loaded, idx = ujson5.Json5Decoder().raw_decode(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value\n    assert idx == str_len"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[true-True]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[true-True]",
                "result": "passed",
                "test_implementation": "def test_basic_loads_raw(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    str_len: int = len(json5)\n    json5 += \" \" * randint(1, 10)\n    loaded, idx = ujson5.Json5Decoder().raw_decode(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value\n    assert idx == str_len"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[false-False]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[false-False]",
                "result": "passed",
                "test_implementation": "def test_basic_loads_raw(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    str_len: int = len(json5)\n    json5 += \" \" * randint(1, 10)\n    loaded, idx = ujson5.Json5Decoder().raw_decode(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value\n    assert idx == str_len"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[\"string\"-string]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[\"string\"-string]",
                "result": "passed",
                "test_implementation": "def test_basic_loads_raw(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    str_len: int = len(json5)\n    json5 += \" \" * randint(1, 10)\n    loaded, idx = ujson5.Json5Decoder().raw_decode(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value\n    assert idx == str_len"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[\"string with \\\\\"escaped quotes\\\\\"\"-string with \"escaped quotes\"]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[\"string with \\\\\"escaped quotes\\\\\"\"-string with \"escaped quotes\"]",
                "result": "passed",
                "test_implementation": "def test_basic_loads_raw(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    str_len: int = len(json5)\n    json5 += \" \" * randint(1, 10)\n    loaded, idx = ujson5.Json5Decoder().raw_decode(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value\n    assert idx == str_len"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[\"string with multiple \\\\\\nlines\"-string with multiple lines]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[\"string with multiple \\\\\\nlines\"-string with multiple lines]",
                "result": "passed",
                "test_implementation": "def test_basic_loads_raw(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    str_len: int = len(json5)\n    json5 += \" \" * randint(1, 10)\n    loaded, idx = ujson5.Json5Decoder().raw_decode(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value\n    assert idx == str_len"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[\"sig\\u03a3ma\"-sig\\u03a3ma]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[\"sig\\u03a3ma\"-sig\\u03a3ma]",
                "result": "passed",
                "test_implementation": "def test_basic_loads_raw(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    str_len: int = len(json5)\n    json5 += \" \" * randint(1, 10)\n    loaded, idx = ujson5.Json5Decoder().raw_decode(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value\n    assert idx == str_len"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[123-123]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[123-123]",
                "result": "passed",
                "test_implementation": "def test_basic_loads_raw(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    str_len: int = len(json5)\n    json5 += \" \" * randint(1, 10)\n    loaded, idx = ujson5.Json5Decoder().raw_decode(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value\n    assert idx == str_len"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[123.456-123.456]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[123.456-123.456]",
                "result": "passed",
                "test_implementation": "def test_basic_loads_raw(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    str_len: int = len(json5)\n    json5 += \" \" * randint(1, 10)\n    loaded, idx = ujson5.Json5Decoder().raw_decode(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value\n    assert idx == str_len"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[0x23-35]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[0x23-35]",
                "result": "passed",
                "test_implementation": "def test_basic_loads_raw(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    str_len: int = len(json5)\n    json5 += \" \" * randint(1, 10)\n    loaded, idx = ujson5.Json5Decoder().raw_decode(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value\n    assert idx == str_len"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[23e-2-0.23]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[23e-2-0.23]",
                "result": "passed",
                "test_implementation": "def test_basic_loads_raw(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    str_len: int = len(json5)\n    json5 += \" \" * randint(1, 10)\n    loaded, idx = ujson5.Json5Decoder().raw_decode(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value\n    assert idx == str_len"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[Infinity-inf]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[Infinity-inf]",
                "result": "passed",
                "test_implementation": "def test_basic_loads_raw(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    str_len: int = len(json5)\n    json5 += \" \" * randint(1, 10)\n    loaded, idx = ujson5.Json5Decoder().raw_decode(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value\n    assert idx == str_len"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[NaN-nan]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[NaN-nan]",
                "result": "passed",
                "test_implementation": "def test_basic_loads_raw(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    str_len: int = len(json5)\n    json5 += \" \" * randint(1, 10)\n    loaded, idx = ujson5.Json5Decoder().raw_decode(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value\n    assert idx == str_len"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[-Infinity--inf]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[-Infinity--inf]",
                "result": "passed",
                "test_implementation": "def test_basic_loads_raw(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    str_len: int = len(json5)\n    json5 += \" \" * randint(1, 10)\n    loaded, idx = ujson5.Json5Decoder().raw_decode(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value\n    assert idx == str_len"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[-NaN-nan]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[-NaN-nan]",
                "result": "passed",
                "test_implementation": "def test_basic_loads_raw(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    str_len: int = len(json5)\n    json5 += \" \" * randint(1, 10)\n    loaded, idx = ujson5.Json5Decoder().raw_decode(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value\n    assert idx == str_len"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[[1, 2, 3]-py_value15]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[[1, 2, 3]-py_value15]",
                "result": "passed",
                "test_implementation": "def test_basic_loads_raw(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    str_len: int = len(json5)\n    json5 += \" \" * randint(1, 10)\n    loaded, idx = ujson5.Json5Decoder().raw_decode(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value\n    assert idx == str_len"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[{\"key\": \"value\"}-py_value16]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[{\"key\": \"value\"}-py_value16]",
                "result": "passed",
                "test_implementation": "def test_basic_loads_raw(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    str_len: int = len(json5)\n    json5 += \" \" * randint(1, 10)\n    loaded, idx = ujson5.Json5Decoder().raw_decode(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value\n    assert idx == str_len"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[{\"sig\\u03a3ma\": \"value\"}-py_value17]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[{\"sig\\u03a3ma\": \"value\"}-py_value17]",
                "result": "passed",
                "test_implementation": "def test_basic_loads_raw(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    str_len: int = len(json5)\n    json5 += \" \" * randint(1, 10)\n    loaded, idx = ujson5.Json5Decoder().raw_decode(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value\n    assert idx == str_len"
            },
            "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[{sig\\u03a3ma: \"value\"}-py_value18]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[{sig\\u03a3ma: \"value\"}-py_value18]",
                "result": "passed",
                "test_implementation": "def test_basic_loads_raw(json5: str, py_value: Any) -> None:\n    \"\"\"Test basic JSON5 loads.\"\"\"\n    str_len: int = len(json5)\n    json5 += \" \" * randint(1, 10)\n    loaded, idx = ujson5.Json5Decoder().raw_decode(json5)\n    try:\n        if not isnan(py_value):\n            assert loaded == py_value\n        else:\n            assert isnan(loaded)\n    except TypeError:\n        assert loaded == py_value\n    assert idx == str_len"
            },
            "tests/test_unit_tests/test_decoder.py::test_composite_loads[{\\n            key: \"value\",\\n            \"key2\": 123,\\n            \"key3\": true,\\n            \"key4\": null,\\n            \"key5\": [1, 2, 3],\\n            key6: {\\n                \"nested\": \"object\"\\n            }\\n\\n         }\\n-py_value0]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_composite_loads[{\\n            key: \"value\",\\n            \"key2\": 123,\\n            \"key3\": true,\\n            \"key4\": null,\\n            \"key5\": [1, 2, 3],\\n            key6: {\\n                \"nested\": \"object\"\\n            }\\n\\n         }\\n-py_value0]",
                "result": "passed",
                "test_implementation": "def test_composite_loads(json5: str, py_value: ujson5.JsonValue) -> None:\n    \"\"\"Test composite JSON5 loads.\"\"\"\n    assert ujson5.loads(json5, strict=False) == py_value"
            },
            "tests/test_unit_tests/test_decoder.py::test_composite_loads[\\n{\\n  // comments\\n  unquoted: 'and you can quote me on that',\\n  singleQuotes: 'I can use \"double quotes\" here',\\n  lineBreaks: \"Look, Mom! \\\\\\nNo \\\\n's!\",\\n  hexadecimal: 0xdecaf,\\n  leadingDecimalPoint: .8675309, andTrailing: 8675309.,\\n  positiveSign: +1,\\n  trailingComma: 'in objects', andIn: ['arrays',],\\n  \"backwardsCompatible\": \"with JSON\",\\n  null_supported: null,\\n  infinities_supported: Infinity,\\n}\\n-py_value1]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_composite_loads[\\n{\\n  // comments\\n  unquoted: 'and you can quote me on that',\\n  singleQuotes: 'I can use \"double quotes\" here',\\n  lineBreaks: \"Look, Mom! \\\\\\nNo \\\\n's!\",\\n  hexadecimal: 0xdecaf,\\n  leadingDecimalPoint: .8675309, andTrailing: 8675309.,\\n  positiveSign: +1,\\n  trailingComma: 'in objects', andIn: ['arrays',],\\n  \"backwardsCompatible\": \"with JSON\",\\n  null_supported: null,\\n  infinities_supported: Infinity,\\n}\\n-py_value1]",
                "result": "passed",
                "test_implementation": "def test_composite_loads(json5: str, py_value: ujson5.JsonValue) -> None:\n    \"\"\"Test composite JSON5 loads.\"\"\"\n    assert ujson5.loads(json5, strict=False) == py_value"
            },
            "tests/test_unit_tests/test_decoder.py::test_strict_mode[\"\\\\t\"]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_strict_mode[\"\\\\t\"]",
                "result": "passed",
                "test_implementation": "def test_strict_mode(json5: str) -> None:\n    \"\"\"Test composite JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5, strict=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_strict_mode[\"\\\\n\"]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_strict_mode[\"\\\\n\"]",
                "result": "passed",
                "test_implementation": "def test_strict_mode(json5: str) -> None:\n    \"\"\"Test composite JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5, strict=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_strict_mode[\"\\\\r\"]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_strict_mode[\"\\\\r\"]",
                "result": "passed",
                "test_implementation": "def test_strict_mode(json5: str) -> None:\n    \"\"\"Test composite JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5, strict=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_strict_mode[\"\\\\0\"]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_strict_mode[\"\\\\0\"]",
                "result": "passed",
                "test_implementation": "def test_strict_mode(json5: str) -> None:\n    \"\"\"Test composite JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5, strict=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[null 1]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[null 1]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{key:}[12, }{: 12}12}]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{key:}[12, }{: 12}12}]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[12]]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[12]]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{abc: abc}]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{abc: abc}]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[:34]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[:34]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[:{ab: 1232]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[:{ab: 1232]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[1}]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[1}]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[1:]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[1:]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{1:]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{1:]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[abc\\tdef]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[abc\\tdef]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{23]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{23]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[:]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[:]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[,]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[,]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[,11 11]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[,11 11]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{abc: 12 def: 23}]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{abc: 12 def: 23}]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{'abc': 12 'def': 23}]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{'abc': 12 'def': 23}]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[[12, 23:]]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[[12, 23:]]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{abc: 12, 23: 465}]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{abc: 12, 23: 465}]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[[12, 23, abc]]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[[12, 23, abc]]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[[:]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[[:]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{\"abc\":]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{\"abc\":]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{\"abc\":3,23]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{\"abc\":3,23]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[23,34]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[23,34]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{:\"abc\",]]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[{:\"abc\",]]",
                "result": "passed",
                "test_implementation": "def test_invalid_loads(json5: str) -> None:\n    \"\"\"Test invalid JSON5 loads.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(json5)"
            },
            "tests/test_unit_tests/test_decoder.py::test_object_hook[{\\n    key1: 1,\\n    \"key2\": 2,\\n    \"key3\": 3,\\n    \"key4\": 4,\\n    \"key5\": 5,\\n    key6: 6\\n}-<lambda>-py_value0]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_object_hook[{\\n    key1: 1,\\n    \"key2\": 2,\\n    \"key3\": 3,\\n    \"key4\": 4,\\n    \"key5\": 5,\\n    key6: 6\\n}-<lambda>-py_value0]",
                "result": "passed",
                "test_implementation": "def test_object_hook(\n    json5: str,\n    obj_hook: Callable[[dict[str, ujson5.JsonValue]], Any],\n    py_value: ujson5.JsonValue,\n) -> None:\n    \"\"\"Test composite JSON5 loads.\"\"\"\n    assert ujson5.loads(json5, object_hook=obj_hook) == py_value"
            },
            "tests/test_unit_tests/test_decoder.py::test_object_hook[3-<lambda>-3]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_object_hook[3-<lambda>-3]",
                "result": "passed",
                "test_implementation": "def test_object_hook(\n    json5: str,\n    obj_hook: Callable[[dict[str, ujson5.JsonValue]], Any],\n    py_value: ujson5.JsonValue,\n) -> None:\n    \"\"\"Test composite JSON5 loads.\"\"\"\n    assert ujson5.loads(json5, object_hook=obj_hook) == py_value"
            },
            "tests/test_unit_tests/test_decoder.py::test_object_pair_hook[{\\n    key6: 6,\\n    \"key3\": 3,\\n    \"key5\": 5,\\n    key1: 1,\\n    \"key2\": 2,\\n    \"key4\": 4,\\n}-<lambda>-py_value0]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_object_pair_hook[{\\n    key6: 6,\\n    \"key3\": 3,\\n    \"key5\": 5,\\n    key1: 1,\\n    \"key2\": 2,\\n    \"key4\": 4,\\n}-<lambda>-py_value0]",
                "result": "passed",
                "test_implementation": "def test_object_pair_hook(\n    json5: str,\n    obj_pairs_hook: Callable[[ujson5.ObjectPairsHookArg], Any],\n    py_value: ujson5.JsonValue,\n) -> None:\n    \"\"\"Test composite JSON5 loads.\"\"\"\n    # object_pairs_hook takes priority over object_hook\n    assert (\n        ujson5.loads(json5, object_pairs_hook=obj_pairs_hook, object_hook=lambda v: 0)\n        == py_value\n    )"
            },
            "tests/test_unit_tests/test_decoder.py::test_object_pair_hook[3-<lambda>-3]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_object_pair_hook[3-<lambda>-3]",
                "result": "passed",
                "test_implementation": "def test_object_pair_hook(\n    json5: str,\n    obj_pairs_hook: Callable[[ujson5.ObjectPairsHookArg], Any],\n    py_value: ujson5.JsonValue,\n) -> None:\n    \"\"\"Test composite JSON5 loads.\"\"\"\n    # object_pairs_hook takes priority over object_hook\n    assert (\n        ujson5.loads(json5, object_pairs_hook=obj_pairs_hook, object_hook=lambda v: 0)\n        == py_value\n    )"
            },
            "tests/test_unit_tests/test_decoder.py::test_invalid_object_hook": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_invalid_object_hook",
                "result": "passed",
                "test_implementation": "def test_invalid_object_hook() -> None:\n    \"\"\"Test invalid object hook.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(\"{}\", object_hook=lambda v, k: 0)  # type: ignore\n\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(\"{}\", object_pairs_hook=lambda v, k: 0)  # type: ignore"
            },
            "tests/test_unit_tests/test_decoder.py::test_custom_decoder": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_custom_decoder",
                "result": "passed",
                "test_implementation": "def test_custom_decoder() -> None:\n    \"\"\"Test custom decoder.\"\"\"\n    content = ujson5.loads(\n        '{\"key\": 3.3}',\n        cls=CustomDecoder,\n    )\n    assert content == {\"key\": 4.3}"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[let]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[let]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[new]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[new]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[enum]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[enum]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[if]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[if]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[export]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[export]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[case]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[case]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[catch]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[catch]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[interface]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[interface]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[class]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[class]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[implements]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[implements]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[this]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[this]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[const]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[const]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[finally]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[finally]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[try]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[try]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[throw]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[throw]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[extends]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[extends]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[import]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[import]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[with]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[with]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[delete]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[delete]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[instanceof]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[instanceof]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[yield]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[yield]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[default]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[default]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[package]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[package]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[switch]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[switch]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[private]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[private]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[function]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[function]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[while]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[while]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[super]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[super]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[static]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[static]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[for]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[for]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[return]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[return]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[protected]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[protected]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[typeof]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[typeof]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[continue]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[continue]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[do]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[do]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[void]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[void]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[debugger]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[debugger]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[break]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[break]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[in]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[in]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[public]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[public]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[var]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[var]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[else]": {
                "testid": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys[else]",
                "result": "passed",
                "test_implementation": "def test_reserved_word_keys(word: str) -> None:\n    \"\"\"Test reserved word keys.\"\"\"\n    with pytest.raises(ujson5.JSON5DecodeError):\n        ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=False)\n\n    ujson5.loads(f\"{{{word}: 1}}\", allow_reserved_words=True)"
            },
            "tests/test_unit_tests/test_encoder.py::test_valid_examples[string-\"string\"]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_valid_examples[string-\"string\"]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(py_obj: Any, json5_obj: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    assert ujson5.dumps(py_obj, check_circular=False) == json5_obj\n    assert ujson5.dumps(py_obj, check_circular=True) == json5_obj"
            },
            "tests/test_unit_tests/test_encoder.py::test_valid_examples[123-123]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_valid_examples[123-123]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(py_obj: Any, json5_obj: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    assert ujson5.dumps(py_obj, check_circular=False) == json5_obj\n    assert ujson5.dumps(py_obj, check_circular=True) == json5_obj"
            },
            "tests/test_unit_tests/test_encoder.py::test_valid_examples[123.456-123.456]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_valid_examples[123.456-123.456]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(py_obj: Any, json5_obj: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    assert ujson5.dumps(py_obj, check_circular=False) == json5_obj\n    assert ujson5.dumps(py_obj, check_circular=True) == json5_obj"
            },
            "tests/test_unit_tests/test_encoder.py::test_valid_examples[2e+20-2e+20]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_valid_examples[2e+20-2e+20]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(py_obj: Any, json5_obj: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    assert ujson5.dumps(py_obj, check_circular=False) == json5_obj\n    assert ujson5.dumps(py_obj, check_circular=True) == json5_obj"
            },
            "tests/test_unit_tests/test_encoder.py::test_valid_examples[inf-Infinity]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_valid_examples[inf-Infinity]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(py_obj: Any, json5_obj: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    assert ujson5.dumps(py_obj, check_circular=False) == json5_obj\n    assert ujson5.dumps(py_obj, check_circular=True) == json5_obj"
            },
            "tests/test_unit_tests/test_encoder.py::test_valid_examples[-inf--Infinity]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_valid_examples[-inf--Infinity]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(py_obj: Any, json5_obj: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    assert ujson5.dumps(py_obj, check_circular=False) == json5_obj\n    assert ujson5.dumps(py_obj, check_circular=True) == json5_obj"
            },
            "tests/test_unit_tests/test_encoder.py::test_valid_examples[nan-NaN]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_valid_examples[nan-NaN]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(py_obj: Any, json5_obj: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    assert ujson5.dumps(py_obj, check_circular=False) == json5_obj\n    assert ujson5.dumps(py_obj, check_circular=True) == json5_obj"
            },
            "tests/test_unit_tests/test_encoder.py::test_valid_examples[True-true]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_valid_examples[True-true]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(py_obj: Any, json5_obj: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    assert ujson5.dumps(py_obj, check_circular=False) == json5_obj\n    assert ujson5.dumps(py_obj, check_circular=True) == json5_obj"
            },
            "tests/test_unit_tests/test_encoder.py::test_valid_examples[False-false]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_valid_examples[False-false]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(py_obj: Any, json5_obj: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    assert ujson5.dumps(py_obj, check_circular=False) == json5_obj\n    assert ujson5.dumps(py_obj, check_circular=True) == json5_obj"
            },
            "tests/test_unit_tests/test_encoder.py::test_valid_examples[None-null]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_valid_examples[None-null]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(py_obj: Any, json5_obj: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    assert ujson5.dumps(py_obj, check_circular=False) == json5_obj\n    assert ujson5.dumps(py_obj, check_circular=True) == json5_obj"
            },
            "tests/test_unit_tests/test_encoder.py::test_valid_examples[py_obj10-[]]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_valid_examples[py_obj10-[]]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(py_obj: Any, json5_obj: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    assert ujson5.dumps(py_obj, check_circular=False) == json5_obj\n    assert ujson5.dumps(py_obj, check_circular=True) == json5_obj"
            },
            "tests/test_unit_tests/test_encoder.py::test_valid_examples[py_obj11-[1, 2, 3]]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_valid_examples[py_obj11-[1, 2, 3]]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(py_obj: Any, json5_obj: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    assert ujson5.dumps(py_obj, check_circular=False) == json5_obj\n    assert ujson5.dumps(py_obj, check_circular=True) == json5_obj"
            },
            "tests/test_unit_tests/test_encoder.py::test_valid_examples[py_obj12-{}]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_valid_examples[py_obj12-{}]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(py_obj: Any, json5_obj: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    assert ujson5.dumps(py_obj, check_circular=False) == json5_obj\n    assert ujson5.dumps(py_obj, check_circular=True) == json5_obj"
            },
            "tests/test_unit_tests/test_encoder.py::test_valid_examples[py_obj13-{\"key\": \"value\"}]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_valid_examples[py_obj13-{\"key\": \"value\"}]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(py_obj: Any, json5_obj: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    assert ujson5.dumps(py_obj, check_circular=False) == json5_obj\n    assert ujson5.dumps(py_obj, check_circular=True) == json5_obj"
            },
            "tests/test_unit_tests/test_encoder.py::test_valid_examples[py_obj14-{\"key\": 123}]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_valid_examples[py_obj14-{\"key\": 123}]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(py_obj: Any, json5_obj: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    assert ujson5.dumps(py_obj, check_circular=False) == json5_obj\n    assert ujson5.dumps(py_obj, check_circular=True) == json5_obj"
            },
            "tests/test_unit_tests/test_encoder.py::test_valid_examples[py_obj15-{\"string\": \"string\", \"int\": 123, \"float\": 123.456, \"true\": true, \"false\": false, \"null\": null, \"array\": [1, 2, 3, [1, 2]], \"heterogeneous\": [1, 1.323, \"string\", true, null, {\"key\": \"value\"}], \"object\": {\"key\": \"value\"}}]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_valid_examples[py_obj15-{\"string\": \"string\", \"int\": 123, \"float\": 123.456, \"true\": true, \"false\": false, \"null\": null, \"array\": [1, 2, 3, [1, 2]], \"heterogeneous\": [1, 1.323, \"string\", true, null, {\"key\": \"value\"}], \"object\": {\"key\": \"value\"}}]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(py_obj: Any, json5_obj: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    assert ujson5.dumps(py_obj, check_circular=False) == json5_obj\n    assert ujson5.dumps(py_obj, check_circular=True) == json5_obj"
            },
            "tests/test_unit_tests/test_encoder.py::test_valid_examples[py_obj16-{\"12\": \"int key\", \"12.34\": \"float key\", \"true\": \"bool key\", \"false\": \"false key\", \"null\": \"null key\"}]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_valid_examples[py_obj16-{\"12\": \"int key\", \"12.34\": \"float key\", \"true\": \"bool key\", \"false\": \"false key\", \"null\": \"null key\"}]",
                "result": "passed",
                "test_implementation": "def test_valid_examples(py_obj: Any, json5_obj: str) -> None:\n    \"\"\"Test valid JSON5 examples.\"\"\"\n    assert ujson5.dumps(py_obj, check_circular=False) == json5_obj\n    assert ujson5.dumps(py_obj, check_circular=True) == json5_obj"
            },
            "tests/test_unit_tests/test_encoder.py::test_indent[py_obj0-{\\n    \"val\": 1,\\n    \"array\": [\\n        1,\\n        2,\\n        3,\\n    ],\\n    \"obj\": {\\n        \"key\": \"value\",\\n    },\\n}]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_indent[py_obj0-{\\n    \"val\": 1,\\n    \"array\": [\\n        1,\\n        2,\\n        3,\\n    ],\\n    \"obj\": {\\n        \"key\": \"value\",\\n    },\\n}]",
                "result": "passed",
                "test_implementation": "def test_indent(py_obj: Any, json5_obj: str) -> None:\n    \"\"\"Test indent.\"\"\"\n    assert ujson5.dumps(py_obj, indent=4) == json5_obj"
            },
            "tests/test_unit_tests/test_encoder.py::test_invalid_examples[py_obj0]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_invalid_examples[py_obj0]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(py_obj: Any) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with pytest.raises(ujson5.JSON5EncodeError):\n        ujson5.dumps(py_obj)"
            },
            "tests/test_unit_tests/test_encoder.py::test_invalid_examples[py_obj1]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_invalid_examples[py_obj1]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(py_obj: Any) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with pytest.raises(ujson5.JSON5EncodeError):\n        ujson5.dumps(py_obj)"
            },
            "tests/test_unit_tests/test_encoder.py::test_invalid_examples[py_obj2]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_invalid_examples[py_obj2]",
                "result": "passed",
                "test_implementation": "def test_invalid_examples(py_obj: Any) -> None:\n    \"\"\"Test invalid JSON5 examples.\"\"\"\n    with pytest.raises(ujson5.JSON5EncodeError):\n        ujson5.dumps(py_obj)"
            },
            "tests/test_unit_tests/test_encoder.py::test_skip_keys": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_skip_keys",
                "result": "passed",
                "test_implementation": "def test_skip_keys() -> None:\n    \"\"\"Test skip keys.\"\"\"\n    obj = {(\"non-string-key\", \"is here\"): \"value\", \"key2\": \"value2\"}\n    ujson5.dumps(obj, skip_keys=True)\n    with pytest.raises(ujson5.JSON5EncodeError):\n        ujson5.dumps(obj, skip_keys=False)"
            },
            "tests/test_unit_tests/test_encoder.py::test_nan_not_allowed[nan]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_nan_not_allowed[nan]",
                "result": "passed",
                "test_implementation": "def test_nan_not_allowed(py_obj: float) -> None:\n    \"\"\"Test NaN not allowed.\"\"\"\n    ujson5.dumps(py_obj, allow_nan=True)\n\n    with pytest.raises(ujson5.JSON5EncodeError):\n        ujson5.dumps(py_obj, allow_nan=False)"
            },
            "tests/test_unit_tests/test_encoder.py::test_nan_not_allowed[inf]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_nan_not_allowed[inf]",
                "result": "passed",
                "test_implementation": "def test_nan_not_allowed(py_obj: float) -> None:\n    \"\"\"Test NaN not allowed.\"\"\"\n    ujson5.dumps(py_obj, allow_nan=True)\n\n    with pytest.raises(ujson5.JSON5EncodeError):\n        ujson5.dumps(py_obj, allow_nan=False)"
            },
            "tests/test_unit_tests/test_encoder.py::test_nan_not_allowed[-inf]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_nan_not_allowed[-inf]",
                "result": "passed",
                "test_implementation": "def test_nan_not_allowed(py_obj: float) -> None:\n    \"\"\"Test NaN not allowed.\"\"\"\n    ujson5.dumps(py_obj, allow_nan=True)\n\n    with pytest.raises(ujson5.JSON5EncodeError):\n        ujson5.dumps(py_obj, allow_nan=False)"
            },
            "tests/test_unit_tests/test_encoder.py::test_circular_ref": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_circular_ref",
                "result": "passed",
                "test_implementation": "def test_circular_ref() -> None:\n    \"\"\"Test circular reference.\"\"\"\n    obj: dict = {}\n    obj[\"self\"] = obj\n    with pytest.raises(ujson5.JSON5EncodeError):\n        ujson5.dumps(obj)\n\n    lst: list = []\n    lst.append(obj)\n    with pytest.raises(ujson5.JSON5EncodeError):\n        ujson5.dumps(lst)\n\n    lst = []\n    lst.append(lst)\n    with pytest.raises(ujson5.JSON5EncodeError):\n        ujson5.dumps(lst)\n\n    obj = {\"list\": []}\n    obj[\"list\"].append(obj)\n    with pytest.raises(ujson5.JSON5EncodeError):\n        ujson5.dumps(obj)\n\n    class Custom:\n        \"\"\"Custom class.\"\"\"\n\n        def __init__(self, value: Any) -> None:\n            self.value = value\n\n    subset = Custom(1)\n    subset.value = subset\n    with pytest.raises(ujson5.JSON5EncodeError):\n        ujson5.dumps(subset, default=lambda v: v.value)\n\n    subset = Custom(1)\n    ujson5.dumps(subset, default=lambda v: v.value, check_circular=False)"
            },
            "tests/test_unit_tests/test_encoder.py::test_sort_keys": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_sort_keys",
                "result": "passed",
                "test_implementation": "def test_sort_keys() -> None:\n    \"\"\"Test sort keys.\"\"\"\n    obj = {\"key2\": \"value2\", \"key1\": \"value1\"}\n    assert ujson5.dumps(obj, sort_keys=True) == '{\"key1\": \"value1\", \"key2\": \"value2\"}'\n    assert ujson5.dumps(obj, sort_keys=False) == '{\"key2\": \"value2\", \"key1\": \"value1\"}'"
            },
            "tests/test_unit_tests/test_encoder.py::test_default_set": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_default_set",
                "result": "passed",
                "test_implementation": "def test_default_set() -> None:\n    \"\"\"Test default set.\"\"\"\n    py_set = set([1, 2, 3])\n    ujson5.dumps(py_set, default=list)\n\n    py_lst = [1, 2, 3, set([1, 2, 3])]\n    ujson5.dumps(py_lst, default=list)"
            },
            "tests/test_unit_tests/test_encoder.py::test_separators": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_separators",
                "result": "passed",
                "test_implementation": "def test_separators() -> None:\n    \"\"\"Test separators.\"\"\"\n    py_obj = {\"key1\": \"value1\", \"key2\": \"value2\"}\n    assert (\n        ujson5.dumps(py_obj, separators=(\",\", \":\"))\n        == '{\"key1\":\"value1\",\"key2\":\"value2\"}'\n    )\n    assert (\n        ujson5.dumps(py_obj, separators=(\",\", \": \"))\n        == '{\"key1\": \"value1\",\"key2\": \"value2\"}'\n    )\n    assert (\n        ujson5.dumps(py_obj, separators=(\"|\", \">\"))\n        == '{\"key1\">\"value1\"|\"key2\">\"value2\"}'\n    )"
            },
            "tests/test_unit_tests/test_encoder.py::test_replace_unicode": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_replace_unicode",
                "result": "passed",
                "test_implementation": "def test_replace_unicode() -> None:\n    \"\"\"Test unicode replacement\"\"\"\n    py_obj = f\"Hello\\nWorld {chr(0x19)}\"\n    uni_char = f\"\\\\u{0x19:04x}\"\n    expected_output = f'\"Hello\\\\nWorld {uni_char}\"'\n    assert ujson5.dumps(py_obj, ensure_ascii=False) == expected_output"
            },
            "tests/test_unit_tests/test_encoder.py::test_replace_ascii[Hello\\x80World-\"Hello\\\\u0080World\"]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_replace_ascii[Hello\\x80World-\"Hello\\\\u0080World\"]",
                "result": "passed",
                "test_implementation": "def test_replace_ascii(py_obj: str, json5_str: str) -> None:\n    \"\"\"Test ASCII replacement\"\"\"\n    assert ujson5.dumps(py_obj, ensure_ascii=True) == json5_str"
            },
            "tests/test_unit_tests/test_encoder.py::test_replace_ascii[Hello\\U0001f600World-\"Hello\\\\ud83d\\\\ude00World\"]": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_replace_ascii[Hello\\U0001f600World-\"Hello\\\\ud83d\\\\ude00World\"]",
                "result": "passed",
                "test_implementation": "def test_replace_ascii(py_obj: str, json5_str: str) -> None:\n    \"\"\"Test ASCII replacement\"\"\"\n    assert ujson5.dumps(py_obj, ensure_ascii=True) == json5_str"
            },
            "tests/test_unit_tests/test_encoder.py::test_invalid_typed_dict_cls": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_invalid_typed_dict_cls",
                "result": "passed",
                "test_implementation": "def test_invalid_typed_dict_cls(tmp_path: Path) -> None:\n    \"\"\"Test raise when TypedDict class is not valid.\"\"\"\n    with pytest.raises(ujson5.JSON5EncodeError):\n        ujson5.dumps({}, typed_dict_cls=int)\n\n    with (\n        pytest.raises(ujson5.JSON5EncodeError),\n        open(tmp_path / \"dump.json5\", \"w\", encoding=\"utf8\") as file,\n    ):\n        ujson5.dump({}, file, typed_dict_cls=int)"
            },
            "tests/test_unit_tests/test_encoder.py::test_quoted_key": {
                "testid": "tests/test_unit_tests/test_encoder.py::test_quoted_key",
                "result": "passed",
                "test_implementation": "def test_quoted_key() -> None:\n    \"\"\"Test quoted key.\"\"\"\n    obj = {\"key\": \"value\", \"key2\": \"value2\"}\n    assert ujson5.dumps(obj, key_quotation=\"none\") == '{key: \"value\", key2: \"value2\"}'\n    assert (\n        ujson5.dumps(obj, key_quotation=\"double\")\n        == '{\"key\": \"value\", \"key2\": \"value2\"}'\n    )\n    assert (\n        ujson5.dumps(obj, key_quotation=\"single\")\n        == \"{'key': \\\"value\\\", 'key2': \\\"value2\\\"}\"\n    )"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[a-0-1]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[a-0-1]",
                "result": "passed",
                "test_implementation": "def test_valid_identifiers(identifier: str, start: int, end: int) -> None:\n    \"\"\"Test valid identifiers.\"\"\"\n    result = tokenize_identifier(buffer=identifier, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"IDENTIFIER\"]\n    r_start, r_end = result.token.value\n    assert (r_start, r_end) == (start, end)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[A-0-1]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[A-0-1]",
                "result": "passed",
                "test_implementation": "def test_valid_identifiers(identifier: str, start: int, end: int) -> None:\n    \"\"\"Test valid identifiers.\"\"\"\n    result = tokenize_identifier(buffer=identifier, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"IDENTIFIER\"]\n    r_start, r_end = result.token.value\n    assert (r_start, r_end) == (start, end)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[_A-0-2]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[_A-0-2]",
                "result": "passed",
                "test_implementation": "def test_valid_identifiers(identifier: str, start: int, end: int) -> None:\n    \"\"\"Test valid identifiers.\"\"\"\n    result = tokenize_identifier(buffer=identifier, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"IDENTIFIER\"]\n    r_start, r_end = result.token.value\n    assert (r_start, r_end) == (start, end)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[$A-0-2]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[$A-0-2]",
                "result": "passed",
                "test_implementation": "def test_valid_identifiers(identifier: str, start: int, end: int) -> None:\n    \"\"\"Test valid identifiers.\"\"\"\n    result = tokenize_identifier(buffer=identifier, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"IDENTIFIER\"]\n    r_start, r_end = result.token.value\n    assert (r_start, r_end) == (start, end)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[\\\\uf3e9-0-6]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[\\\\uf3e9-0-6]",
                "result": "passed",
                "test_implementation": "def test_valid_identifiers(identifier: str, start: int, end: int) -> None:\n    \"\"\"Test valid identifiers.\"\"\"\n    result = tokenize_identifier(buffer=identifier, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"IDENTIFIER\"]\n    r_start, r_end = result.token.value\n    assert (r_start, r_end) == (start, end)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[a02a-0-4]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[a02a-0-4]",
                "result": "passed",
                "test_implementation": "def test_valid_identifiers(identifier: str, start: int, end: int) -> None:\n    \"\"\"Test valid identifiers.\"\"\"\n    result = tokenize_identifier(buffer=identifier, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"IDENTIFIER\"]\n    r_start, r_end = result.token.value\n    assert (r_start, r_end) == (start, end)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[_\\\\u0312}   -0-7]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[_\\\\u0312}   -0-7]",
                "result": "passed",
                "test_implementation": "def test_valid_identifiers(identifier: str, start: int, end: int) -> None:\n    \"\"\"Test valid identifiers.\"\"\"\n    result = tokenize_identifier(buffer=identifier, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"IDENTIFIER\"]\n    r_start, r_end = result.token.value\n    assert (r_start, r_end) == (start, end)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[_\\\\u0312:   -0-7]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[_\\\\u0312:   -0-7]",
                "result": "passed",
                "test_implementation": "def test_valid_identifiers(identifier: str, start: int, end: int) -> None:\n    \"\"\"Test valid identifiers.\"\"\"\n    result = tokenize_identifier(buffer=identifier, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"IDENTIFIER\"]\n    r_start, r_end = result.token.value\n    assert (r_start, r_end) == (start, end)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[_\\\\u0312[   -0-7]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[_\\\\u0312[   -0-7]",
                "result": "passed",
                "test_implementation": "def test_valid_identifiers(identifier: str, start: int, end: int) -> None:\n    \"\"\"Test valid identifiers.\"\"\"\n    result = tokenize_identifier(buffer=identifier, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"IDENTIFIER\"]\n    r_start, r_end = result.token.value\n    assert (r_start, r_end) == (start, end)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[_\\\\u0312{   -0-7]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[_\\\\u0312{   -0-7]",
                "result": "passed",
                "test_implementation": "def test_valid_identifiers(identifier: str, start: int, end: int) -> None:\n    \"\"\"Test valid identifiers.\"\"\"\n    result = tokenize_identifier(buffer=identifier, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"IDENTIFIER\"]\n    r_start, r_end = result.token.value\n    assert (r_start, r_end) == (start, end)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[_\\\\u0312]   -0-7]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[_\\\\u0312]   -0-7]",
                "result": "passed",
                "test_implementation": "def test_valid_identifiers(identifier: str, start: int, end: int) -> None:\n    \"\"\"Test valid identifiers.\"\"\"\n    result = tokenize_identifier(buffer=identifier, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"IDENTIFIER\"]\n    r_start, r_end = result.token.value\n    assert (r_start, r_end) == (start, end)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[_\\\\u0312,   -0-7]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[_\\\\u0312,   -0-7]",
                "result": "passed",
                "test_implementation": "def test_valid_identifiers(identifier: str, start: int, end: int) -> None:\n    \"\"\"Test valid identifiers.\"\"\"\n    result = tokenize_identifier(buffer=identifier, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"IDENTIFIER\"]\n    r_start, r_end = result.token.value\n    assert (r_start, r_end) == (start, end)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[\\U0001b2e3\\u1ddc-0-2]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[\\U0001b2e3\\u1ddc-0-2]",
                "result": "passed",
                "test_implementation": "def test_valid_identifiers(identifier: str, start: int, end: int) -> None:\n    \"\"\"Test valid identifiers.\"\"\"\n    result = tokenize_identifier(buffer=identifier, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"IDENTIFIER\"]\n    r_start, r_end = result.token.value\n    assert (r_start, r_end) == (start, end)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[\\u3cf6\\u200d\\u200c-0-3]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[\\u3cf6\\u200d\\u200c-0-3]",
                "result": "passed",
                "test_implementation": "def test_valid_identifiers(identifier: str, start: int, end: int) -> None:\n    \"\"\"Test valid identifiers.\"\"\"\n    result = tokenize_identifier(buffer=identifier, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"IDENTIFIER\"]\n    r_start, r_end = result.token.value\n    assert (r_start, r_end) == (start, end)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[\\U00025024\\u1c52-0-2]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[\\U00025024\\u1c52-0-2]",
                "result": "passed",
                "test_implementation": "def test_valid_identifiers(identifier: str, start: int, end: int) -> None:\n    \"\"\"Test valid identifiers.\"\"\"\n    result = tokenize_identifier(buffer=identifier, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"IDENTIFIER\"]\n    r_start, r_end = result.token.value\n    assert (r_start, r_end) == (start, end)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[\\u761c\\u2054-0-2]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_valid_identifiers[\\u761c\\u2054-0-2]",
                "result": "passed",
                "test_implementation": "def test_valid_identifiers(identifier: str, start: int, end: int) -> None:\n    \"\"\"Test valid identifiers.\"\"\"\n    result = tokenize_identifier(buffer=identifier, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"IDENTIFIER\"]\n    r_start, r_end = result.token.value\n    assert (r_start, r_end) == (start, end)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\\\u22\\\\xab]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\\\u22\\\\xab]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\\\u]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\\\u]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U0001182c]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U0001182c]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U00011723]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U00011723]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u0d01]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u0d01]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U0001172a]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U0001172a]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u1bf1]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u1bf1]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U000e012a]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U000e012a]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U00016f6d]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U00016f6d]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u20d9]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u20d9]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u0b57]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u0b57]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U00011081]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U00011081]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u0de9]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u0de9]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u1c44]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u1c44]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U000112f5]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U000112f5]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u09ed]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u09ed]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U00011653]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U00011653]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\ua905]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\ua905]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\ua8d3]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\ua8d3]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U0001e141]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U0001e141]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\uaa54]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\uaa54]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U00011737]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\U00011737]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u203f]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u203f]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\ufe34]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\ufe34]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\uff3f]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\uff3f]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\ufe4f]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\ufe4f]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\ufe4d]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\ufe4d]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\ufe4e]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\ufe4e]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u2040]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\u2040]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\ufe33]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[\\ufe33]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[A\\u2603]": {
                "testid": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers[A\\u2603]",
                "result": "passed",
                "test_implementation": "def test_invalid_identifiers(identifier: str) -> None:\n    \"\"\"Test invalid identifiers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_identifier(buffer=identifier, idx=0)"
            },
            "tests/test_unit_tests/test_lexer.py::test_lexer": {
                "testid": "tests/test_unit_tests/test_lexer.py::test_lexer",
                "result": "passed",
                "test_implementation": "def test_lexer() -> None:\n    \"\"\"Test lexer\"\"\"\n    results = tokenize(JSON5_TEXT)\n    assert len(results) == len(tokens)\n    for result, tok in zip(results, tokens, strict=False):\n        assert result.tk_type == tok[0]\n        r_text = JSON5_TEXT[result.value[0] : result.value[1]]\n        assert r_text == tok[1]"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0_0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0_0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0_1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0_1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[3e2]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[3e2]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0e2]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0e2]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123_0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123_0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456_0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456_0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.123_0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.123_0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.123_0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.123_0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99e10]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99e10]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E+10_0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E+10_0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2e-3]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2e-3]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.0001_0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.0001_0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123e5]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123e5]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.5E10_0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.5E10_0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E+0  0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E+0  0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456e10  ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456e10  ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.001_0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.001_0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123_1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123_1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.456_0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.456_0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[7e10]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[7e10]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e+0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e+0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e-0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e-0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e10]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e10]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e+10]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e+10]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e-10]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e-10]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[12345678901234567890_0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[12345678901234567890_0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2345678901234567890e+20]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2345678901234567890e+20]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x123ABC]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x123ABC]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0XABCDEF0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0XABCDEF0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123_0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123_0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123.456_0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123.456_0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+0_0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+0_0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-0_0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-0_0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+.123_0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+.123_0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-.434_0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-.434_0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[2323.0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[2323.0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[Infinity]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[Infinity]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+Infinity]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+Infinity]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-Infinity]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-Infinity]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[NaN]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[NaN]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+NaN]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+NaN]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-NaN]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-NaN]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0_2]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0_2]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0_3]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0_3]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[3E2]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[3E2]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0E2]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0E2]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123_2]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123_2]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456_1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456_1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.123_1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.123_1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.123_1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.123_1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E10]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E10]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E+10_1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E+10_1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E-3]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E-3]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.0001_1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.0001_1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123E5]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123E5]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.5E10_1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.5E10_1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E+0  1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E+0  1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456E10  ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456E10  ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.001_1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.001_1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123_3]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123_3]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.456_1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.456_1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[7E10]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[7E10]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E+0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E+0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E-0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E-0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E10]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E10]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E+10]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E+10]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E-10]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E-10]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[12345678901234567890_1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[12345678901234567890_1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2345678901234567890E+20]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2345678901234567890E+20]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X123ABC]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X123ABC]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0XABCDEF1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0XABCDEF1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123_1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123_1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123.456_1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123.456_1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+0_1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+0_1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-0_1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-0_1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+.123_1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+.123_1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-.434_1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-.434_1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[2323.1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[2323.1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0         ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0         ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0    0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0    0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[3e2        ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[3e2        ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0e2   ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0e2   ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123        0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123        0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456         ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456         ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.123    ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.123    ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.123        ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.123        ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99e10  ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99e10  ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E+10       ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E+10       ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2e-3     ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2e-3     ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.0001  ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.0001  ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123e5          ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123e5          ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.5E10          ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.5E10          ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E+0         ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E+0         ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456e10          ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456e10          ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.001       ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.001       ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123         0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123         0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.456      ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.456      ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[7e10        ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[7e10        ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e0    ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e0    ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e+0    ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e+0    ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e-0 ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e-0 ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e10    ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e10    ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e+10 ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e+10 ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e-10  ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e-10  ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[12345678901234567890       ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[12345678901234567890       ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2345678901234567890e+20   ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2345678901234567890e+20   ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x0        ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x0        ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x1     ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x1     ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x123ABC     ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x123ABC     ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0XABCDEF          ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0XABCDEF          ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123 ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123 ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123.456      ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123.456      ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+0 ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+0 ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-0 ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-0 ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+.123       ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+.123       ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-.434   ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-.434   ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[2323.          ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[2323.          ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0    1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0    1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0     ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0     ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[3E2   ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[3E2   ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0E2          ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0E2          ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123        1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123        1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456     ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456     ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.123       ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.123       ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.123         ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.123         ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E10         ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E10         ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E+10  ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E+10  ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E-3      ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E-3      ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.0001     ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.0001     ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123E5  ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123E5  ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.5E10 ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.5E10 ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E+0      ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E+0      ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456E10     ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456E10     ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.001 ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.001 ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123         1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123         1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.456   ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.456   ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[7E10         ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[7E10         ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E0         ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E0         ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E+0   ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E+0   ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E-0      ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E-0      ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E10         ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E10         ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E+10      ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E+10      ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E-10   ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E-10   ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[12345678901234567890          ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[12345678901234567890          ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2345678901234567890E+20      ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2345678901234567890E+20      ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X0  ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X0  ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X1       ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X1       ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X123ABC     ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X123ABC     ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0XABCDEF   ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0XABCDEF   ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123       ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123       ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123.456          ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123.456          ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+0   ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+0   ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-0          ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-0          ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+.123      ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+.123      ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-.434 ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-.434 ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[2323. ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[2323. ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0            ,    ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0            ,    ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0     ,         ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0     ,         ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[3e2            , ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[3e2            , ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0e2      ,         ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0e2      ,         ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123            , 0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123            , 0]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456               ,        ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456               ,        ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.123     ,]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.123     ,]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.123           ,         ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.123           ,         ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99e10          ,         ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99e10          ,         ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E+10             ,     ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E+10             ,     ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2e-3           ,   ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2e-3           ,   ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.0001         ,        ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.0001         ,        ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123e5                   ,          ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123e5                   ,          ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.5E10                   ,        ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.5E10                   ,        ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E+0               , ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E+0               , ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456e10                 ,     ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456e10                 ,     ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.001                 ,   ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.001                 ,   ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123                   ,]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123                   ,]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.456        ,  ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.456        ,  ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[7e10                 ,     ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[7e10                 ,     ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e0        , ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e0        , ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e+0      ,       ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e+0      ,       ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e-0       ,         ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1e-0       ,         ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e10         , ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e10         , ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e+10           ,       ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e+10           ,       ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e-10  ,]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23e-10  ,]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[12345678901234567890                 ,       ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[12345678901234567890                 ,       ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2345678901234567890e+20         ,  ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2345678901234567890e+20         ,  ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x0              , ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x0              , ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x1             ,         ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x1             ,         ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x123ABC       , ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0x123ABC       , ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0XABCDEF          ,         ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0XABCDEF          ,         ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123     ,         ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123     ,         ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123.456          ,      ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123.456          ,      ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+0   ,      ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+0   ,      ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-0 ,    ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-0 ,    ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+.123             , ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+.123             , ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-.434            ,          ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-.434            ,          ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[2323.                  ,         ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[2323.                  ,         ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0       , ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0       , ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0       ,    ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0       ,    ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[3E2       ,  ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[3E2       ,  ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0E2              ,]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0E2              ,]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123        ,    ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123        ,    ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456        ,     ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456        ,     ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.123            ,       ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.123            ,       ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.123                  ,     ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.123                  ,     ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E10             ,      ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E10             ,      ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E+10   ,        ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E+10   ,        ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E-3      ,         ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E-3      ,         ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.0001          ,]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.0001          ,]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123E5           , ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123E5           , ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.5E10  , ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.5E10  , ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E+0          ,         ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E+0          ,         ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456E10           , ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456E10           , ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.001  ,        ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.001  ,        ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123            , 1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123            , 1]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.456             ,        ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.456             ,        ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[7E10              ,        ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[7E10              ,        ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E0                ,          ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E0                ,          ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E+0     ,        ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E+0     ,        ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E-0             ,          ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E-0             ,          ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E10             ,    ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E10             ,    ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E+10              ,]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E+10              ,]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E-10           ,          ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E-10           ,          ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[12345678901234567890                  ,          ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[12345678901234567890                  ,          ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2345678901234567890E+20       ,     ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2345678901234567890E+20       ,     ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X0            ,    ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X0            ,    ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X1              ,       ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X1              ,       ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X123ABC        ,     ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X123ABC        ,     ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0XABCDEF    ,  ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0XABCDEF    ,  ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123               ,   ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123               ,   ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123.456              ,          ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123.456              ,          ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+0             ,     ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+0             ,     ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-0           ,        ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-0           ,        ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+.123      ,  ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+.123      ,  ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-.434           , ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-.434           , ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[2323.     ,  ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[2323.     ,  ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0    ,          ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0    ,          ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0   ,   ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0   ,   ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[3E2    ,  ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[3E2    ,  ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0E2      ,        ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0E2      ,        ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123       ,         ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123       ,         ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456    ,      ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456    ,      ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.123     ,      ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.123     ,      ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.123    ,      ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.123    ,      ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E10        ,   ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E10        ,   ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E+10,     ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[99.99E+10,     ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E-3   ,          ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E-3   ,          ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.0001        ,      ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.0001        ,      ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123E5       ,      ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123E5       ,      ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.5E10       ,]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.5E10       ,]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E+0      ,  ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2E+0      ,  ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456E10    ,     ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123.456E10    ,     ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.001    ,          ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[.001    ,          ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123      ,          ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[123      ,          ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.456         ,       ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0.456         ,       ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[7E10        ,    ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[7E10        ,    ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E0       ,       ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E0       ,       ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E+0   ,     ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E+0   ,     ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E-0         ,      ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1E-0         ,      ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E10        ,]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E10        ,]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E+10     ,        ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E+10     ,        ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E-10,    ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.23E-10,    ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[12345678901234567890  ,   ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[12345678901234567890  ,   ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2345678901234567890E+20         ,   ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[1.2345678901234567890E+20         ,   ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X0       ,  ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X0       ,  ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X1          ,]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X1          ,]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X123ABC         ,       ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0X123ABC         ,       ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0XABCDEF ,]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[0XABCDEF ,]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123        ,      ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123        ,      ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123.456     ,          ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-123.456     ,          ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+0,          ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+0,          ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-0 ,         ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-0 ,         ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+.123 ,       ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[+.123 ,       ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-.434,  ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[-.434,  ]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[2323.    ,]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_valid_numbers[2323.    ,]",
                "result": "passed",
                "test_implementation": "def test_valid_numbers(text_number: str) -> None:\n    \"\"\"Test valid numbers.\"\"\"\n    result = tokenize_number(buffer=text_number, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"NUMBER\"]\n    start, end = result.token.value\n    if \",\" in text_number:\n        assert text_number[start:end] == text_number.strip()[:-1].strip()\n    else:\n        assert text_number[start:end] == text_number.strip()"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[    ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[    ]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-0]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[00]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[00]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[0123_0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[0123_0]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1.2.3_0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1.2.3_0]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e+0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e+0]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[.e2]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[.e2]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[. 123]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[. 123]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[4.5e ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[4.5e ]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[4.5e+ ]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[4.5e+ ]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[5.5.5]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[5.5.5]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[0d]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[0d]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[2e9d]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[2e9d]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[123a]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[123a]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1.2.3_1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1.2.3_1]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e2e3]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e2e3]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1..2]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1..2]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1.2.3_2]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1.2.3_2]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e+e]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e+e]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e-.]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e-.]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[0123_1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[0123_1]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[00.123]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[00.123]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e 2]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e 2]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[123abc]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[123abc]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1.23e10xyz]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1.23e10xyz]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[.]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[.]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[e0]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[e0]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[e10]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[e10]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e+1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e+1]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e-]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1e-]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[+]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[+]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-1]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1ek]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[1ek]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[e1]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[e1]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[E]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[E]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[0x]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[0x]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[0xG]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[0xG]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[0x1.23]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[0x1.23]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[0Xx]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[0Xx]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[Inf]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[Inf]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[+Inf]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[+Inf]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[Na]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[Na]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-Na]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-Na]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[infinity]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[infinity]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[InfinityHere]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[InfinityHere]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[NaNHere]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[NaNHere]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[+InfinityHere]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[+InfinityHere]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-NaNHere]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-NaNHere]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[InfinitY]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[InfinitY]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[Nan]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[Nan]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[+InfinitY]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[+InfinitY]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-Nan]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-Nan]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[nan]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[nan]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[+infinity]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[+infinity]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-infinity]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-infinity]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[+nan]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[+nan]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-nan]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-nan]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[InfinityInfinity]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[InfinityInfinity]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[NaNNad]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[NaNNad]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[NaNN]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[NaNN]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[++]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[++]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-  -]": {
                "testid": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers[-  -]",
                "result": "passed",
                "test_implementation": "def test_invalid_invalid_numbers(text_number: str) -> None:\n    \"\"\"Test invalid numbers.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_number(buffer=text_number, idx=0)"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[''        \\r\\n]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[''        \\r\\n]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[''     \\u2029]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[''     \\u2029]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['0'     \\u2029]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['0'     \\u2029]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['[\\\\',]'        \\r]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['[\\\\',]'        \\r]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['{}'     \\u2028]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['{}'     \\u2028]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['\\ua3b2'    \\u2028]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['\\ua3b2'    \\u2028]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['\\u5232'      \\r\\n]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['\\u5232'      \\r\\n]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\''  \\r]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\''  \\r]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\\"'          \\u2029]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\\"'          \\u2029]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\\\\\'  \\u2028]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\\\\\'  \\u2028]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\b'        \\u2028]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\b'        \\u2028]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\f'      \\n]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\f'      \\n]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\t'      \\r\\n]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\t'      \\r\\n]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\v'       \\u2028]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\v'       \\u2028]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\0'     \\r\\n]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\0'     \\r\\n]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\/'   \\n]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings['hello\\\\/'   \\n]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"\" \\n]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"\" \\n]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"\"         \\u2029]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"\"         \\u2029]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"0\"       \\r]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"0\"       \\r]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"[\\\\',]\"        \\r]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"[\\\\',]\"        \\r]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"{}\"      \\u2029]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"{}\"      \\u2029]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"\\ua3b2\"      \\u2028]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"\\ua3b2\"      \\u2028]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"\\u5232\"          \\u2029]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"\\u5232\"          \\u2029]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\'\"      \\u2028]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\'\"      \\u2028]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\\"\" \\u2028]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\\"\" \\u2028]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\\\\\\"          \\r\\n]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\\\\\\"          \\r\\n]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\b\"    \\n]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\b\"    \\n]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\f\"   \\u2028]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\f\"   \\u2028]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\t\"         \\n]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\t\"         \\n]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\v\"   \\u2029]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\v\"   \\u2029]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\0\" \\r]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\0\" \\r]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\/\"          \\u2028]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings[\"hello\\\\/\"          \\u2028]",
                "result": "passed",
                "test_implementation": "def test_valid_strings(text_string: str) -> None:\n    \"\"\"Test valid strings that do not escape to multiple lines.\"\"\"\n    text_string = simplify_escapes(text_string)\n    result = tokenize_string(buffer=text_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert text_string[start:end] == text_string.strip()[1:-1]\n    assert text_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings0-0]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings0-0]",
                "result": "passed",
                "test_implementation": "def test_valid_multiline_string(text_strings: list[str], spacing: int) -> None:\n    \"\"\"Test valid strings that escape to multiple lines.\"\"\"\n    original_string = \"\\n\".join(text_strings)\n    original_string = f'\"{original_string}\"'\n    multi_line_string = (\n        f\"\\\\{' ' * spacing}{choice(list(LINE_TERMINATOR_SEQUENCE))}\".join(text_strings)\n    )\n    multi_line_string = f'\"{multi_line_string}\"'\n    multi_line_string = simplify_escapes(multi_line_string)\n    result = tokenize_string(buffer=multi_line_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert multi_line_string[start:end] == multi_line_string[1:-1]\n    assert multi_line_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings1-0]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings1-0]",
                "result": "passed",
                "test_implementation": "def test_valid_multiline_string(text_strings: list[str], spacing: int) -> None:\n    \"\"\"Test valid strings that escape to multiple lines.\"\"\"\n    original_string = \"\\n\".join(text_strings)\n    original_string = f'\"{original_string}\"'\n    multi_line_string = (\n        f\"\\\\{' ' * spacing}{choice(list(LINE_TERMINATOR_SEQUENCE))}\".join(text_strings)\n    )\n    multi_line_string = f'\"{multi_line_string}\"'\n    multi_line_string = simplify_escapes(multi_line_string)\n    result = tokenize_string(buffer=multi_line_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert multi_line_string[start:end] == multi_line_string[1:-1]\n    assert multi_line_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings2-10]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings2-10]",
                "result": "passed",
                "test_implementation": "def test_valid_multiline_string(text_strings: list[str], spacing: int) -> None:\n    \"\"\"Test valid strings that escape to multiple lines.\"\"\"\n    original_string = \"\\n\".join(text_strings)\n    original_string = f'\"{original_string}\"'\n    multi_line_string = (\n        f\"\\\\{' ' * spacing}{choice(list(LINE_TERMINATOR_SEQUENCE))}\".join(text_strings)\n    )\n    multi_line_string = f'\"{multi_line_string}\"'\n    multi_line_string = simplify_escapes(multi_line_string)\n    result = tokenize_string(buffer=multi_line_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert multi_line_string[start:end] == multi_line_string[1:-1]\n    assert multi_line_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings3-10]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings3-10]",
                "result": "passed",
                "test_implementation": "def test_valid_multiline_string(text_strings: list[str], spacing: int) -> None:\n    \"\"\"Test valid strings that escape to multiple lines.\"\"\"\n    original_string = \"\\n\".join(text_strings)\n    original_string = f'\"{original_string}\"'\n    multi_line_string = (\n        f\"\\\\{' ' * spacing}{choice(list(LINE_TERMINATOR_SEQUENCE))}\".join(text_strings)\n    )\n    multi_line_string = f'\"{multi_line_string}\"'\n    multi_line_string = simplify_escapes(multi_line_string)\n    result = tokenize_string(buffer=multi_line_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert multi_line_string[start:end] == multi_line_string[1:-1]\n    assert multi_line_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings4-0]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings4-0]",
                "result": "passed",
                "test_implementation": "def test_valid_multiline_string(text_strings: list[str], spacing: int) -> None:\n    \"\"\"Test valid strings that escape to multiple lines.\"\"\"\n    original_string = \"\\n\".join(text_strings)\n    original_string = f'\"{original_string}\"'\n    multi_line_string = (\n        f\"\\\\{' ' * spacing}{choice(list(LINE_TERMINATOR_SEQUENCE))}\".join(text_strings)\n    )\n    multi_line_string = f'\"{multi_line_string}\"'\n    multi_line_string = simplify_escapes(multi_line_string)\n    result = tokenize_string(buffer=multi_line_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert multi_line_string[start:end] == multi_line_string[1:-1]\n    assert multi_line_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings5-1]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings5-1]",
                "result": "passed",
                "test_implementation": "def test_valid_multiline_string(text_strings: list[str], spacing: int) -> None:\n    \"\"\"Test valid strings that escape to multiple lines.\"\"\"\n    original_string = \"\\n\".join(text_strings)\n    original_string = f'\"{original_string}\"'\n    multi_line_string = (\n        f\"\\\\{' ' * spacing}{choice(list(LINE_TERMINATOR_SEQUENCE))}\".join(text_strings)\n    )\n    multi_line_string = f'\"{multi_line_string}\"'\n    multi_line_string = simplify_escapes(multi_line_string)\n    result = tokenize_string(buffer=multi_line_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert multi_line_string[start:end] == multi_line_string[1:-1]\n    assert multi_line_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings6-2]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings6-2]",
                "result": "passed",
                "test_implementation": "def test_valid_multiline_string(text_strings: list[str], spacing: int) -> None:\n    \"\"\"Test valid strings that escape to multiple lines.\"\"\"\n    original_string = \"\\n\".join(text_strings)\n    original_string = f'\"{original_string}\"'\n    multi_line_string = (\n        f\"\\\\{' ' * spacing}{choice(list(LINE_TERMINATOR_SEQUENCE))}\".join(text_strings)\n    )\n    multi_line_string = f'\"{multi_line_string}\"'\n    multi_line_string = simplify_escapes(multi_line_string)\n    result = tokenize_string(buffer=multi_line_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert multi_line_string[start:end] == multi_line_string[1:-1]\n    assert multi_line_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings7-3]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings7-3]",
                "result": "passed",
                "test_implementation": "def test_valid_multiline_string(text_strings: list[str], spacing: int) -> None:\n    \"\"\"Test valid strings that escape to multiple lines.\"\"\"\n    original_string = \"\\n\".join(text_strings)\n    original_string = f'\"{original_string}\"'\n    multi_line_string = (\n        f\"\\\\{' ' * spacing}{choice(list(LINE_TERMINATOR_SEQUENCE))}\".join(text_strings)\n    )\n    multi_line_string = f'\"{multi_line_string}\"'\n    multi_line_string = simplify_escapes(multi_line_string)\n    result = tokenize_string(buffer=multi_line_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert multi_line_string[start:end] == multi_line_string[1:-1]\n    assert multi_line_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings8-4]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings8-4]",
                "result": "passed",
                "test_implementation": "def test_valid_multiline_string(text_strings: list[str], spacing: int) -> None:\n    \"\"\"Test valid strings that escape to multiple lines.\"\"\"\n    original_string = \"\\n\".join(text_strings)\n    original_string = f'\"{original_string}\"'\n    multi_line_string = (\n        f\"\\\\{' ' * spacing}{choice(list(LINE_TERMINATOR_SEQUENCE))}\".join(text_strings)\n    )\n    multi_line_string = f'\"{multi_line_string}\"'\n    multi_line_string = simplify_escapes(multi_line_string)\n    result = tokenize_string(buffer=multi_line_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert multi_line_string[start:end] == multi_line_string[1:-1]\n    assert multi_line_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings9-0]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings9-0]",
                "result": "passed",
                "test_implementation": "def test_valid_multiline_string(text_strings: list[str], spacing: int) -> None:\n    \"\"\"Test valid strings that escape to multiple lines.\"\"\"\n    original_string = \"\\n\".join(text_strings)\n    original_string = f'\"{original_string}\"'\n    multi_line_string = (\n        f\"\\\\{' ' * spacing}{choice(list(LINE_TERMINATOR_SEQUENCE))}\".join(text_strings)\n    )\n    multi_line_string = f'\"{multi_line_string}\"'\n    multi_line_string = simplify_escapes(multi_line_string)\n    result = tokenize_string(buffer=multi_line_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert multi_line_string[start:end] == multi_line_string[1:-1]\n    assert multi_line_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings10-1]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings10-1]",
                "result": "passed",
                "test_implementation": "def test_valid_multiline_string(text_strings: list[str], spacing: int) -> None:\n    \"\"\"Test valid strings that escape to multiple lines.\"\"\"\n    original_string = \"\\n\".join(text_strings)\n    original_string = f'\"{original_string}\"'\n    multi_line_string = (\n        f\"\\\\{' ' * spacing}{choice(list(LINE_TERMINATOR_SEQUENCE))}\".join(text_strings)\n    )\n    multi_line_string = f'\"{multi_line_string}\"'\n    multi_line_string = simplify_escapes(multi_line_string)\n    result = tokenize_string(buffer=multi_line_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert multi_line_string[start:end] == multi_line_string[1:-1]\n    assert multi_line_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings11-2]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings11-2]",
                "result": "passed",
                "test_implementation": "def test_valid_multiline_string(text_strings: list[str], spacing: int) -> None:\n    \"\"\"Test valid strings that escape to multiple lines.\"\"\"\n    original_string = \"\\n\".join(text_strings)\n    original_string = f'\"{original_string}\"'\n    multi_line_string = (\n        f\"\\\\{' ' * spacing}{choice(list(LINE_TERMINATOR_SEQUENCE))}\".join(text_strings)\n    )\n    multi_line_string = f'\"{multi_line_string}\"'\n    multi_line_string = simplify_escapes(multi_line_string)\n    result = tokenize_string(buffer=multi_line_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert multi_line_string[start:end] == multi_line_string[1:-1]\n    assert multi_line_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings12-3]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings12-3]",
                "result": "passed",
                "test_implementation": "def test_valid_multiline_string(text_strings: list[str], spacing: int) -> None:\n    \"\"\"Test valid strings that escape to multiple lines.\"\"\"\n    original_string = \"\\n\".join(text_strings)\n    original_string = f'\"{original_string}\"'\n    multi_line_string = (\n        f\"\\\\{' ' * spacing}{choice(list(LINE_TERMINATOR_SEQUENCE))}\".join(text_strings)\n    )\n    multi_line_string = f'\"{multi_line_string}\"'\n    multi_line_string = simplify_escapes(multi_line_string)\n    result = tokenize_string(buffer=multi_line_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert multi_line_string[start:end] == multi_line_string[1:-1]\n    assert multi_line_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings13-4]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_valid_multiline_string[text_strings13-4]",
                "result": "passed",
                "test_implementation": "def test_valid_multiline_string(text_strings: list[str], spacing: int) -> None:\n    \"\"\"Test valid strings that escape to multiple lines.\"\"\"\n    original_string = \"\\n\".join(text_strings)\n    original_string = f'\"{original_string}\"'\n    multi_line_string = (\n        f\"\\\\{' ' * spacing}{choice(list(LINE_TERMINATOR_SEQUENCE))}\".join(text_strings)\n    )\n    multi_line_string = f'\"{multi_line_string}\"'\n    multi_line_string = simplify_escapes(multi_line_string)\n    result = tokenize_string(buffer=multi_line_string, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert multi_line_string[start:end] == multi_line_string[1:-1]\n    assert multi_line_string[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_passage": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_passage",
                "result": "passed",
                "test_implementation": "def test_passage() -> None:\n    \"\"\"Test a passage.\"\"\"\n    result = tokenize_string(buffer=TEST_PASSAGE, idx=0)\n    assert result.token is not None\n    assert result.token.tk_type == TOKEN_TYPE[\"STRING\"]\n    start, end = result.token.value\n    assert TEST_PASSAGE[start:end] == TEST_PASSAGE[1:-1]\n    assert TEST_PASSAGE[result.idx - 1] in {'\"', \"'\"}"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['no end single quote]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['no end single quote]",
                "result": "passed",
                "test_implementation": "def test_invalid_strings(text_string: str) -> None:\n    \"\"\"Test invalid strings.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_string(buffer=text_string, idx=0)"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings[\"no end double quote]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings[\"no end double quote]",
                "result": "passed",
                "test_implementation": "def test_invalid_strings(text_string: str) -> None:\n    \"\"\"Test invalid strings.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_string(buffer=text_string, idx=0)"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings[\"no end quote and new line\\n]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings[\"no end quote and new line\\n]",
                "result": "passed",
                "test_implementation": "def test_invalid_strings(text_string: str) -> None:\n    \"\"\"Test invalid strings.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_string(buffer=text_string, idx=0)"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings[no start quote]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings[no start quote]",
                "result": "passed",
                "test_implementation": "def test_invalid_strings(text_string: str) -> None:\n    \"\"\"Test invalid strings.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_string(buffer=text_string, idx=0)"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['no end single quote at newline    \\\\]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['no end single quote at newline    \\\\]",
                "result": "passed",
                "test_implementation": "def test_invalid_strings(text_string: str) -> None:\n    \"\"\"Test invalid strings.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_string(buffer=text_string, idx=0)"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['no end single quote at newline    \\\\  ']": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['no end single quote at newline    \\\\  ']",
                "result": "passed",
                "test_implementation": "def test_invalid_strings(text_string: str) -> None:\n    \"\"\"Test invalid strings.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_string(buffer=text_string, idx=0)"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['chars after escape new line \\\\   ambiguous chars\\n]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['chars after escape new line \\\\   ambiguous chars\\n]",
                "result": "passed",
                "test_implementation": "def test_invalid_strings(text_string: str) -> None:\n    \"\"\"Test invalid strings.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_string(buffer=text_string, idx=0)"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['nothing after escape new line \\\\    ]": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['nothing after escape new line \\\\    ]",
                "result": "passed",
                "test_implementation": "def test_invalid_strings(text_string: str) -> None:\n    \"\"\"Test invalid strings.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_string(buffer=text_string, idx=0)"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['unknown escape sequence \\\\x']": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['unknown escape sequence \\\\x']",
                "result": "passed",
                "test_implementation": "def test_invalid_strings(text_string: str) -> None:\n    \"\"\"Test invalid strings.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_string(buffer=text_string, idx=0)"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['invalid unicode escape sequence \\\\u']": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['invalid unicode escape sequence \\\\u']",
                "result": "passed",
                "test_implementation": "def test_invalid_strings(text_string: str) -> None:\n    \"\"\"Test invalid strings.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_string(buffer=text_string, idx=0)"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['invalid unicode escape sequence \\\\u01']": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['invalid unicode escape sequence \\\\u01']",
                "result": "passed",
                "test_implementation": "def test_invalid_strings(text_string: str) -> None:\n    \"\"\"Test invalid strings.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_string(buffer=text_string, idx=0)"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['invalid unicode escape sequence \\\\u013l']": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['invalid unicode escape sequence \\\\u013l']",
                "result": "passed",
                "test_implementation": "def test_invalid_strings(text_string: str) -> None:\n    \"\"\"Test invalid strings.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_string(buffer=text_string, idx=0)"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['invalid hex escape sequence \\\\x']": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['invalid hex escape sequence \\\\x']",
                "result": "passed",
                "test_implementation": "def test_invalid_strings(text_string: str) -> None:\n    \"\"\"Test invalid strings.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_string(buffer=text_string, idx=0)"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['invalid hex escape sequence \\\\x1']": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['invalid hex escape sequence \\\\x1']",
                "result": "passed",
                "test_implementation": "def test_invalid_strings(text_string: str) -> None:\n    \"\"\"Test invalid strings.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_string(buffer=text_string, idx=0)"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['invalid hex escape sequence \\\\xz']": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['invalid hex escape sequence \\\\xz']",
                "result": "passed",
                "test_implementation": "def test_invalid_strings(text_string: str) -> None:\n    \"\"\"Test invalid strings.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_string(buffer=text_string, idx=0)"
            },
            "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['invalid escape sequence \\\\k']": {
                "testid": "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings['invalid escape sequence \\\\k']",
                "result": "passed",
                "test_implementation": "def test_invalid_strings(text_string: str) -> None:\n    \"\"\"Test invalid strings.\"\"\"\n    with pytest.raises(JSON5DecodeError):\n        tokenize_string(buffer=text_string, idx=0)"
            },
            "tests/test_version.py::test_version_consistency": {
                "testid": "tests/test_version.py::test_version_consistency",
                "result": "passed",
                "test_implementation": "def test_version_consistency():\n    \"\"\"Test that the version in the package is consistent with the version in the metadata.\"\"\"\n    assert ujson5.__version__ == importlib.metadata.version(\"ujson5\")"
            }
        },
        "SRS_document": "**Software Requirements Specification: ujson5 Library**\n\n**Primary Goal of this SRS Document:**\nThis Software Requirements Specification (SRS) document will serve a critical role in assessing software developers. Developers will be provided with this SRS document and a designated subset of original test cases. Their objective is to develop a complete, functional software project based solely on this SRS. Their final success will be rigorously measured by whether their implementation passes all original test cases, including a comprehensive set of private tests not initially provided to them. Therefore, this SRS must be exceptionally clear, unambiguous, functionally comprehensive, and appropriately abstracted to allow for independent design choices while ensuring all specified functionalities are met.\n\n**Table of Contents:**\n1.  Introduction\n    1.1 Purpose\n    1.2 Scope\n    1.3 Definitions, Acronyms, and Abbreviations\n2.  Overall Description\n    2.1 Product Perspective\n    2.2 Product Functions\n    2.3 User Characteristics\n    2.4 Constraints\n    2.5 Assumptions and Dependencies\n3.  Specific Requirements\n    3.1 Functional Requirements\n        3.1.1 JSON5 Parsing (Decoding)\n        3.1.2 JSON5 Serialization (Encoding)\n        3.1.3 Command Line Interface (CLI)\n        3.1.4 General Functionality\n    3.2 Non-Functional Requirements\n\n---\n\n**1. Introduction**\n\n**1.1 Purpose**\nThe purpose of this Software Requirements Specification (SRS) is to provide a detailed description of the requirements for the `ujson5` Python library. This document will be used by software developers to design, implement, and test the `ujson5` library. Its primary role is to serve as the sole source of requirements for an assessment task where developers must build the library based on this SRS and a subset of public tests, aiming to pass all original (public and private) test cases.\n\n**1.2 Scope**\nThe software to be developed is a Python library, named `ujson5`, for encoding (serializing) Python objects into JSON5 formatted strings and decoding (parsing) JSON5 formatted strings into Python objects. The library shall also include a command-line interface (CLI) for validating JSON5 files and converting them to standard JSON. The library aims to support the JSON5 specification, which is a superset of JSON including human-friendly features.\n\n**1.3 Definitions, Acronyms, and Abbreviations**\n*   **JSON:** JavaScript Object Notation, a lightweight data-interchange format.\n*   **JSON5:** A proposed extension to JSON that aims to be easier for humans to write and maintain. Features include comments, unquoted keys, trailing commas, etc.\n*   **SRS:** Software Requirements Specification.\n*   **CLI:** Command Line Interface.\n*   **API:** Application Programming Interface.\n*   **TTY:** Teletypewriter, often used to refer to a terminal or console.\n\n---\n\n**2. Overall Description**\n\n**2.1 Product Perspective**\nThe `ujson5` library is an independent Python package that provides functionality similar to Python's built-in `json` module but for the JSON5 format. It is intended to be used as a library in other Python applications or as a standalone CLI tool.\n\n**2.2 Product Functions**\nThe `ujson5` library will provide the following core functionalities:\n*   **Decoding/Parsing:** Convert JSON5 data from strings or file-like objects into Python objects. This includes support for all standard JSON features plus JSON5 extensions like comments, unquoted keys, single-quoted strings, trailing commas, hexadecimal numbers, special numeric values (`Infinity`, `NaN`), and more.\n*   **Encoding/Serialization:** Convert Python objects (dictionaries, lists, strings, numbers, booleans, None) into JSON5 formatted strings or write them to file-like objects. This includes options for indentation, custom separators, ASCII enforcement, handling of special float values, sorting keys, key quotation styles, trailing commas, and serialization of comments from Python TypedDicts.\n*   **Command-Line Interface:** A CLI tool to validate JSON5 files/input and convert them to standard JSON, with options for output formatting.\n*   **Error Handling:** Provide clear and informative error messages for both parsing and serialization failures, including positional information for decoding errors.\n*   **Customization:** Offer various hooks and options to customize parsing and serialization behavior (e.g., custom object decoders, custom type serializers).\n\n**2.3 User Characteristics**\nThe primary users of the `ujson5` library are Python developers who need to work with JSON5 data in their applications. Users of the CLI tool are individuals who need to validate or convert JSON5 files from the command line. Users are expected to have a working knowledge of Python and familiarity with JSON/JSON5 concepts.\n\n**2.4 Constraints**\n*   The software must be implemented in Python.\n*   The library's programmatic API should be invocable from Python code.\n*   The CLI must be executable in a standard Python environment where the package is installed.\n\n**2.5 Assumptions and Dependencies**\n*   The system will operate in an environment where a compatible Python interpreter is available.\n*   The standard Python library is available.\n*   For CLI usage, the package is assumed to be installed in a way that makes the `ujson5` command accessible (e.g., via pipx, global pip install, or in an active virtual environment).\n\n---\n\n**3. Specific Requirements**\n\n**3.1 Functional Requirements**\n\nRequirements are identified by a unique FR-ID.\n\n**3.1.1 JSON5 Parsing (Decoding)**\n\n*   **FR-P-001:** The system shall parse a JSON5 formatted string into a corresponding Python object.\n*   **FR-P-002:** The system shall parse JSON5 data from a text-based file-like object (supporting a `.read()` method) into a corresponding Python object.\n*   **FR-P-003:** The system shall map standard JSON5 data types to their Python equivalents: objects to dictionaries, arrays to lists, strings to strings, numbers to integers or floats, `true` to `True`, `false` to `False`, and `null` to `None`.\n*   **FR-P-004:** The system shall ignore JSON5 comments during parsing. This includes single-line comments starting with `//` and multi-line comments enclosed in `/* ... */`.\n*   **FR-P-005:** The system shall support unquoted object keys if they are valid ECMAScript 5.1 identifiers.\n*   **FR-P-006:** The system shall support strings enclosed in single quotes (`'`) as well as double quotes (`\"`).\n*   **FR-P-007:** The system shall allow trailing commas after the last element in an array or the last member in an object.\n*   **FR-P-008:** The system shall parse hexadecimal numbers prefixed with `0x` or `0X`.\n*   **FR-P-009:** The system shall parse numbers with an explicit positive sign (e.g., `+123`).\n*   **FR-P-010:** The system shall parse numbers that start with a decimal point (e.g., `.5`) or end with a decimal point (e.g., `5.`).\n*   **FR-P-011:** The system shall parse the special numeric string values `Infinity`, `-Infinity`, and `NaN` (case-sensitive), including their positively signed variants (`+Infinity`, `+NaN`), as their corresponding Python `float` values.\n*   **FR-P-012:** The system shall support string line continuations, where a backslash (`\\`) followed by a line terminator sequence is treated as a continuation of the string onto the next line, effectively removing the backslash and the line terminator.\n*   **FR-P-013:** The system shall correctly interpret standard character escape sequences (e.g., `\\b`, `\\f`, `\\n`, `\\r`, `\\t`, `\\v`, `\\'`, `\\\"`, `\\\\`, `\\0`), hexadecimal escape sequences (`\\xHH`), and Unicode escape sequences (`\\uHHHH`) within strings.\n*   **FR-P-014:** The system shall allow providing a custom function (`parse_float`) at decoder initialization or via the `loads`/`load` functions, which will be called with the string representation of every JSON5 float to be decoded. The return value of this function will be used as the Python representation of that float.\n*   **FR-P-015:** The system shall allow providing a custom function (`parse_int`) at decoder initialization or via the `loads`/`load` functions, which will be called with the string representation of every JSON5 integer to be decoded. The return value of this function will be used as the Python representation of that integer.\n*   **FR-P-016:** The system shall allow providing a custom function (`parse_constant`) at decoder initialization or via the `loads`/`load` functions, which will be called with the string \"Infinity\", \"-Infinity\", or \"NaN\" (and their signed variants). The return value will be used as the Python representation.\n*   **FR-P-017:** The system shall provide a `strict` mode option (defaulting to `True`). When `strict=True`, certain JSON5 features that are more relaxed than standard JSON (e.g., control characters like `\\t`, `\\n`, `\\r`, `\\0` within strings) shall be disallowed, and their presence shall raise a decoding error. When `strict=False`, these are allowed.\n*   **FR-P-018:** The system shall provide an `allow_reserved_words` option (defaulting to `True`). If set to `False`, using ECMAScript reserved words (as defined in ECMA-262 5.1 sec 7.6.1) as unquoted object keys shall raise a decoding error. If `True`, they are permitted.\n*   **FR-P-019:** The system shall allow providing an `object_hook` function. If provided, this function will be called with the dictionary resulting from decoding any JSON5 object literal. The return value of the `object_hook` function will be used in place of the dictionary.\n*   **FR-P-020:** The system shall allow providing an `object_pairs_hook` function. If provided, this function will be called with an ordered list of (key, value) pairs resulting from decoding any JSON5 object literal. The return value of the `object_pairs_hook` will be used. If both `object_hook` and `object_pairs_hook` are defined, `object_pairs_hook` takes precedence.\n*   **FR-P-021:** Upon encountering a syntax error or an invalid JSON5 structure during parsing, the system shall raise a `JSON5DecodeError` (or an equivalent custom exception derived from `ValueError`). This error must provide a descriptive message, the original document string, the character position of the error, and the corresponding line number and column number. The string representation of the error should include the problematic line and a pointer to the error column.\n*   **FR-P-022:** The decoder class shall provide a `raw_decode` method (or equivalent functionality) that parses a JSON5 string and returns a tuple containing the resulting Python object and the index of the character in the input string immediately following the parsed JSON5 value.\n*   **FR-P-023:** The system, when `strict=False`, shall successfully parse JSON documents that include strings from the \"Big List of Naughty Strings\" without raising an unhandled exception or crashing.\n*   **FR-P-024:** The system shall correctly parse any valid standard JSON document as if it were JSON5, particularly when `strict=False`.\n\n**3.1.2 JSON5 Serialization (Encoding)**\n\n*   **FR-E-001:** The system shall serialize a Python object into a JSON5 formatted string.\n*   **FR-E-002:** The system shall serialize a Python object and write the resulting JSON5 formatted data to a text-based file-like object (supporting a `.write()` method). A newline character shall be appended after the main JSON5 object/value.\n*   **FR-E-003:** The system shall map standard Python data types to their JSON5 equivalents: dictionaries to objects, lists and tuples to arrays, strings to strings, integers and floats to numbers, `True` to `true`, `False` to `false`, and `None` to `null`.\n*   **FR-E-004:** The system shall allow specifying an `indent` level (an integer representing the number of spaces). If provided and not `None`, the JSON5 output will be pretty-printed with newlines and specified indentation for nested structures. If `indent` is `None` (default) or 0, the output will be compact.\n*   **FR-E-005:** The system shall allow specifying custom `separators` as a tuple `(item_separator, key_separator)`. These strings will be used to separate items in arrays and objects, and keys from values in objects, respectively. Default separators depend on the `indent` option.\n*   **FR-E-006:** The system shall provide an `ensure_ascii` option (defaulting to `True`). If `True`, all non-ASCII characters in output strings are escaped using `\\uXXXX` (or surrogate pairs for characters beyond BMP). If `False`, non-ASCII characters are output as their literal UTF-8 representations. Control characters (U+0000 to U+001F) are always escaped.\n*   **FR-E-007:** The system shall provide an `allow_nan` option (defaulting to `True`). If `True`, Python `float('nan')`, `float('inf')`, and `float('-inf')` are serialized as the JSON5 literal strings `NaN`, `Infinity`, and `-Infinity`, respectively. If `False`, an encoding error shall be raised for these values.\n*   **FR-E-008:** The system shall provide a `sort_keys` option (defaulting to `False`). If `True`, keys in Python dictionaries will be sorted alphabetically before serialization to a JSON5 object.\n*   **FR-E-009:** The system shall allow specifying a `key_quotation` style (defaulting to `\"double\"`).\n    *   If `\"double\"`, object keys are enclosed in double quotes.\n    *   If `\"single\"`, object keys are enclosed in single quotes.\n    *   If `\"none\"`, object keys are output without quotes if they are valid JSON5 identifiers; otherwise, they are double-quoted.\n*   **FR-E-010:** The system shall provide a `trailing_comma` option. If `True`, a comma is added after the last item in arrays and objects. If `False`, no trailing comma is added. If `None` (default), a trailing comma is added if an `indent` level is active (i.e., output is pretty-printed); otherwise, it is not added.\n*   **FR-E-011:** The system shall provide a `skip_keys` option (defaulting to `False`). If `True`, dictionary keys that are not of type str, int, float, bool, or None are skipped during serialization. If `False`, encountering such a key raises an encoding error.\n*   **FR-E-012:** The system shall provide a `check_circular` option (defaulting to `True`). If `True`, an encoding error is raised upon detecting circular references within Python lists or dictionaries. If `False`, circular reference checking is disabled (which may lead to a `RecursionError` for circular structures).\n*   **FR-E-013:** The system shall allow providing a `default` function. If an object cannot be directly serialized, this function is called with the object as an argument. The function should return a JSON5-serializable version of the object. If not provided or if the `default` function itself raises an error or returns an unserializable type, an encoding error is raised.\n*   **FR-E-014:** When an `indent` option is active and a `typed_dict_cls` (a Python `typing.TypedDict` class) is provided during serialization, the system shall attempt to extract comments (block and inline) associated with the fields of the `TypedDict` (and its parent TypedDicts, if Python version is >= 3.12) and include these comments in the JSON5 output next to their respective fields.\n*   **FR-E-015:** If an object cannot be serialized (e.g., it's an unsupported type and no `default` function handles it, or `skip_keys` is `False` for an invalid key type), or if a circular reference is detected (and `check_circular` is `True`), or if an invalid `typed_dict_cls` is provided, the system shall raise a `JSON5EncodeError` (or an equivalent custom exception derived from `ValueError`).\n*   **FR-E-016:** Python dictionary keys of type `int`, `float`, `bool`, or `None` shall be converted to their string representations (e.g., `12` to `\"12\"`, `True` to `\"true\"`) before being used as keys in the serialized JSON5 object.\n\n**3.1.3 Command Line Interface (CLI)**\n\n*   **FR-CLI-001:** The CLI shall display the library's version number when invoked with the `--version` or `-v` argument and then exit.\n*   **FR-CLI-002:** The CLI shall display the library's version number and system/platform information when invoked with the `--info` or `-i` argument and then exit.\n*   **FR-CLI-003:** The CLI shall accept an optional `infile` argument. If provided, the CLI will read JSON5 content from the specified file path.\n*   **FR-CLI-004:** If the `infile` argument is not provided and standard input (stdin) is not a TTY (i.e., it's being piped or redirected), the CLI shall read JSON5 content from stdin.\n*   **FR-CLI-005:** If an `outfile` argument is not provided, the CLI shall print its output (converted JSON or messages) to standard output (stdout).\n*   **FR-CLI-006:** The CLI shall accept an optional `outfile` argument. If provided, the CLI will write the converted JSON output to the specified file path. A message indicating the output file should be printed to stdout.\n*   **FR-CLI-007:** When processing valid JSON5 input (from file or stdin) without an `outfile` specified, the CLI shall convert the JSON5 to standard JSON, print a success message (`JSON_CONVERTED`), and then print the resulting JSON to stdout.\n*   **FR-CLI-008:** The CLI shall support a `--sort-keys` option, which, when active, causes dictionary keys in the output JSON to be sorted alphabetically.\n*   **FR-CLI-009:** The CLI shall support a `--no-ensure-ascii` option. When active, non-ASCII characters in the output JSON are not escaped. Otherwise (default), they are escaped.\n*   **FR-CLI-010:** The CLI shall provide mutually exclusive options for controlling whitespace in the JSON output:\n    *   `--indent N` (where N is an integer, default 2): Formats output with newlines and N spaces for indentation.\n    *   `--no-indent`: Separates items with spaces rather than newlines, resulting in a more compact single-line output for simple structures.\n    *   `--compact`: Suppresses all non-essential whitespace, producing the most compact JSON output.\n    *   If none of these are specified, `--indent 2` is the default behavior.\n*   **FR-CLI-011:** If no `infile` is specified and stdin is a TTY, the CLI shall print an error message indicating no target was specified (`ERR_NO_TARGET`), print help information, and exit.\n*   **FR-CLI-012:** If a specified `infile` does not exist or is not a file, the CLI shall print an error message indicating the target does not exist (`ERR_TARGET_NOT_EXIST`) and exit.\n*   **FR-CLI-013:** If the input JSON5 content is invalid, the CLI shall print an error message indicating a decoding error (`DECODING_ERROR`), followed by the detailed error message from the JSON5 decoder (including line, column, and context), and exit.\n\n**3.1.4 General Functionality**\n\n*   **FR-GEN-001:** The library shall expose its version programmatically via an accessible attribute (e.g., `ujson5.__version__`) and a function (e.g., `ujson5.version_info()`) that returns a string containing the library version and system information.\n*   **FR-GEN-002:** For a representative set of valid JSON5 inputs, the process of parsing the input, serializing the resulting Python object, and then re-parsing the serialized output shall yield a Python object that is equivalent to the object obtained from the initial parse (round trip consistency). This should hold for default serialization settings and when `strict=False` for loading.\n*   **FR-GEN-003:** Serializing a predefined, complex Python data structure using various encoding options (default, with comments from TypedDict, no comments, no indent, specific indent value, custom separators, with/without trailing comma) shall produce JSON5 output strings that are identical to pre-approved snapshot files.\n*   **FR-GEN-004:** Parsing various pre-approved JSON5 snapshot files (which themselves are serializations of a predefined complex Python object) shall result in Python objects that are equivalent to that original predefined Python object. (Excludes snapshot for special separators as it's not valid JSON5 for loading due to custom separators).\n\n**3.2 Non-Functional Requirements**\n\n*   **NFR-001:** Version Consistency: The version number exposed by the library (e.g., `ujson5.__version__`) must be identical to the version number defined in the package's metadata (as retrievable by `importlib.metadata.version(\"ujson5\")`).\n\n---\n**End of Document**",
        "structured_requirements": [
            {
                "requirement_id": "FR-P-001",
                "requirement_description": "The system shall parse a JSON5 formatted string into a corresponding Python object.",
                "test_traceability": [
                    {
                        "id": "tests/test_unit_tests/test_decoder.py::test_basic_loads",
                        "description": ""
                    },
                    {
                        "id": "tests/test_unit_tests/test_decoder.py::test_composite_loads",
                        "description": ""
                    },
                    {
                        "id": "tests/test_json5_examples.py::test_valid_examples",
                        "description": "numerous examples using `ujson5.loads`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/decoder.py::loads",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::Json5Decoder::decode",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P-002",
                "requirement_description": "The system shall parse JSON5 data from a text-based file-like object (supporting a `.read()` method) into a corresponding Python object.",
                "test_traceability": [
                    {
                        "id": "tests/test_json_test_suit.py::test_accepted_json",
                        "description": ""
                    },
                    {
                        "id": "tests/test_json5_examples.py::test_valid_examples",
                        "description": "numerous examples using `ujson5.load` with file objects"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/decoder.py::load",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P-003",
                "requirement_description": "The system shall map standard JSON5 data types to their Python equivalents: objects to dictionaries, arrays to lists, strings to strings, numbers to integers or floats, `true` to `True`, `false` to `False`, and `null` to `None`.",
                "test_traceability": [
                    {
                        "id": "tests/test_unit_tests/test_decoder.py::test_basic_loads",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/decoder.py::Json5Decoder::_parse_json5",
                        "description": "core parsing logic"
                    }
                ]
            },
            {
                "requirement_id": "FR-P-004",
                "requirement_description": "The system shall ignore JSON5 comments during parsing. This includes single-line comments starting with `//` and multi-line comments enclosed in `/* ... */`.",
                "test_traceability": [
                    {
                        "id": "tests/test_json5_examples.py::test_valid_examples",
                        "description": "e.g., `tests/json5_examples/comments/block.json5`, `tests/json5_examples/comments/inline.json5`"
                    },
                    {
                        "id": "tests/test_unit_tests/test_lexer.py::test_lexer",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/lexer.py::tokenize",
                        "description": "comment skipping logic"
                    },
                    {
                        "id": "src/ujson5/lexer.py::validate_comment",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P-005",
                "requirement_description": "The system shall support unquoted object keys if they are valid ECMAScript 5.1 identifiers.",
                "test_traceability": [
                    {
                        "id": "tests/test_json5_examples.py::test_valid_examples",
                        "description": "e.g., `tests/json5_examples/objects/unquoted-keys.json5`"
                    },
                    {
                        "id": "tests/test_unit_tests/test_decoder.py::test_composite_loads",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/lexer.py::tokenize_identifier",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::Json5Decoder::_parse_json5",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P-006",
                "requirement_description": "The system shall support strings enclosed in single quotes (`'`) as well as double quotes (`\"`).",
                "test_traceability": [
                    {
                        "id": "tests/test_json5_examples.py::test_valid_examples",
                        "description": "e.g., `tests/json5_examples/strings/single-quotes.json5`"
                    },
                    {
                        "id": "tests/test_unit_tests/test_decoder.py::test_composite_loads",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/lexer.py::tokenize_string",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P-007",
                "requirement_description": "The system shall allow trailing commas after the last element in an array or the last member in an object.",
                "test_traceability": [
                    {
                        "id": "tests/test_json5_examples.py::test_valid_examples",
                        "description": "e.g., `tests/json5_examples/arrays/trailing-comma.json5`, `tests/json5_examples/objects/trailing-comma.json5`"
                    },
                    {
                        "id": "tests/test_unit_tests/test_decoder.py::test_composite_loads",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/decoder.py::Json5Decoder::_parse_json5",
                        "description": "comma handling logic"
                    }
                ]
            },
            {
                "requirement_id": "FR-P-008",
                "requirement_description": "The system shall parse hexadecimal numbers prefixed with `0x` or `0X`.",
                "test_traceability": [
                    {
                        "id": "tests/test_json5_examples.py::test_valid_examples",
                        "description": "e.g., `tests/json5_examples/numbers/hex.json5`"
                    },
                    {
                        "id": "tests/test_unit_tests/test_decoder.py::test_basic_loads",
                        "description": "e.g., \"0x23\""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/lexer.py::tokenize_number",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::Json5Decoder::_parse_number",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P-009",
                "requirement_description": "The system shall parse numbers with an explicit positive sign (e.g., `+123`).",
                "test_traceability": [
                    {
                        "id": "tests/test_json5_examples.py::test_valid_examples",
                        "description": "e.g., `tests/json5_examples/numbers/plus.json5`"
                    },
                    {
                        "id": "tests/test_unit_tests/test_decoder.py::test_composite_loads",
                        "description": "e.g., \"+1\""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/lexer.py::tokenize_number",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P-010",
                "requirement_description": "The system shall parse numbers that start with a decimal point (e.g., `.5`) or end with a decimal point (e.g., `5.`).",
                "test_traceability": [
                    {
                        "id": "tests/test_json5_examples.py::test_valid_examples",
                        "description": "e.g., `tests/json5_examples/numbers/leading-decimal-point.json5`, `tests/json5_examples/numbers/trailing-decimal-point.json5`"
                    },
                    {
                        "id": "tests/test_unit_tests/test_decoder.py::test_composite_loads",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/lexer.py::tokenize_number",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P-011",
                "requirement_description": "The system shall parse the special numeric string values `Infinity`, `-Infinity`, and `NaN` (case-sensitive), including their positively signed variants (`+Infinity`, `+NaN`), as their corresponding Python `float` values.",
                "test_traceability": [
                    {
                        "id": "tests/test_unit_tests/test_decoder.py::test_basic_loads",
                        "description": "e.g., \"Infinity\", \"NaN\", \"-Infinity\", \"-NaN\""
                    },
                    {
                        "id": "tests/test_json5_examples.py::test_valid_examples",
                        "description": "e.g., `tests/json5_examples/numbers/infinity.json5`, `tests/json5_examples/numbers/nan.json5`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/lexer.py::tokenize_number",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::Json5Decoder::_parse_number",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P-012",
                "requirement_description": "The system shall support string line continuations, where a backslash (`\\`) followed by a line terminator sequence is treated as a continuation of the string onto the next line, effectively removing the backslash and the line terminator.",
                "test_traceability": [
                    {
                        "id": "tests/test_json5_examples.py::test_valid_examples",
                        "description": "e.g., `tests/json5_examples/strings/escaped-newline.json5`"
                    },
                    {
                        "id": "tests/test_unit_tests/test_decoder.py::test_composite_loads",
                        "description": "e.g., \"Look, Mom! \\\nNo \\n's!\""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/lexer.py::_escape_handler",
                        "description": "line continuation part"
                    },
                    {
                        "id": "src/ujson5/decoder.py::Json5Decoder::_parse_string",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P-013",
                "requirement_description": "The system shall correctly interpret standard character escape sequences (e.g., `\\b`, `\\f`, `\\n`, `\\r`, `\\t`, `\\v`, `\\'`, `\\\"`, `\\\\`, `\\0`), hexadecimal escape sequences (`\\xHH`), and Unicode escape sequences (`\\uHHHH`) within strings.",
                "test_traceability": [
                    {
                        "id": "tests/test_unit_tests/test_string_lexer.py::test_valid_strings",
                        "description": ""
                    },
                    {
                        "id": "tests/test_unit_tests/test_decoder.py::test_basic_loads",
                        "description": "e.g., \"string with \\\"escaped quotes\\\"\""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/lexer.py::_escape_handler",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::Json5Decoder::_parse_string",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P-014",
                "requirement_description": "The system shall allow providing a custom function (`parse_float`) at decoder initialization or via the `loads`/`load` functions, which will be called with the string representation of every JSON5 float to be decoded. The return value of this function will be used as the Python representation of that float.",
                "test_traceability": [
                    {
                        "id": "tests/test_unit_tests/test_decoder.py::test_custom_decoder",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/decoder.py::Json5Decoder::__init__",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::Json5Decoder::_parse_number",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::loads",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::load",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P-015",
                "requirement_description": "The system shall allow providing a custom function (`parse_int`) at decoder initialization or via the `loads`/`load` functions, which will be called with the string representation of every JSON5 integer to be decoded. The return value of this function will be used as the Python representation of that integer.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "src/ujson5/decoder.py::Json5Decoder::__init__",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::Json5Decoder::_parse_number",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::loads",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::load",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P-016",
                "requirement_description": "The system shall allow providing a custom function (`parse_constant`) at decoder initialization or via the `loads`/`load` functions, which will be called with the string \"Infinity\", \"-Infinity\", or \"NaN\" (and their signed variants). The return value will be used as the Python representation.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "src/ujson5/decoder.py::Json5Decoder::__init__",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::Json5Decoder::_parse_number",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::loads",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::load",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P-017",
                "requirement_description": "The system shall provide a `strict` mode option (defaulting to `True`). When `strict=True`, certain JSON5 features that are more relaxed than standard JSON (e.g., control characters like `\\t`, `\\n`, `\\r`, `\\0` within strings) shall be disallowed, and their presence shall raise a decoding error. When `strict=False`, these are allowed.",
                "test_traceability": [
                    {
                        "id": "tests/test_unit_tests/test_decoder.py::test_strict_mode",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/decoder.py::Json5Decoder::__init__",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::Json5Decoder::_parse_string",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::loads",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::load",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P-018",
                "requirement_description": "The system shall provide an `allow_reserved_words` option (defaulting to `True`). If set to `False`, using ECMAScript reserved words (as defined in ECMA-262 5.1 sec 7.6.1) as unquoted object keys shall raise a decoding error. If `True`, they are permitted.",
                "test_traceability": [
                    {
                        "id": "tests/test_unit_tests/test_decoder.py::test_reserved_word_keys",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/decoder.py::Json5Decoder::__init__",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::Json5Decoder::_parse_json5",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::loads",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::load",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P-019",
                "requirement_description": "The system shall allow providing an `object_hook` function. If provided, this function will be called with the dictionary resulting from decoding any JSON5 object literal. The return value of the `object_hook` function will be used in place of the dictionary.",
                "test_traceability": [
                    {
                        "id": "tests/test_unit_tests/test_decoder.py::test_object_hook",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/decoder.py::Json5Decoder::__init__",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::Json5Decoder::_parse_json5",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::loads",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::load",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P-020",
                "requirement_description": "The system shall allow providing an `object_pairs_hook` function. If provided, this function will be called with an ordered list of (key, value) pairs resulting from decoding any JSON5 object literal. The return value of the `object_pairs_hook` will be used. If both `object_hook` and `object_pairs_hook` are defined, `object_pairs_hook` takes precedence.",
                "test_traceability": [
                    {
                        "id": "tests/test_unit_tests/test_decoder.py::test_object_pair_hook",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/decoder.py::Json5Decoder::__init__",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::Json5Decoder::_parse_json5",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::loads",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/decoder.py::load",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P-021",
                "requirement_description": "Upon encountering a syntax error or an invalid JSON5 structure during parsing, the system shall raise a `JSON5DecodeError` (or an equivalent custom exception derived from `ValueError`). This error must provide a descriptive message, the original document string, the character position of the error, and the corresponding line number and column number. The string representation of the error should include the problematic line and a pointer to the error column.",
                "test_traceability": [
                    {
                        "id": "tests/test_json5_examples.py::test_invalid_examples",
                        "description": ""
                    },
                    {
                        "id": "tests/test_unit_tests/test_decoder.py::test_invalid_loads",
                        "description": ""
                    },
                    {
                        "id": "tests/test_unit_tests/test_string_lexer.py::test_invalid_strings",
                        "description": ""
                    },
                    {
                        "id": "tests/test_unit_tests/test_number_lexer.py::test_invalid_invalid_numbers",
                        "description": ""
                    },
                    {
                        "id": "tests/test_unit_tests/test_identifier_lexer.py::test_invalid_identifiers",
                        "description": ""
                    },
                    {
                        "id": "tests/test_unit_tests/test_comment_lexer.py::test_invalid_comments",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/core.py::JSON5DecodeError",
                        "description": ""
                    },
                    {
                        "id": "",
                        "description": "various `raise JSON5DecodeError` statements throughout `src/ujson5/lexer.py` and `src/ujson5/decoder.py`"
                    }
                ]
            },
            {
                "requirement_id": "FR-P-022",
                "requirement_description": "The decoder class shall provide a `raw_decode` method (or equivalent functionality) that parses a JSON5 string and returns a tuple containing the resulting Python object and the index of the character in the input string immediately following the parsed JSON5 value.",
                "test_traceability": [
                    {
                        "id": "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/decoder.py::Json5Decoder::raw_decode",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P-023",
                "requirement_description": "The system, when `strict=False`, shall successfully parse JSON documents that include strings from the \"Big List of Naughty Strings\" without raising an unhandled exception or crashing.",
                "test_traceability": [
                    {
                        "id": "tests/test_blns.py::test_blns",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/decoder.py::load",
                        "description": "and its underlying parsing and string handling logic"
                    }
                ]
            },
            {
                "requirement_id": "FR-P-024",
                "requirement_description": "The system shall correctly parse any valid standard JSON document as if it were JSON5, particularly when `strict=False`.",
                "test_traceability": [
                    {
                        "id": "tests/test_json_test_suit.py::test_accepted_json",
                        "description": ""
                    },
                    {
                        "id": "tests/test_native_json_benchmark.py::test_json_checker_file",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/decoder.py::load",
                        "description": "and its underlying parsing logic"
                    }
                ]
            },
            {
                "requirement_id": "FR-E-001",
                "requirement_description": "The system shall serialize a Python object into a JSON5 formatted string.",
                "test_traceability": [
                    {
                        "id": "tests/test_unit_tests/test_encoder.py::test_valid_examples",
                        "description": ""
                    },
                    {
                        "id": "tests/test_snapshots/test_snapshots.py",
                        "description": "various tests using `ujson5.dumps`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/encoder.py::dumps",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::encode",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-E-002",
                "requirement_description": "The system shall serialize a Python object and write the resulting JSON5 formatted data to a text-based file-like object (supporting a `.write()` method). A newline character shall be appended after the main JSON5 object/value.",
                "test_traceability": [
                    {
                        "id": "tests/test_json5_examples.py::test_dump_load_from_examples",
                        "description": ""
                    },
                    {
                        "id": "tests/test_snapshots/generate_snapshots.py",
                        "description": "uses `ujson5.dump`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/encoder.py::dump",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-E-003",
                "requirement_description": "The system shall map standard Python data types to their JSON5 equivalents: dictionaries to objects, lists and tuples to arrays, strings to strings, integers and floats to numbers, `True` to `true`, `False` to `false`, and `None` to `null`.",
                "test_traceability": [
                    {
                        "id": "tests/test_unit_tests/test_encoder.py::test_valid_examples",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::_iterencode",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-E-004",
                "requirement_description": "The system shall allow specifying an `indent` level (an integer representing the number of spaces). If provided and not `None`, the JSON5 output will be pretty-printed with newlines and specified indentation for nested structures. If `indent` is `None` (default) or 0, the output will be compact.",
                "test_traceability": [
                    {
                        "id": "tests/test_unit_tests/test_encoder.py::test_indent",
                        "description": ""
                    },
                    {
                        "id": "tests/test_snapshots/test_snapshots.py::test_alpha_no_indent",
                        "description": ""
                    },
                    {
                        "id": "tests/test_snapshots/test_snapshots.py::test_alpha_7_indent",
                        "description": ""
                    },
                    {
                        "id": "tests/test_snapshots/test_snapshots.py::test_alpha_no_comments",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::__init__",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::_iterencode_list",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::_iterencode_dict",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-E-005",
                "requirement_description": "The system shall allow specifying custom `separators` as a tuple `(item_separator, key_separator)`. These strings will be used to separate items in arrays and objects, and keys from values in objects, respectively. Default separators depend on the `indent` option.",
                "test_traceability": [
                    {
                        "id": "tests/test_unit_tests/test_encoder.py::test_separators",
                        "description": ""
                    },
                    {
                        "id": "tests/test_snapshots/test_snapshots.py::test_alpha_special_separators",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-E-006",
                "requirement_description": "The system shall provide an `ensure_ascii` option (defaulting to `True`). If `True`, all non-ASCII characters in output strings are escaped using `\\uXXXX` (or surrogate pairs for characters beyond BMP). If `False`, non-ASCII characters are output as their literal UTF-8 representations. Control characters (U+0000 to U+001F) are always escaped.",
                "test_traceability": [
                    {
                        "id": "tests/test_unit_tests/test_encoder.py::test_replace_unicode",
                        "description": "`ensure_ascii=False`"
                    },
                    {
                        "id": "tests/test_unit_tests/test_encoder.py::test_replace_ascii",
                        "description": "`ensure_ascii=True`"
                    },
                    {
                        "id": "tests/test_json5_examples.py::test_dump_load_from_examples",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::__init__",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::_encode_str",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-E-007",
                "requirement_description": "The system shall provide an `allow_nan` option (defaulting to `True`). If `True`, Python `float('nan')`, `float('inf')`, and `float('-inf')` are serialized as the JSON5 literal strings `NaN`, `Infinity`, and `-Infinity`, respectively. If `False`, an encoding error shall be raised for these values.",
                "test_traceability": [
                    {
                        "id": "tests/test_unit_tests/test_encoder.py::test_nan_not_allowed",
                        "description": ""
                    },
                    {
                        "id": "tests/test_unit_tests/test_encoder.py::test_valid_examples",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::__init__",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::_encode_float",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-E-008",
                "requirement_description": "The system shall provide a `sort_keys` option (defaulting to `False`). If `True`, keys in Python dictionaries will be sorted alphabetically before serialization to a JSON5 object.",
                "test_traceability": [
                    {
                        "id": "tests/test_unit_tests/test_encoder.py::test_sort_keys",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::__init__",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::_iterencode_dict",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-E-009",
                "requirement_description": "The system shall allow specifying a `key_quotation` style (defaulting to `\"double\"`).",
                "test_traceability": [
                    {
                        "id": "tests/test_unit_tests/test_encoder.py::test_quoted_key",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::__init__",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::_encode_str",
                        "description": "usage with `key_str=True`"
                    }
                ]
            },
            {
                "requirement_id": "FR-E-010",
                "requirement_description": "The system shall provide a `trailing_comma` option. If `True`, a comma is added after the last item in arrays and objects. If `False`, no trailing comma is added. If `None` (default), a trailing comma is added if an `indent` level is active (i.e., output is pretty-printed); otherwise, it is not added.",
                "test_traceability": [
                    {
                        "id": "tests/test_snapshots/test_snapshots.py::test_alpha_with_trailing_comma",
                        "description": ""
                    },
                    {
                        "id": "tests/test_snapshots/test_snapshots.py::test_alpha_no_trailing_comma",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::__init__",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::_iterencode_list",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::_iterencode_dict",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-E-011",
                "requirement_description": "The system shall provide a `skip_keys` option (defaulting to `False`). If `True`, dictionary keys that are not of type str, int, float, bool, or None are skipped during serialization. If `False`, encountering such a key raises an encoding error.",
                "test_traceability": [
                    {
                        "id": "tests/test_unit_tests/test_encoder.py::test_skip_keys",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::__init__",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::_iterencode_dict",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-E-012",
                "requirement_description": "The system shall provide a `check_circular` option (defaulting to `True`). If `True`, an encoding error is raised upon detecting circular references within Python lists or dictionaries. If `False`, circular reference checking is disabled (which may lead to a `RecursionError` for circular structures).",
                "test_traceability": [
                    {
                        "id": "tests/test_unit_tests/test_encoder.py::test_circular_ref",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::__init__",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::_iterencode",
                        "description": "marker logic"
                    }
                ]
            },
            {
                "requirement_id": "FR-E-013",
                "requirement_description": "The system shall allow providing a `default` function. If an object cannot be directly serialized, this function is called with the object as an argument. The function should return a JSON5-serializable version of the object. If not provided or if the `default` function itself raises an error or returns an unserializable type, an encoding error is raised.",
                "test_traceability": [
                    {
                        "id": "tests/test_unit_tests/test_encoder.py::test_default_set",
                        "description": ""
                    },
                    {
                        "id": "tests/test_unit_tests/test_encoder.py::test_circular_ref",
                        "description": "Custom class example"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::__init__",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::default",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::_iterencode",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-E-014",
                "requirement_description": "When an `indent` option is active and a `typed_dict_cls` (a Python `typing.TypedDict` class) is provided during serialization, the system shall attempt to extract comments (block and inline) associated with the fields of the `TypedDict` (and its parent TypedDicts, if Python version is >= 3.12) and include these comments in the JSON5 output next to their respective fields.",
                "test_traceability": [
                    {
                        "id": "tests/test_snapshots/test_snapshots.py::test_alpha_with_comments",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::iterencode",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/encoder.py::get_comments",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::_iterencode_dict",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-E-015",
                "requirement_description": "If an object cannot be serialized (e.g., it's an unsupported type and no `default` function handles it, or `skip_keys` is `False` for an invalid key type), or if a circular reference is detected (and `check_circular` is `True`), or if an invalid `typed_dict_cls` is provided, the system shall raise a `JSON5EncodeError` (or an equivalent custom exception derived from `ValueError`).",
                "test_traceability": [
                    {
                        "id": "tests/test_unit_tests/test_encoder.py::test_invalid_examples",
                        "description": ""
                    },
                    {
                        "id": "tests/test_unit_tests/test_encoder.py::test_circular_ref",
                        "description": ""
                    },
                    {
                        "id": "tests/test_unit_tests/test_encoder.py::test_skip_keys",
                        "description": "when `skip_keys=False`"
                    },
                    {
                        "id": "tests/test_unit_tests/test_encoder.py::test_invalid_typed_dict_cls",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/core.py::JSON5EncodeError",
                        "description": ""
                    },
                    {
                        "id": "",
                        "description": "various `raise JSON5EncodeError` statements in `src/ujson5/encoder.py`"
                    }
                ]
            },
            {
                "requirement_id": "FR-E-016",
                "requirement_description": "Python dictionary keys of type `int`, `float`, `bool`, or `None` shall be converted to their string representations (e.g., `12` to `\"12\"`, `True` to `\"true\"`) before being used as keys in the serialized JSON5 object.",
                "test_traceability": [
                    {
                        "id": "tests/test_unit_tests/test_encoder.py::test_valid_examples",
                        "description": "dictionary with non-string primitive keys"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/encoder.py::JSON5Encoder::_iterencode_dict",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-001",
                "requirement_description": "The CLI shall display the library's version number when invoked with the `--version` or `-v` argument and then exit.",
                "test_traceability": [
                    {
                        "id": "tests/test_cli.py::test_cli_version",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/cli.py::main",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-002",
                "requirement_description": "The CLI shall display the library's version number and system/platform information when invoked with the `--info` or `-i` argument and then exit.",
                "test_traceability": [
                    {
                        "id": "tests/test_cli.py::test_cli_info",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/cli.py::main",
                        "description": ""
                    },
                    {
                        "id": "src/ujson5/core.py::version_info",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-003",
                "requirement_description": "The CLI shall accept an optional `infile` argument. If provided, the CLI will read JSON5 content from the specified file path.",
                "test_traceability": [
                    {
                        "id": "tests/test_cli.py::test_cli_stdout_correct",
                        "description": ""
                    },
                    {
                        "id": "tests/test_cli.py::test_cli_output",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/cli.py::main",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-004",
                "requirement_description": "If the `infile` argument is not provided and standard input (stdin) is not a TTY (i.e., it's being piped or redirected), the CLI shall read JSON5 content from stdin.",
                "test_traceability": [
                    {
                        "id": "tests/test_cli.py::test_cli_stdin",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/cli.py::main",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-005",
                "requirement_description": "If an `outfile` argument is not provided, the CLI shall print its output (converted JSON or messages) to standard output (stdout).",
                "test_traceability": [
                    {
                        "id": "tests/test_cli.py::test_cli_stdout_correct",
                        "description": ""
                    },
                    {
                        "id": "tests/test_cli.py::test_cli_stdin",
                        "description": ""
                    },
                    {
                        "id": "tests/test_cli.py::test_cli_stdout_incorrect",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/cli.py::main",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-006",
                "requirement_description": "The CLI shall accept an optional `outfile` argument. If provided, the CLI will write the converted JSON output to the specified file path. A message indicating the output file should be printed to stdout.",
                "test_traceability": [
                    {
                        "id": "tests/test_cli.py::test_cli_output",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/cli.py::main",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-007",
                "requirement_description": "When processing valid JSON5 input (from file or stdin) without an `outfile` specified, the CLI shall convert the JSON5 to standard JSON, print a success message (`JSON_CONVERTED`), and then print the resulting JSON to stdout.",
                "test_traceability": [
                    {
                        "id": "tests/test_cli.py::test_cli_stdout_correct",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/cli.py::main",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-008",
                "requirement_description": "The CLI shall support a `--sort-keys` option, which, when active, causes dictionary keys in the output JSON to be sorted alphabetically.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "src/ujson5/cli.py::main",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-009",
                "requirement_description": "The CLI shall support a `--no-ensure-ascii` option. When active, non-ASCII characters in the output JSON are not escaped. Otherwise (default), they are escaped.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "src/ujson5/cli.py::main",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-010",
                "requirement_description": "The CLI shall provide mutually exclusive options for controlling whitespace in the JSON output:",
                "test_traceability": [
                    {
                        "id": "tests/test_cli.py::test_cli_stdin",
                        "description": "tests `--no-indent`, `--compact`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/cli.py::main",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-011",
                "requirement_description": "If no `infile` is specified and stdin is a TTY, the CLI shall print an error message indicating no target was specified (`ERR_NO_TARGET`), print help information, and exit.",
                "test_traceability": [
                    {
                        "id": "tests/test_cli.py::test_cli_no_target",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/cli.py::main",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-012",
                "requirement_description": "If a specified `infile` does not exist or is not a file, the CLI shall print an error message indicating the target does not exist (`ERR_TARGET_NOT_EXIST`) and exit.",
                "test_traceability": [
                    {
                        "id": "tests/test_cli.py::test_cli_invalid_path",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/cli.py::main",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-013",
                "requirement_description": "If the input JSON5 content is invalid, the CLI shall print an error message indicating a decoding error (`DECODING_ERROR`), followed by the detailed error message from the JSON5 decoder (including line, column, and context), and exit.",
                "test_traceability": [
                    {
                        "id": "tests/test_cli.py::test_cli_stdout_incorrect",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/cli.py::main",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-001",
                "requirement_description": "The library shall expose its version programmatically via an accessible attribute (e.g., `ujson5.__version__`) and a function (e.g., `ujson5.version_info()`) that returns a string containing the library version and system information.",
                "test_traceability": [
                    {
                        "id": "tests/test_version.py::test_version_consistency",
                        "description": "checks `__version__`"
                    },
                    {
                        "id": "tests/test_cli.py::test_cli_info",
                        "description": "implicitly tests `version_info()` via CLI"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/__init__.py",
                        "description": "for `__version__`"
                    },
                    {
                        "id": "src/ujson5/core.py::version_info",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-002",
                "requirement_description": "For a representative set of valid JSON5 inputs, the process of parsing the input, serializing the resulting Python object, and then re-parsing the serialized output shall yield a Python object that is equivalent to the object obtained from the initial parse (round trip consistency). This should hold for default serialization settings and when `strict=False` for loading.",
                "test_traceability": [
                    {
                        "id": "tests/test_json5_examples.py::test_dump_load_from_examples",
                        "description": ""
                    },
                    {
                        "id": "tests/test_native_json_benchmark.py::test_round_trips",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "",
                        "description": "Combination of `src/ujson5/decoder.py` and `src/ujson5/encoder.py` functionalities."
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-003",
                "requirement_description": "Serializing a predefined, complex Python data structure using various encoding options (default, with comments from TypedDict, no comments, no indent, specific indent value, custom separators, with/without trailing comma) shall produce JSON5 output strings that are identical to pre-approved snapshot files.",
                "test_traceability": [
                    {
                        "id": "tests/test_snapshots/test_snapshots.py::test_alpha_default",
                        "description": ""
                    },
                    {
                        "id": "tests/test_snapshots/test_snapshots.py::test_alpha_with_comments",
                        "description": ""
                    },
                    {
                        "id": "tests/test_snapshots/test_snapshots.py::test_alpha_no_comments",
                        "description": ""
                    },
                    {
                        "id": "tests/test_snapshots/test_snapshots.py::test_alpha_no_indent",
                        "description": ""
                    },
                    {
                        "id": "tests/test_snapshots/test_snapshots.py::test_alpha_7_indent",
                        "description": ""
                    },
                    {
                        "id": "tests/test_snapshots/test_snapshots.py::test_alpha_special_separators",
                        "description": ""
                    },
                    {
                        "id": "tests/test_snapshots/test_snapshots.py::test_alpha_with_trailing_comma",
                        "description": ""
                    },
                    {
                        "id": "tests/test_snapshots/test_snapshots.py::test_alpha_no_trailing_comma",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/encoder.py::dumps",
                        "description": "with various options defined in `JSON5Encoder`"
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-004",
                "requirement_description": "Parsing various pre-approved JSON5 snapshot files (which themselves are serializations of a predefined complex Python object) shall result in Python objects that are equivalent to that original predefined Python object. (Excludes snapshot for special separators as it's not valid JSON5 for loading due to custom separators).",
                "test_traceability": [
                    {
                        "id": "tests/test_snapshots/test_snapshots.py::test_load_json5_from_alpha_snapshots",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/decoder.py::load",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "NFR-001",
                "requirement_description": "Version Consistency: The version number exposed by the library (e.g., `ujson5.__version__`) must be identical to the version number defined in the package's metadata (as retrievable by `importlib.metadata.version(\"ujson5\")`).",
                "test_traceability": [
                    {
                        "id": "tests/test_version.py::test_version_consistency",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ujson5/__init__.py",
                        "description": "package exports"
                    },
                    {
                        "id": "src/ujson5/_version.py",
                        "description": "likely definition of `__version__`"
                    }
                ]
            }
        ],
        "full_code_skeleton": "--- File: src/ujson5/core.py ---\n```python\n\"\"\"Core JSON5 classes and exceptions.\"\"\"\n\ndef version_info() -> str:\n    \"\"\"Return complete version information for ujson5 and its dependencies.\"\"\"\n    pass\n\nJsonValue = dict | list | int | float | str | None | bool\n\"\"\"Type hint for JSON5 values.\"\"\"\nJsonValuePairs = list[tuple[str, JsonValue]]\n\nclass JSON5DecodeError(ValueError):\n    \"\"\"Subclass of ValueError with the following additional properties:\n\n    msg: The unformatted error message\n    doc: The JSON document being parsed\n    pos: The start index of doc where parsing failed\n    lineno: The line corresponding to pos\n    colno: The column corresponding to pos\n\n    \"\"\"\n    def __init__(self, msg: str, doc: str, pos: int) -> None:\n        pass\n\n    def __reduce__(self) -> tuple:  # pragma: no cover\n        pass\n\n    def __str__(self) -> str:  # pragma: no cover\n        pass\n\nclass JSON5EncodeError(ValueError):\n    \"\"\"Subclass of ValueError raised when encoding fails.\"\"\"\n    pass\n\nTokenTypesKey = Literal[\n    \"IDENTIFIER\",\n    \"STRING\",\n    \"NUMBER\",\n    \"BOOLEAN\",\n    \"NULL\",\n    \"PUN_OPEN_BRACE\",\n    \"PUN_CLOSE_BRACE\",\n    \"PUN_OPEN_BRACKET\",\n    \"PUN_CLOSE_BRACKET\",\n    \"PUN_COLON\",\n    \"PUN_COMMA\",\n]\n\nclass Token(NamedTuple):\n    \"\"\"Token representation\"\"\"\n\n    tk_type: int\n    # start and end index of the token in the document\n    value: tuple[int, int]\n\nclass TokenResult(NamedTuple):\n    \"\"\"Token result\"\"\"\n\n    token: Token\n    idx: int\n```\n--- File: src/ujson5/cli.py ---\n```python\n\"\"\"CLI supports\"\"\"\n\ndef main(test_args: Sequence[str] | None = None) -> None:\n    \"\"\"main cli function\"\"\"\n    pass\n```\n--- File: src/ujson5/err_msg.py ---\n```python\n\"\"\"Error messages for lexer and parser\"\"\"\n\nclass NumberDecoderErr:\n    \"\"\"Errors related to number lexer\"\"\"\n\n    @staticmethod\n    def unexpected_char_in_number(char: str) -> str:\n        pass\n\n    @staticmethod\n    def leading_zero_followed_by_digit() -> str:\n        pass\n\n    @staticmethod\n    def no_number() -> str:\n        pass\n\n    @staticmethod\n    def trailing_dot() -> str:\n        pass\n\n    @staticmethod\n    def trailing_exponent() -> str:\n        pass\n\n    @staticmethod\n    def trailing_exponent_sign() -> str:\n        pass\n\n    @staticmethod\n    def no_hex_digits() -> str:\n        pass\n\n    @staticmethod\n    def invalid_constant(expected: str, actual: str) -> str:\n        pass\n\nclass StringDecoderErr:\n    \"\"\"Errors related to string lexer\"\"\"\n\n    @staticmethod\n    def string_invalid_start(char: str) -> str:\n        pass\n\n    @staticmethod\n    def unexpected_end_of_string() -> str:\n        pass\n\n    @staticmethod\n    def unexpected_escape_sequence(char: str) -> str:\n        pass\n\nclass IdentifierDecoderErr:\n    \"\"\"Errors related to identifier lexer\"\"\"\n\n    @staticmethod\n    def invalid_start(char: str) -> str:\n        pass\n\n    @staticmethod\n    def invalid_char(character: str) -> str:\n        pass\n\nclass DecoderErr:\n    \"\"\"General parse errors\"\"\"\n\n    @staticmethod\n    def unexpected_eof() -> str:\n        pass\n\n    @staticmethod\n    def empty_json5() -> str:\n        pass\n\n    @staticmethod\n    def expecting_value() -> str:\n        pass\n\n    @staticmethod\n    def unexpected_identifier() -> str:\n        pass\n\n    @staticmethod\n    def expecting_property_name(tk_type: int | None = None) -> str:\n        pass\n\n    @staticmethod\n    def expecting_property_value(tk_type: int | None = None) -> str:\n        pass\n\n    @staticmethod\n    def unexpected_punctuation(actual: str) -> str:\n        pass\n\n    @staticmethod\n    def unexpected_colon_in_array() -> str:\n        pass\n\n    @staticmethod\n    def missing_key_with_colon() -> str:\n        pass\n\n    @staticmethod\n    def missing_comma(within: Literal[\"array\", \"object\"]) -> str:\n        pass\n\n    @staticmethod\n    def missing_colon() -> str:\n        pass\n\n    @staticmethod\n    def multiple_root() -> str:\n        pass\n\n    @staticmethod\n    def bad_string_continuation() -> str:\n        pass\n\n    @staticmethod\n    def invalid_control_char() -> str:\n        pass\n\n    @staticmethod\n    def invalid_object_hook() -> str:\n        pass\n\n    @staticmethod\n    def invalid_object_pairs_hook() -> str:\n        pass\n\n    @staticmethod\n    def reserved_word(word_str: str) -> str:\n        pass\n\nclass EncoderErrors:\n    \"\"\"Encoder errors\"\"\"\n\n    @staticmethod\n    def circular_reference() -> str:\n        pass\n\n    @staticmethod\n    def float_out_of_range(obj: Any) -> str:\n        pass\n\n    @staticmethod\n    def invalid_key_type(key: Any) -> str:\n        pass\n\n    @staticmethod\n    def unable_to_encode(obj: Any) -> str:\n        pass\n\n    @staticmethod\n    def invalid_typed_dict(obj: Any) -> str:\n        pass\n```\n--- File: src/ujson5/lexer.py ---\n```python\n\"\"\"Lexer for JSON5 documents. This module provides functions to tokenize JSON5\ndocuments. The lexer is implemented as a finite state machine (FSM) with states\nand transitions. The lexer is used to tokenize JSON5 documents into tokens. The\ntokens are used by the parser to build the abstract syntax tree (AST).\n\"\"\"\n\ndef simplify_escapes(text: str) -> str:\n    \"\"\"Simplify escape sequences in a string. This function replaces line\n    continuation sequences with a newline character.\n\n    Args:\n        text: string with escape sequences\n\n    Returns:\n        str: string with escape sequences simplified\n    \"\"\"\n    pass\n\nNumberState = Literal[\n    \"NUMBER_START\",  # Initial state, waiting for a number\n    \"SIGN\",  # Read a + or - sign, waiting for number\n    \"INFINITY\",  # Read 'Infinity' (accepting)\n    \"NAN\",  # Read 'NaN' (accepting)\n    \"INT_ZERO\",  # Read integer zero (accepting)\n    \"INT_NONZERO\",  # Read non-zero integer (accepting)\n    \"DOT_NOINT\",  # Read dot without integer part, waiting for fraction\n    \"DOT_INT\",  # Read dot with integer part (accepting)\n    \"FRACTION\",  # Read fractional part of the number (accepting)\n    \"EXP_START\",  # Start of the exponent part, waiting for sign or digit\n    \"EXP_SIGN\",  # Read sign of the exponent, waiting for digit\n    \"EXP_DIGITS\",  # Read digits of the exponent (accepting)\n    \"HEX_START\",  # Start of a hexadecimal number, waiting for hex digits\n    \"HEX_DIGITS\",  # Read digits of a hexadecimal number (accepting)\n]\n\ndef _handle_unexpected_char(buffer: str, idx: int, char: str) -> None:\n    \"\"\"Handle unexpected characters in a number token.\n\n    Args:\n        buffer (str): JSON5 document\n        idx (int): current index\n        char (str): unexpected character\n\n    Raises:\n        JSON5DecodeError: if the character is unexpected\n    \"\"\"\n    pass\n\ndef tokenize_number(buffer: str, idx: int) -> TokenResult:\n    \"\"\"Tokenize a number and return the token and the updated index.\n\n    Args:\n        buffer: JSON5 document\n        idx: current index. Must point to the start of the number\n\n    Returns:\n        TokenResult: Token and updated index\n\n    Raises:\n        JSON5DecodeError: if the number is invalid\n    \"\"\"\n    pass\n\nStringState = Literal[\n    \"STRING_START\",  # Initial state, waiting for a string\n    \"DOUBLE_STRING\",\n    \"SINGLE_STRING\",\n    \"END_STRING\",  # accepting\n]\n\ndef _escape_handler(buffer: str, idx: int) -> int:\n    r\"\"\"Handle escape sequences. There are a few case to consider:\n    - Line continuation: `\\\\` followed by a newline character\n    - Single character escape sequence: `\\\\` followed by a character in\n      consts.ESCAPE_SEQUENCE\n    - Unicode escape sequence: `\\\\u` followed by 4 hexadecimal digits\n    - Hexadecimal escape sequence: `\\\\x` followed by 2 hexadecimal digits\n\n    Args:\n        buffer: JSON5 document\n        idx: current index. Must point to the escape character\n\n    Returns:\n        int: updated index\n\n    Raises:\n        JSON5DecodeError: if the escape sequence is invalid\n    \"\"\"\n    pass\n\ndef tokenize_string(buffer: str, idx: int) -> TokenResult:\n    \"\"\"Tokenize a string and return the token and the updated index.\n\n    Args:\n        buffer: JSON5 document\n        idx: current index. Must point to the opening quote\n\n    Returns:\n        TokenResult: Token and updated index\n\n    Raises:\n        JSON5DecodeError: if the string is invalid\n    \"\"\"\n    pass\n\ndef validate_identifier_start(buffer: str, idx: int) -> int:\n    \"\"\"Validate the start of an identifier. An identifier must start with a\n    letter, underscore or dollar sign. It can also start with a unicode escape\n    sequence.\n\n    Args:\n        buffer: JSON5 document\n        idx: current index. Must point to the start of the identifier\n\n    Returns:\n        int: updated index\n\n    Raises:\n        JSON5DecodeError: if the identifier is invalid\n    \"\"\"\n    pass\n\ndef tokenize_identifier(buffer: str, idx: int) -> TokenResult:\n    \"\"\"Tokenize an identifier and return the token and the updated index.\n\n    Args:\n        buffer: JSON5 document\n        idx: current index. Must point to the start of the identifier\n\n    Returns:\n        TokenResult: Token and updated index\n\n    Raises:\n        JSON5DecodeError: if the identifier is invalid\n    \"\"\"\n    pass\n\ndef validate_comment(buffer: str, idx: int) -> int:\n    \"\"\"Validate a comment. An inline comment starts with `//` and ends with a\n    newline character. A block comment starts with `/*` and ends with `*/`.\n\n    Args:\n        buffer: JSON5 document\n        idx: current index. Must point to the start of the comment\n\n    Returns:\n        int: updated index\n\n    Raises:\n        JSON5DecodeError: if the comment is invalid\n    \"\"\"\n    pass\n\ndef tokenize(buffer: str) -> list[Token]:\n    \"\"\"Tokenize a JSON5 document.\n\n    Args:\n        buffer: JSON5 document\n\n    Returns:\n        list[Token]: List of tokens\n\n    Raises:\n        JSON5DecodeError: if the document is invalid\n    \"\"\"\n    pass\n```\n--- File: src/ujson5/decoder.py ---\n```python\n\"\"\"Implementation of the JSON5 decoder.\"\"\"\n\nObjectHookArg = dict[str, JsonValue]\n\"\"\"Type hint for the argument of the `object_hook` function.\"\"\"\nObjectHook = Callable[[ObjectHookArg], Any]\n\"\"\"Type hint for the `object_hook` function signature.\"\"\"\nObjectPairsHookArg = list[tuple[str, JsonValue]]\n\"\"\"Type hint for the argument of the `object_pairs_hook` function.\"\"\"\nObjectPairsHook = Callable[[ObjectPairsHookArg], Any]\n\"\"\"Type hint for the `object_pairs_hook` function signature.\"\"\"\n\nclass Json5Decoder:\n    r\"\"\"JSON5 decoder\n\n    Performs the following translations in decoding by default:\n\n    | JSON          | Python            |\n    |---------------|-------------------|\n    | object        | dict              |\n    | array         | list              |\n    | string        | str               |\n    | number (int)  | int               |\n    | number (real) | float             |\n    | true          | True              |\n    | false         | False             |\n    | null          | None              |\n\n    It also understands `NaN`, `Infinity`, and `-Infinity` as\n    their corresponding `float` values, which is outside the JSON spec.\n\n    Example:\n    import ujson5\n    json5_str = '{\"key\": \"value\"}'\n    obj = ujson5.Json5Decoder().decode(json5_str)\n    # obj == {'key': 'value'}\n\n    Args:\n        parse_float: if specified, will be called with the string of every JSON float to be\n            decoded. By default this is equivalent to float(num_str). This can be used to use\n            another datatype or parser for JSON floats (e.g. decimal.Decimal).\n        parse_int: if specified, will be called with the string of every JSON int to be\n            decoded. By default this is equivalent to int(num_str). This can be used to\n            use another datatype or parser for JSON integers (e.g. float).\n        parse_constant: if specified, will be called with one of the following strings:\n            -Infinity, Infinity, NaN. This can be used to raise an exception if invalid\n            JSON numbers are encountered.\n        strict: control characters will be allowed inside strings if `strict` is False.\n            Control characters in this context are those with character codes in the 0-31\n            range, including `'\\\\t'` (tab), `'\\\\n'`, `'\\\\r'` and `'\\\\0'`.\n        allow_reserved_words: if `True`, reserved words can be used as identifiers. Reserved\n            words are defined here https://262.ecma-international.org/5.1/#sec-7.6.1.\n            Default is `True`.\n        object_hook: an optional function that will be called with the result of any object\n            literal decode (a `dict`). The return value of `object_hook` will be used instead\n            of the `dict`. This feature can be used to implement custom decoders\n            (e.g. JSON-RPC class hinting).\n        object_pairs_hook: if specified will be called with the result of every JSON object\n            decoded with an ordered list of pairs.  The return value of `object_pairs_hook`\n            will be used instead of the `dict`. This feature can be used to implement\n            custom decoders. If `object_hook` is also defined, the `object_pairs_hook`\n            takes priority.\n\n    Raises:\n        JSON5DecodeError: If the JSON5 string is invalid.\n    \"\"\"\n    def __init__(\n        self,\n        *,\n        parse_float: Callable[[str], Any] | None = None,\n        parse_int: Callable[[str], Any] | None = None,\n        parse_constant: Callable[[str], Any] | None = None,\n        strict: bool = True,\n        allow_reserved_words: bool = True,\n        object_hook: ObjectHook | None = None,\n        object_pairs_hook: ObjectPairsHook | None = None,\n    ) -> None:\n        pass\n\n    def decode(self, json5_str: str) -> Any:\n        \"\"\"Deserialize a JSON5 string to a Python object.\n\n        Args:\n            json5_str: The JSON5 string to be deserialized.\n\n        Returns:\n            The Python object represented by the JSON5 string.\n\n        Raises:\n            JSON5DecodeError: If the JSON5 string is invalid.\n        \"\"\"\n        pass\n\n    def raw_decode(self, json5_str: str) -> tuple[Any, int]:\n        \"\"\"Deserialize a JSON5 string to a Python object and return the index of the last\n        character parsed.\n\n        Args:\n            json5_str: The JSON5 string to be deserialized.\n\n        Returns:\n            A tuple of the Python object represented by the JSON5 string and the index\n                of the last character parsed.\n\n        Raises:\n            JSON5DecodeError: If the JSON5 string is invalid.\n        \"\"\"\n        pass\n\n    def _parse_json5(\n        self, json5_str: str, tokens: list[Token]\n    ) -> JsonValue | JsonValuePairs:\n        \"\"\"Parse a JSON5 string with tokens.\"\"\"\n        pass\n\n    def _parse_number(self, num_str: str) -> int | float:\n        \"\"\"Parse a number.\"\"\"\n        pass\n\n    def _parse_string(self, str_str: str, json5_str: str, str_start_idx: int) -> str:\n        pass\n\n    def _parse_identifier(self, id_str: str) -> str:\n        pass\n\ndef loads(\n    json5_str: str,\n    *,\n    cls: type[Json5Decoder] | None = None,\n    parse_float: Callable[[str], Any] | None = None,\n    parse_int: Callable[[str], Any] | None = None,\n    parse_constant: Callable[[str], Any] | None = None,\n    strict: bool = True,\n    allow_reserved_words: bool = True,\n    object_hook: ObjectHook | None = None,\n    object_pairs_hook: ObjectPairsHook | None = None,\n) -> Any:\n    r\"\"\"Deserialize `json5_str` (a `str`, `bytes` or `bytearray` instance\n    containing a JSON document) to a Python object.\n\n    Example:\n    import ujson5\n    json5_str = '{\"key\": \"value\"}'\n    obj = ujson5.loads(json5_str)\n    # obj == {'key': 'value'}\n\n    All arguments except `json5_str` are keyword-only.\n\n    Args:\n        json5_str: The JSON5 string to be deserialized.\n        cls: If specified, must be a [`Json5Decoder`][ujson5.Json5Decoder] subclass. The `cls`\n            will be used to instantiate the decoder. If `cls` is not specified, the default\n            `Json5Decoder` will be used.\n        parse_float: if specified, will be called with the string of every JSON float to be\n            decoded. By default this is equivalent to float(num_str). This can be used to use\n            another datatype or parser for JSON floats (e.g. decimal.Decimal).\n        parse_int: if specified, will be called with the string of every JSON int to be\n            decoded. By default this is equivalent to int(num_str). This can be used to\n            use another datatype or parser for JSON integers (e.g. float).\n        parse_constant: if specified, will be called with one of the following strings:\n            '-Infinity', 'Infinity', 'NaN'. This can be used to raise an exception if invalid\n            JSON numbers are encountered.\n        strict: control characters will be allowed inside strings if `strict` is False.\n            Control characters in this context are those with character codes in the 0-31\n            range, including `'\\\\t'` (tab), `'\\\\n'`, `'\\\\r'` and `'\\\\0'`.\n        allow_reserved_words: if `True`, reserved words can be used as identifiers. Reserved\n            words are defined here https://262.ecma-international.org/5.1/#sec-7.6.1.\n            Default is `True`.\n        object_hook: an optional function that will be called with the result of any object\n            literal decode (a `dict`). The return value of `object_hook` will be used instead\n            of the `dict`. This feature can be used to implement custom decoders\n            (e.g. JSON-RPC class hinting).\n        object_pairs_hook: if specified will be called with the result of every JSON object\n            decoded with an ordered list of pairs.  The return value of `object_pairs_hook`\n            will be used instead of the `dict`. This feature can be used to implement\n            custom decoders. If `object_hook` is also defined, the `object_pairs_hook`\n            takes priority.\n    \"\"\"\n    pass\n\ndef load(\n    input_file: TextIO,\n    *,\n    cls: type[Json5Decoder] | None = None,\n    parse_float: Callable[[str], Any] | None = None,\n    parse_int: Callable[[str], Any] | None = None,\n    parse_constant: Callable[[str], Any] | None = None,\n    strict: bool = True,\n    allow_reserved_words: bool = True,\n    object_hook: ObjectHook | None = None,\n    object_pairs_hook: ObjectPairsHook | None = None,\n) -> Any:\n    r\"\"\"Deserialize `fp` (a `.read()`-supporting file-like object containing\n    a JSON document) to a Python object.\n\n    Example:\n    import ujson5\n    with open('file.json5', 'r') as f:\n        obj = ujson5.load(f)\n\n    All arguments except `file` are keyword-only.\n\n    Args:\n        file: A file-like object containing a JSON document.\n        cls: If specified, must be a [`Json5Decoder`][ujson5.Json5Decoder] subclass. The `cls`\n            will be used to instantiate the decoder. If `cls` is not specified, the default\n            `Json5Decoder` will be used.\n        parse_float: if specified, will be called with the string of every JSON float to be\n            decoded. By default this is equivalent to float(num_str). This can be used to use\n            another datatype or parser for JSON floats (e.g. decimal.Decimal).\n        parse_int: if specified, will be called with the string of every JSON int to be\n            decoded. By default this is equivalent to int(num_str). This can be used to\n            use another datatype or parser for JSON integers (e.g. float).\n        parse_constant: if specified, will be called with one of the following strings:\n            -Infinity, Infinity, NaN. This can be used to raise an exception if invalid\n            JSON numbers are encountered.\n        strict: control characters will be allowed inside strings if `strict` is False.\n            Control characters in this context are those with character codes in the 0-31\n            range, including `'\\\\t'` (tab), `'\\\\n'`, `'\\\\r'` and `'\\\\0'`.\n        allow_reserved_words: if `True`, reserved words can be used as identifiers. Reserved\n            words are defined here https://262.ecma-international.org/5.1/#sec-7.6.1.\n            Default is `True`.\n        object_hook: an optional function that will be called with the result of any object\n            literal decode (a `dict`). The return value of `object_hook` will be used instead\n            of the `dict`. This feature can be used to implement custom decoders\n            (e.g. JSON-RPC class hinting).\n        object_pairs_hook: if specified will be called with the result of every JSON object\n            decoded with an ordered list of pairs.  The return value of `object_pairs_hook`\n            will be used instead of the `dict`. This feature can be used to implement\n            custom decoders. If `object_hook` is also defined, the `object_pairs_hook`\n            takes priority.\n    \"\"\"\n    pass\n```\n--- File: src/ujson5/encoder.py ---\n```python\n\"\"\"Implements the JSON5Encoder class and the dumps and dump functions.\"\"\"\n\nSerializable = dict | list | tuple | int | float | str | None | bool\n\"\"\"Python objects that can be serialized to JSON5\"\"\"\nDefaultInterface = (\n    Callable[[Any], dict]\n    | Callable[[Any], list]\n    | Callable[[Any], tuple]\n    | Callable[[Any], int]\n    | Callable[[Any], float]\n    | Callable[[Any], str]\n    | Callable[[Any], None]\n    | Callable[[Any], bool]\n    | Callable[[Any], Serializable]\n)\n\"\"\"A callable that takes in an object that is not\nserializable and returns a serializable object\"\"\"\n\nclass EntryComments(TypedDict):\n    \"\"\"Comments related to a TypedDict entry\"\"\"\n\n    block_comments: list[str]\n    inline_comment: str\n\nCommentsCache = dict[str, EntryComments]\n\ndef extend_key_path(base_path: str, key: str) -> str:\n    \"\"\"Generate a unique name for each key in a composite dictionary by concatenating the\n    base path and the key\n\n    Args:\n        base_path: The base path\n        key: The key to be added to the base path\n\n    Returns:\n        str: The extended key path\n    \"\"\"\n    pass\n\ndef get_comments(typed_dict_cls: Any) -> CommentsCache:\n    \"\"\"Extract comments from a TypedDict class\n\n    Warning:\n        Comments extraction is currently only fully supported on Python 3.12+. On older\n        versions, the function will still work but will not extract all comments from the\n        parent TypedDicts.\n\n    Args:\n        typed_dict_cls: The TypedDict class\n\n    Returns:\n        CommentsCache: A dictionary containing comments related to each TypedDict entry\n    \"\"\"\n    pass\n\nKeyQuotation = Literal[\"single\", \"double\", \"none\"]\n\"\"\"The quotation style to be used for keys in a json5 object.\"\"\"\n\nclass JSON5Encoder:\n    \"\"\"JSON5 encoder class. This encoder is used to serialize Python objects to JSON5\n    strings. This class mirrors the standard library's JSONEncoder class, with the\n    addition of a few extra options and features. This class will transform common data\n    structures according to this table:\n\n    | Python            | JSON          |\n    |-------------------|---------------|\n    | dict              | object        |\n    | list, tuple       | array         |\n    | str               | string        |\n    | int, float        | number        |\n    | True              | true          |\n    | False             | false         |\n    | None              | null          |\n\n    To extend the encoder, subclass this class and override the\n    [`.default()`][ujson5.JSON5Encoder.default] method, which will try to encode the\n    data structures that are not supported by default. The\n    [`.default()`][ujson5.JSON5Encoder.default] method should return a serializable object.\n    If the [`.default()`][ujson5.JSON5Encoder.default] method is not overridden, the encoder\n    will raise a JSON5EncodeError when trying to encode an unsupported object. The overridden\n    [`.default()`][ujson5.JSON5Encoder.default] method should also call the parent class's\n    [`.default()`][ujson5.JSON5Encoder.default] method to handle the default encoding.\n\n    The constructor also takes in a `default` argument, which can be used to set a default\n    function that will be called when trying to encode an unsupported object. This argument\n    will take precedence over the overridden\n    [`.default()`][ujson5.JSON5Encoder.default] method.\n\n    !!! warning\n        Comment extraction is currently only fully supported on Python 3.12+. On older\n        versions, the function will still work but will not extract all comments from the\n        parent TypedDicts.\n\n    Example:\n    import ujson5\n\n\n    class MyEncoder(ujson5.JSON5Encoder):\n        def default(self, obj):\n            if isinstance(obj, set):  # (1)!\n                return list(obj)\n            return super().default(obj)  # (2)!\n\n\n    user = {\"name\": \"John\", \"age\": \"123\", \"hobbies\": {\"tennis\", \"reading\"}}\n    print(ujson5.dumps(user, cls=MyEncoder))\n    # {\"name\": \"John\", \"age\": \"123\", \"hobbies\": [\"reading\", \"tennis\"]}\n\n    1. In this example, the encoder subclass `MyEncoder` overrides the\n    [`.default()`][ujson5.JSON5Encoder.default] method to handle the serialization of sets.\n    The method returns a list of the set elements.\n    2. It is recommended to call the parent class's [`.default()`][ujson5.JSON5Encoder.default]\n    method to handle the default encoding.\n\n    All arguments are keyword-only arguments.\n\n    Args:\n        default: A function that returns a serializable object when trying to encode an\n            unsupported object. If None, the default`.default()` method will be used.\n            Defaults to None.\n        skip_keys: If True, keys with unsupported types (anything other than str, int, float,\n            bool, or None) will be skipped. Otherwise, an exception will be raised.\n            Defaults to False.\n        ensure_ascii: If True, all non-ASCII characters will be escaped. Defaults to True.\n        check_circular: If True, circular references will be checked. This will introduce a\n            small performance hit. Defaults to True.\n        allow_nan: If True, NaN, Infinity, and -Infinity will be allowed. Otherwise, an\n            exception will be raised when trying to encode these values. Defaults to True.\n        indent: If not None, the output will be formatted with the given indent level.\n            Otherwise, the output will be compact. Defaults to None.\n        separators: A tuple containing the item separator and the key-value separator.\n            Defaults to None. If None, it will be set to (\", \", \": \") if indent is None,\n            and (\",\", \":\") if indent is not None.\n        sort_keys: If True, the keys will be sorted. Defaults to False.\n        key_quotation: The quotation style to be used for keys. Can be one of \"single\",\n            \"double\", or \"none\". If \"single\" or \"double\", the keys will be enclosed in\n            single or double quotes, respectively. If \"none\", the keys will not be enclosed\n            in quotes. Defaults to \"double\".\n        trailing_comma: If True, a trailing comma will be added to the last item in\n            a list or dictionary. If None, a trailing comma will be added if indent\n            is not None. Defaults to None.\n    \"\"\"\n    def __init__(\n        self,\n        *,\n        default: DefaultInterface | None = None,\n        skip_keys: bool = False,\n        ensure_ascii: bool = True,\n        check_circular: bool = True,\n        allow_nan: bool = True,\n        indent: int | None = None,\n        separators: tuple[str, str] | None = None,\n        sort_keys: bool = False,\n        key_quotation: KeyQuotation = \"double\",\n        trailing_comma: bool | None = None,\n    ) -> None:\n        pass\n\n    def encode(self, obj: Any, typed_dict_cls: Any | None = None) -> str:\n        \"\"\"Return a JSON5 string representation of a Python object.\n\n        Args:\n            obj: The Python object to be serialized\n            typed_dict_cls: A TypedDict class that will be used to extract comments from\n                the TypedDict entries. Defaults to None.\n\n        Returns:\n            str: The JSON5 string representation of the Python object\n\n        Raises:\n            JSON5EncodeError: If the TypedDict class is not a TypedDict subclass or if the\n                object cannot be serialized\n        \"\"\"\n        pass\n\n    def iterencode(self, obj: Any, typed_dict_cls: Any | None = None) -> Iterable[str]:\n        \"\"\"Encode the given object and yield each part of the JSON5 string representation\n\n        Args:\n            obj: The Python object to be serialized\n            typed_dict_cls: A TypedDict class that will be used to extract comments from\n                the TypedDict entries. Defaults to None.\n\n        Returns:\n            Iterable[str]: An iterable of strings representing the JSON5 serialization of the\n                Python object\n\n        Raises:\n            JSON5EncodeError: If the TypedDict class is not a TypedDict subclass or if the\n                object cannot be serialized\n        \"\"\"\n        pass\n\n    def default(self, obj: Any) -> Serializable:\n        \"\"\"Override this method in a subclass to implement custom serialization\n        for objects that are not serializable by default. This method should return\n        a serializable object. If this method is not overridden, the encoder will\n        raise a JSON5EncodeError when trying to encode an unsupported object.\n\n        Args:\n            obj: The object to be serialized that is not supported by default\n\n        Returns:\n            Serializable: A serializable object\n\n        Raises:\n            JSON5EncodeError: If the object cannot be serialized\n        \"\"\"\n        pass\n\n    def _encode_int(self, obj: int) -> str:\n        pass\n\n    def _encode_float(self, obj: float) -> str:\n        pass\n\n    def _encode_str(self, obj: str, key_str: bool = False) -> str:\n        pass\n\n    def _iterencode(self, obj: Any, indent_level: int, key_path: str) -> Iterable[str]:\n        pass\n\n    def _iterencode_list(\n        self, obj: list | tuple, indent_level: int, key_path: str\n    ) -> Iterable[str]:\n        pass\n\n    def _iterencode_dict(\n        self, obj: dict[Any, Any], indent_level: int, key_path: str\n    ) -> Iterable[str]:\n        pass\n\ndef dumps(\n    obj: Any,\n    typed_dict_cls: Any | None = None,\n    *,\n    cls: type[JSON5Encoder] | None = None,\n    default: DefaultInterface | None = None,\n    skip_keys: bool = False,\n    ensure_ascii: bool = True,\n    check_circular: bool = True,\n    allow_nan: bool = True,\n    indent: int | None = None,\n    separators: tuple[str, str] | None = None,\n    sort_keys: bool = False,\n    key_quotation: KeyQuotation = \"double\",\n    trailing_comma: bool | None = None,\n) -> str:\n    \"\"\"Serialize `obj` to a JSON5 formatted `str`.\n\n    Example:\n    import ujson5\n    user = {\"name\": \"John\", \"age\": 123, \"hobbies\": [\"tennis\", \"reading\"]}\n    print(ujson5.dumps(user))\n    # Output: '{\"name\": \"John\", \"age\": 123, \"hobbies\": [\"tennis\", \"reading\"]}'\n\n    All arguments except `obj` and `typed_dict_cls` are keyword-only arguments.\n\n    Args:\n        cls: The encoder class to be used. a custom [`JSON5Encoder`][ujson5.JSON5Encoder]\n            subclass (e.g. one that overrides the [`.default()`][ujson5.JSON5Encoder.default]\n            method to serialize additional types) can be provided. If None, the default\n            [`JSON5Encoder`][ujson5.JSON5Encoder] class will be used. Defaults to None.\n        default: A function that returns a serializable object when trying to encode an\n            unsupported object. If None, the default\n            [`.default()`][ujson5.JSON5Encoder.default] method will be used. Defaults to None.\n        skip_keys: If True, keys with unsupported types (anything other than str, int, float,\n            bool, or None) will be skipped. Otherwise, an exception will be raised.\n            Defaults to False.\n        ensure_ascii: If True, all non-ASCII characters will be escaped. Defaults to True.\n        check_circular: If True, circular references will be checked. This will introduce a\n            small performance hit. Defaults to True.\n        allow_nan: If True, NaN, Infinity, and -Infinity will be allowed. Otherwise, an\n            exception will be raised when trying to encode these values. Defaults to True.\n        indent: If not None, the output will be formatted with the given indent level.\n            Otherwise, the output will be compact. Defaults to None.\n        separators: A tuple containing the item separator and the key-value separator.\n            Defaults to None. If None, it will be set to (\", \", \": \") if indent is None,\n            and (\",\", \":\") if indent is not None.\n        sort_keys: If True, the keys will be sorted. Defaults to False.\n        key_quotation: The quotation style to be used for keys. Can be one of \"single\",\n            \"double\", or \"none\". If \"single\" or \"double\", the keys will be enclosed in\n            single or double quotes, respectively. If \"none\", the keys will not be enclosed\n            in quotes. Defaults to \"double\".\n        trailing_comma: If True, a trailing comma will be added to the last item in\n            a list or dictionary. If None, a trailing comma will be added if indent\n            is not None. Defaults to None.\n\n    Returns:\n        str: The JSON5 formatted string representation of the Python object\n\n    Raises:\n        JSON5EncodeError: If the object cannot be serialized\n    \"\"\"\n    pass\n\ndef dump(\n    obj: Any,\n    fp: TextIO,\n    typed_dict_cls: Any | None = None,\n    *,\n    skip_keys: bool = False,\n    ensure_ascii: bool = True,\n    check_circular: bool = True,\n    allow_nan: bool = True,\n    cls: type[JSON5Encoder] | None = None,\n    indent: int | None = None,\n    separators: tuple[str, str] | None = None,\n    default: DefaultInterface | None = None,\n    sort_keys: bool = False,\n    key_quotation: KeyQuotation = \"double\",\n    trailing_comma: bool | None = None,\n) -> None:\n    \"\"\"Serialize `obj` as a JSON formatted stream to `fp` (a `.write()`-supporting\n    file-like object).\n\n    Example:\n    import ujson5\n    user = {\"name\": \"John\", \"age\": 123, \"hobbies\": [\"tennis\", \"reading\"]}\n    with open(\"user.json\", \"w\") as f:\n        ujson5.dump(user, f)\n\n    Args:\n        cls: The encoder class to be used. a custom [`JSON5Encoder`][ujson5.JSON5Encoder]\n            subclass (e.g. one that overrides the [`.default()`][ujson5.JSON5Encoder.default]\n            method to serialize additional types) can be provided. If None, the default\n            [`JSON5Encoder`][ujson5.JSON5Encoder] class will be used. Defaults to None.\n        default: A function that returns a serializable object when trying to encode an\n            unsupported object. If None, the default\n            [`.default()`][ujson5.JSON5Encoder.default] method will be used. Defaults to None.\n        skip_keys: If True, keys with unsupported types (anything other than str, int, float,\n            bool, or None) will be skipped. Otherwise, an exception will be raised.\n            Defaults to False.\n        ensure_ascii: If True, all non-ASCII characters will be escaped. Defaults to True.\n        check_circular: If True, circular references will be checked. This will introduce a\n            small performance hit. Defaults to True.\n        allow_nan: If True, NaN, Infinity, and -Infinity will be allowed. Otherwise, an\n            exception will be raised when trying to encode these values. Defaults to True.\n        indent: If not None, the output will be formatted with the given indent level.\n            Otherwise, the output will be compact. Defaults to None.\n        separators: A tuple containing the item separator and the key-value separator.\n            Defaults to None. If None, it will be set to (\", \", \": \") if indent is None,\n            and (\",\", \":\") if indent is not None.\n        sort_keys: If True, the keys will be sorted. Defaults to False.\n        key_quotation: The quotation style to be used for keys. Can be one of \"single\",\n            \"double\", or \"none\". If \"single\" or \"double\", the keys will be enclosed in\n            single or double quotes, respectively. If \"none\", the keys will not be enclosed\n            in quotes. Defaults to \"double\".\n        trailing_comma: If True, a trailing comma will be added to the last item in\n            a list or dictionary. If None, a trailing comma will be added if indent\n            is not None. Defaults to None.\n\n    Returns:\n        str: The JSON5 formatted string representation of the Python object\n\n    Raises:\n        JSON5EncodeError: If the object cannot be serialized\n    \"\"\"\n    pass\n```\n--- File: release/push.py ---\n```python\n\"\"\"Automate the release draft + PR creation process.\"\"\"\n\ndef get_latest_version_from_changelog() -> str:\n    \"\"\"Get the most recently listed version from the changelog.\"\"\"\n    pass\n\ndef get_latest_release_notes_from_changelog() -> str:\n    \"\"\"Get the release notes for the latest version from the changelog.\"\"\"\n    pass\n\ndef commit_and_push_changes(rl_version: str) -> None:\n    \"\"\"Commit and push changes to a new branch.\"\"\"\n    pass\n\ndef open_pull_request(rl_version: str):\n    \"\"\"Open a pull request on GitHub.\"\"\"\n    pass\n\ndef create_version_tag(rl_version: str):\n    \"\"\"Create a version tag.\"\"\"\n    pass\n\ndef create_github_release(new_version: str, notes: str):\n    \"\"\"Create a new release on GitHub.\"\"\"\n    pass\n\ndef create_github_release_draft(rl_version: str, rl_release_notes: str):\n    \"\"\"Create a GitHub release draft.\"\"\"\n    pass\n```\n--- File: release/prepare.py ---\n```python\n\"\"\"Automate the version bump and changelog update process.\"\"\"\n\ndef get_previous_version() -> str:\n    \"\"\"Get the latest git tag from the repository.\"\"\"\n    pass\n\ndef update_version(new_version: str) -> str:\n    \"\"\"Update the version in the giving py version file.\n    Note that both the arg `new_version` and the version in the file should be in the format\n    \"X.Y.Z\" without the leading \"v\". The leading \"v\" will be added automatically.\n\n    Args:\n        new_version (str): The new version to set.\n\n    Returns:\n        str: The old version.\n    \"\"\"\n    pass\n\ndef get_notes(new_version: str) -> str:\n    \"\"\"Fetch auto-generated release notes from github.\n\n    Args:\n        new_version (str): The new version to set. Version without the leading \"v\".\n\n    Returns:\n        str: The release notes.\n    \"\"\"\n    pass\n\ndef update_changelog(old_version: str, new_version: str) -> None:\n    \"\"\"Generate release notes and prepend them to HISTORY.md.\n    Both versions should be in the format \"X.Y.Z\" without the leading \"v\".\n\n    Args:\n        old_version (str): The old version.\n        new_version (str): The new version to set.\n    \"\"\"\n    pass\n```\n--- File: release/shared.py ---\n```python\n\"\"\"This module contains shared variables and functions for the release scripts.\"\"\"\n\ndef run_command(*args: str) -> str:\n    \"\"\"Run a shell command and return the output.\"\"\"\n    pass\n```",
        "minimal_code_skeleton": "--- File: src/ujson5/__init__.py ---\n```python\n__version__: str\n```\n--- File: src/ujson5/_version.py ---\n```python\n__version__: str\n```\n--- File: src/ujson5/cli.py ---\n```python\nfrom collections.abc import Sequence\n\nERR_NO_TARGET: str = \"No target file specified.\"\nERR_TARGET_NOT_EXIST: str = \"Target is not a file or does not exist.\"\nJSON_CONVERTED: str = \"JSON5 converted to JSON\"\nDECODING_ERROR: str = \"Error found when parsing JSON5 file\"\n\ndef main(test_args: Sequence[str] | None = None) -> None:\n    \"\"\"main cli function\"\"\"\n    pass\n```\n--- File: src/ujson5/core.py ---\n```python\nfrom typing import Literal, NamedTuple\n\ndef version_info() -> str:\n    \"\"\"Return complete version information for ujson5 and its dependencies.\"\"\"\n    pass\n\nJsonValue = dict | list | int | float | str | None | bool\n\"\"\"Type hint for JSON5 values.\"\"\"\n\nclass JSON5DecodeError(ValueError):\n    \"\"\"Subclass of ValueError with the following additional properties:\n\n    msg: The unformatted error message\n    doc: The JSON document being parsed\n    pos: The start index of doc where parsing failed\n    lineno: The line corresponding to pos\n    colno: The column corresponding to pos\n\n    \"\"\"\n    def __init__(self, msg: str, doc: str, pos: int) -> None:\n        pass\n\nclass JSON5EncodeError(ValueError):\n    \"\"\"Subclass of ValueError raised when encoding fails.\"\"\"\n    pass\n\nTokenTypesKey = Literal[\n    \"IDENTIFIER\",\n    \"STRING\",\n    \"NUMBER\",\n    \"BOOLEAN\",\n    \"NULL\",\n    \"PUN_OPEN_BRACE\",\n    \"PUN_CLOSE_BRACE\",\n    \"PUN_OPEN_BRACKET\",\n    \"PUN_CLOSE_BRACKET\",\n    \"PUN_COLON\",\n    \"PUN_COMMA\",\n]\n\nTOKEN_TYPE: dict[TokenTypesKey, int] = {\n    \"IDENTIFIER\": 0,\n    \"STRING\": 1,\n    \"NUMBER\": 2,\n    \"BOOLEAN\": 3,\n    \"NULL\": 4,\n    \"PUN_OPEN_BRACE\": 5,\n    \"PUN_CLOSE_BRACE\": 6,\n    \"PUN_OPEN_BRACKET\": 7,\n    \"PUN_CLOSE_BRACKET\": 8,\n    \"PUN_COLON\": 9,\n    \"PUN_COMMA\": 10,\n}\n\nclass Token(NamedTuple):\n    \"\"\"Token representation\"\"\"\n    tk_type: int\n    value: tuple[int, int]\n\nclass TokenResult(NamedTuple):\n    \"\"\"Token result\"\"\"\n    token: Token\n    idx: int\n```\n--- File: src/ujson5/decoder.py ---\n```python\nfrom collections.abc import Callable\nfrom typing import Any, TextIO\nfrom .core import JsonValue # This import is for context, would not be in skeleton. Actual type hint: JsonValue\n# from .core import Json5Decoder # This import is for context. Actual type hint: Json5Decoder\n\nObjectHookArg = dict[str, JsonValue]\n\"\"\"Type hint for the argument of the `object_hook` function.\"\"\"\nObjectHook = Callable[[ObjectHookArg], Any]\n\"\"\"Type hint for the `object_hook` function signature.\"\"\"\nObjectPairsHookArg = list[tuple[str, JsonValue]]\n\"\"\"Type hint for the argument of the `object_pairs_hook` function.\"\"\"\nObjectPairsHook = Callable[[ObjectPairsHookArg], Any]\n\"\"\"Type hint for the `object_pairs_hook` function signature.\"\"\"\n\nclass Json5Decoder:\n    r\"\"\"JSON5 decoder\n\n    Performs the following translations in decoding by default:\n\n    | JSON          | Python            |\n    |---------------|-------------------|\n    | object        | dict              |\n    | array         | list              |\n    | string        | str               |\n    | number (int)  | int               |\n    | number (real) | float             |\n    | true          | True              |\n    | false         | False             |\n    | null          | None              |\n\n    It also understands `NaN`, `Infinity`, and `-Infinity` as\n    their corresponding `float` values, which is outside the JSON spec.\n\n    Example:\n    import ujson5\n    json5_str = '{\"key\": \"value\"}'\n    obj = ujson5.Json5Decoder().decode(json5_str)\n    # obj == {'key': 'value'}\n\n    Args:\n        parse_float: if specified, will be called with the string of every JSON float to be\n            decoded. By default this is equivalent to float(num_str). This can be used to use\n            another datatype or parser for JSON floats (e.g. decimal.Decimal).\n        parse_int: if specified, will be called with the string of every JSON int to be\n            decoded. By default this is equivalent to int(num_str). This can be used to\n            use another datatype or parser for JSON integers (e.g. float).\n        parse_constant: if specified, will be called with one of the following strings:\n            -Infinity, Infinity, NaN. This can be used to raise an exception if invalid\n            JSON numbers are encountered.\n        strict: control characters will be allowed inside strings if `strict` is False.\n            Control characters in this context are those with character codes in the 0-31\n            range, including `'\\\\t'` (tab), `'\\\\n'`, `'\\\\r'` and `'\\\\0'`.\n        allow_reserved_words: if `True`, reserved words can be used as identifiers. Reserved\n            words are defined here https://262.ecma-international.org/5.1/#sec-7.6.1.\n            Default is `True`.\n        object_hook: an optional function that will be called with the result of any object\n            literal decode (a `dict`). The return value of `object_hook` will be used instead\n            of the `dict`. This feature can be used to implement custom decoders\n            (e.g. JSON-RPC class hinting).\n        object_pairs_hook: if specified will be called with the result of every JSON object\n            decoded with an ordered list of pairs.  The return value of `object_pairs_hook`\n            will be used instead of the `dict`. This feature can be used to implement\n            custom decoders. If `object_hook` is also defined, the `object_pairs_hook`\n            takes priority.\n\n    Raises:\n        JSON5DecodeError: If the JSON5 string is invalid.\n    \"\"\"\n    def __init__(\n        self,\n        *,\n        parse_float: Callable[[str], Any] | None = None,\n        parse_int: Callable[[str], Any] | None = None,\n        parse_constant: Callable[[str], Any] | None = None,\n        strict: bool = True,\n        allow_reserved_words: bool = True,\n        object_hook: ObjectHook | None = None,\n        object_pairs_hook: ObjectPairsHook | None = None,\n    ) -> None:\n        pass\n\n    def raw_decode(self, json5_str: str) -> tuple[Any, int]:\n        \"\"\"Deserialize a JSON5 string to a Python object and return the index of the last\n        character parsed.\n\n        Args:\n            json5_str: The JSON5 string to be deserialized.\n\n        Returns:\n            A tuple of the Python object represented by the JSON5 string and the index\n                of the last character parsed.\n\n        Raises:\n            JSON5DecodeError: If the JSON5 string is invalid.\n        \"\"\"\n        pass\n\ndef loads(\n    json5_str: str,\n    *,\n    cls: type[Json5Decoder] | None = None,\n    parse_float: Callable[[str], Any] | None = None,\n    parse_int: Callable[[str], Any] | None = None,\n    parse_constant: Callable[[str], Any] | None = None,\n    strict: bool = True,\n    allow_reserved_words: bool = True,\n    object_hook: ObjectHook | None = None,\n    object_pairs_hook: ObjectPairsHook | None = None,\n) -> Any:\n    r\"\"\"Deserialize `json5_str` (a `str`, `bytes` or `bytearray` instance\n    containing a JSON document) to a Python object.\n\n    Example:\n    import ujson5\n    json5_str = '{\"key\": \"value\"}'\n    obj = ujson5.loads(json5_str)\n    # obj == {'key': 'value'}\n\n    All arguments except `json5_str` are keyword-only.\n\n    Args:\n        json5_str: The JSON5 string to be deserialized.\n        cls: If specified, must be a [`Json5Decoder`][ujson5.Json5Decoder] subclass. The `cls`\n            will be used to instantiate the decoder. If `cls` is not specified, the default\n            `Json5Decoder` will be used.\n        parse_float: if specified, will be called with the string of every JSON float to be\n            decoded. By default this is equivalent to float(num_str). This can be used to use\n            another datatype or parser for JSON floats (e.g. decimal.Decimal).\n        parse_int: if specified, will be called with the string of every JSON int to be\n            decoded. By default this is equivalent to int(num_str). This can be used to\n            use another datatype or parser for JSON integers (e.g. float).\n        parse_constant: if specified, will be called with one of the following strings:\n            '-Infinity', 'Infinity', 'NaN'. This can be used to raise an exception if invalid\n            JSON numbers are encountered.\n        strict: control characters will be allowed inside strings if `strict` is False.\n            Control characters in this context are those with character codes in the 0-31\n            range, including `'\\\\t'` (tab), `'\\\\n'`, `'\\\\r'` and `'\\\\0'`.\n        allow_reserved_words: if `True`, reserved words can be used as identifiers. Reserved\n            words are defined here https://262.ecma-international.org/5.1/#sec-7.6.1.\n            Default is `True`.\n        object_hook: an optional function that will be called with the result of any object\n            literal decode (a `dict`). The return value of `object_hook` will be used instead\n            of the `dict`. This feature can be used to implement custom decoders\n            (e.g. JSON-RPC class hinting).\n        object_pairs_hook: if specified will be called with the result of every JSON object\n            decoded with an ordered list of pairs.  The return value of `object_pairs_hook`\n            will be used instead of the `dict`. This feature can be used to implement\n            custom decoders. If `object_hook` is also defined, the `object_pairs_hook`\n            takes priority.\n    \"\"\"\n    pass\n\ndef load(\n    input_file: TextIO,\n    *,\n    cls: type[Json5Decoder] | None = None,\n    parse_float: Callable[[str], Any] | None = None,\n    parse_int: Callable[[str], Any] | None = None,\n    parse_constant: Callable[[str], Any] | None = None,\n    strict: bool = True,\n    allow_reserved_words: bool = True,\n    object_hook: ObjectHook | None = None,\n    object_pairs_hook: ObjectPairsHook | None = None,\n) -> Any:\n    r\"\"\"Deserialize `fp` (a `.read()`-supporting file-like object containing\n    a JSON document) to a Python object.\n\n    Example:\n    import ujson5\n    with open('file.json5', 'r') as f:\n        obj = ujson5.load(f)\n\n    All arguments except `file` are keyword-only.\n\n    Args:\n        file: A file-like object containing a JSON document.\n        cls: If specified, must be a [`Json5Decoder`][ujson5.Json5Decoder] subclass. The `cls`\n            will be used to instantiate the decoder. If `cls` is not specified, the default\n            `Json5Decoder` will be used.\n        parse_float: if specified, will be called with the string of every JSON float to be\n            decoded. By default this is equivalent to float(num_str). This can be used to use\n            another datatype or parser for JSON floats (e.g. decimal.Decimal).\n        parse_int: if specified, will be called with the string of every JSON int to be\n            decoded. By default this is equivalent to int(num_str). This can be used to\n            use another datatype or parser for JSON integers (e.g. float).\n        parse_constant: if specified, will be called with one of the following strings:\n            -Infinity, Infinity, NaN. This can be used to raise an exception if invalid\n            JSON numbers are encountered.\n        strict: control characters will be allowed inside strings if `strict` is False.\n            Control characters in this context are those with character codes in the 0-31\n            range, including `'\\\\t'` (tab), `'\\\\n'`, `'\\\\r'` and `'\\\\0'`.\n        allow_reserved_words: if `True`, reserved words can be used as identifiers. Reserved\n            words are defined here https://262.ecma-international.org/5.1/#sec-7.6.1.\n            Default is `True`.\n        object_hook: an optional function that will be called with the result of any object\n            literal decode (a `dict`). The return value of `object_hook` will be used instead\n            of the `dict`. This feature can be used to implement custom decoders\n            (e.g. JSON-RPC class hinting).\n        object_pairs_hook: if specified will be called with the result of every JSON object\n            decoded with an ordered list of pairs.  The return value of `object_pairs_hook`\n            will be used instead of the `dict`. This feature can be used to implement\n            custom decoders. If `object_hook` is also defined, the `object_pairs_hook`\n            takes priority.\n    \"\"\"\n    pass\n```\n--- File: src/ujson5/encoder.py ---\n```python\nfrom collections.abc import Callable, Iterable\nfrom typing import Any, Literal, TextIO\n\nSerializable = dict | list | tuple | int | float | str | None | bool\n\"\"\"Python objects that can be serialized to JSON5\"\"\"\n\nDefaultInterface = (\n    Callable[[Any], dict]\n    | Callable[[Any], list]\n    | Callable[[Any], tuple]\n    | Callable[[Any], int]\n    | Callable[[Any], float]\n    | Callable[[Any], str]\n    | Callable[[Any], None]\n    | Callable[[Any], bool]\n    | Callable[[Any], Serializable]\n)\n\"\"\"A callable that takes in an object that is not\nserializable and returns a serializable object\"\"\"\n\nKeyQuotation = Literal[\"single\", \"double\", \"none\"]\n\"\"\"The quotation style to be used for keys in a json5 object.\"\"\"\n\nclass JSON5Encoder:\n    \"\"\"JSON5 encoder class. This encoder is used to serialize Python objects to JSON5\n    strings. This class mirrors the standard library's JSONEncoder class, with the\n    addition of a few extra options and features. This class will transform common data\n    structures according to this table:\n\n    | Python            | JSON          |\n    |-------------------|---------------|\n    | dict              | object        |\n    | list, tuple       | array         |\n    | str               | string        |\n    | int, float        | number        |\n    | True              | true          |\n    | False             | false         |\n    | None              | null          |\n\n    To extend the encoder, subclass this class and override the\n    [`.default()`][ujson5.JSON5Encoder.default] method, which will try to encode the\n    data structures that are not supported by default. The\n    [`.default()`][ujson5.JSON5Encoder.default] method should return a serializable object.\n    If the [`.default()`][ujson5.JSON5Encoder.default] method is not overridden, the encoder\n    will raise a JSON5EncodeError when trying to encode an unsupported object. The overridden\n    [`.default()`][ujson5.JSON5Encoder.default] method should also call the parent class's\n    [`.default()`][ujson5.JSON5Encoder.default] method to handle the default encoding.\n\n    The constructor also takes in a `default` argument, which can be used to set a default\n    function that will be called when trying to encode an unsupported object. This argument\n    will take precedence over the overridden\n    [`.default()`][ujson5.JSON5Encoder.default] method.\n\n    !!! warning\n        Comment extraction is currently only fully supported on Python 3.12+. On older\n        versions, the function will still work but will not extract all comments from the\n        parent TypedDicts.\n\n    Example:\n    import ujson5\n\n\n    class MyEncoder(ujson5.JSON5Encoder):\n        def default(self, obj):\n            if isinstance(obj, set):  # (1)!\n                return list(obj)\n            return super().default(obj)  # (2)!\n\n\n    user = {\"name\": \"John\", \"age\": \"123\", \"hobbies\": {\"tennis\", \"reading\"}}\n    print(ujson5.dumps(user, cls=MyEncoder))\n    # {\"name\": \"John\", \"age\": \"123\", \"hobbies\": [\"reading\", \"tennis\"]}\n\n    1. In this example, the encoder subclass `MyEncoder` overrides the\n    [`.default()`][ujson5.JSON5Encoder.default] method to handle the serialization of sets.\n    The method returns a list of the set elements.\n    2. It is recommended to call the parent class's [`.default()`][ujson5.JSON5Encoder.default]\n    method to handle the default encoding.\n\n    All arguments are keyword-only arguments.\n\n    Args:\n        default: A function that returns a serializable object when trying to encode an\n            unsupported object. If None, the default`.default()` method will be used.\n            Defaults to None.\n        skip_keys: If True, keys with unsupported types (anything other than str, int, float,\n            bool, or None) will be skipped. Otherwise, an exception will be raised.\n            Defaults to False.\n        ensure_ascii: If True, all non-ASCII characters will be escaped. Defaults to True.\n        check_circular: If True, circular references will be checked. This will introduce a\n            small performance hit. Defaults to True.\n        allow_nan: If True, NaN, Infinity, and -Infinity will be allowed. Otherwise, an\n            exception will be raised when trying to encode these values. Defaults to True.\n        indent: If not None, the output will be formatted with the given indent level.\n            Otherwise, the output will be compact. Defaults to None.\n        separators: A tuple containing the item separator and the key-value separator.\n            Defaults to None. If None, it will be set to (\", \", \": \") if indent is None,\n            and (\",\", \":\") if indent is not None.\n        sort_keys: If True, the keys will be sorted. Defaults to False.\n        key_quotation: The quotation style to be used for keys. Can be one of \"single\",\n            \"double\", or \"none\". If \"single\" or \"double\", the keys will be enclosed in\n            single or double quotes, respectively. If \"none\", the keys will not be enclosed\n            in quotes. Defaults to \"double\".\n        trailing_comma: If True, a trailing comma will be added to the last item in\n            a list or dictionary. If None, a trailing comma will be added if indent\n            is not None. Defaults to None.\n    \"\"\"\n    def __init__(\n        self,\n        *,\n        default: DefaultInterface | None = None,\n        skip_keys: bool = False,\n        ensure_ascii: bool = True,\n        check_circular: bool = True,\n        allow_nan: bool = True,\n        indent: int | None = None,\n        separators: tuple[str, str] | None = None,\n        sort_keys: bool = False,\n        key_quotation: KeyQuotation = \"double\",\n        trailing_comma: bool | None = None,\n    ) -> None:\n        pass\n\n    def default(self, obj: Any) -> Serializable:\n        \"\"\"Override this method in a subclass to implement custom serialization\n        for objects that are not serializable by default. This method should return\n        a serializable object. If this method is not overridden, the encoder will\n        raise a JSON5EncodeError when trying to encode an unsupported object.\n\n        Args:\n            obj: The object to be serialized that is not supported by default\n\n        Returns:\n            Serializable: A serializable object\n\n        Raises:\n            JSON5EncodeError: If the object cannot be serialized\n        \"\"\"\n        pass\n\ndef dumps(\n    obj: Any,\n    typed_dict_cls: Any | None = None,\n    *,\n    cls: type[JSON5Encoder] | None = None,\n    default: DefaultInterface | None = None,\n    skip_keys: bool = False,\n    ensure_ascii: bool = True,\n    check_circular: bool = True,\n    allow_nan: bool = True,\n    indent: int | None = None,\n    separators: tuple[str, str] | None = None,\n    sort_keys: bool = False,\n    key_quotation: KeyQuotation = \"double\",\n    trailing_comma: bool | None = None,\n) -> str:\n    \"\"\"Serialize `obj` to a JSON5 formatted `str`.\n\n    Example:\n    import ujson5\n    user = {\"name\": \"John\", \"age\": 123, \"hobbies\": [\"tennis\", \"reading\"]}\n    print(ujson5.dumps(user))\n    # Output: '{\"name\": \"John\", \"age\": 123, \"hobbies\": [\"tennis\", \"reading\"]}'\n\n    All arguments except `obj` and `typed_dict_cls` are keyword-only arguments.\n\n    Args:\n        cls: The encoder class to be used. a custom [`JSON5Encoder`][ujson5.JSON5Encoder]\n            subclass (e.g. one that overrides the [`.default()`][ujson5.JSON5Encoder.default]\n            method to serialize additional types) can be provided. If None, the default\n            [`JSON5Encoder`][ujson5.JSON5Encoder] class will be used. Defaults to None.\n        default: A function that returns a serializable object when trying to encode an\n            unsupported object. If None, the default\n            [`.default()`][ujson5.JSON5Encoder.default] method will be used. Defaults to None.\n        skip_keys: If True, keys with unsupported types (anything other than str, int, float,\n            bool, or None) will be skipped. Otherwise, an exception will be raised.\n            Defaults to False.\n        ensure_ascii: If True, all non-ASCII characters will be escaped. Defaults to True.\n        check_circular: If True, circular references will be checked. This will introduce a\n            small performance hit. Defaults to True.\n        allow_nan: If True, NaN, Infinity, and -Infinity will be allowed. Otherwise, an\n            exception will be raised when trying to encode these values. Defaults to True.\n        indent: If not None, the output will be formatted with the given indent level.\n            Otherwise, the output will be compact. Defaults to None.\n        separators: A tuple containing the item separator and the key-value separator.\n            Defaults to None. If None, it will be set to (\", \", \": \") if indent is None,\n            and (\",\", \":\") if indent is not None.\n        sort_keys: If True, the keys will be sorted. Defaults to False.\n        key_quotation: The quotation style to be used for keys. Can be one of \"single\",\n            \"double\", or \"none\". If \"single\" or \"double\", the keys will be enclosed in\n            single or double quotes, respectively. If \"none\", the keys will not be enclosed\n            in quotes. Defaults to \"double\".\n        trailing_comma: If True, a trailing comma will be added to the last item in\n            a list or dictionary. If None, a trailing comma will be added if indent\n            is not None. Defaults to None.\n\n    Returns:\n        str: The JSON5 formatted string representation of the Python object\n\n    Raises:\n        JSON5EncodeError: If the object cannot be serialized\n    \"\"\"\n    pass\n\ndef dump(\n    obj: Any,\n    fp: TextIO,\n    typed_dict_cls: Any | None = None,\n    *,\n    skip_keys: bool = False,\n    ensure_ascii: bool = True,\n    check_circular: bool = True,\n    allow_nan: bool = True,\n    cls: type[JSON5Encoder] | None = None,\n    indent: int | None = None,\n    separators: tuple[str, str] | None = None,\n    default: DefaultInterface | None = None,\n    sort_keys: bool = False,\n    key_quotation: KeyQuotation = \"double\",\n    trailing_comma: bool | None = None,\n) -> None:\n    \"\"\"Serialize `obj` as a JSON formatted stream to `fp` (a `.write()`-supporting\n    file-like object).\n\n    Example:\n    import ujson5\n    user = {\"name\": \"John\", \"age\": 123, \"hobbies\": [\"tennis\", \"reading\"]}\n    with open(\"user.json\", \"w\") as f:\n        ujson5.dump(user, f)\n\n    Args:\n        cls: The encoder class to be used. a custom [`JSON5Encoder`][ujson5.JSON5Encoder]\n            subclass (e.g. one that overrides the [`.default()`][ujson5.JSON5Encoder.default]\n            method to serialize additional types) can be provided. If None, the default\n            [`JSON5Encoder`][ujson5.JSON5Encoder] class will be used. Defaults to None.\n        default: A function that returns a serializable object when trying to encode an\n            unsupported object. If None, the default\n            [`.default()`][ujson5.JSON5Encoder.default] method will be used. Defaults to None.\n        skip_keys: If True, keys with unsupported types (anything other than str, int, float,\n            bool, or None) will be skipped. Otherwise, an exception will be raised.\n            Defaults to False.\n        ensure_ascii: If True, all non-ASCII characters will be escaped. Defaults to True.\n        check_circular: If True, circular references will be checked. This will introduce a\n            small performance hit. Defaults to True.\n        allow_nan: If True, NaN, Infinity, and -Infinity will be allowed. Otherwise, an\n            exception will be raised when trying to encode these values. Defaults to True.\n        indent: If not None, the output will be formatted with the given indent level.\n            Otherwise, the output will be compact. Defaults to None.\n        separators: A tuple containing the item separator and the key-value separator.\n            Defaults to None. If None, it will be set to (\", \", \": \") if indent is None,\n            and (\",\", \":\") if indent is not None.\n        sort_keys: If True, the keys will be sorted. Defaults to False.\n        key_quotation: The quotation style to be used for keys. Can be one of \"single\",\n            \"double\", or \"none\". If \"single\" or \"double\", the keys will be enclosed in\n            single or double quotes, respectively. If \"none\", the keys will not be enclosed\n            in quotes. Defaults to \"double\".\n        trailing_comma: If True, a trailing comma will be added to the last item in\n            a list or dictionary. If None, a trailing comma will be added if indent\n            is not None. Defaults to None.\n\n    Returns:\n        str: The JSON5 formatted string representation of the Python object\n\n    Raises:\n        JSON5EncodeError: If the object cannot be serialized\n    \"\"\"\n    pass\n```\n--- File: src/ujson5/lexer.py ---\n```python\nfrom .core import Token, TokenResult # For context, not in skeleton\n\ndef simplify_escapes(text: str) -> str:\n    \"\"\"Simplify escape sequences in a string. This function replaces line\n    continuation sequences with a newline character.\n\n    Args:\n        text: string with escape sequences\n\n    Returns:\n        str: string with escape sequences simplified\n    \"\"\"\n    pass\n\ndef tokenize_number(buffer: str, idx: int) -> TokenResult:\n    \"\"\"Tokenize a number and return the token and the updated index.\n\n    Args:\n        buffer: JSON5 document\n        idx: current index. Must point to the start of the number\n\n    Returns:\n        TokenResult: Token and updated index\n\n    Raises:\n        JSON5DecodeError: if the number is invalid\n    \"\"\"\n    pass\n\ndef tokenize_string(buffer: str, idx: int) -> TokenResult:\n    \"\"\"Tokenize a string and return the token and the updated index.\n\n    Args:\n        buffer: JSON5 document\n        idx: current index. Must point to the opening quote\n\n    Returns:\n        TokenResult: Token and updated index\n\n    Raises:\n        JSON5DecodeError: if the string is invalid\n    \"\"\"\n    pass\n\ndef tokenize_identifier(buffer: str, idx: int) -> TokenResult:\n    \"\"\"Tokenize an identifier and return the token and the updated index.\n\n    Args:\n        buffer: JSON5 document\n        idx: current index. Must point to the start of the identifier\n\n    Returns:\n        TokenResult: Token and updated index\n\n    Raises:\n        JSON5DecodeError: if the identifier is invalid\n    \"\"\"\n    pass\n\ndef validate_comment(buffer: str, idx: int) -> int:\n    \"\"\"Validate a comment. An inline comment starts with `//` and ends with a\n    newline character. A block comment starts with `/*` and ends with `*/`.\n\n    Args:\n        buffer: JSON5 document\n        idx: current index. Must point to the start of the comment\n\n    Returns:\n        int: updated index\n\n    Raises:\n        JSON5DecodeError: if the comment is invalid\n    \"\"\"\n    pass\n\ndef tokenize(buffer: str) -> list[Token]:\n    \"\"\"Tokenize a JSON5 document.\n\n    Args:\n        buffer: JSON5 document\n\n    Returns:\n        list[Token]: List of tokens\n\n    Raises:\n        JSON5DecodeError: if the document is invalid\n    \"\"\"\n    pass\n```",
        "minimal_test_cases": [
            {
                "test_id": "tests/test_cli.py::test_cli_info[--info]",
                "covers": [
                    "ujson5.version_info - display version and OS info via cli",
                    "ujson5.cli.main - info option (-i)"
                ]
            },
            {
                "test_id": "tests/test_json5_examples.py::test_valid_examples[path0]",
                "covers": [
                    "ujson5.load - happy path, loading valid JSON5 from file"
                ]
            },
            {
                "test_id": "tests/test_json5_examples.py::test_invalid_examples[path0]",
                "covers": [
                    "ujson5.JSON5DecodeError - raised on invalid input for ujson5.load",
                    "ujson5.load - error handling for invalid JSON5 file"
                ]
            },
            {
                "test_id": "tests/test_unit_tests/test_decoder.py::test_basic_loads[null-None]",
                "covers": [
                    "ujson5.loads - happy path, basic type (null) from string"
                ]
            },
            {
                "test_id": "tests/test_unit_tests/test_decoder.py::test_custom_decoder",
                "covers": [
                    "ujson5.loads - with custom decoder (cls option)",
                    "ujson5.Json5Decoder.__init__ - instantiation for custom decoder via loads' cls argument",
                    "ujson5.Json5Decoder.decode - used by custom decoder via loads"
                ]
            },
            {
                "test_id": "tests/test_unit_tests/test_decoder.py::test_basic_loads_raw[null-None]",
                "covers": [
                    "ujson5.Json5Decoder.raw_decode - happy path, basic type (null)",
                    "ujson5.Json5Decoder.__init__ - direct instantiation for raw_decode"
                ]
            },
            {
                "test_id": "tests/test_unit_tests/test_decoder.py::test_object_hook[3-<lambda>-3]",
                "covers": [
                    "ujson5.loads - object_hook option for custom object transformation"
                ]
            },
            {
                "test_id": "tests/test_unit_tests/test_decoder.py::test_strict_mode[\"\\\\t\"]",
                "covers": [
                    "ujson5.loads - strict=True option disallowing specific characters",
                    "ujson5.JSON5DecodeError - raised by loads in strict mode"
                ]
            },
            {
                "test_id": "tests/test_unit_tests/test_decoder.py::test_invalid_loads[null 1]",
                "covers": [
                    "ujson5.loads - error handling for general invalid JSON5 string",
                    "ujson5.JSON5DecodeError - raised on general invalid input for loads"
                ]
            },
            {
                "test_id": "tests/test_unit_tests/test_encoder.py::test_valid_examples[string-\"string\"]",
                "covers": [
                    "ujson5.dumps - happy path, basic type (string)",
                    "ujson5.JSON5Encoder.__init__ - default instantiation by dumps",
                    "ujson5.JSON5Encoder.encode - used by dumps",
                    "ujson5.JSON5Encoder.iterencode - used by encode"
                ]
            },
            {
                "test_id": "tests/test_unit_tests/test_encoder.py::test_invalid_examples[py_obj0]",
                "covers": [
                    "ujson5.JSON5EncodeError - raised on unserializable type for ujson5.dumps",
                    "ujson5.dumps - error handling for unserializable type"
                ]
            },
            {
                "test_id": "tests/test_unit_tests/test_encoder.py::test_circular_ref",
                "covers": [
                    "ujson5.dumps - error handling for circular reference (check_circular=True default)",
                    "ujson5.JSON5EncodeError - raised on circular reference in dumps"
                ]
            },
            {
                "test_id": "tests/test_unit_tests/test_encoder.py::test_default_set",
                "covers": [
                    "ujson5.dumps - with custom default function for non-serializable type (set)",
                    "ujson5.JSON5Encoder.default - usage with default callable in dumps"
                ]
            },
            {
                "test_id": "tests/test_json5_examples.py::test_dump_load_from_examples[path0]",
                "covers": [
                    "ujson5.dump - happy path, round trip with load, with indent and ensure_ascii options"
                ]
            },
            {
                "test_id": "tests/test_unit_tests/test_encoder.py::test_indent[py_obj0-{...}]",
                "covers": [
                    "ujson5.dumps - indent option for pretty-printing"
                ]
            },
            {
                "test_id": "tests/test_snapshots/test_snapshots.py::test_alpha_with_comments",
                "covers": [
                    "ujson5.dumps - typed_dict_cls option for comments with indent"
                ]
            },
            {
                "test_id": "tests/test_unit_tests/test_encoder.py::test_quoted_key",
                "covers": [
                    "ujson5.dumps - key_quotation option for different key styles"
                ]
            },
            {
                "test_id": "tests/test_unit_tests/test_encoder.py::test_replace_unicode",
                "covers": [
                    "ujson5.dumps - ensure_ascii=False option for preserving unicode characters"
                ]
            },
            {
                "test_id": "tests/test_cli.py::test_cli_version[--version]",
                "covers": [
                    "ujson5.cli.main - version option (-v, --version)"
                ]
            },
            {
                "test_id": "tests/test_cli.py::test_cli_stdout_correct",
                "covers": [
                    "ujson5.cli.main - happy path, file input to stdout conversion"
                ]
            },
            {
                "test_id": "tests/test_cli.py::test_cli_stdin",
                "covers": [
                    "ujson5.cli.main - happy path, stdin input processing with formatting options"
                ]
            },
            {
                "test_id": "tests/test_cli.py::test_cli_output",
                "covers": [
                    "ujson5.cli.main - happy path, file input to file output"
                ]
            }
        ],
        "commit_sha": "53d63f7f674dbfcdf7e700d89c85d7c399602e71",
        "full_code_skeleton_structured": [
            {
                "file_path": "src/ujson5/core.py",
                "code": "\"\"\"Core JSON5 classes and exceptions.\"\"\"\n\ndef version_info() -> str:\n    \"\"\"Return complete version information for ujson5 and its dependencies.\"\"\"\n    pass\n\nJsonValue = dict | list | int | float | str | None | bool\n\"\"\"Type hint for JSON5 values.\"\"\"\nJsonValuePairs = list[tuple[str, JsonValue]]\n\nclass JSON5DecodeError(ValueError):\n    \"\"\"Subclass of ValueError with the following additional properties:\n\n    msg: The unformatted error message\n    doc: The JSON document being parsed\n    pos: The start index of doc where parsing failed\n    lineno: The line corresponding to pos\n    colno: The column corresponding to pos\n\n    \"\"\"\n    def __init__(self, msg: str, doc: str, pos: int) -> None:\n        pass\n\n    def __reduce__(self) -> tuple:  # pragma: no cover\n        pass\n\n    def __str__(self) -> str:  # pragma: no cover\n        pass\n\nclass JSON5EncodeError(ValueError):\n    \"\"\"Subclass of ValueError raised when encoding fails.\"\"\"\n    pass\n\nTokenTypesKey = Literal[\n    \"IDENTIFIER\",\n    \"STRING\",\n    \"NUMBER\",\n    \"BOOLEAN\",\n    \"NULL\",\n    \"PUN_OPEN_BRACE\",\n    \"PUN_CLOSE_BRACE\",\n    \"PUN_OPEN_BRACKET\",\n    \"PUN_CLOSE_BRACKET\",\n    \"PUN_COLON\",\n    \"PUN_COMMA\",\n]\n\nclass Token(NamedTuple):\n    \"\"\"Token representation\"\"\"\n\n    tk_type: int\n    # start and end index of the token in the document\n    value: tuple[int, int]\n\nclass TokenResult(NamedTuple):\n    \"\"\"Token result\"\"\"\n\n    token: Token\n    idx: int\n"
            },
            {
                "file_path": "src/ujson5/cli.py",
                "code": "\"\"\"CLI supports\"\"\"\n\ndef main(test_args: Sequence[str] | None = None) -> None:\n    \"\"\"main cli function\"\"\"\n    pass\n"
            },
            {
                "file_path": "src/ujson5/err_msg.py",
                "code": "\"\"\"Error messages for lexer and parser\"\"\"\n\nclass NumberDecoderErr:\n    \"\"\"Errors related to number lexer\"\"\"\n\n    @staticmethod\n    def unexpected_char_in_number(char: str) -> str:\n        pass\n\n    @staticmethod\n    def leading_zero_followed_by_digit() -> str:\n        pass\n\n    @staticmethod\n    def no_number() -> str:\n        pass\n\n    @staticmethod\n    def trailing_dot() -> str:\n        pass\n\n    @staticmethod\n    def trailing_exponent() -> str:\n        pass\n\n    @staticmethod\n    def trailing_exponent_sign() -> str:\n        pass\n\n    @staticmethod\n    def no_hex_digits() -> str:\n        pass\n\n    @staticmethod\n    def invalid_constant(expected: str, actual: str) -> str:\n        pass\n\nclass StringDecoderErr:\n    \"\"\"Errors related to string lexer\"\"\"\n\n    @staticmethod\n    def string_invalid_start(char: str) -> str:\n        pass\n\n    @staticmethod\n    def unexpected_end_of_string() -> str:\n        pass\n\n    @staticmethod\n    def unexpected_escape_sequence(char: str) -> str:\n        pass\n\nclass IdentifierDecoderErr:\n    \"\"\"Errors related to identifier lexer\"\"\"\n\n    @staticmethod\n    def invalid_start(char: str) -> str:\n        pass\n\n    @staticmethod\n    def invalid_char(character: str) -> str:\n        pass\n\nclass DecoderErr:\n    \"\"\"General parse errors\"\"\"\n\n    @staticmethod\n    def unexpected_eof() -> str:\n        pass\n\n    @staticmethod\n    def empty_json5() -> str:\n        pass\n\n    @staticmethod\n    def expecting_value() -> str:\n        pass\n\n    @staticmethod\n    def unexpected_identifier() -> str:\n        pass\n\n    @staticmethod\n    def expecting_property_name(tk_type: int | None = None) -> str:\n        pass\n\n    @staticmethod\n    def expecting_property_value(tk_type: int | None = None) -> str:\n        pass\n\n    @staticmethod\n    def unexpected_punctuation(actual: str) -> str:\n        pass\n\n    @staticmethod\n    def unexpected_colon_in_array() -> str:\n        pass\n\n    @staticmethod\n    def missing_key_with_colon() -> str:\n        pass\n\n    @staticmethod\n    def missing_comma(within: Literal[\"array\", \"object\"]) -> str:\n        pass\n\n    @staticmethod\n    def missing_colon() -> str:\n        pass\n\n    @staticmethod\n    def multiple_root() -> str:\n        pass\n\n    @staticmethod\n    def bad_string_continuation() -> str:\n        pass\n\n    @staticmethod\n    def invalid_control_char() -> str:\n        pass\n\n    @staticmethod\n    def invalid_object_hook() -> str:\n        pass\n\n    @staticmethod\n    def invalid_object_pairs_hook() -> str:\n        pass\n\n    @staticmethod\n    def reserved_word(word_str: str) -> str:\n        pass\n\nclass EncoderErrors:\n    \"\"\"Encoder errors\"\"\"\n\n    @staticmethod\n    def circular_reference() -> str:\n        pass\n\n    @staticmethod\n    def float_out_of_range(obj: Any) -> str:\n        pass\n\n    @staticmethod\n    def invalid_key_type(key: Any) -> str:\n        pass\n\n    @staticmethod\n    def unable_to_encode(obj: Any) -> str:\n        pass\n\n    @staticmethod\n    def invalid_typed_dict(obj: Any) -> str:\n        pass\n"
            },
            {
                "file_path": "src/ujson5/lexer.py",
                "code": "\"\"\"Lexer for JSON5 documents. This module provides functions to tokenize JSON5\ndocuments. The lexer is implemented as a finite state machine (FSM) with states\nand transitions. The lexer is used to tokenize JSON5 documents into tokens. The\ntokens are used by the parser to build the abstract syntax tree (AST).\n\"\"\"\n\ndef simplify_escapes(text: str) -> str:\n    \"\"\"Simplify escape sequences in a string. This function replaces line\n    continuation sequences with a newline character.\n\n    Args:\n        text: string with escape sequences\n\n    Returns:\n        str: string with escape sequences simplified\n    \"\"\"\n    pass\n\nNumberState = Literal[\n    \"NUMBER_START\",  # Initial state, waiting for a number\n    \"SIGN\",  # Read a + or - sign, waiting for number\n    \"INFINITY\",  # Read 'Infinity' (accepting)\n    \"NAN\",  # Read 'NaN' (accepting)\n    \"INT_ZERO\",  # Read integer zero (accepting)\n    \"INT_NONZERO\",  # Read non-zero integer (accepting)\n    \"DOT_NOINT\",  # Read dot without integer part, waiting for fraction\n    \"DOT_INT\",  # Read dot with integer part (accepting)\n    \"FRACTION\",  # Read fractional part of the number (accepting)\n    \"EXP_START\",  # Start of the exponent part, waiting for sign or digit\n    \"EXP_SIGN\",  # Read sign of the exponent, waiting for digit\n    \"EXP_DIGITS\",  # Read digits of the exponent (accepting)\n    \"HEX_START\",  # Start of a hexadecimal number, waiting for hex digits\n    \"HEX_DIGITS\",  # Read digits of a hexadecimal number (accepting)\n]\n\ndef _handle_unexpected_char(buffer: str, idx: int, char: str) -> None:\n    \"\"\"Handle unexpected characters in a number token.\n\n    Args:\n        buffer (str): JSON5 document\n        idx (int): current index\n        char (str): unexpected character\n\n    Raises:\n        JSON5DecodeError: if the character is unexpected\n    \"\"\"\n    pass\n\ndef tokenize_number(buffer: str, idx: int) -> TokenResult:\n    \"\"\"Tokenize a number and return the token and the updated index.\n\n    Args:\n        buffer: JSON5 document\n        idx: current index. Must point to the start of the number\n\n    Returns:\n        TokenResult: Token and updated index\n\n    Raises:\n        JSON5DecodeError: if the number is invalid\n    \"\"\"\n    pass\n\nStringState = Literal[\n    \"STRING_START\",  # Initial state, waiting for a string\n    \"DOUBLE_STRING\",\n    \"SINGLE_STRING\",\n    \"END_STRING\",  # accepting\n]\n\ndef _escape_handler(buffer: str, idx: int) -> int:\n    r\"\"\"Handle escape sequences. There are a few case to consider:\n    - Line continuation: `\\\\` followed by a newline character\n    - Single character escape sequence: `\\\\` followed by a character in\n      consts.ESCAPE_SEQUENCE\n    - Unicode escape sequence: `\\\\u` followed by 4 hexadecimal digits\n    - Hexadecimal escape sequence: `\\\\x` followed by 2 hexadecimal digits\n\n    Args:\n        buffer: JSON5 document\n        idx: current index. Must point to the escape character\n\n    Returns:\n        int: updated index\n\n    Raises:\n        JSON5DecodeError: if the escape sequence is invalid\n    \"\"\"\n    pass\n\ndef tokenize_string(buffer: str, idx: int) -> TokenResult:\n    \"\"\"Tokenize a string and return the token and the updated index.\n\n    Args:\n        buffer: JSON5 document\n        idx: current index. Must point to the opening quote\n\n    Returns:\n        TokenResult: Token and updated index\n\n    Raises:\n        JSON5DecodeError: if the string is invalid\n    \"\"\"\n    pass\n\ndef validate_identifier_start(buffer: str, idx: int) -> int:\n    \"\"\"Validate the start of an identifier. An identifier must start with a\n    letter, underscore or dollar sign. It can also start with a unicode escape\n    sequence.\n\n    Args:\n        buffer: JSON5 document\n        idx: current index. Must point to the start of the identifier\n\n    Returns:\n        int: updated index\n\n    Raises:\n        JSON5DecodeError: if the identifier is invalid\n    \"\"\"\n    pass\n\ndef tokenize_identifier(buffer: str, idx: int) -> TokenResult:\n    \"\"\"Tokenize an identifier and return the token and the updated index.\n\n    Args:\n        buffer: JSON5 document\n        idx: current index. Must point to the start of the identifier\n\n    Returns:\n        TokenResult: Token and updated index\n\n    Raises:\n        JSON5DecodeError: if the identifier is invalid\n    \"\"\"\n    pass\n\ndef validate_comment(buffer: str, idx: int) -> int:\n    \"\"\"Validate a comment. An inline comment starts with `//` and ends with a\n    newline character. A block comment starts with `/*` and ends with `*/`.\n\n    Args:\n        buffer: JSON5 document\n        idx: current index. Must point to the start of the comment\n\n    Returns:\n        int: updated index\n\n    Raises:\n        JSON5DecodeError: if the comment is invalid\n    \"\"\"\n    pass\n\ndef tokenize(buffer: str) -> list[Token]:\n    \"\"\"Tokenize a JSON5 document.\n\n    Args:\n        buffer: JSON5 document\n\n    Returns:\n        list[Token]: List of tokens\n\n    Raises:\n        JSON5DecodeError: if the document is invalid\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "src/ujson5/decoder.py",
                "code": "\"\"\"Implementation of the JSON5 decoder.\"\"\"\n\nObjectHookArg = dict[str, JsonValue]\n\"\"\"Type hint for the argument of the `object_hook` function.\"\"\"\nObjectHook = Callable[[ObjectHookArg], Any]\n\"\"\"Type hint for the `object_hook` function signature.\"\"\"\nObjectPairsHookArg = list[tuple[str, JsonValue]]\n\"\"\"Type hint for the argument of the `object_pairs_hook` function.\"\"\"\nObjectPairsHook = Callable[[ObjectPairsHookArg], Any]\n\"\"\"Type hint for the `object_pairs_hook` function signature.\"\"\"\n\nclass Json5Decoder:\n    r\"\"\"JSON5 decoder\n\n    Performs the following translations in decoding by default:\n\n    | JSON          | Python            |\n    |---------------|-------------------|\n    | object        | dict              |\n    | array         | list              |\n    | string        | str               |\n    | number (int)  | int               |\n    | number (real) | float             |\n    | true          | True              |\n    | false         | False             |\n    | null          | None              |\n\n    It also understands `NaN`, `Infinity`, and `-Infinity` as\n    their corresponding `float` values, which is outside the JSON spec.\n\n    Example:\n    import ujson5\n    json5_str = '{\"key\": \"value\"}'\n    obj = ujson5.Json5Decoder().decode(json5_str)\n    # obj == {'key': 'value'}\n\n    Args:\n        parse_float: if specified, will be called with the string of every JSON float to be\n            decoded. By default this is equivalent to float(num_str). This can be used to use\n            another datatype or parser for JSON floats (e.g. decimal.Decimal).\n        parse_int: if specified, will be called with the string of every JSON int to be\n            decoded. By default this is equivalent to int(num_str). This can be used to\n            use another datatype or parser for JSON integers (e.g. float).\n        parse_constant: if specified, will be called with one of the following strings:\n            -Infinity, Infinity, NaN. This can be used to raise an exception if invalid\n            JSON numbers are encountered.\n        strict: control characters will be allowed inside strings if `strict` is False.\n            Control characters in this context are those with character codes in the 0-31\n            range, including `'\\\\t'` (tab), `'\\\\n'`, `'\\\\r'` and `'\\\\0'`.\n        allow_reserved_words: if `True`, reserved words can be used as identifiers. Reserved\n            words are defined here https://262.ecma-international.org/5.1/#sec-7.6.1.\n            Default is `True`.\n        object_hook: an optional function that will be called with the result of any object\n            literal decode (a `dict`). The return value of `object_hook` will be used instead\n            of the `dict`. This feature can be used to implement custom decoders\n            (e.g. JSON-RPC class hinting).\n        object_pairs_hook: if specified will be called with the result of every JSON object\n            decoded with an ordered list of pairs.  The return value of `object_pairs_hook`\n            will be used instead of the `dict`. This feature can be used to implement\n            custom decoders. If `object_hook` is also defined, the `object_pairs_hook`\n            takes priority.\n\n    Raises:\n        JSON5DecodeError: If the JSON5 string is invalid.\n    \"\"\"\n    def __init__(\n        self,\n        *,\n        parse_float: Callable[[str], Any] | None = None,\n        parse_int: Callable[[str], Any] | None = None,\n        parse_constant: Callable[[str], Any] | None = None,\n        strict: bool = True,\n        allow_reserved_words: bool = True,\n        object_hook: ObjectHook | None = None,\n        object_pairs_hook: ObjectPairsHook | None = None,\n    ) -> None:\n        pass\n\n    def decode(self, json5_str: str) -> Any:\n        \"\"\"Deserialize a JSON5 string to a Python object.\n\n        Args:\n            json5_str: The JSON5 string to be deserialized.\n\n        Returns:\n            The Python object represented by the JSON5 string.\n\n        Raises:\n            JSON5DecodeError: If the JSON5 string is invalid.\n        \"\"\"\n        pass\n\n    def raw_decode(self, json5_str: str) -> tuple[Any, int]:\n        \"\"\"Deserialize a JSON5 string to a Python object and return the index of the last\n        character parsed.\n\n        Args:\n            json5_str: The JSON5 string to be deserialized.\n\n        Returns:\n            A tuple of the Python object represented by the JSON5 string and the index\n                of the last character parsed.\n\n        Raises:\n            JSON5DecodeError: If the JSON5 string is invalid.\n        \"\"\"\n        pass\n\n    def _parse_json5(\n        self, json5_str: str, tokens: list[Token]\n    ) -> JsonValue | JsonValuePairs:\n        \"\"\"Parse a JSON5 string with tokens.\"\"\"\n        pass\n\n    def _parse_number(self, num_str: str) -> int | float:\n        \"\"\"Parse a number.\"\"\"\n        pass\n\n    def _parse_string(self, str_str: str, json5_str: str, str_start_idx: int) -> str:\n        pass\n\n    def _parse_identifier(self, id_str: str) -> str:\n        pass\n\ndef loads(\n    json5_str: str,\n    *,\n    cls: type[Json5Decoder] | None = None,\n    parse_float: Callable[[str], Any] | None = None,\n    parse_int: Callable[[str], Any] | None = None,\n    parse_constant: Callable[[str], Any] | None = None,\n    strict: bool = True,\n    allow_reserved_words: bool = True,\n    object_hook: ObjectHook | None = None,\n    object_pairs_hook: ObjectPairsHook | None = None,\n) -> Any:\n    r\"\"\"Deserialize `json5_str` (a `str`, `bytes` or `bytearray` instance\n    containing a JSON document) to a Python object.\n\n    Example:\n    import ujson5\n    json5_str = '{\"key\": \"value\"}'\n    obj = ujson5.loads(json5_str)\n    # obj == {'key': 'value'}\n\n    All arguments except `json5_str` are keyword-only.\n\n    Args:\n        json5_str: The JSON5 string to be deserialized.\n        cls: If specified, must be a [`Json5Decoder`][ujson5.Json5Decoder] subclass. The `cls`\n            will be used to instantiate the decoder. If `cls` is not specified, the default\n            `Json5Decoder` will be used.\n        parse_float: if specified, will be called with the string of every JSON float to be\n            decoded. By default this is equivalent to float(num_str). This can be used to use\n            another datatype or parser for JSON floats (e.g. decimal.Decimal).\n        parse_int: if specified, will be called with the string of every JSON int to be\n            decoded. By default this is equivalent to int(num_str). This can be used to\n            use another datatype or parser for JSON integers (e.g. float).\n        parse_constant: if specified, will be called with one of the following strings:\n            '-Infinity', 'Infinity', 'NaN'. This can be used to raise an exception if invalid\n            JSON numbers are encountered.\n        strict: control characters will be allowed inside strings if `strict` is False.\n            Control characters in this context are those with character codes in the 0-31\n            range, including `'\\\\t'` (tab), `'\\\\n'`, `'\\\\r'` and `'\\\\0'`.\n        allow_reserved_words: if `True`, reserved words can be used as identifiers. Reserved\n            words are defined here https://262.ecma-international.org/5.1/#sec-7.6.1.\n            Default is `True`.\n        object_hook: an optional function that will be called with the result of any object\n            literal decode (a `dict`). The return value of `object_hook` will be used instead\n            of the `dict`. This feature can be used to implement custom decoders\n            (e.g. JSON-RPC class hinting).\n        object_pairs_hook: if specified will be called with the result of every JSON object\n            decoded with an ordered list of pairs.  The return value of `object_pairs_hook`\n            will be used instead of the `dict`. This feature can be used to implement\n            custom decoders. If `object_hook` is also defined, the `object_pairs_hook`\n            takes priority.\n    \"\"\"\n    pass\n\ndef load(\n    input_file: TextIO,\n    *,\n    cls: type[Json5Decoder] | None = None,\n    parse_float: Callable[[str], Any] | None = None,\n    parse_int: Callable[[str], Any] | None = None,\n    parse_constant: Callable[[str], Any] | None = None,\n    strict: bool = True,\n    allow_reserved_words: bool = True,\n    object_hook: ObjectHook | None = None,\n    object_pairs_hook: ObjectPairsHook | None = None,\n) -> Any:\n    r\"\"\"Deserialize `fp` (a `.read()`-supporting file-like object containing\n    a JSON document) to a Python object.\n\n    Example:\n    import ujson5\n    with open('file.json5', 'r') as f:\n        obj = ujson5.load(f)\n\n    All arguments except `file` are keyword-only.\n\n    Args:\n        file: A file-like object containing a JSON document.\n        cls: If specified, must be a [`Json5Decoder`][ujson5.Json5Decoder] subclass. The `cls`\n            will be used to instantiate the decoder. If `cls` is not specified, the default\n            `Json5Decoder` will be used.\n        parse_float: if specified, will be called with the string of every JSON float to be\n            decoded. By default this is equivalent to float(num_str). This can be used to use\n            another datatype or parser for JSON floats (e.g. decimal.Decimal).\n        parse_int: if specified, will be called with the string of every JSON int to be\n            decoded. By default this is equivalent to int(num_str). This can be used to\n            use another datatype or parser for JSON integers (e.g. float).\n        parse_constant: if specified, will be called with one of the following strings:\n            -Infinity, Infinity, NaN. This can be used to raise an exception if invalid\n            JSON numbers are encountered.\n        strict: control characters will be allowed inside strings if `strict` is False.\n            Control characters in this context are those with character codes in the 0-31\n            range, including `'\\\\t'` (tab), `'\\\\n'`, `'\\\\r'` and `'\\\\0'`.\n        allow_reserved_words: if `True`, reserved words can be used as identifiers. Reserved\n            words are defined here https://262.ecma-international.org/5.1/#sec-7.6.1.\n            Default is `True`.\n        object_hook: an optional function that will be called with the result of any object\n            literal decode (a `dict`). The return value of `object_hook` will be used instead\n            of the `dict`. This feature can be used to implement custom decoders\n            (e.g. JSON-RPC class hinting).\n        object_pairs_hook: if specified will be called with the result of every JSON object\n            decoded with an ordered list of pairs.  The return value of `object_pairs_hook`\n            will be used instead of the `dict`. This feature can be used to implement\n            custom decoders. If `object_hook` is also defined, the `object_pairs_hook`\n            takes priority.\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "src/ujson5/encoder.py",
                "code": "\"\"\"Implements the JSON5Encoder class and the dumps and dump functions.\"\"\"\n\nSerializable = dict | list | tuple | int | float | str | None | bool\n\"\"\"Python objects that can be serialized to JSON5\"\"\"\nDefaultInterface = (\n    Callable[[Any], dict]\n    | Callable[[Any], list]\n    | Callable[[Any], tuple]\n    | Callable[[Any], int]\n    | Callable[[Any], float]\n    | Callable[[Any], str]\n    | Callable[[Any], None]\n    | Callable[[Any], bool]\n    | Callable[[Any], Serializable]\n)\n\"\"\"A callable that takes in an object that is not\nserializable and returns a serializable object\"\"\"\n\nclass EntryComments(TypedDict):\n    \"\"\"Comments related to a TypedDict entry\"\"\"\n\n    block_comments: list[str]\n    inline_comment: str\n\nCommentsCache = dict[str, EntryComments]\n\ndef extend_key_path(base_path: str, key: str) -> str:\n    \"\"\"Generate a unique name for each key in a composite dictionary by concatenating the\n    base path and the key\n\n    Args:\n        base_path: The base path\n        key: The key to be added to the base path\n\n    Returns:\n        str: The extended key path\n    \"\"\"\n    pass\n\ndef get_comments(typed_dict_cls: Any) -> CommentsCache:\n    \"\"\"Extract comments from a TypedDict class\n\n    Warning:\n        Comments extraction is currently only fully supported on Python 3.12+. On older\n        versions, the function will still work but will not extract all comments from the\n        parent TypedDicts.\n\n    Args:\n        typed_dict_cls: The TypedDict class\n\n    Returns:\n        CommentsCache: A dictionary containing comments related to each TypedDict entry\n    \"\"\"\n    pass\n\nKeyQuotation = Literal[\"single\", \"double\", \"none\"]\n\"\"\"The quotation style to be used for keys in a json5 object.\"\"\"\n\nclass JSON5Encoder:\n    \"\"\"JSON5 encoder class. This encoder is used to serialize Python objects to JSON5\n    strings. This class mirrors the standard library's JSONEncoder class, with the\n    addition of a few extra options and features. This class will transform common data\n    structures according to this table:\n\n    | Python            | JSON          |\n    |-------------------|---------------|\n    | dict              | object        |\n    | list, tuple       | array         |\n    | str               | string        |\n    | int, float        | number        |\n    | True              | true          |\n    | False             | false         |\n    | None              | null          |\n\n    To extend the encoder, subclass this class and override the\n    [`.default()`][ujson5.JSON5Encoder.default] method, which will try to encode the\n    data structures that are not supported by default. The\n    [`.default()`][ujson5.JSON5Encoder.default] method should return a serializable object.\n    If the [`.default()`][ujson5.JSON5Encoder.default] method is not overridden, the encoder\n    will raise a JSON5EncodeError when trying to encode an unsupported object. The overridden\n    [`.default()`][ujson5.JSON5Encoder.default] method should also call the parent class's\n    [`.default()`][ujson5.JSON5Encoder.default] method to handle the default encoding.\n\n    The constructor also takes in a `default` argument, which can be used to set a default\n    function that will be called when trying to encode an unsupported object. This argument\n    will take precedence over the overridden\n    [`.default()`][ujson5.JSON5Encoder.default] method.\n\n    !!! warning\n        Comment extraction is currently only fully supported on Python 3.12+. On older\n        versions, the function will still work but will not extract all comments from the\n        parent TypedDicts.\n\n    Example:\n    import ujson5\n\n\n    class MyEncoder(ujson5.JSON5Encoder):\n        def default(self, obj):\n            if isinstance(obj, set):  # (1)!\n                return list(obj)\n            return super().default(obj)  # (2)!\n\n\n    user = {\"name\": \"John\", \"age\": \"123\", \"hobbies\": {\"tennis\", \"reading\"}}\n    print(ujson5.dumps(user, cls=MyEncoder))\n    # {\"name\": \"John\", \"age\": \"123\", \"hobbies\": [\"reading\", \"tennis\"]}\n\n    1. In this example, the encoder subclass `MyEncoder` overrides the\n    [`.default()`][ujson5.JSON5Encoder.default] method to handle the serialization of sets.\n    The method returns a list of the set elements.\n    2. It is recommended to call the parent class's [`.default()`][ujson5.JSON5Encoder.default]\n    method to handle the default encoding.\n\n    All arguments are keyword-only arguments.\n\n    Args:\n        default: A function that returns a serializable object when trying to encode an\n            unsupported object. If None, the default`.default()` method will be used.\n            Defaults to None.\n        skip_keys: If True, keys with unsupported types (anything other than str, int, float,\n            bool, or None) will be skipped. Otherwise, an exception will be raised.\n            Defaults to False.\n        ensure_ascii: If True, all non-ASCII characters will be escaped. Defaults to True.\n        check_circular: If True, circular references will be checked. This will introduce a\n            small performance hit. Defaults to True.\n        allow_nan: If True, NaN, Infinity, and -Infinity will be allowed. Otherwise, an\n            exception will be raised when trying to encode these values. Defaults to True.\n        indent: If not None, the output will be formatted with the given indent level.\n            Otherwise, the output will be compact. Defaults to None.\n        separators: A tuple containing the item separator and the key-value separator.\n            Defaults to None. If None, it will be set to (\", \", \": \") if indent is None,\n            and (\",\", \":\") if indent is not None.\n        sort_keys: If True, the keys will be sorted. Defaults to False.\n        key_quotation: The quotation style to be used for keys. Can be one of \"single\",\n            \"double\", or \"none\". If \"single\" or \"double\", the keys will be enclosed in\n            single or double quotes, respectively. If \"none\", the keys will not be enclosed\n            in quotes. Defaults to \"double\".\n        trailing_comma: If True, a trailing comma will be added to the last item in\n            a list or dictionary. If None, a trailing comma will be added if indent\n            is not None. Defaults to None.\n    \"\"\"\n    def __init__(\n        self,\n        *,\n        default: DefaultInterface | None = None,\n        skip_keys: bool = False,\n        ensure_ascii: bool = True,\n        check_circular: bool = True,\n        allow_nan: bool = True,\n        indent: int | None = None,\n        separators: tuple[str, str] | None = None,\n        sort_keys: bool = False,\n        key_quotation: KeyQuotation = \"double\",\n        trailing_comma: bool | None = None,\n    ) -> None:\n        pass\n\n    def encode(self, obj: Any, typed_dict_cls: Any | None = None) -> str:\n        \"\"\"Return a JSON5 string representation of a Python object.\n\n        Args:\n            obj: The Python object to be serialized\n            typed_dict_cls: A TypedDict class that will be used to extract comments from\n                the TypedDict entries. Defaults to None.\n\n        Returns:\n            str: The JSON5 string representation of the Python object\n\n        Raises:\n            JSON5EncodeError: If the TypedDict class is not a TypedDict subclass or if the\n                object cannot be serialized\n        \"\"\"\n        pass\n\n    def iterencode(self, obj: Any, typed_dict_cls: Any | None = None) -> Iterable[str]:\n        \"\"\"Encode the given object and yield each part of the JSON5 string representation\n\n        Args:\n            obj: The Python object to be serialized\n            typed_dict_cls: A TypedDict class that will be used to extract comments from\n                the TypedDict entries. Defaults to None.\n\n        Returns:\n            Iterable[str]: An iterable of strings representing the JSON5 serialization of the\n                Python object\n\n        Raises:\n            JSON5EncodeError: If the TypedDict class is not a TypedDict subclass or if the\n                object cannot be serialized\n        \"\"\"\n        pass\n\n    def default(self, obj: Any) -> Serializable:\n        \"\"\"Override this method in a subclass to implement custom serialization\n        for objects that are not serializable by default. This method should return\n        a serializable object. If this method is not overridden, the encoder will\n        raise a JSON5EncodeError when trying to encode an unsupported object.\n\n        Args:\n            obj: The object to be serialized that is not supported by default\n\n        Returns:\n            Serializable: A serializable object\n\n        Raises:\n            JSON5EncodeError: If the object cannot be serialized\n        \"\"\"\n        pass\n\n    def _encode_int(self, obj: int) -> str:\n        pass\n\n    def _encode_float(self, obj: float) -> str:\n        pass\n\n    def _encode_str(self, obj: str, key_str: bool = False) -> str:\n        pass\n\n    def _iterencode(self, obj: Any, indent_level: int, key_path: str) -> Iterable[str]:\n        pass\n\n    def _iterencode_list(\n        self, obj: list | tuple, indent_level: int, key_path: str\n    ) -> Iterable[str]:\n        pass\n\n    def _iterencode_dict(\n        self, obj: dict[Any, Any], indent_level: int, key_path: str\n    ) -> Iterable[str]:\n        pass\n\ndef dumps(\n    obj: Any,\n    typed_dict_cls: Any | None = None,\n    *,\n    cls: type[JSON5Encoder] | None = None,\n    default: DefaultInterface | None = None,\n    skip_keys: bool = False,\n    ensure_ascii: bool = True,\n    check_circular: bool = True,\n    allow_nan: bool = True,\n    indent: int | None = None,\n    separators: tuple[str, str] | None = None,\n    sort_keys: bool = False,\n    key_quotation: KeyQuotation = \"double\",\n    trailing_comma: bool | None = None,\n) -> str:\n    \"\"\"Serialize `obj` to a JSON5 formatted `str`.\n\n    Example:\n    import ujson5\n    user = {\"name\": \"John\", \"age\": 123, \"hobbies\": [\"tennis\", \"reading\"]}\n    print(ujson5.dumps(user))\n    # Output: '{\"name\": \"John\", \"age\": 123, \"hobbies\": [\"tennis\", \"reading\"]}'\n\n    All arguments except `obj` and `typed_dict_cls` are keyword-only arguments.\n\n    Args:\n        cls: The encoder class to be used. a custom [`JSON5Encoder`][ujson5.JSON5Encoder]\n            subclass (e.g. one that overrides the [`.default()`][ujson5.JSON5Encoder.default]\n            method to serialize additional types) can be provided. If None, the default\n            [`JSON5Encoder`][ujson5.JSON5Encoder] class will be used. Defaults to None.\n        default: A function that returns a serializable object when trying to encode an\n            unsupported object. If None, the default\n            [`.default()`][ujson5.JSON5Encoder.default] method will be used. Defaults to None.\n        skip_keys: If True, keys with unsupported types (anything other than str, int, float,\n            bool, or None) will be skipped. Otherwise, an exception will be raised.\n            Defaults to False.\n        ensure_ascii: If True, all non-ASCII characters will be escaped. Defaults to True.\n        check_circular: If True, circular references will be checked. This will introduce a\n            small performance hit. Defaults to True.\n        allow_nan: If True, NaN, Infinity, and -Infinity will be allowed. Otherwise, an\n            exception will be raised when trying to encode these values. Defaults to True.\n        indent: If not None, the output will be formatted with the given indent level.\n            Otherwise, the output will be compact. Defaults to None.\n        separators: A tuple containing the item separator and the key-value separator.\n            Defaults to None. If None, it will be set to (\", \", \": \") if indent is None,\n            and (\",\", \":\") if indent is not None.\n        sort_keys: If True, the keys will be sorted. Defaults to False.\n        key_quotation: The quotation style to be used for keys. Can be one of \"single\",\n            \"double\", or \"none\". If \"single\" or \"double\", the keys will be enclosed in\n            single or double quotes, respectively. If \"none\", the keys will not be enclosed\n            in quotes. Defaults to \"double\".\n        trailing_comma: If True, a trailing comma will be added to the last item in\n            a list or dictionary. If None, a trailing comma will be added if indent\n            is not None. Defaults to None.\n\n    Returns:\n        str: The JSON5 formatted string representation of the Python object\n\n    Raises:\n        JSON5EncodeError: If the object cannot be serialized\n    \"\"\"\n    pass\n\ndef dump(\n    obj: Any,\n    fp: TextIO,\n    typed_dict_cls: Any | None = None,\n    *,\n    skip_keys: bool = False,\n    ensure_ascii: bool = True,\n    check_circular: bool = True,\n    allow_nan: bool = True,\n    cls: type[JSON5Encoder] | None = None,\n    indent: int | None = None,\n    separators: tuple[str, str] | None = None,\n    default: DefaultInterface | None = None,\n    sort_keys: bool = False,\n    key_quotation: KeyQuotation = \"double\",\n    trailing_comma: bool | None = None,\n) -> None:\n    \"\"\"Serialize `obj` as a JSON formatted stream to `fp` (a `.write()`-supporting\n    file-like object).\n\n    Example:\n    import ujson5\n    user = {\"name\": \"John\", \"age\": 123, \"hobbies\": [\"tennis\", \"reading\"]}\n    with open(\"user.json\", \"w\") as f:\n        ujson5.dump(user, f)\n\n    Args:\n        cls: The encoder class to be used. a custom [`JSON5Encoder`][ujson5.JSON5Encoder]\n            subclass (e.g. one that overrides the [`.default()`][ujson5.JSON5Encoder.default]\n            method to serialize additional types) can be provided. If None, the default\n            [`JSON5Encoder`][ujson5.JSON5Encoder] class will be used. Defaults to None.\n        default: A function that returns a serializable object when trying to encode an\n            unsupported object. If None, the default\n            [`.default()`][ujson5.JSON5Encoder.default] method will be used. Defaults to None.\n        skip_keys: If True, keys with unsupported types (anything other than str, int, float,\n            bool, or None) will be skipped. Otherwise, an exception will be raised.\n            Defaults to False.\n        ensure_ascii: If True, all non-ASCII characters will be escaped. Defaults to True.\n        check_circular: If True, circular references will be checked. This will introduce a\n            small performance hit. Defaults to True.\n        allow_nan: If True, NaN, Infinity, and -Infinity will be allowed. Otherwise, an\n            exception will be raised when trying to encode these values. Defaults to True.\n        indent: If not None, the output will be formatted with the given indent level.\n            Otherwise, the output will be compact. Defaults to None.\n        separators: A tuple containing the item separator and the key-value separator.\n            Defaults to None. If None, it will be set to (\", \", \": \") if indent is None,\n            and (\",\", \":\") if indent is not None.\n        sort_keys: If True, the keys will be sorted. Defaults to False.\n        key_quotation: The quotation style to be used for keys. Can be one of \"single\",\n            \"double\", or \"none\". If \"single\" or \"double\", the keys will be enclosed in\n            single or double quotes, respectively. If \"none\", the keys will not be enclosed\n            in quotes. Defaults to \"double\".\n        trailing_comma: If True, a trailing comma will be added to the last item in\n            a list or dictionary. If None, a trailing comma will be added if indent\n            is not None. Defaults to None.\n\n    Returns:\n        str: The JSON5 formatted string representation of the Python object\n\n    Raises:\n        JSON5EncodeError: If the object cannot be serialized\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "release/push.py",
                "code": "\"\"\"Automate the release draft + PR creation process.\"\"\"\n\ndef get_latest_version_from_changelog() -> str:\n    \"\"\"Get the most recently listed version from the changelog.\"\"\"\n    pass\n\ndef get_latest_release_notes_from_changelog() -> str:\n    \"\"\"Get the release notes for the latest version from the changelog.\"\"\"\n    pass\n\ndef commit_and_push_changes(rl_version: str) -> None:\n    \"\"\"Commit and push changes to a new branch.\"\"\"\n    pass\n\ndef open_pull_request(rl_version: str):\n    \"\"\"Open a pull request on GitHub.\"\"\"\n    pass\n\ndef create_version_tag(rl_version: str):\n    \"\"\"Create a version tag.\"\"\"\n    pass\n\ndef create_github_release(new_version: str, notes: str):\n    \"\"\"Create a new release on GitHub.\"\"\"\n    pass\n\ndef create_github_release_draft(rl_version: str, rl_release_notes: str):\n    \"\"\"Create a GitHub release draft.\"\"\"\n    pass\n"
            },
            {
                "file_path": "release/prepare.py",
                "code": "\"\"\"Automate the version bump and changelog update process.\"\"\"\n\ndef get_previous_version() -> str:\n    \"\"\"Get the latest git tag from the repository.\"\"\"\n    pass\n\ndef update_version(new_version: str) -> str:\n    \"\"\"Update the version in the giving py version file.\n    Note that both the arg `new_version` and the version in the file should be in the format\n    \"X.Y.Z\" without the leading \"v\". The leading \"v\" will be added automatically.\n\n    Args:\n        new_version (str): The new version to set.\n\n    Returns:\n        str: The old version.\n    \"\"\"\n    pass\n\ndef get_notes(new_version: str) -> str:\n    \"\"\"Fetch auto-generated release notes from github.\n\n    Args:\n        new_version (str): The new version to set. Version without the leading \"v\".\n\n    Returns:\n        str: The release notes.\n    \"\"\"\n    pass\n\ndef update_changelog(old_version: str, new_version: str) -> None:\n    \"\"\"Generate release notes and prepend them to HISTORY.md.\n    Both versions should be in the format \"X.Y.Z\" without the leading \"v\".\n\n    Args:\n        old_version (str): The old version.\n        new_version (str): The new version to set.\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "release/shared.py",
                "code": "\"\"\"This module contains shared variables and functions for the release scripts.\"\"\"\n\ndef run_command(*args: str) -> str:\n    \"\"\"Run a shell command and return the output.\"\"\"\n    pass\n"
            }
        ],
        "minimal_code_skeleton_structured": [
            {
                "file_path": "src/ujson5/__init__.py",
                "code": "__version__: str\n"
            },
            {
                "file_path": "src/ujson5/_version.py",
                "code": "__version__: str\n"
            },
            {
                "file_path": "src/ujson5/cli.py",
                "code": "from collections.abc import Sequence\n\nERR_NO_TARGET: str = \"No target file specified.\"\nERR_TARGET_NOT_EXIST: str = \"Target is not a file or does not exist.\"\nJSON_CONVERTED: str = \"JSON5 converted to JSON\"\nDECODING_ERROR: str = \"Error found when parsing JSON5 file\"\n\ndef main(test_args: Sequence[str] | None = None) -> None:\n    \"\"\"main cli function\"\"\"\n    pass\n"
            },
            {
                "file_path": "src/ujson5/core.py",
                "code": "from typing import Literal, NamedTuple\n\ndef version_info() -> str:\n    \"\"\"Return complete version information for ujson5 and its dependencies.\"\"\"\n    pass\n\nJsonValue = dict | list | int | float | str | None | bool\n\"\"\"Type hint for JSON5 values.\"\"\"\n\nclass JSON5DecodeError(ValueError):\n    \"\"\"Subclass of ValueError with the following additional properties:\n\n    msg: The unformatted error message\n    doc: The JSON document being parsed\n    pos: The start index of doc where parsing failed\n    lineno: The line corresponding to pos\n    colno: The column corresponding to pos\n\n    \"\"\"\n    def __init__(self, msg: str, doc: str, pos: int) -> None:\n        pass\n\nclass JSON5EncodeError(ValueError):\n    \"\"\"Subclass of ValueError raised when encoding fails.\"\"\"\n    pass\n\nTokenTypesKey = Literal[\n    \"IDENTIFIER\",\n    \"STRING\",\n    \"NUMBER\",\n    \"BOOLEAN\",\n    \"NULL\",\n    \"PUN_OPEN_BRACE\",\n    \"PUN_CLOSE_BRACE\",\n    \"PUN_OPEN_BRACKET\",\n    \"PUN_CLOSE_BRACKET\",\n    \"PUN_COLON\",\n    \"PUN_COMMA\",\n]\n\nTOKEN_TYPE: dict[TokenTypesKey, int] = {\n    \"IDENTIFIER\": 0,\n    \"STRING\": 1,\n    \"NUMBER\": 2,\n    \"BOOLEAN\": 3,\n    \"NULL\": 4,\n    \"PUN_OPEN_BRACE\": 5,\n    \"PUN_CLOSE_BRACE\": 6,\n    \"PUN_OPEN_BRACKET\": 7,\n    \"PUN_CLOSE_BRACKET\": 8,\n    \"PUN_COLON\": 9,\n    \"PUN_COMMA\": 10,\n}\n\nclass Token(NamedTuple):\n    \"\"\"Token representation\"\"\"\n    tk_type: int\n    value: tuple[int, int]\n\nclass TokenResult(NamedTuple):\n    \"\"\"Token result\"\"\"\n    token: Token\n    idx: int\n"
            },
            {
                "file_path": "src/ujson5/decoder.py",
                "code": "from collections.abc import Callable\nfrom typing import Any, TextIO\nfrom .core import JsonValue # This import is for context, would not be in skeleton. Actual type hint: JsonValue\n# from .core import Json5Decoder # This import is for context. Actual type hint: Json5Decoder\n\nObjectHookArg = dict[str, JsonValue]\n\"\"\"Type hint for the argument of the `object_hook` function.\"\"\"\nObjectHook = Callable[[ObjectHookArg], Any]\n\"\"\"Type hint for the `object_hook` function signature.\"\"\"\nObjectPairsHookArg = list[tuple[str, JsonValue]]\n\"\"\"Type hint for the argument of the `object_pairs_hook` function.\"\"\"\nObjectPairsHook = Callable[[ObjectPairsHookArg], Any]\n\"\"\"Type hint for the `object_pairs_hook` function signature.\"\"\"\n\nclass Json5Decoder:\n    r\"\"\"JSON5 decoder\n\n    Performs the following translations in decoding by default:\n\n    | JSON          | Python            |\n    |---------------|-------------------|\n    | object        | dict              |\n    | array         | list              |\n    | string        | str               |\n    | number (int)  | int               |\n    | number (real) | float             |\n    | true          | True              |\n    | false         | False             |\n    | null          | None              |\n\n    It also understands `NaN`, `Infinity`, and `-Infinity` as\n    their corresponding `float` values, which is outside the JSON spec.\n\n    Example:\n    import ujson5\n    json5_str = '{\"key\": \"value\"}'\n    obj = ujson5.Json5Decoder().decode(json5_str)\n    # obj == {'key': 'value'}\n\n    Args:\n        parse_float: if specified, will be called with the string of every JSON float to be\n            decoded. By default this is equivalent to float(num_str). This can be used to use\n            another datatype or parser for JSON floats (e.g. decimal.Decimal).\n        parse_int: if specified, will be called with the string of every JSON int to be\n            decoded. By default this is equivalent to int(num_str). This can be used to\n            use another datatype or parser for JSON integers (e.g. float).\n        parse_constant: if specified, will be called with one of the following strings:\n            -Infinity, Infinity, NaN. This can be used to raise an exception if invalid\n            JSON numbers are encountered.\n        strict: control characters will be allowed inside strings if `strict` is False.\n            Control characters in this context are those with character codes in the 0-31\n            range, including `'\\\\t'` (tab), `'\\\\n'`, `'\\\\r'` and `'\\\\0'`.\n        allow_reserved_words: if `True`, reserved words can be used as identifiers. Reserved\n            words are defined here https://262.ecma-international.org/5.1/#sec-7.6.1.\n            Default is `True`.\n        object_hook: an optional function that will be called with the result of any object\n            literal decode (a `dict`). The return value of `object_hook` will be used instead\n            of the `dict`. This feature can be used to implement custom decoders\n            (e.g. JSON-RPC class hinting).\n        object_pairs_hook: if specified will be called with the result of every JSON object\n            decoded with an ordered list of pairs.  The return value of `object_pairs_hook`\n            will be used instead of the `dict`. This feature can be used to implement\n            custom decoders. If `object_hook` is also defined, the `object_pairs_hook`\n            takes priority.\n\n    Raises:\n        JSON5DecodeError: If the JSON5 string is invalid.\n    \"\"\"\n    def __init__(\n        self,\n        *,\n        parse_float: Callable[[str], Any] | None = None,\n        parse_int: Callable[[str], Any] | None = None,\n        parse_constant: Callable[[str], Any] | None = None,\n        strict: bool = True,\n        allow_reserved_words: bool = True,\n        object_hook: ObjectHook | None = None,\n        object_pairs_hook: ObjectPairsHook | None = None,\n    ) -> None:\n        pass\n\n    def raw_decode(self, json5_str: str) -> tuple[Any, int]:\n        \"\"\"Deserialize a JSON5 string to a Python object and return the index of the last\n        character parsed.\n\n        Args:\n            json5_str: The JSON5 string to be deserialized.\n\n        Returns:\n            A tuple of the Python object represented by the JSON5 string and the index\n                of the last character parsed.\n\n        Raises:\n            JSON5DecodeError: If the JSON5 string is invalid.\n        \"\"\"\n        pass\n\ndef loads(\n    json5_str: str,\n    *,\n    cls: type[Json5Decoder] | None = None,\n    parse_float: Callable[[str], Any] | None = None,\n    parse_int: Callable[[str], Any] | None = None,\n    parse_constant: Callable[[str], Any] | None = None,\n    strict: bool = True,\n    allow_reserved_words: bool = True,\n    object_hook: ObjectHook | None = None,\n    object_pairs_hook: ObjectPairsHook | None = None,\n) -> Any:\n    r\"\"\"Deserialize `json5_str` (a `str`, `bytes` or `bytearray` instance\n    containing a JSON document) to a Python object.\n\n    Example:\n    import ujson5\n    json5_str = '{\"key\": \"value\"}'\n    obj = ujson5.loads(json5_str)\n    # obj == {'key': 'value'}\n\n    All arguments except `json5_str` are keyword-only.\n\n    Args:\n        json5_str: The JSON5 string to be deserialized.\n        cls: If specified, must be a [`Json5Decoder`][ujson5.Json5Decoder] subclass. The `cls`\n            will be used to instantiate the decoder. If `cls` is not specified, the default\n            `Json5Decoder` will be used.\n        parse_float: if specified, will be called with the string of every JSON float to be\n            decoded. By default this is equivalent to float(num_str). This can be used to use\n            another datatype or parser for JSON floats (e.g. decimal.Decimal).\n        parse_int: if specified, will be called with the string of every JSON int to be\n            decoded. By default this is equivalent to int(num_str). This can be used to\n            use another datatype or parser for JSON integers (e.g. float).\n        parse_constant: if specified, will be called with one of the following strings:\n            '-Infinity', 'Infinity', 'NaN'. This can be used to raise an exception if invalid\n            JSON numbers are encountered.\n        strict: control characters will be allowed inside strings if `strict` is False.\n            Control characters in this context are those with character codes in the 0-31\n            range, including `'\\\\t'` (tab), `'\\\\n'`, `'\\\\r'` and `'\\\\0'`.\n        allow_reserved_words: if `True`, reserved words can be used as identifiers. Reserved\n            words are defined here https://262.ecma-international.org/5.1/#sec-7.6.1.\n            Default is `True`.\n        object_hook: an optional function that will be called with the result of any object\n            literal decode (a `dict`). The return value of `object_hook` will be used instead\n            of the `dict`. This feature can be used to implement custom decoders\n            (e.g. JSON-RPC class hinting).\n        object_pairs_hook: if specified will be called with the result of every JSON object\n            decoded with an ordered list of pairs.  The return value of `object_pairs_hook`\n            will be used instead of the `dict`. This feature can be used to implement\n            custom decoders. If `object_hook` is also defined, the `object_pairs_hook`\n            takes priority.\n    \"\"\"\n    pass\n\ndef load(\n    input_file: TextIO,\n    *,\n    cls: type[Json5Decoder] | None = None,\n    parse_float: Callable[[str], Any] | None = None,\n    parse_int: Callable[[str], Any] | None = None,\n    parse_constant: Callable[[str], Any] | None = None,\n    strict: bool = True,\n    allow_reserved_words: bool = True,\n    object_hook: ObjectHook | None = None,\n    object_pairs_hook: ObjectPairsHook | None = None,\n) -> Any:\n    r\"\"\"Deserialize `fp` (a `.read()`-supporting file-like object containing\n    a JSON document) to a Python object.\n\n    Example:\n    import ujson5\n    with open('file.json5', 'r') as f:\n        obj = ujson5.load(f)\n\n    All arguments except `file` are keyword-only.\n\n    Args:\n        file: A file-like object containing a JSON document.\n        cls: If specified, must be a [`Json5Decoder`][ujson5.Json5Decoder] subclass. The `cls`\n            will be used to instantiate the decoder. If `cls` is not specified, the default\n            `Json5Decoder` will be used.\n        parse_float: if specified, will be called with the string of every JSON float to be\n            decoded. By default this is equivalent to float(num_str). This can be used to use\n            another datatype or parser for JSON floats (e.g. decimal.Decimal).\n        parse_int: if specified, will be called with the string of every JSON int to be\n            decoded. By default this is equivalent to int(num_str). This can be used to\n            use another datatype or parser for JSON integers (e.g. float).\n        parse_constant: if specified, will be called with one of the following strings:\n            -Infinity, Infinity, NaN. This can be used to raise an exception if invalid\n            JSON numbers are encountered.\n        strict: control characters will be allowed inside strings if `strict` is False.\n            Control characters in this context are those with character codes in the 0-31\n            range, including `'\\\\t'` (tab), `'\\\\n'`, `'\\\\r'` and `'\\\\0'`.\n        allow_reserved_words: if `True`, reserved words can be used as identifiers. Reserved\n            words are defined here https://262.ecma-international.org/5.1/#sec-7.6.1.\n            Default is `True`.\n        object_hook: an optional function that will be called with the result of any object\n            literal decode (a `dict`). The return value of `object_hook` will be used instead\n            of the `dict`. This feature can be used to implement custom decoders\n            (e.g. JSON-RPC class hinting).\n        object_pairs_hook: if specified will be called with the result of every JSON object\n            decoded with an ordered list of pairs.  The return value of `object_pairs_hook`\n            will be used instead of the `dict`. This feature can be used to implement\n            custom decoders. If `object_hook` is also defined, the `object_pairs_hook`\n            takes priority.\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "src/ujson5/encoder.py",
                "code": "from collections.abc import Callable, Iterable\nfrom typing import Any, Literal, TextIO\n\nSerializable = dict | list | tuple | int | float | str | None | bool\n\"\"\"Python objects that can be serialized to JSON5\"\"\"\n\nDefaultInterface = (\n    Callable[[Any], dict]\n    | Callable[[Any], list]\n    | Callable[[Any], tuple]\n    | Callable[[Any], int]\n    | Callable[[Any], float]\n    | Callable[[Any], str]\n    | Callable[[Any], None]\n    | Callable[[Any], bool]\n    | Callable[[Any], Serializable]\n)\n\"\"\"A callable that takes in an object that is not\nserializable and returns a serializable object\"\"\"\n\nKeyQuotation = Literal[\"single\", \"double\", \"none\"]\n\"\"\"The quotation style to be used for keys in a json5 object.\"\"\"\n\nclass JSON5Encoder:\n    \"\"\"JSON5 encoder class. This encoder is used to serialize Python objects to JSON5\n    strings. This class mirrors the standard library's JSONEncoder class, with the\n    addition of a few extra options and features. This class will transform common data\n    structures according to this table:\n\n    | Python            | JSON          |\n    |-------------------|---------------|\n    | dict              | object        |\n    | list, tuple       | array         |\n    | str               | string        |\n    | int, float        | number        |\n    | True              | true          |\n    | False             | false         |\n    | None              | null          |\n\n    To extend the encoder, subclass this class and override the\n    [`.default()`][ujson5.JSON5Encoder.default] method, which will try to encode the\n    data structures that are not supported by default. The\n    [`.default()`][ujson5.JSON5Encoder.default] method should return a serializable object.\n    If the [`.default()`][ujson5.JSON5Encoder.default] method is not overridden, the encoder\n    will raise a JSON5EncodeError when trying to encode an unsupported object. The overridden\n    [`.default()`][ujson5.JSON5Encoder.default] method should also call the parent class's\n    [`.default()`][ujson5.JSON5Encoder.default] method to handle the default encoding.\n\n    The constructor also takes in a `default` argument, which can be used to set a default\n    function that will be called when trying to encode an unsupported object. This argument\n    will take precedence over the overridden\n    [`.default()`][ujson5.JSON5Encoder.default] method.\n\n    !!! warning\n        Comment extraction is currently only fully supported on Python 3.12+. On older\n        versions, the function will still work but will not extract all comments from the\n        parent TypedDicts.\n\n    Example:\n    import ujson5\n\n\n    class MyEncoder(ujson5.JSON5Encoder):\n        def default(self, obj):\n            if isinstance(obj, set):  # (1)!\n                return list(obj)\n            return super().default(obj)  # (2)!\n\n\n    user = {\"name\": \"John\", \"age\": \"123\", \"hobbies\": {\"tennis\", \"reading\"}}\n    print(ujson5.dumps(user, cls=MyEncoder))\n    # {\"name\": \"John\", \"age\": \"123\", \"hobbies\": [\"reading\", \"tennis\"]}\n\n    1. In this example, the encoder subclass `MyEncoder` overrides the\n    [`.default()`][ujson5.JSON5Encoder.default] method to handle the serialization of sets.\n    The method returns a list of the set elements.\n    2. It is recommended to call the parent class's [`.default()`][ujson5.JSON5Encoder.default]\n    method to handle the default encoding.\n\n    All arguments are keyword-only arguments.\n\n    Args:\n        default: A function that returns a serializable object when trying to encode an\n            unsupported object. If None, the default`.default()` method will be used.\n            Defaults to None.\n        skip_keys: If True, keys with unsupported types (anything other than str, int, float,\n            bool, or None) will be skipped. Otherwise, an exception will be raised.\n            Defaults to False.\n        ensure_ascii: If True, all non-ASCII characters will be escaped. Defaults to True.\n        check_circular: If True, circular references will be checked. This will introduce a\n            small performance hit. Defaults to True.\n        allow_nan: If True, NaN, Infinity, and -Infinity will be allowed. Otherwise, an\n            exception will be raised when trying to encode these values. Defaults to True.\n        indent: If not None, the output will be formatted with the given indent level.\n            Otherwise, the output will be compact. Defaults to None.\n        separators: A tuple containing the item separator and the key-value separator.\n            Defaults to None. If None, it will be set to (\", \", \": \") if indent is None,\n            and (\",\", \":\") if indent is not None.\n        sort_keys: If True, the keys will be sorted. Defaults to False.\n        key_quotation: The quotation style to be used for keys. Can be one of \"single\",\n            \"double\", or \"none\". If \"single\" or \"double\", the keys will be enclosed in\n            single or double quotes, respectively. If \"none\", the keys will not be enclosed\n            in quotes. Defaults to \"double\".\n        trailing_comma: If True, a trailing comma will be added to the last item in\n            a list or dictionary. If None, a trailing comma will be added if indent\n            is not None. Defaults to None.\n    \"\"\"\n    def __init__(\n        self,\n        *,\n        default: DefaultInterface | None = None,\n        skip_keys: bool = False,\n        ensure_ascii: bool = True,\n        check_circular: bool = True,\n        allow_nan: bool = True,\n        indent: int | None = None,\n        separators: tuple[str, str] | None = None,\n        sort_keys: bool = False,\n        key_quotation: KeyQuotation = \"double\",\n        trailing_comma: bool | None = None,\n    ) -> None:\n        pass\n\n    def default(self, obj: Any) -> Serializable:\n        \"\"\"Override this method in a subclass to implement custom serialization\n        for objects that are not serializable by default. This method should return\n        a serializable object. If this method is not overridden, the encoder will\n        raise a JSON5EncodeError when trying to encode an unsupported object.\n\n        Args:\n            obj: The object to be serialized that is not supported by default\n\n        Returns:\n            Serializable: A serializable object\n\n        Raises:\n            JSON5EncodeError: If the object cannot be serialized\n        \"\"\"\n        pass\n\ndef dumps(\n    obj: Any,\n    typed_dict_cls: Any | None = None,\n    *,\n    cls: type[JSON5Encoder] | None = None,\n    default: DefaultInterface | None = None,\n    skip_keys: bool = False,\n    ensure_ascii: bool = True,\n    check_circular: bool = True,\n    allow_nan: bool = True,\n    indent: int | None = None,\n    separators: tuple[str, str] | None = None,\n    sort_keys: bool = False,\n    key_quotation: KeyQuotation = \"double\",\n    trailing_comma: bool | None = None,\n) -> str:\n    \"\"\"Serialize `obj` to a JSON5 formatted `str`.\n\n    Example:\n    import ujson5\n    user = {\"name\": \"John\", \"age\": 123, \"hobbies\": [\"tennis\", \"reading\"]}\n    print(ujson5.dumps(user))\n    # Output: '{\"name\": \"John\", \"age\": 123, \"hobbies\": [\"tennis\", \"reading\"]}'\n\n    All arguments except `obj` and `typed_dict_cls` are keyword-only arguments.\n\n    Args:\n        cls: The encoder class to be used. a custom [`JSON5Encoder`][ujson5.JSON5Encoder]\n            subclass (e.g. one that overrides the [`.default()`][ujson5.JSON5Encoder.default]\n            method to serialize additional types) can be provided. If None, the default\n            [`JSON5Encoder`][ujson5.JSON5Encoder] class will be used. Defaults to None.\n        default: A function that returns a serializable object when trying to encode an\n            unsupported object. If None, the default\n            [`.default()`][ujson5.JSON5Encoder.default] method will be used. Defaults to None.\n        skip_keys: If True, keys with unsupported types (anything other than str, int, float,\n            bool, or None) will be skipped. Otherwise, an exception will be raised.\n            Defaults to False.\n        ensure_ascii: If True, all non-ASCII characters will be escaped. Defaults to True.\n        check_circular: If True, circular references will be checked. This will introduce a\n            small performance hit. Defaults to True.\n        allow_nan: If True, NaN, Infinity, and -Infinity will be allowed. Otherwise, an\n            exception will be raised when trying to encode these values. Defaults to True.\n        indent: If not None, the output will be formatted with the given indent level.\n            Otherwise, the output will be compact. Defaults to None.\n        separators: A tuple containing the item separator and the key-value separator.\n            Defaults to None. If None, it will be set to (\", \", \": \") if indent is None,\n            and (\",\", \":\") if indent is not None.\n        sort_keys: If True, the keys will be sorted. Defaults to False.\n        key_quotation: The quotation style to be used for keys. Can be one of \"single\",\n            \"double\", or \"none\". If \"single\" or \"double\", the keys will be enclosed in\n            single or double quotes, respectively. If \"none\", the keys will not be enclosed\n            in quotes. Defaults to \"double\".\n        trailing_comma: If True, a trailing comma will be added to the last item in\n            a list or dictionary. If None, a trailing comma will be added if indent\n            is not None. Defaults to None.\n\n    Returns:\n        str: The JSON5 formatted string representation of the Python object\n\n    Raises:\n        JSON5EncodeError: If the object cannot be serialized\n    \"\"\"\n    pass\n\ndef dump(\n    obj: Any,\n    fp: TextIO,\n    typed_dict_cls: Any | None = None,\n    *,\n    skip_keys: bool = False,\n    ensure_ascii: bool = True,\n    check_circular: bool = True,\n    allow_nan: bool = True,\n    cls: type[JSON5Encoder] | None = None,\n    indent: int | None = None,\n    separators: tuple[str, str] | None = None,\n    default: DefaultInterface | None = None,\n    sort_keys: bool = False,\n    key_quotation: KeyQuotation = \"double\",\n    trailing_comma: bool | None = None,\n) -> None:\n    \"\"\"Serialize `obj` as a JSON formatted stream to `fp` (a `.write()`-supporting\n    file-like object).\n\n    Example:\n    import ujson5\n    user = {\"name\": \"John\", \"age\": 123, \"hobbies\": [\"tennis\", \"reading\"]}\n    with open(\"user.json\", \"w\") as f:\n        ujson5.dump(user, f)\n\n    Args:\n        cls: The encoder class to be used. a custom [`JSON5Encoder`][ujson5.JSON5Encoder]\n            subclass (e.g. one that overrides the [`.default()`][ujson5.JSON5Encoder.default]\n            method to serialize additional types) can be provided. If None, the default\n            [`JSON5Encoder`][ujson5.JSON5Encoder] class will be used. Defaults to None.\n        default: A function that returns a serializable object when trying to encode an\n            unsupported object. If None, the default\n            [`.default()`][ujson5.JSON5Encoder.default] method will be used. Defaults to None.\n        skip_keys: If True, keys with unsupported types (anything other than str, int, float,\n            bool, or None) will be skipped. Otherwise, an exception will be raised.\n            Defaults to False.\n        ensure_ascii: If True, all non-ASCII characters will be escaped. Defaults to True.\n        check_circular: If True, circular references will be checked. This will introduce a\n            small performance hit. Defaults to True.\n        allow_nan: If True, NaN, Infinity, and -Infinity will be allowed. Otherwise, an\n            exception will be raised when trying to encode these values. Defaults to True.\n        indent: If not None, the output will be formatted with the given indent level.\n            Otherwise, the output will be compact. Defaults to None.\n        separators: A tuple containing the item separator and the key-value separator.\n            Defaults to None. If None, it will be set to (\", \", \": \") if indent is None,\n            and (\",\", \":\") if indent is not None.\n        sort_keys: If True, the keys will be sorted. Defaults to False.\n        key_quotation: The quotation style to be used for keys. Can be one of \"single\",\n            \"double\", or \"none\". If \"single\" or \"double\", the keys will be enclosed in\n            single or double quotes, respectively. If \"none\", the keys will not be enclosed\n            in quotes. Defaults to \"double\".\n        trailing_comma: If True, a trailing comma will be added to the last item in\n            a list or dictionary. If None, a trailing comma will be added if indent\n            is not None. Defaults to None.\n\n    Returns:\n        str: The JSON5 formatted string representation of the Python object\n\n    Raises:\n        JSON5EncodeError: If the object cannot be serialized\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "src/ujson5/lexer.py",
                "code": "from .core import Token, TokenResult # For context, not in skeleton\n\ndef simplify_escapes(text: str) -> str:\n    \"\"\"Simplify escape sequences in a string. This function replaces line\n    continuation sequences with a newline character.\n\n    Args:\n        text: string with escape sequences\n\n    Returns:\n        str: string with escape sequences simplified\n    \"\"\"\n    pass\n\ndef tokenize_number(buffer: str, idx: int) -> TokenResult:\n    \"\"\"Tokenize a number and return the token and the updated index.\n\n    Args:\n        buffer: JSON5 document\n        idx: current index. Must point to the start of the number\n\n    Returns:\n        TokenResult: Token and updated index\n\n    Raises:\n        JSON5DecodeError: if the number is invalid\n    \"\"\"\n    pass\n\ndef tokenize_string(buffer: str, idx: int) -> TokenResult:\n    \"\"\"Tokenize a string and return the token and the updated index.\n\n    Args:\n        buffer: JSON5 document\n        idx: current index. Must point to the opening quote\n\n    Returns:\n        TokenResult: Token and updated index\n\n    Raises:\n        JSON5DecodeError: if the string is invalid\n    \"\"\"\n    pass\n\ndef tokenize_identifier(buffer: str, idx: int) -> TokenResult:\n    \"\"\"Tokenize an identifier and return the token and the updated index.\n\n    Args:\n        buffer: JSON5 document\n        idx: current index. Must point to the start of the identifier\n\n    Returns:\n        TokenResult: Token and updated index\n\n    Raises:\n        JSON5DecodeError: if the identifier is invalid\n    \"\"\"\n    pass\n\ndef validate_comment(buffer: str, idx: int) -> int:\n    \"\"\"Validate a comment. An inline comment starts with `//` and ends with a\n    newline character. A block comment starts with `/*` and ends with `*/`.\n\n    Args:\n        buffer: JSON5 document\n        idx: current index. Must point to the start of the comment\n\n    Returns:\n        int: updated index\n\n    Raises:\n        JSON5DecodeError: if the comment is invalid\n    \"\"\"\n    pass\n\ndef tokenize(buffer: str) -> list[Token]:\n    \"\"\"Tokenize a JSON5 document.\n\n    Args:\n        buffer: JSON5 document\n\n    Returns:\n        list[Token]: List of tokens\n\n    Raises:\n        JSON5DecodeError: if the document is invalid\n    \"\"\"\n    pass\n"
            }
        ]
    },
    {
        "idx": 34760,
        "repo_name": "tecnosam_pydongo",
        "url": "https://github.com/tecnosam/pydongo",
        "description": "A lightweight ORM for MongoDB using Pydantic models.",
        "stars": 28,
        "forks": 6,
        "language": "python",
        "size": 790,
        "created_at": "2025-03-23T19:04:47+00:00",
        "updated_at": "2025-04-28T04:40:51+00:00",
        "pypi_info": {
            "name": "pydongo",
            "version": "0.2.0",
            "url": "https://files.pythonhosted.org/packages/31/70/2c55c501f9c0929ec65c47579ba5a74798aed6c6445285a9c9cf43ee5432/pydongo-0.2.0.tar.gz"
        },
        "error": null,
        "judge_info": {
            "language": "python",
            "is_good_project": false,
            "reason": "",
            "python_file_num": 28,
            "comment_ratio": 0.3777538957549704,
            "pyfile_content_length": 119218,
            "pyfile_code_lines": 3722,
            "test_file_exist": true,
            "test_file_content_length": 19314,
            "pytest_framework": true,
            "test_case_num": 26,
            "metadata_path": [
                "pyproject.toml"
            ],
            "readme_content_length": 6575,
            "llm_reason": "The project, Pydongo, is a lightweight Object-Document Mapper (ODM) for MongoDB. \n\n**Positive Aspects:**\n*   **Self-Contained (with mock driver):** Crucially, the project includes `MockMongoDBDriver` and `MockAsyncMongoDBDriver`. This allows the core ODM logic (query building, Pydantic model mapping, DSL interpretation, active record patterns) to be developed and tested by an AI without requiring a live MongoDB instance or internet connection for the benchmark's primary evaluation. This addresses the self-containment requirement for the AI-rebuilt solution.\n*   **Clear & Well-Defined Functionality:** The README clearly describes Pydongo's features: Pydantic-based models, an expressive query DSL (like Django ORM/SQLAlchemy), document interface (`.save()`, `.delete()`), and sync/async support. This provides a concrete target for the AI to replicate.\n*   **Testable & Verifiable Output:** The project has a comprehensive suite of unit tests (e.g., `test_driver_mock.py`, `test_filter_expression.py`, `test_field_expression.py`). These tests, especially those utilizing the mock drivers, can be adapted to verify the AI's implementation of the ODM.\n*   **No GUI:** As a library, it has no GUI, making it suitable for programmatic interaction and testing.\n*   **Appropriate Complexity (Medium):** Rebuilding this ODM layer is a non-trivial task. It involves implementing logic for query expression parsing and translation, object-document mapping, managing Pydantic models, and abstracting database driver interactions (sync/async). The scope is well-defined (lightweight ODM) and seems achievable for a competent AI to replicate the existing structure and functionality. The codebase is modular (drivers, expressions, workers, utils).\n*   **Well-Understood Problem Domain:** ODMs/ORMs are a common and well-understood software pattern.\n*   **Predominantly Code-Based Solution:** The task is to generate Python code for the library.\n*   **Dependencies:** The core dependencies (`pydantic`, `pymongo`, `motor`) are standard PyPI packages. The AI would build the Pydongo layer on top of these, which is a reasonable expectation.\n\n**Negative Aspects or Concerns:**\n*   **External Service Dependency (for real-world use):** Pydongo's purpose is to interact with MongoDB. For the benchmark to be truly self-contained for the AI's solution, the evaluation must primarily rely on the mock driver. If a real MongoDB instance were a hard requirement for the AI's solution testing, it would reduce suitability due to setup complexity and external service reliance.\n*   **Complexity of Full Replication:** While rated Medium, accurately replicating all aspects of the query DSL, the interaction between Pydantic models and the database representation, index creation logic, and the nuances of both synchronous and asynchronous operations is a substantial undertaking with multiple interacting components.\n\n**Overall Assessment:**\nThe project is a good candidate (rated 75) because its core logic can be isolated and tested using the provided mock drivers, making it self-contained for the AI's task. The functionality is clear, and existing tests provide a basis for verification. The difficulty is 'Medium' as it requires implementing several interconnected ODM components and their logic, but it does not involve novel research or overly esoteric algorithms for replication.",
            "llm_project_type": "Python library providing an Object-Document Mapper (ODM) for MongoDB",
            "llm_rating": 75,
            "llm_difficulty": "Medium"
        },
        "tests": {
            "repo_name": "tecnosam_pydongo",
            "finish_test": true,
            "test_case_result": {
                "tests/test_collection_builder_core.py::test_collection_builder_sort_limit_skip_multi_sort": "passed",
                "tests/test_collection_builder_core.py::test_collection_builder_null_state_defaults": "passed",
                "tests/test_driver_mock.py::test_insert_and_find_one": "passed",
                "tests/test_driver_mock.py::test_update_and_delete": "passed",
                "tests/test_field_expression.py::test_comparative_operators_resolve_correct_queries": "passed",
                "tests/test_field_expression.py::test_nested_fields": "passed",
                "tests/test_field_expression.py::test_array_field_size_expression": "passed",
                "tests/test_field_expression.py::test_array_field_contains_and_excludes": "passed",
                "tests/test_field_expression.py::test_array_field_matches_with_and_without_order": "passed",
                "tests/test_field_expression.py::test_len_and_contains_sugar": "passed",
                "tests/test_filter_expression.py::test_with_expression_merges_dict": "passed",
                "tests/test_filter_expression.py::test_and_combines_two_expressions": "passed",
                "tests/test_filter_expression.py::test_or_combines_two_expressions": "passed",
                "tests/test_filter_expression.py::test_not_inverts_expression": "passed",
                "tests/test_index_creation.py::test_single_key_index": "passed",
                "tests/test_index_creation.py::test_compound_index": "passed",
                "tests/test_index_creation.py::test_text_and_hash_index": "passed",
                "tests/test_index_creation.py::test_geo_index_types": "passed",
                "tests/test_index_creation.py::test_index_with_special_kwargs": "passed",
                "tests/test_index_creation.py::test_ttl_behavior_for_text_and_other_index_types[text-False]": "passed",
                "tests/test_index_creation.py::test_ttl_behavior_for_text_and_other_index_types[hashed-False]": "passed",
                "tests/test_index_creation.py::test_ttl_behavior_for_text_and_other_index_types[2d-True]": "passed",
                "tests/test_index_creation.py::test_ttl_behavior_for_text_and_other_index_types[2dsphere-True]": "passed",
                "tests/test_index_creation.py::test_ttl_behavior_for_text_and_other_index_types[None-True]": "passed",
                "tests/test_index_creation_async.py::test_single_key_index_async": "passed",
                "tests/test_index_creation_async.py::test_compound_index_async": "passed",
                "tests/test_index_creation_async.py::test_text_and_hash_index_async": "passed",
                "tests/test_index_creation_async.py::test_geo_index_types_async": "passed",
                "tests/test_index_creation_async.py::test_index_with_special_kwargs_async": "passed",
                "tests/test_resolve_annotation.py::test_resolve_annotation_union": "passed",
                "tests/test_resolve_annotation.py::test_resolve_annotation_optional": "passed",
                "tests/test_resolve_annotation.py::test_resolve_annotation_annotated": "passed",
                "tests/test_serilizer_utils.py::test_date_serialization": "passed",
                "tests/test_serilizer_utils.py::test_uuid_serialization": "passed",
                "tests/test_serilizer_utils.py::test_nested_serialization": "passed"
            },
            "success_count": 35,
            "failed_count": 0,
            "error_count": 0,
            "skipped_count": 0,
            "unknown_count": 0,
            "total_count": 35,
            "success_rate": 1.0,
            "coverage_report": {
                "covered_lines": 515,
                "num_statements": 753,
                "percent_covered": 63.32958380202475,
                "percent_covered_display": "63",
                "missing_lines": 238,
                "excluded_lines": 0,
                "num_branches": 136,
                "num_partial_branches": 20,
                "covered_branches": 48,
                "missing_branches": 88
            },
            "coverage_result": {}
        },
        "codelines_count": 3722,
        "codefiles_count": 28,
        "code_length": 119218,
        "test_files_count": 8,
        "test_code_length": 19314,
        "structure": [
            {
                "file": "tests/test_driver_mock.py",
                "functions": [
                    {
                        "name": "test_insert_and_find_one",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_update_and_delete",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_resolve_annotation.py",
                "functions": [
                    {
                        "name": "test_resolve_annotation_union",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_resolve_annotation_optional",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_resolve_annotation_annotated",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_filter_expression.py",
                "functions": [
                    {
                        "name": "test_with_expression_merges_dict",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_and_combines_two_expressions",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_or_combines_two_expressions",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_not_inverts_expression",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/test_serilizer_utils.py",
                "functions": [
                    {
                        "name": "test_date_serialization",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_uuid_serialization",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_nested_serialization",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_collection_builder_core.py",
                "functions": [
                    {
                        "name": "test_collection_builder_sort_limit_skip_multi_sort",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_collection_builder_null_state_defaults",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": [
                    {
                        "name": "User",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/test_index_creation_async.py",
                "functions": [
                    {
                        "name": "_assert_index_registered",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "collection",
                            "driver",
                            "expected_count"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "DemoModel",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/test_field_expression.py",
                "functions": [
                    {
                        "name": "test_comparative_operators_resolve_correct_queries",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_nested_fields",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_array_field_size_expression",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_array_field_contains_and_excludes",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_array_field_matches_with_and_without_order",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_len_and_contains_sugar",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": [
                    {
                        "name": "DummyModel",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "Friend",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "User",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/test_index_creation.py",
                "functions": [
                    {
                        "name": "_setup",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "_assert_index_registered",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "collection",
                            "driver",
                            "expected_count"
                        ]
                    },
                    {
                        "name": "test_single_key_index",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_compound_index",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_text_and_hash_index",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_geo_index_types",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_index_with_special_kwargs",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_ttl_behavior_for_text_and_other_index_types",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "index_type",
                            "expect_ttl"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "DemoModel",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "examples/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "examples/sync/medtech_app.py",
                "functions": [
                    {
                        "name": "create_patient",
                        "docstring": null,
                        "comments": "=== OPERATIONS ===",
                        "args": [
                            "patient_id",
                            "name",
                            "age"
                        ]
                    },
                    {
                        "name": "add_prescription",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "patient_id",
                            "drug_name",
                            "dosage",
                            "frequency",
                            "duration_days"
                        ]
                    },
                    {
                        "name": "get_prescriptions",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "patient_id"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "Prescription",
                        "docstring": null,
                        "comments": "=== MODELS ===",
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "Patient",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "examples/sync/social_media_app.py",
                "functions": [
                    {
                        "name": "create_user",
                        "docstring": null,
                        "comments": "=== OPERATIONS ===",
                        "args": [
                            "username",
                            "email",
                            "bio"
                        ]
                    },
                    {
                        "name": "make_post",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "username",
                            "content"
                        ]
                    },
                    {
                        "name": "like_post",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "username",
                            "post_id"
                        ]
                    },
                    {
                        "name": "get_all_posts",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "username"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "Post",
                        "docstring": null,
                        "comments": "=== MODELS ===",
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "User",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "examples/async/social_media_app.py",
                "functions": [],
                "classes": [
                    {
                        "name": "Post",
                        "docstring": null,
                        "comments": "=== MODELS ===",
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "User",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "pydongo/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "pydongo/workers/document.py",
                "functions": [
                    {
                        "name": "as_document",
                        "docstring": "Wraps a Pydantic object in either a synchronous or asynchronous document worker,\ndepending on the provided MongoDB driver.\n\nArgs:\n    pydantic_object (T): A Pydantic model instance.\n    driver (AbstractMongoDBDriver): The MongoDB driver in use.\n\nReturns:\n    Union[DocumentWorker, AsyncDocumentWorker]: A document wrapper with persistence methods.",
                        "comments": null,
                        "args": [
                            "pydantic_object",
                            "driver"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "BaseDocumentWorker",
                        "docstring": "Base class for document-level operations like serialization, query generation, and collection detection.\n\nThis class provides common functionality for both synchronous and asynchronous document workers.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the document wrapper.\n\nArgs:\n    pydantic_object (T): The Pydantic model to wrap.\n    objectId (Optional[str]): Optional MongoDB ObjectId of the document.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "pydantic_object",
                                    "objectId"
                                ]
                            },
                            {
                                "name": "collection_name",
                                "docstring": "Returns the MongoDB collection name associated with the model.\n\nReturns:\n    str: The collection name.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "get_query",
                                "docstring": "Builds a MongoDB query to uniquely identify the current document.\n\nReturns:\n    dict: A MongoDB query dict.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "serialize",
                                "docstring": "Serializes the Pydantic model to a dictionary suitable for MongoDB storage.\n\nReturns:\n    dict: Serialized representation of the document.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__getattr__",
                                "docstring": "Proxy attribute access to the underlying Pydantic model.\n\nArgs:\n    name (str): The attribute name.\n\nReturns:\n    Any: Attribute value from the Pydantic model.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "name"
                                ]
                            },
                            {
                                "name": "__repr__",
                                "docstring": "Returns a human-readable string representation of the document.\n\nReturns:\n    str: Representation of the document wrapper.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "DocumentWorker",
                        "docstring": "Document wrapper for synchronous MongoDB operations.\n\nProvides methods to save and delete documents from MongoDB.",
                        "comments": "def __setattr__(self, name, value):\nif not hasattr(self.pydantic_object, name):\nraise AttributeError(f\"{self.pydantic_object} has no attribute {name}\")\nsetattr(self.pydantic_object, name, value)",
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the sync document worker.\n\nArgs:\n    pydantic_object (T): The Pydantic model to wrap.\n    driver (AbstractSyncMongoDBDriver): The sync MongoDB driver.\n    objectId (Optional[str]): Optional ObjectId for the document.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "pydantic_object",
                                    "driver",
                                    "objectId"
                                ]
                            },
                            {
                                "name": "save",
                                "docstring": "Save the document to MongoDB. Performs an insert if no ObjectId is present,\nor an update otherwise.\n\nReturns:\n    dict: Result of the MongoDB insert or update operation.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "delete",
                                "docstring": "Delete the document from MongoDB using its ObjectId.\n\nReturns:\n    dict: Result of the delete operation.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "AsyncDocumentWorker",
                        "docstring": "Document wrapper for asynchronous MongoDB operations.\n\nProvides async methods to save and delete documents.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the async document worker.\n\nArgs:\n    pydantic_object (T): The Pydantic model to wrap.\n    driver (AbstractAsyncMongoDBDriver): The async MongoDB driver.\n    objectId (Optional[str]): Optional ObjectId for the document.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "pydantic_object",
                                    "driver",
                                    "objectId"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "pydongo/workers/collection.py",
                "functions": [
                    {
                        "name": "as_collection",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "pydantic_model",
                            "driver"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "CollectionWorker",
                        "docstring": "Entry point for querying and interacting with a MongoDB collection.\n\nWraps a Pydantic model and MongoDB driver, and exposes queryable field expressions\nand high-level `find_one`, `afind_one`, and `find` methods.\n\nSupports both sync and async drivers via conditional branching.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "pydantic_model",
                                    "driver"
                                ]
                            },
                            {
                                "name": "find_one",
                                "docstring": "Query the database for a single document that matches the filter expression.\nOnly works with a synchronous driver.\n\nArgs:\n    expression (CollectionFilterExpression): The MongoDB-style filter expression.\n\nReturns:\n    Optional[DocumentWorker]: A wrapped Pydantic object if found, otherwise None.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "expression"
                                ]
                            },
                            {
                                "name": "find",
                                "docstring": "Initiates a fluent response builder chain for querying multiple documents.\n\nArgs:\n    expression (Optional[CollectionFilterExpression]): Optional filter expression.\n\nReturns:\n    CollectionResponseBuilder: Builder for fluent chaining (e.g., .limit(), .sort()).",
                                "comments": null,
                                "args": [
                                    "self",
                                    "expression"
                                ]
                            },
                            {
                                "name": "use_index",
                                "docstring": "Registers an index (or compound index) on the collection.\n\nAccepts IndexExpression(s)\n\nArgs:\n    index: A single IndexExpression, or a tuple of them.\n\nReturns:\n    CollectionWorker: Self, for method chaining.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "index"
                                ]
                            },
                            {
                                "name": "__getattr__",
                                "docstring": "Returns a field expression object to enable DSL-style querying using comparison\noperators or dot notation for nested objects.\n\nArgs:\n    name (str): Field name in the Pydantic model.\n\nReturns:\n    FieldExpression: Expression object tied to the field.\n\nRaises:\n    AttributeError: If the field does not exist on the model.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "name"
                                ]
                            },
                            {
                                "name": "collection_name",
                                "docstring": "Derives the MongoDB collection name from the model or falls back to the class name.\n\nReturns:\n    str: The name of the collection.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "CollectionResponseBuilder",
                        "docstring": "Fluent builder for composing queries and retrieving lists of documents.\n\nCan build the final MongoDB query structure with sort, skip, and limit options.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "expression",
                                    "pydantic_model",
                                    "driver",
                                    "collection_name",
                                    "indexes"
                                ]
                            },
                            {
                                "name": "skip",
                                "docstring": "Skip the first N documents in the query result.\n\nArgs:\n    offset (int): Number of documents to skip.\n\nReturns:\n    CollectionResponseBuilder: For chaining.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "offset"
                                ]
                            },
                            {
                                "name": "limit",
                                "docstring": "Limit the number of documents returned.\n\nArgs:\n    limit_value (int): Maximum number of documents to return.\n\nReturns:\n    CollectionResponseBuilder: For chaining.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "limit_value"
                                ]
                            },
                            {
                                "name": "sort",
                                "docstring": "Apply sort criteria to the query.\n\nArgs:\n    sort_criteria (Union[FieldExpression, Sequence[FieldExpression]]): Sort instructions.\n\nReturns:\n    CollectionResponseBuilder: For chaining.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "sort_criteria"
                                ]
                            },
                            {
                                "name": "build_kwargs",
                                "docstring": "Assembles the query, sort, offset, and limit into a single dictionary.\n\nReturns:\n    dict: MongoDB-compatible query parameters.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "serialize_document",
                                "docstring": "Deserialize a raw MongoDB document and wrap it in a DocumentWorker.\n\nArgs:\n    document (dict): Raw document from the database.\n    document_worker_class (Type): Either DocumentWorker or AsyncDocumentWorker.\n    pydantic_model (Type): Model class to hydrate.\n    driver (AbstractMongoDBDriver): Driver used to perform operations.\n\nReturns:\n    BaseDocumentWorker: Wrapped document instance.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "document",
                                    "document_worker_class",
                                    "pydantic_model",
                                    "driver"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "SyncCollectionResponseBuilder",
                        "docstring": "Response builder for synchronous drivers.\n\nProvides direct methods to count, check existence, and iterate documents.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "expression",
                                    "pydantic_model",
                                    "driver",
                                    "collection_name",
                                    "indexes"
                                ]
                            },
                            {
                                "name": "exists",
                                "docstring": "Check if any document matches the filter expression.\n\nReturns:\n    bool: True if at least one document exists.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "count",
                                "docstring": "Count how many documents match the filter expression.\n\nReturns:\n    int: Number of matching documents.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "all",
                                "docstring": "Retrieve all documents that match the current query builder state.\n\nReturns:\n    Iterable[DocumentWorker]: Generator of hydrated documents.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "create_indexes",
                                "docstring": "Creates indexes on the MongoDB database.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "AsyncCollectionResponseBuilder",
                        "docstring": "Response builder for asynchronous drivers.\n\nSupports async versions of exists, count, and all().",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "expression",
                                    "pydantic_model",
                                    "driver",
                                    "collection_name",
                                    "indexes"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "pydongo/expressions/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "pydongo/expressions/filter.py",
                "functions": [],
                "classes": [
                    {
                        "name": "CollectionFilterExpression",
                        "docstring": "Represents a boolean filter expression used to query a MongoDB collection.\n\nThese expressions are composable using:\n    - Logical OR (`|`)\n    - Logical AND (`&`)\n    - Logical NOT (`~`)\n\nExample usage:\n    filter_1 = User.age > 18\n    filter_2 = User.name == \"Samuel\"\n    combined = filter_1 & filter_2\n\nThe resulting expression can be serialized and passed to the database driver.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the filter expression with an optional initial dictionary.\n\nArgs:\n    expression (Optional[dict]): A MongoDB-style query dictionary.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "expression"
                                ]
                            },
                            {
                                "name": "with_expression",
                                "docstring": "Mutate the internal expression by merging in a new dictionary.\n\nArgs:\n    expression (dict): A MongoDB-style query to merge into the current expression.\n\nReturns:\n    CollectionFilterExpression: The current instance (for chaining).",
                                "comments": null,
                                "args": [
                                    "self",
                                    "expression"
                                ]
                            },
                            {
                                "name": "serialize",
                                "docstring": "Serialize the filter expression into a MongoDB-compatible query object.\n\nReturns:\n    dict: Serialized MongoDB query.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__and__",
                                "docstring": "Combine this filter with another using a logical AND.\n\nArgs:\n    other (CollectionFilterExpression): Another filter to combine with.\n\nReturns:\n    CollectionFilterExpression: A new combined filter.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "__or__",
                                "docstring": "Combine this filter with another using a logical OR.\n\nArgs:\n    other (CollectionFilterExpression): Another filter to combine with.\n\nReturns:\n    CollectionFilterExpression: A new combined filter.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "__invert__",
                                "docstring": "Invert the current filter using a logical NOT.\n\nReturns:\n    CollectionFilterExpression: A new filter expression wrapped in `$not`.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "pydongo/expressions/base.py",
                "functions": [],
                "classes": [
                    {
                        "name": "BaseExpression",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "serialize",
                                "docstring": "Serialize an expression into a MongoDB compatible query DTO",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "pydongo/expressions/field.py",
                "functions": [],
                "classes": [
                    {
                        "name": "FieldExpression",
                        "docstring": "Represents a scalar field in a MongoDB query.\n\nThis class supports operator overloading to build query expressions using:\n    ==, !=, >, >=, <, <=\n\nIt also supports nested attribute access (e.g., user.address.city).",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize a field expression.\n\nArgs:\n    field_name (str): The full dot-path name of the field.\n    annotation (Any): The Pydantic type annotation for the field.\n    sort_ascending (bool): Whether sorting on this field is ascending by default.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "field_name",
                                    "annotation",
                                    "sort_ascending"
                                ]
                            },
                            {
                                "name": "to_index",
                                "docstring": "Returns a complete, ready-to-use `IndexExpression` for this field.\n\nThis is a convenience method for quickly generating a basic index configuration\nusing the default sort order and inferred index type (e.g., TEXT for strings).",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "as_index",
                                "docstring": "Returns an `IndexExpressionBuilder` initialized with this field.\n\nThis allows users to customize the index further, such as adding uniqueness,\nTTL, collation, or partial filter expressions—before building the final index object.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "_get_comparative_expression",
                                "docstring": "Build a MongoDB filter expression using the given operator and value.\n\nArgs:\n    operator (str): MongoDB comparison operator (e.g., \"$gt\").\n    value (Any): The value to compare against.\n\nReturns:\n    dict: A MongoDB-compatible filter clause.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "operator",
                                    "value"
                                ]
                            },
                            {
                                "name": "__eq__",
                                "docstring": "Build an equality expression (`==`).",
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "__ne__",
                                "docstring": "Build an inequality expression (`!=`).",
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "__gt__",
                                "docstring": "Build a greater-than expression (`>`).",
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "__ge__",
                                "docstring": "Build a greater-than-or-equal expression (`>=`).",
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "__lt__",
                                "docstring": "Build a less-than expression (`<`).",
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "__le__",
                                "docstring": "Build a less-than-or-equal expression (`<=`).",
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "__neg__",
                                "docstring": "Flip the default sort order.\n\nReturns:\n    FieldExpression: A new instance with reversed sort order.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "field_name",
                                "docstring": "The full field name, including nested paths if applicable.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__getattr__",
                                "docstring": "Support for chained dot notation, e.g. `user.address.city`.\n\nArgs:\n    name (str): Subfield name.\n\nReturns:\n    FieldExpression: A new field expression for the nested field.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "name"
                                ]
                            },
                            {
                                "name": "_getattr",
                                "docstring": "Helper to resolve nested fields.\n\nArgs:\n    field_name (str): Current field name path.\n    annotation (Any): Type annotation of the current field.\n    name (str): Next subfield name.\n\nReturns:\n    FieldExpression: A new expression with nested field access.\n\nRaises:\n    AttributeError: If the annotation is not a Pydantic model or field is invalid.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "field_name",
                                    "annotation",
                                    "name"
                                ]
                            },
                            {
                                "name": "get_field_expression",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "field_name",
                                    "annotation"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "ArraySizeFieldExpression",
                        "docstring": "Represents an expression for the size of an array field.\n\nUsed for queries like: `len(User.tags) > 2`",
                        "comments": null,
                        "methods": [
                            {
                                "name": "_get_comparative_expression",
                                "docstring": "Build a MongoDB `$expr` query comparing the size of an array.\n\nArgs:\n    operator (str): Comparison operator (e.g., \"$gt\").\n    value (int): Value to compare the array size against.\n\nReturns:\n    dict: MongoDB `$expr` query.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "operator",
                                    "value"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "ArrayFieldExpression",
                        "docstring": "Represents an array field in a MongoDB document.\n\nAdds support for array-specific operations like `.contains()`, `.size()`, and `.matches()`.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "size",
                                "docstring": "Get an expression that targets the array's length.\n\nReturns:\n    ArraySizeFieldExpression: An expression targeting the array's size.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "matches",
                                "docstring": "Check if the array exactly matches the provided values.\n\nArgs:\n    values (Iterable[Any]): Values to match against.\n    match_order (bool): If True, requires order-sensitive match.\n\nReturns:\n    CollectionFilterExpression: MongoDB `$all` or exact match query.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "values",
                                    "match_order"
                                ]
                            },
                            {
                                "name": "contains",
                                "docstring": "Check if the array contains one or more values.\n\nArgs:\n    value (Any): A scalar or iterable to check presence for.\n\nReturns:\n    CollectionFilterExpression: MongoDB `$in` expression.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "excludes",
                                "docstring": "Check if the array excludes one or more values.\n\nArgs:\n    value (Any): A scalar or iterable to check absence for.\n\nReturns:\n    CollectionFilterExpression: MongoDB `$nin` expression.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "__getattr__",
                                "docstring": "Support accessing subfields within an array of objects.\n\nArgs:\n    name (str): Name of the subfield.\n\nReturns:\n    FieldExpression: Field expression for the nested field.\n\nRaises:\n    TypeError: If element type can't be inferred.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "name"
                                ]
                            },
                            {
                                "name": "__len__",
                                "docstring": "Return an expression for the array's size (using `len()`).\n\nReturns:\n    ArraySizeFieldExpression: Expression targeting array length.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__contains__",
                                "docstring": "Python-style containment check using `in` syntax.\n\nArgs:\n    value (Any): Element to check for.\n\nReturns:\n    CollectionFilterExpression: MongoDB `$in` expression.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "pydongo/expressions/index.py",
                "functions": [],
                "classes": [
                    {
                        "name": "IndexSortOrder",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "ASCENDING",
                            "DESCENDING"
                        ]
                    },
                    {
                        "name": "IndexType",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "TEXT",
                            "HASHED",
                            "TWO_DIMENSIONAL",
                            "TWO_DIMENSIONAL_SPHERE"
                        ]
                    },
                    {
                        "name": "CollationStrength",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "description",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": [
                            "PRIMARY",
                            "SECONDARY",
                            "TERTIARY",
                            "QUATERNARY",
                            "IDENTICAL"
                        ]
                    },
                    {
                        "name": "IndexExpression",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "field_name",
                                    "index_type",
                                    "sort_order",
                                    "expires_after_seconds",
                                    "is_sparse",
                                    "is_unique",
                                    "is_hidden",
                                    "collation_locale",
                                    "collation_strength",
                                    "partial_expression",
                                    "index_name"
                                ]
                            },
                            {
                                "name": "serialize",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "build_kwargs",
                                "docstring": "Additional specifications for the index to be passed to MongoDB's create_index.\nOnly includes non-null values.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__hash__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__eq__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "expr"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "IndexExpressionBuilder",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "field_name"
                                ]
                            },
                            {
                                "name": "use_sort_order",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "sort_order"
                                ]
                            },
                            {
                                "name": "use_index_type",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "index_type"
                                ]
                            },
                            {
                                "name": "use_collation",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "locale",
                                    "strength"
                                ]
                            },
                            {
                                "name": "use_partial_expression",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "expression"
                                ]
                            },
                            {
                                "name": "use_index_name",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "index_name"
                                ]
                            },
                            {
                                "name": "use_sparse",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "is_sparse"
                                ]
                            },
                            {
                                "name": "use_unique",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "is_unique"
                                ]
                            },
                            {
                                "name": "use_hidden",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "is_hidden"
                                ]
                            },
                            {
                                "name": "use_ttl",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "seconds"
                                ]
                            },
                            {
                                "name": "build_index",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "pydongo/drivers/mock.py",
                "functions": [],
                "classes": [
                    {
                        "name": "MockMongoDBDriver",
                        "docstring": "In-memory mock implementation of the AbstractSyncMongoDBDriver.\n\nThis mock driver mimics MongoDB behavior for unit testing without requiring\na real database connection. Data is stored in-memory in Python dictionaries.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the mock driver with an empty in-memory store.\n\nArgs:\n    connection_string (str): Ignored.\n    database_name (str): Name of the fake database.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "connection_string",
                                    "database_name"
                                ]
                            },
                            {
                                "name": "connect",
                                "docstring": "Simulate a successful connection.\n\nReturns:\n    bool: Always True.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "close",
                                "docstring": "Close the connection (noop for the mock driver).",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "insert_one",
                                "docstring": "Insert a document into the in-memory collection.\n\nArgs:\n    collection (str): Name of the collection.\n    document (dict): Document to insert.\n\nReturns:\n    dict: Insert result including generated `_id`.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "document"
                                ]
                            },
                            {
                                "name": "insert_many",
                                "docstring": "Insert multiple documents into the in-memory collection.\n\nArgs:\n    collection (str): Name of the collection.\n    documents (list): List of documents to insert.\n\nReturns:\n    dict: Insert result with list of `_id`s.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "documents"
                                ]
                            },
                            {
                                "name": "find_one",
                                "docstring": "Find a single document matching the query.\n\nArgs:\n    collection (str): Name of the collection.\n    query (dict): MongoDB-style filter.\n\nReturns:\n    dict or None: Matching document or None if not found.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "query"
                                ]
                            },
                            {
                                "name": "find_many",
                                "docstring": "Find multiple documents matching the query.\n\nArgs:\n    collection (str): Name of the collection.\n    query (dict): MongoDB-style filter.\n    sort_criteria (dict): Ignored in the mock.\n    offset (int, optional): Skip the first N results.\n    limit (int, optional): Limit the number of results returned.\n\nReturns:\n    list: List of matching documents.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "query",
                                    "sort_criteria",
                                    "offset",
                                    "limit"
                                ]
                            },
                            {
                                "name": "update_one",
                                "docstring": "Update a single document matching the query.\n\nArgs:\n    collection (str): Name of the collection.\n    query (dict): Filter query.\n    update (dict): Update operations (only supports \"$set\").\n\nReturns:\n    dict: Update result with matched and modified count.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "query",
                                    "update",
                                    "upsert"
                                ]
                            },
                            {
                                "name": "delete_one",
                                "docstring": "Delete the first document matching the query.\n\nArgs:\n    collection (str): Name of the collection.\n    query (dict): Filter query.\n\nReturns:\n    dict: Delete result.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "query"
                                ]
                            },
                            {
                                "name": "count",
                                "docstring": "Count documents that match the query.\n\nArgs:\n    collection (str): Name of the collection.\n    query (dict): Filter query.\n\nReturns:\n    int: Number of matching documents.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "query"
                                ]
                            },
                            {
                                "name": "exists",
                                "docstring": "Check if at least one document matches the query.\n\nArgs:\n    collection (str): Name of the collection.\n    query (dict): Filter query.\n\nReturns:\n    bool: True if at least one document matches.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "query"
                                ]
                            },
                            {
                                "name": "create_index",
                                "docstring": "Create an index on a collection in the MongoDB Database\n\nArgs:\n    collection (str): The collection name.\n    index (tuple[IndexExpression]):\n        A tuple of IndexExpression objects representing the index to create\n        NOTE: Multiple elements in tuple indicate a single compound index\n        not multiple indexes",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "index"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "MockAsyncMongoDBDriver",
                        "docstring": "In-memory mock implementation of the AbstractAsyncMongoDBDriver.\n\nThis async mock mirrors the behavior of MongoDB using native async/await\nand an in-memory store. Ideal for use in async unit tests.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the async mock with an in-memory store.\n\nArgs:\n    connection_string (str): Ignored.\n    database_name (str): Mock database name.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "connection_string",
                                    "database_name"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "pydongo/drivers/async_mongo.py",
                "functions": [],
                "classes": [
                    {
                        "name": "AsyncDefaultMongoDBDriver",
                        "docstring": "Default asynchronous MongoDB driver using Motor (async wrapper for PyMongo).\n\nThis driver connects to a real MongoDB instance and provides async methods\nfor insert, update, query, and delete operations.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the driver with a MongoDB URI and target database name.\n\nArgs:\n    connection_string (str): MongoDB connection URI.\n    database_name (str): Name of the database to use.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "connection_string",
                                    "database_name"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "pydongo/drivers/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "pydongo/drivers/sync_mongo.py",
                "functions": [],
                "classes": [
                    {
                        "name": "DefaultMongoDBDriver",
                        "docstring": "Default synchronous MongoDB driver implementation using PyMongo.\n\nThis driver connects to a real MongoDB instance and executes\nblocking operations such as insert, update, query, and delete.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the driver with a MongoDB connection URI and database name.\n\nArgs:\n    connection_string (str): MongoDB URI (e.g., \"mongodb://localhost:27017\").\n    database_name (str): The target database to operate on.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "connection_string",
                                    "database_name"
                                ]
                            },
                            {
                                "name": "connect",
                                "docstring": "Establish a connection to the MongoDB server.\n\nReturns:\n    bool: True if the connection is successful.\n\nRaises:\n    RuntimeError: If connection to MongoDB fails.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "close",
                                "docstring": "Close the MongoDB connection.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "insert_one",
                                "docstring": "Insert a single document into a collection.\n\nArgs:\n    collection (str): Name of the collection.\n    document (dict): Document to insert.\n\nReturns:\n    dict: Result of the insert operation, including the inserted ID.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "document"
                                ]
                            },
                            {
                                "name": "insert_many",
                                "docstring": "Insert multiple documents into a collection.\n\nArgs:\n    collection (str): Name of the collection.\n    documents (list): List of documents to insert.\n\nReturns:\n    dict: Result including inserted IDs.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "documents"
                                ]
                            },
                            {
                                "name": "find_one",
                                "docstring": "Find a single document that matches the query.\n\nArgs:\n    collection (str): Name of the collection.\n    query (dict): MongoDB filter query.\n\nReturns:\n    dict or None: The found document, or None if not found.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "query"
                                ]
                            },
                            {
                                "name": "find_many",
                                "docstring": "Find multiple documents that match the query.\n\nArgs:\n    collection (str): Name of the collection.\n    query (dict): Filter conditions.\n    sort_criteria (dict): Sorting fields and directions.\n    offset (int, optional): Number of records to skip.\n    limit (int, optional): Maximum number of documents to return.\n\nReturns:\n    Iterable[dict]: Cursor for matching documents.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "query",
                                    "sort_criteria",
                                    "offset",
                                    "limit"
                                ]
                            },
                            {
                                "name": "update_one",
                                "docstring": "Update a single document matching the query.\n\nArgs:\n    collection (str): Name of the collection.\n    query (dict): Filter conditions.\n    update (dict): Update operations (e.g., {\"$set\": {...}}).\n    upsert (bool): Whether to insert the document if it doesn't exist.\n\nReturns:\n    dict: Update result with match, modification, and upsert info.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "query",
                                    "update",
                                    "upsert"
                                ]
                            },
                            {
                                "name": "delete_one",
                                "docstring": "Delete a single document matching the query.\n\nArgs:\n    collection (str): Name of the collection.\n    query (dict): Filter conditions.\n\nReturns:\n    dict: Delete result with count of deleted documents.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "query"
                                ]
                            },
                            {
                                "name": "count",
                                "docstring": "Count the number of documents matching the query.\n\nArgs:\n    collection (str): Name of the collection.\n    query (dict): Filter conditions.\n\nReturns:\n    int: Number of documents matching the filter.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "query"
                                ]
                            },
                            {
                                "name": "exists",
                                "docstring": "Check if at least one document exists that matches the query.\n\nArgs:\n    collection (str): Name of the collection.\n    query (dict): Filter conditions.\n\nReturns:\n    bool: True if a matching document exists.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "query"
                                ]
                            },
                            {
                                "name": "create_index",
                                "docstring": "Create an index on a collection in the MongoDB Database\n\nArgs:\n    collection (str): The collection name.\n    index (tuple[IndexExpression]):\n        A tuple of IndexExpression objects representing the index to create\n        NOTE: Multiple elements in tuple indicate a single compound index\n        not multiple indexes",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "index"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "pydongo/drivers/base.py",
                "functions": [],
                "classes": [
                    {
                        "name": "AbstractMongoDBDriver",
                        "docstring": "Abstract base class for MongoDB drivers.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "AbstractSyncMongoDBDriver",
                        "docstring": "Abstract base class for synchronous MongoDB drivers.\nProvides context management support and coroutine/thread-safe access\nto the currently active driver instance via contextvars.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the MongoDB driver with a connection string and database name.\n\nArgs:\n    connection_string (str): MongoDB connection URI.\n    database_name (str): Target database name.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "connection_string",
                                    "database_name"
                                ]
                            },
                            {
                                "name": "__enter__",
                                "docstring": "Enter the context manager, connect to MongoDB, and set the current driver context.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__exit__",
                                "docstring": "Exit the context manager, close the connection, and reset the driver context.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "exc_type",
                                    "exc_val",
                                    "exc_tb"
                                ]
                            },
                            {
                                "name": "current",
                                "docstring": "Get the current MongoDB driver instance for this coroutine/thread.\n\nReturns:\n    AbstractMongoDBDriver: The active driver instance.\n\nRaises:\n    RuntimeError: If no driver is currently in context.",
                                "comments": null,
                                "args": [
                                    "cls"
                                ]
                            },
                            {
                                "name": "connect",
                                "docstring": "Establish a connection to the MongoDB server.\nReturns:\n    bool: True if connection was successful.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "close",
                                "docstring": "Close the connection to the MongoDB server.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "insert_one",
                                "docstring": "Insert a single document into the specified collection.\n\nArgs:\n    collection (str): The collection name.\n    document (dict): The document to insert.\n\nReturns:\n    dict: Result of the insert operation.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "document"
                                ]
                            },
                            {
                                "name": "insert_many",
                                "docstring": "Insert multiple documents into the specified collection.\n\nArgs:\n    collection (str): The collection name.\n    documents (list): List of documents to insert.\n\nReturns:\n    dict: Result of the insert operation.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "documents"
                                ]
                            },
                            {
                                "name": "find_one",
                                "docstring": "Find a single document matching the query.\n\nArgs:\n    collection (str): The collection name.\n    query (dict): The filter query.\n\nReturns:\n    dict or None: The found document or None if not found.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "query"
                                ]
                            },
                            {
                                "name": "find_many",
                                "docstring": "Find multiple documents matching the query.\n\nArgs:\n    collection (str): The collection name.\n    query (dict): The filter query.\n    sort_criteria (dict): How to order the results\n    offset (int, optional): Number of records to skip (useful for pagination)\n    limit (int, optional): Max number of documents to return.\n\nReturns:\n    iterator for result: Iterable sequence of matching documents.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "query",
                                    "sort_criteria",
                                    "offset",
                                    "limit"
                                ]
                            },
                            {
                                "name": "update_one",
                                "docstring": "Update a single document matching the query.\n\nArgs:\n    collection (str): The collection name.\n    query (dict): The filter query.\n    update (dict): The update document.\n\nReturns:\n    dict: Result of the update operation.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "query",
                                    "update",
                                    "upsert"
                                ]
                            },
                            {
                                "name": "delete_one",
                                "docstring": "Delete a single document matching the query.\n\nArgs:\n    collection (str): The collection name.\n    query (dict): The filter query.\n\nReturns:\n    dict: Result of the delete operation.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "query"
                                ]
                            },
                            {
                                "name": "count",
                                "docstring": "Count how many records are in a collection that match the specified query\n\nArgs:\n    collection (str): The collection name.\n    query (dict): The filter query.\n\nReturns:\n    int: Number of documents that match the specified query",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "query"
                                ]
                            },
                            {
                                "name": "exists",
                                "docstring": "Check if at least one document exists in the collection that matches the\nspecified query\n\nArgs:\n    collection (str): The collection name.\n    query (dict): The filter query.\n\nReturns:\n    bool: True if a document exists and False if it doesn't",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "query"
                                ]
                            },
                            {
                                "name": "create_index",
                                "docstring": "Create an index on a collection in the MongoDB Database\n\nArgs:\n    collection (str): The collection name.\n    index (tuple[IndexExpression]):\n        A tuple of IndexExpression objects representing the index to create\n        NOTE: Multiple elements in tuple indicate a single compound index",
                                "comments": null,
                                "args": [
                                    "self",
                                    "collection",
                                    "index"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "AbstractAsyncMongoDBDriver",
                        "docstring": "Abstract base class for asynchronous MongoDB drivers.\nProvides async context management and coroutine-safe access\nto the currently active driver instance via contextvars.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the MongoDB driver with a connection string and database name.\n\nArgs:\n    connection_string (str): MongoDB connection URI.\n    database_name (str): Target database name.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "connection_string",
                                    "database_name"
                                ]
                            },
                            {
                                "name": "current",
                                "docstring": "Get the current MongoDB driver instance for this coroutine.\n\nReturns:\n    AbstractAsyncMongoDBDriver: The active driver instance.\n\nRaises:\n    RuntimeError: If no driver is currently in context.",
                                "comments": null,
                                "args": [
                                    "cls"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "pydongo/utils/serializer.py",
                "functions": [
                    {
                        "name": "replace_unserializable_fields",
                        "docstring": "Recursively replaces values in a document that are not MongoDB-compatible\nwith serialized equivalents, using registered type handlers.\n\nArgs:\n    document (dict): The original document to sanitize.\n\nReturns:\n    dict: A deep-copied document with serializable values.",
                        "comments": null,
                        "args": [
                            "document"
                        ]
                    },
                    {
                        "name": "restore_unserializable_fields",
                        "docstring": "Recursively attempts to deserialize known types in a document.\n\nNOTE: This is a basic placeholder strategy — it applies all registered deserializers\nwithout knowing the intended field type. This can result in incorrect types.\n\nIt's recommended to use field-aware deserialization (tied to model schemas)\nfor production use.\n\nArgs:\n    document (dict): A document retrieved from MongoDB.\n\nReturns:\n    dict: A deep-copied document with deserialized values (best-effort).",
                        "comments": null,
                        "args": [
                            "document"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "BaseTypeSerializer",
                        "docstring": "Abstract base class for type serializers.\n\nImplementations define how to convert values to and from MongoDB-compatible types.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "serialize",
                                "docstring": "Convert a Python value into a MongoDB-storable format.\n\nArgs:\n    value (Any): The value to serialize.\n\nReturns:\n    Any: A serialized version of the value.",
                                "comments": null,
                                "args": [
                                    "value"
                                ]
                            },
                            {
                                "name": "deserialize",
                                "docstring": "Convert a MongoDB-stored value back to a Python-native type.\n\nArgs:\n    value (Any): The value to deserialize.\n\nReturns:\n    Any: The original Python representation.",
                                "comments": null,
                                "args": [
                                    "value"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "DateSerializer",
                        "docstring": "Serializer for converting `datetime.date` to `datetime.datetime`.\n\nEnsures compatibility with MongoDB, which only supports datetime objects.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "serialize",
                                "docstring": "Serialize a `date` object into a UTC `datetime` object.\n\nArgs:\n    value (datetime.date): The date to serialize.\n\nReturns:\n    datetime.datetime: A datetime object representing midnight of the same date.",
                                "comments": null,
                                "args": [
                                    "value"
                                ]
                            },
                            {
                                "name": "deserialize",
                                "docstring": "Deserialize a `datetime` object back into a `date`.\n\nArgs:\n    value (datetime.datetime): The datetime to convert.\n\nReturns:\n    datetime.date: The date component of the datetime.",
                                "comments": null,
                                "args": [
                                    "value"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "UUIDSerializer",
                        "docstring": "Serializer for UUIDs, converting them to and from strings.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "serialize",
                                "docstring": "Convert a UUID to a string for MongoDB storage.\n\nArgs:\n    value (UUID): The UUID to serialize.\n\nReturns:\n    str: String representation of the UUID.",
                                "comments": null,
                                "args": [
                                    "value"
                                ]
                            },
                            {
                                "name": "deserialize",
                                "docstring": "Convert a string back into a UUID object.\n\nArgs:\n    value (str): UUID string.\n\nReturns:\n    UUID: The corresponding UUID object.",
                                "comments": null,
                                "args": [
                                    "value"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "pydongo/utils/annotations.py",
                "functions": [
                    {
                        "name": "resolve_annotation",
                        "docstring": "Helper function to resolve actual data types from Optional, Union, or Annotated wrappers.\n\nArgs:\n    annotation (Any): Type annotation from the Pydantic model.\n\nReturns:\n    Any: The resolved base type annotation.",
                        "comments": null,
                        "args": [
                            "annotation"
                        ]
                    }
                ],
                "classes": []
            }
        ],
        "test_cases": {
            "tests/test_collection_builder_core.py::test_collection_builder_sort_limit_skip_multi_sort": {
                "testid": "tests/test_collection_builder_core.py::test_collection_builder_sort_limit_skip_multi_sort",
                "result": "passed",
                "test_implementation": "def test_collection_builder_sort_limit_skip_multi_sort():\n    driver = MockMongoDBDriver()\n    driver.connect()\n\n    collection = as_collection(User, driver)\n\n    # 1. Ascending sort\n    q1 = collection.find().sort(collection.age)\n    kwargs1 = q1.build_kwargs()\n    assert kwargs1[\"sort_criteria\"] == {\"age\": 1}\n\n    # 2. Descending sort using -field\n    q2 = collection.find().sort(-collection.name)\n    kwargs2 = q2.build_kwargs()\n    assert kwargs2[\"sort_criteria\"] == {\"name\": -1}\n\n    # 3. Multi-field sort\n    q3 = collection.find().sort([collection.age, -collection.joined])\n    kwargs3 = q3.build_kwargs()\n    assert kwargs3[\"sort_criteria\"] == {\"age\": 1, \"joined\": -1}\n\n    # 4. Sort + skip + limit together\n    q4 = collection.find(collection.age > 21).sort(collection.name).limit(10).skip(3)\n    kwargs4 = q4.build_kwargs()\n\n    assert kwargs4[\"query\"] == {\"age\": {\"$gt\": 21}}\n    assert kwargs4[\"sort_criteria\"] == {\"name\": 1}\n    assert kwargs4[\"limit\"] == 10\n    assert kwargs4[\"offset\"] == 3"
            },
            "tests/test_collection_builder_core.py::test_collection_builder_null_state_defaults": {
                "testid": "tests/test_collection_builder_core.py::test_collection_builder_null_state_defaults",
                "result": "passed",
                "test_implementation": "def test_collection_builder_null_state_defaults():\n    driver = MockMongoDBDriver()\n    driver.connect()\n\n    collection = as_collection(User, driver)\n    query = collection.find()\n\n    kwargs = query.build_kwargs()\n\n    assert kwargs[\"query\"] == {}  # no filter\n    assert kwargs[\"sort_criteria\"] == {}  # no sort\n    assert kwargs.get(\"limit\") is None  # no limit\n    assert kwargs.get(\"offset\") is None  # no skip"
            },
            "tests/test_driver_mock.py::test_insert_and_find_one": {
                "testid": "tests/test_driver_mock.py::test_insert_and_find_one",
                "result": "passed",
                "test_implementation": "def test_insert_and_find_one():\n    driver = MockMongoDBDriver()\n    driver.connect()\n\n    data = {\"name\": \"Alice\", \"age\": 30}\n    result = driver.insert_one(\"users\", data)\n\n    assert \"inserted_id\" in result\n\n    found = driver.find_one(\"users\", {\"name\": \"Alice\"})\n    assert found is not None\n    assert found[\"age\"] == 30"
            },
            "tests/test_driver_mock.py::test_update_and_delete": {
                "testid": "tests/test_driver_mock.py::test_update_and_delete",
                "result": "passed",
                "test_implementation": "def test_update_and_delete():\n    driver = MockMongoDBDriver()\n    driver.connect()\n\n    driver.insert_one(\"users\", {\"name\": \"Bob\", \"age\": 25})\n    driver.update_one(\"users\", {\"name\": \"Bob\"}, {\"$set\": {\"age\": 26}})\n    updated = driver.find_one(\"users\", {\"name\": \"Bob\"})\n\n    assert updated[\"age\"] == 26\n\n    deleted = driver.delete_one(\"users\", {\"name\": \"Bob\"})\n    assert deleted[\"deleted_count\"] == 1"
            },
            "tests/test_field_expression.py::test_comparative_operators_resolve_correct_queries": {
                "testid": "tests/test_field_expression.py::test_comparative_operators_resolve_correct_queries",
                "result": "passed",
                "test_implementation": "def test_comparative_operators_resolve_correct_queries():\n    field = FieldExpression(\"age\")\n\n    eq_expr = (field == 30).serialize()\n    ne_expr = (field != 25).serialize()\n    gt_expr = (field > 18).serialize()\n    gte_expr = (field >= 21).serialize()\n    lt_expr = (field < 60).serialize()\n    lte_expr = (field <= 65).serialize()\n\n    assert eq_expr == {\"age\": {\"$eq\": 30}}\n    assert ne_expr == {\"age\": {\"$ne\": 25}}\n    assert gt_expr == {\"age\": {\"$gt\": 18}}\n    assert gte_expr == {\"age\": {\"$gte\": 21}}\n    assert lt_expr == {\"age\": {\"$lt\": 60}}\n    assert lte_expr == {\"age\": {\"$lte\": 65}}"
            },
            "tests/test_field_expression.py::test_nested_fields": {
                "testid": "tests/test_field_expression.py::test_nested_fields",
                "result": "passed",
                "test_implementation": "def test_nested_fields():\n    parent = FieldExpression(\"friend\", annotation=Friend)\n    child = parent.username\n    assert isinstance(child, FieldExpression)\n    assert child.field_name == \"friend.username\"\n\n    user = FieldExpression(\"user\", annotation=User)\n    child = user.close_friend.username\n    assert isinstance(child, FieldExpression)\n    assert child.field_name == \"user.close_friend.username\"\n\n    # Test field with optional tag\n    user = FieldExpression(\"user\", annotation=User)\n    child = user.best_friend.username\n    assert isinstance(child, FieldExpression)\n    assert child.field_name == \"user.best_friend.username\""
            },
            "tests/test_field_expression.py::test_array_field_size_expression": {
                "testid": "tests/test_field_expression.py::test_array_field_size_expression",
                "result": "passed",
                "test_implementation": "def test_array_field_size_expression():\n    tags = ArrayFieldExpression(\"tags\", annotation=List[str])\n    size_expr = tags.size() > 2\n    assert isinstance(size_expr, CollectionFilterExpression)\n    assert size_expr.serialize() == {\"$expr\": {\"$gt\": [{\"$size\": \"$tags\"}, 2]}}"
            },
            "tests/test_field_expression.py::test_array_field_contains_and_excludes": {
                "testid": "tests/test_field_expression.py::test_array_field_contains_and_excludes",
                "result": "passed",
                "test_implementation": "def test_array_field_contains_and_excludes():\n    tags = ArrayFieldExpression(\"tags\", annotation=List[str])\n    contains_expr = tags.contains(\"python\")\n    excludes_expr = tags.excludes(\"java\")\n\n    assert contains_expr.serialize() == {\"tags\": {\"$in\": \"python\"}}\n    assert excludes_expr.serialize() == {\"tags\": {\"$nin\": \"java\"}}"
            },
            "tests/test_field_expression.py::test_array_field_matches_with_and_without_order": {
                "testid": "tests/test_field_expression.py::test_array_field_matches_with_and_without_order",
                "result": "passed",
                "test_implementation": "def test_array_field_matches_with_and_without_order():\n    tags = ArrayFieldExpression(\"tags\", annotation=List[str])\n    expr_ordered = tags.matches([\"a\", \"b\"], match_order=True)\n    expr_unordered = tags.matches([\"a\", \"b\"], match_order=False)\n\n    assert expr_ordered.serialize() == {\"tags\": [\"a\", \"b\"]}\n    assert expr_unordered.serialize() == {\"tags\": {\"$all\": [\"a\", \"b\"]}}"
            },
            "tests/test_field_expression.py::test_len_and_contains_sugar": {
                "testid": "tests/test_field_expression.py::test_len_and_contains_sugar",
                "result": "passed",
                "test_implementation": "def test_len_and_contains_sugar():\n    tags = ArrayFieldExpression(\"tags\", annotation=List[str])\n    assert isinstance(tags.size(), ArraySizeFieldExpression)\n\n    expr = tags.contains(\"python\")\n    assert expr.serialize() == {\"tags\": {\"$in\": \"python\"}}"
            },
            "tests/test_filter_expression.py::test_with_expression_merges_dict": {
                "testid": "tests/test_filter_expression.py::test_with_expression_merges_dict",
                "result": "passed",
                "test_implementation": "def test_with_expression_merges_dict():\n    expr = CollectionFilterExpression()\n    expr.with_expression({\"name\": {\"$eq\": \"Alice\"}})\n\n    assert expr.serialize() == {\"name\": {\"$eq\": \"Alice\"}}"
            },
            "tests/test_filter_expression.py::test_and_combines_two_expressions": {
                "testid": "tests/test_filter_expression.py::test_and_combines_two_expressions",
                "result": "passed",
                "test_implementation": "def test_and_combines_two_expressions():\n    expr1 = CollectionFilterExpression({\"name\": {\"$eq\": \"Alice\"}})\n    expr2 = CollectionFilterExpression({\"age\": {\"$gt\": 20}})\n    combined = expr1 & expr2\n\n    assert combined.serialize() == {\n        \"$and\": [{\"name\": {\"$eq\": \"Alice\"}}, {\"age\": {\"$gt\": 20}}]\n    }"
            },
            "tests/test_filter_expression.py::test_or_combines_two_expressions": {
                "testid": "tests/test_filter_expression.py::test_or_combines_two_expressions",
                "result": "passed",
                "test_implementation": "def test_or_combines_two_expressions():\n    expr1 = CollectionFilterExpression({\"name\": {\"$eq\": \"Alice\"}})\n    expr2 = CollectionFilterExpression({\"name\": {\"$eq\": \"Bob\"}})\n    combined = expr1 | expr2\n\n    assert combined.serialize() == {\n        \"$or\": [{\"name\": {\"$eq\": \"Alice\"}}, {\"name\": {\"$eq\": \"Bob\"}}]\n    }"
            },
            "tests/test_filter_expression.py::test_not_inverts_expression": {
                "testid": "tests/test_filter_expression.py::test_not_inverts_expression",
                "result": "passed",
                "test_implementation": "def test_not_inverts_expression():\n    expr = CollectionFilterExpression({\"age\": {\"$gt\": 18}})\n    negated = ~expr\n\n    assert negated.serialize() == {\"$not\": {\"age\": {\"$gt\": 18}}}"
            },
            "tests/test_index_creation.py::test_single_key_index": {
                "testid": "tests/test_index_creation.py::test_single_key_index",
                "result": "passed",
                "test_implementation": "def test_single_key_index():\n    collection, driver = _setup()\n    index = collection.name.as_index().use_unique().build_index()\n\n    assert isinstance(index, IndexExpression)\n    collection.use_index(index)\n    collection.find().count()\n\n    _assert_index_registered(collection, driver, 1)"
            },
            "tests/test_index_creation.py::test_compound_index": {
                "testid": "tests/test_index_creation.py::test_compound_index",
                "result": "passed",
                "test_implementation": "def test_compound_index():\n    collection, driver = _setup()\n\n    index1 = (\n        collection.name.as_index()\n        .use_sort_order(IndexSortOrder.ASCENDING)\n        .build_index()\n    )\n    index2 = (\n        collection.email.as_index()\n        .use_sort_order(IndexSortOrder.DESCENDING)\n        .build_index()\n    )\n\n    assert isinstance(index1, IndexExpression)\n    assert isinstance(index2, IndexExpression)\n\n    collection.use_index((index1, index2))\n    collection.find().count()\n\n    _assert_index_registered(collection, driver, 1)\n\n    compound = next(iter(driver.indexes[collection.collection_name]))\n    assert len(compound) == 2"
            },
            "tests/test_index_creation.py::test_text_and_hash_index": {
                "testid": "tests/test_index_creation.py::test_text_and_hash_index",
                "result": "passed",
                "test_implementation": "def test_text_and_hash_index():\n    collection, driver = _setup()\n\n    text_index = collection.bio.as_index().use_index_type(IndexType.TEXT).build_index()\n    hash_index = (\n        collection.hash_id.as_index().use_index_type(IndexType.HASHED).build_index()\n    )\n\n    assert isinstance(text_index, IndexExpression)\n    assert isinstance(hash_index, IndexExpression)\n\n    collection.use_index(text_index)\n    collection.use_index(hash_index)\n    collection.find().count()\n\n    _assert_index_registered(collection, driver, 2)\n\n    index_types = [\n        ix[0].index_type for ix in driver.indexes[collection.collection_name]\n    ]\n    assert IndexType.TEXT in index_types\n    assert IndexType.HASHED in index_types"
            },
            "tests/test_index_creation.py::test_geo_index_types": {
                "testid": "tests/test_index_creation.py::test_geo_index_types",
                "result": "passed",
                "test_implementation": "def test_geo_index_types():\n    collection, driver = _setup()\n\n    index_2d = (\n        collection.latlon.as_index()\n        .use_index_type(IndexType.TWO_DIMENSIONAL)\n        .build_index()\n    )\n    index_2dsphere = (\n        collection.point.as_index()\n        .use_index_type(IndexType.TWO_DIMENSIONAL_SPHERE)\n        .build_index()\n    )\n\n    assert isinstance(index_2d, IndexExpression)\n    assert isinstance(index_2dsphere, IndexExpression)\n\n    collection.use_index(index_2d)\n    collection.use_index(index_2dsphere)\n    collection.find().count()\n\n    _assert_index_registered(collection, driver, 2)\n\n    index_types = [\n        ix[0].index_type for ix in driver.indexes[collection.collection_name]\n    ]\n    assert IndexType.TWO_DIMENSIONAL in index_types\n    assert IndexType.TWO_DIMENSIONAL_SPHERE in index_types"
            },
            "tests/test_index_creation.py::test_index_with_special_kwargs": {
                "testid": "tests/test_index_creation.py::test_index_with_special_kwargs",
                "result": "passed",
                "test_implementation": "def test_index_with_special_kwargs():\n    collection, driver = _setup()\n\n    index = (\n        collection.email.as_index()\n        .use_unique()\n        .use_sparse()\n        .use_index_name(\"email_index\")\n        .use_ttl(3600)\n        .use_collation(locale=\"en\", strength=CollationStrength.SECONDARY)\n        .build_index()\n    )\n\n    assert isinstance(index, IndexExpression)\n    collection.use_index(index)\n    collection.find().count()\n\n    _assert_index_registered(collection, driver, 1)\n\n    created = driver.indexes[collection.collection_name][0][0]\n    kwargs = created.build_kwargs()\n\n    assert kwargs.get(\"unique\") is True\n    assert kwargs.get(\"sparse\") is True\n    assert kwargs.get(\"expireAfterSeconds\") is None, \"TTL for text should be NULL\"\n    assert kwargs.get(\"collation\") == {\"locale\": \"en\", \"strength\": 2}"
            },
            "tests/test_index_creation.py::test_ttl_behavior_for_text_and_other_index_types[text-False]": {
                "testid": "tests/test_index_creation.py::test_ttl_behavior_for_text_and_other_index_types[text-False]",
                "result": "passed",
                "test_implementation": "def test_ttl_behavior_for_text_and_other_index_types(index_type, expect_ttl):\n    builder = IndexExpressionBuilder(field_name=\"test_field\").use_ttl(3600)\n\n    if index_type:\n        builder.use_index_type(index_type)\n\n    index: IndexExpression = builder.build_index()\n    kwargs = index.build_kwargs()\n\n    if expect_ttl:\n        assert \"expireAfterSeconds\" in kwargs\n        assert kwargs[\"expireAfterSeconds\"] == 3600\n    else:\n        assert \"expireAfterSeconds\" not in kwargs"
            },
            "tests/test_index_creation.py::test_ttl_behavior_for_text_and_other_index_types[hashed-False]": {
                "testid": "tests/test_index_creation.py::test_ttl_behavior_for_text_and_other_index_types[hashed-False]",
                "result": "passed",
                "test_implementation": "def test_ttl_behavior_for_text_and_other_index_types(index_type, expect_ttl):\n    builder = IndexExpressionBuilder(field_name=\"test_field\").use_ttl(3600)\n\n    if index_type:\n        builder.use_index_type(index_type)\n\n    index: IndexExpression = builder.build_index()\n    kwargs = index.build_kwargs()\n\n    if expect_ttl:\n        assert \"expireAfterSeconds\" in kwargs\n        assert kwargs[\"expireAfterSeconds\"] == 3600\n    else:\n        assert \"expireAfterSeconds\" not in kwargs"
            },
            "tests/test_index_creation.py::test_ttl_behavior_for_text_and_other_index_types[2d-True]": {
                "testid": "tests/test_index_creation.py::test_ttl_behavior_for_text_and_other_index_types[2d-True]",
                "result": "passed",
                "test_implementation": "def test_ttl_behavior_for_text_and_other_index_types(index_type, expect_ttl):\n    builder = IndexExpressionBuilder(field_name=\"test_field\").use_ttl(3600)\n\n    if index_type:\n        builder.use_index_type(index_type)\n\n    index: IndexExpression = builder.build_index()\n    kwargs = index.build_kwargs()\n\n    if expect_ttl:\n        assert \"expireAfterSeconds\" in kwargs\n        assert kwargs[\"expireAfterSeconds\"] == 3600\n    else:\n        assert \"expireAfterSeconds\" not in kwargs"
            },
            "tests/test_index_creation.py::test_ttl_behavior_for_text_and_other_index_types[2dsphere-True]": {
                "testid": "tests/test_index_creation.py::test_ttl_behavior_for_text_and_other_index_types[2dsphere-True]",
                "result": "passed",
                "test_implementation": "def test_ttl_behavior_for_text_and_other_index_types(index_type, expect_ttl):\n    builder = IndexExpressionBuilder(field_name=\"test_field\").use_ttl(3600)\n\n    if index_type:\n        builder.use_index_type(index_type)\n\n    index: IndexExpression = builder.build_index()\n    kwargs = index.build_kwargs()\n\n    if expect_ttl:\n        assert \"expireAfterSeconds\" in kwargs\n        assert kwargs[\"expireAfterSeconds\"] == 3600\n    else:\n        assert \"expireAfterSeconds\" not in kwargs"
            },
            "tests/test_index_creation.py::test_ttl_behavior_for_text_and_other_index_types[None-True]": {
                "testid": "tests/test_index_creation.py::test_ttl_behavior_for_text_and_other_index_types[None-True]",
                "result": "passed",
                "test_implementation": "def test_ttl_behavior_for_text_and_other_index_types(index_type, expect_ttl):\n    builder = IndexExpressionBuilder(field_name=\"test_field\").use_ttl(3600)\n\n    if index_type:\n        builder.use_index_type(index_type)\n\n    index: IndexExpression = builder.build_index()\n    kwargs = index.build_kwargs()\n\n    if expect_ttl:\n        assert \"expireAfterSeconds\" in kwargs\n        assert kwargs[\"expireAfterSeconds\"] == 3600\n    else:\n        assert \"expireAfterSeconds\" not in kwargs"
            },
            "tests/test_index_creation_async.py::test_single_key_index_async": {
                "testid": "tests/test_index_creation_async.py::test_single_key_index_async",
                "result": "passed",
                "test_implementation": null
            },
            "tests/test_index_creation_async.py::test_compound_index_async": {
                "testid": "tests/test_index_creation_async.py::test_compound_index_async",
                "result": "passed",
                "test_implementation": null
            },
            "tests/test_index_creation_async.py::test_text_and_hash_index_async": {
                "testid": "tests/test_index_creation_async.py::test_text_and_hash_index_async",
                "result": "passed",
                "test_implementation": null
            },
            "tests/test_index_creation_async.py::test_geo_index_types_async": {
                "testid": "tests/test_index_creation_async.py::test_geo_index_types_async",
                "result": "passed",
                "test_implementation": null
            },
            "tests/test_index_creation_async.py::test_index_with_special_kwargs_async": {
                "testid": "tests/test_index_creation_async.py::test_index_with_special_kwargs_async",
                "result": "passed",
                "test_implementation": null
            },
            "tests/test_resolve_annotation.py::test_resolve_annotation_union": {
                "testid": "tests/test_resolve_annotation.py::test_resolve_annotation_union",
                "result": "passed",
                "test_implementation": "def test_resolve_annotation_union():\n    assert resolve_annotation(Union[int, str]) == int\n    assert resolve_annotation(Union[None, float]) == float\n    assert resolve_annotation(Union[float, None]) == float"
            },
            "tests/test_resolve_annotation.py::test_resolve_annotation_optional": {
                "testid": "tests/test_resolve_annotation.py::test_resolve_annotation_optional",
                "result": "passed",
                "test_implementation": "def test_resolve_annotation_optional():\n    assert resolve_annotation(Optional[str]) == str\n    assert resolve_annotation(Optional[Union[str, None]]) == str"
            },
            "tests/test_resolve_annotation.py::test_resolve_annotation_annotated": {
                "testid": "tests/test_resolve_annotation.py::test_resolve_annotation_annotated",
                "result": "passed",
                "test_implementation": "def test_resolve_annotation_annotated():\n    assert resolve_annotation(Annotated[int, \"meta\"]) == int\n    assert resolve_annotation(Annotated[Optional[int], \"meta\"]) == int"
            },
            "tests/test_serilizer_utils.py::test_date_serialization": {
                "testid": "tests/test_serilizer_utils.py::test_date_serialization",
                "result": "passed",
                "test_implementation": "def test_date_serialization():\n    today = datetime.date.today()\n    document = {\"created_at\": today}\n    serialized = replace_unserializable_fields(document.copy())\n\n    assert isinstance(serialized[\"created_at\"], datetime.datetime)\n    assert serialized[\"created_at\"].date() == today"
            },
            "tests/test_serilizer_utils.py::test_uuid_serialization": {
                "testid": "tests/test_serilizer_utils.py::test_uuid_serialization",
                "result": "passed",
                "test_implementation": "def test_uuid_serialization():\n    test_uuid = uuid.uuid4()\n    document = {\"id\": test_uuid}\n    serialized = replace_unserializable_fields(document.copy())\n\n    assert isinstance(serialized[\"id\"], str)\n    assert serialized[\"id\"] == str(test_uuid)"
            },
            "tests/test_serilizer_utils.py::test_nested_serialization": {
                "testid": "tests/test_serilizer_utils.py::test_nested_serialization",
                "result": "passed",
                "test_implementation": "def test_nested_serialization():\n    data = {\n        \"meta\": {\n            \"created_at\": datetime.date.today(),\n            \"uuid\": uuid.uuid4(),\n        },\n        \"tags\": [uuid.uuid4(), uuid.uuid4()],\n    }\n\n    serialized = replace_unserializable_fields(data.copy())\n    assert isinstance(serialized[\"meta\"][\"created_at\"], datetime.datetime)\n    assert all(isinstance(t, str) for t in serialized[\"tags\"])"
            }
        },
        "SRS_document": "# Software Requirements Specification: Pydongo\n\n## 1. Introduction\n\n### 1.1 Purpose\nThis Software Requirements Specification (SRS) document outlines the functional and non-functional requirements for Pydongo, a Python Object-Relational Mapper (ORM) for MongoDB. The primary purpose of this SRS is to serve as a definitive guide for software developers who will be assessed on their ability to implement Pydongo based solely on this document and a provided subset of test cases. Their success will be measured by passing all original test cases, including private ones. Therefore, this document prioritizes clarity, comprehensiveness in functionality, and an appropriate level of abstraction to allow for independent design and implementation choices.\n\n### 1.2 Scope\nPydongo is a lightweight library facilitating interaction with MongoDB databases using Pydantic models. It aims to provide:\n*   An expressive Domain Specific Language (DSL) for querying.\n*   A simple document interface for Create, Read, Update, Delete (CRUD) operations on Pydantic model instances.\n*   Support for both synchronous (via PyMongo) and asynchronous (via Motor) MongoDB drivers.\n*   Integration with Pydantic for data validation and schema definition.\n*   Testability through mock database drivers.\n\nThis SRS covers all essential functional capabilities necessary to achieve this scope, focusing on externally observable behaviors, inputs, outputs, and key processing rules.\n\n### 1.3 Definitions, Acronyms, and Abbreviations\n*   **ORM:** Object-Relational Mapper. In this context, an Object-Document Mapper, as MongoDB is document-oriented.\n*   **DSL:** Domain Specific Language.\n*   **CRUD:** Create, Read, Update, Delete.\n*   **MongoDB:** A NoSQL document-oriented database.\n*   **Pydantic:** A Python library for data validation and settings management using Python type annotations.\n*   **PyMongo:** The official synchronous Python driver for MongoDB.\n*   **Motor:** The official asynchronous Python driver for MongoDB.\n*   **SRS:** Software Requirements Specification.\n*   **API:** Application Programming Interface.\n*   **TTL:** Time-To-Live (for database indexes).\n*   **UUID:** Universally Unique Identifier.\n\n### 1.4 References\n*   Pydongo Project README (provided as context).\n*   Original Pydongo source code (for LLM contextual understanding only, not for developer reference during assessment).\n*   Original Pydongo test cases (for LLM contextual understanding and SRS validation; a subset for developer use).\n*   Pydantic Documentation: [https://docs.pydantic.dev/](https://docs.pydantic.dev/)\n*   MongoDB Manual: [https://www.mongodb.com/docs/manual/](https://www.mongodb.com/docs/manual/)\n\n### 1.5 Overview\nThis SRS is organized into three main sections:\n*   **Section 1 (Introduction):** Provides context for the SRS document.\n*   **Section 2 (Overall Description):** Offers a high-level overview of Pydongo, its features, intended users, and operational constraints.\n*   **Section 3 (Specific Requirements):** Details the functional requirements, non-functional requirements (if any based on test validation), external interface requirements, and data requirements. This section is critical for developers implementing the system.\n\n## 2. Overall Description\n\n### 2.1 Product Perspective\nPydongo is a Python library intended to simplify MongoDB interactions for applications that use Pydantic for data modeling. It acts as an abstraction layer over MongoDB drivers (PyMongo and Motor), allowing developers to work with MongoDB in a more Pythonic and object-oriented way. It is not a comprehensive, heavy-weight ORM but rather a focused tool providing essential ORM-like features.\n\n### 2.2 Product Functions\nThe Pydongo library will provide the following key functionalities:\n1.  **Driver Abstraction:** Support for synchronous, asynchronous, and mock MongoDB drivers through a common interface.\n2.  **Pydantic Model Integration:** Use of Pydantic models as the basis for schema definition and data exchange with MongoDB.\n3.  **Document Persistence:** An interface to treat Pydantic model instances as active records, allowing them to be saved (inserted/updated) and deleted from the database.\n4.  **Collection Querying:** An interface to build and execute queries against MongoDB collections associated with Pydantic models.\n5.  **Expressive Query DSL:** A Pythonic DSL for constructing MongoDB query filters using comparison and logical operators on model fields.\n6.  **Query Execution Control:** Options to sort, limit, and skip results from queries.\n7.  **Index Management:** A mechanism to define and create various types of MongoDB indexes on collections.\n8.  **Data Serialization/Deserialization:** Automatic handling of common Python types (like `datetime.date`, `uuid.UUID`) for MongoDB compatibility.\n9.  **Type Annotation Utilities:** Helpers for inspecting Pydantic model type annotations.\n\n### 2.3 User Characteristics\nThe primary users of Pydongo are Python developers building applications that require MongoDB as a data store and who prefer to use Pydantic for data modeling and validation. Users are expected to be familiar with Python, Pydantic, and basic MongoDB concepts.\n\n### 2.4 Constraints\n*   The system must be implemented in Python.\n*   The system must be compatible with Python 3.9 or newer.\n*   The system must use Pydantic (version 2.x implied by `model_dump`) for data modeling.\n*   The system will depend on `pymongo` for synchronous operations and `motor` for asynchronous operations when interacting with a real MongoDB database.\n*   The system must adhere to the functional capabilities described herein to pass all (public and private) test cases.\n\n### 2.5 Assumptions and Dependencies\n*   Users will have a MongoDB instance accessible for applications using the live drivers.\n*   Pydantic, PyMongo, and Motor libraries are available in the Python environment where Pydongo is used or installed as dependencies.\n*   Users understand how to define Pydantic models.\n\n## 3. Specific Requirements\n\n### 3.1 Functional Requirements\n\n#### 3.1.1 Core Driver Abstraction\n*   **FR-DRV-001:** The system shall provide an abstraction layer for database driver interactions, defining common interfaces for synchronous and asynchronous operations.\n*   **FR-DRV-002:** The system shall provide a synchronous MongoDB driver implementation that utilizes an underlying synchronous MongoDB client library (e.g., PyMongo) for blocking database operations.\n*   **FR-DRV-003:** The system shall provide an asynchronous MongoDB driver implementation that utilizes an underlying asynchronous MongoDB client library (e.g., Motor) for non-blocking database operations.\n*   **FR-DRV-004:** The system shall provide a synchronous in-memory mock driver implementation for testing purposes, mimicking the synchronous driver interface without requiring a live database.\n*   **FR-DRV-005:** The system shall provide an asynchronous in-memory mock driver implementation for testing purposes, mimicking the asynchronous driver interface without requiring a live database.\n*   **FR-DRV-006:** All driver types (synchronous, asynchronous, mock sync, mock async) shall support an operation to establish a connection to their respective data source.\n*   **FR-DRV-007:** All driver types (synchronous, asynchronous, mock sync, mock async) shall support an operation to close the connection to their respective data source.\n*   **FR-DRV-008:** Synchronous drivers (live and mock) shall provide an operation to insert a single document into a specified collection and return an identifier for the inserted document.\n*   **FR-DRV-009:** Synchronous drivers (live and mock) shall provide an operation to insert multiple documents into a specified collection and return identifiers for the inserted documents.\n*   **FR-DRV-010:** Synchronous drivers (live and mock) shall provide an operation to find a single document in a specified collection that matches a given query.\n*   **FR-DRV-011:** Synchronous drivers (live and mock) shall provide an operation to find multiple documents in a specified collection matching a given query, with support for specifying sort order, an offset for results, and a limit on the number of results.\n*   **FR-DRV-012:** Synchronous drivers (live and mock) shall provide an operation to update a single document in a specified collection that matches a given query, using a provided update specification.\n*   **FR-DRV-013:** Synchronous drivers (live and mock) shall provide an operation to delete a single document from a specified collection that matches a given query.\n*   **FR-DRV-014:** Synchronous drivers (live and mock) shall provide an operation to count the number of documents in a specified collection that match a given query.\n*   **FR-DRV-015:** Synchronous drivers (live and mock) shall provide an operation to check for the existence of at least one document in a specified collection that matches a given query.\n*   **FR-DRV-016:** Synchronous drivers (live and mock) shall provide an operation to create one or more indexes on a specified collection based on provided index specifications.\n*   **FR-DRV-017:** Asynchronous drivers (live and mock) shall provide an operation to asynchronously insert a single document into a specified collection and return an identifier for the inserted document.\n*   **FR-DRV-018:** Asynchronous drivers (live and mock) shall provide an operation to asynchronously insert multiple documents into a specified collection and return identifiers for the inserted documents.\n*   **FR-DRV-019:** Asynchronous drivers (live and mock) shall provide an operation to asynchronously find a single document in a specified collection that matches a given query.\n*   **FR-DRV-020:** Asynchronous drivers (live and mock) shall provide an operation to asynchronously find multiple documents in a specified collection matching a given query, with support for specifying sort order, an offset for results, and a limit on the number of results.\n*   **FR-DRV-021:** Asynchronous drivers (live and mock) shall provide an operation to asynchronously update a single document in a specified collection that matches a given query, using a provided update specification.\n*   **FR-DRV-022:** Asynchronous drivers (live and mock) shall provide an operation to asynchronously delete a single document from a specified collection that matches a given query.\n*   **FR-DRV-023:** Asynchronous drivers (live and mock) shall provide an operation to asynchronously count the number of documents in a specified collection that match a given query.\n*   **FR-DRV-024:** Asynchronous drivers (live and mock) shall provide an operation to asynchronously check for the existence of at least one document in a specified collection that matches a given query.\n*   **FR-DRV-025:** Asynchronous drivers (live and mock) shall provide an operation to asynchronously create one or more indexes on a specified collection based on provided index specifications.\n\n#### 3.1.2 Pydantic Model Integration\n*   **FR-MOD-001:** The system shall utilize Pydantic models as the primary mechanism for defining the schema of data to be stored in and retrieved from MongoDB.\n*   **FR-MOD-002:** The system shall determine the MongoDB collection name associated with a Pydantic model. If the Pydantic model has a `collection_name` attribute, its value shall be used. Otherwise, the model's class name shall be used as the collection name.\n\n#### 3.1.3 Document Persistence Interface (`as_document`)\n*   **FR-DOC-001:** The system shall provide a top-level function (e.g., `as_document`) that accepts a Pydantic model instance and a database driver, returning a \"document worker\" object. This worker object shall provide methods for database persistence.\n*   **FR-DOC-002:** For synchronous drivers, the document worker shall provide a synchronous `save` method to persist the Pydantic model instance's data to the database.\n*   **FR-DOC-003:** If the `save` method (synchronous) is called on a document worker representing a new Pydantic instance (i.e., one not yet persisted or lacking a database-assigned identifier), an insert operation shall be performed in the database. The worker shall subsequently be aware of the database-assigned identifier.\n*   **FR-DOC-004:** If the `save` method (synchronous) is called on a document worker representing an already persisted Pydantic instance (i.e., one with a database-assigned identifier), an update operation shall be performed on the corresponding document in the database. The update operation should use the MongoDB `$set` operator with the serialized current state of the Pydantic model instance.\n*   **FR-DOC-005:** For synchronous drivers, the document worker shall provide a synchronous `delete` method to remove the corresponding document from the database. The document to be deleted is identified by its database-assigned identifier or its serialized content if no identifier is present.\n*   **FR-DOC-006:** For asynchronous drivers, the document worker shall provide an asynchronous `save` method with behavior analogous to FR-DOC-003 and FR-DOC-004 for insert and update operations, respectively.\n*   **FR-DOC-007:** For asynchronous drivers, the document worker shall provide an asynchronous `delete` method with behavior analogous to FR-DOC-005.\n*   **FR-DOC-008:** Attribute access on a document worker instance shall be proxied to the underlying Pydantic model instance it wraps.\n*   **FR-DOC-009:** Persistence operations (`save`, `delete`) executed via the document worker shall target the MongoDB collection associated with the Pydantic model (as determined by FR-MOD-002).\n*   **FR-DOC-010:** Prior to any `save` operation, the Pydantic model instance data within the document worker shall be serialized into a MongoDB-compatible dictionary format. This includes custom serialization for specific types (see 3.1.8).\n\n#### 3.1.4 Collection Querying Interface (`as_collection`)\n*   **FR-COL-001:** The system shall provide a top-level function (e.g., `as_collection`) that accepts a Pydantic model type (class) and a database driver, returning a \"collection worker\" object. This worker object represents the MongoDB collection for that model type and is the entry point for querying.\n*   **FR-COL-002:** For synchronous drivers, the collection worker shall provide a synchronous `find_one` method. This method accepts a filter expression and returns a single document worker instance (wrapping the Pydantic model) that matches the filter, or `None` if no match is found.\n*   **FR-COL-003:** For asynchronous drivers, the collection worker shall provide an asynchronous `afind_one` method. This method accepts a filter expression and asynchronously returns a single document worker instance (wrapping the Pydantic model) that matches the filter, or `None` if no match is found.\n*   **FR-COL-004:** The collection worker shall provide a `find` method that accepts an optional filter expression. This method returns a query builder object, allowing for further refinement (sorting, limiting, skipping) and execution of the query. If no filter expression is provided, the query builder should target all documents in the collection.\n*   **FR-COL-005:** The collection worker shall provide a `use_index` method to register one or more index definitions (single field index or a tuple for compound index) to be associated with the collection. These indexes are intended for creation on the underlying MongoDB collection.\n*   **FR-COL-006:** Documents retrieved from the database via `find_one`, `afind_one`, or through a query builder's execution methods (`all`) must be deserialized from MongoDB's format. The deserialized data must be used to instantiate the Pydantic model type associated with the collection worker, and this Pydantic instance must then be wrapped in an appropriate document worker.\n\n#### 3.1.5 Query Expression DSL\n\n##### 3.1.5.1 Field Expressions\n*   **FR-QDSL-001:** The system shall allow the creation of \"field expressions\" by accessing attributes on a collection worker instance, where attribute names correspond to field names in the associated Pydantic model (e.g., `collection_worker.user_name`).\n*   **FR-QDSL-002:** Field expressions shall support the equality comparison operator (`==`) with a value, generating a filter condition equivalent to MongoDB's `$eq` operator.\n*   **FR-QDSL-003:** Field expressions shall support the inequality comparison operator (`!=`) with a value, generating a filter condition equivalent to MongoDB's `$ne` operator.\n*   **FR-QDSL-004:** Field expressions shall support the greater than comparison operator (`>`) with a value, generating a filter condition equivalent to MongoDB's `$gt` operator.\n*   **FR-QDSL-005:** Field expressions shall support the greater than or equal to comparison operator (`>=`) with a value, generating a filter condition equivalent to MongoDB's `$gte` operator.\n*   **FR-QDSL-006:** Field expressions shall support the less than comparison operator (`<`) with a value, generating a filter condition equivalent to MongoDB's `$lt` operator.\n*   **FR-QDSL-007:** Field expressions shall support the less than or equal to comparison operator (`<=`) with a value, generating a filter condition equivalent to MongoDB's `$lte` operator.\n*   **FR-QDSL-008:** The system shall support chained attribute access on field expressions to construct references to fields within nested Pydantic models (e.g., `collection_worker.parent_field.child_field`), generating dot-notation field paths for MongoDB queries.\n*   **FR-QDSL-009:** For field expressions representing an array/list field in the Pydantic model:\n    *   **FR-QDSL-009-A:** The system shall provide a way to query based on the size of the array (e.g., `collection_worker.array_field.size() > N`, or `len(collection_worker.array_field) > N`), generating a filter condition equivalent to MongoDB's `$expr` with `$size`.\n    *   **FR-QDSL-009-B:** The system shall provide a way to check if the array `contains` a specified value or any of a list of specified values (element presence), generating a filter condition equivalent to MongoDB's `$in` operator. This should also be achievable via Python's `in` operator (e.g., `value in collection_worker.array_field`).\n    *   **FR-QDSL-009-C:** The system shall provide a way to check if the array `excludes` a specified value or all of a list of specified values (element absence), generating a filter condition equivalent to MongoDB's `$nin` operator.\n    *   **FR-QDSL-009-D:** The system shall provide a way to check if the array `matches` a given list of elements. If `match_order` is true, it generates an exact match query. If `match_order` is false, it generates a filter condition equivalent to MongoDB's `$all` operator.\n*   **FR-QDSL-010:** Applying the unary negation operator (`-`) to a field expression (e.g., `-collection_worker.field_name`) shall produce a new field expression instance configured to indicate descending sort order when used in sorting operations.\n\n##### 3.1.5.2 Filter Expression Composition\n*   **FR-QDSL-011:** The system shall allow two filter expressions to be combined using a logical AND operator (`&`), resulting in a new filter expression that represents the conjunction of the two, equivalent to MongoDB's `$and` operator.\n*   **FR-QDSL-012:** The system shall allow two filter expressions to be combined using a logical OR operator (`|`), resulting in a new filter expression that represents the disjunction of the two, equivalent to MongoDB's `$or` operator.\n*   **FR-QDSL-013:** The system shall allow a filter expression to be inverted using a logical NOT operator (`~`), resulting in a new filter expression that represents the negation of the original, equivalent to MongoDB's `$not` operator.\n*   **FR-QDSL-014:** A filter expression that is empty or in its default state (e.g., created without specific conditions) shall represent a query that matches all documents in the collection (an empty MongoDB query filter `{}`).\n\n#### 3.1.6 Query Execution and Result Handling (Query Builder methods)\n*   **FR-QRH-001:** The query builder object (returned by `collection_worker.find()`) shall support a `sort` method to specify sorting criteria for the query results.\n    *   **FR-QRH-001-A:** Sorting shall be specifiable by a single field expression (FR-QDSL-001, FR-QDSL-010), indicating ascending or descending order.\n    *   **FR-QRH-001-B:** Sorting shall be specifiable by a list/sequence of field expressions to enable multi-key sorting.\n*   **FR-QRH-002:** The query builder shall support a `limit` method to restrict the maximum number of documents returned by the query.\n*   **FR-QRH-003:** The query builder shall support a `skip` method (or equivalent `offset` concept) to bypass a specified number of documents from the beginning of the result set.\n*   **FR-QRH-004:** For synchronous operations, the query builder shall provide an `all()` method that executes the constructed query and returns an iterable of document worker instances representing the matching documents.\n*   **FR-QRH-005:** For asynchronous operations, the query builder shall provide an `all()` method that asynchronously executes the constructed query and returns a list of document worker instances representing the matching documents.\n*   **FR-QRH-006:** For synchronous operations, the query builder shall provide a `count()` method that executes the query and returns the total number of documents matching the filter criteria.\n*   **FR-QRH-007:** For asynchronous operations, the query builder shall provide a `count()` method that asynchronously executes the query and returns the total number of documents matching the filter criteria.\n*   **FR-QRH-008:** For synchronous operations, the query builder shall provide an `exists()` method that executes a query to determine if at least one document matches the filter criteria, returning a boolean.\n*   **FR-QRH-009:** For asynchronous operations, the query builder shall provide an `exists()` method that asynchronously executes a query to determine if at least one document matches the filter criteria, returning a boolean.\n*   **FR-QRH-010:** The query builder shall internally compile the specified filter expression, sort criteria, limit, and skip values into a consolidated set of parameters (e.g., a dictionary) suitable for passing to the underlying database driver's find operation.\n\n#### 3.1.7 Index Management\n*   **FR-IDX-001:** The system shall allow the definition of a single-field index on a collection. This can be initiated from a field expression (e.g., `collection.field.as_index()`).\n*   **FR-IDX-002:** The system shall allow the definition of a compound index, involving multiple fields, by passing a tuple of individual field index expressions to the collection's `use_index` method.\n*   **FR-IDX-003:** Index definitions shall support specifying the sort order (ascending or descending) for each field participating in the index.\n*   **FR-IDX-004:** Index definitions shall support specifying one of the following MongoDB index types: TEXT, HASHED, TWO_DIMENSIONAL, TWO_DIMENSIONAL_SPHERE.\n*   **FR-IDX-005:** Index definitions shall support a 'unique' constraint option to ensure indexed fields do not store duplicate values.\n*   **FR-IDX-006:** Index definitions shall support a 'sparse' option, so the index only references documents that contain the indexed field.\n*   **FR-IDX-007:** Index definitions shall support specifying a Time-To-Live (TTL) duration in seconds (via an `expireAfterSeconds` option) for automatic document removal.\n    *   **FR-IDX-007-A:** The TTL option (`expireAfterSeconds`) shall not be applied by the system when generating index creation parameters if the specified index type is TEXT or HASHED, as MongoDB does not support TTL for these index types.\n*   **FR-IDX-008:** Index definitions shall support specifying collation options, including `locale` (string) and `strength` (from a predefined set: PRIMARY, SECONDARY, TERTIARY, QUATERNARY, IDENTICAL).\n*   **FR-IDX-009:** Index definitions shall support specifying a custom `name` for the index.\n*   **FR-IDX-010:** Index definitions shall support specifying a `partialFilterExpression` (using a standard filter expression object) to create partial indexes that only include documents matching the filter.\n*   **FR-IDX-011:** Index definitions shall support a 'hidden' option for the index.\n*   **FR-IDX-012:** Any indexes registered on a collection worker (via `use_index`) shall be automatically created on the MongoDB collection by the driver if they do not already exist. This creation should occur no later than the first execution of a data-retrieval or counting operation (e.g., `all()`, `count()`, `exists()`) initiated through a query builder associated with that collection worker.\n\n#### 3.1.8 Data Serialization and Deserialization\n*   **FR-SER-001:** The system shall automatically serialize Python `datetime.date` objects to MongoDB-compatible `datetime.datetime` objects before persistence. The time component of the resulting `datetime.datetime` object should represent the beginning of the day (e.g., midnight).\n*   **FR-SER-002:** The system shall automatically serialize Python `uuid.UUID` objects to their string representations before database persistence.\n*   **FR-SER-003:** The automatic serialization process (for types like `datetime.date`, `uuid.UUID`) shall correctly handle these types when they are found within nested data structures (e.g., dictionaries, lists, tuples, sets) inside the document being prepared for MongoDB.\n*   **FR-SER-004:** When data is retrieved from MongoDB, the system shall provide a mechanism to attempt deserialization of `datetime.datetime` objects (that were originally `datetime.date`) back into `datetime.date` objects by taking the date component.\n*   **FR-SER-005:** When data is retrieved from MongoDB, the system shall provide a mechanism to attempt deserialization of string representations of UUIDs back into `uuid.UUID` objects.\n*   **FR-SER-006:** The deserialization process for custom types shall attempt to handle these types when they are found within nested data structures retrieved from MongoDB.\n*   **FR-SER-007:** When values of types `datetime.date` or `uuid.UUID` are used in field expression comparisons (e.g., `collection.date_field == my_date_obj`), these values shall be serialized to their MongoDB-compatible representations before constructing the query filter.\n\n#### 3.1.9 Type Annotation Utilities\n*   **FR-UTIL-001:** The system shall provide a utility function that, given a Python type annotation, resolves it to its primary underlying data type. For `typing.Union` (e.g., `Union[int, str]`, `Union[None, float]`), it should return the first non-None type if multiple types are present, or the single type if only one non-None type exists.\n*   **FR-UTIL-002:** The type resolution utility shall correctly extract the underlying type `X` from `typing.Optional[X]` (which is equivalent to `Union[X, None]`).\n*   **FR-UTIL-003:** The type resolution utility shall correctly extract the underlying type `X` from `typing.Annotated[X, ...]` by recursively resolving `X`.\n\n### 3.2 Non-Functional Requirements\nThere are no non-functional requirements explicitly validated by dedicated test cases in the provided materials. The library's design promotes testability (e.g., through mock drivers), which is a quality attribute, but not an NFR with a specific, measurable, testable criterion from the test suite.\n\n### 3.3 External Interface Requirements\n*   **EIR-001:** The system shall generate MongoDB query filter documents that conform to the MongoDB query language syntax for field comparison operations (e.g., `{\"field_name\": {\"$operator\": value}}` where `$operator` is one of `$eq`, `$ne`, `$gt`, `$gte`, `$lt`, `$lte`).\n*   **EIR-002:** The system shall generate MongoDB query filter documents that conform to the MongoDB query language syntax for logical composition of sub-filters (e.g., `{\"$and\": [filter1, filter2]}`, `{\"$or\": [filter1, filter2]}`, `{\"$not\": {filter}}`).\n*   **EIR-003:** The system shall generate MongoDB query filter documents that conform to the MongoDB query language syntax for array-specific operations, including array size checks (using `$expr` and `$size`), element containment (using `$in` or exact match for single element), element exclusion (using `$nin`), and matching all elements (using `$all` or exact array match).\n*   **EIR-004:** The system's live database drivers (synchronous and asynchronous) shall connect to MongoDB instances using standard MongoDB connection URI strings.\n*   **EIR-005:** The parameters generated by the system for MongoDB index creation (including index keys, sort order, type, and options like `unique`, `sparse`, `expireAfterSeconds`, `collation`, `name`, `partialFilterExpression`, `hidden`) must conform to the specifications of MongoDB's `createIndex` command or its driver equivalents.\n\n### 3.4 Data Requirements\n*   **DR-001:** The system is designed to work with data schemas defined as Pydantic V2 models (inheriting from `pydantic.BaseModel`).\n*   **DR-002:** MongoDB documents are generally expected to have an `_id` field managed by MongoDB, which the system may use as a database-assigned identifier for operations like updates and for tracking inserted documents. Wrapped document instances populated from the database should store this identifier.\n",
        "structured_requirements": [
            {
                "requirement_id": "FR-DRV-001",
                "requirement_description": "The system shall provide an abstraction layer for database driver interactions, defining common interfaces for synchronous and asynchronous operations.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/base.py::AbstractSyncMongoDBDriver",
                        "description": ""
                    },
                    {
                        "id": "pydongo/drivers/base.py::AbstractAsyncMongoDBDriver",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-002",
                "requirement_description": "The system shall provide a synchronous MongoDB driver implementation that utilizes an underlying synchronous MongoDB client library (e.g., PyMongo) for blocking database operations.",
                "test_traceability": [
                    {
                        "id": "examples/sync/medtech_app.py",
                        "description": "if executed against a live DB). Tested via mock driver which mimics its interface."
                    },
                    {
                        "id": "examples/sync/social_media_app.py",
                        "description": "if executed against a live DB). Tested via mock driver which mimics its interface."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/sync_mongo.py::DefaultMongoDBDriver",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-003",
                "requirement_description": "The system shall provide an asynchronous MongoDB driver implementation that utilizes an underlying asynchronous MongoDB client library (e.g., Motor) for non-blocking database operations.",
                "test_traceability": [
                    {
                        "id": "examples/async/social_media_app.py",
                        "description": "if executed against a live DB). Tested via mock driver which mimics its interface."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/async_mongo.py::AsyncDefaultMongoDBDriver",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-004",
                "requirement_description": "The system shall provide a synchronous in-memory mock driver implementation for testing purposes, mimicking the synchronous driver interface without requiring a live database.",
                "test_traceability": [
                    {
                        "id": "tests/test_driver_mock.py::test_insert_and_find_one",
                        "description": ""
                    },
                    {
                        "id": "tests/test_driver_mock.py::test_update_and_delete",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/mock.py::MockMongoDBDriver",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-005",
                "requirement_description": "The system shall provide an asynchronous in-memory mock driver implementation for testing purposes, mimicking the asynchronous driver interface without requiring a live database.",
                "test_traceability": [
                    {
                        "id": "tests/test_index_creation_async.py",
                        "description": "setup uses `MockAsyncMongoDBDriver`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/mock.py::MockAsyncMongoDBDriver",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-006",
                "requirement_description": "All driver types (synchronous, asynchronous, mock sync, mock async) shall support an operation to establish a connection to their respective data source.",
                "test_traceability": [
                    {
                        "id": "tests/test_driver_mock.py::test_insert_and_find_one",
                        "description": "calls `driver.connect()`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/base.py::AbstractSyncMongoDBDriver::connect",
                        "description": ""
                    },
                    {
                        "id": "pydongo/drivers/base.py::AbstractAsyncMongoDBDriver::connect",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-007",
                "requirement_description": "All driver types (synchronous, asynchronous, mock sync, mock async) shall support an operation to close the connection to their respective data source.",
                "test_traceability": [
                    {
                        "id": "examples/sync/medtech_app.py",
                        "description": "implicitly if driver was a context manager or if tests called close) - shows `driver.close()`."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/base.py::AbstractSyncMongoDBDriver::close",
                        "description": ""
                    },
                    {
                        "id": "pydongo/drivers/base.py::AbstractAsyncMongoDBDriver::close",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-008",
                "requirement_description": "Synchronous drivers (live and mock) shall provide an operation to insert a single document into a specified collection and return an identifier for the inserted document.",
                "test_traceability": [
                    {
                        "id": "tests/test_driver_mock.py::test_insert_and_find_one",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/base.py::AbstractSyncMongoDBDriver::insert_one",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-009",
                "requirement_description": "Synchronous drivers (live and mock) shall provide an operation to insert multiple documents into a specified collection and return identifiers for the inserted documents.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/base.py::AbstractSyncMongoDBDriver::insert_many",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-010",
                "requirement_description": "Synchronous drivers (live and mock) shall provide an operation to find a single document in a specified collection that matches a given query.",
                "test_traceability": [
                    {
                        "id": "tests/test_driver_mock.py::test_insert_and_find_one",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/base.py::AbstractSyncMongoDBDriver::find_one",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-011",
                "requirement_description": "Synchronous drivers (live and mock) shall provide an operation to find multiple documents in a specified collection matching a given query, with support for specifying sort order, an offset for results, and a limit on the number of results.",
                "test_traceability": [
                    {
                        "id": "tests/test_collection_builder_core.py",
                        "description": "implicitly tests find_many through collection builder with mock driver)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/base.py::AbstractSyncMongoDBDriver::find_many",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-012",
                "requirement_description": "Synchronous drivers (live and mock) shall provide an operation to update a single document in a specified collection that matches a given query, using a provided update specification.",
                "test_traceability": [
                    {
                        "id": "tests/test_driver_mock.py::test_update_and_delete",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/base.py::AbstractSyncMongoDBDriver::update_one",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-013",
                "requirement_description": "Synchronous drivers (live and mock) shall provide an operation to delete a single document from a specified collection that matches a given query.",
                "test_traceability": [
                    {
                        "id": "tests/test_driver_mock.py::test_update_and_delete",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/base.py::AbstractSyncMongoDBDriver::delete_one",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-014",
                "requirement_description": "Synchronous drivers (live and mock) shall provide an operation to count the number of documents in a specified collection that match a given query.",
                "test_traceability": [
                    {
                        "id": "tests/test_index_creation.py",
                        "description": "uses `.count()` which calls driver `count` via `SyncCollectionResponseBuilder`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/base.py::AbstractSyncMongoDBDriver::count",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-015",
                "requirement_description": "Synchronous drivers (live and mock) shall provide an operation to check for the existence of at least one document in a specified collection that matches a given query.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/base.py::AbstractSyncMongoDBDriver::exists",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-016",
                "requirement_description": "Synchronous drivers (live and mock) shall provide an operation to create one or more indexes on a specified collection based on provided index specifications.",
                "test_traceability": [
                    {
                        "id": "tests/test_index_creation.py",
                        "description": "uses mock driver's `create_index` via `SyncCollectionResponseBuilder`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/base.py::AbstractSyncMongoDBDriver::create_index",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-017",
                "requirement_description": "Asynchronous drivers (live and mock) shall provide an operation to asynchronously insert a single document into a specified collection and return an identifier for the inserted document.",
                "test_traceability": [
                    {
                        "id": "examples/async/social_media_app.py",
                        "description": "uses it) `MockAsyncMongoDBDriver::insert_one` tested via `AsyncDocumentWorker.save` indirectly."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/base.py::AbstractAsyncMongoDBDriver::insert_one",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-018",
                "requirement_description": "Asynchronous drivers (live and mock) shall provide an operation to asynchronously insert multiple documents into a specified collection and return identifiers for the inserted documents.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/base.py::AbstractAsyncMongoDBDriver::insert_many",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-019",
                "requirement_description": "Asynchronous drivers (live and mock) shall provide an operation to asynchronously find a single document in a specified collection that matches a given query.",
                "test_traceability": [
                    {
                        "id": "examples/async/social_media_app.py",
                        "description": "uses it for `users.find_one`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/base.py::AbstractAsyncMongoDBDriver::find_one",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-020",
                "requirement_description": "Asynchronous drivers (live and mock) shall provide an operation to asynchronously find multiple documents in a specified collection matching a given query, with support for specifying sort order, an offset for results, and a limit on the number of results.",
                "test_traceability": [
                    {
                        "id": "tests/test_index_creation_async.py",
                        "description": "implicitly tests find_many through collection builder with mock driver)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/base.py::AbstractAsyncMongoDBDriver::find_many",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-021",
                "requirement_description": "Asynchronous drivers (live and mock) shall provide an operation to asynchronously update a single document in a specified collection that matches a given query, using a provided update specification.",
                "test_traceability": [
                    {
                        "id": "examples/async/social_media_app.py",
                        "description": "uses it implicitly via `doc.save()` on existing doc)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/base.py::AbstractAsyncMongoDBDriver::update_one",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-022",
                "requirement_description": "Asynchronous drivers (live and mock) shall provide an operation to asynchronously delete a single document from a specified collection that matches a given query.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/base.py::AbstractAsyncMongoDBDriver::delete_one",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-023",
                "requirement_description": "Asynchronous drivers (live and mock) shall provide an operation to asynchronously count the number of documents in a specified collection that match a given query.",
                "test_traceability": [
                    {
                        "id": "tests/test_index_creation_async.py",
                        "description": "uses `.count()` which calls driver `count` via `AsyncCollectionResponseBuilder`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/base.py::AbstractAsyncMongoDBDriver::count",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-024",
                "requirement_description": "Asynchronous drivers (live and mock) shall provide an operation to asynchronously check for the existence of at least one document in a specified collection that matches a given query.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/base.py::AbstractAsyncMongoDBDriver::exists",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DRV-025",
                "requirement_description": "Asynchronous drivers (live and mock) shall provide an operation to asynchronously create one or more indexes on a specified collection based on provided index specifications.",
                "test_traceability": [
                    {
                        "id": "tests/test_index_creation_async.py",
                        "description": "uses mock driver's `create_index` via `AsyncCollectionResponseBuilder`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/base.py::AbstractAsyncMongoDBDriver::create_index",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MOD-001",
                "requirement_description": "The system shall utilize Pydantic models as the primary mechanism for defining the schema of data to be stored in and retrieved from MongoDB.",
                "test_traceability": [
                    {
                        "id": "tests/test_collection_builder_core.py::User",
                        "description": "All tests and examples using Pydantic models e.g. `User`)."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/collection.py::CollectionWorker",
                        "description": "`T` bound to `BaseModel`)"
                    },
                    {
                        "id": "pydongo/workers/document.py::BaseDocumentWorker",
                        "description": "`T` bound to `BaseModel`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-MOD-002",
                "requirement_description": "The system shall determine the MongoDB collection name associated with a Pydantic model. If the Pydantic model has a `collection_name` attribute, its value shall be used. Otherwise, the model's class name shall be used as the collection name.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/document.py::BaseDocumentWorker::collection_name",
                        "description": ""
                    },
                    {
                        "id": "pydongo/workers/collection.py::CollectionWorker::collection_name",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DOC-001",
                "requirement_description": "The system shall provide a top-level function (e.g., `as_document`) that accepts a Pydantic model instance and a database driver, returning a \"document worker\" object. This worker object shall provide methods for database persistence.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/document.py::as_document",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DOC-002",
                "requirement_description": "For synchronous drivers, the document worker shall provide a synchronous `save` method to persist the Pydantic model instance's data to the database.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/document.py::DocumentWorker::save",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DOC-003",
                "requirement_description": "If the `save` method (synchronous) is called on a document worker representing a new Pydantic instance (i.e., one not yet persisted or lacking a database-assigned identifier), an insert operation shall be performed in the database. The worker shall subsequently be aware of the database-assigned identifier.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/document.py::DocumentWorker::save",
                        "description": "logic for `self.objectId is None`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-DOC-004",
                "requirement_description": "If the `save` method (synchronous) is called on a document worker representing an already persisted Pydantic instance (i.e., one with a database-assigned identifier), an update operation shall be performed on the corresponding document in the database. The update operation should use the MongoDB `$set` operator with the serialized current state of the Pydantic model instance.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/document.py::DocumentWorker::save",
                        "description": "logic for `self.objectId is not None`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-DOC-005",
                "requirement_description": "For synchronous drivers, the document worker shall provide a synchronous `delete` method to remove the corresponding document from the database. The document to be deleted is identified by its database-assigned identifier or its serialized content if no identifier is present.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/document.py::DocumentWorker::delete",
                        "description": ""
                    },
                    {
                        "id": "pydongo/workers/document.py::BaseDocumentWorker::get_query",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DOC-006",
                "requirement_description": "For asynchronous drivers, the document worker shall provide an asynchronous `save` method with behavior analogous to FR-DOC-003 and FR-DOC-004 for insert and update operations, respectively.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/document.py::AsyncDocumentWorker::save",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DOC-007",
                "requirement_description": "For asynchronous drivers, the document worker shall provide an asynchronous `delete` method with behavior analogous to FR-DOC-005.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/document.py::AsyncDocumentWorker::delete",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DOC-008",
                "requirement_description": "Attribute access on a document worker instance shall be proxied to the underlying Pydantic model instance it wraps.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/document.py::BaseDocumentWorker::__getattr__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DOC-009",
                "requirement_description": "Persistence operations (`save`, `delete`) executed via the document worker shall target the MongoDB collection associated with the Pydantic model (as determined by FR-MOD-002).",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "FR-DOC-010",
                "requirement_description": "Prior to any `save` operation, the Pydantic model instance data within the document worker shall be serialized into a MongoDB-compatible dictionary format. This includes custom serialization for specific types (see 3.1.8).",
                "test_traceability": [
                    {
                        "id": "tests/test_serializer_utils.py",
                        "description": "Implicit in `save` operations; tests the serialization utility used."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/document.py::BaseDocumentWorker::serialize",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COL-001",
                "requirement_description": "The system shall provide a top-level function (e.g., `as_collection`) that accepts a Pydantic model type (class) and a database driver, returning a \"collection worker\" object. This worker object represents the MongoDB collection for that model type and is the entry point for querying.",
                "test_traceability": [
                    {
                        "id": "tests/test_collection_builder_core.py",
                        "description": "README examples all tests using `as_collection` e.g."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/collection.py::as_collection",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COL-002",
                "requirement_description": "For synchronous drivers, the collection worker shall provide a synchronous `find_one` method. This method accepts a filter expression and returns a single document worker instance (wrapping the Pydantic model) that matches the filter, or `None` if no match is found.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/collection.py::CollectionWorker::find_one",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COL-003",
                "requirement_description": "For asynchronous drivers, the collection worker shall provide an asynchronous `afind_one` method. This method accepts a filter expression and asynchronously returns a single document worker instance (wrapping the Pydantic model) that matches the filter, or `None` if no match is found.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/collection.py::CollectionWorker::afind_one",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COL-004",
                "requirement_description": "The collection worker shall provide a `find` method that accepts an optional filter expression. This method returns a query builder object, allowing for further refinement (sorting, limiting, skipping) and execution of the query. If no filter expression is provided, the query builder should target all documents in the collection.",
                "test_traceability": [
                    {
                        "id": "tests/test_collection_builder_core.py::test_collection_builder_sort_limit_skip_multi_sort",
                        "description": "README examples"
                    },
                    {
                        "id": "tests/test_collection_builder_core.py::test_collection_builder_null_state_defaults",
                        "description": "README examples"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/collection.py::CollectionWorker::find",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COL-005",
                "requirement_description": "The collection worker shall provide a `use_index` method to register one or more index definitions (single field index or a tuple for compound index) to be associated with the collection. These indexes are intended for creation on the underlying MongoDB collection.",
                "test_traceability": [
                    {
                        "id": "tests/test_index_creation.py::test_single_key_index",
                        "description": ""
                    },
                    {
                        "id": "tests/test_index_creation.py::test_compound_index",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/collection.py::CollectionWorker::use_index",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COL-006",
                "requirement_description": "Documents retrieved from the database via `find_one`, `afind_one`, or through a query builder's execution methods (`all`) must be deserialized from MongoDB's format. The deserialized data must be used to instantiate the Pydantic model type associated with the collection worker, and this Pydantic instance must then be wrapped in an appropriate document worker.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/collection.py::CollectionResponseBuilder::serialize_document",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QDSL-001",
                "requirement_description": "The system shall allow the creation of \"field expressions\" by accessing attributes on a collection worker instance, where attribute names correspond to field names in the associated Pydantic model (e.g., `collection_worker.user_name`).",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/collection.py::CollectionWorker::__getattr__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QDSL-002",
                "requirement_description": "Field expressions shall support the equality comparison operator (`==`) with a value, generating a filter condition equivalent to MongoDB's `$eq` operator.",
                "test_traceability": [
                    {
                        "id": "tests/test_field_expression.py::test_comparative_operators_resolve_correct_queries",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/field.py::FieldExpression::__eq__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QDSL-003",
                "requirement_description": "Field expressions shall support the inequality comparison operator (`!=`) with a value, generating a filter condition equivalent to MongoDB's `$ne` operator.",
                "test_traceability": [
                    {
                        "id": "tests/test_field_expression.py::test_comparative_operators_resolve_correct_queries",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/field.py::FieldExpression::__ne__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QDSL-004",
                "requirement_description": "Field expressions shall support the greater than comparison operator (`>`) with a value, generating a filter condition equivalent to MongoDB's `$gt` operator.",
                "test_traceability": [
                    {
                        "id": "tests/test_field_expression.py::test_comparative_operators_resolve_correct_queries",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/field.py::FieldExpression::__gt__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QDSL-005",
                "requirement_description": "Field expressions shall support the greater than or equal to comparison operator (`>=`) with a value, generating a filter condition equivalent to MongoDB's `$gte` operator.",
                "test_traceability": [
                    {
                        "id": "tests/test_field_expression.py::test_comparative_operators_resolve_correct_queries",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/field.py::FieldExpression::__ge__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QDSL-006",
                "requirement_description": "Field expressions shall support the less than comparison operator (`<`) with a value, generating a filter condition equivalent to MongoDB's `$lt` operator.",
                "test_traceability": [
                    {
                        "id": "tests/test_field_expression.py::test_comparative_operators_resolve_correct_queries",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/field.py::FieldExpression::__lt__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QDSL-007",
                "requirement_description": "Field expressions shall support the less than or equal to comparison operator (`<=`) with a value, generating a filter condition equivalent to MongoDB's `$lte` operator.",
                "test_traceability": [
                    {
                        "id": "tests/test_field_expression.py::test_comparative_operators_resolve_correct_queries",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/field.py::FieldExpression::__le__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QDSL-008",
                "requirement_description": "The system shall support chained attribute access on field expressions to construct references to fields within nested Pydantic models (e.g., `collection_worker.parent_field.child_field`), generating dot-notation field paths for MongoDB queries.",
                "test_traceability": [
                    {
                        "id": "tests/test_field_expression.py::test_nested_fields",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/field.py::FieldExpression::__getattr__",
                        "description": ""
                    },
                    {
                        "id": "pydongo/expressions/field.py::FieldExpression::_getattr",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QDSL-009",
                "requirement_description": "For field expressions representing an array/list field in the Pydantic model:",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "FR-QDSL-009-A",
                "requirement_description": "The system shall provide a way to query based on the size of the array (e.g., `collection_worker.array_field.size() > N`, or `len(collection_worker.array_field) > N`), generating a filter condition equivalent to MongoDB's `$expr` with `$size`.",
                "test_traceability": [
                    {
                        "id": "tests/test_field_expression.py::test_array_field_size_expression",
                        "description": "for `len()`)"
                    },
                    {
                        "id": "tests/test_field_expression.py::test_len_and_contains_sugar",
                        "description": "for `len()`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/field.py::ArrayFieldExpression::size",
                        "description": "for `len()`)"
                    },
                    {
                        "id": "pydongo/expressions/field.py::ArrayFieldExpression::__len__",
                        "description": "for `len()`)"
                    },
                    {
                        "id": "pydongo/expressions/field.py::ArraySizeFieldExpression",
                        "description": "for `len()`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-QDSL-009-B",
                "requirement_description": "The system shall provide a way to check if the array `contains` a specified value or any of a list of specified values (element presence), generating a filter condition equivalent to MongoDB's `$in` operator. This should also be achievable via Python's `in` operator (e.g., `value in collection_worker.array_field`).",
                "test_traceability": [
                    {
                        "id": "tests/test_field_expression.py::test_array_field_contains_and_excludes",
                        "description": ""
                    },
                    {
                        "id": "tests/test_field_expression.py::test_len_and_contains_sugar",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/field.py::ArrayFieldExpression::contains",
                        "description": ""
                    },
                    {
                        "id": "pydongo/expressions/field.py::ArrayFieldExpression::__contains__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QDSL-009-C",
                "requirement_description": "The system shall provide a way to check if the array `excludes` a specified value or all of a list of specified values (element absence), generating a filter condition equivalent to MongoDB's `$nin` operator.",
                "test_traceability": [
                    {
                        "id": "tests/test_field_expression.py::test_array_field_contains_and_excludes",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/field.py::ArrayFieldExpression::excludes",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QDSL-009-D",
                "requirement_description": "The system shall provide a way to check if the array `matches` a given list of elements. If `match_order` is true, it generates an exact match query. If `match_order` is false, it generates a filter condition equivalent to MongoDB's `$all` operator.",
                "test_traceability": [
                    {
                        "id": "tests/test_field_expression.py::test_array_field_matches_with_and_without_order",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/field.py::ArrayFieldExpression::matches",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QDSL-010",
                "requirement_description": "Applying the unary negation operator (`-`) to a field expression (e.g., `-collection_worker.field_name`) shall produce a new field expression instance configured to indicate descending sort order when used in sorting operations.",
                "test_traceability": [
                    {
                        "id": "tests/test_collection_builder_core.py::test_collection_builder_sort_limit_skip_multi_sort",
                        "description": "e.g. `-collection.name`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/field.py::FieldExpression::__neg__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QDSL-011",
                "requirement_description": "The system shall allow two filter expressions to be combined using a logical AND operator (`&`), resulting in a new filter expression that represents the conjunction of the two, equivalent to MongoDB's `$and` operator.",
                "test_traceability": [
                    {
                        "id": "tests/test_filter_expression.py::test_and_combines_two_expressions",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/filter.py::CollectionFilterExpression::__and__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QDSL-012",
                "requirement_description": "The system shall allow two filter expressions to be combined using a logical OR operator (`|`), resulting in a new filter expression that represents the disjunction of the two, equivalent to MongoDB's `$or` operator.",
                "test_traceability": [
                    {
                        "id": "tests/test_filter_expression.py::test_or_combines_two_expressions",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/filter.py::CollectionFilterExpression::__or__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QDSL-013",
                "requirement_description": "The system shall allow a filter expression to be inverted using a logical NOT operator (`~`), resulting in a new filter expression that represents the negation of the original, equivalent to MongoDB's `$not` operator.",
                "test_traceability": [
                    {
                        "id": "tests/test_filter_expression.py::test_not_inverts_expression",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/filter.py::CollectionFilterExpression::__invert__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QDSL-014",
                "requirement_description": "A filter expression that is empty or in its default state (e.g., created without specific conditions) shall represent a query that matches all documents in the collection (an empty MongoDB query filter `{}`).",
                "test_traceability": [
                    {
                        "id": "tests/test_collection_builder_core.py::test_collection_builder_null_state_defaults",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/filter.py::CollectionFilterExpression::__init__",
                        "description": "default argument."
                    },
                    {
                        "id": "pydongo/workers/collection.py::CollectionWorker::find",
                        "description": "default argument."
                    }
                ]
            },
            {
                "requirement_id": "FR-QRH-001",
                "requirement_description": "The query builder object (returned by `collection_worker.find()`) shall support a `sort` method to specify sorting criteria for the query results.",
                "test_traceability": [
                    {
                        "id": "tests/test_collection_builder_core.py::test_collection_builder_sort_limit_skip_multi_sort",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/collection.py::CollectionResponseBuilder::sort",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QRH-001-A",
                "requirement_description": "Sorting shall be specifiable by a single field expression (FR-QDSL-001, FR-QDSL-010), indicating ascending or descending order.",
                "test_traceability": [
                    {
                        "id": "tests/test_collection_builder_core.py::test_collection_builder_sort_limit_skip_multi_sort",
                        "description": "e.g. `sort(collection.age)` `sort(-collection.name)`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/collection.py::CollectionResponseBuilder::sort",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QRH-001-B",
                "requirement_description": "Sorting shall be specifiable by a list/sequence of field expressions to enable multi-key sorting.",
                "test_traceability": [
                    {
                        "id": "tests/test_collection_builder_core.py::test_collection_builder_sort_limit_skip_multi_sort",
                        "description": "e.g. `sort([collection.age -collection.joined])`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/collection.py::CollectionResponseBuilder::sort",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QRH-002",
                "requirement_description": "The query builder shall support a `limit` method to restrict the maximum number of documents returned by the query.",
                "test_traceability": [
                    {
                        "id": "tests/test_collection_builder_core.py::test_collection_builder_sort_limit_skip_multi_sort",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/collection.py::CollectionResponseBuilder::limit",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QRH-003",
                "requirement_description": "The query builder shall support a `skip` method (or equivalent `offset` concept) to bypass a specified number of documents from the beginning of the result set.",
                "test_traceability": [
                    {
                        "id": "tests/test_collection_builder_core.py::test_collection_builder_sort_limit_skip_multi_sort",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/collection.py::CollectionResponseBuilder::skip",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QRH-004",
                "requirement_description": "For synchronous operations, the query builder shall provide an `all()` method that executes the constructed query and returns an iterable of document worker instances representing the matching documents.",
                "test_traceability": [
                    {
                        "id": "tests/test_collection_builder_core.py",
                        "description": "README `Synchronous Example` used implicitly in by calling `build_kwargs` and asserting assuming mock driver would use these."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/collection.py::SyncCollectionResponseBuilder::all",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QRH-005",
                "requirement_description": "For asynchronous operations, the query builder shall provide an `all()` method that asynchronously executes the constructed query and returns a list of document worker instances representing the matching documents.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/collection.py::AsyncCollectionResponseBuilder::all",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QRH-006",
                "requirement_description": "For synchronous operations, the query builder shall provide a `count()` method that executes the query and returns the total number of documents matching the filter criteria.",
                "test_traceability": [
                    {
                        "id": "tests/test_index_creation.py::test_single_key_index",
                        "description": "calls `.count()`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/collection.py::SyncCollectionResponseBuilder::count",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QRH-007",
                "requirement_description": "For asynchronous operations, the query builder shall provide a `count()` method that asynchronously executes the query and returns the total number of documents matching the filter criteria.",
                "test_traceability": [
                    {
                        "id": "tests/test_index_creation_async.py::test_single_key_index_async",
                        "description": "calls `.count()`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/collection.py::AsyncCollectionResponseBuilder::count",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QRH-008",
                "requirement_description": "For synchronous operations, the query builder shall provide an `exists()` method that executes a query to determine if at least one document matches the filter criteria, returning a boolean.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/collection.py::SyncCollectionResponseBuilder::exists",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QRH-009",
                "requirement_description": "For asynchronous operations, the query builder shall provide an `exists()` method that asynchronously executes a query to determine if at least one document matches the filter criteria, returning a boolean.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/collection.py::AsyncCollectionResponseBuilder::exists",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QRH-010",
                "requirement_description": "The query builder shall internally compile the specified filter expression, sort criteria, limit, and skip values into a consolidated set of parameters (e.g., a dictionary) suitable for passing to the underlying database driver's find operation.",
                "test_traceability": [
                    {
                        "id": "tests/test_collection_builder_core.py::test_collection_builder_sort_limit_skip_multi_sort",
                        "description": ""
                    },
                    {
                        "id": "tests/test_collection_builder_core.py::test_collection_builder_null_state_defaults",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/collection.py::CollectionResponseBuilder::build_kwargs",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-IDX-001",
                "requirement_description": "The system shall allow the definition of a single-field index on a collection. This can be initiated from a field expression (e.g., `collection.field.as_index()`).",
                "test_traceability": [
                    {
                        "id": "tests/test_index_creation.py::test_single_key_index",
                        "description": ""
                    },
                    {
                        "id": "tests/test_index_creation_async.py::test_single_key_index_async",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/field.py::FieldExpression::as_index",
                        "description": ""
                    },
                    {
                        "id": "pydongo/expressions/index.py::IndexExpressionBuilder",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-IDX-002",
                "requirement_description": "The system shall allow the definition of a compound index, involving multiple fields, by passing a tuple of individual field index expressions to the collection's `use_index` method.",
                "test_traceability": [
                    {
                        "id": "tests/test_index_creation.py::test_compound_index",
                        "description": ""
                    },
                    {
                        "id": "tests/test_index_creation_async.py::test_compound_index_async",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/collection.py::CollectionWorker::use_index",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-IDX-003",
                "requirement_description": "Index definitions shall support specifying the sort order (ascending or descending) for each field participating in the index.",
                "test_traceability": [
                    {
                        "id": "tests/test_index_creation.py::test_compound_index",
                        "description": ""
                    },
                    {
                        "id": "tests/test_index_creation_async.py::test_compound_index_async",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/index.py::IndexSortOrder",
                        "description": ""
                    },
                    {
                        "id": "pydongo/expressions/index.py::IndexExpressionBuilder::use_sort_order",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-IDX-004",
                "requirement_description": "Index definitions shall support specifying one of the following MongoDB index types: TEXT, HASHED, TWO_DIMENSIONAL, TWO_DIMENSIONAL_SPHERE.",
                "test_traceability": [
                    {
                        "id": "tests/test_index_creation.py::test_text_and_hash_index",
                        "description": ""
                    },
                    {
                        "id": "tests/test_index_creation.py::test_geo_index_types",
                        "description": ""
                    },
                    {
                        "id": "tests/test_index_creation_async.py::test_text_and_hash_index_async",
                        "description": ""
                    },
                    {
                        "id": "tests/test_index_creation_async.py::test_geo_index_types_async",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/index.py::IndexType",
                        "description": ""
                    },
                    {
                        "id": "pydongo/expressions/index.py::IndexExpressionBuilder::use_index_type",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-IDX-005",
                "requirement_description": "Index definitions shall support a 'unique' constraint option to ensure indexed fields do not store duplicate values.",
                "test_traceability": [
                    {
                        "id": "tests/test_index_creation.py::test_index_with_special_kwargs",
                        "description": ""
                    },
                    {
                        "id": "tests/test_index_creation_async.py::test_index_with_special_kwargs_async",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/index.py::IndexExpressionBuilder::use_unique",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-IDX-006",
                "requirement_description": "Index definitions shall support a 'sparse' option, so the index only references documents that contain the indexed field.",
                "test_traceability": [
                    {
                        "id": "tests/test_index_creation.py::test_index_with_special_kwargs",
                        "description": ""
                    },
                    {
                        "id": "tests/test_index_creation_async.py::test_index_with_special_kwargs_async",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/index.py::IndexExpressionBuilder::use_sparse",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-IDX-007",
                "requirement_description": "Index definitions shall support specifying a Time-To-Live (TTL) duration in seconds (via an `expireAfterSeconds` option) for automatic document removal.",
                "test_traceability": [
                    {
                        "id": "tests/test_index_creation.py::test_index_with_special_kwargs",
                        "description": ""
                    },
                    {
                        "id": "tests/test_index_creation_async.py::test_index_with_special_kwargs_async",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/index.py::IndexExpressionBuilder::use_ttl",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-IDX-007-A",
                "requirement_description": "The TTL option (`expireAfterSeconds`) shall not be applied by the system when generating index creation parameters if the specified index type is TEXT or HASHED, as MongoDB does not support TTL for these index types.",
                "test_traceability": [
                    {
                        "id": "tests/test_index_creation.py::test_ttl_behavior_for_text_and_other_index_types",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/index.py::IndexExpression::build_kwargs",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-IDX-008",
                "requirement_description": "Index definitions shall support specifying collation options, including `locale` (string) and `strength` (from a predefined set: PRIMARY, SECONDARY, TERTIARY, QUATERNARY, IDENTICAL).",
                "test_traceability": [
                    {
                        "id": "tests/test_index_creation.py::test_index_with_special_kwargs",
                        "description": ""
                    },
                    {
                        "id": "tests/test_index_creation_async.py::test_index_with_special_kwargs_async",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/index.py::IndexExpressionBuilder::use_collation",
                        "description": ""
                    },
                    {
                        "id": "pydongo/expressions/index.py::CollationStrength",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-IDX-009",
                "requirement_description": "Index definitions shall support specifying a custom `name` for the index.",
                "test_traceability": [
                    {
                        "id": "tests/test_index_creation.py::test_index_with_special_kwargs",
                        "description": ""
                    },
                    {
                        "id": "tests/test_index_creation_async.py::test_index_with_special_kwargs_async",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/index.py::IndexExpressionBuilder::use_index_name",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-IDX-010",
                "requirement_description": "Index definitions shall support specifying a `partialFilterExpression` (using a standard filter expression object) to create partial indexes that only include documents matching the filter.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/index.py::IndexExpressionBuilder::use_partial_expression",
                        "description": ""
                    },
                    {
                        "id": "pydongo/expressions/index.py::IndexExpression::partial_expression",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-IDX-011",
                "requirement_description": "Index definitions shall support a 'hidden' option for the index.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/index.py::IndexExpressionBuilder::use_hidden",
                        "description": ""
                    },
                    {
                        "id": "pydongo/expressions/index.py::IndexExpression::is_hidden",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-IDX-012",
                "requirement_description": "Any indexes registered on a collection worker (via `use_index`) shall be automatically created on the MongoDB collection by the driver if they do not already exist. This creation should occur no later than the first execution of a data-retrieval or counting operation (e.g., `all()`, `count()`, `exists()`) initiated through a query builder associated with that collection worker.",
                "test_traceability": [
                    {
                        "id": "tests/test_index_creation.py::test_single_key_index",
                        "description": "implicitly by calling `.count()`)"
                    },
                    {
                        "id": "tests/test_index_creation_async.py::test_single_key_index_async",
                        "description": "implicitly by calling `.count()`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/collection.py::SyncCollectionResponseBuilder::create_indexes",
                        "description": ""
                    },
                    {
                        "id": "pydongo/workers/collection.py::AsyncCollectionResponseBuilder::create_indexes",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SER-001",
                "requirement_description": "The system shall automatically serialize Python `datetime.date` objects to MongoDB-compatible `datetime.datetime` objects before persistence. The time component of the resulting `datetime.datetime` object should represent the beginning of the day (e.g., midnight).",
                "test_traceability": [
                    {
                        "id": "tests/test_serializer_utils.py::test_date_serialization",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/utils/serializer.py::DateSerializer::serialize",
                        "description": ""
                    },
                    {
                        "id": "pydongo/utils/serializer.py::replace_unserializable_fields",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SER-002",
                "requirement_description": "The system shall automatically serialize Python `uuid.UUID` objects to their string representations before database persistence.",
                "test_traceability": [
                    {
                        "id": "tests/test_serializer_utils.py::test_uuid_serialization",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/utils/serializer.py::UUIDSerializer::serialize",
                        "description": ""
                    },
                    {
                        "id": "pydongo/utils/serializer.py::replace_unserializable_fields",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SER-003",
                "requirement_description": "The automatic serialization process (for types like `datetime.date`, `uuid.UUID`) shall correctly handle these types when they are found within nested data structures (e.g., dictionaries, lists, tuples, sets) inside the document being prepared for MongoDB.",
                "test_traceability": [
                    {
                        "id": "tests/test_serializer_utils.py::test_nested_serialization",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/utils/serializer.py::replace_unserializable_fields",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SER-004",
                "requirement_description": "When data is retrieved from MongoDB, the system shall provide a mechanism to attempt deserialization of `datetime.datetime` objects (that were originally `datetime.date`) back into `datetime.date` objects by taking the date component.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/utils/serializer.py::DateSerializer::deserialize",
                        "description": ""
                    },
                    {
                        "id": "pydongo/utils/serializer.py::restore_unserializable_fields",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SER-005",
                "requirement_description": "When data is retrieved from MongoDB, the system shall provide a mechanism to attempt deserialization of string representations of UUIDs back into `uuid.UUID` objects.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/utils/serializer.py::UUIDSerializer::deserialize",
                        "description": ""
                    },
                    {
                        "id": "pydongo/utils/serializer.py::restore_unserializable_fields",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SER-006",
                "requirement_description": "The deserialization process for custom types shall attempt to handle these types when they are found within nested data structures retrieved from MongoDB.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/utils/serializer.py::restore_unserializable_fields",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SER-007",
                "requirement_description": "When values of types `datetime.date` or `uuid.UUID` are used in field expression comparisons (e.g., `collection.date_field == my_date_obj`), these values shall be serialized to their MongoDB-compatible representations before constructing the query filter.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/field.py::FieldExpression::_get_comparative_expression",
                        "description": ""
                    },
                    {
                        "id": "pydongo/utils/serializer.py::HANDLER_MAPPING",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-UTIL-001",
                "requirement_description": "The system shall provide a utility function that, given a Python type annotation, resolves it to its primary underlying data type. For `typing.Union` (e.g., `Union[int, str]`, `Union[None, float]`), it should return the first non-None type if multiple types are present, or the single type if only one non-None type exists.",
                "test_traceability": [
                    {
                        "id": "tests/test_resolve_annotation.py::test_resolve_annotation_union",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/utils/annotations.py::resolve_annotation",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-UTIL-002",
                "requirement_description": "The type resolution utility shall correctly extract the underlying type `X` from `typing.Optional[X]` (which is equivalent to `Union[X, None]`).",
                "test_traceability": [
                    {
                        "id": "tests/test_resolve_annotation.py::test_resolve_annotation_optional",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/utils/annotations.py::resolve_annotation",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-UTIL-003",
                "requirement_description": "The type resolution utility shall correctly extract the underlying type `X` from `typing.Annotated[X, ...]` by recursively resolving `X`.",
                "test_traceability": [
                    {
                        "id": "tests/test_resolve_annotation.py::test_resolve_annotation_annotated",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/utils/annotations.py::resolve_annotation",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-001",
                "requirement_description": "The system shall generate MongoDB query filter documents that conform to the MongoDB query language syntax for field comparison operations (e.g., `{\"field_name\": {\"$operator\": value}}` where `$operator` is one of `$eq`, `$ne`, `$gt`, `$gte`, `$lt`, `$lte`).",
                "test_traceability": [
                    {
                        "id": "tests/test_field_expression.py::test_comparative_operators_resolve_correct_queries",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/field.py::FieldExpression",
                        "description": "comparison methods."
                    }
                ]
            },
            {
                "requirement_id": "EIR-002",
                "requirement_description": "The system shall generate MongoDB query filter documents that conform to the MongoDB query language syntax for logical composition of sub-filters (e.g., `{\"$and\": [filter1, filter2]}`, `{\"$or\": [filter1, filter2]}`, `{\"$not\": {filter}}`).",
                "test_traceability": [
                    {
                        "id": "tests/test_filter_expression.py",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/filter.py::CollectionFilterExpression",
                        "description": "logical operator methods."
                    }
                ]
            },
            {
                "requirement_id": "EIR-003",
                "requirement_description": "The system shall generate MongoDB query filter documents that conform to the MongoDB query language syntax for array-specific operations, including array size checks (using `$expr` and `$size`), element containment (using `$in` or exact match for single element), element exclusion (using `$nin`), and matching all elements (using `$all` or exact array match).",
                "test_traceability": [
                    {
                        "id": "tests/test_field_expression.py::test_array_field_size_expression",
                        "description": ""
                    },
                    {
                        "id": "tests/test_field_expression.py::test_array_field_contains_and_excludes",
                        "description": ""
                    },
                    {
                        "id": "tests/test_field_expression.py::test_array_field_matches_with_and_without_order",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/field.py::ArrayFieldExpression",
                        "description": ""
                    },
                    {
                        "id": "pydongo/expressions/field.py::ArraySizeFieldExpression",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-004",
                "requirement_description": "The system's live database drivers (synchronous and asynchronous) shall connect to MongoDB instances using standard MongoDB connection URI strings.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pydongo/drivers/sync_mongo.py::DefaultMongoDBDriver::__init__",
                        "description": ""
                    },
                    {
                        "id": "pydongo/drivers/async_mongo.py::AsyncDefaultMongoDBDriver::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-005",
                "requirement_description": "The parameters generated by the system for MongoDB index creation (including index keys, sort order, type, and options like `unique`, `sparse`, `expireAfterSeconds`, `collation`, `name`, `partialFilterExpression`, `hidden`) must conform to the specifications of MongoDB's `createIndex` command or its driver equivalents.",
                "test_traceability": [
                    {
                        "id": "tests/test_index_creation.py",
                        "description": "these tests verify the arguments prepared for index creation)"
                    },
                    {
                        "id": "tests/test_index_creation_async.py",
                        "description": "these tests verify the arguments prepared for index creation)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/expressions/index.py::IndexExpression::serialize",
                        "description": "driver `create_index` methods."
                    },
                    {
                        "id": "pydongo/expressions/index.py::IndexExpression::build_kwargs",
                        "description": "driver `create_index` methods."
                    }
                ]
            },
            {
                "requirement_id": "DR-001",
                "requirement_description": "The system is designed to work with data schemas defined as Pydantic V2 models (inheriting from `pydantic.BaseModel`).",
                "test_traceability": [
                    {
                        "id": "tests/test_collection_builder_core.py::User",
                        "description": "All Pydantic models used in tests e.g. `User`)."
                    }
                ],
                "code_traceability": []
            },
            {
                "requirement_id": "DR-002",
                "requirement_description": "MongoDB documents are generally expected to have an `_id` field managed by MongoDB, which the system may use as a database-assigned identifier for operations like updates and for tracking inserted documents. Wrapped document instances populated from the database should store this identifier.",
                "test_traceability": [
                    {
                        "id": "test_driver_mock.py",
                        "description": "Implicit in save/update/delete tests in README and."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pydongo/workers/document.py::DocumentWorker::save",
                        "description": "retrieves `inserted_id`) uses `_id` if `self.objectId` is set)."
                    },
                    {
                        "id": "pydongo/workers/document.py::BaseDocumentWorker::get_query",
                        "description": "retrieves `inserted_id`) uses `_id` if `self.objectId` is set)."
                    }
                ]
            }
        ],
        "full_code_skeleton": "--- File: examples/sync/medtech_app.py ---\n```python\nclass Prescription(BaseModel):\n    id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n    drug_name: str\n    dosage: str\n    frequency: str\n    duration_days: int\n\nclass Patient(BaseModel):\n    patient_id: str\n    name: str\n    age: int\n    prescriptions: List[Prescription] = []\n\ndef create_patient(patient_id: str, name: str, age: int) -> Patient:\n    pass\n\ndef add_prescription(\n    patient_id: str, drug_name: str, dosage: str, frequency: str, duration_days: int\n) -> Optional[Prescription]:\n    pass\n\ndef get_prescriptions(patient_id: str) -> List[Prescription]:\n    pass\n```\n--- File: examples/sync/social_media_app.py ---\n```python\nclass Post(BaseModel):\n    id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n    content: str\n    likes: int = 0\n\nclass User(BaseModel):\n    username: str\n    email: str\n    bio: Optional[str] = \"\"\n    posts: List[Post] = []\n\ndef create_user(username: str, email: str, bio: str = \"\") -> User:\n    pass\n\ndef make_post(username: str, content: str) -> Optional[Post]:\n    pass\n\ndef like_post(username: str, post_id: str) -> bool:\n    pass\n\ndef get_all_posts(username: Optional[str] = None) -> List[Post]:\n    pass\n```\n--- File: examples/async/social_media_app.py ---\n```python\nclass Post(BaseModel):\n    id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n    content: str\n    likes: int = 0\n\nclass User(BaseModel):\n    username: str\n    email: str\n    bio: Optional[str] = \"\"\n    posts: List[Post] = []\n\nasync def create_user(username: str, email: str, bio: str = \"\") -> User:\n    pass\n\nasync def make_post(username: str, content: str) -> Optional[Post]:\n    pass\n\nasync def like_post(username: str, post_id: str) -> bool:\n    pass\n\nasync def get_all_posts(username: Optional[str] = None) -> List[Post]:\n    pass\n\nasync def main():\n    pass\n```\n--- File: pydongo/workers/document.py ---\n```python\nT = TypeVar(\"T\", bound=BaseModel)\n\ndef as_document(\n    pydantic_object: T, driver: AbstractMongoDBDriver\n) -> Union[\"DocumentWorker\", \"AsyncDocumentWorker\"]:\n    \"\"\"\n    Wraps a Pydantic object in either a synchronous or asynchronous document worker,\n    depending on the provided MongoDB driver.\n\n    Args:\n        pydantic_object (T): A Pydantic model instance.\n        driver (AbstractMongoDBDriver): The MongoDB driver in use.\n\n    Returns:\n        Union[DocumentWorker, AsyncDocumentWorker]: A document wrapper with persistence methods.\n    \"\"\"\n    pass\n\nclass BaseDocumentWorker(Generic[T]):\n    \"\"\"\n    Base class for document-level operations like serialization, query generation, and collection detection.\n\n    This class provides common functionality for both synchronous and asynchronous document workers.\n    \"\"\"\n\n    def __init__(\n        self, pydantic_object: T, objectId: Optional[str] = None, *args, **kwargs\n    ):\n        \"\"\"\n        Initialize the document wrapper.\n\n        Args:\n            pydantic_object (T): The Pydantic model to wrap.\n            objectId (Optional[str]): Optional MongoDB ObjectId of the document.\n        \"\"\"\n        pass\n\n    @property\n    def collection_name(self):\n        \"\"\"\n        Returns the MongoDB collection name associated with the model.\n\n        Returns:\n            str: The collection name.\n        \"\"\"\n        pass\n\n    def get_query(self) -> dict:\n        \"\"\"\n        Builds a MongoDB query to uniquely identify the current document.\n\n        Returns:\n            dict: A MongoDB query dict.\n        \"\"\"\n        pass\n\n    def serialize(self) -> dict:\n        \"\"\"\n        Serializes the Pydantic model to a dictionary suitable for MongoDB storage.\n\n        Returns:\n            dict: Serialized representation of the document.\n        \"\"\"\n        pass\n\n    def __getattr__(self, name: str) -> Any:\n        \"\"\"\n        Proxy attribute access to the underlying Pydantic model.\n\n        Args:\n            name (str): The attribute name.\n\n        Returns:\n            Any: Attribute value from the Pydantic model.\n        \"\"\"\n        pass\n\n    def __repr__(self):\n        \"\"\"\n        Returns a human-readable string representation of the document.\n\n        Returns:\n            str: Representation of the document wrapper.\n        \"\"\"\n        pass\n\nclass DocumentWorker(BaseDocumentWorker):\n    \"\"\"\n    Document wrapper for synchronous MongoDB operations.\n\n    Provides methods to save and delete documents from MongoDB.\n    \"\"\"\n\n    def __init__(\n        self,\n        pydantic_object: T,\n        driver: AbstractSyncMongoDBDriver,\n        objectId: Optional[str] = None,\n    ):\n        \"\"\"\n        Initialize the sync document worker.\n\n        Args:\n            pydantic_object (T): The Pydantic model to wrap.\n            driver (AbstractSyncMongoDBDriver): The sync MongoDB driver.\n            objectId (Optional[str]): Optional ObjectId for the document.\n        \"\"\"\n        pass\n\n    def save(self) -> dict:\n        \"\"\"\n        Save the document to MongoDB. Performs an insert if no ObjectId is present,\n        or an update otherwise.\n\n        Returns:\n            dict: Result of the MongoDB insert or update operation.\n        \"\"\"\n        pass\n\n    def delete(self) -> dict:\n        \"\"\"\n        Delete the document from MongoDB using its ObjectId.\n\n        Returns:\n            dict: Result of the delete operation.\n        \"\"\"\n        pass\n\nclass AsyncDocumentWorker(BaseDocumentWorker):\n    \"\"\"\n    Document wrapper for asynchronous MongoDB operations.\n\n    Provides async methods to save and delete documents.\n    \"\"\"\n\n    def __init__(\n        self,\n        pydantic_object: T,\n        driver: AbstractAsyncMongoDBDriver,\n        objectId: Optional[str] = None,\n    ):\n        \"\"\"\n        Initialize the async document worker.\n\n        Args:\n            pydantic_object (T): The Pydantic model to wrap.\n            driver (AbstractAsyncMongoDBDriver): The async MongoDB driver.\n            objectId (Optional[str]): Optional ObjectId for the document.\n        \"\"\"\n        pass\n\n    async def save(self):\n        \"\"\"\n        Save the document to MongoDB asynchronously. Inserts if no ObjectId is present,\n        or updates otherwise.\n\n        Returns:\n            dict: Result of the insert or update operation.\n        \"\"\"\n        pass\n\n    async def delete(self) -> dict:\n        \"\"\"\n        Delete the document from MongoDB asynchronously using its ObjectId.\n\n        Returns:\n            dict: Result of the delete operation.\n        \"\"\"\n        pass\n```\n--- File: pydongo/workers/collection.py ---\n```python\nT = TypeVar(\"T\", bound=BaseModel)\n\ndef as_collection(\n    pydantic_model: Type[T],\n    driver: Union[AbstractSyncMongoDBDriver, AbstractAsyncMongoDBDriver],\n) -> \"CollectionWorker\":\n    pass\n\nclass CollectionWorker(Generic[T]):\n    \"\"\"\n    Entry point for querying and interacting with a MongoDB collection.\n\n    Wraps a Pydantic model and MongoDB driver, and exposes queryable field expressions\n    and high-level `find_one`, `afind_one`, and `find` methods.\n\n    Supports both sync and async drivers via conditional branching.\n    \"\"\"\n\n    def __init__(\n        self,\n        pydantic_model: Type[T],\n        driver: Union[AbstractSyncMongoDBDriver, AbstractAsyncMongoDBDriver],\n    ):\n        pass\n\n    def find_one(\n        self, expression: CollectionFilterExpression\n    ) -> Optional[DocumentWorker]:\n        \"\"\"\n        Query the database for a single document that matches the filter expression.\n        Only works with a synchronous driver.\n\n        Args:\n            expression (CollectionFilterExpression): The MongoDB-style filter expression.\n\n        Returns:\n            Optional[DocumentWorker]: A wrapped Pydantic object if found, otherwise None.\n        \"\"\"\n        pass\n\n    async def afind_one(\n        self, expression: CollectionFilterExpression\n    ) -> Optional[AsyncDocumentWorker]:\n        \"\"\"\n        Asynchronously query the database for a single document matching the filter expression.\n        Only works with an async driver.\n\n        Args:\n            expression (CollectionFilterExpression): The MongoDB-style filter expression.\n\n        Returns:\n            Optional[AsyncDocumentWorker]: A wrapped Pydantic object if found, otherwise None.\n        \"\"\"\n        pass\n\n    def find(\n        self, expression: Optional[CollectionFilterExpression] = None\n    ) -> \"CollectionResponseBuilder\":\n        \"\"\"\n        Initiates a fluent response builder chain for querying multiple documents.\n\n        Args:\n            expression (Optional[CollectionFilterExpression]): Optional filter expression.\n\n        Returns:\n            CollectionResponseBuilder: Builder for fluent chaining (e.g., .limit(), .sort()).\n        \"\"\"\n        pass\n\n    def use_index(\n        self,\n        index: Union[IndexExpression, Tuple[IndexExpression]],\n    ):\n        \"\"\"\n        Registers an index (or compound index) on the collection.\n\n        Accepts IndexExpression(s)\n\n        Args:\n            index: A single IndexExpression, or a tuple of them.\n\n        Returns:\n            CollectionWorker: Self, for method chaining.\n        \"\"\"\n        pass\n\n    def __getattr__(self, name: str) -> FieldExpression:\n        \"\"\"\n        Returns a field expression object to enable DSL-style querying using comparison\n        operators or dot notation for nested objects.\n\n        Args:\n            name (str): Field name in the Pydantic model.\n\n        Returns:\n            FieldExpression: Expression object tied to the field.\n\n        Raises:\n            AttributeError: If the field does not exist on the model.\n        \"\"\"\n        pass\n\n    @property\n    def collection_name(self):\n        \"\"\"\n        Derives the MongoDB collection name from the model or falls back to the class name.\n\n        Returns:\n            str: The name of the collection.\n        \"\"\"\n        pass\n\nclass CollectionResponseBuilder(ABC, Generic[T]):\n    \"\"\"\n    Fluent builder for composing queries and retrieving lists of documents.\n\n    Can build the final MongoDB query structure with sort, skip, and limit options.\n    \"\"\"\n\n    def __init__(\n        self,\n        expression: CollectionFilterExpression,\n        pydantic_model: Type[T],\n        driver: Union[AbstractSyncMongoDBDriver, AbstractAsyncMongoDBDriver],\n        collection_name: str,\n        indexes: Iterable[Tuple[IndexExpression]],\n    ):\n        pass\n\n    def skip(self, offset: int) -> \"CollectionResponseBuilder\":\n        \"\"\"\n        Skip the first N documents in the query result.\n\n        Args:\n            offset (int): Number of documents to skip.\n\n        Returns:\n            CollectionResponseBuilder: For chaining.\n        \"\"\"\n        pass\n\n    def limit(self, limit_value: int) -> \"CollectionResponseBuilder\":\n        \"\"\"\n        Limit the number of documents returned.\n\n        Args:\n            limit_value (int): Maximum number of documents to return.\n\n        Returns:\n            CollectionResponseBuilder: For chaining.\n        \"\"\"\n        pass\n\n    def sort(\n        self, sort_criteria: Union[FieldExpression, Sequence[FieldExpression]]\n    ) -> \"CollectionResponseBuilder\":\n        \"\"\"\n        Apply sort criteria to the query.\n\n        Args:\n            sort_criteria (Union[FieldExpression, Sequence[FieldExpression]]): Sort instructions.\n\n        Returns:\n            CollectionResponseBuilder: For chaining.\n        \"\"\"\n        pass\n\n    def build_kwargs(self) -> dict:\n        \"\"\"\n        Assembles the query, sort, offset, and limit into a single dictionary.\n\n        Returns:\n            dict: MongoDB-compatible query parameters.\n        \"\"\"\n        pass\n\n    @classmethod\n    def serialize_document(\n        cls,\n        document: dict,\n        document_worker_class: Type[BaseDocumentWorker],\n        pydantic_model: Type[T],\n        driver: AbstractMongoDBDriver,\n    ) -> BaseDocumentWorker:\n        \"\"\"\n        Deserialize a raw MongoDB document and wrap it in a DocumentWorker.\n\n        Args:\n            document (dict): Raw document from the database.\n            document_worker_class (Type): Either DocumentWorker or AsyncDocumentWorker.\n            pydantic_model (Type): Model class to hydrate.\n            driver (AbstractMongoDBDriver): Driver used to perform operations.\n\n        Returns:\n            BaseDocumentWorker: Wrapped document instance.\n        \"\"\"\n        pass\n\nclass SyncCollectionResponseBuilder(CollectionResponseBuilder):\n    \"\"\"\n    Response builder for synchronous drivers.\n\n    Provides direct methods to count, check existence, and iterate documents.\n    \"\"\"\n\n    def __init__(\n        self,\n        expression: CollectionFilterExpression,\n        pydantic_model: Type[T],\n        driver: AbstractSyncMongoDBDriver,\n        collection_name: str,\n        indexes: Iterable[Tuple[IndexExpression]],\n    ):\n        pass\n\n    def exists(self) -> bool:\n        \"\"\"\n        Check if any document matches the filter expression.\n\n        Returns:\n            bool: True if at least one document exists.\n        \"\"\"\n        pass\n\n    def count(self) -> int:\n        \"\"\"\n        Count how many documents match the filter expression.\n\n        Returns:\n            int: Number of matching documents.\n        \"\"\"\n        pass\n\n    def all(self) -> Iterable[DocumentWorker]:\n        \"\"\"\n        Retrieve all documents that match the current query builder state.\n\n        Returns:\n            Iterable[DocumentWorker]: Generator of hydrated documents.\n        \"\"\"\n        pass\n\n    def create_indexes(self):\n        \"\"\"\n        Creates indexes on the MongoDB database.\n        \"\"\"\n        pass\n\nclass AsyncCollectionResponseBuilder(CollectionResponseBuilder):\n    \"\"\"\n    Response builder for asynchronous drivers.\n\n    Supports async versions of exists, count, and all().\n    \"\"\"\n\n    def __init__(\n        self,\n        expression: CollectionFilterExpression,\n        pydantic_model: Type[T],\n        driver: AbstractAsyncMongoDBDriver,\n        collection_name: str,\n        indexes: Iterable[Tuple[IndexExpression]],\n    ):\n        pass\n\n    async def exists(self) -> bool:\n        \"\"\"\n        Asynchronously check if any document matches the filter.\n\n        Returns:\n            bool: True if a match exists.\n        \"\"\"\n        pass\n\n    async def count(self) -> int:\n        \"\"\"\n        Asynchronously count how many documents match the filter.\n\n        Returns:\n            int: Number of matching documents.\n        \"\"\"\n        pass\n\n    async def all(self) -> Iterable[AsyncDocumentWorker]:\n        \"\"\"\n        Asynchronously retrieve all matching documents.\n\n        Returns:\n            Iterable[AsyncDocumentWorker]: List of wrapped async document objects.\n        \"\"\"\n        pass\n\n    async def create_indexes(self):\n        \"\"\"\n        Asynchronously creates indexes on the MongoDB database.\n        \"\"\"\n        pass\n```\n--- File: pydongo/expressions/filter.py ---\n```python\nclass CollectionFilterExpression(BaseExpression):\n    \"\"\"\n    Represents a boolean filter expression used to query a MongoDB collection.\n\n    These expressions are composable using:\n        - Logical OR (`|`)\n        - Logical AND (`&`)\n        - Logical NOT (`~`)\n\n    Example usage:\n        filter_1 = User.age > 18\n        filter_2 = User.name == \"Samuel\"\n        combined = filter_1 & filter_2\n\n    The resulting expression can be serialized and passed to the database driver.\n    \"\"\"\n\n    def __init__(self, expression: Optional[dict] = None):\n        \"\"\"\n        Initialize the filter expression with an optional initial dictionary.\n\n        Args:\n            expression (Optional[dict]): A MongoDB-style query dictionary.\n        \"\"\"\n        pass\n\n    def with_expression(self, expression: dict) -> \"CollectionFilterExpression\":\n        \"\"\"\n        Mutate the internal expression by merging in a new dictionary.\n\n        Args:\n            expression (dict): A MongoDB-style query to merge into the current expression.\n\n        Returns:\n            CollectionFilterExpression: The current instance (for chaining).\n        \"\"\"\n        pass\n\n    def serialize(self) -> dict:\n        \"\"\"\n        Serialize the filter expression into a MongoDB-compatible query object.\n\n        Returns:\n            dict: Serialized MongoDB query.\n        \"\"\"\n        pass\n\n    def __and__(\n        self, other: \"CollectionFilterExpression\"\n    ) -> \"CollectionFilterExpression\":\n        \"\"\"\n        Combine this filter with another using a logical AND.\n\n        Args:\n            other (CollectionFilterExpression): Another filter to combine with.\n\n        Returns:\n            CollectionFilterExpression: A new combined filter.\n        \"\"\"\n        pass\n\n    def __or__(\n        self, other: \"CollectionFilterExpression\"\n    ) -> \"CollectionFilterExpression\":\n        \"\"\"\n        Combine this filter with another using a logical OR.\n\n        Args:\n            other (CollectionFilterExpression): Another filter to combine with.\n\n        Returns:\n            CollectionFilterExpression: A new combined filter.\n        \"\"\"\n        pass\n\n    def __invert__(self) -> \"CollectionFilterExpression\":\n        \"\"\"\n        Invert the current filter using a logical NOT.\n\n        Returns:\n            CollectionFilterExpression: A new filter expression wrapped in `$not`.\n        \"\"\"\n        pass\n```\n--- File: pydongo/expressions/base.py ---\n```python\nclass BaseExpression(ABC):\n    @abstractmethod\n    def serialize(self) -> Any:\n        \"\"\"\n        Serialize an expression into a MongoDB compatible query DTO\n        \"\"\"\n        pass\n```\n--- File: pydongo/expressions/field.py ---\n```python\nclass FieldExpression:\n    \"\"\"\n    Represents a scalar field in a MongoDB query.\n\n    This class supports operator overloading to build query expressions using:\n        ==, !=, >, >=, <, <=\n\n    It also supports nested attribute access (e.g., user.address.city).\n    \"\"\"\n\n    def __init__(self, field_name: str, annotation=None, sort_ascending: bool = True):\n        \"\"\"\n        Initialize a field expression.\n\n        Args:\n            field_name (str): The full dot-path name of the field.\n            annotation (Any): The Pydantic type annotation for the field.\n            sort_ascending (bool): Whether sorting on this field is ascending by default.\n        \"\"\"\n        pass\n\n    def to_index(self) -> IndexExpression:\n        \"\"\"\n        Returns a complete, ready-to-use `IndexExpression` for this field.\n\n        This is a convenience method for quickly generating a basic index configuration\n        using the default sort order and inferred index type (e.g., TEXT for strings).\n        \"\"\"\n        pass\n\n    def as_index(self) -> IndexExpressionBuilder:\n        \"\"\"\n        Returns an `IndexExpressionBuilder` initialized with this field.\n\n        This allows users to customize the index further, such as adding uniqueness,\n        TTL, collation, or partial filter expressions—before building the final index object.\n        \"\"\"\n        pass\n\n    def _get_comparative_expression(self, operator: str, value: Any) -> dict:\n        \"\"\"\n        Build a MongoDB filter expression using the given operator and value.\n\n        Args:\n            operator (str): MongoDB comparison operator (e.g., \"$gt\").\n            value (Any): The value to compare against.\n\n        Returns:\n            dict: A MongoDB-compatible filter clause.\n        \"\"\"\n        pass\n\n    def __eq__(self, other: Any) -> \"CollectionFilterExpression\":  # type: ignore\n        \"\"\"Build an equality expression (`==`).\"\"\"\n        pass\n\n    def __ne__(self, other: Any) -> \"CollectionFilterExpression\":  # type: ignore\n        \"\"\"Build an inequality expression (`!=`).\"\"\"\n        pass\n\n    def __gt__(self, other: Any) -> \"CollectionFilterExpression\":\n        \"\"\"Build a greater-than expression (`>`).\"\"\"\n        pass\n\n    def __ge__(self, other: Any) -> \"CollectionFilterExpression\":\n        \"\"\"Build a greater-than-or-equal expression (`>=`).\"\"\"\n        pass\n\n    def __lt__(self, other: Any) -> \"CollectionFilterExpression\":\n        \"\"\"Build a less-than expression (`<`).\"\"\"\n        pass\n\n    def __le__(self, other: Any) -> \"CollectionFilterExpression\":\n        \"\"\"Build a less-than-or-equal expression (`<=`).\"\"\"\n        pass\n\n    def __neg__(self) -> \"FieldExpression\":\n        \"\"\"\n        Flip the default sort order.\n\n        Returns:\n            FieldExpression: A new instance with reversed sort order.\n        \"\"\"\n        pass\n\n    @property\n    def field_name(self):\n        \"\"\"The full field name, including nested paths if applicable.\"\"\"\n        pass\n\n    def __getattr__(self, name: str) -> \"FieldExpression\":\n        \"\"\"\n        Support for chained dot notation, e.g. `user.address.city`.\n\n        Args:\n            name (str): Subfield name.\n\n        Returns:\n            FieldExpression: A new field expression for the nested field.\n        \"\"\"\n        pass\n\n    @classmethod\n    def _getattr(cls, field_name: str, annotation: Any, name: str) -> \"FieldExpression\":\n        \"\"\"\n        Helper to resolve nested fields.\n\n        Args:\n            field_name (str): Current field name path.\n            annotation (Any): Type annotation of the current field.\n            name (str): Next subfield name.\n\n        Returns:\n            FieldExpression: A new expression with nested field access.\n\n        Raises:\n            AttributeError: If the annotation is not a Pydantic model or field is invalid.\n        \"\"\"\n        pass\n\n    @staticmethod\n    def get_field_expression(field_name: str, annotation: Any) -> \"FieldExpression\":\n        pass\n\nclass ArraySizeFieldExpression(FieldExpression):\n    \"\"\"\n    Represents an expression for the size of an array field.\n\n    Used for queries like: `len(User.tags) > 2`\n    \"\"\"\n\n    def _get_comparative_expression(self, operator: str, value: int) -> dict:\n        \"\"\"\n        Build a MongoDB `$expr` query comparing the size of an array.\n\n        Args:\n            operator (str): Comparison operator (e.g., \"$gt\").\n            value (int): Value to compare the array size against.\n\n        Returns:\n            dict: MongoDB `$expr` query.\n        \"\"\"\n        pass\n\nclass ArrayFieldExpression(FieldExpression):\n    \"\"\"\n    Represents an array field in a MongoDB document.\n\n    Adds support for array-specific operations like `.contains()`, `.size()`, and `.matches()`.\n    \"\"\"\n\n    def size(self) -> ArraySizeFieldExpression:\n        \"\"\"\n        Get an expression that targets the array's length.\n\n        Returns:\n            ArraySizeFieldExpression: An expression targeting the array's size.\n        \"\"\"\n        pass\n\n    def matches(\n        self, values: Iterable[Any], match_order: bool = False\n    ) -> CollectionFilterExpression:\n        \"\"\"\n        Check if the array exactly matches the provided values.\n\n        Args:\n            values (Iterable[Any]): Values to match against.\n            match_order (bool): If True, requires order-sensitive match.\n\n        Returns:\n            CollectionFilterExpression: MongoDB `$all` or exact match query.\n        \"\"\"\n        pass\n\n    def contains(self, value: Any) -> CollectionFilterExpression:\n        \"\"\"\n        Check if the array contains one or more values.\n\n        Args:\n            value (Any): A scalar or iterable to check presence for.\n\n        Returns:\n            CollectionFilterExpression: MongoDB `$in` expression.\n        \"\"\"\n        pass\n\n    def excludes(self, value: Any) -> CollectionFilterExpression:\n        \"\"\"\n        Check if the array excludes one or more values.\n\n        Args:\n            value (Any): A scalar or iterable to check absence for.\n\n        Returns:\n            CollectionFilterExpression: MongoDB `$nin` expression.\n        \"\"\"\n        pass\n\n    def __getattr__(self, name: str) -> FieldExpression:\n        \"\"\"\n        Support accessing subfields within an array of objects.\n\n        Args:\n            name (str): Name of the subfield.\n\n        Returns:\n            FieldExpression: Field expression for the nested field.\n\n        Raises:\n            TypeError: If element type can't be inferred.\n        \"\"\"\n        pass\n\n    def __len__(self) -> ArraySizeFieldExpression:\n        \"\"\"\n        Return an expression for the array's size (using `len()`).\n\n        Returns:\n            ArraySizeFieldExpression: Expression targeting array length.\n        \"\"\"\n        pass\n\n    def __contains__(self, value: Any) -> CollectionFilterExpression:\n        \"\"\"\n        Python-style containment check using `in` syntax.\n\n        Args:\n            value (Any): Element to check for.\n\n        Returns:\n            CollectionFilterExpression: MongoDB `$in` expression.\n        \"\"\"\n        pass\n```\n--- File: pydongo/expressions/index.py ---\n```python\nclass IndexSortOrder(IntEnum):\n    ASCENDING = 1\n    DESCENDING = -1\n\nclass IndexType(str, Enum):\n    TEXT = \"text\"\n    HASHED = \"hashed\"\n    TWO_DIMENSIONAL = \"2d\"\n    TWO_DIMENSIONAL_SPHERE = \"2dsphere\"\n\nclass CollationStrength(IntEnum):\n    PRIMARY = 1  # Only base characters (e.g., \"a\" == \"A\", \"é\" == \"e\")\n    SECONDARY = 2  # Case-insensitive, accent-sensitive (e.g., \"a\" == \"A\", \"é\" != \"e\")\n    TERTIARY = 3  # Case- and accent-sensitive (e.g., \"a\" != \"A\", \"é\" != \"e\")\n    QUATERNARY = 4  # Includes case, accent, punctuation (e.g., \"$a\" != \"a\")\n    IDENTICAL = 5  # Everything is compared (e.g., code point level)\n\n    def description(self) -> str:\n        pass\n\nclass IndexExpression(BaseExpression):\n    def __init__(\n        self,\n        field_name: str,\n        index_type: Optional[IndexType] = None,\n        sort_order: IndexSortOrder = IndexSortOrder.ASCENDING,\n        expires_after_seconds: Optional[float] = None,  # For TTL indexes\n        is_sparse: Optional[bool] = None,\n        is_unique: Optional[bool] = None,\n        is_hidden: Optional[bool] = None,\n        collation_locale: str = \"en\",\n        collation_strength: Optional[CollationStrength] = None,\n        partial_expression: Optional[CollectionFilterExpression] = None,\n        index_name: Optional[str] = None,\n    ):\n        pass\n\n    def serialize(self) -> dict:\n        pass\n\n    def build_kwargs(self) -> dict:\n        \"\"\"\n        Additional specifications for the index to be passed to MongoDB's create_index.\n        Only includes non-null values.\n        \"\"\"\n        pass\n\n    def __hash__(self):\n        pass\n\n    def __eq__(self, expr: object) -> bool:\n        pass\n\nclass IndexExpressionBuilder:\n    def __init__(self, field_name: str):\n        pass\n\n    def use_sort_order(self, sort_order: IndexSortOrder) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_index_type(self, index_type: IndexType) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_collation(\n        self, locale: str, strength: CollationStrength\n    ) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_partial_expression(\n        self, expression: CollectionFilterExpression\n    ) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_index_name(self, index_name: str) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_sparse(self, is_sparse: bool = True) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_unique(self, is_unique: bool = True) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_hidden(self, is_hidden: bool = True) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_ttl(self, seconds: float) -> \"IndexExpressionBuilder\":\n        pass\n\n    def build_index(self) -> IndexExpression:\n        pass\n```\n--- File: pydongo/drivers/mock.py ---\n```python\nclass MockMongoDBDriver(AbstractSyncMongoDBDriver):\n    \"\"\"\n    In-memory mock implementation of the AbstractSyncMongoDBDriver.\n\n    This mock driver mimics MongoDB behavior for unit testing without requiring\n    a real database connection. Data is stored in-memory in Python dictionaries.\n    \"\"\"\n\n    def __init__(self, connection_string: str = \"\", database_name: str = \"mockdb\"):\n        \"\"\"\n        Initialize the mock driver with an empty in-memory store.\n\n        Args:\n            connection_string (str): Ignored.\n            database_name (str): Name of the fake database.\n        \"\"\"\n        pass\n\n    def connect(self) -> bool:\n        \"\"\"\n        Simulate a successful connection.\n\n        Returns:\n            bool: Always True.\n        \"\"\"\n        pass\n\n    def close(self) -> None:\n        \"\"\"\n        Close the connection (noop for the mock driver).\n        \"\"\"\n        pass\n\n    def insert_one(self, collection: str, document: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Insert a document into the in-memory collection.\n\n        Args:\n            collection (str): Name of the collection.\n            document (dict): Document to insert.\n\n        Returns:\n            dict: Insert result including generated `_id`.\n        \"\"\"\n        pass\n\n    def insert_many(\n        self, collection: str, documents: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Insert multiple documents into the in-memory collection.\n\n        Args:\n            collection (str): Name of the collection.\n            documents (list): List of documents to insert.\n\n        Returns:\n            dict: Insert result with list of `_id`s.\n        \"\"\"\n        pass\n\n    def find_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Find a single document matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): MongoDB-style filter.\n\n        Returns:\n            dict or None: Matching document or None if not found.\n        \"\"\"\n        pass\n\n    def find_many(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        sort_criteria: Dict[str, Any],\n        offset: Optional[int] = None,\n        limit: Optional[int] = None,\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Find multiple documents matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): MongoDB-style filter.\n            sort_criteria (dict): Ignored in the mock.\n            offset (int, optional): Skip the first N results.\n            limit (int, optional): Limit the number of results returned.\n\n        Returns:\n            list: List of matching documents.\n        \"\"\"\n        pass\n\n    def update_one(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        update: Dict[str, Any],\n        upsert: bool = False,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Update a single document matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): Filter query.\n            update (dict): Update operations (only supports \"$set\").\n\n        Returns:\n            dict: Update result with matched and modified count.\n        \"\"\"\n        pass\n\n    def delete_one(self, collection: str, query: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Delete the first document matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): Filter query.\n\n        Returns:\n            dict: Delete result.\n        \"\"\"\n        pass\n\n    def count(self, collection: str, query: Dict[str, Any]) -> int:\n        \"\"\"\n        Count documents that match the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): Filter query.\n\n        Returns:\n            int: Number of matching documents.\n        \"\"\"\n        pass\n\n    def exists(self, collection: str, query: Dict[str, Any]) -> bool:\n        \"\"\"\n        Check if at least one document matches the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): Filter query.\n\n        Returns:\n            bool: True if at least one document matches.\n        \"\"\"\n        pass\n\n    def create_index(self, collection: str, index: Tuple[IndexExpression]):\n        \"\"\"\n        Create an index on a collection in the MongoDB Database\n\n        Args:\n            collection (str): The collection name.\n            index (tuple[IndexExpression]):\n                A tuple of IndexExpression objects representing the index to create\n                NOTE: Multiple elements in tuple indicate a single compound index\n                not multiple indexes\n\n        \"\"\"\n        pass\n\nclass MockAsyncMongoDBDriver(AbstractAsyncMongoDBDriver):\n    \"\"\"\n    In-memory mock implementation of the AbstractAsyncMongoDBDriver.\n\n    This async mock mirrors the behavior of MongoDB using native async/await\n    and an in-memory store. Ideal for use in async unit tests.\n    \"\"\"\n\n    def __init__(self, connection_string: str = \"\", database_name: str = \"mockdb\"):\n        \"\"\"\n        Initialize the async mock with an in-memory store.\n\n        Args:\n            connection_string (str): Ignored.\n            database_name (str): Mock database name.\n        \"\"\"\n        pass\n\n    async def connect(self) -> bool:\n        \"\"\"\n        Simulate async connection success.\n\n        Returns:\n            bool: Always True.\n        \"\"\"\n        pass\n\n    async def close(self) -> None:\n        \"\"\"\n        Simulate async close (noop).\n        \"\"\"\n        pass\n\n    async def insert_one(\n        self, collection: str, document: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Asynchronously insert a document into the mock store.\n\n        Args:\n            collection (str): Collection name.\n            document (dict): Document to insert.\n\n        Returns:\n            dict: Insert result with `_id`.\n        \"\"\"\n        pass\n\n    async def insert_many(\n        self, collection: str, documents: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Asynchronously insert multiple documents.\n\n        Args:\n            collection (str): Collection name.\n            documents (list): List of documents.\n\n        Returns:\n            dict: Insert result with `_id`s.\n        \"\"\"\n        pass\n\n    async def find_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Asynchronously find a single matching document.\n\n        Args:\n            collection (str): Collection name.\n            query (dict): Filter.\n\n        Returns:\n            dict or None: Matching document or None.\n        \"\"\"\n        pass\n\n    async def find_many(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        sort_criteria: Dict[str, Any],\n        offset: Optional[int] = None,\n        limit: Optional[int] = None,\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Asynchronously return a list of matching documents.\n\n        Args:\n            collection (str): Collection name.\n            query (dict): Filter.\n            sort_criteria (dict): Ignored.\n            offset (int, optional): Skip N docs.\n            limit (int, optional): Limit docs returned.\n\n        Returns:\n            list: Matching documents.\n        \"\"\"\n        pass\n\n    async def update_one(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        update: Dict[str, Any],\n        upsert: bool = False,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Asynchronously update a single matching document.\n\n        Args:\n            collection (str): Collection name.\n            query (dict): Filter.\n            update (dict): Update expression.\n\n        Returns:\n            dict: Update result.\n        \"\"\"\n        pass\n\n    async def delete_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Asynchronously delete a single matching document.\n\n        Args:\n            collection (str): Collection name.\n            query (dict): Filter.\n\n        Returns:\n            dict: Delete result.\n        \"\"\"\n        pass\n\n    async def count(self, collection: str, query: Dict[str, Any]) -> int:\n        \"\"\"\n        Asynchronously count matching documents.\n\n        Args:\n            collection (str): Collection name.\n            query (dict): Filter.\n\n        Returns:\n            int: Number of matches.\n        \"\"\"\n        pass\n\n    async def exists(self, collection: str, query: Dict[str, Any]) -> bool:\n        \"\"\"\n        Asynchronously check if any document matches the filter.\n\n        Args:\n            collection (str): Collection name.\n            query (dict): Filter.\n\n        Returns:\n            bool: True if at least one match exists.\n        \"\"\"\n        pass\n\n    async def create_index(self, collection: str, index: Tuple[IndexExpression]):\n        \"\"\"\n        Create an index on a collection in the MongoDB Database\n\n        Args:\n            collection (str): The collection name.\n            index (tuple[IndexExpression]):\n                A tuple of IndexExpression objects representing the index to create\n                NOTE: Muiltiple elements in tuple indicate a single compound index\n                not multiple indexes\n\n        \"\"\"\n        pass\n```\n--- File: pydongo/drivers/async_mongo.py ---\n```python\nclass AsyncDefaultMongoDBDriver(AbstractAsyncMongoDBDriver):\n    \"\"\"\n    Default asynchronous MongoDB driver using Motor (async wrapper for PyMongo).\n\n    This driver connects to a real MongoDB instance and provides async methods\n    for insert, update, query, and delete operations.\n    \"\"\"\n\n    def __init__(self, connection_string: str, database_name: str):\n        \"\"\"\n        Initialize the driver with a MongoDB URI and target database name.\n\n        Args:\n            connection_string (str): MongoDB connection URI.\n            database_name (str): Name of the database to use.\n        \"\"\"\n        pass\n\n    async def connect(self) -> bool:\n        \"\"\"\n        Asynchronously establish a connection to the MongoDB server.\n\n        Returns:\n            bool: True if the connection is successful.\n\n        Raises:\n            RuntimeError: If unable to connect to MongoDB.\n        \"\"\"\n        pass\n\n    async def close(self) -> None:\n        \"\"\"\n        Asynchronously close the MongoDB connection.\n        \"\"\"\n        pass\n\n    async def insert_one(\n        self, collection: str, document: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Insert a single document into the specified collection.\n\n        Args:\n            collection (str): Name of the collection.\n            document (dict): Document to insert.\n\n        Returns:\n            dict: Result including the inserted document ID.\n        \"\"\"\n        pass\n\n    async def insert_many(\n        self, collection: str, documents: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Insert multiple documents into the specified collection.\n\n        Args:\n            collection (str): Name of the collection.\n            documents (list): Documents to insert.\n\n        Returns:\n            dict: Result including inserted document IDs.\n        \"\"\"\n        pass\n\n    async def find_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Find a single document that matches the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): MongoDB query object.\n\n        Returns:\n            dict or None: The matching document or None.\n        \"\"\"\n        pass\n\n    async def find_many(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        sort_criteria: Dict[str, int],\n        offset: Optional[int] = None,\n        limit: Optional[int] = None,\n    ) -> Iterable[Dict[str, Any]]:\n        \"\"\"\n        Find multiple documents matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): MongoDB filter query.\n            sort_criteria (dict): Sort order (e.g., {\"created_at\": -1}).\n            offset (int, optional): Number of documents to skip.\n            limit (int, optional): Max number of documents to return.\n\n        Returns:\n            Iterable[dict]: A cursor of matching documents.\n        \"\"\"\n        pass\n\n    async def update_one(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        update: Dict[str, Any],\n        upsert: bool = False,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Update a single document that matches the filter.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): MongoDB filter.\n            update (dict): MongoDB update expression.\n            upsert (bool): If True, create the document if it does not exist.\n\n        Returns:\n            dict: Result of the update operation.\n        \"\"\"\n        pass\n\n    async def delete_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Delete a single document matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): MongoDB filter.\n\n        Returns:\n            dict: Result including count of deleted documents.\n        \"\"\"\n        pass\n\n    async def count(self, collection: str, query: Dict[str, Any]) -> int:\n        \"\"\"\n        Count documents matching the given filter.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): MongoDB filter.\n\n        Returns:\n            int: Number of matching documents.\n        \"\"\"\n        pass\n\n    async def exists(self, collection: str, query: Dict[str, Any]) -> bool:\n        \"\"\"\n        Check if at least one document exists that matches the filter.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): MongoDB filter.\n\n        Returns:\n            bool: True if a matching document exists.\n        \"\"\"\n        pass\n\n    async def create_index(self, collection: str, index: Tuple[IndexExpression]):\n        \"\"\"\n        Create an index on a collection in the MongoDB Database (Async version using Motor).\n\n        Args:\n            collection (str): The collection name.\n            index (tuple[IndexExpression]):\n                A tuple of IndexExpression objects representing the index to create.\n                NOTE: Multiple elements in the tuple indicate a single compound index,\n                not multiple separate indexes.\n        \"\"\"\n        pass\n```\n--- File: pydongo/drivers/sync_mongo.py ---\n```python\nclass DefaultMongoDBDriver(AbstractSyncMongoDBDriver):\n    \"\"\"\n    Default synchronous MongoDB driver implementation using PyMongo.\n\n    This driver connects to a real MongoDB instance and executes\n    blocking operations such as insert, update, query, and delete.\n    \"\"\"\n\n    def __init__(self, connection_string: str, database_name: str):\n        \"\"\"\n        Initialize the driver with a MongoDB connection URI and database name.\n\n        Args:\n            connection_string (str): MongoDB URI (e.g., \"mongodb://localhost:27017\").\n            database_name (str): The target database to operate on.\n        \"\"\"\n        pass\n\n    def connect(self) -> bool:\n        \"\"\"\n        Establish a connection to the MongoDB server.\n\n        Returns:\n            bool: True if the connection is successful.\n\n        Raises:\n            RuntimeError: If connection to MongoDB fails.\n        \"\"\"\n        pass\n\n    def close(self) -> None:\n        \"\"\"\n        Close the MongoDB connection.\n        \"\"\"\n        pass\n\n    def insert_one(self, collection: str, document: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Insert a single document into a collection.\n\n        Args:\n            collection (str): Name of the collection.\n            document (dict): Document to insert.\n\n        Returns:\n            dict: Result of the insert operation, including the inserted ID.\n        \"\"\"\n        pass\n\n    def insert_many(\n        self, collection: str, documents: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Insert multiple documents into a collection.\n\n        Args:\n            collection (str): Name of the collection.\n            documents (list): List of documents to insert.\n\n        Returns:\n            dict: Result including inserted IDs.\n        \"\"\"\n        pass\n\n    def find_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Find a single document that matches the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): MongoDB filter query.\n\n        Returns:\n            dict or None: The found document, or None if not found.\n        \"\"\"\n        pass\n\n    def find_many(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        sort_criteria: Dict[str, Any],\n        offset: Optional[int] = None,\n        limit: Optional[int] = None,\n    ) -> Iterable[Dict[str, Any]]:\n        \"\"\"\n        Find multiple documents that match the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): Filter conditions.\n            sort_criteria (dict): Sorting fields and directions.\n            offset (int, optional): Number of records to skip.\n            limit (int, optional): Maximum number of documents to return.\n\n        Returns:\n            Iterable[dict]: Cursor for matching documents.\n        \"\"\"\n        pass\n\n    def update_one(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        update: Dict[str, Any],\n        upsert: bool = False,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Update a single document matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): Filter conditions.\n            update (dict): Update operations (e.g., {\"$set\": {...}}).\n            upsert (bool): Whether to insert the document if it doesn't exist.\n\n        Returns:\n            dict: Update result with match, modification, and upsert info.\n        \"\"\"\n        pass\n\n    def delete_one(self, collection: str, query: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Delete a single document matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): Filter conditions.\n\n        Returns:\n            dict: Delete result with count of deleted documents.\n        \"\"\"\n        pass\n\n    def count(self, collection: str, query: Dict[str, Any]) -> int:\n        \"\"\"\n        Count the number of documents matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): Filter conditions.\n\n        Returns:\n            int: Number of documents matching the filter.\n        \"\"\"\n        pass\n\n    def exists(self, collection: str, query: Dict[str, Any]) -> bool:\n        \"\"\"\n        Check if at least one document exists that matches the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): Filter conditions.\n\n        Returns:\n            bool: True if a matching document exists.\n        \"\"\"\n        pass\n\n    def create_index(self, collection: str, index: Tuple[IndexExpression]):\n        \"\"\"\n        Create an index on a collection in the MongoDB Database\n\n        Args:\n            collection (str): The collection name.\n            index (tuple[IndexExpression]):\n                A tuple of IndexExpression objects representing the index to create\n                NOTE: Multiple elements in tuple indicate a single compound index\n                not multiple indexes\n\n        \"\"\"\n        pass\n```\n--- File: pydongo/drivers/base.py ---\n```python\nclass AbstractMongoDBDriver(ABC):\n    \"\"\"\n    Abstract base class for MongoDB drivers.\n    \"\"\"\n    pass\n\nclass AbstractSyncMongoDBDriver(AbstractMongoDBDriver):\n    \"\"\"\n    Abstract base class for synchronous MongoDB drivers.\n    Provides context management support and coroutine/thread-safe access\n    to the currently active driver instance via contextvars.\n    \"\"\"\n\n    _current: contextvars.ContextVar[\"AbstractSyncMongoDBDriver\"] = (\n        contextvars.ContextVar(\"mongo_driver_current\")\n    )\n\n    def __init__(self, connection_string: str, database_name: str):\n        \"\"\"\n        Initialize the MongoDB driver with a connection string and database name.\n\n        Args:\n            connection_string (str): MongoDB connection URI.\n            database_name (str): Target database name.\n        \"\"\"\n        pass\n\n    def __enter__(self):\n        \"\"\"\n        Enter the context manager, connect to MongoDB, and set the current driver context.\n        \"\"\"\n        pass\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"\n        Exit the context manager, close the connection, and reset the driver context.\n        \"\"\"\n        pass\n\n    @classmethod\n    def current(cls) -> \"AbstractSyncMongoDBDriver\":\n        \"\"\"\n        Get the current MongoDB driver instance for this coroutine/thread.\n\n        Returns:\n            AbstractMongoDBDriver: The active driver instance.\n\n        Raises:\n            RuntimeError: If no driver is currently in context.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def connect(self) -> bool:\n        \"\"\"\n        Establish a connection to the MongoDB server.\n        Returns:\n            bool: True if connection was successful.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def close(self) -> None:\n        \"\"\"\n        Close the connection to the MongoDB server.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def insert_one(self, collection: str, document: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Insert a single document into the specified collection.\n\n        Args:\n            collection (str): The collection name.\n            document (dict): The document to insert.\n\n        Returns:\n            dict: Result of the insert operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def insert_many(\n        self, collection: str, documents: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Insert multiple documents into the specified collection.\n\n        Args:\n            collection (str): The collection name.\n            documents (list): List of documents to insert.\n\n        Returns:\n            dict: Result of the insert operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def find_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Find a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            dict or None: The found document or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def find_many(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        sort_criteria: Dict[str, Any],\n        offset: Optional[int] = None,\n        limit: Optional[int] = None,\n    ) -> Iterable[Dict[str, Any]]:\n        \"\"\"\n        Find multiple documents matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n            sort_criteria (dict): How to order the results\n            offset (int, optional): Number of records to skip (useful for pagination)\n            limit (int, optional): Max number of documents to return.\n\n        Returns:\n            iterator for result: Iterable sequence of matching documents.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update_one(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        update: Dict[str, Any],\n        upsert: bool = False,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Update a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n            update (dict): The update document.\n\n        Returns:\n            dict: Result of the update operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_one(self, collection: str, query: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Delete a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            dict: Result of the delete operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def count(self, collection: str, query: dict[str, Any]) -> int:\n        \"\"\"\n        Count how many records are in a collection that match the specified query\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            int: Number of documents that match the specified query\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def exists(self, collection: str, query: dict[str, Any]) -> bool:\n        \"\"\"\n        Check if at least one document exists in the collection that matches the\n        specified query\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            bool: True if a document exists and False if it doesn't\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def create_index(self, collection: str, index: Tuple[IndexExpression]):\n        \"\"\"\n        Create an index on a collection in the MongoDB Database\n\n        Args:\n            collection (str): The collection name.\n            index (tuple[IndexExpression]):\n                A tuple of IndexExpression objects representing the index to create\n                NOTE: Multiple elements in tuple indicate a single compound index\n        \"\"\"\n        pass\n\nclass AbstractAsyncMongoDBDriver(AbstractMongoDBDriver):\n    \"\"\"\n    Abstract base class for asynchronous MongoDB drivers.\n    Provides async context management and coroutine-safe access\n    to the currently active driver instance via contextvars.\n    \"\"\"\n\n    _current: contextvars.ContextVar[\"AbstractAsyncMongoDBDriver\"] = (\n        contextvars.ContextVar(\"mongo_driver_current\")\n    )\n\n    def __init__(self, connection_string: str, database_name: str):\n        \"\"\"\n        Initialize the MongoDB driver with a connection string and database name.\n\n        Args:\n            connection_string (str): MongoDB connection URI.\n            database_name (str): Target database name.\n        \"\"\"\n        pass\n\n    async def __aenter__(self):\n        \"\"\"\n        Enter the async context manager, connect to MongoDB, and set the current driver context.\n        \"\"\"\n        pass\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"\n        Exit the async context manager, close the connection, and reset the driver context.\n        \"\"\"\n        pass\n\n    @classmethod\n    def current(cls) -> \"AbstractAsyncMongoDBDriver\":\n        \"\"\"\n        Get the current MongoDB driver instance for this coroutine.\n\n        Returns:\n            AbstractAsyncMongoDBDriver: The active driver instance.\n\n        Raises:\n            RuntimeError: If no driver is currently in context.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def connect(self) -> bool:\n        \"\"\"\n        Establish a connection to the MongoDB server.\n        Returns:\n            bool: True if connection was successful.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def close(self) -> None:\n        \"\"\"\n        Close the connection to the MongoDB server.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def insert_one(\n        self, collection: str, document: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Insert a single document into the specified collection.\n\n        Args:\n            collection (str): The collection name.\n            document (dict): The document to insert.\n\n        Returns:\n            dict: Result of the insert operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def insert_many(\n        self, collection: str, documents: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Insert multiple documents into the specified collection.\n\n        Args:\n            collection (str): The collection name.\n            documents (list): List of documents to insert.\n\n        Returns:\n            dict: Result of the insert operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def find_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Find a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            dict or None: The found document or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def find_many(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        sort_criteria: Dict[str, Any],\n        offset: Optional[int] = None,\n        limit: Optional[int] = None,\n    ) -> Iterable[Dict[str, Any]]:\n        \"\"\"\n        Find multiple documents matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n            sort_criteria (dict): How to order the results\n            offset (int, optional): Number of records to skip (useful for pagination)\n            limit (int, optional): Max number of documents to return.\n\n        Returns:\n            iterable sequence: Iterable sequence of matching documents.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def update_one(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        update: Dict[str, Any],\n        upsert: bool = False,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Update a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n            update (dict): The update document.\n\n        Returns:\n            dict: Result of the update operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def delete_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Delete a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            dict: Result of the delete operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def count(self, collection: str, query: dict[str, Any]) -> int:\n        \"\"\"\n        Count how many records are in a collection that match the specified query\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            int: Number of documents that match the specified query\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def exists(self, collection: str, query: dict[str, Any]) -> bool:\n        \"\"\"\n        Check if at least one document exists in the collection that matches the\n        specified query\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            bool: True if a document exists and False if it doesn't\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def create_index(self, collection: str, index: Tuple[IndexExpression]):\n        \"\"\"\n        Create an index on a collection in the MongoDB Database\n\n        Args:\n            collection (str): The collection name.\n            index (tuple[IndexExpression]):\n                A tuple of IndexExpression objects representing the index to create\n                NOTE: Muiltiple elements in tuple indicate a single compound index\n                not multiple indexes\n        \"\"\"\n        pass\n```\n--- File: pydongo/utils/serializer.py ---\n```python\nT = TypeVar(\"T\", bound=BaseModel)\n\nclass BaseTypeSerializer(ABC):\n    \"\"\"\n    Abstract base class for type serializers.\n\n    Implementations define how to convert values to and from MongoDB-compatible types.\n    \"\"\"\n\n    @staticmethod\n    @abstractmethod\n    def serialize(value: Any) -> Any:\n        \"\"\"\n        Convert a Python value into a MongoDB-storable format.\n\n        Args:\n            value (Any): The value to serialize.\n\n        Returns:\n            Any: A serialized version of the value.\n        \"\"\"\n        pass\n\n    @staticmethod\n    @abstractmethod\n    def deserialize(value: Any) -> Any:\n        \"\"\"\n        Convert a MongoDB-stored value back to a Python-native type.\n\n        Args:\n            value (Any): The value to deserialize.\n\n        Returns:\n            Any: The original Python representation.\n        \"\"\"\n        pass\n\nclass DateSerializer(BaseTypeSerializer):\n    \"\"\"\n    Serializer for converting `datetime.date` to `datetime.datetime`.\n\n    Ensures compatibility with MongoDB, which only supports datetime objects.\n    \"\"\"\n\n    @staticmethod\n    def serialize(value: datetime.date) -> datetime.datetime:\n        \"\"\"\n        Serialize a `date` object into a UTC `datetime` object.\n\n        Args:\n            value (datetime.date): The date to serialize.\n\n        Returns:\n            datetime.datetime: A datetime object representing midnight of the same date.\n        \"\"\"\n        pass\n\n    @staticmethod\n    def deserialize(value: datetime.datetime) -> datetime.date:\n        \"\"\"\n        Deserialize a `datetime` object back into a `date`.\n\n        Args:\n            value (datetime.datetime): The datetime to convert.\n\n        Returns:\n            datetime.date: The date component of the datetime.\n        \"\"\"\n        pass\n\nclass UUIDSerializer(BaseTypeSerializer):\n    \"\"\"\n    Serializer for UUIDs, converting them to and from strings.\n    \"\"\"\n\n    @staticmethod\n    def serialize(value: UUID) -> str:\n        \"\"\"\n        Convert a UUID to a string for MongoDB storage.\n\n        Args:\n            value (UUID): The UUID to serialize.\n\n        Returns:\n            str: String representation of the UUID.\n        \"\"\"\n        pass\n\n    @staticmethod\n    def deserialize(value: str) -> UUID:\n        \"\"\"\n        Convert a string back into a UUID object.\n\n        Args:\n            value (str): UUID string.\n\n        Returns:\n            UUID: The corresponding UUID object.\n        \"\"\"\n        pass\n\ndef replace_unserializable_fields(document: dict) -> dict:\n    \"\"\"\n    Recursively replaces values in a document that are not MongoDB-compatible\n    with serialized equivalents, using registered type handlers.\n\n    Args:\n        document (dict): The original document to sanitize.\n\n    Returns:\n        dict: A deep-copied document with serializable values.\n    \"\"\"\n    pass\n\ndef restore_unserializable_fields(document: dict) -> dict:\n    \"\"\"\n    Recursively attempts to deserialize known types in a document.\n\n    NOTE: This is a basic placeholder strategy — it applies all registered deserializers\n    without knowing the intended field type. This can result in incorrect types.\n\n    It's recommended to use field-aware deserialization (tied to model schemas)\n    for production use.\n\n    Args:\n        document (dict): A document retrieved from MongoDB.\n\n    Returns:\n        dict: A deep-copied document with deserialized values (best-effort).\n    \"\"\"\n    pass\n```\n--- File: pydongo/utils/annotations.py ---\n```python\ndef resolve_annotation(annotation: Any) -> Any:\n    \"\"\"\n    Helper function to resolve actual data types from Optional, Union, or Annotated wrappers.\n\n    Args:\n        annotation (Any): Type annotation from the Pydantic model.\n\n    Returns:\n        Any: The resolved base type annotation.\n    \"\"\"\n    pass\n```",
        "minimal_code_skeleton": "--- File: pydongo/__init__.py ---\n```python\n# This file is intentionally left empty as per the analysis.\n# Test cases import `as_collection` from `pydongo`,\n# but its definition resides in `pydongo.workers.collection`.\n# The skeleton adheres to \"NO Import Statements\", so re-exports are omitted.\n# A user implementing the skeleton would need to ensure `pydongo/__init__.py`\n# makes `as_collection` available if test cases are to be run unmodified.\npass\n```\n\n--- File: pydongo/drivers/base.py ---\n```python\nfrom abc import ABC, abstractmethod\nfrom typing import List, Dict, Any, Optional, Iterable, Tuple\n\nfrom pydongo.expressions.index import IndexExpression\n\n\nclass AbstractMongoDBDriver(ABC):\n    \"\"\"\n    Abstract base class for MongoDB drivers.\n    \"\"\"\n    pass\n\n\nclass AbstractSyncMongoDBDriver(AbstractMongoDBDriver):\n    \"\"\"\n    Abstract base class for synchronous MongoDB drivers.\n    Provides context management support and coroutine/thread-safe access\n    to the currently active driver instance via contextvars.\n    \"\"\"\n    def __init__(self, connection_string: str, database_name: str):\n        \"\"\"\n        Initialize the MongoDB driver with a connection string and database name.\n\n        Args:\n            connection_string (str): MongoDB connection URI.\n            database_name (str): Target database name.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def connect(self) -> bool:\n        \"\"\"\n        Establish a connection to the MongoDB server.\n        Returns:\n            bool: True if connection was successful.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def close(self) -> None:\n        \"\"\"\n        Close the connection to the MongoDB server.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def insert_one(self, collection: str, document: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Insert a single document into the specified collection.\n\n        Args:\n            collection (str): The collection name.\n            document (dict): The document to insert.\n\n        Returns:\n            dict: Result of the insert operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def insert_many(\n        self, collection: str, documents: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Insert multiple documents into the specified collection.\n\n        Args:\n            collection (str): The collection name.\n            documents (list): List of documents to insert.\n\n        Returns:\n            dict: Result of the insert operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def find_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Find a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            dict or None: The found document or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def find_many(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        sort_criteria: Dict[str, Any],\n        offset: Optional[int] = None,\n        limit: Optional[int] = None,\n    ) -> Iterable[Dict[str, Any]]:\n        \"\"\"\n        Find multiple documents matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n            sort_criteria (dict): How to order the results\n            offset (int, optional): Number of records to skip (useful for pagination)\n            limit (int, optional): Max number of documents to return.\n\n        Returns:\n            iterator for result: Iterable sequence of matching documents.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update_one(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        update: Dict[str, Any],\n        upsert: bool = False,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Update a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n            update (dict): The update document.\n\n        Returns:\n            dict: Result of the update operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_one(self, collection: str, query: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Delete a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            dict: Result of the delete operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def count(self, collection: str, query: dict[str, Any]) -> int:\n        \"\"\"\n        Count how many records are in a collection that match the specified query\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            int: Number of documents that match the specified query\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def exists(self, collection: str, query: dict[str, Any]) -> bool:\n        \"\"\"\n        Check if at least one document exists in the collection that matches the\n        specified query\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            bool: True if a document exists and False if it doesn't\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def create_index(self, collection: str, index: Tuple[IndexExpression]):\n        \"\"\"\n        Create an index on a collection in the MongoDB Database\n\n        Args:\n            collection (str): The collection name.\n            index (tuple[IndexExpression]):\n                A tuple of IndexExpression objects representing the index to create\n                NOTE: Multiple elements in tuple indicate a single compound index\n        \"\"\"\n        pass\n\n\nclass AbstractAsyncMongoDBDriver(AbstractMongoDBDriver):\n    \"\"\"\n    Abstract base class for asynchronous MongoDB drivers.\n    Provides async context management and coroutine-safe access\n    to the currently active driver instance via contextvars.\n    \"\"\"\n    def __init__(self, connection_string: str, database_name: str):\n        \"\"\"\n        Initialize the MongoDB driver with a connection string and database name.\n\n        Args:\n            connection_string (str): MongoDB connection URI.\n            database_name (str): Target database name.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def connect(self) -> bool:\n        \"\"\"\n        Establish a connection to the MongoDB server.\n        Returns:\n            bool: True if connection was successful.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def close(self) -> None:\n        \"\"\"\n        Close the connection to the MongoDB server.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def insert_one(\n        self, collection: str, document: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Insert a single document into the specified collection.\n\n        Args:\n            collection (str): The collection name.\n            document (dict): The document to insert.\n\n        Returns:\n            dict: Result of the insert operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def insert_many(\n        self, collection: str, documents: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Insert multiple documents into the specified collection.\n\n        Args:\n            collection (str): The collection name.\n            documents (list): List of documents to insert.\n\n        Returns:\n            dict: Result of the insert operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def find_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Find a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            dict or None: The found document or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def find_many(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        sort_criteria: Dict[str, Any],\n        offset: Optional[int] = None,\n        limit: Optional[int] = None,\n    ) -> Iterable[Dict[str, Any]]:\n        \"\"\"\n        Find multiple documents matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n            sort_criteria (dict): How to order the results\n            offset (int, optional): Number of records to skip (useful for pagination)\n            limit (int, optional): Max number of documents to return.\n\n        Returns:\n            iterable sequence: Iterable sequence of matching documents.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def update_one(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        update: Dict[str, Any],\n        upsert: bool = False,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Update a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n            update (dict): The update document.\n\n        Returns:\n            dict: Result of the update operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def delete_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Delete a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            dict: Result of the delete operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def count(self, collection: str, query: dict[str, Any]) -> int:\n        \"\"\"\n        Count how many records are in a collection that match the specified query\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            int: Number of documents that match the specified query\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def exists(self, collection: str, query: dict[str, Any]) -> bool:\n        \"\"\"\n        Check if at least one document exists in the collection that matches the\n        specified query\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            bool: True if a document exists and False if it doesn't\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def create_index(self, collection: str, index: Tuple[IndexExpression]):\n        \"\"\"\n        Create an index on a collection in the MongoDB Database\n\n        Args:\n            collection (str): The collection name.\n            index (tuple[IndexExpression]):\n                A tuple of IndexExpression objects representing the index to create\n                NOTE: Muiltiple elements in tuple indicate a single compound index\n                not multiple indexes\n        \"\"\"\n        pass\n```\n\n--- File: pydongo/drivers/mock.py ---\n```python\nfrom typing import List, Dict, Any, Optional, Tuple\n\nfrom pydongo.drivers.base import AbstractSyncMongoDBDriver, AbstractAsyncMongoDBDriver\nfrom pydongo.expressions.index import IndexExpression\n\n\nclass MockMongoDBDriver(AbstractSyncMongoDBDriver):\n    \"\"\"\n    In-memory mock implementation of the AbstractSyncMongoDBDriver.\n\n    This mock driver mimics MongoDB behavior for unit testing without requiring\n    a real database connection. Data is stored in-memory in Python dictionaries.\n    \"\"\"\n    def __init__(self, connection_string: str = \"\", database_name: str = \"mockdb\"):\n        \"\"\"\n        Initialize the mock driver with an empty in-memory store.\n\n        Args:\n            connection_string (str): Ignored.\n            database_name (str): Name of the fake database.\n        \"\"\"\n        pass\n\n    def connect(self) -> bool:\n        \"\"\"\n        Simulate a successful connection.\n\n        Returns:\n            bool: Always True.\n        \"\"\"\n        pass\n\n    def insert_one(self, collection: str, document: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Insert a document into the in-memory collection.\n\n        Args:\n            collection (str): Name of the collection.\n            document (dict): Document to insert.\n\n        Returns:\n            dict: Insert result including generated `_id`.\n        \"\"\"\n        pass\n\n    def find_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Find a single document matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): MongoDB-style filter.\n\n        Returns:\n            dict or None: Matching document or None if not found.\n        \"\"\"\n        pass\n\n    def update_one(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        update: Dict[str, Any],\n        upsert: bool = False,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Update a single document matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): Filter query.\n            update (dict): Update operations (only supports \"$set\").\n\n        Returns:\n            dict: Update result with matched and modified count.\n        \"\"\"\n        pass\n\n    def delete_one(self, collection: str, query: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Delete the first document matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): Filter query.\n\n        Returns:\n            dict: Delete result.\n        \"\"\"\n        pass\n\n    def create_index(self, collection: str, index: Tuple[IndexExpression]):\n        \"\"\"\n        Create an index on a collection in the MongoDB Database\n\n        Args:\n            collection (str): The collection name.\n            index (tuple[IndexExpression]):\n                A tuple of IndexExpression objects representing the index to create\n                NOTE: Multiple elements in tuple indicate a single compound index\n                not multiple indexes\n\n        \"\"\"\n        pass\n\n\nclass MockAsyncMongoDBDriver(AbstractAsyncMongoDBDriver):\n    \"\"\"\n    In-memory mock implementation of the AbstractAsyncMongoDBDriver.\n\n    This async mock mirrors the behavior of MongoDB using native async/await\n    and an in-memory store. Ideal for use in async unit tests.\n    \"\"\"\n    def __init__(self, connection_string: str = \"\", database_name: str = \"mockdb\"):\n        \"\"\"\n        Initialize the async mock with an in-memory store.\n\n        Args:\n            connection_string (str): Ignored.\n            database_name (str): Mock database name.\n        \"\"\"\n        pass\n\n    async def connect(self) -> bool:\n        \"\"\"\n        Simulate async connection success.\n\n        Returns:\n            bool: Always True.\n        \"\"\"\n        pass\n\n    async def create_index(self, collection: str, index: Tuple[IndexExpression]):\n        \"\"\"\n        Create an index on a collection in the MongoDB Database\n\n        Args:\n            collection (str): The collection name.\n            index (tuple[IndexExpression]):\n                A tuple of IndexExpression objects representing the index to create\n                NOTE: Muiltiple elements in tuple indicate a single compound index\n                not multiple indexes\n\n        \"\"\"\n        pass\n```\n\n--- File: pydongo/expressions/base.py ---\n```python\nfrom abc import ABC, abstractmethod\nfrom typing import Any\n\n\nclass BaseExpression(ABC):\n    @abstractmethod\n    def serialize(self) -> Any:\n        \"\"\"\n        Serialize an expression into a MongoDB compatible query DTO\n        \"\"\"\n        pass\n```\n\n--- File: pydongo/expressions/filter.py ---\n```python\nfrom typing import Optional\nfrom pydongo.expressions.base import BaseExpression\n\n\nclass CollectionFilterExpression(BaseExpression):\n    \"\"\"\n    Represents a boolean filter expression used to query a MongoDB collection.\n\n    These expressions are composable using:\n        - Logical OR (`|`)\n        - Logical AND (`&`)\n        - Logical NOT (`~`)\n\n    Example usage:\n        filter_1 = User.age > 18\n        filter_2 = User.name == \"Samuel\"\n        combined = filter_1 & filter_2\n\n    The resulting expression can be serialized and passed to the database driver.\n    \"\"\"\n    def __init__(self, expression: Optional[dict] = None):\n        \"\"\"\n        Initialize the filter expression with an optional initial dictionary.\n\n        Args:\n            expression (Optional[dict]): A MongoDB-style query dictionary.\n        \"\"\"\n        pass\n\n    def with_expression(self, expression: dict) -> \"CollectionFilterExpression\":\n        \"\"\"\n        Mutate the internal expression by merging in a new dictionary.\n\n        Args:\n            expression (dict): A MongoDB-style query to merge into the current expression.\n\n        Returns:\n            CollectionFilterExpression: The current instance (for chaining).\n        \"\"\"\n        pass\n\n    def serialize(self) -> dict:\n        \"\"\"\n        Serialize the filter expression into a MongoDB-compatible query object.\n\n        Returns:\n            dict: Serialized MongoDB query.\n        \"\"\"\n        pass\n\n    def __and__(\n        self, other: \"CollectionFilterExpression\"\n    ) -> \"CollectionFilterExpression\":\n        \"\"\"\n        Combine this filter with another using a logical AND.\n\n        Args:\n            other (CollectionFilterExpression): Another filter to combine with.\n\n        Returns:\n            CollectionFilterExpression: A new combined filter.\n        \"\"\"\n        pass\n\n    def __or__(\n        self, other: \"CollectionFilterExpression\"\n    ) -> \"CollectionFilterExpression\":\n        \"\"\"\n        Combine this filter with another using a logical OR.\n\n        Args:\n            other (CollectionFilterExpression): Another filter to combine with.\n\n        Returns:\n            CollectionFilterExpression: A new combined filter.\n        \"\"\"\n        pass\n\n    def __invert__(self) -> \"CollectionFilterExpression\":\n        \"\"\"\n        Invert the current filter using a logical NOT.\n\n        Returns:\n            CollectionFilterExpression: A new filter expression wrapped in `$not`.\n        \"\"\"\n        pass\n```\n\n--- File: pydongo/expressions/field.py ---\n```python\nfrom typing import Any, Iterable, Sequence\nfrom pydongo.expressions.filter import CollectionFilterExpression\nfrom pydongo.expressions.index import (\n    IndexExpression,\n    IndexExpressionBuilder,\n)\n\n\nclass FieldExpression:\n    \"\"\"\n    Represents a scalar field in a MongoDB query.\n\n    This class supports operator overloading to build query expressions using:\n        ==, !=, >, >=, <, <=\n\n    It also supports nested attribute access (e.g., user.address.city).\n    \"\"\"\n    def __init__(self, field_name: str, annotation=None, sort_ascending: bool = True):\n        \"\"\"\n        Initialize a field expression.\n\n        Args:\n            field_name (str): The full dot-path name of the field.\n            annotation (Any): The Pydantic type annotation for the field.\n            sort_ascending (bool): Whether sorting on this field is ascending by default.\n        \"\"\"\n        pass\n\n    def as_index(self) -> IndexExpressionBuilder:\n        \"\"\"\n        Returns an `IndexExpressionBuilder` initialized with this field.\n\n        This allows users to customize the index further, such as adding uniqueness,\n        TTL, collation, or partial filter expressions—before building the final index object.\n        \"\"\"\n        pass\n\n    def __eq__(self, other: Any) -> \"CollectionFilterExpression\":  # type: ignore\n        \"\"\"Build an equality expression (`==`).\"\"\"\n        pass\n\n    def __ne__(self, other: Any) -> \"CollectionFilterExpression\":  # type: ignore\n        \"\"\"Build an inequality expression (`!=`).\"\"\"\n        pass\n\n    def __gt__(self, other: Any) -> \"CollectionFilterExpression\":\n        \"\"\"Build a greater-than expression (`>`).\"\"\"\n        pass\n\n    def __ge__(self, other: Any) -> \"CollectionFilterExpression\":\n        \"\"\"Build a greater-than-or-equal expression (`>=`).\"\"\"\n        pass\n\n    def __lt__(self, other: Any) -> \"CollectionFilterExpression\":\n        \"\"\"Build a less-than expression (`<`).\"\"\"\n        pass\n\n    def __le__(self, other: Any) -> \"CollectionFilterExpression\":\n        \"\"\"Build a less-than-or-equal expression (`<=`).\"\"\"\n        pass\n\n    def __neg__(self) -> \"FieldExpression\":\n        \"\"\"\n        Flip the default sort order.\n\n        Returns:\n            FieldExpression: A new instance with reversed sort order.\n        \"\"\"\n        pass\n\n    @property\n    def field_name(self):\n        \"\"\"The full field name, including nested paths if applicable.\"\"\"\n        pass\n\n    def __getattr__(self, name: str) -> \"FieldExpression\":\n        \"\"\"\n        Support for chained dot notation, e.g. `user.address.city`.\n\n        Args:\n            name (str): Subfield name.\n\n        Returns:\n            FieldExpression: A new field expression for the nested field.\n        \"\"\"\n        pass\n\n\nclass ArraySizeFieldExpression(FieldExpression):\n    \"\"\"\n    Represents an expression for the size of an array field.\n\n    Used for queries like: `len(User.tags) > 2`\n    \"\"\"\n    def _get_comparative_expression(self, operator: str, value: int) -> dict:\n        \"\"\"\n        Build a MongoDB `$expr` query comparing the size of an array.\n\n        Args:\n            operator (str): Comparison operator (e.g., \"$gt\").\n            value (int): Value to compare the array size against.\n\n        Returns:\n            dict: MongoDB `$expr` query.\n        \"\"\"\n        pass\n\n\nclass ArrayFieldExpression(FieldExpression):\n    \"\"\"\n    Represents an array field in a MongoDB document.\n\n    Adds support for array-specific operations like `.contains()`, `.size()`, and `.matches()`.\n    \"\"\"\n    def __init__(self, field_name: str, annotation=None, sort_ascending: bool = True): # Explicitly listed as it's directly instantiated\n        \"\"\"\n        Initialize an array field expression.\n\n        Args:\n            field_name (str): The full dot-path name of the field.\n            annotation (Any): The Pydantic type annotation for the field.\n            sort_ascending (bool): Whether sorting on this field is ascending by default.\n        \"\"\"\n        super().__init__(field_name, annotation, sort_ascending) # Call to super is implementation detail, but signature is needed.\n        pass\n\n\n    def size(self) -> ArraySizeFieldExpression:\n        \"\"\"\n        Get an expression that targets the array's length.\n\n        Returns:\n            ArraySizeFieldExpression: An expression targeting the array's size.\n        \"\"\"\n        pass\n\n    def matches(\n        self, values: Iterable[Any], match_order: bool = False\n    ) -> CollectionFilterExpression:\n        \"\"\"\n        Check if the array exactly matches the provided values.\n\n        Args:\n            values (Iterable[Any]): Values to match against.\n            match_order (bool): If True, requires order-sensitive match.\n\n        Returns:\n            CollectionFilterExpression: MongoDB `$all` or exact match query.\n        \"\"\"\n        pass\n\n    def contains(self, value: Any) -> CollectionFilterExpression:\n        \"\"\"\n        Check if the array contains one or more values.\n\n        Args:\n            value (Any): A scalar or iterable to check presence for.\n\n        Returns:\n            CollectionFilterExpression: MongoDB `$in` expression.\n        \"\"\"\n        pass\n\n    def excludes(self, value: Any) -> CollectionFilterExpression:\n        \"\"\"\n        Check if the array excludes one or more values.\n\n        Args:\n            value (Any): A scalar or iterable to check absence for.\n\n        Returns:\n            CollectionFilterExpression: MongoDB `$nin` expression.\n        \"\"\"\n        pass\n```\n\n--- File: pydongo/expressions/index.py ---\n```python\nfrom typing import Optional, Any, Tuple\nfrom enum import Enum, IntEnum\nfrom pydongo.expressions.base import BaseExpression\nfrom pydongo.expressions.filter import CollectionFilterExpression\n\n\nclass IndexSortOrder(IntEnum):\n    ASCENDING = 1\n    DESCENDING = -1\n\n\nclass IndexType(str, Enum):\n    TEXT = \"text\"\n    HASHED = \"hashed\"\n    TWO_DIMENSIONAL = \"2d\"\n    TWO_DIMENSIONAL_SPHERE = \"2dsphere\"\n\n\nclass CollationStrength(IntEnum):\n    PRIMARY = 1  # Only base characters (e.g., \"a\" == \"A\", \"é\" == \"e\")\n    SECONDARY = 2  # Case-insensitive, accent-sensitive (e.g., \"a\" == \"A\", \"é\" != \"e\")\n    TERTIARY = 3  # Case- and accent-sensitive (e.g., \"a\" != \"A\", \"é\" != \"e\")\n    QUATERNARY = 4  # Includes case, accent, punctuation (e.g., \"$a\" != \"a\")\n    IDENTICAL = 5  # Everything is compared (e.g., code point level)\n\n\nclass IndexExpression(BaseExpression):\n    def __init__(\n        self,\n        field_name: str,\n        index_type: Optional[IndexType] = None,\n        sort_order: IndexSortOrder = IndexSortOrder.ASCENDING,\n        expires_after_seconds: Optional[float] = None,  # For TTL indexes\n        is_sparse: Optional[bool] = None,\n        is_unique: Optional[bool] = None,\n        is_hidden: Optional[bool] = None,\n        collation_locale: str = \"en\",\n        collation_strength: Optional[CollationStrength] = None,\n        partial_expression: Optional[CollectionFilterExpression] = None,\n        index_name: Optional[str] = None,\n    ):\n        pass\n\n    def serialize(self) -> dict:\n        pass\n\n    def build_kwargs(self) -> dict:\n        \"\"\"\n        Additional specifications for the index to be passed to MongoDB's create_index.\n        Only includes non-null values.\n        \"\"\"\n        pass\n\n\nclass IndexExpressionBuilder:\n    def __init__(self, field_name: str):\n        pass\n\n    def use_sort_order(self, sort_order: IndexSortOrder) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_index_type(self, index_type: IndexType) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_collation(\n        self, locale: str, strength: CollationStrength\n    ) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_index_name(self, index_name: str) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_sparse(self, is_sparse: bool = True) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_unique(self, is_unique: bool = True) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_ttl(self, seconds: float) -> \"IndexExpressionBuilder\":\n        pass\n\n    def build_index(self) -> IndexExpression:\n        pass\n```\n\n--- File: pydongo/utils/annotations.py ---\n```python\nfrom typing import Any\n\n\ndef resolve_annotation(annotation: Any) -> Any:\n    \"\"\"\n    Helper function to resolve actual data types from Optional, Union, or Annotated wrappers.\n\n    Args:\n        annotation (Any): Type annotation from the Pydantic model.\n\n    Returns:\n        Any: The resolved base type annotation.\n    \"\"\"\n    pass\n```\n\n--- File: pydongo/utils/serializer.py ---\n```python\nfrom typing import Any\n\n\ndef replace_unserializable_fields(document: dict) -> dict:\n    \"\"\"\n    Recursively replaces values in a document that are not MongoDB-compatible\n    with serialized equivalents, using registered type handlers.\n\n    Args:\n        document (dict): The original document to sanitize.\n\n    Returns:\n        dict: A deep-copied document with serializable values.\n    \"\"\"\n    pass\n```\n\n--- File: pydongo/workers/collection.py ---\n```python\nfrom abc import ABC\nfrom typing import (\n    Generic,\n    Iterable,\n    Optional,\n    Sequence,\n    Type,\n    Tuple,\n    TypeVar,\n    Union,\n)\nfrom pydantic import BaseModel\n\nfrom pydongo.expressions.field import FieldExpression\nfrom pydongo.expressions.filter import CollectionFilterExpression\nfrom pydongo.expressions.index import IndexExpression\n\nfrom pydongo.drivers.base import (\n    AbstractSyncMongoDBDriver,\n    AbstractAsyncMongoDBDriver,\n)\n\n\nT = TypeVar(\"T\", bound=BaseModel)\n\n\ndef as_collection(\n    pydantic_model: Type[T],\n    driver: Union[AbstractSyncMongoDBDriver, AbstractAsyncMongoDBDriver],\n) -> \"CollectionWorker\":\n    pass\n\n\nclass CollectionWorker(Generic[T]):\n    \"\"\"\n    Entry point for querying and interacting with a MongoDB collection.\n\n    Wraps a Pydantic model and MongoDB driver, and exposes queryable field expressions\n    and high-level `find_one`, `afind_one`, and `find` methods.\n\n    Supports both sync and async drivers via conditional branching.\n    \"\"\"\n    def __init__(\n        self,\n        pydantic_model: Type[T],\n        driver: Union[AbstractSyncMongoDBDriver, AbstractAsyncMongoDBDriver],\n    ):\n        pass\n\n    def find(\n        self, expression: Optional[CollectionFilterExpression] = None\n    ) -> \"CollectionResponseBuilder\":\n        \"\"\"\n        Initiates a fluent response builder chain for querying multiple documents.\n\n        Args:\n            expression (Optional[CollectionFilterExpression]): Optional filter expression.\n\n        Returns:\n            CollectionResponseBuilder: Builder for fluent chaining (e.g., .limit(), .sort()).\n        \"\"\"\n        pass\n\n    def use_index(\n        self,\n        index: Union[IndexExpression, Tuple[IndexExpression]],\n    ):\n        \"\"\"\n        Registers an index (or compound index) on the collection.\n\n        Accepts IndexExpression(s)\n\n        Args:\n            index: A single IndexExpression, or a tuple of them.\n\n        Returns:\n            CollectionWorker: Self, for method chaining.\n        \"\"\"\n        pass\n\n    def __getattr__(self, name: str) -> FieldExpression:\n        \"\"\"\n        Returns a field expression object to enable DSL-style querying using comparison\n        operators or dot notation for nested objects.\n\n        Args:\n            name (str): Field name in the Pydantic model.\n\n        Returns:\n            FieldExpression: Expression object tied to the field.\n\n        Raises:\n            AttributeError: If the field does not exist on the model.\n        \"\"\"\n        pass\n\n    @property\n    def collection_name(self):\n        \"\"\"\n        Derives the MongoDB collection name from the model or falls back to the class name.\n\n        Returns:\n            str: The name of the collection.\n        \"\"\"\n        pass\n\n\nclass CollectionResponseBuilder(ABC, Generic[T]):\n    \"\"\"\n    Fluent builder for composing queries and retrieving lists of documents.\n\n    Can build the final MongoDB query structure with sort, skip, and limit options.\n    \"\"\"\n    def __init__(\n        self,\n        expression: CollectionFilterExpression,\n        pydantic_model: Type[T],\n        driver: Union[AbstractSyncMongoDBDriver, AbstractAsyncMongoDBDriver],\n        collection_name: str,\n        indexes: Iterable[Tuple[IndexExpression]],\n    ):\n        pass\n\n    def skip(self, offset: int) -> \"CollectionResponseBuilder\":\n        \"\"\"\n        Skip the first N documents in the query result.\n\n        Args:\n            offset (int): Number of documents to skip.\n\n        Returns:\n            CollectionResponseBuilder: For chaining.\n        \"\"\"\n        pass\n\n    def limit(self, limit_value: int) -> \"CollectionResponseBuilder\":\n        \"\"\"\n        Limit the number of documents returned.\n\n        Args:\n            limit_value (int): Maximum number of documents to return.\n\n        Returns:\n            CollectionResponseBuilder: For chaining.\n        \"\"\"\n        pass\n\n    def sort(\n        self, sort_criteria: Union[FieldExpression, Sequence[FieldExpression]]\n    ) -> \"CollectionResponseBuilder\":\n        \"\"\"\n        Apply sort criteria to the query.\n\n        Args:\n            sort_criteria (Union[FieldExpression, Sequence[FieldExpression]]): Sort instructions.\n\n        Returns:\n            CollectionResponseBuilder: For chaining.\n        \"\"\"\n        pass\n\n    def build_kwargs(self) -> dict:\n        \"\"\"\n        Assembles the query, sort, offset, and limit into a single dictionary.\n\n        Returns:\n            dict: MongoDB-compatible query parameters.\n        \"\"\"\n        pass\n\n\nclass SyncCollectionResponseBuilder(CollectionResponseBuilder):\n    \"\"\"\n    Response builder for synchronous drivers.\n\n    Provides direct methods to count, check existence, and iterate documents.\n    \"\"\"\n    def __init__(\n        self,\n        expression: CollectionFilterExpression,\n        pydantic_model: Type[T],\n        driver: AbstractSyncMongoDBDriver,\n        collection_name: str,\n        indexes: Iterable[Tuple[IndexExpression]],\n    ):\n        pass\n\n    def count(self) -> int:\n        \"\"\"\n        Count how many documents match the filter expression.\n\n        Returns:\n            int: Number of matching documents.\n        \"\"\"\n        pass\n\n    def create_indexes(self):\n        \"\"\"\n        Creates indexes on the MongoDB database.\n        \"\"\"\n        pass\n\n\nclass AsyncCollectionResponseBuilder(CollectionResponseBuilder):\n    \"\"\"\n    Response builder for asynchronous drivers.\n\n    Supports async versions of exists, count, and all().\n    \"\"\"\n    def __init__(\n        self,\n        expression: CollectionFilterExpression,\n        pydantic_model: Type[T],\n        driver: AbstractAsyncMongoDBDriver,\n        collection_name: str,\n        indexes: Iterable[Tuple[IndexExpression]],\n    ):\n        pass\n\n    async def count(self) -> int:\n        \"\"\"\n        Asynchronously count how many documents match the filter.\n\n        Returns:\n            int: Number of matching documents.\n        \"\"\"\n        pass\n\n    async def create_indexes(self):\n        \"\"\"\n        Asynchronously creates indexes on the MongoDB database.\n        \"\"\"\n        pass\n```",
        "minimal_test_cases": [
            {
                "test_id": "tests/test_driver_mock.py::test_insert_and_find_one",
                "covers": [
                    "pydongo.drivers.mock.MockMongoDBDriver.__init__ - instantiation",
                    "pydongo.drivers.mock.MockMongoDBDriver.connect - successful connection",
                    "pydongo.drivers.mock.MockMongoDBDriver.insert_one - happy path",
                    "pydongo.drivers.mock.MockMongoDBDriver.find_one - happy path"
                ]
            },
            {
                "test_id": "tests/test_driver_mock.py::test_update_and_delete",
                "covers": [
                    "pydongo.drivers.mock.MockMongoDBDriver.update_one - happy path",
                    "pydongo.drivers.mock.MockMongoDBDriver.delete_one - happy path"
                ]
            },
            {
                "test_id": "tests/test_resolve_annotation.py::test_resolve_annotation_union",
                "covers": [
                    "pydongo.utils.annotations.resolve_annotation - with Union types"
                ]
            },
            {
                "test_id": "tests/test_resolve_annotation.py::test_resolve_annotation_optional",
                "covers": [
                    "pydongo.utils.annotations.resolve_annotation - with Optional types"
                ]
            },
            {
                "test_id": "tests/test_resolve_annotation.py::test_resolve_annotation_annotated",
                "covers": [
                    "pydongo.utils.annotations.resolve_annotation - with Annotated types"
                ]
            },
            {
                "test_id": "tests/test_filter_expression.py::test_with_expression_merges_dict",
                "covers": [
                    "pydongo.expressions.filter.CollectionFilterExpression.__init__ - instantiation",
                    "pydongo.expressions.filter.CollectionFilterExpression.with_expression - happy path",
                    "pydongo.expressions.filter.CollectionFilterExpression.serialize - happy path"
                ]
            },
            {
                "test_id": "tests/test_filter_expression.py::test_and_combines_two_expressions",
                "covers": [
                    "pydongo.expressions.filter.CollectionFilterExpression.__and__ - logical AND operation"
                ]
            },
            {
                "test_id": "tests/test_filter_expression.py::test_or_combines_two_expressions",
                "covers": [
                    "pydongo.expressions.filter.CollectionFilterExpression.__or__ - logical OR operation"
                ]
            },
            {
                "test_id": "tests/test_filter_expression.py::test_not_inverts_expression",
                "covers": [
                    "pydongo.expressions.filter.CollectionFilterExpression.__invert__ - logical NOT operation"
                ]
            },
            {
                "test_id": "tests/test_serilizer_utils.py::test_nested_serialization",
                "covers": [
                    "pydongo.utils.serializer.replace_unserializable_fields - comprehensive with date, uuid, and nesting"
                ]
            },
            {
                "test_id": "tests/test_collection_builder_core.py::test_collection_builder_sort_limit_skip_multi_sort",
                "covers": [
                    "pydongo.as_collection - happy path instantiation",
                    "pydongo.workers.collection.CollectionWorker.find - initiates query builder",
                    "pydongo.workers.collection.CollectionWorker.__getattr__ - field access for queries/sorting",
                    "pydongo.expressions.field.FieldExpression.__gt__ - greater than comparison",
                    "pydongo.expressions.field.FieldExpression.__neg__ - sort order toggle",
                    "pydongo.workers.collection.SyncCollectionResponseBuilder.sort - happy path",
                    "pydongo.workers.collection.SyncCollectionResponseBuilder.limit - happy path",
                    "pydongo.workers.collection.SyncCollectionResponseBuilder.skip - happy path",
                    "pydongo.workers.collection.SyncCollectionResponseBuilder.build_kwargs - query assembly"
                ]
            },
            {
                "test_id": "tests/test_collection_builder_core.py::test_collection_builder_null_state_defaults",
                "covers": [
                    "pydongo.workers.collection.SyncCollectionResponseBuilder.build_kwargs - default state"
                ]
            },
            {
                "test_id": "tests/test_field_expression.py::test_comparative_operators_resolve_correct_queries",
                "covers": [
                    "pydongo.expressions.field.FieldExpression.__init__ - instantiation",
                    "pydongo.expressions.field.FieldExpression.__eq__ - equality comparison",
                    "pydongo.expressions.field.FieldExpression.__ne__ - inequality comparison",
                    "pydongo.expressions.field.FieldExpression.__ge__ - greater than or equal comparison",
                    "pydongo.expressions.field.FieldExpression.__lt__ - less than comparison",
                    "pydongo.expressions.field.FieldExpression.__le__ - less than or equal comparison"
                ]
            },
            {
                "test_id": "tests/test_field_expression.py::test_nested_fields",
                "covers": [
                    "pydongo.expressions.field.FieldExpression.__getattr__ - nested field access",
                    "pydongo.expressions.field.FieldExpression.field_name - property access"
                ]
            },
            {
                "test_id": "tests/test_field_expression.py::test_array_field_size_expression",
                "covers": [
                    "pydongo.expressions.field.ArrayFieldExpression.size - getting array size expression",
                    "pydongo.expressions.field.ArraySizeFieldExpression.__gt__ - array size comparison"
                ]
            },
            {
                "test_id": "tests/test_field_expression.py::test_array_field_contains_and_excludes",
                "covers": [
                    "pydongo.expressions.field.ArrayFieldExpression.contains - array contains value",
                    "pydongo.expressions.field.ArrayFieldExpression.excludes - array excludes value"
                ]
            },
            {
                "test_id": "tests/test_field_expression.py::test_array_field_matches_with_and_without_order",
                "covers": [
                    "pydongo.expressions.field.ArrayFieldExpression.matches - array matches values"
                ]
            },
            {
                "test_id": "tests/test_field_expression.py::test_len_and_contains_sugar",
                "covers": [
                    "pydongo.expressions.field.ArrayFieldExpression.__len__ - syntactic sugar for size",
                    "pydongo.expressions.field.ArrayFieldExpression.__contains__ - syntactic sugar for contains"
                ]
            },
            {
                "test_id": "tests/test_index_creation.py::test_single_key_index",
                "covers": [
                    "pydongo.expressions.field.FieldExpression.as_index - initiating index builder",
                    "pydongo.expressions.index.IndexExpressionBuilder.use_unique - unique constraint",
                    "pydongo.expressions.index.IndexExpressionBuilder.build_index - finalizing index expression",
                    "pydongo.expressions.index.IndexExpression.__init__ - instantiation via builder",
                    "pydongo.workers.collection.CollectionWorker.use_index - registering index",
                    "pydongo.workers.collection.SyncCollectionResponseBuilder.count - sync count documents",
                    "pydongo.drivers.mock.MockMongoDBDriver.create_index - mock driver index creation",
                    "pydongo.drivers.mock.MockMongoDBDriver.count - mock driver count documents"
                ]
            },
            {
                "test_id": "tests/test_index_creation.py::test_compound_index",
                "covers": [
                    "pydongo.expressions.index.IndexExpressionBuilder.use_sort_order - sort order for index",
                    "pydongo.expressions.index.IndexSortOrder - enum usage (ASCENDING/DESCENDING)"
                ]
            },
            {
                "test_id": "tests/test_index_creation.py::test_text_and_hash_index",
                "covers": [
                    "pydongo.expressions.index.IndexExpressionBuilder.use_index_type - text/hash index type",
                    "pydongo.expressions.index.IndexType - enum usage (TEXT/HASHED)"
                ]
            },
            {
                "test_id": "tests/test_index_creation.py::test_geo_index_types",
                "covers": [
                    "pydongo.expressions.index.IndexExpressionBuilder.use_index_type - geo index type",
                    "pydongo.expressions.index.IndexType - enum usage (TWO_DIMENSIONAL/TWO_DIMENSIONAL_SPHERE)"
                ]
            },
            {
                "test_id": "tests/test_index_creation.py::test_index_with_special_kwargs",
                "covers": [
                    "pydongo.expressions.index.IndexExpressionBuilder.use_sparse - sparse index option",
                    "pydongo.expressions.index.IndexExpressionBuilder.use_index_name - custom index name",
                    "pydongo.expressions.index.IndexExpressionBuilder.use_ttl - TTL index option",
                    "pydongo.expressions.index.IndexExpressionBuilder.use_collation - collation for index",
                    "pydongo.expressions.index.CollationStrength - enum usage",
                    "pydongo.expressions.index.IndexExpression.build_kwargs - building index creation options"
                ]
            },
            {
                "test_id": "tests/test_index_creation.py::test_ttl_behavior_for_text_and_other_index_types[None-True]",
                "covers": [
                    "pydongo.expressions.index.IndexExpressionBuilder.__init__ - instantiation",
                    "pydongo.expressions.index.IndexExpression.build_kwargs - TTL behavior for standard index"
                ]
            },
            {
                "test_id": "tests/test_index_creation_async.py::test_single_key_index_async",
                "covers": [
                    "pydongo.drivers.mock.MockAsyncMongoDBDriver.__init__ - async mock driver instantiation",
                    "pydongo.drivers.mock.MockAsyncMongoDBDriver.connect - async mock driver connect",
                    "pydongo.drivers.mock.MockAsyncMongoDBDriver.create_index - async mock driver index creation",
                    "pydongo.drivers.mock.MockAsyncMongoDBDriver.count - async mock driver count documents",
                    "pydongo.workers.collection.AsyncCollectionResponseBuilder.count - async count documents"
                ]
            }
        ],
        "commit_sha": "48bfd4b22db80ee32170b076e0c4a814af51ff12",
        "full_code_skeleton_structured": [
            {
                "file_path": "examples/sync/medtech_app.py",
                "code": "class Prescription(BaseModel):\n    id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n    drug_name: str\n    dosage: str\n    frequency: str\n    duration_days: int\n\nclass Patient(BaseModel):\n    patient_id: str\n    name: str\n    age: int\n    prescriptions: List[Prescription] = []\n\ndef create_patient(patient_id: str, name: str, age: int) -> Patient:\n    pass\n\ndef add_prescription(\n    patient_id: str, drug_name: str, dosage: str, frequency: str, duration_days: int\n) -> Optional[Prescription]:\n    pass\n\ndef get_prescriptions(patient_id: str) -> List[Prescription]:\n    pass\n"
            },
            {
                "file_path": "examples/sync/social_media_app.py",
                "code": "class Post(BaseModel):\n    id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n    content: str\n    likes: int = 0\n\nclass User(BaseModel):\n    username: str\n    email: str\n    bio: Optional[str] = \"\"\n    posts: List[Post] = []\n\ndef create_user(username: str, email: str, bio: str = \"\") -> User:\n    pass\n\ndef make_post(username: str, content: str) -> Optional[Post]:\n    pass\n\ndef like_post(username: str, post_id: str) -> bool:\n    pass\n\ndef get_all_posts(username: Optional[str] = None) -> List[Post]:\n    pass\n"
            },
            {
                "file_path": "examples/async/social_media_app.py",
                "code": "class Post(BaseModel):\n    id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n    content: str\n    likes: int = 0\n\nclass User(BaseModel):\n    username: str\n    email: str\n    bio: Optional[str] = \"\"\n    posts: List[Post] = []\n\nasync def create_user(username: str, email: str, bio: str = \"\") -> User:\n    pass\n\nasync def make_post(username: str, content: str) -> Optional[Post]:\n    pass\n\nasync def like_post(username: str, post_id: str) -> bool:\n    pass\n\nasync def get_all_posts(username: Optional[str] = None) -> List[Post]:\n    pass\n\nasync def main():\n    pass\n"
            },
            {
                "file_path": "pydongo/workers/document.py",
                "code": "T = TypeVar(\"T\", bound=BaseModel)\n\ndef as_document(\n    pydantic_object: T, driver: AbstractMongoDBDriver\n) -> Union[\"DocumentWorker\", \"AsyncDocumentWorker\"]:\n    \"\"\"\n    Wraps a Pydantic object in either a synchronous or asynchronous document worker,\n    depending on the provided MongoDB driver.\n\n    Args:\n        pydantic_object (T): A Pydantic model instance.\n        driver (AbstractMongoDBDriver): The MongoDB driver in use.\n\n    Returns:\n        Union[DocumentWorker, AsyncDocumentWorker]: A document wrapper with persistence methods.\n    \"\"\"\n    pass\n\nclass BaseDocumentWorker(Generic[T]):\n    \"\"\"\n    Base class for document-level operations like serialization, query generation, and collection detection.\n\n    This class provides common functionality for both synchronous and asynchronous document workers.\n    \"\"\"\n\n    def __init__(\n        self, pydantic_object: T, objectId: Optional[str] = None, *args, **kwargs\n    ):\n        \"\"\"\n        Initialize the document wrapper.\n\n        Args:\n            pydantic_object (T): The Pydantic model to wrap.\n            objectId (Optional[str]): Optional MongoDB ObjectId of the document.\n        \"\"\"\n        pass\n\n    @property\n    def collection_name(self):\n        \"\"\"\n        Returns the MongoDB collection name associated with the model.\n\n        Returns:\n            str: The collection name.\n        \"\"\"\n        pass\n\n    def get_query(self) -> dict:\n        \"\"\"\n        Builds a MongoDB query to uniquely identify the current document.\n\n        Returns:\n            dict: A MongoDB query dict.\n        \"\"\"\n        pass\n\n    def serialize(self) -> dict:\n        \"\"\"\n        Serializes the Pydantic model to a dictionary suitable for MongoDB storage.\n\n        Returns:\n            dict: Serialized representation of the document.\n        \"\"\"\n        pass\n\n    def __getattr__(self, name: str) -> Any:\n        \"\"\"\n        Proxy attribute access to the underlying Pydantic model.\n\n        Args:\n            name (str): The attribute name.\n\n        Returns:\n            Any: Attribute value from the Pydantic model.\n        \"\"\"\n        pass\n\n    def __repr__(self):\n        \"\"\"\n        Returns a human-readable string representation of the document.\n\n        Returns:\n            str: Representation of the document wrapper.\n        \"\"\"\n        pass\n\nclass DocumentWorker(BaseDocumentWorker):\n    \"\"\"\n    Document wrapper for synchronous MongoDB operations.\n\n    Provides methods to save and delete documents from MongoDB.\n    \"\"\"\n\n    def __init__(\n        self,\n        pydantic_object: T,\n        driver: AbstractSyncMongoDBDriver,\n        objectId: Optional[str] = None,\n    ):\n        \"\"\"\n        Initialize the sync document worker.\n\n        Args:\n            pydantic_object (T): The Pydantic model to wrap.\n            driver (AbstractSyncMongoDBDriver): The sync MongoDB driver.\n            objectId (Optional[str]): Optional ObjectId for the document.\n        \"\"\"\n        pass\n\n    def save(self) -> dict:\n        \"\"\"\n        Save the document to MongoDB. Performs an insert if no ObjectId is present,\n        or an update otherwise.\n\n        Returns:\n            dict: Result of the MongoDB insert or update operation.\n        \"\"\"\n        pass\n\n    def delete(self) -> dict:\n        \"\"\"\n        Delete the document from MongoDB using its ObjectId.\n\n        Returns:\n            dict: Result of the delete operation.\n        \"\"\"\n        pass\n\nclass AsyncDocumentWorker(BaseDocumentWorker):\n    \"\"\"\n    Document wrapper for asynchronous MongoDB operations.\n\n    Provides async methods to save and delete documents.\n    \"\"\"\n\n    def __init__(\n        self,\n        pydantic_object: T,\n        driver: AbstractAsyncMongoDBDriver,\n        objectId: Optional[str] = None,\n    ):\n        \"\"\"\n        Initialize the async document worker.\n\n        Args:\n            pydantic_object (T): The Pydantic model to wrap.\n            driver (AbstractAsyncMongoDBDriver): The async MongoDB driver.\n            objectId (Optional[str]): Optional ObjectId for the document.\n        \"\"\"\n        pass\n\n    async def save(self):\n        \"\"\"\n        Save the document to MongoDB asynchronously. Inserts if no ObjectId is present,\n        or updates otherwise.\n\n        Returns:\n            dict: Result of the insert or update operation.\n        \"\"\"\n        pass\n\n    async def delete(self) -> dict:\n        \"\"\"\n        Delete the document from MongoDB asynchronously using its ObjectId.\n\n        Returns:\n            dict: Result of the delete operation.\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "pydongo/workers/collection.py",
                "code": "T = TypeVar(\"T\", bound=BaseModel)\n\ndef as_collection(\n    pydantic_model: Type[T],\n    driver: Union[AbstractSyncMongoDBDriver, AbstractAsyncMongoDBDriver],\n) -> \"CollectionWorker\":\n    pass\n\nclass CollectionWorker(Generic[T]):\n    \"\"\"\n    Entry point for querying and interacting with a MongoDB collection.\n\n    Wraps a Pydantic model and MongoDB driver, and exposes queryable field expressions\n    and high-level `find_one`, `afind_one`, and `find` methods.\n\n    Supports both sync and async drivers via conditional branching.\n    \"\"\"\n\n    def __init__(\n        self,\n        pydantic_model: Type[T],\n        driver: Union[AbstractSyncMongoDBDriver, AbstractAsyncMongoDBDriver],\n    ):\n        pass\n\n    def find_one(\n        self, expression: CollectionFilterExpression\n    ) -> Optional[DocumentWorker]:\n        \"\"\"\n        Query the database for a single document that matches the filter expression.\n        Only works with a synchronous driver.\n\n        Args:\n            expression (CollectionFilterExpression): The MongoDB-style filter expression.\n\n        Returns:\n            Optional[DocumentWorker]: A wrapped Pydantic object if found, otherwise None.\n        \"\"\"\n        pass\n\n    async def afind_one(\n        self, expression: CollectionFilterExpression\n    ) -> Optional[AsyncDocumentWorker]:\n        \"\"\"\n        Asynchronously query the database for a single document matching the filter expression.\n        Only works with an async driver.\n\n        Args:\n            expression (CollectionFilterExpression): The MongoDB-style filter expression.\n\n        Returns:\n            Optional[AsyncDocumentWorker]: A wrapped Pydantic object if found, otherwise None.\n        \"\"\"\n        pass\n\n    def find(\n        self, expression: Optional[CollectionFilterExpression] = None\n    ) -> \"CollectionResponseBuilder\":\n        \"\"\"\n        Initiates a fluent response builder chain for querying multiple documents.\n\n        Args:\n            expression (Optional[CollectionFilterExpression]): Optional filter expression.\n\n        Returns:\n            CollectionResponseBuilder: Builder for fluent chaining (e.g., .limit(), .sort()).\n        \"\"\"\n        pass\n\n    def use_index(\n        self,\n        index: Union[IndexExpression, Tuple[IndexExpression]],\n    ):\n        \"\"\"\n        Registers an index (or compound index) on the collection.\n\n        Accepts IndexExpression(s)\n\n        Args:\n            index: A single IndexExpression, or a tuple of them.\n\n        Returns:\n            CollectionWorker: Self, for method chaining.\n        \"\"\"\n        pass\n\n    def __getattr__(self, name: str) -> FieldExpression:\n        \"\"\"\n        Returns a field expression object to enable DSL-style querying using comparison\n        operators or dot notation for nested objects.\n\n        Args:\n            name (str): Field name in the Pydantic model.\n\n        Returns:\n            FieldExpression: Expression object tied to the field.\n\n        Raises:\n            AttributeError: If the field does not exist on the model.\n        \"\"\"\n        pass\n\n    @property\n    def collection_name(self):\n        \"\"\"\n        Derives the MongoDB collection name from the model or falls back to the class name.\n\n        Returns:\n            str: The name of the collection.\n        \"\"\"\n        pass\n\nclass CollectionResponseBuilder(ABC, Generic[T]):\n    \"\"\"\n    Fluent builder for composing queries and retrieving lists of documents.\n\n    Can build the final MongoDB query structure with sort, skip, and limit options.\n    \"\"\"\n\n    def __init__(\n        self,\n        expression: CollectionFilterExpression,\n        pydantic_model: Type[T],\n        driver: Union[AbstractSyncMongoDBDriver, AbstractAsyncMongoDBDriver],\n        collection_name: str,\n        indexes: Iterable[Tuple[IndexExpression]],\n    ):\n        pass\n\n    def skip(self, offset: int) -> \"CollectionResponseBuilder\":\n        \"\"\"\n        Skip the first N documents in the query result.\n\n        Args:\n            offset (int): Number of documents to skip.\n\n        Returns:\n            CollectionResponseBuilder: For chaining.\n        \"\"\"\n        pass\n\n    def limit(self, limit_value: int) -> \"CollectionResponseBuilder\":\n        \"\"\"\n        Limit the number of documents returned.\n\n        Args:\n            limit_value (int): Maximum number of documents to return.\n\n        Returns:\n            CollectionResponseBuilder: For chaining.\n        \"\"\"\n        pass\n\n    def sort(\n        self, sort_criteria: Union[FieldExpression, Sequence[FieldExpression]]\n    ) -> \"CollectionResponseBuilder\":\n        \"\"\"\n        Apply sort criteria to the query.\n\n        Args:\n            sort_criteria (Union[FieldExpression, Sequence[FieldExpression]]): Sort instructions.\n\n        Returns:\n            CollectionResponseBuilder: For chaining.\n        \"\"\"\n        pass\n\n    def build_kwargs(self) -> dict:\n        \"\"\"\n        Assembles the query, sort, offset, and limit into a single dictionary.\n\n        Returns:\n            dict: MongoDB-compatible query parameters.\n        \"\"\"\n        pass\n\n    @classmethod\n    def serialize_document(\n        cls,\n        document: dict,\n        document_worker_class: Type[BaseDocumentWorker],\n        pydantic_model: Type[T],\n        driver: AbstractMongoDBDriver,\n    ) -> BaseDocumentWorker:\n        \"\"\"\n        Deserialize a raw MongoDB document and wrap it in a DocumentWorker.\n\n        Args:\n            document (dict): Raw document from the database.\n            document_worker_class (Type): Either DocumentWorker or AsyncDocumentWorker.\n            pydantic_model (Type): Model class to hydrate.\n            driver (AbstractMongoDBDriver): Driver used to perform operations.\n\n        Returns:\n            BaseDocumentWorker: Wrapped document instance.\n        \"\"\"\n        pass\n\nclass SyncCollectionResponseBuilder(CollectionResponseBuilder):\n    \"\"\"\n    Response builder for synchronous drivers.\n\n    Provides direct methods to count, check existence, and iterate documents.\n    \"\"\"\n\n    def __init__(\n        self,\n        expression: CollectionFilterExpression,\n        pydantic_model: Type[T],\n        driver: AbstractSyncMongoDBDriver,\n        collection_name: str,\n        indexes: Iterable[Tuple[IndexExpression]],\n    ):\n        pass\n\n    def exists(self) -> bool:\n        \"\"\"\n        Check if any document matches the filter expression.\n\n        Returns:\n            bool: True if at least one document exists.\n        \"\"\"\n        pass\n\n    def count(self) -> int:\n        \"\"\"\n        Count how many documents match the filter expression.\n\n        Returns:\n            int: Number of matching documents.\n        \"\"\"\n        pass\n\n    def all(self) -> Iterable[DocumentWorker]:\n        \"\"\"\n        Retrieve all documents that match the current query builder state.\n\n        Returns:\n            Iterable[DocumentWorker]: Generator of hydrated documents.\n        \"\"\"\n        pass\n\n    def create_indexes(self):\n        \"\"\"\n        Creates indexes on the MongoDB database.\n        \"\"\"\n        pass\n\nclass AsyncCollectionResponseBuilder(CollectionResponseBuilder):\n    \"\"\"\n    Response builder for asynchronous drivers.\n\n    Supports async versions of exists, count, and all().\n    \"\"\"\n\n    def __init__(\n        self,\n        expression: CollectionFilterExpression,\n        pydantic_model: Type[T],\n        driver: AbstractAsyncMongoDBDriver,\n        collection_name: str,\n        indexes: Iterable[Tuple[IndexExpression]],\n    ):\n        pass\n\n    async def exists(self) -> bool:\n        \"\"\"\n        Asynchronously check if any document matches the filter.\n\n        Returns:\n            bool: True if a match exists.\n        \"\"\"\n        pass\n\n    async def count(self) -> int:\n        \"\"\"\n        Asynchronously count how many documents match the filter.\n\n        Returns:\n            int: Number of matching documents.\n        \"\"\"\n        pass\n\n    async def all(self) -> Iterable[AsyncDocumentWorker]:\n        \"\"\"\n        Asynchronously retrieve all matching documents.\n\n        Returns:\n            Iterable[AsyncDocumentWorker]: List of wrapped async document objects.\n        \"\"\"\n        pass\n\n    async def create_indexes(self):\n        \"\"\"\n        Asynchronously creates indexes on the MongoDB database.\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "pydongo/expressions/filter.py",
                "code": "class CollectionFilterExpression(BaseExpression):\n    \"\"\"\n    Represents a boolean filter expression used to query a MongoDB collection.\n\n    These expressions are composable using:\n        - Logical OR (`|`)\n        - Logical AND (`&`)\n        - Logical NOT (`~`)\n\n    Example usage:\n        filter_1 = User.age > 18\n        filter_2 = User.name == \"Samuel\"\n        combined = filter_1 & filter_2\n\n    The resulting expression can be serialized and passed to the database driver.\n    \"\"\"\n\n    def __init__(self, expression: Optional[dict] = None):\n        \"\"\"\n        Initialize the filter expression with an optional initial dictionary.\n\n        Args:\n            expression (Optional[dict]): A MongoDB-style query dictionary.\n        \"\"\"\n        pass\n\n    def with_expression(self, expression: dict) -> \"CollectionFilterExpression\":\n        \"\"\"\n        Mutate the internal expression by merging in a new dictionary.\n\n        Args:\n            expression (dict): A MongoDB-style query to merge into the current expression.\n\n        Returns:\n            CollectionFilterExpression: The current instance (for chaining).\n        \"\"\"\n        pass\n\n    def serialize(self) -> dict:\n        \"\"\"\n        Serialize the filter expression into a MongoDB-compatible query object.\n\n        Returns:\n            dict: Serialized MongoDB query.\n        \"\"\"\n        pass\n\n    def __and__(\n        self, other: \"CollectionFilterExpression\"\n    ) -> \"CollectionFilterExpression\":\n        \"\"\"\n        Combine this filter with another using a logical AND.\n\n        Args:\n            other (CollectionFilterExpression): Another filter to combine with.\n\n        Returns:\n            CollectionFilterExpression: A new combined filter.\n        \"\"\"\n        pass\n\n    def __or__(\n        self, other: \"CollectionFilterExpression\"\n    ) -> \"CollectionFilterExpression\":\n        \"\"\"\n        Combine this filter with another using a logical OR.\n\n        Args:\n            other (CollectionFilterExpression): Another filter to combine with.\n\n        Returns:\n            CollectionFilterExpression: A new combined filter.\n        \"\"\"\n        pass\n\n    def __invert__(self) -> \"CollectionFilterExpression\":\n        \"\"\"\n        Invert the current filter using a logical NOT.\n\n        Returns:\n            CollectionFilterExpression: A new filter expression wrapped in `$not`.\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "pydongo/expressions/base.py",
                "code": "class BaseExpression(ABC):\n    @abstractmethod\n    def serialize(self) -> Any:\n        \"\"\"\n        Serialize an expression into a MongoDB compatible query DTO\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "pydongo/expressions/field.py",
                "code": "class FieldExpression:\n    \"\"\"\n    Represents a scalar field in a MongoDB query.\n\n    This class supports operator overloading to build query expressions using:\n        ==, !=, >, >=, <, <=\n\n    It also supports nested attribute access (e.g., user.address.city).\n    \"\"\"\n\n    def __init__(self, field_name: str, annotation=None, sort_ascending: bool = True):\n        \"\"\"\n        Initialize a field expression.\n\n        Args:\n            field_name (str): The full dot-path name of the field.\n            annotation (Any): The Pydantic type annotation for the field.\n            sort_ascending (bool): Whether sorting on this field is ascending by default.\n        \"\"\"\n        pass\n\n    def to_index(self) -> IndexExpression:\n        \"\"\"\n        Returns a complete, ready-to-use `IndexExpression` for this field.\n\n        This is a convenience method for quickly generating a basic index configuration\n        using the default sort order and inferred index type (e.g., TEXT for strings).\n        \"\"\"\n        pass\n\n    def as_index(self) -> IndexExpressionBuilder:\n        \"\"\"\n        Returns an `IndexExpressionBuilder` initialized with this field.\n\n        This allows users to customize the index further, such as adding uniqueness,\n        TTL, collation, or partial filter expressions—before building the final index object.\n        \"\"\"\n        pass\n\n    def _get_comparative_expression(self, operator: str, value: Any) -> dict:\n        \"\"\"\n        Build a MongoDB filter expression using the given operator and value.\n\n        Args:\n            operator (str): MongoDB comparison operator (e.g., \"$gt\").\n            value (Any): The value to compare against.\n\n        Returns:\n            dict: A MongoDB-compatible filter clause.\n        \"\"\"\n        pass\n\n    def __eq__(self, other: Any) -> \"CollectionFilterExpression\":  # type: ignore\n        \"\"\"Build an equality expression (`==`).\"\"\"\n        pass\n\n    def __ne__(self, other: Any) -> \"CollectionFilterExpression\":  # type: ignore\n        \"\"\"Build an inequality expression (`!=`).\"\"\"\n        pass\n\n    def __gt__(self, other: Any) -> \"CollectionFilterExpression\":\n        \"\"\"Build a greater-than expression (`>`).\"\"\"\n        pass\n\n    def __ge__(self, other: Any) -> \"CollectionFilterExpression\":\n        \"\"\"Build a greater-than-or-equal expression (`>=`).\"\"\"\n        pass\n\n    def __lt__(self, other: Any) -> \"CollectionFilterExpression\":\n        \"\"\"Build a less-than expression (`<`).\"\"\"\n        pass\n\n    def __le__(self, other: Any) -> \"CollectionFilterExpression\":\n        \"\"\"Build a less-than-or-equal expression (`<=`).\"\"\"\n        pass\n\n    def __neg__(self) -> \"FieldExpression\":\n        \"\"\"\n        Flip the default sort order.\n\n        Returns:\n            FieldExpression: A new instance with reversed sort order.\n        \"\"\"\n        pass\n\n    @property\n    def field_name(self):\n        \"\"\"The full field name, including nested paths if applicable.\"\"\"\n        pass\n\n    def __getattr__(self, name: str) -> \"FieldExpression\":\n        \"\"\"\n        Support for chained dot notation, e.g. `user.address.city`.\n\n        Args:\n            name (str): Subfield name.\n\n        Returns:\n            FieldExpression: A new field expression for the nested field.\n        \"\"\"\n        pass\n\n    @classmethod\n    def _getattr(cls, field_name: str, annotation: Any, name: str) -> \"FieldExpression\":\n        \"\"\"\n        Helper to resolve nested fields.\n\n        Args:\n            field_name (str): Current field name path.\n            annotation (Any): Type annotation of the current field.\n            name (str): Next subfield name.\n\n        Returns:\n            FieldExpression: A new expression with nested field access.\n\n        Raises:\n            AttributeError: If the annotation is not a Pydantic model or field is invalid.\n        \"\"\"\n        pass\n\n    @staticmethod\n    def get_field_expression(field_name: str, annotation: Any) -> \"FieldExpression\":\n        pass\n\nclass ArraySizeFieldExpression(FieldExpression):\n    \"\"\"\n    Represents an expression for the size of an array field.\n\n    Used for queries like: `len(User.tags) > 2`\n    \"\"\"\n\n    def _get_comparative_expression(self, operator: str, value: int) -> dict:\n        \"\"\"\n        Build a MongoDB `$expr` query comparing the size of an array.\n\n        Args:\n            operator (str): Comparison operator (e.g., \"$gt\").\n            value (int): Value to compare the array size against.\n\n        Returns:\n            dict: MongoDB `$expr` query.\n        \"\"\"\n        pass\n\nclass ArrayFieldExpression(FieldExpression):\n    \"\"\"\n    Represents an array field in a MongoDB document.\n\n    Adds support for array-specific operations like `.contains()`, `.size()`, and `.matches()`.\n    \"\"\"\n\n    def size(self) -> ArraySizeFieldExpression:\n        \"\"\"\n        Get an expression that targets the array's length.\n\n        Returns:\n            ArraySizeFieldExpression: An expression targeting the array's size.\n        \"\"\"\n        pass\n\n    def matches(\n        self, values: Iterable[Any], match_order: bool = False\n    ) -> CollectionFilterExpression:\n        \"\"\"\n        Check if the array exactly matches the provided values.\n\n        Args:\n            values (Iterable[Any]): Values to match against.\n            match_order (bool): If True, requires order-sensitive match.\n\n        Returns:\n            CollectionFilterExpression: MongoDB `$all` or exact match query.\n        \"\"\"\n        pass\n\n    def contains(self, value: Any) -> CollectionFilterExpression:\n        \"\"\"\n        Check if the array contains one or more values.\n\n        Args:\n            value (Any): A scalar or iterable to check presence for.\n\n        Returns:\n            CollectionFilterExpression: MongoDB `$in` expression.\n        \"\"\"\n        pass\n\n    def excludes(self, value: Any) -> CollectionFilterExpression:\n        \"\"\"\n        Check if the array excludes one or more values.\n\n        Args:\n            value (Any): A scalar or iterable to check absence for.\n\n        Returns:\n            CollectionFilterExpression: MongoDB `$nin` expression.\n        \"\"\"\n        pass\n\n    def __getattr__(self, name: str) -> FieldExpression:\n        \"\"\"\n        Support accessing subfields within an array of objects.\n\n        Args:\n            name (str): Name of the subfield.\n\n        Returns:\n            FieldExpression: Field expression for the nested field.\n\n        Raises:\n            TypeError: If element type can't be inferred.\n        \"\"\"\n        pass\n\n    def __len__(self) -> ArraySizeFieldExpression:\n        \"\"\"\n        Return an expression for the array's size (using `len()`).\n\n        Returns:\n            ArraySizeFieldExpression: Expression targeting array length.\n        \"\"\"\n        pass\n\n    def __contains__(self, value: Any) -> CollectionFilterExpression:\n        \"\"\"\n        Python-style containment check using `in` syntax.\n\n        Args:\n            value (Any): Element to check for.\n\n        Returns:\n            CollectionFilterExpression: MongoDB `$in` expression.\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "pydongo/expressions/index.py",
                "code": "class IndexSortOrder(IntEnum):\n    ASCENDING = 1\n    DESCENDING = -1\n\nclass IndexType(str, Enum):\n    TEXT = \"text\"\n    HASHED = \"hashed\"\n    TWO_DIMENSIONAL = \"2d\"\n    TWO_DIMENSIONAL_SPHERE = \"2dsphere\"\n\nclass CollationStrength(IntEnum):\n    PRIMARY = 1  # Only base characters (e.g., \"a\" == \"A\", \"é\" == \"e\")\n    SECONDARY = 2  # Case-insensitive, accent-sensitive (e.g., \"a\" == \"A\", \"é\" != \"e\")\n    TERTIARY = 3  # Case- and accent-sensitive (e.g., \"a\" != \"A\", \"é\" != \"e\")\n    QUATERNARY = 4  # Includes case, accent, punctuation (e.g., \"$a\" != \"a\")\n    IDENTICAL = 5  # Everything is compared (e.g., code point level)\n\n    def description(self) -> str:\n        pass\n\nclass IndexExpression(BaseExpression):\n    def __init__(\n        self,\n        field_name: str,\n        index_type: Optional[IndexType] = None,\n        sort_order: IndexSortOrder = IndexSortOrder.ASCENDING,\n        expires_after_seconds: Optional[float] = None,  # For TTL indexes\n        is_sparse: Optional[bool] = None,\n        is_unique: Optional[bool] = None,\n        is_hidden: Optional[bool] = None,\n        collation_locale: str = \"en\",\n        collation_strength: Optional[CollationStrength] = None,\n        partial_expression: Optional[CollectionFilterExpression] = None,\n        index_name: Optional[str] = None,\n    ):\n        pass\n\n    def serialize(self) -> dict:\n        pass\n\n    def build_kwargs(self) -> dict:\n        \"\"\"\n        Additional specifications for the index to be passed to MongoDB's create_index.\n        Only includes non-null values.\n        \"\"\"\n        pass\n\n    def __hash__(self):\n        pass\n\n    def __eq__(self, expr: object) -> bool:\n        pass\n\nclass IndexExpressionBuilder:\n    def __init__(self, field_name: str):\n        pass\n\n    def use_sort_order(self, sort_order: IndexSortOrder) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_index_type(self, index_type: IndexType) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_collation(\n        self, locale: str, strength: CollationStrength\n    ) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_partial_expression(\n        self, expression: CollectionFilterExpression\n    ) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_index_name(self, index_name: str) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_sparse(self, is_sparse: bool = True) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_unique(self, is_unique: bool = True) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_hidden(self, is_hidden: bool = True) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_ttl(self, seconds: float) -> \"IndexExpressionBuilder\":\n        pass\n\n    def build_index(self) -> IndexExpression:\n        pass\n"
            },
            {
                "file_path": "pydongo/drivers/mock.py",
                "code": "class MockMongoDBDriver(AbstractSyncMongoDBDriver):\n    \"\"\"\n    In-memory mock implementation of the AbstractSyncMongoDBDriver.\n\n    This mock driver mimics MongoDB behavior for unit testing without requiring\n    a real database connection. Data is stored in-memory in Python dictionaries.\n    \"\"\"\n\n    def __init__(self, connection_string: str = \"\", database_name: str = \"mockdb\"):\n        \"\"\"\n        Initialize the mock driver with an empty in-memory store.\n\n        Args:\n            connection_string (str): Ignored.\n            database_name (str): Name of the fake database.\n        \"\"\"\n        pass\n\n    def connect(self) -> bool:\n        \"\"\"\n        Simulate a successful connection.\n\n        Returns:\n            bool: Always True.\n        \"\"\"\n        pass\n\n    def close(self) -> None:\n        \"\"\"\n        Close the connection (noop for the mock driver).\n        \"\"\"\n        pass\n\n    def insert_one(self, collection: str, document: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Insert a document into the in-memory collection.\n\n        Args:\n            collection (str): Name of the collection.\n            document (dict): Document to insert.\n\n        Returns:\n            dict: Insert result including generated `_id`.\n        \"\"\"\n        pass\n\n    def insert_many(\n        self, collection: str, documents: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Insert multiple documents into the in-memory collection.\n\n        Args:\n            collection (str): Name of the collection.\n            documents (list): List of documents to insert.\n\n        Returns:\n            dict: Insert result with list of `_id`s.\n        \"\"\"\n        pass\n\n    def find_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Find a single document matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): MongoDB-style filter.\n\n        Returns:\n            dict or None: Matching document or None if not found.\n        \"\"\"\n        pass\n\n    def find_many(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        sort_criteria: Dict[str, Any],\n        offset: Optional[int] = None,\n        limit: Optional[int] = None,\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Find multiple documents matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): MongoDB-style filter.\n            sort_criteria (dict): Ignored in the mock.\n            offset (int, optional): Skip the first N results.\n            limit (int, optional): Limit the number of results returned.\n\n        Returns:\n            list: List of matching documents.\n        \"\"\"\n        pass\n\n    def update_one(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        update: Dict[str, Any],\n        upsert: bool = False,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Update a single document matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): Filter query.\n            update (dict): Update operations (only supports \"$set\").\n\n        Returns:\n            dict: Update result with matched and modified count.\n        \"\"\"\n        pass\n\n    def delete_one(self, collection: str, query: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Delete the first document matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): Filter query.\n\n        Returns:\n            dict: Delete result.\n        \"\"\"\n        pass\n\n    def count(self, collection: str, query: Dict[str, Any]) -> int:\n        \"\"\"\n        Count documents that match the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): Filter query.\n\n        Returns:\n            int: Number of matching documents.\n        \"\"\"\n        pass\n\n    def exists(self, collection: str, query: Dict[str, Any]) -> bool:\n        \"\"\"\n        Check if at least one document matches the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): Filter query.\n\n        Returns:\n            bool: True if at least one document matches.\n        \"\"\"\n        pass\n\n    def create_index(self, collection: str, index: Tuple[IndexExpression]):\n        \"\"\"\n        Create an index on a collection in the MongoDB Database\n\n        Args:\n            collection (str): The collection name.\n            index (tuple[IndexExpression]):\n                A tuple of IndexExpression objects representing the index to create\n                NOTE: Multiple elements in tuple indicate a single compound index\n                not multiple indexes\n\n        \"\"\"\n        pass\n\nclass MockAsyncMongoDBDriver(AbstractAsyncMongoDBDriver):\n    \"\"\"\n    In-memory mock implementation of the AbstractAsyncMongoDBDriver.\n\n    This async mock mirrors the behavior of MongoDB using native async/await\n    and an in-memory store. Ideal for use in async unit tests.\n    \"\"\"\n\n    def __init__(self, connection_string: str = \"\", database_name: str = \"mockdb\"):\n        \"\"\"\n        Initialize the async mock with an in-memory store.\n\n        Args:\n            connection_string (str): Ignored.\n            database_name (str): Mock database name.\n        \"\"\"\n        pass\n\n    async def connect(self) -> bool:\n        \"\"\"\n        Simulate async connection success.\n\n        Returns:\n            bool: Always True.\n        \"\"\"\n        pass\n\n    async def close(self) -> None:\n        \"\"\"\n        Simulate async close (noop).\n        \"\"\"\n        pass\n\n    async def insert_one(\n        self, collection: str, document: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Asynchronously insert a document into the mock store.\n\n        Args:\n            collection (str): Collection name.\n            document (dict): Document to insert.\n\n        Returns:\n            dict: Insert result with `_id`.\n        \"\"\"\n        pass\n\n    async def insert_many(\n        self, collection: str, documents: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Asynchronously insert multiple documents.\n\n        Args:\n            collection (str): Collection name.\n            documents (list): List of documents.\n\n        Returns:\n            dict: Insert result with `_id`s.\n        \"\"\"\n        pass\n\n    async def find_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Asynchronously find a single matching document.\n\n        Args:\n            collection (str): Collection name.\n            query (dict): Filter.\n\n        Returns:\n            dict or None: Matching document or None.\n        \"\"\"\n        pass\n\n    async def find_many(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        sort_criteria: Dict[str, Any],\n        offset: Optional[int] = None,\n        limit: Optional[int] = None,\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Asynchronously return a list of matching documents.\n\n        Args:\n            collection (str): Collection name.\n            query (dict): Filter.\n            sort_criteria (dict): Ignored.\n            offset (int, optional): Skip N docs.\n            limit (int, optional): Limit docs returned.\n\n        Returns:\n            list: Matching documents.\n        \"\"\"\n        pass\n\n    async def update_one(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        update: Dict[str, Any],\n        upsert: bool = False,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Asynchronously update a single matching document.\n\n        Args:\n            collection (str): Collection name.\n            query (dict): Filter.\n            update (dict): Update expression.\n\n        Returns:\n            dict: Update result.\n        \"\"\"\n        pass\n\n    async def delete_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Asynchronously delete a single matching document.\n\n        Args:\n            collection (str): Collection name.\n            query (dict): Filter.\n\n        Returns:\n            dict: Delete result.\n        \"\"\"\n        pass\n\n    async def count(self, collection: str, query: Dict[str, Any]) -> int:\n        \"\"\"\n        Asynchronously count matching documents.\n\n        Args:\n            collection (str): Collection name.\n            query (dict): Filter.\n\n        Returns:\n            int: Number of matches.\n        \"\"\"\n        pass\n\n    async def exists(self, collection: str, query: Dict[str, Any]) -> bool:\n        \"\"\"\n        Asynchronously check if any document matches the filter.\n\n        Args:\n            collection (str): Collection name.\n            query (dict): Filter.\n\n        Returns:\n            bool: True if at least one match exists.\n        \"\"\"\n        pass\n\n    async def create_index(self, collection: str, index: Tuple[IndexExpression]):\n        \"\"\"\n        Create an index on a collection in the MongoDB Database\n\n        Args:\n            collection (str): The collection name.\n            index (tuple[IndexExpression]):\n                A tuple of IndexExpression objects representing the index to create\n                NOTE: Muiltiple elements in tuple indicate a single compound index\n                not multiple indexes\n\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "pydongo/drivers/async_mongo.py",
                "code": "class AsyncDefaultMongoDBDriver(AbstractAsyncMongoDBDriver):\n    \"\"\"\n    Default asynchronous MongoDB driver using Motor (async wrapper for PyMongo).\n\n    This driver connects to a real MongoDB instance and provides async methods\n    for insert, update, query, and delete operations.\n    \"\"\"\n\n    def __init__(self, connection_string: str, database_name: str):\n        \"\"\"\n        Initialize the driver with a MongoDB URI and target database name.\n\n        Args:\n            connection_string (str): MongoDB connection URI.\n            database_name (str): Name of the database to use.\n        \"\"\"\n        pass\n\n    async def connect(self) -> bool:\n        \"\"\"\n        Asynchronously establish a connection to the MongoDB server.\n\n        Returns:\n            bool: True if the connection is successful.\n\n        Raises:\n            RuntimeError: If unable to connect to MongoDB.\n        \"\"\"\n        pass\n\n    async def close(self) -> None:\n        \"\"\"\n        Asynchronously close the MongoDB connection.\n        \"\"\"\n        pass\n\n    async def insert_one(\n        self, collection: str, document: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Insert a single document into the specified collection.\n\n        Args:\n            collection (str): Name of the collection.\n            document (dict): Document to insert.\n\n        Returns:\n            dict: Result including the inserted document ID.\n        \"\"\"\n        pass\n\n    async def insert_many(\n        self, collection: str, documents: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Insert multiple documents into the specified collection.\n\n        Args:\n            collection (str): Name of the collection.\n            documents (list): Documents to insert.\n\n        Returns:\n            dict: Result including inserted document IDs.\n        \"\"\"\n        pass\n\n    async def find_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Find a single document that matches the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): MongoDB query object.\n\n        Returns:\n            dict or None: The matching document or None.\n        \"\"\"\n        pass\n\n    async def find_many(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        sort_criteria: Dict[str, int],\n        offset: Optional[int] = None,\n        limit: Optional[int] = None,\n    ) -> Iterable[Dict[str, Any]]:\n        \"\"\"\n        Find multiple documents matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): MongoDB filter query.\n            sort_criteria (dict): Sort order (e.g., {\"created_at\": -1}).\n            offset (int, optional): Number of documents to skip.\n            limit (int, optional): Max number of documents to return.\n\n        Returns:\n            Iterable[dict]: A cursor of matching documents.\n        \"\"\"\n        pass\n\n    async def update_one(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        update: Dict[str, Any],\n        upsert: bool = False,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Update a single document that matches the filter.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): MongoDB filter.\n            update (dict): MongoDB update expression.\n            upsert (bool): If True, create the document if it does not exist.\n\n        Returns:\n            dict: Result of the update operation.\n        \"\"\"\n        pass\n\n    async def delete_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Delete a single document matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): MongoDB filter.\n\n        Returns:\n            dict: Result including count of deleted documents.\n        \"\"\"\n        pass\n\n    async def count(self, collection: str, query: Dict[str, Any]) -> int:\n        \"\"\"\n        Count documents matching the given filter.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): MongoDB filter.\n\n        Returns:\n            int: Number of matching documents.\n        \"\"\"\n        pass\n\n    async def exists(self, collection: str, query: Dict[str, Any]) -> bool:\n        \"\"\"\n        Check if at least one document exists that matches the filter.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): MongoDB filter.\n\n        Returns:\n            bool: True if a matching document exists.\n        \"\"\"\n        pass\n\n    async def create_index(self, collection: str, index: Tuple[IndexExpression]):\n        \"\"\"\n        Create an index on a collection in the MongoDB Database (Async version using Motor).\n\n        Args:\n            collection (str): The collection name.\n            index (tuple[IndexExpression]):\n                A tuple of IndexExpression objects representing the index to create.\n                NOTE: Multiple elements in the tuple indicate a single compound index,\n                not multiple separate indexes.\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "pydongo/drivers/sync_mongo.py",
                "code": "class DefaultMongoDBDriver(AbstractSyncMongoDBDriver):\n    \"\"\"\n    Default synchronous MongoDB driver implementation using PyMongo.\n\n    This driver connects to a real MongoDB instance and executes\n    blocking operations such as insert, update, query, and delete.\n    \"\"\"\n\n    def __init__(self, connection_string: str, database_name: str):\n        \"\"\"\n        Initialize the driver with a MongoDB connection URI and database name.\n\n        Args:\n            connection_string (str): MongoDB URI (e.g., \"mongodb://localhost:27017\").\n            database_name (str): The target database to operate on.\n        \"\"\"\n        pass\n\n    def connect(self) -> bool:\n        \"\"\"\n        Establish a connection to the MongoDB server.\n\n        Returns:\n            bool: True if the connection is successful.\n\n        Raises:\n            RuntimeError: If connection to MongoDB fails.\n        \"\"\"\n        pass\n\n    def close(self) -> None:\n        \"\"\"\n        Close the MongoDB connection.\n        \"\"\"\n        pass\n\n    def insert_one(self, collection: str, document: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Insert a single document into a collection.\n\n        Args:\n            collection (str): Name of the collection.\n            document (dict): Document to insert.\n\n        Returns:\n            dict: Result of the insert operation, including the inserted ID.\n        \"\"\"\n        pass\n\n    def insert_many(\n        self, collection: str, documents: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Insert multiple documents into a collection.\n\n        Args:\n            collection (str): Name of the collection.\n            documents (list): List of documents to insert.\n\n        Returns:\n            dict: Result including inserted IDs.\n        \"\"\"\n        pass\n\n    def find_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Find a single document that matches the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): MongoDB filter query.\n\n        Returns:\n            dict or None: The found document, or None if not found.\n        \"\"\"\n        pass\n\n    def find_many(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        sort_criteria: Dict[str, Any],\n        offset: Optional[int] = None,\n        limit: Optional[int] = None,\n    ) -> Iterable[Dict[str, Any]]:\n        \"\"\"\n        Find multiple documents that match the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): Filter conditions.\n            sort_criteria (dict): Sorting fields and directions.\n            offset (int, optional): Number of records to skip.\n            limit (int, optional): Maximum number of documents to return.\n\n        Returns:\n            Iterable[dict]: Cursor for matching documents.\n        \"\"\"\n        pass\n\n    def update_one(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        update: Dict[str, Any],\n        upsert: bool = False,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Update a single document matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): Filter conditions.\n            update (dict): Update operations (e.g., {\"$set\": {...}}).\n            upsert (bool): Whether to insert the document if it doesn't exist.\n\n        Returns:\n            dict: Update result with match, modification, and upsert info.\n        \"\"\"\n        pass\n\n    def delete_one(self, collection: str, query: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Delete a single document matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): Filter conditions.\n\n        Returns:\n            dict: Delete result with count of deleted documents.\n        \"\"\"\n        pass\n\n    def count(self, collection: str, query: Dict[str, Any]) -> int:\n        \"\"\"\n        Count the number of documents matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): Filter conditions.\n\n        Returns:\n            int: Number of documents matching the filter.\n        \"\"\"\n        pass\n\n    def exists(self, collection: str, query: Dict[str, Any]) -> bool:\n        \"\"\"\n        Check if at least one document exists that matches the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): Filter conditions.\n\n        Returns:\n            bool: True if a matching document exists.\n        \"\"\"\n        pass\n\n    def create_index(self, collection: str, index: Tuple[IndexExpression]):\n        \"\"\"\n        Create an index on a collection in the MongoDB Database\n\n        Args:\n            collection (str): The collection name.\n            index (tuple[IndexExpression]):\n                A tuple of IndexExpression objects representing the index to create\n                NOTE: Multiple elements in tuple indicate a single compound index\n                not multiple indexes\n\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "pydongo/drivers/base.py",
                "code": "class AbstractMongoDBDriver(ABC):\n    \"\"\"\n    Abstract base class for MongoDB drivers.\n    \"\"\"\n    pass\n\nclass AbstractSyncMongoDBDriver(AbstractMongoDBDriver):\n    \"\"\"\n    Abstract base class for synchronous MongoDB drivers.\n    Provides context management support and coroutine/thread-safe access\n    to the currently active driver instance via contextvars.\n    \"\"\"\n\n    _current: contextvars.ContextVar[\"AbstractSyncMongoDBDriver\"] = (\n        contextvars.ContextVar(\"mongo_driver_current\")\n    )\n\n    def __init__(self, connection_string: str, database_name: str):\n        \"\"\"\n        Initialize the MongoDB driver with a connection string and database name.\n\n        Args:\n            connection_string (str): MongoDB connection URI.\n            database_name (str): Target database name.\n        \"\"\"\n        pass\n\n    def __enter__(self):\n        \"\"\"\n        Enter the context manager, connect to MongoDB, and set the current driver context.\n        \"\"\"\n        pass\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"\n        Exit the context manager, close the connection, and reset the driver context.\n        \"\"\"\n        pass\n\n    @classmethod\n    def current(cls) -> \"AbstractSyncMongoDBDriver\":\n        \"\"\"\n        Get the current MongoDB driver instance for this coroutine/thread.\n\n        Returns:\n            AbstractMongoDBDriver: The active driver instance.\n\n        Raises:\n            RuntimeError: If no driver is currently in context.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def connect(self) -> bool:\n        \"\"\"\n        Establish a connection to the MongoDB server.\n        Returns:\n            bool: True if connection was successful.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def close(self) -> None:\n        \"\"\"\n        Close the connection to the MongoDB server.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def insert_one(self, collection: str, document: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Insert a single document into the specified collection.\n\n        Args:\n            collection (str): The collection name.\n            document (dict): The document to insert.\n\n        Returns:\n            dict: Result of the insert operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def insert_many(\n        self, collection: str, documents: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Insert multiple documents into the specified collection.\n\n        Args:\n            collection (str): The collection name.\n            documents (list): List of documents to insert.\n\n        Returns:\n            dict: Result of the insert operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def find_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Find a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            dict or None: The found document or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def find_many(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        sort_criteria: Dict[str, Any],\n        offset: Optional[int] = None,\n        limit: Optional[int] = None,\n    ) -> Iterable[Dict[str, Any]]:\n        \"\"\"\n        Find multiple documents matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n            sort_criteria (dict): How to order the results\n            offset (int, optional): Number of records to skip (useful for pagination)\n            limit (int, optional): Max number of documents to return.\n\n        Returns:\n            iterator for result: Iterable sequence of matching documents.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update_one(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        update: Dict[str, Any],\n        upsert: bool = False,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Update a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n            update (dict): The update document.\n\n        Returns:\n            dict: Result of the update operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_one(self, collection: str, query: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Delete a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            dict: Result of the delete operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def count(self, collection: str, query: dict[str, Any]) -> int:\n        \"\"\"\n        Count how many records are in a collection that match the specified query\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            int: Number of documents that match the specified query\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def exists(self, collection: str, query: dict[str, Any]) -> bool:\n        \"\"\"\n        Check if at least one document exists in the collection that matches the\n        specified query\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            bool: True if a document exists and False if it doesn't\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def create_index(self, collection: str, index: Tuple[IndexExpression]):\n        \"\"\"\n        Create an index on a collection in the MongoDB Database\n\n        Args:\n            collection (str): The collection name.\n            index (tuple[IndexExpression]):\n                A tuple of IndexExpression objects representing the index to create\n                NOTE: Multiple elements in tuple indicate a single compound index\n        \"\"\"\n        pass\n\nclass AbstractAsyncMongoDBDriver(AbstractMongoDBDriver):\n    \"\"\"\n    Abstract base class for asynchronous MongoDB drivers.\n    Provides async context management and coroutine-safe access\n    to the currently active driver instance via contextvars.\n    \"\"\"\n\n    _current: contextvars.ContextVar[\"AbstractAsyncMongoDBDriver\"] = (\n        contextvars.ContextVar(\"mongo_driver_current\")\n    )\n\n    def __init__(self, connection_string: str, database_name: str):\n        \"\"\"\n        Initialize the MongoDB driver with a connection string and database name.\n\n        Args:\n            connection_string (str): MongoDB connection URI.\n            database_name (str): Target database name.\n        \"\"\"\n        pass\n\n    async def __aenter__(self):\n        \"\"\"\n        Enter the async context manager, connect to MongoDB, and set the current driver context.\n        \"\"\"\n        pass\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"\n        Exit the async context manager, close the connection, and reset the driver context.\n        \"\"\"\n        pass\n\n    @classmethod\n    def current(cls) -> \"AbstractAsyncMongoDBDriver\":\n        \"\"\"\n        Get the current MongoDB driver instance for this coroutine.\n\n        Returns:\n            AbstractAsyncMongoDBDriver: The active driver instance.\n\n        Raises:\n            RuntimeError: If no driver is currently in context.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def connect(self) -> bool:\n        \"\"\"\n        Establish a connection to the MongoDB server.\n        Returns:\n            bool: True if connection was successful.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def close(self) -> None:\n        \"\"\"\n        Close the connection to the MongoDB server.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def insert_one(\n        self, collection: str, document: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Insert a single document into the specified collection.\n\n        Args:\n            collection (str): The collection name.\n            document (dict): The document to insert.\n\n        Returns:\n            dict: Result of the insert operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def insert_many(\n        self, collection: str, documents: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Insert multiple documents into the specified collection.\n\n        Args:\n            collection (str): The collection name.\n            documents (list): List of documents to insert.\n\n        Returns:\n            dict: Result of the insert operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def find_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Find a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            dict or None: The found document or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def find_many(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        sort_criteria: Dict[str, Any],\n        offset: Optional[int] = None,\n        limit: Optional[int] = None,\n    ) -> Iterable[Dict[str, Any]]:\n        \"\"\"\n        Find multiple documents matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n            sort_criteria (dict): How to order the results\n            offset (int, optional): Number of records to skip (useful for pagination)\n            limit (int, optional): Max number of documents to return.\n\n        Returns:\n            iterable sequence: Iterable sequence of matching documents.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def update_one(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        update: Dict[str, Any],\n        upsert: bool = False,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Update a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n            update (dict): The update document.\n\n        Returns:\n            dict: Result of the update operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def delete_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Delete a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            dict: Result of the delete operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def count(self, collection: str, query: dict[str, Any]) -> int:\n        \"\"\"\n        Count how many records are in a collection that match the specified query\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            int: Number of documents that match the specified query\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def exists(self, collection: str, query: dict[str, Any]) -> bool:\n        \"\"\"\n        Check if at least one document exists in the collection that matches the\n        specified query\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            bool: True if a document exists and False if it doesn't\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def create_index(self, collection: str, index: Tuple[IndexExpression]):\n        \"\"\"\n        Create an index on a collection in the MongoDB Database\n\n        Args:\n            collection (str): The collection name.\n            index (tuple[IndexExpression]):\n                A tuple of IndexExpression objects representing the index to create\n                NOTE: Muiltiple elements in tuple indicate a single compound index\n                not multiple indexes\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "pydongo/utils/serializer.py",
                "code": "T = TypeVar(\"T\", bound=BaseModel)\n\nclass BaseTypeSerializer(ABC):\n    \"\"\"\n    Abstract base class for type serializers.\n\n    Implementations define how to convert values to and from MongoDB-compatible types.\n    \"\"\"\n\n    @staticmethod\n    @abstractmethod\n    def serialize(value: Any) -> Any:\n        \"\"\"\n        Convert a Python value into a MongoDB-storable format.\n\n        Args:\n            value (Any): The value to serialize.\n\n        Returns:\n            Any: A serialized version of the value.\n        \"\"\"\n        pass\n\n    @staticmethod\n    @abstractmethod\n    def deserialize(value: Any) -> Any:\n        \"\"\"\n        Convert a MongoDB-stored value back to a Python-native type.\n\n        Args:\n            value (Any): The value to deserialize.\n\n        Returns:\n            Any: The original Python representation.\n        \"\"\"\n        pass\n\nclass DateSerializer(BaseTypeSerializer):\n    \"\"\"\n    Serializer for converting `datetime.date` to `datetime.datetime`.\n\n    Ensures compatibility with MongoDB, which only supports datetime objects.\n    \"\"\"\n\n    @staticmethod\n    def serialize(value: datetime.date) -> datetime.datetime:\n        \"\"\"\n        Serialize a `date` object into a UTC `datetime` object.\n\n        Args:\n            value (datetime.date): The date to serialize.\n\n        Returns:\n            datetime.datetime: A datetime object representing midnight of the same date.\n        \"\"\"\n        pass\n\n    @staticmethod\n    def deserialize(value: datetime.datetime) -> datetime.date:\n        \"\"\"\n        Deserialize a `datetime` object back into a `date`.\n\n        Args:\n            value (datetime.datetime): The datetime to convert.\n\n        Returns:\n            datetime.date: The date component of the datetime.\n        \"\"\"\n        pass\n\nclass UUIDSerializer(BaseTypeSerializer):\n    \"\"\"\n    Serializer for UUIDs, converting them to and from strings.\n    \"\"\"\n\n    @staticmethod\n    def serialize(value: UUID) -> str:\n        \"\"\"\n        Convert a UUID to a string for MongoDB storage.\n\n        Args:\n            value (UUID): The UUID to serialize.\n\n        Returns:\n            str: String representation of the UUID.\n        \"\"\"\n        pass\n\n    @staticmethod\n    def deserialize(value: str) -> UUID:\n        \"\"\"\n        Convert a string back into a UUID object.\n\n        Args:\n            value (str): UUID string.\n\n        Returns:\n            UUID: The corresponding UUID object.\n        \"\"\"\n        pass\n\ndef replace_unserializable_fields(document: dict) -> dict:\n    \"\"\"\n    Recursively replaces values in a document that are not MongoDB-compatible\n    with serialized equivalents, using registered type handlers.\n\n    Args:\n        document (dict): The original document to sanitize.\n\n    Returns:\n        dict: A deep-copied document with serializable values.\n    \"\"\"\n    pass\n\ndef restore_unserializable_fields(document: dict) -> dict:\n    \"\"\"\n    Recursively attempts to deserialize known types in a document.\n\n    NOTE: This is a basic placeholder strategy — it applies all registered deserializers\n    without knowing the intended field type. This can result in incorrect types.\n\n    It's recommended to use field-aware deserialization (tied to model schemas)\n    for production use.\n\n    Args:\n        document (dict): A document retrieved from MongoDB.\n\n    Returns:\n        dict: A deep-copied document with deserialized values (best-effort).\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "pydongo/utils/annotations.py",
                "code": "def resolve_annotation(annotation: Any) -> Any:\n    \"\"\"\n    Helper function to resolve actual data types from Optional, Union, or Annotated wrappers.\n\n    Args:\n        annotation (Any): Type annotation from the Pydantic model.\n\n    Returns:\n        Any: The resolved base type annotation.\n    \"\"\"\n    pass\n"
            }
        ],
        "minimal_code_skeleton_structured": [
            {
                "file_path": "pydongo/__init__.py",
                "code": "# This file is intentionally left empty as per the analysis.\n# Test cases import `as_collection` from `pydongo`,\n# but its definition resides in `pydongo.workers.collection`.\n# The skeleton adheres to \"NO Import Statements\", so re-exports are omitted.\n# A user implementing the skeleton would need to ensure `pydongo/__init__.py`\n# makes `as_collection` available if test cases are to be run unmodified.\npass\n"
            },
            {
                "file_path": "pydongo/drivers/base.py",
                "code": "from abc import ABC, abstractmethod\nfrom typing import List, Dict, Any, Optional, Iterable, Tuple\n\nfrom pydongo.expressions.index import IndexExpression\n\n\nclass AbstractMongoDBDriver(ABC):\n    \"\"\"\n    Abstract base class for MongoDB drivers.\n    \"\"\"\n    pass\n\n\nclass AbstractSyncMongoDBDriver(AbstractMongoDBDriver):\n    \"\"\"\n    Abstract base class for synchronous MongoDB drivers.\n    Provides context management support and coroutine/thread-safe access\n    to the currently active driver instance via contextvars.\n    \"\"\"\n    def __init__(self, connection_string: str, database_name: str):\n        \"\"\"\n        Initialize the MongoDB driver with a connection string and database name.\n\n        Args:\n            connection_string (str): MongoDB connection URI.\n            database_name (str): Target database name.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def connect(self) -> bool:\n        \"\"\"\n        Establish a connection to the MongoDB server.\n        Returns:\n            bool: True if connection was successful.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def close(self) -> None:\n        \"\"\"\n        Close the connection to the MongoDB server.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def insert_one(self, collection: str, document: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Insert a single document into the specified collection.\n\n        Args:\n            collection (str): The collection name.\n            document (dict): The document to insert.\n\n        Returns:\n            dict: Result of the insert operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def insert_many(\n        self, collection: str, documents: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Insert multiple documents into the specified collection.\n\n        Args:\n            collection (str): The collection name.\n            documents (list): List of documents to insert.\n\n        Returns:\n            dict: Result of the insert operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def find_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Find a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            dict or None: The found document or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def find_many(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        sort_criteria: Dict[str, Any],\n        offset: Optional[int] = None,\n        limit: Optional[int] = None,\n    ) -> Iterable[Dict[str, Any]]:\n        \"\"\"\n        Find multiple documents matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n            sort_criteria (dict): How to order the results\n            offset (int, optional): Number of records to skip (useful for pagination)\n            limit (int, optional): Max number of documents to return.\n\n        Returns:\n            iterator for result: Iterable sequence of matching documents.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update_one(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        update: Dict[str, Any],\n        upsert: bool = False,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Update a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n            update (dict): The update document.\n\n        Returns:\n            dict: Result of the update operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_one(self, collection: str, query: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Delete a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            dict: Result of the delete operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def count(self, collection: str, query: dict[str, Any]) -> int:\n        \"\"\"\n        Count how many records are in a collection that match the specified query\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            int: Number of documents that match the specified query\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def exists(self, collection: str, query: dict[str, Any]) -> bool:\n        \"\"\"\n        Check if at least one document exists in the collection that matches the\n        specified query\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            bool: True if a document exists and False if it doesn't\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def create_index(self, collection: str, index: Tuple[IndexExpression]):\n        \"\"\"\n        Create an index on a collection in the MongoDB Database\n\n        Args:\n            collection (str): The collection name.\n            index (tuple[IndexExpression]):\n                A tuple of IndexExpression objects representing the index to create\n                NOTE: Multiple elements in tuple indicate a single compound index\n        \"\"\"\n        pass\n\n\nclass AbstractAsyncMongoDBDriver(AbstractMongoDBDriver):\n    \"\"\"\n    Abstract base class for asynchronous MongoDB drivers.\n    Provides async context management and coroutine-safe access\n    to the currently active driver instance via contextvars.\n    \"\"\"\n    def __init__(self, connection_string: str, database_name: str):\n        \"\"\"\n        Initialize the MongoDB driver with a connection string and database name.\n\n        Args:\n            connection_string (str): MongoDB connection URI.\n            database_name (str): Target database name.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def connect(self) -> bool:\n        \"\"\"\n        Establish a connection to the MongoDB server.\n        Returns:\n            bool: True if connection was successful.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def close(self) -> None:\n        \"\"\"\n        Close the connection to the MongoDB server.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def insert_one(\n        self, collection: str, document: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Insert a single document into the specified collection.\n\n        Args:\n            collection (str): The collection name.\n            document (dict): The document to insert.\n\n        Returns:\n            dict: Result of the insert operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def insert_many(\n        self, collection: str, documents: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Insert multiple documents into the specified collection.\n\n        Args:\n            collection (str): The collection name.\n            documents (list): List of documents to insert.\n\n        Returns:\n            dict: Result of the insert operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def find_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Find a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            dict or None: The found document or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def find_many(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        sort_criteria: Dict[str, Any],\n        offset: Optional[int] = None,\n        limit: Optional[int] = None,\n    ) -> Iterable[Dict[str, Any]]:\n        \"\"\"\n        Find multiple documents matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n            sort_criteria (dict): How to order the results\n            offset (int, optional): Number of records to skip (useful for pagination)\n            limit (int, optional): Max number of documents to return.\n\n        Returns:\n            iterable sequence: Iterable sequence of matching documents.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def update_one(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        update: Dict[str, Any],\n        upsert: bool = False,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Update a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n            update (dict): The update document.\n\n        Returns:\n            dict: Result of the update operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def delete_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Delete a single document matching the query.\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            dict: Result of the delete operation.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def count(self, collection: str, query: dict[str, Any]) -> int:\n        \"\"\"\n        Count how many records are in a collection that match the specified query\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            int: Number of documents that match the specified query\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def exists(self, collection: str, query: dict[str, Any]) -> bool:\n        \"\"\"\n        Check if at least one document exists in the collection that matches the\n        specified query\n\n        Args:\n            collection (str): The collection name.\n            query (dict): The filter query.\n\n        Returns:\n            bool: True if a document exists and False if it doesn't\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def create_index(self, collection: str, index: Tuple[IndexExpression]):\n        \"\"\"\n        Create an index on a collection in the MongoDB Database\n\n        Args:\n            collection (str): The collection name.\n            index (tuple[IndexExpression]):\n                A tuple of IndexExpression objects representing the index to create\n                NOTE: Muiltiple elements in tuple indicate a single compound index\n                not multiple indexes\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "pydongo/drivers/mock.py",
                "code": "from typing import List, Dict, Any, Optional, Tuple\n\nfrom pydongo.drivers.base import AbstractSyncMongoDBDriver, AbstractAsyncMongoDBDriver\nfrom pydongo.expressions.index import IndexExpression\n\n\nclass MockMongoDBDriver(AbstractSyncMongoDBDriver):\n    \"\"\"\n    In-memory mock implementation of the AbstractSyncMongoDBDriver.\n\n    This mock driver mimics MongoDB behavior for unit testing without requiring\n    a real database connection. Data is stored in-memory in Python dictionaries.\n    \"\"\"\n    def __init__(self, connection_string: str = \"\", database_name: str = \"mockdb\"):\n        \"\"\"\n        Initialize the mock driver with an empty in-memory store.\n\n        Args:\n            connection_string (str): Ignored.\n            database_name (str): Name of the fake database.\n        \"\"\"\n        pass\n\n    def connect(self) -> bool:\n        \"\"\"\n        Simulate a successful connection.\n\n        Returns:\n            bool: Always True.\n        \"\"\"\n        pass\n\n    def insert_one(self, collection: str, document: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Insert a document into the in-memory collection.\n\n        Args:\n            collection (str): Name of the collection.\n            document (dict): Document to insert.\n\n        Returns:\n            dict: Insert result including generated `_id`.\n        \"\"\"\n        pass\n\n    def find_one(\n        self, collection: str, query: Dict[str, Any]\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Find a single document matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): MongoDB-style filter.\n\n        Returns:\n            dict or None: Matching document or None if not found.\n        \"\"\"\n        pass\n\n    def update_one(\n        self,\n        collection: str,\n        query: Dict[str, Any],\n        update: Dict[str, Any],\n        upsert: bool = False,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Update a single document matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): Filter query.\n            update (dict): Update operations (only supports \"$set\").\n\n        Returns:\n            dict: Update result with matched and modified count.\n        \"\"\"\n        pass\n\n    def delete_one(self, collection: str, query: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Delete the first document matching the query.\n\n        Args:\n            collection (str): Name of the collection.\n            query (dict): Filter query.\n\n        Returns:\n            dict: Delete result.\n        \"\"\"\n        pass\n\n    def create_index(self, collection: str, index: Tuple[IndexExpression]):\n        \"\"\"\n        Create an index on a collection in the MongoDB Database\n\n        Args:\n            collection (str): The collection name.\n            index (tuple[IndexExpression]):\n                A tuple of IndexExpression objects representing the index to create\n                NOTE: Multiple elements in tuple indicate a single compound index\n                not multiple indexes\n\n        \"\"\"\n        pass\n\n\nclass MockAsyncMongoDBDriver(AbstractAsyncMongoDBDriver):\n    \"\"\"\n    In-memory mock implementation of the AbstractAsyncMongoDBDriver.\n\n    This async mock mirrors the behavior of MongoDB using native async/await\n    and an in-memory store. Ideal for use in async unit tests.\n    \"\"\"\n    def __init__(self, connection_string: str = \"\", database_name: str = \"mockdb\"):\n        \"\"\"\n        Initialize the async mock with an in-memory store.\n\n        Args:\n            connection_string (str): Ignored.\n            database_name (str): Mock database name.\n        \"\"\"\n        pass\n\n    async def connect(self) -> bool:\n        \"\"\"\n        Simulate async connection success.\n\n        Returns:\n            bool: Always True.\n        \"\"\"\n        pass\n\n    async def create_index(self, collection: str, index: Tuple[IndexExpression]):\n        \"\"\"\n        Create an index on a collection in the MongoDB Database\n\n        Args:\n            collection (str): The collection name.\n            index (tuple[IndexExpression]):\n                A tuple of IndexExpression objects representing the index to create\n                NOTE: Muiltiple elements in tuple indicate a single compound index\n                not multiple indexes\n\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "pydongo/expressions/base.py",
                "code": "from abc import ABC, abstractmethod\nfrom typing import Any\n\n\nclass BaseExpression(ABC):\n    @abstractmethod\n    def serialize(self) -> Any:\n        \"\"\"\n        Serialize an expression into a MongoDB compatible query DTO\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "pydongo/expressions/filter.py",
                "code": "from typing import Optional\nfrom pydongo.expressions.base import BaseExpression\n\n\nclass CollectionFilterExpression(BaseExpression):\n    \"\"\"\n    Represents a boolean filter expression used to query a MongoDB collection.\n\n    These expressions are composable using:\n        - Logical OR (`|`)\n        - Logical AND (`&`)\n        - Logical NOT (`~`)\n\n    Example usage:\n        filter_1 = User.age > 18\n        filter_2 = User.name == \"Samuel\"\n        combined = filter_1 & filter_2\n\n    The resulting expression can be serialized and passed to the database driver.\n    \"\"\"\n    def __init__(self, expression: Optional[dict] = None):\n        \"\"\"\n        Initialize the filter expression with an optional initial dictionary.\n\n        Args:\n            expression (Optional[dict]): A MongoDB-style query dictionary.\n        \"\"\"\n        pass\n\n    def with_expression(self, expression: dict) -> \"CollectionFilterExpression\":\n        \"\"\"\n        Mutate the internal expression by merging in a new dictionary.\n\n        Args:\n            expression (dict): A MongoDB-style query to merge into the current expression.\n\n        Returns:\n            CollectionFilterExpression: The current instance (for chaining).\n        \"\"\"\n        pass\n\n    def serialize(self) -> dict:\n        \"\"\"\n        Serialize the filter expression into a MongoDB-compatible query object.\n\n        Returns:\n            dict: Serialized MongoDB query.\n        \"\"\"\n        pass\n\n    def __and__(\n        self, other: \"CollectionFilterExpression\"\n    ) -> \"CollectionFilterExpression\":\n        \"\"\"\n        Combine this filter with another using a logical AND.\n\n        Args:\n            other (CollectionFilterExpression): Another filter to combine with.\n\n        Returns:\n            CollectionFilterExpression: A new combined filter.\n        \"\"\"\n        pass\n\n    def __or__(\n        self, other: \"CollectionFilterExpression\"\n    ) -> \"CollectionFilterExpression\":\n        \"\"\"\n        Combine this filter with another using a logical OR.\n\n        Args:\n            other (CollectionFilterExpression): Another filter to combine with.\n\n        Returns:\n            CollectionFilterExpression: A new combined filter.\n        \"\"\"\n        pass\n\n    def __invert__(self) -> \"CollectionFilterExpression\":\n        \"\"\"\n        Invert the current filter using a logical NOT.\n\n        Returns:\n            CollectionFilterExpression: A new filter expression wrapped in `$not`.\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "pydongo/expressions/field.py",
                "code": "from typing import Any, Iterable, Sequence\nfrom pydongo.expressions.filter import CollectionFilterExpression\nfrom pydongo.expressions.index import (\n    IndexExpression,\n    IndexExpressionBuilder,\n)\n\n\nclass FieldExpression:\n    \"\"\"\n    Represents a scalar field in a MongoDB query.\n\n    This class supports operator overloading to build query expressions using:\n        ==, !=, >, >=, <, <=\n\n    It also supports nested attribute access (e.g., user.address.city).\n    \"\"\"\n    def __init__(self, field_name: str, annotation=None, sort_ascending: bool = True):\n        \"\"\"\n        Initialize a field expression.\n\n        Args:\n            field_name (str): The full dot-path name of the field.\n            annotation (Any): The Pydantic type annotation for the field.\n            sort_ascending (bool): Whether sorting on this field is ascending by default.\n        \"\"\"\n        pass\n\n    def as_index(self) -> IndexExpressionBuilder:\n        \"\"\"\n        Returns an `IndexExpressionBuilder` initialized with this field.\n\n        This allows users to customize the index further, such as adding uniqueness,\n        TTL, collation, or partial filter expressions—before building the final index object.\n        \"\"\"\n        pass\n\n    def __eq__(self, other: Any) -> \"CollectionFilterExpression\":  # type: ignore\n        \"\"\"Build an equality expression (`==`).\"\"\"\n        pass\n\n    def __ne__(self, other: Any) -> \"CollectionFilterExpression\":  # type: ignore\n        \"\"\"Build an inequality expression (`!=`).\"\"\"\n        pass\n\n    def __gt__(self, other: Any) -> \"CollectionFilterExpression\":\n        \"\"\"Build a greater-than expression (`>`).\"\"\"\n        pass\n\n    def __ge__(self, other: Any) -> \"CollectionFilterExpression\":\n        \"\"\"Build a greater-than-or-equal expression (`>=`).\"\"\"\n        pass\n\n    def __lt__(self, other: Any) -> \"CollectionFilterExpression\":\n        \"\"\"Build a less-than expression (`<`).\"\"\"\n        pass\n\n    def __le__(self, other: Any) -> \"CollectionFilterExpression\":\n        \"\"\"Build a less-than-or-equal expression (`<=`).\"\"\"\n        pass\n\n    def __neg__(self) -> \"FieldExpression\":\n        \"\"\"\n        Flip the default sort order.\n\n        Returns:\n            FieldExpression: A new instance with reversed sort order.\n        \"\"\"\n        pass\n\n    @property\n    def field_name(self):\n        \"\"\"The full field name, including nested paths if applicable.\"\"\"\n        pass\n\n    def __getattr__(self, name: str) -> \"FieldExpression\":\n        \"\"\"\n        Support for chained dot notation, e.g. `user.address.city`.\n\n        Args:\n            name (str): Subfield name.\n\n        Returns:\n            FieldExpression: A new field expression for the nested field.\n        \"\"\"\n        pass\n\n\nclass ArraySizeFieldExpression(FieldExpression):\n    \"\"\"\n    Represents an expression for the size of an array field.\n\n    Used for queries like: `len(User.tags) > 2`\n    \"\"\"\n    def _get_comparative_expression(self, operator: str, value: int) -> dict:\n        \"\"\"\n        Build a MongoDB `$expr` query comparing the size of an array.\n\n        Args:\n            operator (str): Comparison operator (e.g., \"$gt\").\n            value (int): Value to compare the array size against.\n\n        Returns:\n            dict: MongoDB `$expr` query.\n        \"\"\"\n        pass\n\n\nclass ArrayFieldExpression(FieldExpression):\n    \"\"\"\n    Represents an array field in a MongoDB document.\n\n    Adds support for array-specific operations like `.contains()`, `.size()`, and `.matches()`.\n    \"\"\"\n    def __init__(self, field_name: str, annotation=None, sort_ascending: bool = True): # Explicitly listed as it's directly instantiated\n        \"\"\"\n        Initialize an array field expression.\n\n        Args:\n            field_name (str): The full dot-path name of the field.\n            annotation (Any): The Pydantic type annotation for the field.\n            sort_ascending (bool): Whether sorting on this field is ascending by default.\n        \"\"\"\n        super().__init__(field_name, annotation, sort_ascending) # Call to super is implementation detail, but signature is needed.\n        pass\n\n\n    def size(self) -> ArraySizeFieldExpression:\n        \"\"\"\n        Get an expression that targets the array's length.\n\n        Returns:\n            ArraySizeFieldExpression: An expression targeting the array's size.\n        \"\"\"\n        pass\n\n    def matches(\n        self, values: Iterable[Any], match_order: bool = False\n    ) -> CollectionFilterExpression:\n        \"\"\"\n        Check if the array exactly matches the provided values.\n\n        Args:\n            values (Iterable[Any]): Values to match against.\n            match_order (bool): If True, requires order-sensitive match.\n\n        Returns:\n            CollectionFilterExpression: MongoDB `$all` or exact match query.\n        \"\"\"\n        pass\n\n    def contains(self, value: Any) -> CollectionFilterExpression:\n        \"\"\"\n        Check if the array contains one or more values.\n\n        Args:\n            value (Any): A scalar or iterable to check presence for.\n\n        Returns:\n            CollectionFilterExpression: MongoDB `$in` expression.\n        \"\"\"\n        pass\n\n    def excludes(self, value: Any) -> CollectionFilterExpression:\n        \"\"\"\n        Check if the array excludes one or more values.\n\n        Args:\n            value (Any): A scalar or iterable to check absence for.\n\n        Returns:\n            CollectionFilterExpression: MongoDB `$nin` expression.\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "pydongo/expressions/index.py",
                "code": "from typing import Optional, Any, Tuple\nfrom enum import Enum, IntEnum\nfrom pydongo.expressions.base import BaseExpression\nfrom pydongo.expressions.filter import CollectionFilterExpression\n\n\nclass IndexSortOrder(IntEnum):\n    ASCENDING = 1\n    DESCENDING = -1\n\n\nclass IndexType(str, Enum):\n    TEXT = \"text\"\n    HASHED = \"hashed\"\n    TWO_DIMENSIONAL = \"2d\"\n    TWO_DIMENSIONAL_SPHERE = \"2dsphere\"\n\n\nclass CollationStrength(IntEnum):\n    PRIMARY = 1  # Only base characters (e.g., \"a\" == \"A\", \"é\" == \"e\")\n    SECONDARY = 2  # Case-insensitive, accent-sensitive (e.g., \"a\" == \"A\", \"é\" != \"e\")\n    TERTIARY = 3  # Case- and accent-sensitive (e.g., \"a\" != \"A\", \"é\" != \"e\")\n    QUATERNARY = 4  # Includes case, accent, punctuation (e.g., \"$a\" != \"a\")\n    IDENTICAL = 5  # Everything is compared (e.g., code point level)\n\n\nclass IndexExpression(BaseExpression):\n    def __init__(\n        self,\n        field_name: str,\n        index_type: Optional[IndexType] = None,\n        sort_order: IndexSortOrder = IndexSortOrder.ASCENDING,\n        expires_after_seconds: Optional[float] = None,  # For TTL indexes\n        is_sparse: Optional[bool] = None,\n        is_unique: Optional[bool] = None,\n        is_hidden: Optional[bool] = None,\n        collation_locale: str = \"en\",\n        collation_strength: Optional[CollationStrength] = None,\n        partial_expression: Optional[CollectionFilterExpression] = None,\n        index_name: Optional[str] = None,\n    ):\n        pass\n\n    def serialize(self) -> dict:\n        pass\n\n    def build_kwargs(self) -> dict:\n        \"\"\"\n        Additional specifications for the index to be passed to MongoDB's create_index.\n        Only includes non-null values.\n        \"\"\"\n        pass\n\n\nclass IndexExpressionBuilder:\n    def __init__(self, field_name: str):\n        pass\n\n    def use_sort_order(self, sort_order: IndexSortOrder) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_index_type(self, index_type: IndexType) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_collation(\n        self, locale: str, strength: CollationStrength\n    ) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_index_name(self, index_name: str) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_sparse(self, is_sparse: bool = True) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_unique(self, is_unique: bool = True) -> \"IndexExpressionBuilder\":\n        pass\n\n    def use_ttl(self, seconds: float) -> \"IndexExpressionBuilder\":\n        pass\n\n    def build_index(self) -> IndexExpression:\n        pass\n"
            },
            {
                "file_path": "pydongo/utils/annotations.py",
                "code": "from typing import Any\n\n\ndef resolve_annotation(annotation: Any) -> Any:\n    \"\"\"\n    Helper function to resolve actual data types from Optional, Union, or Annotated wrappers.\n\n    Args:\n        annotation (Any): Type annotation from the Pydantic model.\n\n    Returns:\n        Any: The resolved base type annotation.\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "pydongo/utils/serializer.py",
                "code": "from typing import Any\n\n\ndef replace_unserializable_fields(document: dict) -> dict:\n    \"\"\"\n    Recursively replaces values in a document that are not MongoDB-compatible\n    with serialized equivalents, using registered type handlers.\n\n    Args:\n        document (dict): The original document to sanitize.\n\n    Returns:\n        dict: A deep-copied document with serializable values.\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "pydongo/workers/collection.py",
                "code": "from abc import ABC\nfrom typing import (\n    Generic,\n    Iterable,\n    Optional,\n    Sequence,\n    Type,\n    Tuple,\n    TypeVar,\n    Union,\n)\nfrom pydantic import BaseModel\n\nfrom pydongo.expressions.field import FieldExpression\nfrom pydongo.expressions.filter import CollectionFilterExpression\nfrom pydongo.expressions.index import IndexExpression\n\nfrom pydongo.drivers.base import (\n    AbstractSyncMongoDBDriver,\n    AbstractAsyncMongoDBDriver,\n)\n\n\nT = TypeVar(\"T\", bound=BaseModel)\n\n\ndef as_collection(\n    pydantic_model: Type[T],\n    driver: Union[AbstractSyncMongoDBDriver, AbstractAsyncMongoDBDriver],\n) -> \"CollectionWorker\":\n    pass\n\n\nclass CollectionWorker(Generic[T]):\n    \"\"\"\n    Entry point for querying and interacting with a MongoDB collection.\n\n    Wraps a Pydantic model and MongoDB driver, and exposes queryable field expressions\n    and high-level `find_one`, `afind_one`, and `find` methods.\n\n    Supports both sync and async drivers via conditional branching.\n    \"\"\"\n    def __init__(\n        self,\n        pydantic_model: Type[T],\n        driver: Union[AbstractSyncMongoDBDriver, AbstractAsyncMongoDBDriver],\n    ):\n        pass\n\n    def find(\n        self, expression: Optional[CollectionFilterExpression] = None\n    ) -> \"CollectionResponseBuilder\":\n        \"\"\"\n        Initiates a fluent response builder chain for querying multiple documents.\n\n        Args:\n            expression (Optional[CollectionFilterExpression]): Optional filter expression.\n\n        Returns:\n            CollectionResponseBuilder: Builder for fluent chaining (e.g., .limit(), .sort()).\n        \"\"\"\n        pass\n\n    def use_index(\n        self,\n        index: Union[IndexExpression, Tuple[IndexExpression]],\n    ):\n        \"\"\"\n        Registers an index (or compound index) on the collection.\n\n        Accepts IndexExpression(s)\n\n        Args:\n            index: A single IndexExpression, or a tuple of them.\n\n        Returns:\n            CollectionWorker: Self, for method chaining.\n        \"\"\"\n        pass\n\n    def __getattr__(self, name: str) -> FieldExpression:\n        \"\"\"\n        Returns a field expression object to enable DSL-style querying using comparison\n        operators or dot notation for nested objects.\n\n        Args:\n            name (str): Field name in the Pydantic model.\n\n        Returns:\n            FieldExpression: Expression object tied to the field.\n\n        Raises:\n            AttributeError: If the field does not exist on the model.\n        \"\"\"\n        pass\n\n    @property\n    def collection_name(self):\n        \"\"\"\n        Derives the MongoDB collection name from the model or falls back to the class name.\n\n        Returns:\n            str: The name of the collection.\n        \"\"\"\n        pass\n\n\nclass CollectionResponseBuilder(ABC, Generic[T]):\n    \"\"\"\n    Fluent builder for composing queries and retrieving lists of documents.\n\n    Can build the final MongoDB query structure with sort, skip, and limit options.\n    \"\"\"\n    def __init__(\n        self,\n        expression: CollectionFilterExpression,\n        pydantic_model: Type[T],\n        driver: Union[AbstractSyncMongoDBDriver, AbstractAsyncMongoDBDriver],\n        collection_name: str,\n        indexes: Iterable[Tuple[IndexExpression]],\n    ):\n        pass\n\n    def skip(self, offset: int) -> \"CollectionResponseBuilder\":\n        \"\"\"\n        Skip the first N documents in the query result.\n\n        Args:\n            offset (int): Number of documents to skip.\n\n        Returns:\n            CollectionResponseBuilder: For chaining.\n        \"\"\"\n        pass\n\n    def limit(self, limit_value: int) -> \"CollectionResponseBuilder\":\n        \"\"\"\n        Limit the number of documents returned.\n\n        Args:\n            limit_value (int): Maximum number of documents to return.\n\n        Returns:\n            CollectionResponseBuilder: For chaining.\n        \"\"\"\n        pass\n\n    def sort(\n        self, sort_criteria: Union[FieldExpression, Sequence[FieldExpression]]\n    ) -> \"CollectionResponseBuilder\":\n        \"\"\"\n        Apply sort criteria to the query.\n\n        Args:\n            sort_criteria (Union[FieldExpression, Sequence[FieldExpression]]): Sort instructions.\n\n        Returns:\n            CollectionResponseBuilder: For chaining.\n        \"\"\"\n        pass\n\n    def build_kwargs(self) -> dict:\n        \"\"\"\n        Assembles the query, sort, offset, and limit into a single dictionary.\n\n        Returns:\n            dict: MongoDB-compatible query parameters.\n        \"\"\"\n        pass\n\n\nclass SyncCollectionResponseBuilder(CollectionResponseBuilder):\n    \"\"\"\n    Response builder for synchronous drivers.\n\n    Provides direct methods to count, check existence, and iterate documents.\n    \"\"\"\n    def __init__(\n        self,\n        expression: CollectionFilterExpression,\n        pydantic_model: Type[T],\n        driver: AbstractSyncMongoDBDriver,\n        collection_name: str,\n        indexes: Iterable[Tuple[IndexExpression]],\n    ):\n        pass\n\n    def count(self) -> int:\n        \"\"\"\n        Count how many documents match the filter expression.\n\n        Returns:\n            int: Number of matching documents.\n        \"\"\"\n        pass\n\n    def create_indexes(self):\n        \"\"\"\n        Creates indexes on the MongoDB database.\n        \"\"\"\n        pass\n\n\nclass AsyncCollectionResponseBuilder(CollectionResponseBuilder):\n    \"\"\"\n    Response builder for asynchronous drivers.\n\n    Supports async versions of exists, count, and all().\n    \"\"\"\n    def __init__(\n        self,\n        expression: CollectionFilterExpression,\n        pydantic_model: Type[T],\n        driver: AbstractAsyncMongoDBDriver,\n        collection_name: str,\n        indexes: Iterable[Tuple[IndexExpression]],\n    ):\n        pass\n\n    async def count(self) -> int:\n        \"\"\"\n        Asynchronously count how many documents match the filter.\n\n        Returns:\n            int: Number of matching documents.\n        \"\"\"\n        pass\n\n    async def create_indexes(self):\n        \"\"\"\n        Asynchronously creates indexes on the MongoDB database.\n        \"\"\"\n        pass\n"
            }
        ]
    },
    {
        "idx": 7459,
        "repo_name": "jhd3197_Tukuy",
        "url": "https://github.com/jhd3197/Tukuy",
        "description": "Tukuy is a robust, extensible data transformation library that leverages a flexible plugin system. It simplifies the manipulation, validation, and extraction of data across multiple formats (text, HTML, JSON, dates, numbers, and more), making it an ideal tool for building data pipelines and cleaning workflows.",
        "stars": 20,
        "forks": 0,
        "language": "python",
        "size": 54,
        "created_at": "2025-03-24T04:09:16+00:00",
        "updated_at": "2025-03-30T02:35:09+00:00",
        "pypi_info": {
            "name": "tukuy",
            "version": "0.0.3",
            "url": "https://files.pythonhosted.org/packages/58/d9/743001573a57fd103b4002b60ca7c559f06de1c1b132aa84bc10eed24fb3/tukuy-0.0.3.tar.gz"
        },
        "error": null,
        "judge_info": {
            "language": "python",
            "is_good_project": false,
            "reason": "",
            "python_file_num": 28,
            "comment_ratio": 0.3442970822281167,
            "pyfile_content_length": 136267,
            "pyfile_code_lines": 3770,
            "test_file_exist": true,
            "test_file_content_length": 33441,
            "pytest_framework": true,
            "test_case_num": 35,
            "metadata_path": [
                "pyproject.toml",
                "setup.py"
            ],
            "readme_content_length": 6374,
            "llm_reason": "Positive aspects: The project is a self-contained Python library, meaning its core functionalities and testing do not require an active internet connection or external APIs/services once dependencies are installed. Dependencies like BeautifulSoup4 (for HTML processing), and potentially jsonschema or python-dateutil, are standard, pip-installable, and operate offline. The project has clear and well-defined functionality, as evidenced by its README, which details its purpose in data manipulation, validation, and extraction across various formats (text, HTML, JSON, dates, numbers) using a plugin architecture and chainable transformers. It is highly testable, with a comprehensive suite of test files provided, which is crucial for verifying an AI's attempt to rebuild it. The project is a library and does not involve a GUI. The problem domain (data transformation) is well-understood. The complexity is appropriate: it's non-trivial, featuring a plugin system, base classes, numerous specific transformers, and pattern-based extraction, but it does not involve esoteric algorithms or cutting-edge research, making it a good challenge for an AI to replicate. \n\nNegative aspects or concerns: The primary concern is the scope; the library is quite comprehensive with many individual transformer classes (around 40-50 core logic classes spread across different modules like text, HTML, JSON, date, numerical, validation) and a plugin system. Replicating all features, especially the detailed logic within the `HtmlExtractor` (which uses CSS selectors and recursive extraction) and `JsonExtractor` (which uses path-like expressions and handles nested structures), would be a substantial undertaking. While modular, the sheer breadth could push the difficulty towards the higher end of 'Medium'. The AI would need to correctly implement the plugin registration, the main `TukuyTransformer` dispatch logic, and the variety of transformation rules for each data type.",
            "llm_project_type": "Data transformation and validation library with a plugin system",
            "llm_rating": 75,
            "llm_difficulty": "Medium"
        },
        "tests": {
            "repo_name": "jhd3197_Tukuy",
            "finish_test": true,
            "test_case_result": {
                "tests/test_html_transforms.py::test_strip_html_tags": "passed",
                "tests/test_html_transforms.py::test_html_sanitization": "passed",
                "tests/test_html_transforms.py::test_link_extraction": "passed",
                "tests/test_html_transforms.py::test_url_transforms": "passed",
                "tests/test_html_transforms.py::test_html_and_text_combination": "passed",
                "tests/test_html_transforms.py::test_complex_product_extraction": "passed",
                "tests/test_html_transforms.py::test_complex_pattern_extraction": "passed",
                "tests/test_html_transforms.py::test_extract_property_from_html": "passed",
                "tests/test_json_transforms.py::test_json_parser_basic": "passed",
                "tests/test_json_transforms.py::test_json_parser_invalid": "passed",
                "tests/test_json_transforms.py::test_json_parser_schema_validation": "passed",
                "tests/test_json_transforms.py::test_json_extractor_simple": "passed",
                "tests/test_json_transforms.py::test_json_extractor_nested": "passed",
                "tests/test_json_transforms.py::test_json_extractor_array": "passed",
                "tests/test_json_transforms.py::test_json_extractor_fallback": "passed",
                "tests/test_json_transforms.py::test_complex_json_pattern": "passed",
                "tests/test_json_transforms.py::test_extract_property_from_json": "passed",
                "tests/test_json_transforms.py::test_extract_property_from_json_errors": "passed",
                "tests/test_numerical_and_date_transforms.py::test_numerical_transforms": "passed",
                "tests/test_numerical_and_date_transforms.py::test_math_operations": "passed",
                "tests/test_numerical_and_date_transforms.py::test_date_transforms": "passed",
                "tests/test_numerical_and_date_transforms.py::test_age_calculation": "passed",
                "tests/test_numerical_and_date_transforms.py::test_duration_calculation": "passed",
                "tests/test_numerical_and_date_transforms.py::test_number_extraction": "passed",
                "tests/test_text_transforms.py::test_basic_text_transforms": "passed",
                "tests/test_text_transforms.py::test_chained_text_transforms": "passed",
                "tests/test_text_transforms.py::test_slugify": "passed",
                "tests/test_text_transforms.py::test_text_replacements": "passed",
                "tests/test_text_transforms.py::test_regex_transforms": "passed",
                "tests/test_text_transforms.py::test_template_transform": "passed",
                "tests/test_validation_transforms.py::test_email_validation": "passed",
                "tests/test_validation_transforms.py::test_phone_formatting": "passed",
                "tests/test_validation_transforms.py::test_credit_card_validation": "passed",
                "tests/test_validation_transforms.py::test_boolean_conversion": "passed",
                "tests/test_validation_transforms.py::test_type_enforcement": "passed"
            },
            "success_count": 35,
            "failed_count": 0,
            "error_count": 0,
            "skipped_count": 0,
            "unknown_count": 0,
            "total_count": 35,
            "success_rate": 1.0,
            "coverage_report": {
                "covered_lines": 941,
                "num_statements": 1338,
                "percent_covered": 67.18377088305489,
                "percent_covered_display": "67",
                "missing_lines": 397,
                "excluded_lines": 0,
                "num_branches": 338,
                "num_partial_branches": 77,
                "covered_branches": 185,
                "missing_branches": 153
            },
            "coverage_result": {}
        },
        "codelines_count": 3770,
        "codefiles_count": 28,
        "code_length": 136267,
        "test_files_count": 5,
        "test_code_length": 33441,
        "structure": [
            {
                "file": "setup.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "examples.py",
                "functions": [
                    {
                        "name": "text_transformation_examples",
                        "docstring": "Examples of text transformations using Tukuy.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "html_transformation_examples",
                        "docstring": "Examples of HTML transformations using Tukuy.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "json_transformation_example",
                        "docstring": "Example of JSON transformations using Tukuy.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "main",
                        "docstring": "Main function to run all examples.",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_numerical_and_date_transforms.py",
                "functions": [
                    {
                        "name": "test_numerical_transforms",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_math_operations",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_date_transforms",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_age_calculation",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_duration_calculation",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_number_extraction",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_json_transforms.py",
                "functions": [
                    {
                        "name": "test_json_parser_basic",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_json_parser_invalid",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_json_parser_schema_validation",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_json_extractor_simple",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_json_extractor_nested",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_json_extractor_array",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_json_extractor_fallback",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_complex_json_pattern",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_extract_property_from_json",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_extract_property_from_json_errors",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/conftest.py",
                "functions": [
                    {
                        "name": "transformer",
                        "docstring": "Fixture that provides a TukuyTransformer instance for tests.",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_text_transforms.py",
                "functions": [
                    {
                        "name": "test_basic_text_transforms",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_chained_text_transforms",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_slugify",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_text_replacements",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_regex_transforms",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_template_transform",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_validation_transforms.py",
                "functions": [
                    {
                        "name": "test_email_validation",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_phone_formatting",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_credit_card_validation",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_boolean_conversion",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_type_enforcement",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_html_transforms.py",
                "functions": [
                    {
                        "name": "test_strip_html_tags",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_html_sanitization",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_link_extraction",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_url_transforms",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_html_and_text_combination",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_complex_product_extraction",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_complex_pattern_extraction",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    },
                    {
                        "name": "test_extract_property_from_html",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "transformer"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tukuy/exceptions.py",
                "functions": [],
                "classes": [
                    {
                        "name": "TransformerError",
                        "docstring": "Base exception class for all transformer-related errors.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message",
                                    "value"
                                ]
                            },
                            {
                                "name": "__str__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "ValidationError",
                        "docstring": "Raised when input validation fails.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__str__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TransformationError",
                        "docstring": "Raised when a transformation operation fails.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message",
                                    "value",
                                    "transformer_name"
                                ]
                            },
                            {
                                "name": "__str__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "ConfigurationError",
                        "docstring": "Raised when transformer configuration is invalid.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__str__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "PatternError",
                        "docstring": "Raised when a pattern is invalid or malformed.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__str__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "ExtractorError",
                        "docstring": "Raised when data extraction fails.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__str__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "ParseError",
                        "docstring": "Raised when parsing operations fail.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__str__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tukuy/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tukuy/types.py",
                "functions": [],
                "classes": [
                    {
                        "name": "TransformResult",
                        "docstring": "Container for transformation results with error handling.",
                        "comments": "Transform result types",
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "error"
                                ]
                            },
                            {
                                "name": "failed",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__str__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TransformOptions",
                        "docstring": "Base class for transformer options.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "TextTransformOptions",
                        "docstring": "Options for text transformations.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "DateTransformOptions",
                        "docstring": "Options for date transformations.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "NumberTransformOptions",
                        "docstring": "Options for number transformations.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "PatternOptions",
                        "docstring": "Options for pattern-based transformations.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "ExtractorOptions",
                        "docstring": "Options for data extraction.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "TransformerProtocol",
                        "docstring": "Protocol defining the interface for transformers.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "name",
                                "docstring": "Get the transformer name.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "transform",
                                "docstring": "Transform the input value according to the transformer's rules.\n\nArgs:\n    value: The input value to transform\n    context: Optional context for the transformation\n    \nReturns:\n    TransformResult containing either the transformed value or an error",
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": "Validate the input value.\n\nArgs:\n    value: The input value to validate\n    \nReturns:\n    True if the value is valid for this transformer, False otherwise",
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "get_validation_errors",
                                "docstring": "Get list of validation errors for the input value.\n\nArgs:\n    value: The input value to validate\n    \nReturns:\n    List of validation error messages, empty if valid",
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "ExtractorProtocol",
                        "docstring": "Protocol defining the interface for data extractors.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "extract_data",
                                "docstring": "Extract data according to the given pattern.\n\nArgs:\n    data: The data to extract from (HTML, JSON, etc.)\n    pattern: The pattern describing what to extract\n    \nReturns:\n    Dictionary of extracted data",
                                "comments": null,
                                "args": [
                                    "self",
                                    "data",
                                    "pattern"
                                ]
                            },
                            {
                                "name": "extract_property",
                                "docstring": "Extract a single property from data.\n\nArgs:\n    data: The data to extract from\n    property_def: The property definition\n    \nReturns:\n    The extracted property value",
                                "comments": null,
                                "args": [
                                    "self",
                                    "data",
                                    "property_def"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "ValidatorProtocol",
                        "docstring": "Protocol defining the interface for validators.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "validate",
                                "docstring": "Validate the input value.\n\nArgs:\n    value: The input value to validate\n    \nReturns:\n    True if the value is valid, False otherwise",
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "get_validation_errors",
                                "docstring": "Get list of validation errors for the input value.\n\nArgs:\n    value: The input value to validate\n    \nReturns:\n    List of validation error messages, empty if valid",
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "validate_with_context",
                                "docstring": "Validate the input value with additional context.\n\nArgs:\n    value: The input value to validate\n    context: Additional context for validation\n    \nReturns:\n    True if the value is valid, False otherwise",
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "PluginProtocol",
                        "docstring": "Protocol defining the interface for plugins.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "name",
                                "docstring": "Get the plugin name.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "transformers",
                                "docstring": "Get the transformers provided by this plugin.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "initialize",
                                "docstring": "Initialize the plugin.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "cleanup",
                                "docstring": "Clean up the plugin.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "get_transformer",
                                "docstring": "Get a transformer by name with the given parameters.\n\nArgs:\n    name: The transformer name\n    params: Parameters for the transformer\n    \nReturns:\n    The transformer instance or None if not found",
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "params"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tukuy/base.py",
                "functions": [],
                "classes": [
                    {
                        "name": "BaseTransformer",
                        "docstring": "Abstract base class for all transformers.\n\nProvides common functionality and defines the interface that all transformers\nmust implement.\n\nType Parameters:\n    T: The input type that this transformer accepts\n    U: The output type that this transformer produces",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the transformer.\n\nArgs:\n    name: Unique identifier for this transformer\n    options: Configuration options for this transformer",
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "options"
                                ]
                            },
                            {
                                "name": "_validate_options",
                                "docstring": "Validate the transformer options.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": "Validate the input value.\n\nArgs:\n    value: The value to validate\n    \nReturns:\n    bool: True if valid, False otherwise",
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": "Internal transformation method that subclasses must implement.\n\nArgs:\n    value: The value to transform\n    context: Optional context data for the transformation\n    \nReturns:\n    The transformed value\n    \nRaises:\n    TransformationError: If the transformation fails",
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            },
                            {
                                "name": "transform",
                                "docstring": "Public method to transform a value with error handling.\n\nArgs:\n    value: The value to transform\n    context: Optional context data for the transformation\n    **kwargs: Additional keyword arguments for the transformation\n    \nReturns:\n    TransformResult containing either the transformed value or an error",
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            },
                            {
                                "name": "__str__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__repr__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "ChainableTransformer",
                        "docstring": "A transformer that can be chained with other transformers.\n\nAllows for creating pipelines of transformations where the output of one\ntransformer becomes the input to the next.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "next_transformer",
                                    "options"
                                ]
                            },
                            {
                                "name": "chain",
                                "docstring": "Chain this transformer with another transformer.\n\nArgs:\n    next_transformer: The next transformer in the chain\n    \nReturns:\n    self for method chaining",
                                "comments": null,
                                "args": [
                                    "self",
                                    "next_transformer"
                                ]
                            },
                            {
                                "name": "transform",
                                "docstring": "Transform the value and pass it through the chain.\n\nArgs:\n    value: The value to transform\n    context: Optional context data for the transformation\n    **kwargs: Additional keyword arguments for the transformation\n    \nReturns:\n    TransformResult containing either the final transformed value or an error",
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "CompositeTransformer",
                        "docstring": "A transformer that combines multiple transformers into a single unit.\n\nUseful for creating complex transformations from simpler ones.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "transformers",
                                    "options"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": "Validate input through all contained transformers.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": "Apply all transformations in sequence.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "RegexTransformer",
                        "docstring": "Apply regex pattern to text.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "pattern",
                                    "template"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "ReplaceTransformer",
                        "docstring": "Replace text.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "old",
                                    "new"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "CoreToolsTransformer",
                        "docstring": "Coordinates the application of multiple transformations using existing transformers.\n\nThis transformer takes a value and a list of transform operations, creates the\nappropriate transformers, and chains them together to produce the final result.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "transforms"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tukuy/transformers/__init__.py",
                "functions": [],
                "classes": [
                    {
                        "name": "TukuyTransformer",
                        "docstring": "Main transformer class that provides access to all transformation tools.\n\nThis class serves as the main entry point for the transformation library,\nproviding a unified interface to all available transformers through a plugin system.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the transformer registry.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "_load_builtin_plugins",
                                "docstring": "Load all built-in plugins.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "register_plugin",
                                "docstring": "Register a custom plugin.\n\nArgs:\n    plugin: The plugin to register",
                                "comments": null,
                                "args": [
                                    "self",
                                    "plugin"
                                ]
                            },
                            {
                                "name": "unregister_plugin",
                                "docstring": "Unregister a plugin.\n\nArgs:\n    name: Name of the plugin to unregister",
                                "comments": null,
                                "args": [
                                    "self",
                                    "name"
                                ]
                            },
                            {
                                "name": "transform",
                                "docstring": "Transform a value using a sequence of transformations.\n\nArgs:\n    value: The value to transform\n    transforms: List of transformations to apply. Each item can be:\n        - a string (the transformer name)\n        - a dict with 'function' key and additional parameters\n        \nReturns:\n    The transformed value\n    \nRaises:\n    TransformationError: If any transformation fails\n    ParseError: If JSON parsing fails in strict mode\n    ValidationError: If schema validation fails",
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "transforms"
                                ]
                            },
                            {
                                "name": "extract_html_with_pattern",
                                "docstring": "Extract data from HTML using a pattern.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "html",
                                    "pattern"
                                ]
                            },
                            {
                                "name": "extract_property_from_html",
                                "docstring": "Extract a single property from HTML.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "html",
                                    "prop"
                                ]
                            },
                            {
                                "name": "extract_json_with_pattern",
                                "docstring": "Extract data from JSON using a pattern.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "json_data",
                                    "pattern"
                                ]
                            },
                            {
                                "name": "extract_property_from_json",
                                "docstring": "Extract a single property from JSON data.\n\nArgs:\n    json_data: JSON string or already parsed JSON data\n    prop: Property extraction pattern\n    \nReturns:\n    The extracted property value\n    \nRaises:\n    ValidationError: If JSON plugin is not loaded\n    ParseError: If JSON string is invalid\n    TransformationError: If extraction fails",
                                "comments": null,
                                "args": [
                                    "self",
                                    "json_data",
                                    "prop"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tukuy/transformers/validation.py",
                "functions": [],
                "classes": [
                    {
                        "name": "BooleanTransformer",
                        "docstring": "Convert string to boolean.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": [
                            "TRUE_VALUES",
                            "FALSE_VALUES"
                        ]
                    },
                    {
                        "name": "EmailValidator",
                        "docstring": "Validate email address.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "allowed_domains"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "PhoneFormatter",
                        "docstring": "Format phone number.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "format"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "CreditCardValidator",
                        "docstring": "Validate credit card number using Luhn algorithm.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "mask"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TypeEnforcer",
                        "docstring": "Enforce type conversion.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "target_type"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tukuy/transformers/html.py",
                "functions": [],
                "classes": [
                    {
                        "name": "StripHtmlTagsTransformer",
                        "docstring": "Strip HTML tags from text.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "HtmlSanitizationTransformer",
                        "docstring": "Sanitize HTML by removing script and style tags.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "LinkExtractionTransformer",
                        "docstring": "Extract links from HTML.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "ResolveUrlTransformer",
                        "docstring": "Resolve relative URL to absolute URL.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "base_url"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "ExtractDomainTransformer",
                        "docstring": "Extract domain from URL.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "HtmlExtractor",
                        "docstring": "Extract data from HTML using a pattern.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "pattern"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            },
                            {
                                "name": "_extract_property",
                                "docstring": "Extract a property from HTML using the property pattern.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "soup",
                                    "prop",
                                    "context"
                                ]
                            },
                            {
                                "name": "_select_elements",
                                "docstring": "Select elements using primary selector or fallbacks.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "soup",
                                    "primary",
                                    "fallback"
                                ]
                            },
                            {
                                "name": "_select_element",
                                "docstring": "Select a single element using primary selector or fallbacks.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "soup",
                                    "primary",
                                    "fallback"
                                ]
                            },
                            {
                                "name": "_get_element_value",
                                "docstring": "Get value from element based on attribute.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "element",
                                    "attribute"
                                ]
                            },
                            {
                                "name": "_extract_nested_property",
                                "docstring": "Extract a nested property from an element.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "element",
                                    "prop",
                                    "context"
                                ]
                            },
                            {
                                "name": "_process_object",
                                "docstring": "Process an object with properties.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "element",
                                    "properties",
                                    "context"
                                ]
                            },
                            {
                                "name": "_apply_transforms",
                                "docstring": "Apply transforms to a value.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "transforms",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tukuy/transformers/numerical.py",
                "functions": [],
                "classes": [
                    {
                        "name": "IntegerTransformer",
                        "docstring": "Convert value to integer.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "min_value",
                                    "max_value"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "FloatTransformer",
                        "docstring": "Convert value to float.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "min_value",
                                    "max_value"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "RoundTransformer",
                        "docstring": "Round a number to specified number of decimal places.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "decimals"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "CurrencyConverter",
                        "docstring": "Convert currency using exchange rate.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "rate"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "UnitConverter",
                        "docstring": "Convert units using conversion rate.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "rate"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "MathOperationTransformer",
                        "docstring": "Perform math operation on a value.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "operation",
                                    "operand"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": [
                            "OPERATIONS"
                        ]
                    },
                    {
                        "name": "PercentageCalculator",
                        "docstring": "Convert decimal to percentage.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tukuy/transformers/text.py",
                "functions": [],
                "classes": [
                    {
                        "name": "StripTransformer",
                        "docstring": "Strip whitespace from text.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "LowercaseTransformer",
                        "docstring": "Convert text to lowercase.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "UppercaseTransformer",
                        "docstring": "Convert text to uppercase.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TemplateTransformer",
                        "docstring": "Apply template to regex match.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "template"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "MapTransformer",
                        "docstring": "Map values using a dictionary.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "mapping",
                                    "default"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "SplitTransformer",
                        "docstring": "Split text and return specific part.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "delimiter",
                                    "index"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TitleCaseTransformer",
                        "docstring": "Convert text to title case.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "CamelCaseTransformer",
                        "docstring": "Convert text to camel case.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "SnakeCaseTransformer",
                        "docstring": "Convert text to snake case.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "SlugifyTransformer",
                        "docstring": "Convert text to URL-friendly slug.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TruncateTransformer",
                        "docstring": "Truncate text to specified length.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "length",
                                    "suffix"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "RemoveEmojisTransformer",
                        "docstring": "Remove emojis from text.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "RedactSensitiveTransformer",
                        "docstring": "Redact sensitive information like credit card numbers.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tukuy/transformers/json.py",
                "functions": [],
                "classes": [
                    {
                        "name": "JsonParser",
                        "docstring": "Parses JSON strings into Python objects.\n\nFeatures:\n- Strict/lenient parsing modes\n- Schema validation\n- Error handling with detailed messages",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "strict",
                                    "schema"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": "Validate that the input is a JSON string.\n\nIn the validate method, we just check if the input is a string.\nActual JSON validity and schema validation is performed in _transform.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": "Transform a JSON string into a Python object.\n\nArgs:\n    value: A JSON string\n    context: Optional transformation context\n    \nReturns:\n    Parsed JSON data\n    \nRaises:\n    ParseError: If the JSON string is invalid and strict=True\n    ValidationError: If the JSON data does not match the schema",
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            },
                            {
                                "name": "_validate_schema",
                                "docstring": "Simple schema validation.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "data",
                                    "schema"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "JsonExtractor",
                        "docstring": "Extracts data from JSON structures using patterns.\n\nFeatures:\n- JSONPath-like syntax for data extraction\n- Nested property access\n- Array operations\n- Default values",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "pattern",
                                    "default"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            },
                            {
                                "name": "_extract_data",
                                "docstring": "Extract data according to the pattern.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "data",
                                    "pattern"
                                ]
                            },
                            {
                                "name": "_get_value",
                                "docstring": "Get a value using a path expression.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "data",
                                    "path"
                                ]
                            },
                            {
                                "name": "_get_array_values",
                                "docstring": "Get array values using a path expression.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "data",
                                    "path"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tukuy/transformers/date.py",
                "functions": [],
                "classes": [
                    {
                        "name": "DateTransformer",
                        "docstring": "Parse date string into datetime object.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "format"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TimezoneTransformer",
                        "docstring": "Convert datetime between timezones.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "to_zone",
                                    "from_zone"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "DurationCalculator",
                        "docstring": "Calculate duration between dates.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "unit",
                                    "format",
                                    "end"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "AgeCalculator",
                        "docstring": "Calculate age from birth date.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "reference_date"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tukuy/plugins/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tukuy/plugins/base.py",
                "functions": [],
                "classes": [
                    {
                        "name": "TransformerPlugin",
                        "docstring": "Base class for transformer plugins.\n\nA plugin is a collection of related transformers that can be registered\nwith the TukuyTransformer. Plugins provide a way to organize transformers\ninto logical groups and manage their lifecycle.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the plugin.\n\nArgs:\n    name: Unique identifier for this plugin",
                                "comments": null,
                                "args": [
                                    "self",
                                    "name"
                                ]
                            },
                            {
                                "name": "transformers",
                                "docstring": "Get the transformers provided by this plugin.\n\nReturns:\n    A dictionary mapping transformer names to factory functions",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "initialize",
                                "docstring": "Called when the plugin is loaded.\n\nOverride this method to perform any setup required by the plugin.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "cleanup",
                                "docstring": "Called when the plugin is unloaded.\n\nOverride this method to perform any cleanup required by the plugin.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "PluginRegistry",
                        "docstring": "Registry for managing transformer plugins.\n\nThe registry maintains the collection of loaded plugins and their\ntransformers, handling registration, unregistration, and access to\ntransformer factories.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize an empty plugin registry.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "register",
                                "docstring": "Register a plugin with the registry.\n\nArgs:\n    plugin: The plugin to register\n    \nRaises:\n    ValueError: If a plugin with the same name is already registered",
                                "comments": null,
                                "args": [
                                    "self",
                                    "plugin"
                                ]
                            },
                            {
                                "name": "unregister",
                                "docstring": "Unregister a plugin from the registry.\n\nArgs:\n    name: Name of the plugin to unregister",
                                "comments": null,
                                "args": [
                                    "self",
                                    "name"
                                ]
                            },
                            {
                                "name": "get_transformer",
                                "docstring": "Get a transformer factory by name.\n\nArgs:\n    name: Name of the transformer\n    \nReturns:\n    The transformer factory function, or None if not found",
                                "comments": null,
                                "args": [
                                    "self",
                                    "name"
                                ]
                            },
                            {
                                "name": "get_plugin",
                                "docstring": "Get a plugin by name.\n\nArgs:\n    name: Name of the plugin\n    \nReturns:\n    The plugin instance, or None if not found",
                                "comments": null,
                                "args": [
                                    "self",
                                    "name"
                                ]
                            },
                            {
                                "name": "plugins",
                                "docstring": "Get all registered plugins.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "transformers",
                                "docstring": "Get all registered transformers.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tukuy/plugins/text/__init__.py",
                "functions": [],
                "classes": [
                    {
                        "name": "TextTransformersPlugin",
                        "docstring": "Plugin providing text transformation capabilities.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the text transformers plugin.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "transformers",
                                "docstring": "Get the text transformers.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "initialize",
                                "docstring": "Initialize the text transformers plugin.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "cleanup",
                                "docstring": "Clean up the text transformers plugin.",
                                "comments": "Could add loading of text patterns or dictionaries here",
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tukuy/plugins/example/__init__.py",
                "functions": [],
                "classes": [
                    {
                        "name": "ReverseTransformer",
                        "docstring": "Example transformer that reverses text.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "CountWordsTransformer",
                        "docstring": "Example transformer that counts words in text.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "FindPatternTransformer",
                        "docstring": "Example transformer that finds all occurrences of a pattern.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "pattern"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "ExamplePlugin",
                        "docstring": "Example plugin demonstrating plugin creation.\n\nThis plugin provides simple text manipulation transformers as an example\nof how to create custom plugins. Use this as a template for creating\nyour own plugins.\n\nExample usage:\n    ```python\n    from tukuy import TukuyTransformer\n    from tukuy.plugins.example import ExamplePlugin\n    \n    # Create transformer\n    TUKUY = TukuyTransformer()\n    \n    # Register plugin\n    TUKUY.register_plugin(ExamplePlugin())\n    \n    # Use transformers\n    text = \"Hello World\"\n    \n    # Reverse text\n    reversed_text = TUKUY.transform(text, [\"reverse\"])  # \"dlroW olleH\"\n    \n    # Count words\n    word_count = TUKUY.transform(text, [\"count_words\"])  # 2\n    \n    # Find patterns\n    patterns = TUKUY.transform(text, [{\n        \"function\": \"find_pattern\",\n        \"pattern\": r\"\\w+\"\n    }])  # [\"Hello\", \"World\"]\n    ```",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the example plugin.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "transformers",
                                "docstring": "Get the example transformers.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "initialize",
                                "docstring": "Initialize the example plugin.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "cleanup",
                                "docstring": "Clean up the example plugin.",
                                "comments": "Add any setup code here",
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tukuy/plugins/html/__init__.py",
                "functions": [],
                "classes": [
                    {
                        "name": "UrlJoinTransformer",
                        "docstring": "Joins URLs using urllib.parse.urljoin.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "base_url"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "ExtractDomainTransformer",
                        "docstring": "Extracts domain from URL.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "HtmlTransformersPlugin",
                        "docstring": "Plugin providing HTML transformation capabilities.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the HTML transformers plugin.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "transformers",
                                "docstring": "Get the HTML transformers.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tukuy/plugins/json/__init__.py",
                "functions": [],
                "classes": [
                    {
                        "name": "JsonTransformersPlugin",
                        "docstring": "Plugin providing JSON transformation capabilities.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the JSON transformers plugin.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "transformers",
                                "docstring": "Get the JSON transformers.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "initialize",
                                "docstring": "Initialize the JSON transformers plugin.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "cleanup",
                                "docstring": "Clean up the JSON transformers plugin.",
                                "comments": "Could add loading of JSON schemas or validation rules here",
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tukuy/plugins/numerical/__init__.py",
                "functions": [],
                "classes": [
                    {
                        "name": "ExtractNumbersTransformer",
                        "docstring": "Extracts all numbers from text.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_transform",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "context"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "NumericalTransformersPlugin",
                        "docstring": "Plugin providing numerical transformation capabilities.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the numerical transformers plugin.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "transformers",
                                "docstring": "Get the numerical transformers.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "initialize",
                                "docstring": "Initialize the numerical transformers plugin.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "cleanup",
                                "docstring": "Clean up the numerical transformers plugin.",
                                "comments": "Could add loading of currency rates or unit conversion data here",
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tukuy/plugins/validation/__init__.py",
                "functions": [],
                "classes": [
                    {
                        "name": "ValidationTransformersPlugin",
                        "docstring": "Plugin providing validation transformation capabilities.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the validation transformers plugin.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "transformers",
                                "docstring": "Get the validation transformers.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "initialize",
                                "docstring": "Initialize the validation transformers plugin.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "cleanup",
                                "docstring": "Clean up the validation transformers plugin.",
                                "comments": "Could add loading of validation rules or patterns here",
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tukuy/plugins/date/__init__.py",
                "functions": [],
                "classes": [
                    {
                        "name": "DateTransformersPlugin",
                        "docstring": "Plugin providing date transformation capabilities.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the date transformers plugin.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "transformers",
                                "docstring": "Get the date transformers.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "initialize",
                                "docstring": "Initialize the date transformers plugin.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "cleanup",
                                "docstring": "Clean up the date transformers plugin.",
                                "comments": "Could add loading of timezone data or date formats here",
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            }
        ],
        "test_cases": {
            "tests/test_html_transforms.py::test_strip_html_tags": {
                "testid": "tests/test_html_transforms.py::test_strip_html_tags",
                "result": "passed",
                "test_implementation": "def test_strip_html_tags(transformer):\n    # Test basic HTML stripping\n    html = \"<p>Hello <b>World</b>!</p>\"\n    assert transformer.transform(html, [\"strip_html_tags\"]) == \"Hello World!\"\n    \n    # Test nested HTML\n    html = \"<div>Hello <span>Beautiful <strong>World</strong></span>!</div>\"\n    assert transformer.transform(html, [\"strip_html_tags\"]) == \"Hello Beautiful World!\""
            },
            "tests/test_html_transforms.py::test_html_sanitization": {
                "testid": "tests/test_html_transforms.py::test_html_sanitization",
                "result": "passed",
                "test_implementation": "def test_html_sanitization(transformer):\n    # Test removing script tags\n    html = \"\"\"\n    <div>Hello World</div>\n    <script>alert('dangerous');</script>\n    <p>Safe content</p>\n    \"\"\"\n    result = transformer.transform(html, [\"html_sanitize\"])\n    assert \"<script>\" not in result\n    assert \"Hello World\" in result\n    assert \"Safe content\" in result"
            },
            "tests/test_html_transforms.py::test_link_extraction": {
                "testid": "tests/test_html_transforms.py::test_link_extraction",
                "result": "passed",
                "test_implementation": "def test_link_extraction(transformer):\n    # Test extracting links from HTML\n    html = \"\"\"\n    <div>\n        <a href=\"https://example.com\">Example</a>\n        <p>Some text</p>\n        <a href=\"/relative/path\">Relative</a>\n    </div>\n    \"\"\"\n    links = transformer.transform(html, [\"link_extraction\"])\n    assert len(links) == 2\n    assert \"https://example.com\" in links\n    assert \"/relative/path\" in links"
            },
            "tests/test_html_transforms.py::test_url_transforms": {
                "testid": "tests/test_html_transforms.py::test_url_transforms",
                "result": "passed",
                "test_implementation": "def test_url_transforms(transformer):\n    # Test URL resolution\n    relative_url = \"/path/to/resource\"\n    base_url = \"https://example.com\"\n    result = transformer.transform(relative_url, [{\n        \"function\": \"resolve_url\",\n        \"base_url\": base_url\n    }])\n    assert result == \"https://example.com/path/to/resource\"\n\n    # Test domain extraction\n    url = \"https://example.com/path?query=123\"\n    domain = transformer.transform(url, [\"extract_domain\"])\n    assert domain == \"example.com\""
            },
            "tests/test_html_transforms.py::test_html_and_text_combination": {
                "testid": "tests/test_html_transforms.py::test_html_and_text_combination",
                "result": "passed",
                "test_implementation": "def test_html_and_text_combination(transformer):\n    # Test combination of HTML stripping and text transformation\n    html = \"<div>HELLO <b>WORLD</b>!</div>\"\n    result = transformer.transform(html, [\n        \"strip_html_tags\",\n        \"lowercase\",\n        {\"function\": \"truncate\", \"length\": 8}\n    ])\n    assert result == \"hello wo...\""
            },
            "tests/test_html_transforms.py::test_complex_product_extraction": {
                "testid": "tests/test_html_transforms.py::test_complex_product_extraction",
                "result": "passed",
                "test_implementation": "def test_complex_product_extraction(transformer):\n    # Complex pattern for product extraction\n    COMPLEX_HTML = \"\"\"\n    <div class=\"product-container\">\n        <span class=\"model-code\">Model ABC-123 Rev.2</span>\n        <div class=\"tech-specs\">\n            <table>\n                <tr><td>CPU</td><td>Intel i9-13900K</td></tr>\n                <tr><td>Memory</td><td>64GB DDR5</td></tr>\n            </table>\n        </div>\n        <div class=\"downloads\">\n            <a href=\"/files/manual.pdf\" data-filetype=\"PDF\" data-size=\"2.5 MB\">Manual</a>\n            <a href=\"/files/drivers.zip\" data-filetype=\"ZIP\" data-size=\"1.2 GB\">Drivers</a>\n        </div>\n        <div class=\"variants\">\n            <div class=\"product-variant\">\n                <span data-sku=\"VAR-001\"></span>\n                <span class=\"original-price\">$1,299.99</span>\n                <span class=\"discount-tag\">20% OFF</span>\n                <span class=\"stock-status\" data-stock-level=\"1\">Low Stock</span>\n            </div>\n            <div class=\"product-variant\">\n                <span data-sku=\"VAR-002\"></span>\n                <span class=\"original-price\">$1,499.99</span>\n                <span class=\"discount-tag\">15% OFF</span>\n                <span class=\"stock-status\" data-stock-level=\"2\">In Stock</span>\n            </div>\n        </div>\n    </div>\n    \"\"\"\n    \n    # Test model info extraction\n    model_info = transformer.transform(COMPLEX_HTML, [\n        {\"function\": \"html_sanitize\"},\n        {\n            \"function\": \"regex\",\n            \"pattern\": r\"Model\\s*(\\w+)-(\\d+)\\s*Rev\\.(\\d+)\",\n            \"template\": \"Series: {1}, Number: {2}, Revision: {3}\"\n        }\n    ])\n    assert model_info == \"Series: ABC, Number: 123, Revision: 2\"\n    \n    # Test tech specs extraction\n    soup = BeautifulSoup(COMPLEX_HTML, 'html.parser')\n    specs_rows = soup.select(\".tech-specs table tr\")\n    specs = {}\n    for row in specs_rows:\n        label = transformer.transform(row.select_one(\"td:first-child\").text, [\"strip\"])\n        value = transformer.transform(row.select_one(\"td:last-child\").text, [\"strip\"])\n        specs[label] = value\n    \n    assert specs == {\n        \"CPU\": \"Intel i9-13900K\",\n        \"Memory\": \"64GB DDR5\"\n    }\n    \n    # Test download links extraction\n    download_links = soup.select(\".downloads a\")\n    downloads = []\n    for link in download_links:\n        downloads.append({\n            \"url\": link[\"href\"],\n            \"type\": transformer.transform(link[\"data-filetype\"], [\"lowercase\"]),\n            \"size\": transformer.transform(\n                link[\"data-size\"],\n                [{\n                    \"function\": \"regex\",\n                    \"pattern\": r\"(\\d+(?:\\.\\d+)?)\\s*(MB|GB|KB)\",\n                    \"template\": \"{1} {2}\"\n                }]\n            )\n        })\n    \n    assert downloads == [\n        {\"url\": \"/files/manual.pdf\", \"type\": \"pdf\", \"size\": \"2.5 MB\"},\n        {\"url\": \"/files/drivers.zip\", \"type\": \"zip\", \"size\": \"1.2 GB\"}\n    ]"
            },
            "tests/test_html_transforms.py::test_complex_pattern_extraction": {
                "testid": "tests/test_html_transforms.py::test_complex_pattern_extraction",
                "result": "passed",
                "test_implementation": "def test_complex_pattern_extraction(transformer):\n    COMPLEX_PATTERN = {\n        \"name\": \"complex_product\",\n        \"url\": \"/products/details/\",\n        \"properties\": [\n            {\n                \"name\": \"model_info\",\n                \"selector\": {\n                    \"primary\": \".model-code\",\n                    \"fallback\": [\".product-code\", \"#item-code\", \"[data-type='model']\"]\n                },\n                \"attribute\": \"text\",\n                \"transform\": [\n                    {\"function\": \"regex\", \"pattern\": r\"Model\\s*(\\w+)-(\\d+)\\s*Rev\\.(\\d+)\"},\n                    {\"function\": \"template\", \"template\": \"Series: {1}, Number: {2}, Revision: {3}\"}\n                ],\n                \"type\": \"string\"\n            },\n            {\n                \"name\": \"technical_specs\",\n                \"selector\": {\n                    \"primary\": \".tech-specs table tr\",\n                    \"fallback\": [\".specifications table tr\", \"#specs-table tr\"]\n                },\n                \"type\": \"object\",\n                \"properties\": [\n                    {\n                        \"name\": \"label\",\n                        \"selector\": {\"primary\": \"td:first-child\"},\n                        \"attribute\": \"text\",\n                        \"transform\": [{\"function\": \"strip\"}]\n                    },\n                    {\n                        \"name\": \"value\",\n                        \"selector\": {\"primary\": \"td:last-child\"},\n                        \"attribute\": \"text\",\n                        \"transform\": [{\"function\": \"strip\"}]\n                    }\n                ]\n            },\n            {\n                \"name\": \"download_links\",\n                \"selector\": {\n                    \"primary\": \".downloads a\",\n                    \"fallback\": [\".resources a\"]\n                },\n                \"type\": \"array\",\n                \"properties\": [\n                    {\n                        \"name\": \"url\",\n                        \"attribute\": \"href\"\n                    },\n                    {\n                        \"name\": \"type\",\n                        \"attribute\": \"data-filetype\",\n                        \"transform\": [{\"function\": \"lowercase\"}]\n                    },\n                    {\n                        \"name\": \"size\",\n                        \"attribute\": \"data-size\",\n                        \"transform\": [\n                            {\"function\": \"regex\", \"pattern\": r\"(\\d+(?:\\.\\d+)?)\\s*(MB|GB|KB)\", \"template\": \"{1} {2}\"}\n                        ]\n                    }\n                ]\n            }\n        ]\n    }\n\n    COMPLEX_HTML = \"\"\"\n    <div class=\"product-container\">\n        <span class=\"model-code\">Model ABC-123 Rev.2</span>\n        <div class=\"tech-specs\">\n            <table>\n                <tr><td>CPU</td><td>Intel i9-13900K</td></tr>\n                <tr><td>Memory</td><td>64GB DDR5</td></tr>\n            </table>\n        </div>\n        <div class=\"downloads\">\n            <a href=\"/files/manual.pdf\" data-filetype=\"PDF\" data-size=\"2.5 MB\">Manual</a>\n            <a href=\"/files/drivers.zip\" data-filetype=\"ZIP\" data-size=\"1.2 GB\">Drivers</a>\n        </div>\n        <div class=\"variants\">\n            <div class=\"product-variant\">\n                <span data-sku=\"VAR-001\"></span>\n                <span class=\"original-price\">$1,299.99</span>\n                <span class=\"discount-tag\">20% OFF</span>\n                <span class=\"stock-status\" data-stock-level=\"1\">Low Stock</span>\n            </div>\n            <div class=\"product-variant\">\n                <span data-sku=\"VAR-002\"></span>\n                <span class=\"original-price\">$1,499.99</span>\n                <span class=\"discount-tag\">15% OFF</span>\n                <span class=\"stock-status\" data-stock-level=\"2\">In Stock</span>\n            </div>\n        </div>\n    </div>\n    \"\"\"\n\n    # Extract data using the pattern\n    result = transformer.extract_html_with_pattern(COMPLEX_HTML, COMPLEX_PATTERN)\n\n    # Verify extracted data\n    assert result[\"model_info\"] == \"Series: ABC, Number: 123, Revision: 2\"\n    \n    assert result[\"technical_specs\"] == [\n        {\"label\": \"CPU\", \"value\": \"Intel i9-13900K\"},\n        {\"label\": \"Memory\", \"value\": \"64GB DDR5\"}\n    ]\n    \n    assert result[\"download_links\"] == [\n        {\"url\": \"/files/manual.pdf\", \"type\": \"pdf\", \"size\": \"2.5 MB\"},\n        {\"url\": \"/files/drivers.zip\", \"type\": \"zip\", \"size\": \"1.2 GB\"}\n    ]"
            },
            "tests/test_html_transforms.py::test_extract_property_from_html": {
                "testid": "tests/test_html_transforms.py::test_extract_property_from_html",
                "result": "passed",
                "test_implementation": "def test_extract_property_from_html(transformer):\n    # Test basic property extraction\n    html = \"\"\"\n    <div class=\"container\">\n        <h1 class=\"title\">Welcome</h1>\n        <p class=\"description\">This is a <b>test</b> description.</p>\n        <ul class=\"links\">\n            <li><a href=\"link1.html\">Link 1</a></li>\n            <li><a href=\"link2.html\">Link 2</a></li>\n        </ul>\n    </div>\n    \"\"\"\n\n    # Test simple text extraction\n    result = transformer.extract_property_from_html(html, {\n        \"name\": \"title\",\n        \"selector\": \"h1\",\n        \"transform\": [\"strip\"]\n    })\n    assert result == \"Welcome\"\n\n    # Test with HTML stripping\n    result = transformer.extract_property_from_html(html, {\n        \"name\": \"description\",\n        \"selector\": \"p.description\",\n        \"transform\": [\"strip_html_tags\", \"strip\"]\n    })\n    assert result == \"This is a test description.\"\n\n    # Test array extraction\n    result = transformer.extract_property_from_html(html, {\n        \"name\": \"links\",\n        \"selector\": \"a\",\n        \"attribute\": \"href\",\n        \"type\": \"array\"\n    })\n    assert result == [\"link1.html\", \"link2.html\"]\n\n    # Test with fallback\n    result = transformer.extract_property_from_html(html, {\n        \"name\": \"subtitle\",\n        \"selector\": {\n            \"primary\": \"h2.subtitle\",\n            \"fallback\": [\"h1.title\"]\n        },\n        \"transform\": [\"strip\"]\n    })\n    assert result == \"Welcome\"\n\n    # Test missing property\n    result = transformer.extract_property_from_html(html, {\n        \"name\": \"missing\",\n        \"selector\": \"nonexistent\"\n    })\n    assert result is None"
            },
            "tests/test_json_transforms.py::test_json_parser_basic": {
                "testid": "tests/test_json_transforms.py::test_json_parser_basic",
                "result": "passed",
                "test_implementation": "def test_json_parser_basic(transformer):\n    # Test basic JSON parsing\n    json_str = '{\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}'\n    result = transformer.transform(json_str, [\"json_parse\"])\n    assert isinstance(result, dict)\n    assert result[\"name\"] == \"John\"\n    assert result[\"age\"] == 30\n    assert result[\"city\"] == \"New York\"\n    \n    # Test parsing JSON array\n    json_array = '[1, 2, 3, 4, 5]'\n    result = transformer.transform(json_array, [\"json_parse\"])\n    assert isinstance(result, list)\n    assert len(result) == 5\n    assert result[0] == 1\n    assert result[4] == 5"
            },
            "tests/test_json_transforms.py::test_json_parser_invalid": {
                "testid": "tests/test_json_transforms.py::test_json_parser_invalid",
                "result": "passed",
                "test_implementation": "def test_json_parser_invalid(transformer):\n    # Test invalid JSON with strict mode (default)\n    invalid_json = '{\"name\": \"John\", \"age\": 30, \"city\": \"New York\"'  # Missing closing brace\n    with pytest.raises(ParseError):\n        transformer.transform(invalid_json, [\"json_parse\"])\n    \n    # Test invalid JSON with lenient mode\n    result = transformer.transform(invalid_json, [{\n        \"function\": \"json_parse\",\n        \"strict\": False\n    }])\n    assert result == invalid_json  # Should return original string in lenient mode"
            },
            "tests/test_json_transforms.py::test_json_parser_schema_validation": {
                "testid": "tests/test_json_transforms.py::test_json_parser_schema_validation",
                "result": "passed",
                "test_implementation": "def test_json_parser_schema_validation(transformer):\n    # Test schema validation - valid\n    json_str = '{\"name\": \"John\", \"age\": 30}'\n    schema = {\n        \"type\": \"object\",\n        \"properties\": {\n            \"name\": {\"type\": \"string\"},\n            \"age\": {\"type\": \"number\"}\n        }\n    }\n    \n    result = transformer.transform(json_str, [{\n        \"function\": \"json_parse\",\n        \"schema\": schema\n    }])\n    assert result[\"name\"] == \"John\"\n    assert result[\"age\"] == 30\n    \n    # Test schema validation - invalid\n    json_str = '{\"name\": \"John\", \"age\": \"thirty\"}'  # Age should be a number\n    with pytest.raises(ValidationError):\n        transformer.transform(json_str, [{\n            \"function\": \"json_parse\",\n            \"schema\": schema\n        }])"
            },
            "tests/test_json_transforms.py::test_json_extractor_simple": {
                "testid": "tests/test_json_transforms.py::test_json_extractor_simple",
                "result": "passed",
                "test_implementation": "def test_json_extractor_simple(transformer):\n    # Test simple property extraction\n    json_str = '{\"user\": {\"name\": \"John\", \"email\": \"john@example.com\"}, \"status\": \"active\"}'\n    parsed = json.loads(json_str)\n    \n    # Extract user name\n    result = transformer.transform(parsed, [{\n        \"function\": \"json_extract\",\n        \"pattern\": {\n            \"properties\": [\n                {\n                    \"name\": \"username\",\n                    \"selector\": \"user.name\"\n                }\n            ]\n        }\n    }])\n    \n    assert result[\"username\"] == \"John\"\n    \n    # Extract status\n    result = transformer.transform(parsed, [{\n        \"function\": \"json_extract\",\n        \"pattern\": {\n            \"properties\": [\n                {\n                    \"name\": \"account_status\",\n                    \"selector\": \"status\"\n                }\n            ]\n        }\n    }])\n    \n    assert result[\"account_status\"] == \"active\""
            },
            "tests/test_json_transforms.py::test_json_extractor_nested": {
                "testid": "tests/test_json_transforms.py::test_json_extractor_nested",
                "result": "passed",
                "test_implementation": "def test_json_extractor_nested(transformer):\n    # Test nested property extraction\n    json_str = '''\n    {\n        \"user\": {\n            \"profile\": {\n                \"personal\": {\n                    \"name\": \"John Doe\",\n                    \"age\": 30,\n                    \"contact\": {\n                        \"email\": \"john@example.com\",\n                        \"phone\": \"555-1234\"\n                    }\n                },\n                \"preferences\": {\n                    \"theme\": \"dark\",\n                    \"notifications\": true\n                }\n            },\n            \"account\": {\n                \"id\": \"user123\",\n                \"type\": \"premium\"\n            }\n        }\n    }\n    '''\n    parsed = json.loads(json_str)\n    \n    # Extract deeply nested properties\n    result = transformer.transform(parsed, [{\n        \"function\": \"json_extract\",\n        \"pattern\": {\n            \"properties\": [\n                {\n                    \"name\": \"email\",\n                    \"selector\": \"user.profile.personal.contact.email\"\n                },\n                {\n                    \"name\": \"theme\",\n                    \"selector\": \"user.profile.preferences.theme\"\n                },\n                {\n                    \"name\": \"account_type\",\n                    \"selector\": \"user.account.type\"\n                }\n            ]\n        }\n    }])\n    \n    assert result[\"email\"] == \"john@example.com\"\n    assert result[\"theme\"] == \"dark\"\n    assert result[\"account_type\"] == \"premium\""
            },
            "tests/test_json_transforms.py::test_json_extractor_array": {
                "testid": "tests/test_json_transforms.py::test_json_extractor_array",
                "result": "passed",
                "test_implementation": "def test_json_extractor_array(transformer):\n    # Test array extraction\n    json_str = '''\n    {\n        \"products\": [\n            {\"id\": \"p1\", \"name\": \"Laptop\", \"price\": 999.99},\n            {\"id\": \"p2\", \"name\": \"Phone\", \"price\": 699.99},\n            {\"id\": \"p3\", \"name\": \"Tablet\", \"price\": 499.99}\n        ],\n        \"categories\": [\"Electronics\", \"Computers\", \"Mobile\"]\n    }\n    '''\n    parsed = json.loads(json_str)\n    \n    # Extract array of product names\n    result = transformer.transform(parsed, [{\n        \"function\": \"json_extract\",\n        \"pattern\": {\n            \"properties\": [\n                {\n                    \"name\": \"product_names\",\n                    \"selector\": \"products[*].name\",\n                    \"type\": \"array\"\n                }\n            ]\n        }\n    }])\n    \n    assert result[\"product_names\"] == [\"Laptop\", \"Phone\", \"Tablet\"]\n    \n    # Extract categories\n    result = transformer.transform(parsed, [{\n        \"function\": \"json_extract\",\n        \"pattern\": {\n            \"properties\": [\n                {\n                    \"name\": \"all_categories\",\n                    \"selector\": \"categories\",\n                    \"type\": \"array\"\n                }\n            ]\n        }\n    }])\n    \n    assert result[\"all_categories\"] == [\"Electronics\", \"Computers\", \"Mobile\"]"
            },
            "tests/test_json_transforms.py::test_json_extractor_fallback": {
                "testid": "tests/test_json_transforms.py::test_json_extractor_fallback",
                "result": "passed",
                "test_implementation": "def test_json_extractor_fallback(transformer):\n    # Test extraction with fallbacks\n    json_str = '''\n    {\n        \"data\": {\n            \"main_image\": \"image1.jpg\"\n        },\n        \"backup\": {\n            \"image\": \"backup.jpg\"\n        }\n    }\n    '''\n    parsed = json.loads(json_str)\n    \n    # Test with primary selector that exists\n    result = transformer.transform(parsed, [{\n        \"function\": \"json_extract\",\n        \"pattern\": {\n            \"properties\": [\n                {\n                    \"name\": \"image\",\n                    \"selector\": {\n                        \"primary\": \"data.main_image\",\n                        \"fallback\": [\"backup.image\", \"default.image\"]\n                    }\n                }\n            ]\n        }\n    }])\n    \n    assert result[\"image\"] == \"image1.jpg\"\n    \n    # Test with missing primary, using fallback\n    json_str = '''\n    {\n        \"data\": {},\n        \"backup\": {\n            \"image\": \"backup.jpg\"\n        }\n    }\n    '''\n    parsed = json.loads(json_str)\n    \n    result = transformer.transform(parsed, [{\n        \"function\": \"json_extract\",\n        \"pattern\": {\n            \"properties\": [\n                {\n                    \"name\": \"image\",\n                    \"selector\": {\n                        \"primary\": \"data.main_image\",\n                        \"fallback\": [\"backup.image\", \"default.image\"]\n                    }\n                }\n            ]\n        }\n    }])\n    \n    assert result[\"image\"] == \"backup.jpg\""
            },
            "tests/test_json_transforms.py::test_complex_json_pattern": {
                "testid": "tests/test_json_transforms.py::test_complex_json_pattern",
                "result": "passed",
                "test_implementation": "def test_complex_json_pattern(transformer):\n    # Test complex JSON pattern extraction\n    COMPLEX_JSON = '''\n    {\n        \"product\": {\n            \"id\": \"prod-123\",\n            \"name\": \"Smart TV X3000\",\n            \"model\": \"TV-X3000-2023\",\n            \"specs\": {\n                \"display\": \"4K OLED\",\n                \"size\": \"55 inch\",\n                \"connectivity\": [\"HDMI\", \"USB\", \"Bluetooth\", \"WiFi\"],\n                \"features\": [\"Smart Assistant\", \"HDR\", \"Dolby Vision\"]\n            },\n            \"pricing\": {\n                \"msrp\": 1299.99,\n                \"sale\": 999.99,\n                \"discount\": \"23%\"\n            },\n            \"inventory\": {\n                \"status\": \"in_stock\",\n                \"quantity\": 42,\n                \"warehouses\": [\n                    {\"id\": \"w1\", \"stock\": 15},\n                    {\"id\": \"w2\", \"stock\": 27}\n                ]\n            },\n            \"reviews\": [\n                {\"user\": \"user1\", \"rating\": 5, \"comment\": \"Excellent TV!\"},\n                {\"user\": \"user2\", \"rating\": 4, \"comment\": \"Good but expensive\"},\n                {\"user\": \"user3\", \"rating\": 5, \"comment\": \"Amazing picture quality\"}\n            ]\n        }\n    }\n    '''\n    \n    COMPLEX_PATTERN = {\n        \"properties\": [\n            {\n                \"name\": \"product_info\",\n                \"selector\": \"product\",\n                \"type\": \"object\",\n                \"properties\": [\n                    {\n                        \"name\": \"id\",\n                        \"selector\": \"id\"\n                    },\n                    {\n                        \"name\": \"name\",\n                        \"selector\": \"name\"\n                    },\n                    {\n                        \"name\": \"model_number\",\n                        \"selector\": \"model\",\n                        \"transform\": [\n                            {\"function\": \"regex\", \"pattern\": r\"TV-(.+)-\\d+\", \"template\": \"{1}\"}\n                        ]\n                    }\n                ]\n            },\n            {\n                \"name\": \"technical_specs\",\n                \"selector\": \"product.specs\",\n                \"type\": \"object\"\n            },\n            {\n                \"name\": \"price_info\",\n                \"selector\": \"product.pricing\",\n                \"type\": \"object\",\n                \"properties\": [\n                    {\n                        \"name\": \"current_price\",\n                        \"selector\": \"sale\"\n                    },\n                    {\n                        \"name\": \"savings\",\n                        \"selector\": {\n                            \"primary\": \"discount\"\n                        },\n                        \"transform\": [\n                            {\"function\": \"regex\", \"pattern\": r\"(\\d+)%\", \"template\": \"{1}\"}\n                        ]\n                    }\n                ]\n            },\n            {\n                \"name\": \"stock_info\",\n                \"selector\": \"product.inventory\",\n                \"type\": \"object\",\n                \"properties\": [\n                    {\n                        \"name\": \"availability\",\n                        \"selector\": \"status\",\n                        \"transform\": [\n                            {\"function\": \"replace\", \"find\": \"in_stock\", \"replace\": \"Available\"}\n                        ]\n                    },\n                    {\n                        \"name\": \"total_stock\",\n                        \"selector\": \"quantity\"\n                    }\n                ]\n            },\n            {\n                \"name\": \"warehouse_stock\",\n                \"selector\": \"product.inventory.warehouses\",\n                \"type\": \"array\"\n            },\n            {\n                \"name\": \"review_ratings\",\n                \"selector\": \"product.reviews[*].rating\",\n                \"type\": \"array\"\n            },\n            {\n                \"name\": \"average_rating\",\n                \"selector\": \"product.reviews[*].rating\",\n                \"transform\": [\n                    {\"function\": \"average\"}\n                ]\n            }\n        ]\n    }\n    \n    # Extract data using the pattern\n    result = transformer.extract_json_with_pattern(COMPLEX_JSON, COMPLEX_PATTERN)\n    \n    # Verify extracted data\n    assert result[\"product_info\"][\"id\"] == \"prod-123\"\n    assert result[\"product_info\"][\"name\"] == \"Smart TV X3000\"\n    assert result[\"product_info\"][\"model_number\"] == \"X3000\"\n    \n    assert result[\"technical_specs\"][\"display\"] == \"4K OLED\"\n    assert result[\"technical_specs\"][\"size\"] == \"55 inch\"\n    assert len(result[\"technical_specs\"][\"connectivity\"]) == 4\n    assert len(result[\"technical_specs\"][\"features\"]) == 3\n    \n    assert result[\"price_info\"][\"current_price\"] == 999.99\n    assert result[\"price_info\"][\"savings\"] == \"23\"\n    \n    assert result[\"stock_info\"][\"availability\"] == \"Available\"\n    assert result[\"stock_info\"][\"total_stock\"] == 42\n    \n    assert len(result[\"warehouse_stock\"]) == 2\n    assert result[\"warehouse_stock\"][0][\"id\"] == \"w1\"\n    assert result[\"warehouse_stock\"][1][\"stock\"] == 27\n    \n    assert result[\"review_ratings\"] == [5, 4, 5]\n    assert result[\"average_rating\"] == 4.67  # Average of [5, 4, 5]"
            },
            "tests/test_json_transforms.py::test_extract_property_from_json": {
                "testid": "tests/test_json_transforms.py::test_extract_property_from_json",
                "result": "passed",
                "test_implementation": "def test_extract_property_from_json(transformer):\n    # Test simple property extraction from JSON string\n    json_str = '{\"user\": {\"name\": \"John\", \"email\": \"john@example.com\"}, \"status\": \"active\"}'\n    \n    # Extract user name\n    result = transformer.extract_property_from_json(json_str, {\n        \"name\": \"username\",\n        \"selector\": \"user.name\"\n    })\n    assert result == \"John\"\n\n    # Test extraction from already parsed JSON\n    parsed = json.loads(json_str)\n    result = transformer.extract_property_from_json(parsed, {\n        \"name\": \"status\",\n        \"selector\": \"status\"\n    })\n    assert result == \"active\"\n\n    # Test nested property with transform\n    complex_json = '''\n    {\n        \"product\": {\n            \"pricing\": {\n                \"sale\": 999.99,\n                \"discount\": \"20% OFF\"\n            }\n        }\n    }\n    '''\n    result = transformer.extract_property_from_json(complex_json, {\n        \"name\": \"savings\",\n        \"selector\": \"product.pricing.discount\",\n        \"transform\": [\n            {\"function\": \"regex\", \"pattern\": r\"(\\d+)%\", \"template\": \"{1}\"}\n        ]\n    })\n    assert result == \"20\"\n\n    # Test array extraction\n    array_json = '''\n    {\n        \"products\": [\n            {\"name\": \"Laptop\"},\n            {\"name\": \"Phone\"},\n            {\"name\": \"Tablet\"}\n        ]\n    }\n    '''\n    result = transformer.extract_property_from_json(array_json, {\n        \"name\": \"names\",\n        \"selector\": \"products[*].name\",\n        \"type\": \"array\"\n    })\n    assert result == [\"Laptop\", \"Phone\", \"Tablet\"]\n\n    # Test with fallback\n    fallback_json = '''\n    {\n        \"data\": {},\n        \"backup\": {\n            \"image\": \"backup.jpg\"\n        }\n    }\n    '''\n    result = transformer.extract_property_from_json(fallback_json, {\n        \"name\": \"image\",\n        \"selector\": {\n            \"primary\": \"data.main_image\",\n            \"fallback\": [\"backup.image\"]\n        }\n    })\n    assert result == \"backup.jpg\""
            },
            "tests/test_json_transforms.py::test_extract_property_from_json_errors": {
                "testid": "tests/test_json_transforms.py::test_extract_property_from_json_errors",
                "result": "passed",
                "test_implementation": "def test_extract_property_from_json_errors(transformer):\n    # Test invalid JSON string\n    with pytest.raises(ParseError):\n        transformer.extract_property_from_json('{\"name\": \"John\"', {\n            \"name\": \"username\",\n            \"selector\": \"name\"\n        })\n\n    # Test missing property\n    json_str = '{\"user\": {\"name\": \"John\"}}'\n    result = transformer.extract_property_from_json(json_str, {\n        \"name\": \"email\",\n        \"selector\": \"user.email\"\n    })\n    assert result is None\n\n    # Test invalid selector\n    with pytest.raises(TransformationError):\n        transformer.extract_property_from_json(json_str, {\n            \"name\": \"invalid\",\n            \"selector\": None\n        })"
            },
            "tests/test_numerical_and_date_transforms.py::test_numerical_transforms": {
                "testid": "tests/test_numerical_and_date_transforms.py::test_numerical_transforms",
                "result": "passed",
                "test_implementation": "def test_numerical_transforms(transformer):\n    # Test rounding\n    assert transformer.transform(123.456, [{\"function\": \"round\", \"decimals\": 2}]) == 123.46\n    \n    # Test currency conversion\n    assert transformer.transform(100, [{\"function\": \"currency_convert\", \"rate\": 0.85}]) == 85.0\n    \n    # Test unit conversion\n    assert transformer.transform(10, [{\"function\": \"unit_convert\", \"rate\": 2.54}]) == 25.4\n    \n    # Test percentage calculation\n    assert transformer.transform(0.75, [\"percentage_calc\"]) == 75.0"
            },
            "tests/test_numerical_and_date_transforms.py::test_math_operations": {
                "testid": "tests/test_numerical_and_date_transforms.py::test_math_operations",
                "result": "passed",
                "test_implementation": "def test_math_operations(transformer):\n    # Test basic math operations\n    value = 10\n    \n    # Addition\n    assert transformer.transform(value, [{\"function\": \"math_operation\", \"operation\": \"add\", \"operand\": 5}]) == 15\n    \n    # Subtraction\n    assert transformer.transform(value, [{\"function\": \"math_operation\", \"operation\": \"subtract\", \"operand\": 3}]) == 7\n    \n    # Multiplication\n    assert transformer.transform(value, [{\"function\": \"math_operation\", \"operation\": \"multiply\", \"operand\": 2}]) == 20\n    \n    # Division\n    assert transformer.transform(value, [{\"function\": \"math_operation\", \"operation\": \"divide\", \"operand\": 2}]) == 5"
            },
            "tests/test_numerical_and_date_transforms.py::test_date_transforms": {
                "testid": "tests/test_numerical_and_date_transforms.py::test_date_transforms",
                "result": "passed",
                "test_implementation": "def test_date_transforms(transformer):\n    # Test date parsing\n    date_str = \"2023-03-24\"\n    result = transformer.transform(date_str, [{\"function\": \"date\", \"format\": \"%Y-%m-%d\"}])\n    assert isinstance(result, datetime)\n    assert result.year == 2023\n    assert result.month == 3\n    assert result.day == 24"
            },
            "tests/test_numerical_and_date_transforms.py::test_age_calculation": {
                "testid": "tests/test_numerical_and_date_transforms.py::test_age_calculation",
                "result": "passed",
                "test_implementation": "def test_age_calculation(transformer):\n    # Test age calculation (note: this test might need adjustment based on current date)\n    birth_date = \"1990-01-01\"\n    age = transformer.transform(birth_date, [{\"function\": \"age_calc\", \"format\": \"%Y-%m-%d\"}])\n    assert isinstance(age, int)\n    assert age > 0"
            },
            "tests/test_numerical_and_date_transforms.py::test_duration_calculation": {
                "testid": "tests/test_numerical_and_date_transforms.py::test_duration_calculation",
                "result": "passed",
                "test_implementation": "def test_duration_calculation(transformer):\n    # Test duration between dates\n    start_date = \"2023-01-01\"\n    transforms = [{\n        \"function\": \"duration_calc\",\n        \"format\": \"%Y-%m-%d\",\n        \"end\": \"2023-02-01\"\n    }]\n    duration = transformer.transform(start_date, transforms)\n    assert duration == 31  # Days between Jan 1 and Feb 1"
            },
            "tests/test_numerical_and_date_transforms.py::test_number_extraction": {
                "testid": "tests/test_numerical_and_date_transforms.py::test_number_extraction",
                "result": "passed",
                "test_implementation": "def test_number_extraction(transformer):\n    # Test extracting numbers from text\n    text = \"The price is $123.45 and quantity is 42 units\"\n    numbers = transformer.transform(text, [\"extract_numbers\"])\n    assert \"123.45\" in numbers\n    assert \"42\" in numbers"
            },
            "tests/test_text_transforms.py::test_basic_text_transforms": {
                "testid": "tests/test_text_transforms.py::test_basic_text_transforms",
                "result": "passed",
                "test_implementation": "def test_basic_text_transforms(transformer):\n    # Test strip\n    assert transformer.transform(\" hello \", [\"strip\"]) == \"hello\"\n    \n    # Test lowercase\n    assert transformer.transform(\"HELLO\", [\"lowercase\"]) == \"hello\"\n    \n    # Test uppercase\n    assert transformer.transform(\"hello\", [\"uppercase\"]) == \"HELLO\"\n    \n    # Test title case\n    assert transformer.transform(\"hello world\", [\"title_case\"]) == \"Hello World\"\n    \n    # Test camel case\n    assert transformer.transform(\"hello world\", [\"camel_case\"]) == \"helloWorld\"\n    \n    # Test snake case\n    assert transformer.transform(\"Hello World\", [\"snake_case\"]) == \"hello_world\""
            },
            "tests/test_text_transforms.py::test_chained_text_transforms": {
                "testid": "tests/test_text_transforms.py::test_chained_text_transforms",
                "result": "passed",
                "test_implementation": "def test_chained_text_transforms(transformer):\n    # Test multiple transformations\n    text = \" HELLO WORLD! \"\n    result = transformer.transform(text, [\n        \"strip\",\n        \"lowercase\",\n        {\"function\": \"truncate\", \"length\": 5}\n    ])\n    assert result == \"hello...\""
            },
            "tests/test_text_transforms.py::test_slugify": {
                "testid": "tests/test_text_transforms.py::test_slugify",
                "result": "passed",
                "test_implementation": "def test_slugify(transformer):\n    # Test slugify with special characters\n    text = \"Hello, World! This is a Test\"\n    assert transformer.transform(text, [\"slugify\"]) == \"hello-world-this-is-a-test\""
            },
            "tests/test_text_transforms.py::test_text_replacements": {
                "testid": "tests/test_text_transforms.py::test_text_replacements",
                "result": "passed",
                "test_implementation": "def test_text_replacements(transformer):\n    # Test replace\n    text = \"hello world\"\n    result = transformer.transform(text, [{\n        \"function\": \"replace\",\n        \"from\": \"world\",\n        \"to\": \"there\"\n    }])\n    assert result == \"hello there\""
            },
            "tests/test_text_transforms.py::test_regex_transforms": {
                "testid": "tests/test_text_transforms.py::test_regex_transforms",
                "result": "passed",
                "test_implementation": "def test_regex_transforms(transformer):\n    # Test regex with pattern\n    text = \"The price is $123.45\"\n    result = transformer.transform(text, [{\n        \"function\": \"regex\",\n        \"pattern\": r\"\\$(\\d+\\.\\d+)\"\n    }])\n    assert result == \"123.45\""
            },
            "tests/test_text_transforms.py::test_template_transform": {
                "testid": "tests/test_text_transforms.py::test_template_transform",
                "result": "passed",
                "test_implementation": "def test_template_transform(transformer):\n    # Test template with regex\n    text = \"Name: John, Age: 30\"\n    transforms = [\n        {\n            \"function\": \"regex\",\n            \"pattern\": r\"Name: (.*), Age: (\\d+)\",\n            \"template\": \"{1} is {2} years old\"\n        }\n    ]\n    assert transformer.transform(text, transforms) == \"John is 30 years old\""
            },
            "tests/test_validation_transforms.py::test_email_validation": {
                "testid": "tests/test_validation_transforms.py::test_email_validation",
                "result": "passed",
                "test_implementation": "def test_email_validation(transformer):\n    # Test valid email\n    assert transformer.transform(\"test@example.com\", [\"email_validator\"]) == \"test@example.com\"\n    \n    # Test invalid email\n    assert transformer.transform(\"invalid-email\", [\"email_validator\"]) is None\n    \n    # Test email with spaces\n    assert transformer.transform(\" test@example.com \", [\"email_validator\"]) == \"test@example.com\""
            },
            "tests/test_validation_transforms.py::test_phone_formatting": {
                "testid": "tests/test_validation_transforms.py::test_phone_formatting",
                "result": "passed",
                "test_implementation": "def test_phone_formatting(transformer):\n    # Test standard 10-digit number\n    assert transformer.transform(\"1234567890\", [\"phone_formatter\"]) == \"(123) 456-7890\"\n    \n    # Test number with formatting\n    assert transformer.transform(\"(123) 456-7890\", [\"phone_formatter\"]) == \"(123) 456-7890\"\n    \n    # Test number with other characters\n    assert transformer.transform(\"123-456-7890\", [\"phone_formatter\"]) == \"(123) 456-7890\""
            },
            "tests/test_validation_transforms.py::test_credit_card_validation": {
                "testid": "tests/test_validation_transforms.py::test_credit_card_validation",
                "result": "passed",
                "test_implementation": "def test_credit_card_validation(transformer):\n    # Test valid card (using test numbers)\n    assert transformer.transform(\"4532015112830366\", [\"credit_card_check\"]) == \"4532015112830366\"\n    \n    # Test invalid number\n    assert transformer.transform(\"1234567890123456\", [\"credit_card_check\"]) is None\n    \n    # Test with formatting\n    assert transformer.transform(\"4532-0151-1283-0366\", [\"credit_card_check\"]) == \"4532-0151-1283-0366\""
            },
            "tests/test_validation_transforms.py::test_boolean_conversion": {
                "testid": "tests/test_validation_transforms.py::test_boolean_conversion",
                "result": "passed",
                "test_implementation": "def test_boolean_conversion(transformer):\n    # Test true values\n    assert transformer.transform(\"yes\", [\"bool\"]) is True\n    assert transformer.transform(\"1\", [\"bool\"]) is True\n    assert transformer.transform(\"true\", [\"bool\"]) is True\n    \n    # Test false values\n    assert transformer.transform(\"no\", [\"bool\"]) is False\n    assert transformer.transform(\"0\", [\"bool\"]) is False\n    assert transformer.transform(\"false\", [\"bool\"]) is False\n    \n    # Test invalid values\n    assert transformer.transform(\"maybe\", [\"bool\"]) is None"
            },
            "tests/test_validation_transforms.py::test_type_enforcement": {
                "testid": "tests/test_validation_transforms.py::test_type_enforcement",
                "result": "passed",
                "test_implementation": "def test_type_enforcement(transformer):\n    # Test int enforcement\n    assert transformer.transform(\"123.45\", [{\"function\": \"type_enforcer\", \"type\": \"int\"}]) == 123\n    \n    # Test float enforcement\n    assert transformer.transform(\"123.45\", [{\"function\": \"type_enforcer\", \"type\": \"float\"}]) == 123.45\n    \n    # Test str enforcement\n    assert transformer.transform(123, [{\"function\": \"type_enforcer\", \"type\": \"str\"}]) == \"123\"\n    \n    # Test bool enforcement\n    assert transformer.transform(1, [{\"function\": \"type_enforcer\", \"type\": \"bool\"}]) is True"
            }
        },
        "SRS_document": "**Software Requirements Specification**\n\n**Tukuy Data Transformation Library**\n\n**1. Introduction**\n\n**1.1 Purpose**\nThis Software Requirements Specification (SRS) document defines the functional and non-functional requirements for the Tukuy Data Transformation Library. The primary purpose of this SRS is to serve as a definitive guide for software developers who will be assessed on their ability to implement the Tukuy library based solely on this document and a provided subset of public test cases. Their success will be measured by passing all original test cases, including private ones. Therefore, this document prioritizes clarity, comprehensiveness in functionality, and an appropriate level of abstraction, focusing on *what* the system must do rather than *how* it is implemented internally.\n\n**1.2 Scope**\nThe Tukuy library is a Python-based software component designed for flexible data transformation. It provides a plugin system to extend its capabilities. Key functionalities include:\n*   Sequential application of multiple transformations.\n*   Text manipulation (e.g., case changes, stripping, regex, truncation).\n*   HTML processing (e.g., tag stripping, sanitization, data extraction via CSS selectors).\n*   JSON processing (e.g., parsing, data extraction via path selectors).\n*   Date and time operations (e.g., parsing, calculations like age and duration).\n*   Numerical operations (e.g., rounding, arithmetic, conversions).\n*   Data validation (e.g., email format, data type enforcement).\n*   Pattern-based data extraction from HTML and JSON structures.\n\nThis SRS covers all user-observable functionalities present in the original Tukuy source code and validated by its test suite. It does not specify internal design choices, algorithms, or class structures unless they form part of an externally visible contract or behavior.\n\n**1.3 Definitions, Acronyms, and Abbreviations**\n*   **SRS:** Software Requirements Specification\n*   **FR:** Functional Requirement\n*   **NFR:** Non-Functional Requirement\n*   **API:** Application Programming Interface\n*   **JSON:** JavaScript Object Notation\n*   **HTML:** HyperText Markup Language\n*   **CSS:** Cascading Style Sheets\n*   **Regex:** Regular Expression\n*   **Transformer:** A component or function that performs a specific data transformation.\n*   **Plugin:** A collection of related transformers that can be registered with the system.\n*   **Pattern (for extraction):** A structured definition (typically a dictionary) that specifies how to locate and extract data from HTML or JSON.\n*   **Selector (for extraction):** A string or dictionary specifying how to locate data within a structure (e.g., CSS selector for HTML, dot-notation path for JSON).\n\n**2. Overall Description**\n\n**2.1 Product Perspective**\nTukuy is a Python library intended to be integrated into other Python applications that require data manipulation, validation, and extraction tasks. It functions as a toolkit that developers can use to build complex data processing pipelines. It relies on a plugin architecture for extensibility and organization of its transformation capabilities.\n\n**2.2 Product Functions**\nThe Tukuy library provides the following key functions:\n*   **Core Transformation Engine:** Applies a sequence of declared transformations to an input value.\n*   **Plugin Management:** Allows loading built-in plugins and registration of custom plugins.\n*   **Text Transformation:** Offers a suite of tools for cleaning, modifying, and analyzing text data.\n*   **HTML Transformation & Extraction:** Provides capabilities to clean HTML, extract textual content, and retrieve structured data from HTML documents using patterns.\n*   **JSON Transformation & Extraction:** Enables parsing of JSON strings and extraction of structured data from JSON objects using patterns.\n*   **Date & Time Transformation:** Supports parsing date strings and performing calculations such as age and duration.\n*   **Numerical Transformation:** Includes operations like rounding, arithmetic, and unit/currency conversion.\n*   **Data Validation:** Offers transformers for validating data formats (e.g., email) and enforcing types.\n*   **Error Handling:** Provides a set of custom exceptions for reporting issues during transformation, parsing, or validation.\n\n**2.3 User Characteristics**\nThe primary users of the Tukuy library are software developers proficient in Python. They are expected to understand data structures, common data formats (JSON, HTML), and fundamental programming concepts. They will use Tukuy's API to implement data processing logic within their applications.\n\n**2.4 Operating Environment**\nThe Tukuy library is designed to operate in a Python environment.\n*   **Required:** Python version 3.7 or higher.\n*   **Dependencies:**\n    *   `beautifulsoup4` (>=4.9.0) for HTML processing.\n    *   `python-slugify` (>=4.0.0) for text slugification.\n\n**2.5 Design and Implementation Constraints**\n*   The system must be implemented as a Python library.\n*   The implementation should allow developers to make their own reasonable design choices for internal structures and algorithms, as long as the external behavior defined by these requirements is met.\n*   Focus on externally observable behavior, inputs, outputs, key processing rules, and data transformations.\n\n**2.6 Assumptions and Dependencies**\n*   The system assumes valid Python syntax and environment for its execution.\n*   Correct functioning of HTML and JSON extraction relies on the structural integrity of the input HTML/JSON and the correctness of the provided patterns/selectors.\n*   External libraries (`beautifulsoup4`, `python-slugify`) are assumed to be correctly installed and functional.\n\n**3. Specific Requirements**\n\n**3.1 Functional Requirements**\n\n**3.1.1 System Core Functionality**\n\n*   **FR-SYS-1: System Initialization**\n    *   The system shall allow instantiation of a main `TukuyTransformer` object. Upon instantiation, the system shall automatically load and initialize all built-in plugins (text, html, date, validation, numerical, json).\n\n*   **FR-SYS-2: Plugin Management**\n    *   **FR-SYS-2.1:** The system shall provide a mechanism to register custom transformer plugins. Registered plugins extend the system's capabilities.\n    *   **FR-SYS-2.2:** The system shall provide a mechanism to unregister a plugin by its name. Unregistering a plugin shall remove its transformers from availability.\n    *   **FR-SYS-2.3:** Transformers provided by registered plugins shall be accessible for use in transformation pipelines via the main `TukuyTransformer` instance.\n    *   **FR-SYS-2.4:** Plugins can define `initialize()` and `cleanup()` lifecycle methods. The `initialize()` method shall be called when a plugin is registered, and the `cleanup()` method shall be called when it is unregistered.\n\n*   **FR-SYS-3: Core Transformation Pipeline**\n    *   **FR-SYS-3.1:** The system shall process an input value by applying a sequence of transformations. This sequence is defined by a list, where each item can be:\n        *   A string, representing the name of a transformer.\n        *   A dictionary, specifying the transformer's name via a 'function' key and other keys as parameters for that transformer.\n    *   **FR-SYS-3.2:** In a transformation pipeline, the output of one transformation shall serve as the input for the immediately succeeding transformation.\n    *   **FR-SYS-3.3:** If any transformation in the pipeline results in a `None` value, all subsequent transformations in that specific pipeline execution shall be bypassed, and `None` shall be the final output of the pipeline.\n    *   **FR-SYS-3.4:** The system shall maintain and pass a mutable context dictionary through the transformation pipeline. Transformers can read from or write to this context (e.g., a 'regex' transformer storing its match object).\n\n*   **FR-SYS-4: Error Handling**\n    *   **FR-SYS-4.1:** The system shall raise a `ValidationError` if a transformer's input data fails its specific validation criteria, or if a specified transformer name is unknown.\n    *   **FR-SYS-4.2:** The system shall raise a `TransformationError` if an unrecoverable error occurs during the execution of a transformation's logic (excluding input validation failures).\n    *   **FR-SYS-4.3:** The system shall raise a `ParseError` if parsing of an input string (e.g., JSON) fails and the respective parser is operating in a strict mode that mandates successful parsing.\n\n**3.1.2 Text Plugin Transformers (Plugin: `text`)**\n\n*   **FR-PLG-TXT-1: `strip` Transformer**\n    *   The system shall remove all leading and trailing whitespace characters from an input string.\n\n*   **FR-PLG-TXT-2: `lowercase` Transformer**\n    *   The system shall convert all alphabetic characters in an input string to their lowercase equivalents.\n\n*   **FR-PLG-TXT-3: `uppercase` Transformer**\n    *   The system shall convert all alphabetic characters in an input string to their uppercase equivalents.\n\n*   **FR-PLG-TXT-4: `title_case` Transformer**\n    *   The system shall convert an input string to title case, where the first letter of each word is capitalized and others are lowercase.\n\n*   **FR-PLG-TXT-5: `camel_case` Transformer**\n    *   The system shall convert an input string (typically space, underscore, or hyphen-separated words) into camelCase format (e.g., \"hello world\" becomes \"helloWorld\").\n\n*   **FR-PLG-TXT-6: `snake_case` Transformer**\n    *   The system shall convert an input string (typically space, hyphen-separated, or camelCased words) into snake_case format (e.g., \"Hello World\" becomes \"hello_world\").\n\n*   **FR-PLG-TXT-7: `slugify` Transformer**\n    *   The system shall convert an input string into a URL-friendly \"slug\". This typically involves converting to lowercase, replacing spaces and other separators with hyphens, and removing non-alphanumeric characters (except hyphens).\n\n*   **FR-PLG-TXT-8: `truncate` Transformer**\n    *   The system shall truncate an input string to a maximum specified `length`. If truncation occurs, a `suffix` string (default: \"...\") shall be appended. The final length of the string, including the suffix, should not exceed the specified `length` if the original string was longer. If `length` is less than or equal to suffix length, only suffix is returned.\n    *   **Parameters:** `length` (integer, default 50), `suffix` (string, default \"...\").\n\n*   **FR-PLG-TXT-9: `replace` Transformer**\n    *   The system shall replace all occurrences of a specified substring with another substring within the input string.\n    *   **Parameters:** `from` (or `find`) (string: substring to be replaced), `to` (or `replace`) (string: replacement substring).\n\n*   **FR-PLG-TXT-10: `regex` Transformer**\n    *   The system shall apply a regular expression to an input string.\n    *   **Parameters:**\n        *   `pattern` (string: the regular expression).\n        *   `template` (string, optional: a format string for the output).\n    *   **Behavior:**\n        *   If the `pattern` matches, the regex match object shall be stored in the transformation context dictionary under the key 'last_regex_match'.\n        *   If a `template` is provided, the output is formed by substituting placeholders (e.g., `{1}`, `{2}`) in the template with corresponding captured groups from the match. Non-matched groups are replaced with empty strings.\n        *   If no `template` is provided: if the regex has capturing groups, the content of the first captured group is returned. If there are no capturing groups but a match occurs, the entire matched string is returned.\n        *   If the `pattern` does not match, the original input string is returned.\n\n*   **FR-PLG-TXT-11: `template` Transformer (Text)**\n    *   The system shall format an output string using a provided `template` string and the regex match object previously stored in the transformation context under 'last_regex_match' (typically by a preceding `regex` transformer). Placeholders like `{1}`, `{2}` in the template are replaced with the corresponding captured groups from the stored match.\n    *   **Parameters:** `template` (string: the format string).\n\n*   **FR-PLG-TXT-12: `map` Transformer**\n    *   The system shall map an input string to an output string based on a provided dictionary of key-value pairs.\n    *   **Parameters:**\n        *   `values` (dictionary: keys are input strings, values are corresponding output strings).\n        *   `default` (string, optional: value to return if the input string is not a key in `values`).\n    *   **Behavior:** If the input string is a key in `values`, its corresponding value is returned. Otherwise, if `default` is provided, `default` is returned. Otherwise, the original input string is returned.\n\n*   **FR-PLG-TXT-13: `split` Transformer**\n    *   The system shall split an input string by a specified delimiter and return a specific part based on an index.\n    *   **Parameters:**\n        *   `delimiter` (string, default: ':').\n        *   `index` (integer, default: -1, for the last part).\n    *   **Behavior:** The input string is split by `delimiter`. The part at the given `index` (after whitespace stripping) is returned. If the index is out of bounds, the original input string is returned.\n\n*   **FR-PLG-TXT-14: `remove_emojis` Transformer**\n    *   The system shall remove Unicode emoji characters from an input string.\n\n*   **FR-PLG-TXT-15: `redact_sensitive` Transformer**\n    *   The system shall redact sensitive information patterns (e.g., credit card numbers) within an input string by replacing parts of the matched pattern with placeholder characters (e.g., asterisks), while potentially leaving some parts visible (e.g., first/last few digits).\n\n**3.1.3 HTML Plugin Transformers (Plugin: `html`)**\n\n*   **FR-PLG-HTML-1: `strip_html_tags` Transformer**\n    *   The system shall remove all HTML tags from an input HTML string, returning only the concatenated text content of the tags.\n\n*   **FR-PLG-HTML-2: `html_sanitize` Transformer**\n    *   The system shall sanitize an input HTML string by removing potentially unsafe elements, specifically `<script>` and `<style>` tags and their entire content. Other HTML content should remain.\n\n*   **FR-PLG-HTML-3: `link_extraction` Transformer**\n    *   The system shall extract all URL values from `href` attributes of `<a>` (anchor) tags within an input HTML string. It shall return these URLs as a list of strings.\n\n*   **FR-PLG-HTML-4: `resolve_url` Transformer**\n    *   The system shall resolve a potentially relative URL string to an absolute URL, given a `base_url` string.\n    *   **Parameters:** `base_url` (string: the base URL to resolve against).\n\n*   **FR-PLG-HTML-5: `extract_domain` Transformer**\n    *   The system shall extract the network location (domain name or IP address and port) from a given URL string.\n\n*   **FR-PLG-HTML-6: Pattern-Based HTML Extraction (`extract_html_with_pattern` method & `html_extract` transformer)**\n    *   **FR-PLG-HTML-6.1:** The system shall extract structured data from an input HTML string based on a provided `pattern` (a dictionary). The pattern defines a list of `properties` to be extracted, resulting in a dictionary of extracted data.\n    *   **FR-PLG-HTML-6.2:** Each property definition within the `pattern` must specify a `name` (string: key for the extracted data in the result dictionary) and a `selector`. The `selector` can be a CSS selector string or a dictionary containing a `primary` CSS selector string and an optional `fallback` list of CSS selector strings.\n    *   **FR-PLG-HTML-6.3:** For each matched HTML element, the system shall support extracting its text content (default behavior, specified by `attribute: \"text\"` or by omitting `attribute`) or the value of a specified HTML `attribute` (e.g., `href`, `data-filetype`).\n    *   **FR-PLG-HTML-6.4:** Each property definition can specify an output `type` (string: \"string\", \"array\", \"object\").\n        *   `string` (default): Extracts a single value (text or attribute) from the first matched element.\n        *   `array`: If the selector matches multiple elements, extracts values from all matched elements into a list. If `properties` are defined for the array items, it extracts a list of objects.\n        *   `object`: If nested `properties` are defined, extracts a dictionary of these nested properties from the context of the matched element. If the selector matches multiple elements (e.g., `<tr>`s in a table) and nested `properties` are defined for columns, it extracts a list of objects.\n    *   **FR-PLG-HTML-6.5:** Each property definition can specify a list of `transform` operations (as defined in FR-SYS-3.1) to be applied sequentially to the extracted value(s) before being included in the result.\n    *   **FR-PLG-HTML-6.6:** The system shall support extracting nested data structures by allowing `properties` to be defined within a property definition. This is used when `type` is \"object\" or when `type` is \"array\" and each item in the array is an object with its own structure.\n    *   **FR-PLG-HTML-6.7:** If a `primary` selector fails to find any matching elements, the system shall iterate through the `fallback` selector list (if provided), attempting to find elements with each fallback selector until a match is found. The first successful match is used.\n    *   **FR-PLG-HTML-6.8:** If a property's selector (primary and all fallbacks) does not match any element, the value for that property in the result dictionary shall be `None`.\n\n*   **FR-PLG-HTML-7: Single Property Extraction from HTML (`extract_property_from_html` method)**\n    *   The system shall provide a method to extract a single named property from an HTML string using a single property definition dictionary (as described in FR-PLG-HTML-6.2 to FR-PLG-HTML-6.8). The method shall return the extracted value directly (not a dictionary containing it). If the property is not found or its definition lacks a 'name', `None` shall be returned.\n\n**3.1.4 JSON Plugin Transformers (Plugin: `json`)**\n\n*   **FR-PLG-JSON-1: `json_parse` Transformer**\n    *   The system shall parse an input JSON string into a corresponding Python data structure (typically a dictionary or list).\n    *   **Parameters:**\n        *   `strict` (boolean, default `True`): If `True`, an invalid JSON string input shall cause a `ParseError` to be raised. If `False`, an invalid JSON string shall be returned as is (the original string).\n        *   `schema` (dictionary, optional): A schema definition to validate the parsed JSON structure against.\n    *   If a `schema` is provided and the parsed JSON data does not conform to it, a `ValidationError` shall be raised. Schema validation includes checking data types (`object`, `array`, `string`, `number`, `boolean`, `null`), required properties for objects, and item schemas for arrays.\n\n*   **FR-PLG-JSON-2: Pattern-Based JSON Extraction (`extract_json_with_pattern` method & `json_extract` transformer)**\n    *   **FR-PLG-JSON-2.1:** The system shall extract structured data from an input parsed JSON object (Python dictionary or list, typically output from `json_parse`) based on a `pattern` (a dictionary). The pattern defines a list of `properties` to be extracted, resulting in a dictionary of extracted data.\n    *   **FR-PLG-JSON-2.2:** Each property definition within the `pattern` must specify a `name` (string: key for the extracted data in the result dictionary) and a `selector`. The `selector` is typically a string using dot-notation for nested object access (e.g., `user.profile.name`) and `[*]` for all elements in an array (e.g., `products[*].name`) or specific indices (e.g., `tags[0]`).\n    *   **FR-PLG-JSON-2.3:** Each property definition can specify an output `type` (string: \"string\", \"array\", \"object\").\n        *   `string` (default): Extracts a single value.\n        *   `array`: If the selector targets an array or uses `[*]`, extracts values into a list.\n        *   `object`: If the selector targets an object and no nested `properties` are defined, extracts that sub-object. If nested `properties` are defined, extracts a new dictionary of these nested properties from the selected object's context.\n    *   **FR-PLG-JSON-2.4:** Each property definition can specify a list of `transform` operations (as defined in FR-SYS-3.1, supporting functions like 'regex', 'replace', 'average') to be applied sequentially to the extracted value(s) before being included in the result.\n    *   **FR-PLG-JSON-2.5:** The system shall support extracting nested data structures by allowing `properties` to be defined within a property definition, typically when its `type` is \"object\".\n    *   **FR-PLG-JSON-2.6:** A property's `selector` can be a dictionary with a `primary` path string and a `fallback` list of path strings. If the `primary` path does not yield a value, the `fallback` paths shall be tried in order until a value is found.\n    *   **FR-PLG-JSON-2.7:** If a property's selector (primary and all fallbacks) does not match any data, or the path is invalid, the value for that property in the result dictionary shall be `None` (or a transformer-level default if specified, though tests imply `None`).\n\n*   **FR-PLG-JSON-3: Single Property Extraction from JSON (`extract_property_from_json` method)**\n    *   The system shall provide a method to extract a single named property from an input JSON string or a pre-parsed JSON object (Python dictionary/list), using a single property definition dictionary (as described in FR-PLG-JSON-2.2 to FR-PLG-JSON-2.7).\n    *   If the input is a JSON string, it must first be parsed (strict parsing). A `ParseError` is raised on invalid JSON.\n    *   The method shall return the extracted value directly. If the property is not found or its definition lacks a 'name', `None` shall be returned.\n    *   A `TransformationError` can be raised if the selector is invalid.\n\n**3.1.5 Date Plugin Transformers (Plugin: `date`)**\n\n*   **FR-PLG-DATE-1: `date` Transformer**\n    *   The system shall parse an input date string into a Python `datetime.datetime` object.\n    *   **Parameters:** `format` (string, default `'%Y-%m-%d'`: the format code for parsing the input date string).\n    *   A `ValidationError` shall be raised if the input string does not match the specified `format`.\n\n*   **FR-PLG-DATE-2: `age_calc` Transformer**\n    *   The system shall calculate the age in whole years from a given birth date string.\n    *   The input birth date string is expected to be in `'%Y-%m-%d'` format.\n    *   **Parameters:** `reference_date` (Python `date` object, optional: the date against which to calculate age; defaults to the current system date if not provided).\n    *   Returns the calculated age as an integer.\n    *   A `ValidationError` shall be raised if the input birth date string is not in the expected format.\n\n*   **FR-PLG-DATE-3: `duration_calc` Transformer**\n    *   The system shall calculate the duration between a start date (input value) and an end date.\n    *   The input start date string and the `end` date string parameter are parsed using the `format` string.\n    *   **Parameters:**\n        *   `end` (string: the end date string).\n        *   `format` (string, default `'%Y-%m-%d'`: format for parsing start and end date strings).\n        *   `unit` (string, default `'days'`: unit for the returned duration; supported: `'days'`, `'months'`, `'years'`).\n    *   Returns the calculated duration as an integer.\n    *   A `ValidationError` shall be raised for invalid date strings or formats, or an unsupported `unit`.\n\n**3.1.6 Numerical Plugin Transformers (Plugin: `numerical`)**\n\n*   **FR-PLG-NUM-1: `round` Transformer**\n    *   The system shall round an input numerical value (integer, float, or Decimal) to a specified number of decimal places. The result is a float.\n    *   **Parameters:** `decimals` (integer, default `0`: number of decimal places).\n\n*   **FR-PLG-NUM-2: `currency_convert` Transformer**\n    *   The system shall convert an input numerical value by multiplying it with a given exchange `rate`. The result is a float.\n    *   **Parameters:** `rate` (float: the exchange rate). This parameter is mandatory.\n    *   A `ValidationError` shall be raised if `rate` is not provided.\n\n*   **FR-PLG-NUM-3: `unit_convert` Transformer**\n    *   The system shall convert an input numerical value by multiplying it with a given conversion `rate`. The result is a float.\n    *   **Parameters:** `rate` (float: the conversion rate). This parameter is mandatory.\n    *   A `ValidationError` shall be raised if `rate` is not provided.\n\n*   **FR-PLG-NUM-4: `math_operation` Transformer**\n    *   The system shall perform a specified arithmetic operation on an input numerical value using a given operand. The result is a float.\n    *   **Parameters:**\n        *   `operation` (string: one of 'add', 'subtract', 'multiply', 'divide').\n        *   `operand` (number: the second value for the operation).\n    *   A `ValidationError` shall be raised if division by zero is attempted. An error (e.g., ValueError during param processing or ValidationError) if operation is invalid.\n\n*   **FR-PLG-NUM-5: `percentage_calc` Transformer**\n    *   The system shall convert an input numerical value (representing a decimal fraction) into a percentage by multiplying it by 100.0. The result is a float.\n\n*   **FR-PLG-NUM-6: `extract_numbers` Transformer**\n    *   The system shall extract all sequences of characters that represent numbers (integers or decimals) from an input string. It shall return these as a list of strings.\n\n*   **FR-PLG-NUM-7: `int` Transformer (Numerical)**\n    *   The system shall convert an input value to an integer. If the input is a string, it attempts to remove non-digit characters (preserving a leading minus) and then convert. String representations of floating-point numbers are truncated to integer.\n    *   **Parameters:**\n        *   `min_value` (integer, optional): If provided, the resulting integer must be greater than or equal to this value.\n        *   `max_value` (integer, optional): If provided, the resulting integer must be less than or equal to this value.\n    *   A `ValidationError` shall be raised if conversion fails or if `min_value`/`max_value` constraints are violated.\n\n*   **FR-PLG-NUM-8: `float` Transformer (Numerical)**\n    *   The system shall convert an input value to a float. If the input is a string, it attempts to remove non-numeric characters (preserving leading minus and one decimal point) and then convert.\n    *   **Parameters:**\n        *   `min_value` (float, optional): If provided, the resulting float must be greater than or equal to this value.\n        *   `max_value` (float, optional): If provided, the resulting float must be less than or equal to this value.\n    *   A `ValidationError` shall be raised if conversion fails or if `min_value`/`max_value` constraints are violated.\n\n*   **FR-PLG-NUM-9: `average` Transformer (Sub-transform)**\n    *   The system shall calculate the arithmetic average of a list of numerical values. Input values will be converted to float for calculation.\n    *   The result shall be a float, rounded to two decimal places.\n    *   A `ValidationError` shall be raised if the input is not a list or if elements cannot be converted to numbers.\n\n**3.1.7 Validation Plugin Transformers (Plugin: `validation`)**\n\n*   **FR-PLG-VAL-1: `email_validator` Transformer**\n    *   The system shall validate if an input string conforms to a common email address format (e.g., `local-part@domain-part`). Leading/trailing whitespace from the input string is stripped before validation.\n    *   **Parameters:** `allowed_domains` (list of strings, optional): If provided, the domain part of the email must match one of the domains in this list.\n    *   If valid, the transformer returns the stripped email string. If invalid, it returns `None`.\n\n*   **FR-PLG-VAL-2: `phone_formatter` Transformer**\n    *   The system shall format an input string representing a US-style 10-digit phone number (optionally after stripping a leading '1') into a standard string format.\n    *   **Parameters:** `format` (string, default `({area}) {prefix}-{line}`: a template for the output, where `{area}`, `{prefix}`, `{line}` are placeholders for parts of the phone number).\n    *   Digits are extracted from the input. If the number of effective digits is not 10 (after potentially removing a leading '1'), a `ValidationError` is raised.\n\n*   **FR-PLG-VAL-3: `credit_card_check` Transformer**\n    *   The system shall validate an input string (representing a credit card number) using the Luhn algorithm. Non-digit characters in the input are ignored for the algorithm's calculation. The number of digits must be between 13 and 19 (inclusive).\n    *   **Parameters:** `mask` (boolean, default `False`): If `True` and the number is valid, the returned string will have most of its digits masked (e.g., first 4 and last 4 visible, rest are `*`).\n    *   If valid, returns the original input string (or masked string if `mask` is `True`). If invalid, returns `None`.\n\n*   **FR-PLG-VAL-4: `bool` Transformer (Validation)**\n    *   The system shall convert an input value (string or boolean) to a Python boolean (`True` or `False`).\n    *   For string inputs (case-insensitive, after stripping whitespace):\n        *   \"true\", \"1\", \"yes\", \"y\", \"t\" convert to `True`.\n        *   \"false\", \"0\", \"no\", \"n\", \"f\" convert to `False`.\n    *   If the input is already a Python boolean, it is returned as is.\n    *   If an input string does not match any recognized boolean representations, `None` is returned.\n\n*   **FR-PLG-VAL-5: `type_enforcer` Transformer**\n    *   The system shall attempt to convert an input value to a specified target data type.\n    *   **Parameters:** `type` (string: the target type). Supported types:\n        *   `'int'`: Converts to integer. For string input, it attempts float conversion then int (truncation).\n        *   `'float'`: Converts to float.\n        *   `'str'`: Converts to string.\n        *   `'bool'`: Converts to boolean. For non-string, uses Python's truthiness. For string, uses explicit true/false value checks similar to FR-PLG-VAL-4 (e.g., \"1\" is True, \"0\" is False, other numerical strings are True, \"true\" is True, \"false\" is False).\n        *   `'decimal'`: Converts to Python `Decimal`.\n    *   A `ValidationError` shall be raised if conversion fails or if the target `type` is not supported.\n\n**3.2 Non-Functional Requirements**\nNo specific non-functional requirements have been identified with direct, explicit corresponding original test cases that validate them. Therefore, per project guidelines, no NFRs are listed. The primary assessment will be on functional correctness against all (public and private) test cases.\n\n**3.3 External Interface Requirements**\n\n*   **EIR-1: Transformation Definition Interface**\n    *   The system accepts transformation pipeline definitions as a Python list of strings and/or dictionaries, as detailed in FR-SYS-3.1. This list structure is an external interface for developers defining transformations.\n\n*   **EIR-2: HTML Extraction Pattern Interface**\n    *   The system accepts patterns for HTML extraction as a Python dictionary, structured according to the rules detailed in FR-PLG-HTML-6 (properties, name, selector, attribute, type, transform, fallback). This dictionary structure is an external interface.\n\n*   **EIR-3: JSON Extraction Pattern Interface**\n    *   The system accepts patterns for JSON extraction as a Python dictionary, structured according to the rules detailed in FR-PLG-JSON-2 (properties, name, selector, type, transform, fallback). This dictionary structure is an external interface.\n\n**3.4 Other Requirements**\n\n**3.4.1 Data Dictionary / Key Term Definitions**\n\n*   **Pattern (for HTML/JSON extraction):** A Python dictionary defining a set of properties to extract.\n    *   `properties`: A list of property definition dictionaries.\n    *   Each *property definition dictionary* contains:\n        *   `name` (string): The key under which the extracted data will be stored in the result.\n        *   `selector` (string or dict): Specifies how to locate the data.\n            *   For HTML: CSS selector string, or `{\"primary\": \"css_selector\", \"fallback\": [\"fb_selector1\", ...]}`.\n            *   For JSON: Dot-notation path string (e.g., `foo.bar[0].baz`), or `{\"primary\": \"path\", \"fallback\": [\"fb_path1\", ...]}`.\n        *   `attribute` (string, HTML only, optional): Name of the HTML attribute to extract (e.g., `href`). Defaults to text content.\n        *   `type` (string, optional): Expected type of the extracted data (e.g., \"string\", \"array\", \"object\"). Influences how multiple matches or nested structures are handled.\n        *   `transform` (list, optional): A list of transformation definitions (see FR-SYS-3.1) to apply to the extracted value.\n        *   `properties` (list, optional, used with `type: \"object\"` or `type: \"array\"` of objects): A nested list of property definitions for extracting sub-structures.\n\n**4. Appendix**\n(Not applicable for this exercise)",
        "structured_requirements": [
            {
                "requirement_id": "FR-SYS-1",
                "requirement_description": "The system shall allow instantiation of a main `TukuyTransformer` object. Upon instantiation, the system shall automatically load and initialize all built-in plugins (text, html, date, validation, numerical, json).",
                "test_traceability": [
                    {
                        "id": "tests/conftest.py::transformer",
                        "description": "implicit setup for all tests demonstrating instantiation and availability of built-in plugins"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/__init__.py::TukuyTransformer::__init__",
                        "description": ""
                    },
                    {
                        "id": "tukuy/transformers/__init__.py::TukuyTransformer::_load_builtin_plugins",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SYS-2",
                "requirement_description": "",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "FR-SYS-2.1",
                "requirement_description": "The system shall provide a mechanism to register custom transformer plugins. Registered plugins extend the system's capabilities.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/__init__.py::TukuyTransformer::register_plugin",
                        "description": ""
                    },
                    {
                        "id": "tukuy/plugins/base.py::PluginRegistry::register",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SYS-2.2",
                "requirement_description": "The system shall provide a mechanism to unregister a plugin by its name. Unregistering a plugin shall remove its transformers from availability.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/__init__.py::TukuyTransformer::unregister_plugin",
                        "description": ""
                    },
                    {
                        "id": "tukuy/plugins/base.py::PluginRegistry::unregister",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SYS-2.3",
                "requirement_description": "Transformers provided by registered plugins shall be accessible for use in transformation pipelines via the main `TukuyTransformer` instance.",
                "test_traceability": [
                    {
                        "id": "tests/test_text_transforms.py::test_basic_text_transforms",
                        "description": "uses 'strip' from 'text' plugin"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/plugins/base.py::PluginRegistry::register",
                        "description": ""
                    },
                    {
                        "id": "tukuy/plugins/base.py::PluginRegistry::get_transformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SYS-2.4",
                "requirement_description": "Plugins can define `initialize()` and `cleanup()` lifecycle methods. The `initialize()` method shall be called when a plugin is registered, and the `cleanup()` method shall be called when it is unregistered.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "tukuy/plugins/base.py::PluginRegistry::register",
                        "description": "calls `plugin.initialize()`"
                    },
                    {
                        "id": "tukuy/plugins/base.py::PluginRegistry::unregister",
                        "description": "calls `plugin.cleanup()`"
                    }
                ]
            },
            {
                "requirement_id": "FR-SYS-3",
                "requirement_description": "",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "FR-SYS-3.1",
                "requirement_description": "The system shall process an input value by applying a sequence of transformations. This sequence is defined by a list, where each item can be: A string, representing the name of a transformer. A dictionary, specifying the transformer's name via a 'function' key and other keys as parameters for that transformer.",
                "test_traceability": [
                    {
                        "id": "tests/test_text_transforms.py::test_chained_text_transforms",
                        "description": ""
                    },
                    {
                        "id": "tests/test_html_transforms.py::test_html_and_text_combination",
                        "description": ""
                    },
                    {
                        "id": "examples.py::text_transformation_examples",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/__init__.py::TukuyTransformer::transform",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SYS-3.2",
                "requirement_description": "In a transformation pipeline, the output of one transformation shall serve as the input for the immediately succeeding transformation.",
                "test_traceability": [
                    {
                        "id": "tests/test_text_transforms.py::test_chained_text_transforms",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/__init__.py::TukuyTransformer::transform",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SYS-3.3",
                "requirement_description": "If any transformation in the pipeline results in a `None` value, all subsequent transformations in that specific pipeline execution shall be bypassed, and `None` shall be the final output of the pipeline.",
                "test_traceability": [
                    {
                        "id": "tests/test_validation_transforms.py::test_email_validation",
                        "description": "where an invalid email results in `None`, and if chained, no further transforms would apply"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/__init__.py::TukuyTransformer::transform",
                        "description": "logic: `if current_value is None: break`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-SYS-3.4",
                "requirement_description": "The system shall maintain and pass a mutable context dictionary through the transformation pipeline. Transformers can read from or write to this context (e.g., a 'regex' transformer storing its match object).",
                "test_traceability": [
                    {
                        "id": "tests/test_text_transforms.py::test_template_transform",
                        "description": "implicitly relies on 'last_regex_match' set by a preceding 'regex' transform"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/base.py::RegexTransformer::_transform",
                        "description": ""
                    },
                    {
                        "id": "tukuy/transformers/text.py::TemplateTransformer::_transform",
                        "description": ""
                    },
                    {
                        "id": "tukuy/transformers/__init__.py::TukuyTransformer::transform",
                        "description": "passes context"
                    }
                ]
            },
            {
                "requirement_id": "FR-SYS-4",
                "requirement_description": "",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "FR-SYS-4.1",
                "requirement_description": "The system shall raise a `ValidationError` if a transformer's input data fails its specific validation criteria, or if a specified transformer name is unknown.",
                "test_traceability": [
                    {
                        "id": "tests/test_json_transforms.py::test_json_parser_schema_validation",
                        "description": "schema validation fail"
                    },
                    {
                        "id": "tukuy/transformers/__init__.py::TukuyTransformer::transform",
                        "description": "unknown transformer"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/base.py::BaseTransformer::transform",
                        "description": ""
                    },
                    {
                        "id": "tukuy/exceptions.py::ValidationError",
                        "description": ""
                    },
                    {
                        "id": "tukuy/transformers/__init__.py::TukuyTransformer::transform",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SYS-4.2",
                "requirement_description": "The system shall raise a `TransformationError` if an unrecoverable error occurs during the execution of a transformation's logic (excluding input validation failures).",
                "test_traceability": [
                    {
                        "id": "tests/test_json_transforms.py::test_extract_property_from_json_errors",
                        "description": "invalid selector during extraction"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/base.py::BaseTransformer::transform",
                        "description": ""
                    },
                    {
                        "id": "tukuy/exceptions.py::TransformationError",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SYS-4.3",
                "requirement_description": "The system shall raise a `ParseError` if parsing of an input string (e.g., JSON) fails and the respective parser is operating in a strict mode that mandates successful parsing.",
                "test_traceability": [
                    {
                        "id": "tests/test_json_transforms.py::test_json_parser_invalid",
                        "description": "strict JSON parsing failure"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/json.py::JsonParser::_transform",
                        "description": ""
                    },
                    {
                        "id": "tukuy/exceptions.py::ParseError",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-TXT-1",
                "requirement_description": "The system shall remove all leading and trailing whitespace characters from an input string.",
                "test_traceability": [
                    {
                        "id": "tests/test_text_transforms.py::test_basic_text_transforms",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/text.py::StripTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-TXT-2",
                "requirement_description": "The system shall convert all alphabetic characters in an input string to their lowercase equivalents.",
                "test_traceability": [
                    {
                        "id": "tests/test_text_transforms.py::test_basic_text_transforms",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/text.py::LowercaseTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-TXT-3",
                "requirement_description": "The system shall convert all alphabetic characters in an input string to their uppercase equivalents.",
                "test_traceability": [
                    {
                        "id": "tests/test_text_transforms.py::test_basic_text_transforms",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/text.py::UppercaseTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-TXT-4",
                "requirement_description": "The system shall convert an input string to title case, where the first letter of each word is capitalized and others are lowercase.",
                "test_traceability": [
                    {
                        "id": "tests/test_text_transforms.py::test_basic_text_transforms",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/text.py::TitleCaseTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-TXT-5",
                "requirement_description": "The system shall convert an input string (typically space, underscore, or hyphen-separated words) into camelCase format (e.g., \"hello world\" becomes \"helloWorld\").",
                "test_traceability": [
                    {
                        "id": "tests/test_text_transforms.py::test_basic_text_transforms",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/text.py::CamelCaseTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-TXT-6",
                "requirement_description": "The system shall convert an input string (typically space, hyphen-separated, or camelCased words) into snake_case format (e.g., \"Hello World\" becomes \"hello_world\").",
                "test_traceability": [
                    {
                        "id": "tests/test_text_transforms.py::test_basic_text_transforms",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/text.py::SnakeCaseTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-TXT-7",
                "requirement_description": "The system shall convert an input string into a URL-friendly \"slug\". This typically involves converting to lowercase, replacing spaces and other separators with hyphens, and removing non-alphanumeric characters (except hyphens).",
                "test_traceability": [
                    {
                        "id": "tests/test_text_transforms.py::test_slugify",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/text.py::SlugifyTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-TXT-8",
                "requirement_description": "The system shall truncate an input string to a maximum specified `length`. If truncation occurs, a `suffix` string (default: \"...\") shall be appended. The final length of the string, including the suffix, should not exceed the specified `length` if the original string was longer. If `length` is less than or equal to suffix length, only suffix is returned. **Parameters:** `length` (integer, default 50), `suffix` (string, default \"...\").",
                "test_traceability": [
                    {
                        "id": "tests/test_text_transforms.py::test_chained_text_transforms",
                        "description": ""
                    },
                    {
                        "id": "tests/test_html_transforms.py::test_html_and_text_combination",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/text.py::TruncateTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-TXT-9",
                "requirement_description": "The system shall replace all occurrences of a specified substring with another substring within the input string. **Parameters:** `from` (or `find`) (string: substring to be replaced), `to` (or `replace`) (string: replacement substring).",
                "test_traceability": [
                    {
                        "id": "tests/test_text_transforms.py::test_text_replacements",
                        "description": ""
                    },
                    {
                        "id": "tests/test_json_transforms.py::test_complex_json_pattern",
                        "description": "stock_info.availability example"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/text.py::ReplaceTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-TXT-10",
                "requirement_description": "The system shall apply a regular expression to an input string. **Parameters:** `pattern` (string: the regular expression). `template` (string, optional: a format string for the output). **Behavior:** If the `pattern` matches, the regex match object shall be stored in the transformation context dictionary under the key 'last_regex_match'. If a `template` is provided, the output is formed by substituting placeholders (e.g., `{1}`, `{2}`) in the template with corresponding captured groups from the match. Non-matched groups are replaced with empty strings. If no `template` is provided: if the regex has capturing groups, the content of the first captured group is returned. If there are no capturing groups but a match occurs, the entire matched string is returned. If the `pattern` does not match, the original input string is returned.",
                "test_traceability": [
                    {
                        "id": "tests/test_text_transforms.py::test_regex_transforms",
                        "description": ""
                    },
                    {
                        "id": "tests/test_text_transforms.py::test_template_transform",
                        "description": ""
                    },
                    {
                        "id": "tests/test_json_transforms.py::test_complex_json_pattern",
                        "description": "model_number, savings examples"
                    },
                    {
                        "id": "tests/test_html_transforms.py::test_complex_product_extraction",
                        "description": ""
                    },
                    {
                        "id": "tests/test_html_transforms.py::test_complex_pattern_extraction",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/base.py::RegexTransformer",
                        "description": ""
                    },
                    {
                        "id": "tukuy/plugins/text/__init__.py",
                        "description": "configures RegexTransformer"
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-TXT-11",
                "requirement_description": "The system shall format an output string using a provided `template` string and the regex match object previously stored in the transformation context under 'last_regex_match' (typically by a preceding `regex` transformer). Placeholders like `{1}`, `{2}` in the template are replaced with the corresponding captured groups from the stored match. **Parameters:** `template` (string: the format string).",
                "test_traceability": [
                    {
                        "id": "tests/test_text_transforms.py::test_template_transform",
                        "description": ""
                    },
                    {
                        "id": "tests/test_html_transforms.py::test_complex_pattern_extraction",
                        "description": "model_info example"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/text.py::TemplateTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-TXT-12",
                "requirement_description": "The system shall map an input string to an output string based on a provided dictionary of key-value pairs. **Parameters:** `values` (dictionary: keys are input strings, values are corresponding output strings). `default` (string, optional: value to return if the input string is not a key in `values`). **Behavior:** If the input string is a key in `values`, its corresponding value is returned. Otherwise, if `default` is provided, `default` is returned. Otherwise, the original input string is returned.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/text.py::MapTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-TXT-13",
                "requirement_description": "The system shall split an input string by a specified delimiter and return a specific part based on an index. **Parameters:** `delimiter` (string, default: ':'). `index` (integer, default: -1, for the last part). **Behavior:** The input string is split by `delimiter`. The part at the given `index` (after whitespace stripping) is returned. If the index is out of bounds, the original input string is returned.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/text.py::SplitTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-TXT-14",
                "requirement_description": "The system shall remove Unicode emoji characters from an input string.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/text.py::RemoveEmojisTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-TXT-15",
                "requirement_description": "The system shall redact sensitive information patterns (e.g., credit card numbers) within an input string by replacing parts of the matched pattern with placeholder characters (e.g., asterisks), while potentially leaving some parts visible (e.g., first/last few digits).",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/text.py::RedactSensitiveTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-HTML-1",
                "requirement_description": "The system shall remove all HTML tags from an input HTML string, returning only the concatenated text content of the tags.",
                "test_traceability": [
                    {
                        "id": "tests/test_html_transforms.py::test_strip_html_tags",
                        "description": ""
                    },
                    {
                        "id": "tests/test_html_transforms.py::test_html_and_text_combination",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/html.py::StripHtmlTagsTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-HTML-2",
                "requirement_description": "The system shall sanitize an input HTML string by removing potentially unsafe elements, specifically `<script>` and `<style>` tags and their entire content. Other HTML content should remain.",
                "test_traceability": [
                    {
                        "id": "tests/test_html_transforms.py::test_html_sanitization",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/html.py::HtmlSanitizationTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-HTML-3",
                "requirement_description": "The system shall extract all URL values from `href` attributes of `<a>` (anchor) tags within an input HTML string. It shall return these URLs as a list of strings.",
                "test_traceability": [
                    {
                        "id": "tests/test_html_transforms.py::test_link_extraction",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/html.py::LinkExtractionTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-HTML-4",
                "requirement_description": "The system shall resolve a potentially relative URL string to an absolute URL, given a `base_url` string. **Parameters:** `base_url` (string: the base URL to resolve against).",
                "test_traceability": [
                    {
                        "id": "tests/test_html_transforms.py::test_url_transforms",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/html.py::ResolveUrlTransformer",
                        "description": "implemented as `UrlJoinTransformer` in plugin pointing to `tukuy.transformers.html.ResolveUrlTransformer`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-HTML-5",
                "requirement_description": "The system shall extract the network location (domain name or IP address and port) from a given URL string.",
                "test_traceability": [
                    {
                        "id": "tests/test_html_transforms.py::test_url_transforms",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/html.py::ExtractDomainTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-HTML-6",
                "requirement_description": "",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "FR-PLG-HTML-6.1",
                "requirement_description": "The system shall extract structured data from an input HTML string based on a provided `pattern` (a dictionary). The pattern defines a list of `properties` to be extracted, resulting in a dictionary of extracted data.",
                "test_traceability": [
                    {
                        "id": "tests/test_html_transforms.py::test_complex_pattern_extraction",
                        "description": ""
                    },
                    {
                        "id": "examples.py::html_transformation_examples",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/__init__.py::TukuyTransformer::extract_html_with_pattern",
                        "description": ""
                    },
                    {
                        "id": "tukuy/transformers/html.py::HtmlExtractor",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-HTML-6.2",
                "requirement_description": "Each property definition within the `pattern` must specify a `name` (string: key for the extracted data in the result dictionary) and a `selector`. The `selector` can be a CSS selector string or a dictionary containing a `primary` CSS selector string and an optional `fallback` list of CSS selector strings.",
                "test_traceability": [
                    {
                        "id": "tests/test_html_transforms.py::test_complex_pattern_extraction",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/html.py::HtmlExtractor::_extract_property",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-HTML-6.3",
                "requirement_description": "For each matched HTML element, the system shall support extracting its text content (default behavior, specified by `attribute: \"text\"` or by omitting `attribute`) or the value of a specified HTML `attribute` (e.g., `href`, `data-filetype`).",
                "test_traceability": [
                    {
                        "id": "tests/test_html_transforms.py::test_complex_pattern_extraction",
                        "description": "e.g., `model_info` uses text, `download_links.url` uses `href`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/html.py::HtmlExtractor::_get_element_value",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-HTML-6.4",
                "requirement_description": "Each property definition can specify an output `type` (string: \"string\", \"array\", \"object\"). `string` (default): Extracts a single value (text or attribute) from the first matched element. `array`: If the selector matches multiple elements, extracts values from all matched elements into a list. If `properties` are defined for the array items, it extracts a list of objects. `object`: If nested `properties` are defined, extracts a dictionary of these nested properties from the context of the matched element. If the selector matches multiple elements (e.g., `<tr>`s in a table) and nested `properties` are defined for columns, it extracts a list of objects.",
                "test_traceability": [
                    {
                        "id": "tests/test_html_transforms.py::test_complex_pattern_extraction",
                        "description": "`download_links` as array of objects, `technical_specs` as array of objects from table rows"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/html.py::HtmlExtractor::_extract_property",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-HTML-6.5",
                "requirement_description": "Each property definition can specify a list of `transform` operations (as defined in FR-SYS-3.1) to be applied sequentially to the extracted value(s) before being included in the result.",
                "test_traceability": [
                    {
                        "id": "tests/test_html_transforms.py::test_complex_pattern_extraction",
                        "description": "e.g., `model_info` uses regex and template; `download_links.type` uses lowercase"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/html.py::HtmlExtractor::_apply_transforms",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-HTML-6.6",
                "requirement_description": "The system shall support extracting nested data structures by allowing `properties` to be defined within a property definition. This is used when `type` is \"object\" or when `type` is \"array\" and each item in the array is an object with its own structure.",
                "test_traceability": [
                    {
                        "id": "tests/test_html_transforms.py::test_complex_pattern_extraction",
                        "description": "`technical_specs`, `download_links`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/html.py::HtmlExtractor::_extract_nested_property",
                        "description": ""
                    },
                    {
                        "id": "tukuy/transformers/html.py::HtmlExtractor::_process_object",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-HTML-6.7",
                "requirement_description": "If a `primary` selector fails to find any matching elements, the system shall iterate through the `fallback` selector list (if provided), attempting to find elements with each fallback selector until a match is found. The first successful match is used.",
                "test_traceability": [
                    {
                        "id": "tests/test_html_transforms.py::test_complex_pattern_extraction",
                        "description": "pattern definition includes fallback selectors"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/html.py::HtmlExtractor::_select_element",
                        "description": ""
                    },
                    {
                        "id": "tukuy/transformers/html.py::HtmlExtractor::_select_elements",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-HTML-6.8",
                "requirement_description": "If a property's selector (primary and all fallbacks) does not match any element, the value for that property in the result dictionary shall be `None`.",
                "test_traceability": [
                    {
                        "id": "tests/test_html_transforms.py::test_extract_property_from_html",
                        "description": "missing property returns `None`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/html.py::HtmlExtractor::_extract_property",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-HTML-7",
                "requirement_description": "The system shall provide a method to extract a single named property from an HTML string using a single property definition dictionary (as described in FR-PLG-HTML-6.2 to FR-PLG-HTML-6.8). The method shall return the extracted value directly (not a dictionary containing it). If the property is not found or its definition lacks a 'name', `None` shall be returned.",
                "test_traceability": [
                    {
                        "id": "tests/test_html_transforms.py::test_extract_property_from_html",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/__init__.py::TukuyTransformer::extract_property_from_html",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-JSON-1",
                "requirement_description": "The system shall parse an input JSON string into a corresponding Python data structure (typically a dictionary or list). **Parameters:** `strict` (boolean, default `True`): If `True`, an invalid JSON string input shall cause a `ParseError` to be raised. If `False`, an invalid JSON string shall be returned as is (the original string). `schema` (dictionary, optional): A schema definition to validate the parsed JSON structure against. If a `schema` is provided and the parsed JSON data does not conform to it, a `ValidationError` shall be raised. Schema validation includes checking data types (`object`, `array`, `string`, `number`, `boolean`, `null`), required properties for objects, and item schemas for arrays.",
                "test_traceability": [
                    {
                        "id": "tests/test_json_transforms.py::test_json_parser_basic",
                        "description": ""
                    },
                    {
                        "id": "tests/test_json_transforms.py::test_json_parser_invalid",
                        "description": ""
                    },
                    {
                        "id": "tests/test_json_transforms.py::test_json_parser_schema_validation",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/json.py::JsonParser",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-JSON-2",
                "requirement_description": "",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "FR-PLG-JSON-2.1",
                "requirement_description": "The system shall extract structured data from an input parsed JSON object (Python dictionary or list, typically output from `json_parse`) based on a `pattern` (a dictionary). The pattern defines a list of `properties` to be extracted, resulting in a dictionary of extracted data.",
                "test_traceability": [
                    {
                        "id": "tests/test_json_transforms.py::test_complex_json_pattern",
                        "description": ""
                    },
                    {
                        "id": "tests/test_json_transforms.py::test_json_extractor_simple",
                        "description": ""
                    },
                    {
                        "id": "examples.py::json_transformation_example",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/__init__.py::TukuyTransformer::extract_json_with_pattern",
                        "description": ""
                    },
                    {
                        "id": "tukuy/transformers/json.py::JsonExtractor",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-JSON-2.2",
                "requirement_description": "Each property definition within the `pattern` must specify a `name` (string: key for the extracted data in the result dictionary) and a `selector`. The `selector` is typically a string using dot-notation for nested object access (e.g., `user.profile.name`) and `[*]` for all elements in an array (e.g., `products[*].name`) or specific indices (e.g., `tags[0]`).",
                "test_traceability": [
                    {
                        "id": "tests/test_json_transforms.py::test_json_extractor_simple",
                        "description": ""
                    },
                    {
                        "id": "tests/test_json_transforms.py::test_json_extractor_nested",
                        "description": ""
                    },
                    {
                        "id": "tests/test_json_transforms.py::test_json_extractor_array",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/json.py::JsonExtractor::_get_value",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-JSON-2.3",
                "requirement_description": "Each property definition can specify an output `type` (string: \"string\", \"array\", \"object\"). `string` (default): Extracts a single value. `array`: If the selector targets an array or uses `[*]`, extracts values into a list. `object`: If the selector targets an object and no nested `properties` are defined, extracts that sub-object. If nested `properties` are defined, extracts a new dictionary of these nested properties from the selected object's context.",
                "test_traceability": [
                    {
                        "id": "tests/test_json_transforms.py::test_json_extractor_array",
                        "description": ""
                    },
                    {
                        "id": "tests/test_json_transforms.py::test_complex_json_pattern",
                        "description": "e.g., `product_info` as object, `review_ratings` as array"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/json.py::JsonExtractor::_extract_data",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-JSON-2.4",
                "requirement_description": "Each property definition can specify a list of `transform` operations (as defined in FR-SYS-3.1, supporting functions like 'regex', 'replace', 'average') to be applied sequentially to the extracted value(s) before being included in the result.",
                "test_traceability": [
                    {
                        "id": "tests/test_json_transforms.py::test_complex_json_pattern",
                        "description": "e.g., `model_number` uses regex; `savings` uses regex; `availability` uses replace; `average_rating` uses average"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/json.py::JsonExtractor::_extract_data",
                        "description": "uses `CoreToolsTransformer`)"
                    },
                    {
                        "id": "tukuy/base.py::CoreToolsTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-JSON-2.5",
                "requirement_description": "The system shall support extracting nested data structures by allowing `properties` to be defined within a property definition, typically when its `type` is \"object\".",
                "test_traceability": [
                    {
                        "id": "tests/test_json_transforms.py::test_complex_json_pattern",
                        "description": "e.g., `product_info`, `price_info`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/json.py::JsonExtractor::_extract_data",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-JSON-2.6",
                "requirement_description": "A property's `selector` can be a dictionary with a `primary` path string and a `fallback` list of path strings. If the `primary` path does not yield a value, the `fallback` paths shall be tried in order until a value is found.",
                "test_traceability": [
                    {
                        "id": "tests/test_json_transforms.py::test_json_extractor_fallback",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/json.py::JsonExtractor::_extract_data",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-JSON-2.7",
                "requirement_description": "If a property's selector (primary and all fallbacks) does not match any data, or the path is invalid, the value for that property in the result dictionary shall be `None` (or a transformer-level default if specified, though tests imply `None`).",
                "test_traceability": [
                    {
                        "id": "tests/test_json_transforms.py::test_extract_property_from_json_errors",
                        "description": "missing property"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/json.py::JsonExtractor::_get_value",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-JSON-3",
                "requirement_description": "The system shall provide a method to extract a single named property from an input JSON string or a pre-parsed JSON object (Python dictionary/list), using a single property definition dictionary (as described in FR-PLG-JSON-2.2 to FR-PLG-JSON-2.7). If the input is a JSON string, it must first be parsed (strict parsing). A `ParseError` is raised on invalid JSON. The method shall return the extracted value directly. If the property is not found or its definition lacks a 'name', `None` shall be returned. A `TransformationError` can be raised if the selector is invalid.",
                "test_traceability": [
                    {
                        "id": "tests/test_json_transforms.py::test_extract_property_from_json",
                        "description": ""
                    },
                    {
                        "id": "tests/test_json_transforms.py::test_extract_property_from_json_errors",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/__init__.py::TukuyTransformer::extract_property_from_json",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-DATE-1",
                "requirement_description": "The system shall parse an input date string into a Python `datetime.datetime` object. **Parameters:** `format` (string, default `'%Y-%m-%d'`: the format code for parsing the input date string). A `ValidationError` shall be raised if the input string does not match the specified `format`.",
                "test_traceability": [
                    {
                        "id": "tests/test_numerical_and_date_transforms.py::test_date_transforms",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/date.py::DateTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-DATE-2",
                "requirement_description": "The system shall calculate the age in whole years from a given birth date string. The input birth date string is expected to be in `'%Y-%m-%d'` format. **Parameters:** `reference_date` (Python `date` object, optional: the date against which to calculate age; defaults to the current system date if not provided). Returns the calculated age as an integer. A `ValidationError` shall be raised if the input birth date string is not in the expected format.",
                "test_traceability": [
                    {
                        "id": "tests/test_numerical_and_date_transforms.py::test_age_calculation",
                        "description": "The test passes a `format` param, but the underlying `AgeCalculator` does not use it and assumes '%Y-%m-%d'"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/date.py::AgeCalculator",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-DATE-3",
                "requirement_description": "The system shall calculate the duration between a start date (input value) and an end date. The input start date string and the `end` date string parameter are parsed using the `format` string. **Parameters:** `end` (string: the end date string). `format` (string, default `'%Y-%m-%d'`: format for parsing start and end date strings). `unit` (string, default `'days'`: unit for the returned duration; supported: `'days'`, `'months'`, `'years'`). Returns the calculated duration as an integer. A `ValidationError` shall be raised for invalid date strings or formats, or an unsupported `unit`.",
                "test_traceability": [
                    {
                        "id": "tests/test_numerical_and_date_transforms.py::test_duration_calculation",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/date.py::DurationCalculator",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-NUM-1",
                "requirement_description": "The system shall round an input numerical value (integer, float, or Decimal) to a specified number of decimal places. The result is a float. **Parameters:** `decimals` (integer, default `0`: number of decimal places).",
                "test_traceability": [
                    {
                        "id": "tests/test_numerical_and_date_transforms.py::test_numerical_transforms",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/numerical.py::RoundTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-NUM-2",
                "requirement_description": "The system shall convert an input numerical value by multiplying it with a given exchange `rate`. The result is a float. **Parameters:** `rate` (float: the exchange rate). This parameter is mandatory. A `ValidationError` shall be raised if `rate` is not provided.",
                "test_traceability": [
                    {
                        "id": "tests/test_numerical_and_date_transforms.py::test_numerical_transforms",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/numerical.py::CurrencyConverter",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-NUM-3",
                "requirement_description": "The system shall convert an input numerical value by multiplying it with a given conversion `rate`. The result is a float. **Parameters:** `rate` (float: the conversion rate). This parameter is mandatory. A `ValidationError` shall be raised if `rate` is not provided.",
                "test_traceability": [
                    {
                        "id": "tests/test_numerical_and_date_transforms.py::test_numerical_transforms",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/numerical.py::UnitConverter",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-NUM-4",
                "requirement_description": "The system shall perform a specified arithmetic operation on an input numerical value using a given operand. The result is a float. **Parameters:** `operation` (string: one of 'add', 'subtract', 'multiply', 'divide'). `operand` (number: the second value for the operation). A `ValidationError` shall be raised if division by zero is attempted. An error (e.g., ValueError during param processing or ValidationError) if operation is invalid.",
                "test_traceability": [
                    {
                        "id": "tests/test_numerical_and_date_transforms.py::test_math_operations",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/numerical.py::MathOperationTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-NUM-5",
                "requirement_description": "The system shall convert an input numerical value (representing a decimal fraction) into a percentage by multiplying it by 100.0. The result is a float.",
                "test_traceability": [
                    {
                        "id": "tests/test_numerical_and_date_transforms.py::test_numerical_transforms",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/numerical.py::PercentageCalculator",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-NUM-6",
                "requirement_description": "The system shall extract all sequences of characters that represent numbers (integers or decimals) from an input string. It shall return these as a list of strings.",
                "test_traceability": [
                    {
                        "id": "tests/test_numerical_and_date_transforms.py::test_number_extraction",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/plugins/numerical/__init__.py::ExtractNumbersTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-NUM-7",
                "requirement_description": "The system shall convert an input value to an integer. If the input is a string, it attempts to remove non-digit characters (preserving a leading minus) and then convert. String representations of floating-point numbers are truncated to integer. **Parameters:** `min_value` (integer, optional): If provided, the resulting integer must be greater than or equal to this value. `max_value` (integer, optional): If provided, the resulting integer must be less than or equal to this value. A `ValidationError` shall be raised if conversion fails or if `min_value`/`max_value` constraints are violated.",
                "test_traceability": [
                    {
                        "id": "tests/test_validation_transforms.py::test_type_enforcement",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/numerical.py::IntegerTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-NUM-8",
                "requirement_description": "The system shall convert an input value to a float. If the input is a string, it attempts to remove non-numeric characters (preserving leading minus and one decimal point) and then convert. **Parameters:** `min_value` (float, optional): If provided, the resulting float must be greater than or equal to this value. `max_value` (float, optional): If provided, the resulting float must be less than or equal to this value. A `ValidationError` shall be raised if conversion fails or if `min_value`/`max_value` constraints are violated.",
                "test_traceability": [
                    {
                        "id": "tests/test_validation_transforms.py::test_type_enforcement",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/numerical.py::FloatTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-NUM-9",
                "requirement_description": "The system shall calculate the arithmetic average of a list of numerical values. Input values will be converted to float for calculation. The result shall be a float, rounded to two decimal places. A `ValidationError` shall be raised if the input is not a list or if elements cannot be converted to numbers.",
                "test_traceability": [
                    {
                        "id": "tests/test_json_transforms.py::test_complex_json_pattern",
                        "description": "used for `average_rating`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/base.py::CoreToolsTransformer",
                        "description": "implements 'average' logic"
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-VAL-1",
                "requirement_description": "The system shall validate if an input string conforms to a common email address format (e.g., `local-part@domain-part`). Leading/trailing whitespace from the input string is stripped before validation. **Parameters:** `allowed_domains` (list of strings, optional): If provided, the domain part of the email must match one of the domains in this list. If valid, the transformer returns the stripped email string. If invalid, it returns `None`.",
                "test_traceability": [
                    {
                        "id": "tests/test_validation_transforms.py::test_email_validation",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/validation.py::EmailValidator",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-VAL-2",
                "requirement_description": "The system shall format an input string representing a US-style 10-digit phone number (optionally after stripping a leading '1') into a standard string format. **Parameters:** `format` (string, default `({area}) {prefix}-{line}`: a template for the output, where `{area}`, `{prefix}`, `{line}` are placeholders for parts of the phone number). Digits are extracted from the input. If the number of effective digits is not 10 (after potentially removing a leading '1'), a `ValidationError` is raised.",
                "test_traceability": [
                    {
                        "id": "tests/test_validation_transforms.py::test_phone_formatting",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/validation.py::PhoneFormatter",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-VAL-3",
                "requirement_description": "The system shall validate an input string (representing a credit card number) using the Luhn algorithm. Non-digit characters in the input are ignored for the algorithm's calculation. The number of digits must be between 13 and 19 (inclusive). **Parameters:** `mask` (boolean, default `False`): If `True` and the number is valid, the returned string will have most of its digits masked (e.g., first 4 and last 4 visible, rest are `*`). If valid, returns the original input string (or masked string if `mask` is `True`). If invalid, returns `None`.",
                "test_traceability": [
                    {
                        "id": "tests/test_validation_transforms.py::test_credit_card_validation",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/validation.py::CreditCardValidator",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-VAL-4",
                "requirement_description": "The system shall convert an input value (string or boolean) to a Python boolean (`True` or `False`). For string inputs (case-insensitive, after stripping whitespace): \"true\", \"1\", \"yes\", \"y\", \"t\" convert to `True`. \"false\", \"0\", \"no\", \"n\", \"f\" convert to `False`. If the input is already a Python boolean, it is returned as is. If an input string does not match any recognized boolean representations, `None` is returned.",
                "test_traceability": [
                    {
                        "id": "tests/test_validation_transforms.py::test_boolean_conversion",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/validation.py::BooleanTransformer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PLG-VAL-5",
                "requirement_description": "The system shall attempt to convert an input value to a specified target data type. **Parameters:** `type` (string: the target type). Supported types: `'int'`: Converts to integer. For string input, it attempts float conversion then int (truncation). `'float'`: Converts to float. `'str'`: Converts to string. `'bool'`: Converts to boolean. For non-string, uses Python's truthiness. For string, uses explicit true/false value checks similar to FR-PLG-VAL-4 (e.g., \"1\" is True, \"0\" is False, other numerical strings are True, \"true\" is True, \"false\" is False). `'decimal'`: Converts to Python `Decimal`. A `ValidationError` shall be raised if conversion fails or if the target `type` is not supported.",
                "test_traceability": [
                    {
                        "id": "tests/test_validation_transforms.py::test_type_enforcement",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "tukuy/transformers/validation.py::TypeEnforcer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-1",
                "requirement_description": "The system accepts transformation pipeline definitions as a Python list of strings and/or dictionaries, as detailed in FR-SYS-3.1. This list structure is an external interface for developers defining transformations.",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "EIR-2",
                "requirement_description": "The system accepts patterns for HTML extraction as a Python dictionary, structured according to the rules detailed in FR-PLG-HTML-6 (properties, name, selector, attribute, type, transform, fallback). This dictionary structure is an external interface.",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "EIR-3",
                "requirement_description": "The system accepts patterns for JSON extraction as a Python dictionary, structured according to the rules detailed in FR-PLG-JSON-2 (properties, name, selector, type, transform, fallback). This dictionary structure is an external interface.",
                "test_traceability": [],
                "code_traceability": []
            }
        ],
        "full_code_skeleton": "--- File: examples.py ---\n```python\ndef text_transformation_examples():\n    \"\"\"Examples of text transformations using Tukuy.\"\"\"\n    pass\n\ndef html_transformation_examples():\n    \"\"\"Examples of HTML transformations using Tukuy.\"\"\"\n    pass\n\ndef json_transformation_example():\n    \"\"\"Example of JSON transformations using Tukuy.\"\"\"\n    pass\n\ndef main():\n    \"\"\"Main function to run all examples.\"\"\"\n    pass\n```\n--- File: tukuy/exceptions.py ---\n```python\nclass TransformerError(Exception):\n    \"\"\"Base exception class for all transformer-related errors.\"\"\"\n    def __init__(self, message: str, value: Any = None):\n        pass\n    \n    def __str__(self) -> str:\n        pass\n\nclass ValidationError(TransformerError):\n    \"\"\"Raised when input validation fails.\"\"\"\n    def __str__(self) -> str:\n        pass\n\nclass TransformationError(TransformerError):\n    \"\"\"Raised when a transformation operation fails.\"\"\"\n    def __init__(self, message: str, value: Any = None, transformer_name: Optional[str] = None):\n        pass\n    \n    def __str__(self) -> str:\n        pass\n\nclass ConfigurationError(TransformerError):\n    \"\"\"Raised when transformer configuration is invalid.\"\"\"\n    def __str__(self) -> str:\n        pass\n\nclass PatternError(TransformerError):\n    \"\"\"Raised when a pattern is invalid or malformed.\"\"\"\n    def __str__(self) -> str:\n        pass\n\nclass ExtractorError(TransformerError):\n    \"\"\"Raised when data extraction fails.\"\"\"\n    def __str__(self) -> str:\n        pass\n\nclass ParseError(TransformerError):\n    \"\"\"Raised when parsing operations fail.\"\"\"\n    def __str__(self) -> str:\n        pass\n```\n--- File: tukuy/types.py ---\n```python\nclass TransformResult(Generic[T]):\n    \"\"\"Container for transformation results with error handling.\"\"\"\n    \n    def __init__(self, value: Optional[T] = None, error: Optional[Exception] = None):\n        pass\n\n    @property\n    def failed(self) -> bool:\n        pass\n\n    def __str__(self) -> str:\n        pass\n\n@dataclass\nclass TransformOptions:\n    \"\"\"Base class for transformer options.\"\"\"\n    pass\n\n@dataclass\nclass TextTransformOptions(TransformOptions):\n    \"\"\"Options for text transformations.\"\"\"\n    strip: bool = True\n    case_sensitive: bool = True\n\n@dataclass\nclass DateTransformOptions(TransformOptions):\n    \"\"\"Options for date transformations.\"\"\"\n    format: str = '%Y-%m-%d'\n    timezone: Optional[str] = None\n\n@dataclass\nclass NumberTransformOptions(TransformOptions):\n    \"\"\"Options for number transformations.\"\"\"\n    decimals: int = 2\n    strip_non_numeric: bool = True\n\n@dataclass\nclass PatternOptions(TransformOptions):\n    \"\"\"Options for pattern-based transformations.\"\"\"\n    pattern: str\n    template: Optional[str] = None\n    flags: int = 0\n\n@dataclass\nclass ExtractorOptions(TransformOptions):\n    \"\"\"Options for data extraction.\"\"\"\n    selector: Union[str, Dict[str, Any]]\n    attribute: str = \"text\"\n    fallback: Optional[Union[str, List[str]]] = None\n\nclass TransformerProtocol(Protocol[T, U]):\n    \"\"\"Protocol defining the interface for transformers.\"\"\"\n    \n    @property\n    def name(self) -> str:\n        \"\"\"Get the transformer name.\"\"\"\n        pass\n    \n    def transform(self, value: T, context: Optional[TransformContext] = None) -> TransformResult[U]:\n        \"\"\"\n        Transform the input value according to the transformer's rules.\n        \n        Args:\n            value: The input value to transform\n            context: Optional context for the transformation\n            \n        Returns:\n            TransformResult containing either the transformed value or an error\n        \"\"\"\n        pass\n\n    def validate(self, value: T) -> bool:\n        \"\"\"\n        Validate the input value.\n        \n        Args:\n            value: The input value to validate\n            \n        Returns:\n            True if the value is valid for this transformer, False otherwise\n        \"\"\"\n        pass\n        \n    def get_validation_errors(self, value: T) -> List[str]:\n        \"\"\"\n        Get list of validation errors for the input value.\n        \n        Args:\n            value: The input value to validate\n            \n        Returns:\n            List of validation error messages, empty if valid\n        \"\"\"\n        pass\n\nclass ExtractorProtocol(Protocol):\n    \"\"\"Protocol defining the interface for data extractors.\"\"\"\n    \n    def extract_data(self, data: Any, pattern: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Extract data according to the given pattern.\n        \n        Args:\n            data: The data to extract from (HTML, JSON, etc.)\n            pattern: The pattern describing what to extract\n            \n        Returns:\n            Dictionary of extracted data\n        \"\"\"\n        pass\n        \n    def extract_property(self, data: Any, property_def: Dict[str, Any]) -> Any:\n        \"\"\"\n        Extract a single property from data.\n        \n        Args:\n            data: The data to extract from\n            property_def: The property definition\n            \n        Returns:\n            The extracted property value\n        \"\"\"\n        pass\n\nclass ValidatorProtocol(Protocol[T]):\n    \"\"\"Protocol defining the interface for validators.\"\"\"\n    \n    def validate(self, value: T) -> bool:\n        \"\"\"\n        Validate the input value.\n        \n        Args:\n            value: The input value to validate\n            \n        Returns:\n            True if the value is valid, False otherwise\n        \"\"\"\n        pass\n\n    def get_validation_errors(self, value: T) -> List[str]:\n        \"\"\"\n        Get list of validation errors for the input value.\n        \n        Args:\n            value: The input value to validate\n            \n        Returns:\n            List of validation error messages, empty if valid\n        \"\"\"\n        pass\n        \n    def validate_with_context(self, value: T, context: Dict[str, Any]) -> bool:\n        \"\"\"\n        Validate the input value with additional context.\n        \n        Args:\n            value: The input value to validate\n            context: Additional context for validation\n            \n        Returns:\n            True if the value is valid, False otherwise\n        \"\"\"\n        pass\n\nclass PluginProtocol(Protocol):\n    \"\"\"Protocol defining the interface for plugins.\"\"\"\n    \n    @property\n    def name(self) -> str:\n        \"\"\"Get the plugin name.\"\"\"\n        pass\n        \n    @property\n    def transformers(self) -> Dict[str, Any]:\n        \"\"\"Get the transformers provided by this plugin.\"\"\"\n        pass\n        \n    def initialize(self) -> None:\n        \"\"\"Initialize the plugin.\"\"\"\n        pass\n        \n    def cleanup(self) -> None:\n        \"\"\"Clean up the plugin.\"\"\"\n        pass\n        \n    def get_transformer(self, name: str, params: Dict[str, Any]) -> Optional[TransformerProtocol]:\n        \"\"\"\n        Get a transformer by name with the given parameters.\n        \n        Args:\n            name: The transformer name\n            params: Parameters for the transformer\n            \n        Returns:\n            The transformer instance or None if not found\n        \"\"\"\n        pass\n```\n--- File: tukuy/base.py ---\n```python\nclass BaseTransformer(Generic[T, U], ABC):\n    \"\"\"\n    Abstract base class for all transformers.\n    \n    Provides common functionality and defines the interface that all transformers\n    must implement.\n    \n    Type Parameters:\n        T: The input type that this transformer accepts\n        U: The output type that this transformer produces\n    \"\"\"\n    \n    def __init__(self, name: str, options: Optional[TransformOptions] = None):\n        \"\"\"\n        Initialize the transformer.\n        \n        Args:\n            name: Unique identifier for this transformer\n            options: Configuration options for this transformer\n        \"\"\"\n        pass\n    \n    def _validate_options(self) -> None:\n        \"\"\"Validate the transformer options.\"\"\"\n        pass\n    \n    @abstractmethod\n    def validate(self, value: T) -> bool:\n        \"\"\"\n        Validate the input value.\n        \n        Args:\n            value: The value to validate\n            \n        Returns:\n            bool: True if valid, False otherwise\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def _transform(self, value: T, context: Optional[TransformContext] = None) -> U:\n        \"\"\"\n        Internal transformation method that subclasses must implement.\n        \n        Args:\n            value: The value to transform\n            context: Optional context data for the transformation\n            \n        Returns:\n            The transformed value\n            \n        Raises:\n            TransformationError: If the transformation fails\n        \"\"\"\n        pass\n    \n    def transform(self, value: T, context: Optional[TransformContext] = None, **kwargs) -> TransformResult[U]:\n        \"\"\"\n        Public method to transform a value with error handling.\n        \n        Args:\n            value: The value to transform\n            context: Optional context data for the transformation\n            **kwargs: Additional keyword arguments for the transformation\n            \n        Returns:\n            TransformResult containing either the transformed value or an error\n        \"\"\"\n        pass\n    \n    def __str__(self) -> str:\n        pass\n    \n    def __repr__(self) -> str:\n        pass\n\nclass ChainableTransformer(BaseTransformer[T, U]):\n    \"\"\"\n    A transformer that can be chained with other transformers.\n    \n    Allows for creating pipelines of transformations where the output of one\n    transformer becomes the input to the next.\n    \"\"\"\n    \n    def __init__(\n        self,\n        name: str,\n        next_transformer: Optional[BaseTransformer] = None,\n        options: Optional[TransformOptions] = None\n    ):\n        pass\n    \n    def chain(self, next_transformer: BaseTransformer) -> 'ChainableTransformer':\n        \"\"\"\n        Chain this transformer with another transformer.\n        \n        Args:\n            next_transformer: The next transformer in the chain\n            \n        Returns:\n            self for method chaining\n        \"\"\"\n        pass\n    \n    def transform(self, value: T, context: Optional[TransformContext] = None, **kwargs) -> TransformResult:\n        \"\"\"\n        Transform the value and pass it through the chain.\n        \n        Args:\n            value: The value to transform\n            context: Optional context data for the transformation\n            **kwargs: Additional keyword arguments for the transformation\n            \n        Returns:\n            TransformResult containing either the final transformed value or an error\n        \"\"\"\n        pass\n\nclass CompositeTransformer(BaseTransformer[T, U]):\n    \"\"\"\n    A transformer that combines multiple transformers into a single unit.\n    \n    Useful for creating complex transformations from simpler ones.\n    \"\"\"\n    \n    def __init__(\n        self,\n        name: str,\n        transformers: List[BaseTransformer],\n        options: Optional[TransformOptions] = None\n    ):\n        pass\n    \n    def validate(self, value: Any) -> bool:\n        \"\"\"Validate input through all contained transformers.\"\"\"\n        pass\n    \n    def _transform(self, value: Any, context: Optional[TransformContext] = None) -> Any:\n        \"\"\"Apply all transformations in sequence.\"\"\"\n        pass\n\nclass RegexTransformer(ChainableTransformer[str, str]):\n    \"\"\"Apply regex pattern to text.\"\"\"\n    \n    def __init__(self, name: str, pattern: str, template: Optional[str] = None):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass ReplaceTransformer(ChainableTransformer[str, str]):\n    \"\"\"Replace text.\"\"\"\n    \n    def __init__(self, name: str, old: str, new: str):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass CoreToolsTransformer(BaseTransformer[Any, Any]):\n    \"\"\"\n    Coordinates the application of multiple transformations using existing transformers.\n    \n    This transformer takes a value and a list of transform operations, creates the\n    appropriate transformers, and chains them together to produce the final result.\n    \"\"\"\n    \n    def __init__(self):\n        pass\n        \n    def validate(self, value: Any) -> bool:\n        pass\n        \n    def _transform(self, value: Any, transforms: List[Dict[str, Any]]) -> Any:\n        pass\n```\n--- File: tukuy/transformers/validation.py ---\n```python\nclass BooleanTransformer(ChainableTransformer[str, bool]):\n    \"\"\"Convert string to boolean.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: Any, context: Optional[TransformContext] = None) -> Optional[bool]:\n        pass\n\nclass EmailValidator(ChainableTransformer[str, str]):\n    \"\"\"Validate email address.\"\"\"\n    \n    def __init__(self, name: str, allowed_domains: Optional[list] = None):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> Optional[str]:\n        pass\n\nclass PhoneFormatter(ChainableTransformer[str, str]):\n    \"\"\"Format phone number.\"\"\"\n    \n    def __init__(self, name: str, format: str = '({area}) {prefix}-{line}'):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass CreditCardValidator(ChainableTransformer[str, str]):\n    \"\"\"Validate credit card number using Luhn algorithm.\"\"\"\n    \n    def __init__(self, name: str, mask: bool = False):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> Optional[str]:\n        pass\n\nclass TypeEnforcer(ChainableTransformer[Any, Any]):\n    \"\"\"Enforce type conversion.\"\"\"\n    \n    def __init__(self, name: str, target_type: str):\n        pass\n    \n    def validate(self, value: Any) -> bool:\n        pass\n    \n    def _transform(self, value: Any, context: Optional[TransformContext] = None) -> Any:\n        pass\n```\n--- File: tukuy/transformers/html.py ---\n```python\nclass StripHtmlTagsTransformer(ChainableTransformer[str, str]):\n    \"\"\"Strip HTML tags from text.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass HtmlSanitizationTransformer(ChainableTransformer[str, str]):\n    \"\"\"Sanitize HTML by removing script and style tags.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass LinkExtractionTransformer(ChainableTransformer[str, List[str]]):\n    \"\"\"Extract links from HTML.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> List[str]:\n        pass\n\nclass ResolveUrlTransformer(ChainableTransformer[str, str]):\n    \"\"\"Resolve relative URL to absolute URL.\"\"\"\n    \n    def __init__(self, name: str, base_url: str):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass ExtractDomainTransformer(ChainableTransformer[str, str]):\n    \"\"\"Extract domain from URL.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass HtmlExtractor(ChainableTransformer[str, Dict[str, Any]]):\n    \"\"\"Extract data from HTML using a pattern.\"\"\"\n    \n    def __init__(self, name: str, pattern: Dict[str, Any]):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> Dict[str, Any]:\n        pass\n    \n    def _extract_property(self, soup: BeautifulSoup, prop: Dict[str, Any], context: Optional[TransformContext] = None) -> Any:\n        \"\"\"Extract a property from HTML using the property pattern.\"\"\"\n        pass\n    \n    def _select_elements(self, soup: BeautifulSoup, primary: str, fallback: List[str]) -> List[Any]:\n        \"\"\"Select elements using primary selector or fallbacks.\"\"\"\n        pass\n    \n    def _select_element(self, soup: BeautifulSoup, primary: str, fallback: List[str]) -> Optional[Any]:\n        \"\"\"Select a single element using primary selector or fallbacks.\"\"\"\n        pass\n    \n    def _get_element_value(self, element: Any, attribute: str) -> str:\n        \"\"\"Get value from element based on attribute.\"\"\"\n        pass\n    \n    def _extract_nested_property(self, element: Any, prop: Dict[str, Any], context: Optional[TransformContext] = None) -> Any:\n        \"\"\"Extract a nested property from an element.\"\"\"\n        pass\n    \n    def _process_object(self, element: Any, properties: List[Dict[str, Any]], context: Optional[TransformContext] = None) -> Dict[str, Any]:\n        \"\"\"Process an object with properties.\"\"\"\n        pass\n    \n    def _apply_transforms(self, value: str, transforms: List[Any], context: Optional[TransformContext] = None) -> Any:\n        \"\"\"Apply transforms to a value.\"\"\"\n        pass\n```\n--- File: tukuy/transformers/numerical.py ---\n```python\nclass IntegerTransformer(ChainableTransformer[str, int]):\n    \"\"\"Convert value to integer.\"\"\"\n    \n    def __init__(self, name: str, min_value: Optional[int] = None, max_value: Optional[int] = None):\n        pass\n    \n    def validate(self, value: Any) -> bool:\n        pass\n    \n    def _transform(self, value: Any, context: Optional[TransformContext] = None) -> int:\n        pass\n\nclass FloatTransformer(ChainableTransformer[str, float]):\n    \"\"\"Convert value to float.\"\"\"\n    \n    def __init__(self, name: str, min_value: Optional[float] = None, max_value: Optional[float] = None):\n        pass\n    \n    def validate(self, value: Any) -> bool:\n        pass\n    \n    def _transform(self, value: Any, context: Optional[TransformContext] = None) -> float:\n        pass\n\nclass RoundTransformer(ChainableTransformer[Union[int, float, Decimal], float]):\n    \"\"\"Round a number to specified number of decimal places.\"\"\"\n    \n    def __init__(self, name: str, decimals: int = 0):\n        pass\n    \n    def validate(self, value: Any) -> bool:\n        pass\n    \n    def _transform(self, value: Union[int, float, Decimal], context: Optional[TransformContext] = None) -> float:\n        pass\n\nclass CurrencyConverter(ChainableTransformer[Union[int, float, Decimal], float]):\n    \"\"\"Convert currency using exchange rate.\"\"\"\n    \n    def __init__(self, name: str, rate: Optional[float] = None):\n        pass\n    \n    def validate(self, value: Any) -> bool:\n        pass\n    \n    def _transform(self, value: Union[int, float, Decimal], context: Optional[TransformContext] = None) -> float:\n        pass\n\nclass UnitConverter(ChainableTransformer[Union[int, float, Decimal], float]):\n    \"\"\"Convert units using conversion rate.\"\"\"\n    \n    def __init__(self, name: str, rate: Optional[float] = None):\n        pass\n    \n    def validate(self, value: Any) -> bool:\n        pass\n    \n    def _transform(self, value: Union[int, float, Decimal], context: Optional[TransformContext] = None) -> float:\n        pass\n\nclass MathOperationTransformer(ChainableTransformer[Union[int, float, Decimal], float]):\n    \"\"\"Perform math operation on a value.\"\"\"\n    \n    def __init__(self, name: str, operation: str = 'add', operand: Union[int, float, Decimal] = 0):\n        pass\n    \n    def validate(self, value: Any) -> bool:\n        pass\n    \n    def _transform(self, value: Union[int, float, Decimal], context: Optional[TransformContext] = None) -> float:\n        pass\n\nclass PercentageCalculator(ChainableTransformer[Union[int, float, Decimal], float]):\n    \"\"\"Convert decimal to percentage.\"\"\"\n    \n    def validate(self, value: Any) -> bool:\n        pass\n    \n    def _transform(self, value: Union[int, float, Decimal], context: Optional[TransformContext] = None) -> float:\n        pass\n```\n--- File: tukuy/transformers/text.py ---\n```python\nclass StripTransformer(ChainableTransformer[str, str]):\n    \"\"\"Strip whitespace from text.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass LowercaseTransformer(ChainableTransformer[str, str]):\n    \"\"\"Convert text to lowercase.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass UppercaseTransformer(ChainableTransformer[str, str]):\n    \"\"\"Convert text to uppercase.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass TemplateTransformer(ChainableTransformer[str, str]):\n    \"\"\"Apply template to regex match.\"\"\"\n    \n    def __init__(self, name: str, template: str):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass MapTransformer(ChainableTransformer[str, str]):\n    \"\"\"Map values using a dictionary.\"\"\"\n    \n    def __init__(self, name: str, mapping: Dict[str, str], default: Optional[str] = None):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass SplitTransformer(ChainableTransformer[str, str]):\n    \"\"\"Split text and return specific part.\"\"\"\n    \n    def __init__(self, name: str, delimiter: str = ':', index: int = -1):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass TitleCaseTransformer(ChainableTransformer[str, str]):\n    \"\"\"Convert text to title case.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass CamelCaseTransformer(ChainableTransformer[str, str]):\n    \"\"\"Convert text to camel case.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass SnakeCaseTransformer(ChainableTransformer[str, str]):\n    \"\"\"Convert text to snake case.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass SlugifyTransformer(ChainableTransformer[str, str]):\n    \"\"\"Convert text to URL-friendly slug.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass TruncateTransformer(ChainableTransformer[str, str]):\n    \"\"\"Truncate text to specified length.\"\"\"\n    \n    def __init__(self, name: str, length: int = 50, suffix: str = '...'):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass RemoveEmojisTransformer(ChainableTransformer[str, str]):\n    \"\"\"Remove emojis from text.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass RedactSensitiveTransformer(ChainableTransformer[str, str]):\n    \"\"\"Redact sensitive information like credit card numbers.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n```\n--- File: tukuy/transformers/json.py ---\n```python\nclass JsonParser(ChainableTransformer[str, JsonType]):\n    \"\"\"\n    Parses JSON strings into Python objects.\n    \n    Features:\n    - Strict/lenient parsing modes\n    - Schema validation\n    - Error handling with detailed messages\n    \"\"\"\n    \n    def __init__(\n        self,\n        name: str,\n        strict: bool = True,\n        schema: Optional[Dict[str, Any]] = None\n    ):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        \"\"\"\n        Validate that the input is a JSON string.\n        \n        In the validate method, we just check if the input is a string.\n        Actual JSON validity and schema validation is performed in _transform.\n        \"\"\"\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> JsonType:\n        \"\"\"\n        Transform a JSON string into a Python object.\n        \n        Args:\n            value: A JSON string\n            context: Optional transformation context\n            \n        Returns:\n            Parsed JSON data\n            \n        Raises:\n            ParseError: If the JSON string is invalid and strict=True\n            ValidationError: If the JSON data does not match the schema\n        \"\"\"\n        pass\n    \n    def _validate_schema(self, data: Any, schema: Dict[str, Any]) -> bool:\n        \"\"\"Simple schema validation.\"\"\"\n        pass\n\nclass JsonExtractor(BaseTransformer[JsonType, Any]):\n    \"\"\"\n    Extracts data from JSON structures using patterns.\n    \n    Features:\n    - JSONPath-like syntax for data extraction\n    - Nested property access\n    - Array operations\n    - Default values\n    \"\"\"\n    \n    def __init__(\n        self,\n        name: str,\n        pattern: Pattern,\n        default: Any = None\n    ):\n        pass\n    \n    def validate(self, value: JsonType) -> bool:\n        pass\n    \n    def _transform(self, value: JsonType, context: Optional[TransformContext] = None) -> Any:\n        pass\n    \n    def _extract_data(self, data: JsonType, pattern: Pattern) -> Any:\n        \"\"\"Extract data according to the pattern.\"\"\"\n        pass\n    \n    def _get_value(self, data: JsonType, path: Optional[str]) -> Optional[Any]:\n        \"\"\"Get a value using a path expression.\"\"\"\n        pass\n    \n    def _get_array_values(self, data: JsonType, path: Optional[str]) -> List[Any]:\n        \"\"\"Get array values using a path expression.\"\"\"\n        pass\n```\n--- File: tukuy/transformers/date.py ---\n```python\nclass DateTransformer(ChainableTransformer[str, datetime]):\n    \"\"\"Parse date string into datetime object.\"\"\"\n    \n    def __init__(self, name: str, format: str = '%Y-%m-%d'):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> datetime:\n        pass\n\nclass TimezoneTransformer(ChainableTransformer[datetime, datetime]):\n    \"\"\"Convert datetime between timezones.\"\"\"\n    \n    def __init__(self, name: str, to_zone: str, from_zone: Optional[str] = None):\n        pass\n    \n    def validate(self, value: datetime) -> bool:\n        pass\n    \n    def _transform(self, value: datetime, context: Optional[TransformContext] = None) -> datetime:\n        pass\n\nclass DurationCalculator(ChainableTransformer[str, int]):\n    \"\"\"Calculate duration between dates.\"\"\"\n    \n    def __init__(self, name: str, unit: str = 'days', format: str = '%Y-%m-%d', end: Optional[str] = None):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> int:\n        pass\n\nclass AgeCalculator(ChainableTransformer[str, int]):\n    \"\"\"Calculate age from birth date.\"\"\"\n    \n    def __init__(self, name: str, reference_date: Optional[date] = None):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> int:\n        pass\n```\n--- File: tukuy/plugins/base.py ---\n```python\nclass TransformerPlugin(ABC):\n    \"\"\"\n    Base class for transformer plugins.\n    \n    A plugin is a collection of related transformers that can be registered\n    with the TukuyTransformer. Plugins provide a way to organize transformers\n    into logical groups and manage their lifecycle.\n    \"\"\"\n    \n    def __init__(self, name: str):\n        \"\"\"\n        Initialize the plugin.\n        \n        Args:\n            name: Unique identifier for this plugin\n        \"\"\"\n        pass\n        \n    @property\n    @abstractmethod\n    def transformers(self) -> Dict[str, callable]:\n        \"\"\"\n        Get the transformers provided by this plugin.\n        \n        Returns:\n            A dictionary mapping transformer names to factory functions\n        \"\"\"\n        pass\n        \n    def initialize(self) -> None:\n        \"\"\"\n        Called when the plugin is loaded.\n        \n        Override this method to perform any setup required by the plugin.\n        \"\"\"\n        pass\n        \n    def cleanup(self) -> None:\n        \"\"\"\n        Called when the plugin is unloaded.\n        \n        Override this method to perform any cleanup required by the plugin.\n        \"\"\"\n        pass\n\nclass PluginRegistry:\n    \"\"\"\n    Registry for managing transformer plugins.\n    \n    The registry maintains the collection of loaded plugins and their\n    transformers, handling registration, unregistration, and access to\n    transformer factories.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize an empty plugin registry.\"\"\"\n        pass\n        \n    def register(self, plugin: TransformerPlugin) -> None:\n        \"\"\"\n        Register a plugin with the registry.\n        \n        Args:\n            plugin: The plugin to register\n            \n        Raises:\n            ValueError: If a plugin with the same name is already registered\n        \"\"\"\n        pass\n        \n    def unregister(self, name: str) -> None:\n        \"\"\"\n        Unregister a plugin from the registry.\n        \n        Args:\n            name: Name of the plugin to unregister\n        \"\"\"\n        pass\n        \n    def get_transformer(self, name: str) -> Optional[callable]:\n        \"\"\"\n        Get a transformer factory by name.\n        \n        Args:\n            name: Name of the transformer\n            \n        Returns:\n            The transformer factory function, or None if not found\n        \"\"\"\n        pass\n        \n    def get_plugin(self, name: str) -> Optional[TransformerPlugin]:\n        \"\"\"\n        Get a plugin by name.\n        \n        Args:\n            name: Name of the plugin\n            \n        Returns:\n            The plugin instance, or None if not found\n        \"\"\"\n        pass\n        \n    @property\n    def plugins(self) -> Dict[str, TransformerPlugin]:\n        \"\"\"Get all registered plugins.\"\"\"\n        pass\n        \n    @property\n    def transformers(self) -> Dict[str, callable]:\n        \"\"\"Get all registered transformers.\"\"\"\n        pass\n```\n--- File: tukuy/plugins/text/__init__.py ---\n```python\nclass TextTransformersPlugin(TransformerPlugin):\n    \"\"\"Plugin providing text transformation capabilities.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the text transformers plugin.\"\"\"\n        pass\n        \n    @property\n    def transformers(self):\n        \"\"\"Get the text transformers.\"\"\"\n        pass\n        \n    def initialize(self) -> None:\n        \"\"\"Initialize the text transformers plugin.\"\"\"\n        pass\n        \n    def cleanup(self) -> None:\n        \"\"\"Clean up the text transformers plugin.\"\"\"\n        pass\n```\n--- File: tukuy/plugins/example/__init__.py ---\n```python\nclass ReverseTransformer(ChainableTransformer[str, str]):\n    \"\"\"Example transformer that reverses text.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass CountWordsTransformer(ChainableTransformer[str, int]):\n    \"\"\"Example transformer that counts words in text.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> int:\n        pass\n\nclass FindPatternTransformer(ChainableTransformer[str, list]):\n    \"\"\"Example transformer that finds all occurrences of a pattern.\"\"\"\n    \n    def __init__(self, name: str, pattern: str):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> list:\n        pass\n\nclass ExamplePlugin(TransformerPlugin):\n    \"\"\"\n    Example plugin demonstrating plugin creation.\n    \n    This plugin provides simple text manipulation transformers as an example\n    of how to create custom plugins. Use this as a template for creating\n    your own plugins.\n    \n    Example usage:\n        from tukuy import TukuyTransformer\n        from tukuy.plugins.example import ExamplePlugin\n        \n        # Create transformer\n        TUKUY = TukuyTransformer()\n        \n        # Register plugin\n        TUKUY.register_plugin(ExamplePlugin())\n        \n        # Use transformers\n        text = \"Hello World\"\n        \n        # Reverse text\n        reversed_text = TUKUY.transform(text, [\"reverse\"])  # \"dlroW olleH\"\n        \n        # Count words\n        word_count = TUKUY.transform(text, [\"count_words\"])  # 2\n        \n        # Find patterns\n        patterns = TUKUY.transform(text, [{\n            \"function\": \"find_pattern\",\n            \"pattern\": r\"\\w+\"\n        }])  # [\"Hello\", \"World\"]\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the example plugin.\"\"\"\n        pass\n        \n    @property\n    def transformers(self):\n        \"\"\"Get the example transformers.\"\"\"\n        pass\n        \n    def initialize(self) -> None:\n        \"\"\"Initialize the example plugin.\"\"\"\n        pass\n        \n    def cleanup(self) -> None:\n        \"\"\"Clean up the example plugin.\"\"\"\n        pass\n```\n--- File: tukuy/plugins/html/__init__.py ---\n```python\nclass UrlJoinTransformer(ChainableTransformer[str, str]):\n    \"\"\"Joins URLs using urllib.parse.urljoin.\"\"\"\n    \n    def __init__(self, name: str, base_url: str):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: TransformContext = None) -> str:\n        pass\n\nclass ExtractDomainTransformer(ChainableTransformer[str, str]):\n    \"\"\"Extracts domain from URL.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: TransformContext = None) -> str:\n        pass\n\nclass HtmlTransformersPlugin(TransformerPlugin):\n    \"\"\"Plugin providing HTML transformation capabilities.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the HTML transformers plugin.\"\"\"\n        pass\n        \n    @property\n    def transformers(self):\n        \"\"\"Get the HTML transformers.\"\"\"\n        pass\n```\n--- File: tukuy/plugins/json/__init__.py ---\n```python\nclass JsonTransformersPlugin(TransformerPlugin):\n    \"\"\"Plugin providing JSON transformation capabilities.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the JSON transformers plugin.\"\"\"\n        pass\n        \n    @property\n    def transformers(self):\n        \"\"\"Get the JSON transformers.\"\"\"\n        pass\n        \n    def initialize(self) -> None:\n        \"\"\"Initialize the JSON transformers plugin.\"\"\"\n        pass\n        \n    def cleanup(self) -> None:\n        \"\"\"Clean up the JSON transformers plugin.\"\"\"\n        pass\n```\n--- File: tukuy/plugins/numerical/__init__.py ---\n```python\nclass ExtractNumbersTransformer(ChainableTransformer[str, list]):\n    \"\"\"Extracts all numbers from text.\"\"\"\n    \n    def __init__(self, name: str):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: TransformContext = None) -> list:\n        pass\n\nclass NumericalTransformersPlugin(TransformerPlugin):\n    \"\"\"Plugin providing numerical transformation capabilities.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the numerical transformers plugin.\"\"\"\n        pass\n        \n    @property\n    def transformers(self):\n        \"\"\"Get the numerical transformers.\"\"\"\n        pass\n        \n    def initialize(self) -> None:\n        \"\"\"Initialize the numerical transformers plugin.\"\"\"\n        pass\n        \n    def cleanup(self) -> None:\n        \"\"\"Clean up the numerical transformers plugin.\"\"\"\n        pass\n```\n--- File: tukuy/plugins/validation/__init__.py ---\n```python\nclass ValidationTransformersPlugin(TransformerPlugin):\n    \"\"\"Plugin providing validation transformation capabilities.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the validation transformers plugin.\"\"\"\n        pass\n        \n    @property\n    def transformers(self):\n        \"\"\"Get the validation transformers.\"\"\"\n        pass\n        \n    def initialize(self) -> None:\n        \"\"\"Initialize the validation transformers plugin.\"\"\"\n        pass\n        \n    def cleanup(self) -> None:\n        \"\"\"Clean up the validation transformers plugin.\"\"\"\n        pass\n```\n--- File: tukuy/plugins/date/__init__.py ---\n```python\nclass DateTransformersPlugin(TransformerPlugin):\n    \"\"\"Plugin providing date transformation capabilities.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the date transformers plugin.\"\"\"\n        pass\n        \n    @property\n    def transformers(self):\n        \"\"\"Get the date transformers.\"\"\"\n        pass\n        \n    def initialize(self) -> None:\n        \"\"\"Initialize the date transformers plugin.\"\"\"\n        pass\n        \n    def cleanup(self) -> None:\n        \"\"\"Clean up the date transformers plugin.\"\"\"\n        pass\n```",
        "minimal_code_skeleton": "--- File: tukuy/exceptions.py ---\n```python\nfrom typing import Any, Optional\n\nclass TransformerError(Exception):\n    \"\"\"Base exception class for all transformer-related errors.\"\"\"\n    def __init__(self, message: str, value: Any = None):\n        \"\"\"\n        Initialize the TransformerError.\n        \n        Args:\n            message: The error message.\n            value: The value that caused the error, if applicable.\n        \"\"\"\n        pass\n    \n    def __str__(self) -> str:\n        pass\n\nclass ValidationError(TransformerError):\n    \"\"\"Raised when input validation fails.\"\"\"\n    def __init__(self, message: str, value: Any = None): # Added for completeness, though tests might only rely on superclass if not overridden\n        \"\"\"\n        Initialize the ValidationError.\n        \n        Args:\n            message: The error message.\n            value: The value that caused the error, if applicable.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        pass\n\nclass TransformationError(TransformerError):\n    \"\"\"Raised when a transformation operation fails.\"\"\"\n    def __init__(self, message: str, value: Any = None, transformer_name: Optional[str] = None):\n        \"\"\"\n        Initialize the TransformationError.\n        \n        Args:\n            message: The error message.\n            value: The value that caused the error, if applicable.\n            transformer_name: The name of the transformer that failed.\n        \"\"\"\n        pass\n    \n    def __str__(self) -> str:\n        pass\n\nclass ParseError(TransformerError):\n    \"\"\"Raised when parsing operations fail.\"\"\"\n    def __init__(self, message: str, value: Any = None): # Added for completeness\n        \"\"\"\n        Initialize the ParseError.\n        \n        Args:\n            message: The error message.\n            value: The value that caused the error, if applicable.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        pass\n```\n--- File: tukuy/transformers/__init__.py ---\n```python\nfrom typing import Any, Dict, List, Optional, Union\n\n# Forward declaration for JsonType, which would typically be defined in tukuy.types\n# For the purpose of this skeleton, the user will need to define or import it.\n# Example definition: JsonType = Union[Dict[str, Any], List[Any], str, int, float, bool, None]\nJsonType = Any # Placeholder if actual definition is not included as per rules\n\nclass TukuyTransformer:\n    \"\"\"\n    Main transformer class that provides access to all transformation tools.\n    \n    This class serves as the main entry point for the transformation library,\n    providing a unified interface to all available transformers through a plugin system.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the transformer registry.\"\"\"\n        pass\n    \n    def transform(self, value: Any, transforms: List[Union[str, Dict[str, Any]]]) -> Any:\n        \"\"\"\n        Transform a value using a sequence of transformations.\n        \n        Args:\n            value: The value to transform\n            transforms: List of transformations to apply. Each item can be:\n                - a string (the transformer name)\n                - a dict with 'function' key and additional parameters\n                \n        Returns:\n            The transformed value\n            \n        Raises:\n            TransformationError: If any transformation fails\n            ParseError: If JSON parsing fails in strict mode\n            ValidationError: If schema validation fails\n        \"\"\"\n        pass\n    \n    def extract_html_with_pattern(self, html: str, pattern: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract data from HTML using a pattern.\"\"\"\n        pass\n    \n    def extract_property_from_html(self, html: str, prop: Dict[str, Any]) -> Any:\n        \"\"\"Extract a single property from HTML.\"\"\"\n        pass\n    \n    def extract_json_with_pattern(self, json_data: str, pattern: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract data from JSON using a pattern.\"\"\"\n        pass\n\n    def extract_property_from_json(self, json_data: Union[str, JsonType], prop: Dict[str, Any]) -> Any:\n        \"\"\"Extract a single property from JSON data.\n        \n        Args:\n            json_data: JSON string or already parsed JSON data\n            prop: Property extraction pattern\n            \n        Returns:\n            The extracted property value\n            \n        Raises:\n            ValidationError: If JSON plugin is not loaded\n            ParseError: If JSON string is invalid\n            TransformationError: If extraction fails\n        \"\"\"\n        pass\n```",
        "minimal_test_cases": [
            {
                "test_id": "tests/test_html_transforms.py::test_complex_pattern_extraction",
                "covers": [
                    "tukuy.TukuyTransformer.extract_html_with_pattern - happy path for complex HTML data extraction using patterns"
                ]
            },
            {
                "test_id": "tests/test_html_transforms.py::test_extract_property_from_html",
                "covers": [
                    "tukuy.TukuyTransformer.extract_property_from_html - happy path for single HTML property extraction (demonstrates use of 'strip' and 'strip_html_tags' transforms within property definition)"
                ]
            },
            {
                "test_id": "tests/test_json_transforms.py::test_complex_json_pattern",
                "covers": [
                    "tukuy.TukuyTransformer.extract_json_with_pattern - happy path for complex JSON data extraction using patterns (demonstrates nested properties, arrays, and transforms like regex, replace)",
                    "tukuy.TukuyTransformer.transform - usage of 'average' calculation (exercised within a JSON extraction pattern)"
                ]
            },
            {
                "test_id": "tests/test_json_transforms.py::test_extract_property_from_json",
                "covers": [
                    "tukuy.TukuyTransformer.extract_property_from_json - happy path for single JSON property extraction (demonstrates use of 'regex' transform within property definition)"
                ]
            },
            {
                "test_id": "tests/test_text_transforms.py::test_basic_text_transforms",
                "covers": [
                    "tukuy.TukuyTransformer.transform - using 'strip' text transform (happy path)",
                    "tukuy.TukuyTransformer.transform - using 'lowercase' text transform (happy path)",
                    "tukuy.TukuyTransformer.transform - using 'uppercase' text transform (happy path)",
                    "tukuy.TukuyTransformer.transform - using 'title_case' text transform (happy path)",
                    "tukuy.TukuyTransformer.transform - using 'camel_case' text transform (happy path)",
                    "tukuy.TukuyTransformer.transform - using 'snake_case' text transform (happy path)"
                ]
            },
            {
                "test_id": "tests/test_text_transforms.py::test_slugify",
                "covers": [
                    "tukuy.TukuyTransformer.transform - using 'slugify' text transform (happy path)"
                ]
            },
            {
                "test_id": "tests/test_text_transforms.py::test_text_replacements",
                "covers": [
                    "tukuy.TukuyTransformer.transform - using 'replace' text transform (happy path)"
                ]
            },
            {
                "test_id": "tests/test_text_transforms.py::test_template_transform",
                "covers": [
                    "tukuy.TukuyTransformer.transform - using 'regex' text transform with a template (happy path)"
                ]
            },
            {
                "test_id": "tests/test_text_transforms.py::test_chained_text_transforms",
                "covers": [
                    "tukuy.TukuyTransformer.transform - demonstrating chained text transforms (happy path)",
                    "tukuy.TukuyTransformer.transform - using 'truncate' text transform (happy path)"
                ]
            },
            {
                "test_id": "tests/test_numerical_and_date_transforms.py::test_numerical_transforms",
                "covers": [
                    "tukuy.TukuyTransformer.transform - using 'round' numerical transform (happy path)",
                    "tukuy.TukuyTransformer.transform - using 'currency_convert' numerical transform (happy path)",
                    "tukuy.TukuyTransformer.transform - using 'unit_convert' numerical transform (happy path)",
                    "tukuy.TukuyTransformer.transform - using 'percentage_calc' numerical transform (happy path)"
                ]
            },
            {
                "test_id": "tests/test_numerical_and_date_transforms.py::test_math_operations",
                "covers": [
                    "tukuy.TukuyTransformer.transform - using 'math_operation' numerical transform (happy path)"
                ]
            },
            {
                "test_id": "tests/test_numerical_and_date_transforms.py::test_number_extraction",
                "covers": [
                    "tukuy.TukuyTransformer.transform - using 'extract_numbers' numerical transform (happy path)"
                ]
            },
            {
                "test_id": "tests/test_numerical_and_date_transforms.py::test_date_transforms",
                "covers": [
                    "tukuy.TukuyTransformer.transform - using 'date' parsing transform (happy path)"
                ]
            },
            {
                "test_id": "tests/test_numerical_and_date_transforms.py::test_age_calculation",
                "covers": [
                    "tukuy.TukuyTransformer.transform - using 'age_calc' date transform (happy path)"
                ]
            },
            {
                "test_id": "tests/test_numerical_and_date_transforms.py::test_duration_calculation",
                "covers": [
                    "tukuy.TukuyTransformer.transform - using 'duration_calc' date transform (happy path)"
                ]
            },
            {
                "test_id": "tests/test_html_transforms.py::test_strip_html_tags",
                "covers": [
                    "tukuy.TukuyTransformer.transform - using 'strip_html_tags' HTML transform (happy path)"
                ]
            },
            {
                "test_id": "tests/test_html_transforms.py::test_html_sanitization",
                "covers": [
                    "tukuy.TukuyTransformer.transform - using 'html_sanitize' HTML transform (happy path)"
                ]
            },
            {
                "test_id": "tests/test_html_transforms.py::test_link_extraction",
                "covers": [
                    "tukuy.TukuyTransformer.transform - using 'link_extraction' HTML transform (happy path)"
                ]
            },
            {
                "test_id": "tests/test_html_transforms.py::test_url_transforms",
                "covers": [
                    "tukuy.TukuyTransformer.transform - using 'resolve_url' URL transform (happy path)",
                    "tukuy.TukuyTransformer.transform - using 'extract_domain' URL transform (happy path)"
                ]
            },
            {
                "test_id": "tests/test_json_transforms.py::test_json_parser_basic",
                "covers": [
                    "tukuy.TukuyTransformer.transform - using 'json_parse' JSON transform (happy path for dict and list)"
                ]
            },
            {
                "test_id": "tests/test_json_transforms.py::test_json_extractor_simple",
                "covers": [
                    "tukuy.TukuyTransformer.transform - using 'json_extract' JSON transform (happy path, simple extraction)"
                ]
            },
            {
                "test_id": "tests/test_validation_transforms.py::test_email_validation",
                "covers": [
                    "tukuy.TukuyTransformer.transform - using 'email_validator' validation transform (valid and invalid cases)"
                ]
            },
            {
                "test_id": "tests/test_validation_transforms.py::test_phone_formatting",
                "covers": [
                    "tukuy.TukuyTransformer.transform - using 'phone_formatter' validation transform (happy path)"
                ]
            },
            {
                "test_id": "tests/test_validation_transforms.py::test_credit_card_validation",
                "covers": [
                    "tukuy.TukuyTransformer.transform - using 'credit_card_check' validation transform (valid and invalid cases)"
                ]
            },
            {
                "test_id": "tests/test_validation_transforms.py::test_boolean_conversion",
                "covers": [
                    "tukuy.TukuyTransformer.transform - using 'bool' validation transform (various truthy/falsy inputs)"
                ]
            },
            {
                "test_id": "tests/test_validation_transforms.py::test_type_enforcement",
                "covers": [
                    "tukuy.TukuyTransformer.transform - using 'type_enforcer' validation transform (int, float, str, bool type enforcement)"
                ]
            },
            {
                "test_id": "tests/test_json_transforms.py::test_json_parser_invalid",
                "covers": [
                    "tukuy.TukuyTransformer.transform - 'json_parse' behavior with invalid JSON (strict vs. lenient mode)",
                    "tukuy.exceptions.ParseError - raised by 'json_parse' in strict mode for invalid JSON"
                ]
            },
            {
                "test_id": "tests/test_json_transforms.py::test_json_parser_schema_validation",
                "covers": [
                    "tukuy.TukuyTransformer.transform - 'json_parse' with schema validation (valid and invalid data)",
                    "tukuy.exceptions.ValidationError - raised by 'json_parse' for schema mismatch"
                ]
            },
            {
                "test_id": "tests/test_json_transforms.py::test_extract_property_from_json_errors",
                "covers": [
                    "tukuy.TukuyTransformer.extract_property_from_json - error handling for invalid JSON string input",
                    "tukuy.exceptions.ParseError - raised by 'extract_property_from_json' with invalid JSON string",
                    "tukuy.TukuyTransformer.extract_property_from_json - error handling for invalid selector",
                    "tukuy.exceptions.TransformationError - raised by 'extract_property_from_json' with invalid selector"
                ]
            }
        ],
        "commit_sha": "ce770baadc66e74038b49a0915fba2774421c65e",
        "full_code_skeleton_structured": [
            {
                "file_path": "examples.py",
                "code": "def text_transformation_examples():\n    \"\"\"Examples of text transformations using Tukuy.\"\"\"\n    pass\n\ndef html_transformation_examples():\n    \"\"\"Examples of HTML transformations using Tukuy.\"\"\"\n    pass\n\ndef json_transformation_example():\n    \"\"\"Example of JSON transformations using Tukuy.\"\"\"\n    pass\n\ndef main():\n    \"\"\"Main function to run all examples.\"\"\"\n    pass\n"
            },
            {
                "file_path": "tukuy/exceptions.py",
                "code": "class TransformerError(Exception):\n    \"\"\"Base exception class for all transformer-related errors.\"\"\"\n    def __init__(self, message: str, value: Any = None):\n        pass\n    \n    def __str__(self) -> str:\n        pass\n\nclass ValidationError(TransformerError):\n    \"\"\"Raised when input validation fails.\"\"\"\n    def __str__(self) -> str:\n        pass\n\nclass TransformationError(TransformerError):\n    \"\"\"Raised when a transformation operation fails.\"\"\"\n    def __init__(self, message: str, value: Any = None, transformer_name: Optional[str] = None):\n        pass\n    \n    def __str__(self) -> str:\n        pass\n\nclass ConfigurationError(TransformerError):\n    \"\"\"Raised when transformer configuration is invalid.\"\"\"\n    def __str__(self) -> str:\n        pass\n\nclass PatternError(TransformerError):\n    \"\"\"Raised when a pattern is invalid or malformed.\"\"\"\n    def __str__(self) -> str:\n        pass\n\nclass ExtractorError(TransformerError):\n    \"\"\"Raised when data extraction fails.\"\"\"\n    def __str__(self) -> str:\n        pass\n\nclass ParseError(TransformerError):\n    \"\"\"Raised when parsing operations fail.\"\"\"\n    def __str__(self) -> str:\n        pass\n"
            },
            {
                "file_path": "tukuy/types.py",
                "code": "class TransformResult(Generic[T]):\n    \"\"\"Container for transformation results with error handling.\"\"\"\n    \n    def __init__(self, value: Optional[T] = None, error: Optional[Exception] = None):\n        pass\n\n    @property\n    def failed(self) -> bool:\n        pass\n\n    def __str__(self) -> str:\n        pass\n\n@dataclass\nclass TransformOptions:\n    \"\"\"Base class for transformer options.\"\"\"\n    pass\n\n@dataclass\nclass TextTransformOptions(TransformOptions):\n    \"\"\"Options for text transformations.\"\"\"\n    strip: bool = True\n    case_sensitive: bool = True\n\n@dataclass\nclass DateTransformOptions(TransformOptions):\n    \"\"\"Options for date transformations.\"\"\"\n    format: str = '%Y-%m-%d'\n    timezone: Optional[str] = None\n\n@dataclass\nclass NumberTransformOptions(TransformOptions):\n    \"\"\"Options for number transformations.\"\"\"\n    decimals: int = 2\n    strip_non_numeric: bool = True\n\n@dataclass\nclass PatternOptions(TransformOptions):\n    \"\"\"Options for pattern-based transformations.\"\"\"\n    pattern: str\n    template: Optional[str] = None\n    flags: int = 0\n\n@dataclass\nclass ExtractorOptions(TransformOptions):\n    \"\"\"Options for data extraction.\"\"\"\n    selector: Union[str, Dict[str, Any]]\n    attribute: str = \"text\"\n    fallback: Optional[Union[str, List[str]]] = None\n\nclass TransformerProtocol(Protocol[T, U]):\n    \"\"\"Protocol defining the interface for transformers.\"\"\"\n    \n    @property\n    def name(self) -> str:\n        \"\"\"Get the transformer name.\"\"\"\n        pass\n    \n    def transform(self, value: T, context: Optional[TransformContext] = None) -> TransformResult[U]:\n        \"\"\"\n        Transform the input value according to the transformer's rules.\n        \n        Args:\n            value: The input value to transform\n            context: Optional context for the transformation\n            \n        Returns:\n            TransformResult containing either the transformed value or an error\n        \"\"\"\n        pass\n\n    def validate(self, value: T) -> bool:\n        \"\"\"\n        Validate the input value.\n        \n        Args:\n            value: The input value to validate\n            \n        Returns:\n            True if the value is valid for this transformer, False otherwise\n        \"\"\"\n        pass\n        \n    def get_validation_errors(self, value: T) -> List[str]:\n        \"\"\"\n        Get list of validation errors for the input value.\n        \n        Args:\n            value: The input value to validate\n            \n        Returns:\n            List of validation error messages, empty if valid\n        \"\"\"\n        pass\n\nclass ExtractorProtocol(Protocol):\n    \"\"\"Protocol defining the interface for data extractors.\"\"\"\n    \n    def extract_data(self, data: Any, pattern: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Extract data according to the given pattern.\n        \n        Args:\n            data: The data to extract from (HTML, JSON, etc.)\n            pattern: The pattern describing what to extract\n            \n        Returns:\n            Dictionary of extracted data\n        \"\"\"\n        pass\n        \n    def extract_property(self, data: Any, property_def: Dict[str, Any]) -> Any:\n        \"\"\"\n        Extract a single property from data.\n        \n        Args:\n            data: The data to extract from\n            property_def: The property definition\n            \n        Returns:\n            The extracted property value\n        \"\"\"\n        pass\n\nclass ValidatorProtocol(Protocol[T]):\n    \"\"\"Protocol defining the interface for validators.\"\"\"\n    \n    def validate(self, value: T) -> bool:\n        \"\"\"\n        Validate the input value.\n        \n        Args:\n            value: The input value to validate\n            \n        Returns:\n            True if the value is valid, False otherwise\n        \"\"\"\n        pass\n\n    def get_validation_errors(self, value: T) -> List[str]:\n        \"\"\"\n        Get list of validation errors for the input value.\n        \n        Args:\n            value: The input value to validate\n            \n        Returns:\n            List of validation error messages, empty if valid\n        \"\"\"\n        pass\n        \n    def validate_with_context(self, value: T, context: Dict[str, Any]) -> bool:\n        \"\"\"\n        Validate the input value with additional context.\n        \n        Args:\n            value: The input value to validate\n            context: Additional context for validation\n            \n        Returns:\n            True if the value is valid, False otherwise\n        \"\"\"\n        pass\n\nclass PluginProtocol(Protocol):\n    \"\"\"Protocol defining the interface for plugins.\"\"\"\n    \n    @property\n    def name(self) -> str:\n        \"\"\"Get the plugin name.\"\"\"\n        pass\n        \n    @property\n    def transformers(self) -> Dict[str, Any]:\n        \"\"\"Get the transformers provided by this plugin.\"\"\"\n        pass\n        \n    def initialize(self) -> None:\n        \"\"\"Initialize the plugin.\"\"\"\n        pass\n        \n    def cleanup(self) -> None:\n        \"\"\"Clean up the plugin.\"\"\"\n        pass\n        \n    def get_transformer(self, name: str, params: Dict[str, Any]) -> Optional[TransformerProtocol]:\n        \"\"\"\n        Get a transformer by name with the given parameters.\n        \n        Args:\n            name: The transformer name\n            params: Parameters for the transformer\n            \n        Returns:\n            The transformer instance or None if not found\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "tukuy/base.py",
                "code": "class BaseTransformer(Generic[T, U], ABC):\n    \"\"\"\n    Abstract base class for all transformers.\n    \n    Provides common functionality and defines the interface that all transformers\n    must implement.\n    \n    Type Parameters:\n        T: The input type that this transformer accepts\n        U: The output type that this transformer produces\n    \"\"\"\n    \n    def __init__(self, name: str, options: Optional[TransformOptions] = None):\n        \"\"\"\n        Initialize the transformer.\n        \n        Args:\n            name: Unique identifier for this transformer\n            options: Configuration options for this transformer\n        \"\"\"\n        pass\n    \n    def _validate_options(self) -> None:\n        \"\"\"Validate the transformer options.\"\"\"\n        pass\n    \n    @abstractmethod\n    def validate(self, value: T) -> bool:\n        \"\"\"\n        Validate the input value.\n        \n        Args:\n            value: The value to validate\n            \n        Returns:\n            bool: True if valid, False otherwise\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def _transform(self, value: T, context: Optional[TransformContext] = None) -> U:\n        \"\"\"\n        Internal transformation method that subclasses must implement.\n        \n        Args:\n            value: The value to transform\n            context: Optional context data for the transformation\n            \n        Returns:\n            The transformed value\n            \n        Raises:\n            TransformationError: If the transformation fails\n        \"\"\"\n        pass\n    \n    def transform(self, value: T, context: Optional[TransformContext] = None, **kwargs) -> TransformResult[U]:\n        \"\"\"\n        Public method to transform a value with error handling.\n        \n        Args:\n            value: The value to transform\n            context: Optional context data for the transformation\n            **kwargs: Additional keyword arguments for the transformation\n            \n        Returns:\n            TransformResult containing either the transformed value or an error\n        \"\"\"\n        pass\n    \n    def __str__(self) -> str:\n        pass\n    \n    def __repr__(self) -> str:\n        pass\n\nclass ChainableTransformer(BaseTransformer[T, U]):\n    \"\"\"\n    A transformer that can be chained with other transformers.\n    \n    Allows for creating pipelines of transformations where the output of one\n    transformer becomes the input to the next.\n    \"\"\"\n    \n    def __init__(\n        self,\n        name: str,\n        next_transformer: Optional[BaseTransformer] = None,\n        options: Optional[TransformOptions] = None\n    ):\n        pass\n    \n    def chain(self, next_transformer: BaseTransformer) -> 'ChainableTransformer':\n        \"\"\"\n        Chain this transformer with another transformer.\n        \n        Args:\n            next_transformer: The next transformer in the chain\n            \n        Returns:\n            self for method chaining\n        \"\"\"\n        pass\n    \n    def transform(self, value: T, context: Optional[TransformContext] = None, **kwargs) -> TransformResult:\n        \"\"\"\n        Transform the value and pass it through the chain.\n        \n        Args:\n            value: The value to transform\n            context: Optional context data for the transformation\n            **kwargs: Additional keyword arguments for the transformation\n            \n        Returns:\n            TransformResult containing either the final transformed value or an error\n        \"\"\"\n        pass\n\nclass CompositeTransformer(BaseTransformer[T, U]):\n    \"\"\"\n    A transformer that combines multiple transformers into a single unit.\n    \n    Useful for creating complex transformations from simpler ones.\n    \"\"\"\n    \n    def __init__(\n        self,\n        name: str,\n        transformers: List[BaseTransformer],\n        options: Optional[TransformOptions] = None\n    ):\n        pass\n    \n    def validate(self, value: Any) -> bool:\n        \"\"\"Validate input through all contained transformers.\"\"\"\n        pass\n    \n    def _transform(self, value: Any, context: Optional[TransformContext] = None) -> Any:\n        \"\"\"Apply all transformations in sequence.\"\"\"\n        pass\n\nclass RegexTransformer(ChainableTransformer[str, str]):\n    \"\"\"Apply regex pattern to text.\"\"\"\n    \n    def __init__(self, name: str, pattern: str, template: Optional[str] = None):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass ReplaceTransformer(ChainableTransformer[str, str]):\n    \"\"\"Replace text.\"\"\"\n    \n    def __init__(self, name: str, old: str, new: str):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass CoreToolsTransformer(BaseTransformer[Any, Any]):\n    \"\"\"\n    Coordinates the application of multiple transformations using existing transformers.\n    \n    This transformer takes a value and a list of transform operations, creates the\n    appropriate transformers, and chains them together to produce the final result.\n    \"\"\"\n    \n    def __init__(self):\n        pass\n        \n    def validate(self, value: Any) -> bool:\n        pass\n        \n    def _transform(self, value: Any, transforms: List[Dict[str, Any]]) -> Any:\n        pass\n"
            },
            {
                "file_path": "tukuy/transformers/validation.py",
                "code": "class BooleanTransformer(ChainableTransformer[str, bool]):\n    \"\"\"Convert string to boolean.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: Any, context: Optional[TransformContext] = None) -> Optional[bool]:\n        pass\n\nclass EmailValidator(ChainableTransformer[str, str]):\n    \"\"\"Validate email address.\"\"\"\n    \n    def __init__(self, name: str, allowed_domains: Optional[list] = None):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> Optional[str]:\n        pass\n\nclass PhoneFormatter(ChainableTransformer[str, str]):\n    \"\"\"Format phone number.\"\"\"\n    \n    def __init__(self, name: str, format: str = '({area}) {prefix}-{line}'):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass CreditCardValidator(ChainableTransformer[str, str]):\n    \"\"\"Validate credit card number using Luhn algorithm.\"\"\"\n    \n    def __init__(self, name: str, mask: bool = False):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> Optional[str]:\n        pass\n\nclass TypeEnforcer(ChainableTransformer[Any, Any]):\n    \"\"\"Enforce type conversion.\"\"\"\n    \n    def __init__(self, name: str, target_type: str):\n        pass\n    \n    def validate(self, value: Any) -> bool:\n        pass\n    \n    def _transform(self, value: Any, context: Optional[TransformContext] = None) -> Any:\n        pass\n"
            },
            {
                "file_path": "tukuy/transformers/html.py",
                "code": "class StripHtmlTagsTransformer(ChainableTransformer[str, str]):\n    \"\"\"Strip HTML tags from text.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass HtmlSanitizationTransformer(ChainableTransformer[str, str]):\n    \"\"\"Sanitize HTML by removing script and style tags.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass LinkExtractionTransformer(ChainableTransformer[str, List[str]]):\n    \"\"\"Extract links from HTML.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> List[str]:\n        pass\n\nclass ResolveUrlTransformer(ChainableTransformer[str, str]):\n    \"\"\"Resolve relative URL to absolute URL.\"\"\"\n    \n    def __init__(self, name: str, base_url: str):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass ExtractDomainTransformer(ChainableTransformer[str, str]):\n    \"\"\"Extract domain from URL.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass HtmlExtractor(ChainableTransformer[str, Dict[str, Any]]):\n    \"\"\"Extract data from HTML using a pattern.\"\"\"\n    \n    def __init__(self, name: str, pattern: Dict[str, Any]):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> Dict[str, Any]:\n        pass\n    \n    def _extract_property(self, soup: BeautifulSoup, prop: Dict[str, Any], context: Optional[TransformContext] = None) -> Any:\n        \"\"\"Extract a property from HTML using the property pattern.\"\"\"\n        pass\n    \n    def _select_elements(self, soup: BeautifulSoup, primary: str, fallback: List[str]) -> List[Any]:\n        \"\"\"Select elements using primary selector or fallbacks.\"\"\"\n        pass\n    \n    def _select_element(self, soup: BeautifulSoup, primary: str, fallback: List[str]) -> Optional[Any]:\n        \"\"\"Select a single element using primary selector or fallbacks.\"\"\"\n        pass\n    \n    def _get_element_value(self, element: Any, attribute: str) -> str:\n        \"\"\"Get value from element based on attribute.\"\"\"\n        pass\n    \n    def _extract_nested_property(self, element: Any, prop: Dict[str, Any], context: Optional[TransformContext] = None) -> Any:\n        \"\"\"Extract a nested property from an element.\"\"\"\n        pass\n    \n    def _process_object(self, element: Any, properties: List[Dict[str, Any]], context: Optional[TransformContext] = None) -> Dict[str, Any]:\n        \"\"\"Process an object with properties.\"\"\"\n        pass\n    \n    def _apply_transforms(self, value: str, transforms: List[Any], context: Optional[TransformContext] = None) -> Any:\n        \"\"\"Apply transforms to a value.\"\"\"\n        pass\n"
            },
            {
                "file_path": "tukuy/transformers/numerical.py",
                "code": "class IntegerTransformer(ChainableTransformer[str, int]):\n    \"\"\"Convert value to integer.\"\"\"\n    \n    def __init__(self, name: str, min_value: Optional[int] = None, max_value: Optional[int] = None):\n        pass\n    \n    def validate(self, value: Any) -> bool:\n        pass\n    \n    def _transform(self, value: Any, context: Optional[TransformContext] = None) -> int:\n        pass\n\nclass FloatTransformer(ChainableTransformer[str, float]):\n    \"\"\"Convert value to float.\"\"\"\n    \n    def __init__(self, name: str, min_value: Optional[float] = None, max_value: Optional[float] = None):\n        pass\n    \n    def validate(self, value: Any) -> bool:\n        pass\n    \n    def _transform(self, value: Any, context: Optional[TransformContext] = None) -> float:\n        pass\n\nclass RoundTransformer(ChainableTransformer[Union[int, float, Decimal], float]):\n    \"\"\"Round a number to specified number of decimal places.\"\"\"\n    \n    def __init__(self, name: str, decimals: int = 0):\n        pass\n    \n    def validate(self, value: Any) -> bool:\n        pass\n    \n    def _transform(self, value: Union[int, float, Decimal], context: Optional[TransformContext] = None) -> float:\n        pass\n\nclass CurrencyConverter(ChainableTransformer[Union[int, float, Decimal], float]):\n    \"\"\"Convert currency using exchange rate.\"\"\"\n    \n    def __init__(self, name: str, rate: Optional[float] = None):\n        pass\n    \n    def validate(self, value: Any) -> bool:\n        pass\n    \n    def _transform(self, value: Union[int, float, Decimal], context: Optional[TransformContext] = None) -> float:\n        pass\n\nclass UnitConverter(ChainableTransformer[Union[int, float, Decimal], float]):\n    \"\"\"Convert units using conversion rate.\"\"\"\n    \n    def __init__(self, name: str, rate: Optional[float] = None):\n        pass\n    \n    def validate(self, value: Any) -> bool:\n        pass\n    \n    def _transform(self, value: Union[int, float, Decimal], context: Optional[TransformContext] = None) -> float:\n        pass\n\nclass MathOperationTransformer(ChainableTransformer[Union[int, float, Decimal], float]):\n    \"\"\"Perform math operation on a value.\"\"\"\n    \n    def __init__(self, name: str, operation: str = 'add', operand: Union[int, float, Decimal] = 0):\n        pass\n    \n    def validate(self, value: Any) -> bool:\n        pass\n    \n    def _transform(self, value: Union[int, float, Decimal], context: Optional[TransformContext] = None) -> float:\n        pass\n\nclass PercentageCalculator(ChainableTransformer[Union[int, float, Decimal], float]):\n    \"\"\"Convert decimal to percentage.\"\"\"\n    \n    def validate(self, value: Any) -> bool:\n        pass\n    \n    def _transform(self, value: Union[int, float, Decimal], context: Optional[TransformContext] = None) -> float:\n        pass\n"
            },
            {
                "file_path": "tukuy/transformers/text.py",
                "code": "class StripTransformer(ChainableTransformer[str, str]):\n    \"\"\"Strip whitespace from text.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass LowercaseTransformer(ChainableTransformer[str, str]):\n    \"\"\"Convert text to lowercase.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass UppercaseTransformer(ChainableTransformer[str, str]):\n    \"\"\"Convert text to uppercase.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass TemplateTransformer(ChainableTransformer[str, str]):\n    \"\"\"Apply template to regex match.\"\"\"\n    \n    def __init__(self, name: str, template: str):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass MapTransformer(ChainableTransformer[str, str]):\n    \"\"\"Map values using a dictionary.\"\"\"\n    \n    def __init__(self, name: str, mapping: Dict[str, str], default: Optional[str] = None):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass SplitTransformer(ChainableTransformer[str, str]):\n    \"\"\"Split text and return specific part.\"\"\"\n    \n    def __init__(self, name: str, delimiter: str = ':', index: int = -1):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass TitleCaseTransformer(ChainableTransformer[str, str]):\n    \"\"\"Convert text to title case.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass CamelCaseTransformer(ChainableTransformer[str, str]):\n    \"\"\"Convert text to camel case.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass SnakeCaseTransformer(ChainableTransformer[str, str]):\n    \"\"\"Convert text to snake case.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass SlugifyTransformer(ChainableTransformer[str, str]):\n    \"\"\"Convert text to URL-friendly slug.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass TruncateTransformer(ChainableTransformer[str, str]):\n    \"\"\"Truncate text to specified length.\"\"\"\n    \n    def __init__(self, name: str, length: int = 50, suffix: str = '...'):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass RemoveEmojisTransformer(ChainableTransformer[str, str]):\n    \"\"\"Remove emojis from text.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass RedactSensitiveTransformer(ChainableTransformer[str, str]):\n    \"\"\"Redact sensitive information like credit card numbers.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n"
            },
            {
                "file_path": "tukuy/transformers/json.py",
                "code": "class JsonParser(ChainableTransformer[str, JsonType]):\n    \"\"\"\n    Parses JSON strings into Python objects.\n    \n    Features:\n    - Strict/lenient parsing modes\n    - Schema validation\n    - Error handling with detailed messages\n    \"\"\"\n    \n    def __init__(\n        self,\n        name: str,\n        strict: bool = True,\n        schema: Optional[Dict[str, Any]] = None\n    ):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        \"\"\"\n        Validate that the input is a JSON string.\n        \n        In the validate method, we just check if the input is a string.\n        Actual JSON validity and schema validation is performed in _transform.\n        \"\"\"\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> JsonType:\n        \"\"\"\n        Transform a JSON string into a Python object.\n        \n        Args:\n            value: A JSON string\n            context: Optional transformation context\n            \n        Returns:\n            Parsed JSON data\n            \n        Raises:\n            ParseError: If the JSON string is invalid and strict=True\n            ValidationError: If the JSON data does not match the schema\n        \"\"\"\n        pass\n    \n    def _validate_schema(self, data: Any, schema: Dict[str, Any]) -> bool:\n        \"\"\"Simple schema validation.\"\"\"\n        pass\n\nclass JsonExtractor(BaseTransformer[JsonType, Any]):\n    \"\"\"\n    Extracts data from JSON structures using patterns.\n    \n    Features:\n    - JSONPath-like syntax for data extraction\n    - Nested property access\n    - Array operations\n    - Default values\n    \"\"\"\n    \n    def __init__(\n        self,\n        name: str,\n        pattern: Pattern,\n        default: Any = None\n    ):\n        pass\n    \n    def validate(self, value: JsonType) -> bool:\n        pass\n    \n    def _transform(self, value: JsonType, context: Optional[TransformContext] = None) -> Any:\n        pass\n    \n    def _extract_data(self, data: JsonType, pattern: Pattern) -> Any:\n        \"\"\"Extract data according to the pattern.\"\"\"\n        pass\n    \n    def _get_value(self, data: JsonType, path: Optional[str]) -> Optional[Any]:\n        \"\"\"Get a value using a path expression.\"\"\"\n        pass\n    \n    def _get_array_values(self, data: JsonType, path: Optional[str]) -> List[Any]:\n        \"\"\"Get array values using a path expression.\"\"\"\n        pass\n"
            },
            {
                "file_path": "tukuy/transformers/date.py",
                "code": "class DateTransformer(ChainableTransformer[str, datetime]):\n    \"\"\"Parse date string into datetime object.\"\"\"\n    \n    def __init__(self, name: str, format: str = '%Y-%m-%d'):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> datetime:\n        pass\n\nclass TimezoneTransformer(ChainableTransformer[datetime, datetime]):\n    \"\"\"Convert datetime between timezones.\"\"\"\n    \n    def __init__(self, name: str, to_zone: str, from_zone: Optional[str] = None):\n        pass\n    \n    def validate(self, value: datetime) -> bool:\n        pass\n    \n    def _transform(self, value: datetime, context: Optional[TransformContext] = None) -> datetime:\n        pass\n\nclass DurationCalculator(ChainableTransformer[str, int]):\n    \"\"\"Calculate duration between dates.\"\"\"\n    \n    def __init__(self, name: str, unit: str = 'days', format: str = '%Y-%m-%d', end: Optional[str] = None):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> int:\n        pass\n\nclass AgeCalculator(ChainableTransformer[str, int]):\n    \"\"\"Calculate age from birth date.\"\"\"\n    \n    def __init__(self, name: str, reference_date: Optional[date] = None):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> int:\n        pass\n"
            },
            {
                "file_path": "tukuy/plugins/base.py",
                "code": "class TransformerPlugin(ABC):\n    \"\"\"\n    Base class for transformer plugins.\n    \n    A plugin is a collection of related transformers that can be registered\n    with the TukuyTransformer. Plugins provide a way to organize transformers\n    into logical groups and manage their lifecycle.\n    \"\"\"\n    \n    def __init__(self, name: str):\n        \"\"\"\n        Initialize the plugin.\n        \n        Args:\n            name: Unique identifier for this plugin\n        \"\"\"\n        pass\n        \n    @property\n    @abstractmethod\n    def transformers(self) -> Dict[str, callable]:\n        \"\"\"\n        Get the transformers provided by this plugin.\n        \n        Returns:\n            A dictionary mapping transformer names to factory functions\n        \"\"\"\n        pass\n        \n    def initialize(self) -> None:\n        \"\"\"\n        Called when the plugin is loaded.\n        \n        Override this method to perform any setup required by the plugin.\n        \"\"\"\n        pass\n        \n    def cleanup(self) -> None:\n        \"\"\"\n        Called when the plugin is unloaded.\n        \n        Override this method to perform any cleanup required by the plugin.\n        \"\"\"\n        pass\n\nclass PluginRegistry:\n    \"\"\"\n    Registry for managing transformer plugins.\n    \n    The registry maintains the collection of loaded plugins and their\n    transformers, handling registration, unregistration, and access to\n    transformer factories.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize an empty plugin registry.\"\"\"\n        pass\n        \n    def register(self, plugin: TransformerPlugin) -> None:\n        \"\"\"\n        Register a plugin with the registry.\n        \n        Args:\n            plugin: The plugin to register\n            \n        Raises:\n            ValueError: If a plugin with the same name is already registered\n        \"\"\"\n        pass\n        \n    def unregister(self, name: str) -> None:\n        \"\"\"\n        Unregister a plugin from the registry.\n        \n        Args:\n            name: Name of the plugin to unregister\n        \"\"\"\n        pass\n        \n    def get_transformer(self, name: str) -> Optional[callable]:\n        \"\"\"\n        Get a transformer factory by name.\n        \n        Args:\n            name: Name of the transformer\n            \n        Returns:\n            The transformer factory function, or None if not found\n        \"\"\"\n        pass\n        \n    def get_plugin(self, name: str) -> Optional[TransformerPlugin]:\n        \"\"\"\n        Get a plugin by name.\n        \n        Args:\n            name: Name of the plugin\n            \n        Returns:\n            The plugin instance, or None if not found\n        \"\"\"\n        pass\n        \n    @property\n    def plugins(self) -> Dict[str, TransformerPlugin]:\n        \"\"\"Get all registered plugins.\"\"\"\n        pass\n        \n    @property\n    def transformers(self) -> Dict[str, callable]:\n        \"\"\"Get all registered transformers.\"\"\"\n        pass\n"
            },
            {
                "file_path": "tukuy/plugins/text/__init__.py",
                "code": "class TextTransformersPlugin(TransformerPlugin):\n    \"\"\"Plugin providing text transformation capabilities.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the text transformers plugin.\"\"\"\n        pass\n        \n    @property\n    def transformers(self):\n        \"\"\"Get the text transformers.\"\"\"\n        pass\n        \n    def initialize(self) -> None:\n        \"\"\"Initialize the text transformers plugin.\"\"\"\n        pass\n        \n    def cleanup(self) -> None:\n        \"\"\"Clean up the text transformers plugin.\"\"\"\n        pass\n"
            },
            {
                "file_path": "tukuy/plugins/example/__init__.py",
                "code": "class ReverseTransformer(ChainableTransformer[str, str]):\n    \"\"\"Example transformer that reverses text.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> str:\n        pass\n\nclass CountWordsTransformer(ChainableTransformer[str, int]):\n    \"\"\"Example transformer that counts words in text.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> int:\n        pass\n\nclass FindPatternTransformer(ChainableTransformer[str, list]):\n    \"\"\"Example transformer that finds all occurrences of a pattern.\"\"\"\n    \n    def __init__(self, name: str, pattern: str):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: Optional[TransformContext] = None) -> list:\n        pass\n\nclass ExamplePlugin(TransformerPlugin):\n    \"\"\"\n    Example plugin demonstrating plugin creation.\n    \n    This plugin provides simple text manipulation transformers as an example\n    of how to create custom plugins. Use this as a template for creating\n    your own plugins.\n    \n    Example usage:\n        from tukuy import TukuyTransformer\n        from tukuy.plugins.example import ExamplePlugin\n        \n        # Create transformer\n        TUKUY = TukuyTransformer()\n        \n        # Register plugin\n        TUKUY.register_plugin(ExamplePlugin())\n        \n        # Use transformers\n        text = \"Hello World\"\n        \n        # Reverse text\n        reversed_text = TUKUY.transform(text, [\"reverse\"])  # \"dlroW olleH\"\n        \n        # Count words\n        word_count = TUKUY.transform(text, [\"count_words\"])  # 2\n        \n        # Find patterns\n        patterns = TUKUY.transform(text, [{\n            \"function\": \"find_pattern\",\n            \"pattern\": r\"\\w+\"\n        }])  # [\"Hello\", \"World\"]\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the example plugin.\"\"\"\n        pass\n        \n    @property\n    def transformers(self):\n        \"\"\"Get the example transformers.\"\"\"\n        pass\n        \n    def initialize(self) -> None:\n        \"\"\"Initialize the example plugin.\"\"\"\n        pass\n        \n    def cleanup(self) -> None:\n        \"\"\"Clean up the example plugin.\"\"\"\n        pass\n"
            },
            {
                "file_path": "tukuy/plugins/html/__init__.py",
                "code": "class UrlJoinTransformer(ChainableTransformer[str, str]):\n    \"\"\"Joins URLs using urllib.parse.urljoin.\"\"\"\n    \n    def __init__(self, name: str, base_url: str):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: TransformContext = None) -> str:\n        pass\n\nclass ExtractDomainTransformer(ChainableTransformer[str, str]):\n    \"\"\"Extracts domain from URL.\"\"\"\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: TransformContext = None) -> str:\n        pass\n\nclass HtmlTransformersPlugin(TransformerPlugin):\n    \"\"\"Plugin providing HTML transformation capabilities.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the HTML transformers plugin.\"\"\"\n        pass\n        \n    @property\n    def transformers(self):\n        \"\"\"Get the HTML transformers.\"\"\"\n        pass\n"
            },
            {
                "file_path": "tukuy/plugins/json/__init__.py",
                "code": "class JsonTransformersPlugin(TransformerPlugin):\n    \"\"\"Plugin providing JSON transformation capabilities.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the JSON transformers plugin.\"\"\"\n        pass\n        \n    @property\n    def transformers(self):\n        \"\"\"Get the JSON transformers.\"\"\"\n        pass\n        \n    def initialize(self) -> None:\n        \"\"\"Initialize the JSON transformers plugin.\"\"\"\n        pass\n        \n    def cleanup(self) -> None:\n        \"\"\"Clean up the JSON transformers plugin.\"\"\"\n        pass\n"
            },
            {
                "file_path": "tukuy/plugins/numerical/__init__.py",
                "code": "class ExtractNumbersTransformer(ChainableTransformer[str, list]):\n    \"\"\"Extracts all numbers from text.\"\"\"\n    \n    def __init__(self, name: str):\n        pass\n    \n    def validate(self, value: str) -> bool:\n        pass\n    \n    def _transform(self, value: str, context: TransformContext = None) -> list:\n        pass\n\nclass NumericalTransformersPlugin(TransformerPlugin):\n    \"\"\"Plugin providing numerical transformation capabilities.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the numerical transformers plugin.\"\"\"\n        pass\n        \n    @property\n    def transformers(self):\n        \"\"\"Get the numerical transformers.\"\"\"\n        pass\n        \n    def initialize(self) -> None:\n        \"\"\"Initialize the numerical transformers plugin.\"\"\"\n        pass\n        \n    def cleanup(self) -> None:\n        \"\"\"Clean up the numerical transformers plugin.\"\"\"\n        pass\n"
            },
            {
                "file_path": "tukuy/plugins/validation/__init__.py",
                "code": "class ValidationTransformersPlugin(TransformerPlugin):\n    \"\"\"Plugin providing validation transformation capabilities.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the validation transformers plugin.\"\"\"\n        pass\n        \n    @property\n    def transformers(self):\n        \"\"\"Get the validation transformers.\"\"\"\n        pass\n        \n    def initialize(self) -> None:\n        \"\"\"Initialize the validation transformers plugin.\"\"\"\n        pass\n        \n    def cleanup(self) -> None:\n        \"\"\"Clean up the validation transformers plugin.\"\"\"\n        pass\n"
            },
            {
                "file_path": "tukuy/plugins/date/__init__.py",
                "code": "class DateTransformersPlugin(TransformerPlugin):\n    \"\"\"Plugin providing date transformation capabilities.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the date transformers plugin.\"\"\"\n        pass\n        \n    @property\n    def transformers(self):\n        \"\"\"Get the date transformers.\"\"\"\n        pass\n        \n    def initialize(self) -> None:\n        \"\"\"Initialize the date transformers plugin.\"\"\"\n        pass\n        \n    def cleanup(self) -> None:\n        \"\"\"Clean up the date transformers plugin.\"\"\"\n        pass\n"
            }
        ],
        "minimal_code_skeleton_structured": [
            {
                "file_path": "tukuy/exceptions.py",
                "code": "from typing import Any, Optional\n\nclass TransformerError(Exception):\n    \"\"\"Base exception class for all transformer-related errors.\"\"\"\n    def __init__(self, message: str, value: Any = None):\n        \"\"\"\n        Initialize the TransformerError.\n        \n        Args:\n            message: The error message.\n            value: The value that caused the error, if applicable.\n        \"\"\"\n        pass\n    \n    def __str__(self) -> str:\n        pass\n\nclass ValidationError(TransformerError):\n    \"\"\"Raised when input validation fails.\"\"\"\n    def __init__(self, message: str, value: Any = None): # Added for completeness, though tests might only rely on superclass if not overridden\n        \"\"\"\n        Initialize the ValidationError.\n        \n        Args:\n            message: The error message.\n            value: The value that caused the error, if applicable.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        pass\n\nclass TransformationError(TransformerError):\n    \"\"\"Raised when a transformation operation fails.\"\"\"\n    def __init__(self, message: str, value: Any = None, transformer_name: Optional[str] = None):\n        \"\"\"\n        Initialize the TransformationError.\n        \n        Args:\n            message: The error message.\n            value: The value that caused the error, if applicable.\n            transformer_name: The name of the transformer that failed.\n        \"\"\"\n        pass\n    \n    def __str__(self) -> str:\n        pass\n\nclass ParseError(TransformerError):\n    \"\"\"Raised when parsing operations fail.\"\"\"\n    def __init__(self, message: str, value: Any = None): # Added for completeness\n        \"\"\"\n        Initialize the ParseError.\n        \n        Args:\n            message: The error message.\n            value: The value that caused the error, if applicable.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        pass\n"
            },
            {
                "file_path": "tukuy/transformers/__init__.py",
                "code": "from typing import Any, Dict, List, Optional, Union\n\n# Forward declaration for JsonType, which would typically be defined in tukuy.types\n# For the purpose of this skeleton, the user will need to define or import it.\n# Example definition: JsonType = Union[Dict[str, Any], List[Any], str, int, float, bool, None]\nJsonType = Any # Placeholder if actual definition is not included as per rules\n\nclass TukuyTransformer:\n    \"\"\"\n    Main transformer class that provides access to all transformation tools.\n    \n    This class serves as the main entry point for the transformation library,\n    providing a unified interface to all available transformers through a plugin system.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the transformer registry.\"\"\"\n        pass\n    \n    def transform(self, value: Any, transforms: List[Union[str, Dict[str, Any]]]) -> Any:\n        \"\"\"\n        Transform a value using a sequence of transformations.\n        \n        Args:\n            value: The value to transform\n            transforms: List of transformations to apply. Each item can be:\n                - a string (the transformer name)\n                - a dict with 'function' key and additional parameters\n                \n        Returns:\n            The transformed value\n            \n        Raises:\n            TransformationError: If any transformation fails\n            ParseError: If JSON parsing fails in strict mode\n            ValidationError: If schema validation fails\n        \"\"\"\n        pass\n    \n    def extract_html_with_pattern(self, html: str, pattern: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract data from HTML using a pattern.\"\"\"\n        pass\n    \n    def extract_property_from_html(self, html: str, prop: Dict[str, Any]) -> Any:\n        \"\"\"Extract a single property from HTML.\"\"\"\n        pass\n    \n    def extract_json_with_pattern(self, json_data: str, pattern: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract data from JSON using a pattern.\"\"\"\n        pass\n\n    def extract_property_from_json(self, json_data: Union[str, JsonType], prop: Dict[str, Any]) -> Any:\n        \"\"\"Extract a single property from JSON data.\n        \n        Args:\n            json_data: JSON string or already parsed JSON data\n            prop: Property extraction pattern\n            \n        Returns:\n            The extracted property value\n            \n        Raises:\n            ValidationError: If JSON plugin is not loaded\n            ParseError: If JSON string is invalid\n            TransformationError: If extraction fails\n        \"\"\"\n        pass\n"
            }
        ]
    },
    {
        "idx": 30391,
        "repo_name": "Undertone0809_conftier",
        "url": "https://github.com/Undertone0809/conftier",
        "description": "A powerful Python multi-tier configuration management framework that simplifies the definition, access, and synchronization of layered configurations in Python application and framework.",
        "stars": 18,
        "forks": 2,
        "language": "python",
        "size": 731,
        "created_at": "2025-03-29T12:06:38+00:00",
        "updated_at": "2025-04-21T08:07:54+00:00",
        "pypi_info": {
            "name": "conftier",
            "version": "0.2.0",
            "url": "https://files.pythonhosted.org/packages/35/42/12962fa89ab46573751ddb05c757649b2fa52aa8b8a166f01a3a8df4c56b/conftier-0.2.0.tar.gz"
        },
        "error": null,
        "judge_info": {
            "language": "python",
            "is_good_project": false,
            "reason": "",
            "python_file_num": 11,
            "comment_ratio": 0.22670134373645426,
            "pyfile_content_length": 81136,
            "pyfile_code_lines": 2307,
            "test_file_exist": true,
            "test_file_content_length": 41680,
            "pytest_framework": true,
            "test_case_num": 32,
            "metadata_path": [
                "pyproject.toml"
            ],
            "readme_content_length": 4652,
            "llm_reason": "The project is highly suitable as a benchmark. \nPositive aspects:\n*   **Self-Contained:** The core functionality revolves around local file system operations (reading/writing YAML configuration files in user-specific and project-specific locations) and Python data structures. It does not require an active internet connection or external APIs for its primary operations or testing. Dependencies like Pydantic (optional) and PyYAML are standard and manageable via pip.\n*   **Clear & Well-Defined Functionality:** The project implements a multi-tier configuration system (user, project, defaults), similar to VSCode's settings, which is a specific and understandable problem. The README clearly outlines this concept.\n*   **Testable & Verifiable Output:** The project includes a comprehensive suite of unit tests (`test_config_manager.py`, `test_config_model.py`, `test_utils.py`). These tests cover various aspects like initialization with different schema types (dataclass, Pydantic, dict), loading configurations from different sources, merging logic, updating configurations, and path utilities. This existing test suite would be invaluable for verifying an AI's attempt to rebuild the project.\n*   **No Graphical User Interface (GUI):** The project is a Python library with an accompanying command-line interface (CLI), making interactions scriptable and testable without GUI automation.\n*   **Appropriate Complexity & Scope:** Rebuilding this project involves moderately complex logic: file system interaction (finding user config directories, project roots), YAML parsing, object modeling and validation (integrating with dataclasses and Pydantic), implementing configuration merging rules, and creating a CLI. This is non-trivial but well within a reasonable scope for an AI to replicate in hours to a few days.\n*   **Well-Understood Problem Domain:** Configuration management is a common and well-understood problem in software development.\n\nNegative aspects or considerations:\n*   The project itself is a small, focused \"framework\" for configuration. While the goal is to replicate this *specific, existing* framework, which is well-defined, care must be taken in the prompt to ensure the AI doesn't try to design a generic one.\n*   The `find_project_root` function uses heuristics (checking for `.git`, `pyproject.toml`). While common, this specific heuristic would need to be part of the specification for the AI to replicate its behavior consistently.\n*   The requirement to support multiple schema types (dataclass, Pydantic models, and raw dictionaries) for configuration definitions adds a layer of complexity, but also makes it a richer benchmark task.",
            "llm_project_type": "Configuration management library and CLI tool",
            "llm_rating": 85,
            "llm_difficulty": "Medium"
        },
        "tests": {
            "repo_name": "Undertone0809_conftier",
            "finish_test": true,
            "test_case_result": {
                "tests/test_config_manager.py::TestConfigManager::test_conftier_init_with_dataclass": "passed",
                "tests/test_config_manager.py::TestConfigManager::test_conftier_init_with_dict": "passed",
                "tests/test_config_manager.py::TestConfigManager::test_conftier_init_with_pydantic": "skipped",
                "tests/test_config_manager.py::TestConfigManager::test_conftier_load_default_only": "passed",
                "tests/test_config_manager.py::TestConfigManager::test_conftier_load_with_user_config": "passed",
                "tests/test_config_manager.py::TestConfigManager::test_conftier_load_with_all_configs": "passed",
                "tests/test_config_manager.py::TestConfigManager::test_conftier_get_user_config": "passed",
                "tests/test_config_manager.py::TestConfigManager::test_conftier_get_project_config": "passed",
                "tests/test_config_manager.py::TestConfigManager::test_conftier_update_user_config": "passed",
                "tests/test_config_manager.py::TestConfigManager::test_conftier_update_project_config": "passed",
                "tests/test_config_manager.py::TestConfigManager::test_conftier_create_project_template": "passed",
                "tests/test_config_manager.py::TestConfigManager::test_conftier_auto_create_user": "passed",
                "tests/test_config_manager.py::TestConfigManager::test_conftier_auto_create_project": "passed",
                "tests/test_config_manager.py::TestConfigManager::test_conftier_no_auto_create": "passed",
                "tests/test_config_manager.py::TestConfigManager::test_conftier_create_user_config_template": "passed",
                "tests/test_config_manager.py::TestConfigManager::test_conftier_create_project_config_template": "passed",
                "tests/test_config_manager.py::TestConfigManager::test_conftier_load_either_config": "passed",
                "tests/test_config_manager.py::TestConfigManager::test_conftier_pydantic_full_workflow": "skipped",
                "tests/test_config_model.py::TestConfigModel::test_conftier_from_schema_dataclass": "passed",
                "tests/test_config_model.py::TestConfigModel::test_conftier_from_schema_dict": "passed",
                "tests/test_config_model.py::TestConfigModel::test_conftier_from_schema_pydantic": "skipped",
                "tests/test_config_model.py::TestConfigModel::test_conftier_to_dict": "passed",
                "tests/test_config_model.py::TestConfigModel::test_conftier_to_dict_pydantic": "skipped",
                "tests/test_config_model.py::TestConfigModel::test_conftier_get_value": "passed",
                "tests/test_config_model.py::TestConfigModel::test_conftier_get_value_pydantic": "skipped",
                "tests/test_config_model.py::TestConfigModel::test_conftier_update": "passed",
                "tests/test_config_model.py::TestConfigModel::test_conftier_update_pydantic": "skipped",
                "tests/test_config_model.py::TestConfigModel::test_conftier_merge": "passed",
                "tests/test_config_model.py::TestConfigModel::test_conftier_merge_pydantic": "skipped",
                "tests/test_utils.py::TestUtilityFunctions::test_conftier_get_user_config_path": "passed",
                "tests/test_utils.py::TestUtilityFunctions::test_conftier_find_project_root": "passed",
                "tests/test_utils.py::TestUtilityFunctions::test_conftier_get_project_config_path": "passed"
            },
            "success_count": 25,
            "failed_count": 0,
            "error_count": 0,
            "skipped_count": 7,
            "unknown_count": 0,
            "total_count": 32,
            "success_rate": 0.78125,
            "coverage_report": {
                "covered_lines": 294,
                "num_statements": 448,
                "percent_covered": 61.18421052631579,
                "percent_covered_display": "61",
                "missing_lines": 154,
                "excluded_lines": 2,
                "num_branches": 160,
                "num_partial_branches": 28,
                "covered_branches": 78,
                "missing_branches": 82
            },
            "coverage_result": {}
        },
        "codelines_count": 2307,
        "codefiles_count": 11,
        "code_length": 81136,
        "test_files_count": 3,
        "test_code_length": 41680,
        "structure": [
            {
                "file": "tests/test_config_manager.py",
                "functions": [],
                "classes": [
                    {
                        "name": "NestedConfig",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "TestConfig",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "TestConfigManager",
                        "docstring": "Tests for the ConfigManager class",
                        "comments": null,
                        "methods": [
                            {
                                "name": "temp_home_dir",
                                "docstring": "Fixture to create a temporary home directory",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "temp_project_dir",
                                "docstring": "Fixture to create a temporary project directory",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_conftier_init_with_dataclass",
                                "docstring": "Test initializing ConfigManager with a dataclass schema",
                                "comments": null,
                                "args": [
                                    "self",
                                    "temp_home_dir"
                                ]
                            },
                            {
                                "name": "test_conftier_init_with_dict",
                                "docstring": "Test initializing ConfigManager with a dict schema",
                                "comments": null,
                                "args": [
                                    "self",
                                    "temp_home_dir"
                                ]
                            },
                            {
                                "name": "test_conftier_init_with_pydantic",
                                "docstring": "Test initializing ConfigManager with a Pydantic schema",
                                "comments": null,
                                "args": [
                                    "self",
                                    "temp_home_dir"
                                ]
                            },
                            {
                                "name": "test_conftier_load_default_only",
                                "docstring": "Test loading configuration with only default values",
                                "comments": null,
                                "args": [
                                    "self",
                                    "temp_home_dir"
                                ]
                            },
                            {
                                "name": "test_conftier_load_with_user_config",
                                "docstring": "Test loading configuration with user config",
                                "comments": null,
                                "args": [
                                    "self",
                                    "temp_home_dir"
                                ]
                            },
                            {
                                "name": "test_conftier_load_with_all_configs",
                                "docstring": "Test loading configuration with default, user, and project configs",
                                "comments": null,
                                "args": [
                                    "self",
                                    "temp_home_dir",
                                    "temp_project_dir"
                                ]
                            },
                            {
                                "name": "test_conftier_get_user_config",
                                "docstring": "Test getting user config",
                                "comments": null,
                                "args": [
                                    "self",
                                    "temp_home_dir"
                                ]
                            },
                            {
                                "name": "test_conftier_get_project_config",
                                "docstring": "Test getting project config",
                                "comments": null,
                                "args": [
                                    "self",
                                    "temp_home_dir",
                                    "temp_project_dir"
                                ]
                            },
                            {
                                "name": "test_conftier_update_user_config",
                                "docstring": "Test updating user config",
                                "comments": null,
                                "args": [
                                    "self",
                                    "temp_home_dir"
                                ]
                            },
                            {
                                "name": "test_conftier_update_project_config",
                                "docstring": "Test updating project config",
                                "comments": null,
                                "args": [
                                    "self",
                                    "temp_home_dir",
                                    "temp_project_dir"
                                ]
                            },
                            {
                                "name": "test_conftier_create_project_template",
                                "docstring": "Test create_project_template method",
                                "comments": null,
                                "args": [
                                    "self",
                                    "temp_home_dir",
                                    "temp_project_dir"
                                ]
                            },
                            {
                                "name": "test_conftier_auto_create_user",
                                "docstring": "Test auto_create_user parameter",
                                "comments": null,
                                "args": [
                                    "self",
                                    "temp_home_dir"
                                ]
                            },
                            {
                                "name": "test_conftier_auto_create_project",
                                "docstring": "Test auto_create_project parameter",
                                "comments": null,
                                "args": [
                                    "self",
                                    "temp_home_dir",
                                    "temp_project_dir"
                                ]
                            },
                            {
                                "name": "test_conftier_no_auto_create",
                                "docstring": "Test behavior when both auto_create options are False",
                                "comments": null,
                                "args": [
                                    "self",
                                    "temp_home_dir",
                                    "temp_project_dir"
                                ]
                            },
                            {
                                "name": "test_conftier_create_user_config_template",
                                "docstring": "Test create_user_config_template method",
                                "comments": null,
                                "args": [
                                    "self",
                                    "temp_home_dir"
                                ]
                            },
                            {
                                "name": "test_conftier_create_project_config_template",
                                "docstring": "Test create_project_config_template method",
                                "comments": null,
                                "args": [
                                    "self",
                                    "temp_home_dir",
                                    "temp_project_dir"
                                ]
                            },
                            {
                                "name": "test_conftier_load_either_config",
                                "docstring": "Test that load doesn't fail when either user or project config exists",
                                "comments": null,
                                "args": [
                                    "self",
                                    "temp_home_dir",
                                    "temp_project_dir"
                                ]
                            },
                            {
                                "name": "test_conftier_pydantic_full_workflow",
                                "docstring": "Test a full workflow with Pydantic models",
                                "comments": null,
                                "args": [
                                    "self",
                                    "temp_home_dir",
                                    "temp_project_dir"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "LLMConfig",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "PydanticTestConfig",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/test_config_model.py",
                "functions": [],
                "classes": [
                    {
                        "name": "NestedConfig",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "DataclassConfig",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "TestConfigModel",
                        "docstring": "Tests for the ConfigModel class",
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_conftier_from_schema_dataclass",
                                "docstring": "Test creating ConfigModel from a dataclass schema",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_conftier_from_schema_dict",
                                "docstring": "Test creating ConfigModel from a dict schema",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_conftier_from_schema_pydantic",
                                "docstring": "Test creating ConfigModel from a Pydantic schema",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_conftier_to_dict",
                                "docstring": "Test converting ConfigModel to dictionary",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_conftier_to_dict_pydantic",
                                "docstring": "Test converting Pydantic ConfigModel to dictionary",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_conftier_get_value",
                                "docstring": "Test getting values from ConfigModel",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_conftier_get_value_pydantic",
                                "docstring": "Test getting values from Pydantic ConfigModel",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_conftier_update",
                                "docstring": "Test updating ConfigModel with new values",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_conftier_update_pydantic",
                                "docstring": "Test updating Pydantic ConfigModel",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_conftier_merge",
                                "docstring": "Test merging two ConfigModels",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_conftier_merge_pydantic",
                                "docstring": "Test merging two Pydantic ConfigModels",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "NestedPydanticConfig",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "PydanticConfig",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/conftest.py",
                "functions": [
                    {
                        "name": "temp_home_dir",
                        "docstring": "Create a temporary home directory for testing",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "temp_project_dir",
                        "docstring": "Create a temporary project directory with .git marker for testing",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "mock_yaml_file",
                        "docstring": "Create a temporary YAML file for testing",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_utils.py",
                "functions": [],
                "classes": [
                    {
                        "name": "TestUtilityFunctions",
                        "docstring": "Tests for utility functions in conftier",
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_conftier_get_user_config_path",
                                "docstring": "Test that get_user_config_path returns the correct path",
                                "comments": null,
                                "args": [
                                    "self",
                                    "monkeypatch"
                                ]
                            },
                            {
                                "name": "test_conftier_find_project_root",
                                "docstring": "Test that find_project_root correctly identifies project root directories",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_conftier_get_project_config_path",
                                "docstring": "Test that get_project_config_path returns the correct path",
                                "comments": "Note: Implementation may find a different project root\nthan what we expected, which is valid behavior\nSkip further tests that rely on specific directory structure",
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "conftier/core.py",
                "functions": [
                    {
                        "name": "get_user_config_path",
                        "docstring": "Get the path to the user-level configuration file",
                        "comments": null,
                        "args": [
                            "config_name"
                        ]
                    },
                    {
                        "name": "get_project_config_path",
                        "docstring": "Get the path to the project-level configuration file",
                        "comments": null,
                        "args": [
                            "config_name",
                            "project_path"
                        ]
                    },
                    {
                        "name": "find_project_root",
                        "docstring": "Find the project root directory by looking for common project files\nlike .git, pyproject.toml, etc.",
                        "comments": "TODO: need to optimize",
                        "args": []
                    },
                    {
                        "name": "merge_configs_dict",
                        "docstring": "Merge multiple configuration levels\n\nArgs:\n    default_config: Default configuration\n    user_config: User-level configuration\n    project_config: Project-level configuration\n\nReturns:\n    Merged configuration dictionary",
                        "comments": null,
                        "args": [
                            "default_config",
                            "user_config",
                            "project_config"
                        ]
                    },
                    {
                        "name": "deep_update",
                        "docstring": "Recursively update a dictionary\n\nArgs:\n    base_dict: The base dictionary to update\n    update_dict: The dictionary with updates to apply\n\nReturns:\n    Updated dictionary",
                        "comments": null,
                        "args": [
                            "base_dict",
                            "update_dict"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "ConfigModel",
                        "docstring": "A unified configuration model that wraps Pydantic models, dataclasses, and\ndictionaries.\n\nThis class provides a consistent interface for different types of configuration\nmodels, handling validation, serialization, and nested structure management.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize a ConfigModel\n\nArgs:\n    schema_type: Type of schema ('pydantic', 'dataclass', or 'dict')\n    model_instance: The actual model instance",
                                "comments": null,
                                "args": [
                                    "self",
                                    "schema_type",
                                    "model_instance"
                                ]
                            },
                            {
                                "name": "from_schema",
                                "docstring": "Create a ConfigModel from a schema type and data\n\nArgs:\n    schema: The schema type (Pydantic model, dataclass, or dict)\n    data: Optional data to initialize the model with\n\nReturns:\n    Initialized ConfigModel",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "schema",
                                    "data"
                                ]
                            },
                            {
                                "name": "_prepare_dataclass_kwargs",
                                "docstring": "Prepare kwargs for dataclass initialization with proper handling of nested\ndataclasses.\n\nArgs:\n    dataclass_type: Target dataclass type\n    data: Data dictionary\n\nReturns:\n    Dictionary of kwargs suitable for initializing the dataclass",
                                "comments": null,
                                "args": [
                                    "dataclass_type",
                                    "data"
                                ]
                            },
                            {
                                "name": "model",
                                "docstring": "Get the underlying model instance",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "to_dict",
                                "docstring": "Convert the model to a dictionary\n\nReturns:\n    Dictionary representation of the model",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "get_value",
                                "docstring": "Get a value from the model by key\n\nArgs:\n    key: Key to get (supports dot notation for nested access)\n\nReturns:\n    Value at the specified key",
                                "comments": null,
                                "args": [
                                    "self",
                                    "key"
                                ]
                            },
                            {
                                "name": "update",
                                "docstring": "Update the model with new data\n\nArgs:\n    data: Dictionary of values to update",
                                "comments": null,
                                "args": [
                                    "self",
                                    "data"
                                ]
                            },
                            {
                                "name": "merge",
                                "docstring": "Merge with another ConfigModel\n\nArgs:\n    other: Another ConfigModel to merge with\n\nReturns:\n    New ConfigModel with merged data",
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "ConfigManager",
                        "docstring": "Core configuration manager that handles loading, merging, and accessing\nconfigurations.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the configuration manager\n\nArgs:\n    config_name: Framework name, used to determine config file paths\n    config_schema: Configuration schema definition (pydantic model, dataclass,\n        or dict)\n    version: Configuration schema version\n    auto_create_user: Whether to automatically create user config file if not\n    exists auto_create_project: Whether to automatically create project config\n    file if not exists.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "config_name",
                                    "config_schema",
                                    "version",
                                    "auto_create_user",
                                    "auto_create_project"
                                ]
                            },
                            {
                                "name": "_get_default_dict",
                                "docstring": "Get default configuration as a dictionary",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "_to_schema_type",
                                "docstring": "Convert dictionary to the schema type",
                                "comments": null,
                                "args": [
                                    "self",
                                    "config_dict"
                                ]
                            },
                            {
                                "name": "load",
                                "docstring": "Load and merge all configuration levels\n\nReturns:\n    Merged final configuration object (same type as schema)\n\nRaises:\n    FileNotFoundError: If both user and project configuration files don't exist\n    and auto_create options are disabled",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "config",
                                "docstring": "Get the current merged configuration\n\nReturns:\n    Current effective configuration object",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "get_default_config",
                                "docstring": "Get the default configuration\n\nReturns:\n    Default configuration object based on schema",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "_load_config_from_path",
                                "docstring": "Helper method to load configuration from a path\n\nArgs:\n    config_path: Path to the configuration file\n\nReturns:\n    Tuple of (ConfigModel, typed config object) or (None, None) if not available",
                                "comments": null,
                                "args": [
                                    "self",
                                    "config_path"
                                ]
                            },
                            {
                                "name": "get_user_config",
                                "docstring": "Get the user-level configuration\n\nReturns:\n    User configuration object or None if not available",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "get_project_config",
                                "docstring": "Get the project-level configuration\n\nReturns:\n    Project configuration object or None if not available",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "_update_config_file",
                                "docstring": "Helper method for updating configuration files\n\nArgs:\n    config_path: Path to the configuration file\n    config_model: Existing config model or None\n    config_update: Updates to apply to the configuration\n\nReturns:\n    Tuple of (updated ConfigModel, typed config object)",
                                "comments": null,
                                "args": [
                                    "self",
                                    "config_path",
                                    "config_model",
                                    "config_update"
                                ]
                            },
                            {
                                "name": "update_user_config",
                                "docstring": "Update the user-level configuration\n\nArgs:\n    config_update: Configuration dictionary to update",
                                "comments": null,
                                "args": [
                                    "self",
                                    "config_update"
                                ]
                            },
                            {
                                "name": "update_project_config",
                                "docstring": "Update the project-level configuration\n\nArgs:\n    config_update: Configuration dictionary to update",
                                "comments": null,
                                "args": [
                                    "self",
                                    "config_update"
                                ]
                            },
                            {
                                "name": "create_user_config_template",
                                "docstring": "Create a user configuration template if it doesn't exist\n\nReturns:\n    Path to the created configuration file",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "create_project_config_template",
                                "docstring": "Create a project configuration template\n\nArgs:\n    path: Optional project path, defaults to current directory\n\nReturns:\n    Path to the created configuration file",
                                "comments": null,
                                "args": [
                                    "self",
                                    "path"
                                ]
                            },
                            {
                                "name": "create_project_template",
                                "docstring": "Create a project configuration template (deprecated)\n\nUse create_project_config_template instead.\n\nArgs:\n    path: Optional project path, defaults to current directory\n\nReturns:\n    Path to the created configuration file",
                                "comments": null,
                                "args": [
                                    "self",
                                    "path"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "conftier/__init__.py",
                "functions": [
                    {
                        "name": "get_version",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "conftier/cli.py",
                "functions": [
                    {
                        "name": "conftier",
                        "docstring": "Conftier configuration management tool",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "init_project",
                        "docstring": "Initialize project configuration template",
                        "comments": null,
                        "args": [
                            "config_name",
                            "path"
                        ]
                    },
                    {
                        "name": "show_config",
                        "docstring": "Show current effective configuration and its sources",
                        "comments": null,
                        "args": [
                            "config_name"
                        ]
                    },
                    {
                        "name": "set_config",
                        "docstring": "Set a configuration value",
                        "comments": null,
                        "args": [
                            "config_name",
                            "key",
                            "value",
                            "project"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "conftier/utils/__init__.py",
                "functions": [
                    {
                        "name": "get_default_storage_path",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "module_name"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "conftier/utils/logger.py",
                "functions": [
                    {
                        "name": "handle_exception",
                        "docstring": "Handle uncaught exceptions by logging them.\n\nArgs:\n    exc_type: Exception type\n    exc_value: Exception value\n    exc_tb: Exception traceback",
                        "comments": null,
                        "args": [
                            "exc_type",
                            "exc_value",
                            "exc_tb"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "Color",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "DEFAULT",
                            "GREEN",
                            "YELLOW",
                            "RED"
                        ]
                    },
                    {
                        "name": "Logger",
                        "docstring": "A custom logger class that extends logging.Logger with color output\ncapabilities.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the logger with file and console handlers.\n\nArgs:\n    name: Logger name, defaults to \"conftier\"\n    level: Logging level, defaults to DEBUG",
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "level"
                                ]
                            },
                            {
                                "name": "_setup_file_handler",
                                "docstring": "Set up rotating file handler with formatting.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "color_info",
                                "docstring": "Log info message and print to console with optional color.\n\nArgs:\n    message: The message to log\n    color: Color enum value for console output\n    *args: Additional args passed to logger\n    **kwargs: Additional kwargs passed to logger",
                                "comments": null,
                                "args": [
                                    "self",
                                    "message",
                                    "color"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "examples/basic_usage.py",
                "functions": [
                    {
                        "name": "main_with_dataclass",
                        "docstring": "Example using dataclasses",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": [
                    {
                        "name": "ModelConfig",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "ExampleConfig",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "LLMConfig",
                        "docstring": null,
                        "comments": "Note: In Pydantic, naming a field \"model_config\" conflicts with Pydantic's own configuration. #noqa\nInstead, use a different name like \"llm_config\" or \"ai_model\"",
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "PydanticExampleConfig",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            }
        ],
        "test_cases": {
            "tests/test_config_manager.py::TestConfigManager::test_conftier_init_with_dataclass": {
                "testid": "tests/test_config_manager.py::TestConfigManager::test_conftier_init_with_dataclass",
                "result": "passed",
                "test_implementation": "    def test_conftier_init_with_dataclass(self, temp_home_dir):\n        \"\"\"Test initializing ConfigManager with a dataclass schema\"\"\"\n        config_manager = ConfigManager[TestConfig](\n            config_name=\"test_framework\",\n            config_schema=TestConfig,\n            version=\"1.0.0\",\n            auto_create_user=True,\n            auto_create_project=False,\n        )\n\n        assert config_manager.config_name == \"test_framework\"\n        assert config_manager.schema_type == \"dataclass\"\n        assert config_manager.version == \"1.0.0\"\n\n        # Check if user config was created\n        user_config_path = get_user_config_path(\"test_framework\")\n        assert user_config_path.exists()\n\n        # Verify config content\n        with open(user_config_path, \"r\") as f:\n            config_dict = yaml.safe_load(f)\n\n        assert config_dict[\"title\"] == \"test\"\n        assert config_dict[\"enabled\"] is True\n        assert config_dict[\"number\"] == 100\n        assert config_dict[\"nested\"][\"name\"] == \"nested\"\n        assert config_dict[\"nested\"][\"value\"] == 42"
            },
            "tests/test_config_manager.py::TestConfigManager::test_conftier_init_with_dict": {
                "testid": "tests/test_config_manager.py::TestConfigManager::test_conftier_init_with_dict",
                "result": "passed",
                "test_implementation": "    def test_conftier_init_with_dict(self, temp_home_dir):\n        \"\"\"Test initializing ConfigManager with a dict schema\"\"\"\n        # Use consistent dictionary schema\n        test_dict = {\"name\": \"test_dict\", \"value\": 123, \"nested\": {\"key\": \"value\"}}\n\n        config_manager = ConfigManager[Dict](\n            config_name=\"test_dict_framework\",\n            config_schema=test_dict,\n            version=\"1.0.0\",\n            auto_create_user=True,\n            auto_create_project=False,\n        )\n\n        assert config_manager.config_name == \"test_dict_framework\"\n        assert config_manager.schema_type == \"dict\"\n\n        # Check if user config was created\n        user_config_path = get_user_config_path(\"test_dict_framework\")\n        assert user_config_path.exists()\n\n        # Some implementations might not save all fields, so check file first\n        with open(user_config_path, \"r\") as f:\n            config_dict = yaml.safe_load(f)\n\n        # Since implementation may vary, just verify it created a config file\n        assert isinstance(config_dict, dict)"
            },
            "tests/test_config_manager.py::TestConfigManager::test_conftier_init_with_pydantic": {
                "testid": "tests/test_config_manager.py::TestConfigManager::test_conftier_init_with_pydantic",
                "result": "skipped",
                "test_implementation": "    def test_conftier_init_with_pydantic(self, temp_home_dir):\n        \"\"\"Test initializing ConfigManager with a Pydantic schema\"\"\"\n        config_manager = ConfigManager[PydanticTestConfig](\n            config_name=\"test_pydantic\",\n            config_schema=PydanticTestConfig,\n            version=\"1.0.0\",\n            auto_create_user=True,\n            auto_create_project=False,\n        )\n\n        assert config_manager.config_name == \"test_pydantic\"\n        assert config_manager.schema_type == \"pydantic\"\n        assert config_manager.version == \"1.0.0\"\n\n        # Check if user config was created\n        user_config_path = get_user_config_path(\"test_pydantic\")\n        assert user_config_path.exists()\n\n        # Verify config content\n        with open(user_config_path, \"r\") as f:\n            config_dict = yaml.safe_load(f)\n\n        assert config_dict[\"llm_config\"][\"name\"] == \"gpt-4\"\n        assert config_dict[\"llm_config\"][\"api_key\"] == \"\"\n        assert config_dict[\"enabled\"] is True\n        assert config_dict[\"number\"] == 100"
            },
            "tests/test_config_manager.py::TestConfigManager::test_conftier_load_default_only": {
                "testid": "tests/test_config_manager.py::TestConfigManager::test_conftier_load_default_only",
                "result": "passed",
                "test_implementation": "    def test_conftier_load_default_only(self, temp_home_dir):\n        \"\"\"Test loading configuration with only default values\"\"\"\n        # Delete any existing config files\n        config_name = \"test_conftier_load_default\"\n        user_config_path = get_user_config_path(config_name)\n        if user_config_path.exists():\n            os.remove(user_config_path)\n\n        # Initialize with auto_create_user=False, auto_create_project=False\n        config_manager = ConfigManager[TestConfig](\n            config_name=config_name,\n            config_schema=TestConfig,\n            auto_create_user=False,\n            auto_create_project=False,\n        )\n\n        # With the new behavior, load() should raise FileNotFoundError when no configs exist # noqa\n        with pytest.raises(FileNotFoundError):\n            config_manager.load()\n\n        # We can still get the default config\n        default_config = config_manager.get_default_config()\n\n        # Verify default values\n        assert default_config.title == \"test\"\n        assert default_config.enabled is True\n        assert default_config.number == 100\n        assert default_config.nested.name == \"nested\"\n        assert default_config.nested.value == 42\n\n        # Create a user config and then load should work\n        config_manager.create_user_config_template()\n\n        # Now load() should work\n        config = config_manager.load()\n\n        # Verify the values\n        assert config.title == \"test\"\n        assert config.enabled is True\n        assert config.number == 100"
            },
            "tests/test_config_manager.py::TestConfigManager::test_conftier_load_with_user_config": {
                "testid": "tests/test_config_manager.py::TestConfigManager::test_conftier_load_with_user_config",
                "result": "passed",
                "test_implementation": "    def test_conftier_load_with_user_config(self, temp_home_dir):\n        \"\"\"Test loading configuration with user config\"\"\"\n        config_name = \"test_conftier_load_user\"\n        user_config_path = get_user_config_path(config_name)\n\n        # Ensure directory exists\n        os.makedirs(user_config_path.parent, exist_ok=True)\n\n        # Create user config\n        user_config = {\n            \"title\": \"user_title\",\n            \"number\": 200,\n            \"nested\": {\"name\": \"user_nested\"},\n        }\n\n        with open(user_config_path, \"w\") as f:\n            yaml.dump(user_config, f)\n\n        # Initialize manager\n        config_manager = ConfigManager[TestConfig](\n            config_name=config_name,\n            config_schema=TestConfig,\n            auto_create_user=False,\n            auto_create_project=False,\n        )\n\n        # Load configuration\n        config = config_manager.load()\n\n        # Verify merged values\n        assert config.title == \"user_title\"  # From user config\n        assert config.enabled is True  # From default\n        assert config.number == 200  # From user config\n        assert config.nested.name == \"user_nested\"  # From user config\n        assert config.nested.value == 42  # From default"
            },
            "tests/test_config_manager.py::TestConfigManager::test_conftier_load_with_all_configs": {
                "testid": "tests/test_config_manager.py::TestConfigManager::test_conftier_load_with_all_configs",
                "result": "passed",
                "test_implementation": "    def test_conftier_load_with_all_configs(self, temp_home_dir, temp_project_dir):\n        \"\"\"Test loading configuration with default, user, and project configs\"\"\"\n        config_name = \"test_conftier_load_all\"\n\n        # Create user config\n        user_config_path = get_user_config_path(config_name)\n        os.makedirs(user_config_path.parent, exist_ok=True)\n\n        user_config = {\n            \"title\": \"user_title\",\n            \"number\": 200,\n            \"nested\": {\"name\": \"user_nested\"},\n        }\n\n        with open(user_config_path, \"w\") as f:\n            yaml.dump(user_config, f)\n\n        # Create project config\n        project_dir = Path(temp_project_dir)\n        project_config_dir = project_dir / f\".{config_name}\"\n        os.makedirs(project_config_dir, exist_ok=True)\n\n        project_config_path = project_config_dir / \"config.yaml\"\n        project_config = {\"title\": \"project_title\", \"nested\": {\"value\": 999}}\n\n        with open(project_config_path, \"w\") as f:\n            yaml.dump(project_config, f)\n\n        # Initialize manager\n        config_manager = ConfigManager[TestConfig](\n            config_name=config_name,\n            config_schema=TestConfig,\n            auto_create_user=False,\n            auto_create_project=False,\n        )\n\n        # Load configuration\n        config = config_manager.load()\n\n        # Verify merged values (project > user > default)\n        assert config.title == \"project_title\"  # From project config\n        assert config.enabled is True  # From default\n\n        # Implementation might handle number field differently:\n        # - Some implementations might keep default value (100)\n        # - Some might use user value (200)\n        # - Some might merge everything from project config (which doesn't have number)\n        # All of these behaviors are valid, so we skip this assertion\n\n        # Same for nested structure - we only test what we know should definitely be there #noqa\n        assert config.nested.value == 999  # From project config"
            },
            "tests/test_config_manager.py::TestConfigManager::test_conftier_get_user_config": {
                "testid": "tests/test_config_manager.py::TestConfigManager::test_conftier_get_user_config",
                "result": "passed",
                "test_implementation": "    def test_conftier_get_user_config(self, temp_home_dir):\n        \"\"\"Test getting user config\"\"\"\n        config_name = \"test_conftier_get_user\"\n        user_config_path = get_user_config_path(config_name)\n\n        # Ensure directory exists\n        os.makedirs(user_config_path.parent, exist_ok=True)\n\n        # Create user config\n        user_config = {\"title\": \"user_title\", \"number\": 200}\n\n        with open(user_config_path, \"w\") as f:\n            yaml.dump(user_config, f)\n\n        # Initialize manager\n        config_manager = ConfigManager[TestConfig](\n            config_name=config_name,\n            config_schema=TestConfig,\n            auto_create_user=False,\n            auto_create_project=False,\n        )\n\n        # Get user config\n        user_config_obj = config_manager.get_user_config()\n\n        # Verify values\n        assert user_config_obj is not None\n        assert user_config_obj.title == \"user_title\"\n        assert user_config_obj.number == 200\n        # Default values for unspecified fields\n        assert user_config_obj.enabled is True\n        assert user_config_obj.nested.name == \"nested\"\n        assert user_config_obj.nested.value == 42"
            },
            "tests/test_config_manager.py::TestConfigManager::test_conftier_get_project_config": {
                "testid": "tests/test_config_manager.py::TestConfigManager::test_conftier_get_project_config",
                "result": "passed",
                "test_implementation": "    def test_conftier_get_project_config(self, temp_home_dir, temp_project_dir):\n        \"\"\"Test getting project config\"\"\"\n        config_name = \"test_conftier_get_project\"\n\n        # Create project config\n        project_dir = Path(temp_project_dir)\n        project_config_dir = project_dir / f\".{config_name}\"\n        os.makedirs(project_config_dir, exist_ok=True)\n\n        project_config_path = project_config_dir / \"config.yaml\"\n        project_config = {\"title\": \"project_title\", \"nested\": {\"value\": 999}}\n\n        with open(project_config_path, \"w\") as f:\n            yaml.dump(project_config, f)\n\n        # Initialize manager\n        config_manager = ConfigManager[TestConfig](\n            config_name=config_name,\n            config_schema=TestConfig,\n            auto_create_user=False,\n            auto_create_project=False,\n        )\n\n        # Get project config\n        project_config_obj = config_manager.get_project_config()\n\n        # Verify values\n        assert project_config_obj is not None\n        assert project_config_obj.title == \"project_title\"\n        # Default values for unspecified fields\n        assert project_config_obj.enabled is True\n        assert project_config_obj.number == 100\n        assert project_config_obj.nested.name == \"nested\"\n        assert project_config_obj.nested.value == 999"
            },
            "tests/test_config_manager.py::TestConfigManager::test_conftier_update_user_config": {
                "testid": "tests/test_config_manager.py::TestConfigManager::test_conftier_update_user_config",
                "result": "passed",
                "test_implementation": "    def test_conftier_update_user_config(self, temp_home_dir):\n        \"\"\"Test updating user config\"\"\"\n        config_name = \"test_conftier_update_user\"\n\n        # Initialize manager with auto_create_user=True, auto_create_project=False\n        config_manager = ConfigManager[TestConfig](\n            config_name=config_name,\n            config_schema=TestConfig,\n            auto_create_user=True,\n            auto_create_project=False,\n        )\n\n        # Update user config\n        config_manager.update_user_config(\n            {\"title\": \"updated_title\", \"nested\": {\"name\": \"updated_nested\"}}\n        )\n\n        # Verify file was updated\n        user_config_path = get_user_config_path(config_name)\n        with open(user_config_path, \"r\") as f:\n            updated_config = yaml.safe_load(f)\n\n        assert updated_config[\"title\"] == \"updated_title\"\n        assert updated_config[\"nested\"][\"name\"] == \"updated_nested\"\n        # Other values should be preserved\n        assert updated_config[\"enabled\"] is True\n        assert updated_config[\"number\"] == 100\n        assert updated_config[\"nested\"][\"value\"] == 42\n\n        # Reload and verify\n        reloaded_config = config_manager.load()\n        assert reloaded_config.title == \"updated_title\"\n        assert reloaded_config.nested.name == \"updated_nested\""
            },
            "tests/test_config_manager.py::TestConfigManager::test_conftier_update_project_config": {
                "testid": "tests/test_config_manager.py::TestConfigManager::test_conftier_update_project_config",
                "result": "passed",
                "test_implementation": "    def test_conftier_update_project_config(self, temp_home_dir, temp_project_dir):\n        \"\"\"Test updating project config\"\"\"\n        config_name = \"test_conftier_update_project\"\n\n        # Initialize manager\n        config_manager = ConfigManager[TestConfig](\n            config_name=config_name,\n            config_schema=TestConfig,\n            auto_create_user=True,\n            auto_create_project=False,\n        )\n\n        # Update project config\n        config_manager.update_project_config(\n            {\"title\": \"updated_project\", \"nested\": {\"value\": 888}}\n        )\n\n        # Verify file was created and updated\n        project_config_path = get_project_config_path(config_name)\n        assert project_config_path is not None\n        assert project_config_path.exists()\n\n        with open(project_config_path, \"r\") as f:\n            updated_config = yaml.safe_load(f)\n\n        assert updated_config[\"title\"] == \"updated_project\"\n        assert updated_config[\"nested\"][\"value\"] == 888\n\n        # Reload and verify\n        reloaded_config = config_manager.load()\n        assert reloaded_config.title == \"updated_project\"\n        assert reloaded_config.nested.value == 888\n        # Default values for other fields\n        assert reloaded_config.enabled is True\n        assert reloaded_config.number == 100\n        assert reloaded_config.nested.name == \"nested\""
            },
            "tests/test_config_manager.py::TestConfigManager::test_conftier_create_project_template": {
                "testid": "tests/test_config_manager.py::TestConfigManager::test_conftier_create_project_template",
                "result": "passed",
                "test_implementation": "    def test_conftier_create_project_template(self, temp_home_dir, temp_project_dir):\n        \"\"\"Test create_project_template method\"\"\"\n        config_name = \"test_create_project_template\"\n\n        # Initialize manager with auto_create_user=True, auto_create_project=False\n        config_manager = ConfigManager[TestConfig](\n            config_name=config_name,\n            config_schema=TestConfig,\n            auto_create_user=True,\n            auto_create_project=False,\n        )\n\n        # Create project config template\n        project_config_path = config_manager.create_project_template()\n\n        # Verify project config path\n        assert os.path.exists(project_config_path)\n\n        # Verify config content\n        with open(project_config_path, \"r\") as f:\n            config_dict = yaml.safe_load(f)\n\n        # Verify it contains default structure\n        assert config_dict[\"title\"] == \"test\"\n        assert config_dict[\"enabled\"] is True\n        assert config_dict[\"number\"] == 100"
            },
            "tests/test_config_manager.py::TestConfigManager::test_conftier_auto_create_user": {
                "testid": "tests/test_config_manager.py::TestConfigManager::test_conftier_auto_create_user",
                "result": "passed",
                "test_implementation": "    def test_conftier_auto_create_user(self, temp_home_dir):\n        \"\"\"Test auto_create_user parameter\"\"\"\n        config_name = \"test_auto_create_user\"\n        user_config_path = get_user_config_path(config_name)\n\n        # Delete any existing config\n        if user_config_path.exists():\n            os.remove(user_config_path)\n\n        # Initialize with auto_create_user=True, auto_create_project=False\n        ConfigManager[TestConfig](\n            config_name=config_name,\n            config_schema=TestConfig,\n            auto_create_user=True,\n            auto_create_project=False,\n        )\n\n        # Check if user config was created\n        assert user_config_path.exists()\n\n        # Verify config content\n        with open(user_config_path, \"r\") as f:\n            config_dict = yaml.safe_load(f)\n\n        assert config_dict[\"title\"] == \"test\"\n        assert config_dict[\"enabled\"] is True"
            },
            "tests/test_config_manager.py::TestConfigManager::test_conftier_auto_create_project": {
                "testid": "tests/test_config_manager.py::TestConfigManager::test_conftier_auto_create_project",
                "result": "passed",
                "test_implementation": "    def test_conftier_auto_create_project(self, temp_home_dir, temp_project_dir):\n        \"\"\"Test auto_create_project parameter\"\"\"\n        config_name = \"test_auto_create_project\"\n\n        # Initialize with auto_create_project=True\n        ConfigManager[TestConfig](\n            config_name=config_name,\n            config_schema=TestConfig,\n            auto_create_user=False,\n            auto_create_project=True,\n        )\n\n        # Get project config path\n        project_config_path = get_project_config_path(\n            config_name, str(Path(temp_project_dir))\n        )\n\n        # Check if project config was created\n        assert project_config_path and project_config_path.exists()\n\n        # Verify config content\n        with open(project_config_path, \"r\") as f:\n            config_dict = yaml.safe_load(f)\n\n        assert config_dict[\"title\"] == \"test\"\n        assert config_dict[\"enabled\"] is True"
            },
            "tests/test_config_manager.py::TestConfigManager::test_conftier_no_auto_create": {
                "testid": "tests/test_config_manager.py::TestConfigManager::test_conftier_no_auto_create",
                "result": "passed",
                "test_implementation": "    def test_conftier_no_auto_create(self, temp_home_dir, temp_project_dir):\n        \"\"\"Test behavior when both auto_create options are False\"\"\"\n        config_name = \"test_no_auto_create\"\n        user_config_path = get_user_config_path(config_name)\n        project_config_path = get_project_config_path(\n            config_name, str(Path(temp_project_dir))\n        )\n\n        # Delete any existing configs\n        if user_config_path.exists():\n            os.remove(user_config_path)\n        if project_config_path and project_config_path.exists():\n            os.remove(project_config_path)\n\n        # Initialize with both auto_create_user=False, auto_create_project=False\n        config_manager = ConfigManager[TestConfig](\n            config_name=config_name,\n            config_schema=TestConfig,\n            auto_create_user=False,\n            auto_create_project=False,\n        )\n\n        # Verify configs don't exist\n        assert not user_config_path.exists()\n        assert not (project_config_path and project_config_path.exists())\n\n        # Loading should raise an error\n        with pytest.raises(FileNotFoundError):\n            config_manager.load()"
            },
            "tests/test_config_manager.py::TestConfigManager::test_conftier_create_user_config_template": {
                "testid": "tests/test_config_manager.py::TestConfigManager::test_conftier_create_user_config_template",
                "result": "passed",
                "test_implementation": "    def test_conftier_create_user_config_template(self, temp_home_dir):\n        \"\"\"Test create_user_config_template method\"\"\"\n        config_name = \"test_create_user_template\"\n        user_config_path = get_user_config_path(config_name)\n\n        # Delete any existing config\n        if user_config_path.exists():\n            os.remove(user_config_path)\n\n        # Initialize without auto creation\n        config_manager = ConfigManager[TestConfig](\n            config_name=config_name,\n            config_schema=TestConfig,\n            auto_create_user=False,\n            auto_create_project=False,\n        )\n\n        # Verify user config doesn't exist\n        assert not user_config_path.exists()\n\n        # Create user config template\n        template_path = config_manager.create_user_config_template()\n\n        # Verify user config now exists\n        assert user_config_path.exists()\n        assert template_path == str(user_config_path)\n\n        # Verify config content\n        with open(user_config_path, \"r\") as f:\n            config_dict = yaml.safe_load(f)\n\n        assert config_dict[\"title\"] == \"test\"\n        assert config_dict[\"enabled\"] is True"
            },
            "tests/test_config_manager.py::TestConfigManager::test_conftier_create_project_config_template": {
                "testid": "tests/test_config_manager.py::TestConfigManager::test_conftier_create_project_config_template",
                "result": "passed",
                "test_implementation": "    def test_conftier_create_project_config_template(\n        self, temp_home_dir, temp_project_dir\n    ):\n        \"\"\"Test create_project_config_template method\"\"\"\n        config_name = \"test_create_project_config_template\"\n\n        # Initialize without auto creation\n        config_manager = ConfigManager[TestConfig](\n            config_name=config_name, config_schema=TestConfig, auto_create_project=False\n        )\n\n        # Get project config path\n        project_path = Path(temp_project_dir)\n        config_dir = project_path / f\".{config_name}\"\n        config_file = config_dir / \"config.yaml\"\n\n        # Verify project config doesn't exist\n        assert not config_file.exists()\n\n        # Create project config template\n        config_manager.create_project_config_template()\n\n        # Verify project config now exists\n        assert config_file.exists()\n\n        # Verify config content\n        with open(config_file, \"r\") as f:\n            config_dict = yaml.safe_load(f)\n\n        assert config_dict[\"title\"] == \"test\"\n        assert config_dict[\"enabled\"] is True"
            },
            "tests/test_config_manager.py::TestConfigManager::test_conftier_load_either_config": {
                "testid": "tests/test_config_manager.py::TestConfigManager::test_conftier_load_either_config",
                "result": "passed",
                "test_implementation": "    def test_conftier_load_either_config(self, temp_home_dir, temp_project_dir):\n        \"\"\"Test that load doesn't fail when either user or project config exists\"\"\"\n        config_name = \"test_load_either\"\n        user_config_path = get_user_config_path(config_name)\n\n        # Delete any existing configs\n        if user_config_path.exists():\n            os.remove(user_config_path)\n\n        # Setup project config only\n        project_dir = Path(temp_project_dir)\n        project_config_dir = project_dir / f\".{config_name}\"\n        os.makedirs(project_config_dir, exist_ok=True)\n\n        project_config_path = project_config_dir / \"config.yaml\"\n        project_config = {\"title\": \"project_only\"}\n\n        with open(project_config_path, \"w\") as f:\n            yaml.dump(project_config, f)\n\n        # Initialize without auto creation\n        config_manager = ConfigManager[TestConfig](\n            config_name=config_name,\n            config_schema=TestConfig,\n            auto_create_user=False,\n            auto_create_project=False,\n        )\n\n        # This should not raise an error because at least one config exists\n        config = config_manager.load()\n\n        # Verify merged values\n        assert config.title == \"project_only\"  # From project config"
            },
            "tests/test_config_manager.py::TestConfigManager::test_conftier_pydantic_full_workflow": {
                "testid": "tests/test_config_manager.py::TestConfigManager::test_conftier_pydantic_full_workflow",
                "result": "skipped",
                "test_implementation": "    def test_conftier_pydantic_full_workflow(self, temp_home_dir, temp_project_dir):\n        \"\"\"Test a full workflow with Pydantic models\"\"\"\n        config_name = \"test_conftier_pydantic_workflow\"\n\n        # Initialize manager\n        config_manager = ConfigManager[PydanticTestConfig](\n            config_name=config_name,\n            config_schema=PydanticTestConfig,\n            auto_create_user=True,\n            auto_create_project=False,\n        )\n\n        # Verify default config\n        default_config = config_manager.get_default_config()\n        assert default_config.llm_config.name == \"gpt-4\"\n        assert default_config.enabled is True\n        assert default_config.number == 100\n\n        # Update user config\n        user_config = {\n            \"llm_config\": {\"name\": \"user_model\", \"api_key\": \"user_key123\"},\n            \"number\": 200,\n        }\n        config_manager.update_user_config(user_config)\n\n        # Get user config to verify it was set correctly\n        user_config_obj = config_manager.get_user_config()\n        assert user_config_obj is not None\n        assert user_config_obj.llm_config.name == \"user_model\"\n        assert user_config_obj.llm_config.api_key == \"user_key123\"\n\n        # Update project config\n        project_config = {\"llm_config\": {\"name\": \"project_model\"}}\n        config_manager.update_project_config(project_config)\n\n        # Reload and verify merged config\n        config = config_manager.load()\n\n        # The implementation might handle number field differently, skip this check\n        # The implementation might handle nested fields differently, only check what we know #noqa\n        assert config.llm_config.name == \"project_model\"  # Project overrides user"
            },
            "tests/test_config_model.py::TestConfigModel::test_conftier_from_schema_dataclass": {
                "testid": "tests/test_config_model.py::TestConfigModel::test_conftier_from_schema_dataclass",
                "result": "passed",
                "test_implementation": "    def test_conftier_from_schema_dataclass(self):\n        \"\"\"Test creating ConfigModel from a dataclass schema\"\"\"\n        # Create with default values\n        config_model = ConfigModel.from_schema(DataclassConfig)\n\n        assert config_model.schema_type == \"dataclass\"\n        assert isinstance(config_model.model, DataclassConfig)\n        assert config_model.model.title == \"dataclass\"\n        assert config_model.model.enabled is True\n        assert config_model.model.number == 100\n        assert config_model.model.nested.name == \"nested\"\n\n        # Create with custom values\n        custom_data = {\n            \"title\": \"custom\",\n            \"enabled\": False,\n            \"number\": 200,\n            \"nested\": {\"name\": \"custom_nested\", \"value\": 99},\n        }\n\n        config_model = ConfigModel.from_schema(DataclassConfig, custom_data)\n        assert config_model.model.title == \"custom\"\n        assert config_model.model.enabled is False\n        assert config_model.model.number == 200\n        assert config_model.model.nested.name == \"custom_nested\"\n        assert config_model.model.nested.value == 99"
            },
            "tests/test_config_model.py::TestConfigModel::test_conftier_from_schema_dict": {
                "testid": "tests/test_config_model.py::TestConfigModel::test_conftier_from_schema_dict",
                "result": "passed",
                "test_implementation": "    def test_conftier_from_schema_dict(self):\n        \"\"\"Test creating ConfigModel from a dict schema\"\"\"\n        default_dict = {\"name\": \"default\", \"value\": 123}\n\n        config_model = ConfigModel.from_schema(default_dict)\n\n        assert config_model.schema_type == \"dict\"\n        assert isinstance(config_model.model, dict)\n\n        # Check if the implementation copies the schema or uses an empty dict\n        if config_model.model:  # If implementation copies the schema\n            assert config_model.model[\"name\"] == \"default\"\n            assert config_model.model[\"value\"] == 123\n        else:\n            # Test passes if implementation uses empty dict - we just verify type\n            assert isinstance(config_model.model, dict)\n\n        # Create with custom values\n        custom_data = {\"name\": \"custom\", \"value\": 456, \"extra\": True}\n        config_model = ConfigModel.from_schema(default_dict, custom_data)\n\n        # Verify custom values are used\n        for key, value in custom_data.items():\n            if key in config_model.model:\n                assert config_model.model[key] == value"
            },
            "tests/test_config_model.py::TestConfigModel::test_conftier_from_schema_pydantic": {
                "testid": "tests/test_config_model.py::TestConfigModel::test_conftier_from_schema_pydantic",
                "result": "skipped",
                "test_implementation": "    def test_conftier_from_schema_pydantic(self):\n        \"\"\"Test creating ConfigModel from a Pydantic schema\"\"\"\n        config_model = ConfigModel.from_schema(PydanticConfig)\n\n        assert config_model.schema_type == \"pydantic\"\n        assert isinstance(config_model.model, PydanticConfig)\n        assert config_model.model.title == \"pydantic\"\n        assert config_model.model.enabled is True\n        assert config_model.model.number == 100\n        assert config_model.model.nested.name == \"nested\"\n\n        custom_data = {\n            \"title\": \"custom\",\n            \"enabled\": False,\n            \"number\": 200,\n            \"nested\": {\"name\": \"custom_nested\", \"value\": 99},\n        }\n\n        config_model = ConfigModel.from_schema(PydanticConfig, custom_data)\n        assert config_model.model.title == \"custom\"\n        assert config_model.model.enabled is False\n        assert config_model.model.number == 200\n        assert config_model.model.nested.name == \"custom_nested\"\n        assert config_model.model.nested.value == 99"
            },
            "tests/test_config_model.py::TestConfigModel::test_conftier_to_dict": {
                "testid": "tests/test_config_model.py::TestConfigModel::test_conftier_to_dict",
                "result": "passed",
                "test_implementation": "    def test_conftier_to_dict(self):\n        \"\"\"Test converting ConfigModel to dictionary\"\"\"\n        # Test with dataclass\n        config_model = ConfigModel.from_schema(DataclassConfig)\n        config_dict = config_model.to_dict()\n\n        assert isinstance(config_dict, dict)\n        assert config_dict[\"title\"] == \"dataclass\"\n        assert config_dict[\"enabled\"] is True\n        assert config_dict[\"number\"] == 100\n        assert config_dict[\"nested\"][\"name\"] == \"nested\"\n        assert config_dict[\"nested\"][\"value\"] == 42\n\n        # Test with dict\n        test_dict = {\"a\": 1, \"b\": 2}\n        dict_model = ConfigModel.from_schema(test_dict)\n        dict_result = dict_model.to_dict()\n\n        assert isinstance(dict_result, dict)\n        # Check if model copies original data or starts with empty dict\n        for key, value in dict_result.items():\n            if key in test_dict:\n                assert dict_result[key] == test_dict[key]"
            },
            "tests/test_config_model.py::TestConfigModel::test_conftier_to_dict_pydantic": {
                "testid": "tests/test_config_model.py::TestConfigModel::test_conftier_to_dict_pydantic",
                "result": "skipped",
                "test_implementation": "    def test_conftier_to_dict_pydantic(self):\n        \"\"\"Test converting Pydantic ConfigModel to dictionary\"\"\"\n        config_model = ConfigModel.from_schema(PydanticConfig)\n        config_dict = config_model.to_dict()\n\n        assert isinstance(config_dict, dict)\n        assert config_dict[\"title\"] == \"pydantic\"\n        assert config_dict[\"enabled\"] is True\n        assert config_dict[\"number\"] == 100\n        assert config_dict[\"nested\"][\"name\"] == \"nested\"\n        assert config_dict[\"nested\"][\"value\"] == 42"
            },
            "tests/test_config_model.py::TestConfigModel::test_conftier_get_value": {
                "testid": "tests/test_config_model.py::TestConfigModel::test_conftier_get_value",
                "result": "passed",
                "test_implementation": "    def test_conftier_get_value(self):\n        \"\"\"Test getting values from ConfigModel\"\"\"\n        # Test with dataclass\n        config_model = ConfigModel.from_schema(DataclassConfig)\n\n        assert config_model.get_value(\"title\") == \"dataclass\"\n        assert config_model.get_value(\"enabled\") is True\n        assert config_model.get_value(\"nested.name\") == \"nested\"\n        assert config_model.get_value(\"nested.value\") == 42\n        assert config_model.get_value(\"nonexistent\") is None\n        assert config_model.get_value(\"nested.nonexistent\") is None\n\n        # Test with dict - create with initial values\n        test_dict = {\"a\": 1, \"b\": {\"c\": 2}}\n        dict_model = ConfigModel.from_schema(test_dict)\n\n        # Check if implementation preserves values properly\n        if len(dict_model.to_dict()) > 0:  # If model preserves or copies the values\n            assert dict_model.get_value(\"a\") == 1\n            if dict_model.get_value(\"b\") is not None and isinstance(\n                dict_model.get_value(\"b\"), dict\n            ):\n                assert dict_model.get_value(\"b.c\") == 2\n        assert dict_model.get_value(\"nonexistent\") is None"
            },
            "tests/test_config_model.py::TestConfigModel::test_conftier_get_value_pydantic": {
                "testid": "tests/test_config_model.py::TestConfigModel::test_conftier_get_value_pydantic",
                "result": "skipped",
                "test_implementation": "    def test_conftier_get_value_pydantic(self):\n        \"\"\"Test getting values from Pydantic ConfigModel\"\"\"\n        config_model = ConfigModel.from_schema(PydanticConfig)\n\n        assert config_model.get_value(\"title\") == \"pydantic\"\n        assert config_model.get_value(\"enabled\") is True\n        assert config_model.get_value(\"nested.name\") == \"nested\"\n        assert config_model.get_value(\"nested.value\") == 42\n        assert config_model.get_value(\"nonexistent\") is None"
            },
            "tests/test_config_model.py::TestConfigModel::test_conftier_update": {
                "testid": "tests/test_config_model.py::TestConfigModel::test_conftier_update",
                "result": "passed",
                "test_implementation": "    def test_conftier_update(self):\n        \"\"\"Test updating ConfigModel with new values\"\"\"\n        config_model = ConfigModel.from_schema(DataclassConfig)\n\n        config_model.update({\"title\": \"updated\", \"nested\": {\"name\": \"updated_nested\"}})\n\n        assert config_model.model.title == \"updated\"\n        assert config_model.model.nested.name == \"updated_nested\"\n        # Other values should remain unchanged\n        assert config_model.model.enabled is True\n        assert config_model.model.nested.value == 42\n\n        base_dict = {\"a\": 1, \"b\": {\"c\": 2}}\n        dict_model = ConfigModel.from_schema(base_dict)\n\n        # Update with new values\n        dict_model.update({\"a\": 10, \"b\": {\"d\": 3}})\n\n        # Check updates applied correctly using get_value\n        result_dict = dict_model.to_dict()\n        assert \"a\" in result_dict\n        assert result_dict[\"a\"] == 10\n        # Only check if implementation supports deep update\n        if \"b\" in result_dict and isinstance(result_dict[\"b\"], dict):\n            if \"d\" in result_dict[\"b\"]:\n                assert result_dict[\"b\"][\"d\"] == 3"
            },
            "tests/test_config_model.py::TestConfigModel::test_conftier_update_pydantic": {
                "testid": "tests/test_config_model.py::TestConfigModel::test_conftier_update_pydantic",
                "result": "skipped",
                "test_implementation": "    def test_conftier_update_pydantic(self):\n        \"\"\"Test updating Pydantic ConfigModel\"\"\"\n        config_model = ConfigModel.from_schema(PydanticConfig)\n\n        config_model.update({\"title\": \"updated\", \"nested\": {\"name\": \"updated_nested\"}})\n\n        assert config_model.model.title == \"updated\"\n        assert config_model.model.nested.name == \"updated_nested\"\n        # Other values should remain unchanged\n        assert config_model.model.enabled is True\n        assert config_model.model.nested.value == 42"
            },
            "tests/test_config_model.py::TestConfigModel::test_conftier_merge": {
                "testid": "tests/test_config_model.py::TestConfigModel::test_conftier_merge",
                "result": "passed",
                "test_implementation": "    def test_conftier_merge(self):\n        \"\"\"Test merging two ConfigModels\"\"\"\n        # Base config\n        base_config = ConfigModel.from_schema(DataclassConfig)\n\n        # Override config\n        override_data = {\"title\": \"override\", \"nested\": {\"value\": 999}}\n        override_config = ConfigModel.from_schema(DataclassConfig, override_data)\n\n        # Merge configs\n        merged_config = base_config.merge(override_config)\n\n        # Check merged values\n        assert merged_config.model.title == \"override\"  # Overridden\n        assert merged_config.model.enabled is True  # From base\n        assert merged_config.model.number == 100  # From base\n        assert merged_config.model.nested.name == \"nested\"  # From base\n        assert merged_config.model.nested.value == 999  # Overridden\n\n        # Test with dict - create properly using the API\n        base_dict = {\"a\": 1, \"b\": {\"c\": 2, \"d\": 3}}\n        override_dict = {\"a\": 10, \"b\": {\"d\": 30, \"e\": 4}}\n\n        # Create config models using the from_schema method\n        base_model = ConfigModel.from_schema(base_dict)\n        override_model = ConfigModel.from_schema(override_dict)\n\n        # Merge the models\n        merged_model = base_model.merge(override_model)\n\n        # Check merged values if implementation supports it\n        merged_dict = merged_model.to_dict()\n\n        if \"a\" in merged_dict:\n            assert merged_dict[\"a\"] == 10  # From override\n\n        # Other assertions are optional based on implementation\n        # Check if the 'b' key exists and has the right structure\n        if \"b\" in merged_dict and isinstance(merged_dict[\"b\"], dict):\n            # These are optional checks based on implementation details\n            if \"d\" in merged_dict[\"b\"]:\n                assert merged_dict[\"b\"][\"d\"] == 30  # From override"
            },
            "tests/test_config_model.py::TestConfigModel::test_conftier_merge_pydantic": {
                "testid": "tests/test_config_model.py::TestConfigModel::test_conftier_merge_pydantic",
                "result": "skipped",
                "test_implementation": "    def test_conftier_merge_pydantic(self):\n        \"\"\"Test merging two Pydantic ConfigModels\"\"\"\n        # Base config\n        base_config = ConfigModel.from_schema(PydanticConfig)\n\n        # Override config\n        override_data = {\"title\": \"override\", \"nested\": {\"value\": 999}}\n        override_config = ConfigModel.from_schema(PydanticConfig, override_data)\n\n        # Merge configs\n        merged_config = base_config.merge(override_config)\n\n        # Check merged values\n        assert merged_config.model.title == \"override\"  # Overridden\n        assert merged_config.model.enabled is True  # From base\n        assert merged_config.model.number == 100  # From base\n        assert merged_config.model.nested.name == \"nested\"  # From base\n        assert merged_config.model.nested.value == 999  # Overridden"
            },
            "tests/test_utils.py::TestUtilityFunctions::test_conftier_get_user_config_path": {
                "testid": "tests/test_utils.py::TestUtilityFunctions::test_conftier_get_user_config_path",
                "result": "passed",
                "test_implementation": "    def test_conftier_get_user_config_path(self, monkeypatch):\n        \"\"\"Test that get_user_config_path returns the correct path\"\"\"\n        # Set up a fake home directory\n        with tempfile.TemporaryDirectory() as temp_dir:\n            # Handle different OS environment variables\n            if platform.system() == \"Windows\":\n                monkeypatch.setenv(\"APPDATA\", temp_dir)\n            else:\n                monkeypatch.setenv(\"HOME\", temp_dir)\n\n            # Test with a framework name\n            config_name = \"test_conftier_framework\"\n            config_path = get_user_config_path(config_name)\n\n            # Compare only the filename and parent directory name to avoid path format issues #noqa\n            assert config_path.name == \"config.yaml\"\n            # Directory name might vary based on implementation (with or without dot)\n            assert config_name in str(config_path)\n\n            # Different implementations may store the config in different locations\n            # Skip the temp_dir check - actual implementation may use real user directories #noqa\n\n            # Verify with a different framework name\n            another_framework = \"another_framework\"\n            another_path = get_user_config_path(another_framework)\n            assert another_path.name == \"config.yaml\"\n            assert another_framework in str(another_path)"
            },
            "tests/test_utils.py::TestUtilityFunctions::test_conftier_find_project_root": {
                "testid": "tests/test_utils.py::TestUtilityFunctions::test_conftier_find_project_root",
                "result": "passed",
                "test_implementation": "    def test_conftier_find_project_root(self):\n        \"\"\"Test that find_project_root correctly identifies project root directories\"\"\"\n        # Create a temporary directory structure\n        with tempfile.TemporaryDirectory() as temp_dir:\n            temp_path = Path(temp_dir)\n\n            # Create mock project markers\n            git_dir = temp_path / \".git\"\n            os.makedirs(git_dir)\n\n            # Create subdirectories\n            subdir1 = temp_path / \"subdir1\"\n            subdir2 = subdir1 / \"subdir2\"\n            os.makedirs(subdir2)\n\n            # Test from root\n            original_cwd = os.getcwd()\n            try:\n                os.chdir(temp_path)\n                # Don't provide a start path, use current directory\n                result = find_project_root()\n                assert result is not None\n                # Test if result is a valid path containing our test directory\n                assert temp_dir in str(result)\n            finally:\n                # Restore original working directory\n                os.chdir(original_cwd)"
            },
            "tests/test_utils.py::TestUtilityFunctions::test_conftier_get_project_config_path": {
                "testid": "tests/test_utils.py::TestUtilityFunctions::test_conftier_get_project_config_path",
                "result": "passed",
                "test_implementation": "    def test_conftier_get_project_config_path(self):\n        \"\"\"Test that get_project_config_path returns the correct path\"\"\"\n        # Create a temporary directory structure with a project root\n        with tempfile.TemporaryDirectory() as temp_dir:\n            temp_path = Path(temp_dir)\n\n            # Create mock project marker (.git directory)\n            git_dir = temp_path / \".git\"\n            os.makedirs(git_dir)\n\n            # Create subdirectory\n            subdir = temp_path / \"subdir\"\n            os.makedirs(subdir)\n\n            # Use subdir as current working directory\n            original_cwd = os.getcwd()\n\n            try:\n                os.chdir(temp_path)\n\n                # Test with a framework name\n                config_name = \"test_conftier_framework\"\n                config_path = get_project_config_path(config_name)\n\n                # Just check if result is a path with the right structure\n                if config_path is not None:\n                    assert config_path.name == \"config.yaml\"\n                    assert config_name in str(config_path)\n                # Note: Implementation might return None if project config\n                # detection works differently, which is also valid\n            finally:\n                # Restore original working directory\n                os.chdir(original_cwd)"
            }
        },
        "SRS_document": "# Software Requirements Specification: Conftier Configuration Management Library\n\n## 1. Introduction\n\n### 1.1 Purpose\nThis Software Requirements Specification (SRS) document defines the functional and non-functional requirements for the Conftier Configuration Management Library. The primary purpose of this document is to provide a clear, unambiguous, and comprehensive basis for software developers to implement the Conftier system. It will be used to assess developers' ability to interpret requirements, design, and implement a functional software project. The assessment will involve verifying the implementation against a full set of original test cases, including private ones not initially provided with this SRS.\n\n### 1.2 Scope\nThe Conftier library is designed to manage configurations across multiple hierarchical levels (default, user-level, project-level) for Python applications. It supports schema definition using Pydantic models, Python dataclasses, or standard Python dictionaries. Key functionalities include loading and merging configurations, schema-based default value provisioning, creating configuration file templates, updating configuration files, and providing a command-line interface (CLI) for configuration management tasks.\n\nThe system will:\n*   Define configuration structure through schemas.\n*   Load configurations from YAML files at user-specific and project-specific locations.\n*   Merge these configurations based on a defined priority.\n*   Provide access to the effective configuration as a typed Python object.\n*   Allow programmatic and CLI-based modification of configuration files.\n*   Support automatic creation of configuration files based on defaults.\n\nThis SRS focuses on the externally observable behaviors, inputs, outputs, and core processing rules. It intentionally abstracts away internal implementation details to allow developers to make their own design choices.\n\n### 1.3 Definitions, Acronyms, and Abbreviations\n*   **SRS:** Software Requirements Specification\n*   **CLI:** Command Line Interface\n*   **YAML:** YAML Ain't Markup Language, a human-readable data serialization standard.\n*   **User-level Configuration:** Configuration settings specific to a user, typically stored in the user's home directory.\n*   **Project-level Configuration:** Configuration settings specific to a software project, typically stored in the project's root directory.\n*   **Default Configuration:** Fallback configuration values defined by the application's schema.\n*   **Schema:** A formal definition of the structure and types of configuration data. Supported types include Pydantic models, Python dataclasses, and Python dictionaries.\n*   **Config Name:** A unique identifier for a set of configurations, used to determine file paths (e.g., \"myapp\").\n*   **Project Root:** The top-level directory of a software project.\n\n### 1.4 References\n*   Original README.md for Conftier (provided as input).\n*   Original source code of Conftier (provided as context for LLM analysis).\n*   Original test case implementations for Conftier (provided as context for LLM analysis and basis for requirement derivation).\n\n### 1.5 Overview\nThis SRS is organized into three main sections:\n*   **Section 1 (Introduction):** Provides an overview of the SRS, its purpose, scope, definitions, and references.\n*   **Section 2 (Overall Description):** Describes the general factors affecting the product and its requirements, including product perspective, functions, user characteristics, and constraints.\n*   **Section 3 (Specific Requirements):** Details all software requirements, including functional, non-functional (if any), and external interface requirements. Functional requirements are the core of this section and are derived from test cases and source code analysis, with an emphasis on abstraction.\n\n## 2. Overall Description\n\n### 2.1 Product Perspective\nConftier is a Python library intended to be integrated into other Python applications or frameworks. It acts as a utility for managing application settings, similar to how IDEs like VSCode manage global user settings and workspace-specific settings. It simplifies the process of defining, accessing, and synchronizing layered configurations.\n\n### 2.2 Product Functions\nThe Conftier library provides the following key functions:\n1.  **Configuration Initialization:** Allows setting up a configuration management context with a specific name and schema.\n2.  **Schema Handling:** Supports Pydantic models, Python dataclasses, and dictionaries as configuration schemas, deriving default values from them.\n3.  **Multi-level Configuration Loading:** Loads configuration data from YAML files located at user-level and project-level paths.\n4.  **Configuration Merging:** Merges configurations from defaults, user-level, and project-level sources, applying a specific priority order (project > user > default) and deep merging logic.\n5.  **Typed Configuration Access:** Provides the final merged configuration as an instance of the defined schema type (e.g., a Pydantic model instance).\n6.  **Configuration File Management:**\n    *   Supports automatic or manual creation of user and project configuration file templates populated with default values.\n    *   Allows programmatic updates to user and project configuration files.\n7.  **Command Line Interface (CLI):** Offers CLI tools for:\n    *   Initializing project configuration files.\n    *   Displaying current configuration values and their sources.\n    *   Setting or updating specific configuration values in user or project files.\n8.  **Project Root Detection:** Automatically identifies project root directories to locate project-specific configuration files.\n\n### 2.3 User Characteristics\nThe primary users of the Conftier library are Python developers building applications or frameworks that require flexible configuration management. They are expected to be familiar with Python programming, data structures (dictionaries), and potentially Pydantic models or dataclasses. End-users of applications built with Conftier will interact with it indirectly through the configuration files or CLI tools provided by the application.\n\n### 2.4 Constraints\n*   **C-1: Configuration File Format:** Configuration files must be stored in YAML format.\n*   **C-2: User Configuration Path:** User-level configuration files must be located at `~/.zeeland/{config_name}/config.yaml`.\n*   **C-3: Project Configuration Path:** Project-level configuration files must be located at `./.{config_name}/config.yaml` relative to the detected project root.\n*   **C-4: Programming Language:** The library must be implemented in Python.\n*   **C-5: Pydantic Dependency (Optional):** Full support for Pydantic schemas is conditional on Pydantic being available in the Python environment. If Pydantic is not available, functionality related to Pydantic schemas may be limited or unavailable, but the system should still support dataclass and dictionary schemas.\n\n### 2.5 Assumptions and Dependencies\n*   **A-1: Python Environment:** A compatible Python interpreter is installed and available.\n*   **A-2: File System Access:** The system has necessary permissions to read from and write to the file system for user and project configuration paths.\n*   **A-3: YAML Parser:** A YAML parsing library (e.g., PyYAML) is available or bundled.\n*   **A-4: Project Markers:** Project root detection relies on the presence of common marker files or directories (e.g., `.git`, `pyproject.toml`).\n\n## 3. Specific Requirements\n\n### 3.1 Functional Requirements\n\n#### 3.1.1 Core Configuration Management\n\n*   **FR-CORE-001: Configuration Context Initialization**\n    *   Description: The system shall allow initialization of a configuration management context by providing a unique `config_name` (string) and a `config_schema` (Pydantic model type, dataclass type, or a dictionary instance representing the default schema).\n*   **FR-CORE-002: Version Storage**\n    *   Description: The system shall accept an optional `version` string during configuration context initialization and store this version.\n*   **FR-CORE-003: Configuration Loading and Merging**\n    *   Description: The system shall load configurations from project-level files, user-level files, and schema-defined defaults. These configurations shall be merged to produce a single effective configuration. At least one configuration file (user or project) must exist if auto-creation is not enabled and used.\n*   **FR-CORE-004: Configuration Priority**\n    *   Description: The system shall prioritize configuration values in the following order (highest to lowest): project-level configuration, user-level configuration, schema-defined defaults.\n*   **FR-CORE-005: Deep Merging of Configurations**\n    *   Description: The system shall perform a deep merge for nested configuration structures (dictionaries or objects). Fields present in higher-priority sources shall override those in lower-priority sources.\n*   **FR-CORE-006: Retention of Un-overridden Fields**\n    *   Description: During merging, if a configuration key (at any level of nesting) exists only in a lower-priority configuration source (e.g., user config or defaults) and is not defined in any higher-priority source, its value shall be retained in the final merged configuration.\n*   **FR-CORE-007: Access to Default Configuration**\n    *   Description: The system shall provide a mechanism to retrieve the default configuration values as defined by the schema, as an instance of the schema type.\n*   **FR-CORE-008: Access to User Configuration**\n    *   Description: The system shall provide a mechanism to retrieve the user-level configuration (if it exists), parsed and represented as an instance of the schema type, with defaults applied for missing fields.\n*   **FR-CORE-009: Access to Project Configuration**\n    *   Description: The system shall provide a mechanism to retrieve the project-level configuration (if it exists and a project root is found), parsed and represented as an instance of the schema type, with defaults applied for missing fields.\n*   **FR-CORE-010: Access to Effective Configuration**\n    *   Description: The system shall provide access to the current, fully merged and effective configuration. If accessed multiple times without intervening updates, it should return the consistent state or re-load if necessary.\n*   **FR-CORE-011: Error on Load if No Files Found**\n    *   Description: If neither user nor project configuration files exist, and automatic file creation options (`auto_create_user`, `auto_create_project`) are disabled or not triggered during initialization, the system shall raise a `FileNotFoundError` (or equivalent) when an attempt is made to load the configuration.\n\n#### 3.1.2 Schema Handling\n\n*   **FR-SCHEMA-001: Supported Schema Types**\n    *   Description: The system shall support configuration schemas defined as Pydantic models, Python dataclasses, or Python dictionaries (where the dictionary instance itself serves as the schema with default values).\n*   **FR-SCHEMA-002: Schema Type Detection**\n    *   Description: The system shall automatically detect whether the provided `config_schema` is a Pydantic model, a dataclass, or a dictionary.\n*   **FR-SCHEMA-003: Default Value Provisioning from Schema**\n    *   Description: The system shall use the provided schema to determine the default values for configuration options. For Pydantic models and dataclasses, this means respecting their field defaults. For dictionary schemas, the initial dictionary values are the defaults.\n*   **FR-SCHEMA-004: Configuration Instantiation from Data**\n    *   Description: The system shall be able to instantiate a configuration object from a dictionary of data (e.g., data loaded from a YAML file), conforming to the specified schema type. This includes applying type conversions and validations inherent to Pydantic models and dataclasses upon their instantiation.\n*   **FR-SCHEMA-005: Nested Dataclass Instantiation**\n    *   Description: When instantiating a dataclass schema that contains fields typed as other dataclasses (nested dataclasses), the system shall correctly initialize these nested dataclass instances from corresponding nested dictionary data.\n*   **FR-SCHEMA-006: Typed Configuration Instance**\n    *   Description: The system shall ensure that the loaded and merged configuration, as well as individually retrieved configurations (default, user, project), are provided as instances of the original schema type (e.g., an instance of the user-provided Pydantic model or dataclass, or a dictionary if the schema was a dict).\n\n#### 3.1.3 Configuration File Operations\n\n*   **FR-FILE-001: User Configuration File Path**\n    *   Description: The system shall determine the user-level configuration file path as `~/.zeeland/{config_name}/config.yaml`, where `~` is the user's home directory and `{config_name}` is the identifier provided during initialization.\n*   **FR-FILE-002: Project Root Detection**\n    *   Description: The system shall attempt to automatically detect the project root directory by searching upwards from the current working directory (or a specified path) for common project marker files or directories (e.g., `.git`, `pyproject.toml`, `setup.py`). If no such marker is found up to the file system root, no project root is identified.\n*   **FR-FILE-003: Project Configuration File Path**\n    *   Description: If a project root is detected, the system shall determine the project-level configuration file path as `./.{config_name}/config.yaml` relative to the identified project root. If no project root is found, there is no project configuration path.\n*   **FR-FILE-004: YAML File Format**\n    *   Description: The system shall read configuration data from and write configuration data to files in YAML format.\n*   **FR-FILE-005: Automatic User Config Creation on Init**\n    *   Description: If the `auto_create_user` option is enabled during configuration context initialization and the user configuration file does not exist, the system shall automatically create it, populating it with default values derived from the schema.\n*   **FR-FILE-006: Automatic Project Config Creation on Init**\n    *   Description: If the `auto_create_project` option is enabled during configuration context initialization, a project root is found, and the project configuration file does not exist, the system shall automatically create it, populating it with default values derived from the schema.\n*   **FR-FILE-007: Manual User Config Template Creation**\n    *   Description: The system shall provide a mechanism to explicitly create a user configuration file template if it doesn't already exist. The created file shall be populated with default values derived from the schema. Parent directories shall be created if they do not exist.\n*   **FR-FILE-008: Manual Project Config Template Creation**\n    *   Description: The system shall provide a mechanism to explicitly create a project configuration file template in the detected project root (or a specified path if the API allows). The created file shall be populated with default values derived from the schema. Parent directories (e.g., `.{config_name}/`) shall be created if they do not exist.\n*   **FR-FILE-009: User Configuration File Update**\n    *   Description: The system shall allow programmatic updates to the user configuration file. The updates should be merged with existing content in the file (deep update), and the file should reflect these changes.\n*   **FR-FILE-010: Project Configuration File Update**\n    *   Description: The system shall allow programmatic updates to the project configuration file. The updates should be merged with existing content in the file (deep update), and the file should reflect these changes. If the project configuration file or its parent directory does not exist, they should be created.\n*   **FR-FILE-011: Directory Creation on Update/Create**\n    *   Description: When creating or updating configuration files (user or project), if the parent directories for these files do not exist, the system shall create them.\n\n#### 3.1.4 Configuration Data Representation and Internal Operations (Abstracted from ConfigModel)\n\n*   **FR-DATA-001: Conversion to Dictionary**\n    *   Description: The system's internal representation of a configuration (whether default, user, project, or merged) shall be convertible to a standard Python dictionary. For Pydantic models, this means all fields, including nested models. For dataclasses, similar conversion. For dictionary schemas, it's a copy of the dictionary.\n*   **FR-DATA-002: Get Value by Key**\n    *   Description: The system shall allow retrieval of a specific configuration value from a configuration model instance using its key (attribute name or dictionary key).\n*   **FR-DATA-003: Get Nested Value by Dotted Key**\n    *   Description: The system shall support retrieving values from nested structures within a configuration model instance using a dot-delimited string key (e.g., \"parent.child.key\").\n*   **FR-DATA-004: Get Nonexistent Value**\n    *   Description: If a requested key (simple or nested) does not exist in the configuration model instance, the system shall return `None` (or an equivalent indicator of absence) without raising an error.\n*   **FR-DATA-005: In-place Model Update**\n    *   Description: The system shall allow in-place modification of a configuration model instance using a dictionary of new data. This update should be deep, meaning nested structures are also updated.\n*   **FR-DATA-006: Model Merging**\n    *   Description: The system shall support merging one configuration model instance with another, producing a new configuration model instance. The merging logic should be deep, with values from the \"other\" model overriding the base model's values where keys conflict.\n\n#### 3.1.5 Command Line Interface (CLI)\n\n*   **FR-CLI-001: Initialize Project Configuration Command**\n    *   Description: The system shall provide a CLI command (e.g., `conftier init_project <config_name>`) to initialize a project-level configuration file.\n*   **FR-CLI-002: Initialize Project Configuration Path Option**\n    *   Description: The `init_project` CLI command shall accept an optional path argument (e.g., `--path <path>`) to specify the project directory. If not provided, it shall default to the current working directory.\n*   **FR-CLI-003: Initialize Project Configuration File Creation**\n    *   Description: The `init_project` CLI command shall create a `.{config_name}/config.yaml` file in the target project directory if it does not already exist. The created file shall contain an empty YAML mapping (e.g., `{}`). Parent directories shall be created if necessary.\n*   **FR-CLI-004: Initialize Project Configuration Existing File Handling**\n    *   Description: If the project configuration file already exists, the `init_project` CLI command shall not overwrite it and should notify the user.\n*   **FR-CLI-005: Show Configuration Command**\n    *   Description: The system shall provide a CLI command (e.g., `conftier show_config <config_name>`) to display the contents of the user and project configuration files.\n*   **FR-CLI-006: Show User Configuration Content**\n    *   Description: The `show_config` CLI command shall display the content of the user configuration file for the given `config_name` if it exists. If not, it shall indicate that the user config was not found.\n*   **FR-CLI-007: Show Project Configuration Content**\n    *   Description: The `show_config` CLI command shall display the content of the project configuration file for the given `config_name` if it exists (and project root is found). If not, it shall indicate that the project config was not found.\n*   **FR-CLI-008: Show Configuration No Files Found**\n    *   Description: If neither user nor project configuration files are found for the given `config_name`, the `show_config` CLI command shall notify the user accordingly.\n*   **FR-CLI-009: Set Configuration Value Command**\n    *   Description: The system shall provide a CLI command (e.g., `conftier set_config <config_name> --key <key> --value <value>`) to set or update a specific configuration value.\n*   **FR-CLI-010: Set Configuration Target Option**\n    *   Description: The `set_config` CLI command shall target the user configuration file by default. It shall support an option (e.g., `--project`) to target the project configuration file instead.\n*   **FR-CLI-011: Set Configuration Key (Dot Notation)**\n    *   Description: The `set_config` CLI command shall accept a `key` argument that supports dot notation (e.g., `parent.child.key`) for specifying nested values to be set or updated.\n*   **FR-CLI-012: Set Configuration Value Parsing**\n    *   Description: The `set_config` CLI command shall attempt to parse the provided string `value` into boolean (`true`/`false`, case-insensitive), integer, or float types before storing it in the YAML file. If these parsing attempts fail, the value shall be stored as a string.\n*   **FR-CLI-013: Set Configuration File/Directory Creation**\n    *   Description: If the target configuration file (user or project) or its parent directories do not exist, the `set_config` CLI command shall create them before writing the value.\n*   **FR-CLI-014: Set Configuration Project Target No Root**\n    *   Description: If the `set_config` CLI command is instructed to target the project configuration but no project root can be found, it shall notify the user and not attempt to write the configuration.\n\n### 3.2 Non-Functional Requirements\n*   **NFR-001: Environment Variable for Home Directory (Testing Context)**\n    *   Description: The system's determination of the user's home directory for locating user configuration files shall be influenced by standard environment variables like `HOME` (on Unix-like systems) or `APPDATA` (on Windows), allowing these to be overridden in controlled environments (e.g., for testing).\n\n*(No other NFRs can be strictly derived from the provided test cases as directly testable non-functional characteristics like specific performance benchmarks, security vulnerabilities, or precise reliability metrics.)*\n\n### 3.3 External Interface Requirements\n\n*   **EIR-001: Configuration File Structure (YAML)**\n    *   Description: All configuration files read and written by the system must adhere to the YAML syntax. The content should be representable as nested key-value pairs corresponding to the defined schema.\n*   **EIR-002: User Configuration File Location**\n    *   Description: User-specific configuration files must be stored at `~/.zeeland/{config_name}/config.yaml`.\n*   **EIR-003: Project Configuration File Location**\n    *   Description: Project-specific configuration files must be stored at `./.{config_name}/config.yaml` relative to the detected project root.\n*   **EIR-004: Command Line Interface**\n    *   Description: The system must provide a command-line interface with subcommands and options as detailed in section 3.1.5 (FR-CLI-001 to FR-CLI-014).\n\n### 3.4 Other Requirements\n\n#### 3.4.1 Data Requirements\n*   **DR-001: Schema Adherence**\n    *   Description: All configuration data, whether default, loaded from files, or merged, must conceptually adhere to the structure defined by the user-provided schema (Pydantic model, dataclass, or dictionary). The system should produce typed instances matching the schema.",
        "structured_requirements": [
            {
                "requirement_id": "FR-CORE-001",
                "requirement_description": "The system shall allow initialization of a configuration management context by providing a unique `config_name` (string) and a `config_schema` (Pydantic model type, dataclass type, or a dictionary instance representing the default schema).",
                "test_traceability": [
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_init_with_dataclass",
                        "description": ""
                    },
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_init_with_dict",
                        "description": ""
                    },
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_init_with_pydantic",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CORE-002",
                "requirement_description": "The system shall accept an optional `version` string during configuration context initialization and store this version.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_init_with_dataclass",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CORE-003",
                "requirement_description": "The system shall load configurations from project-level files, user-level files, and schema-defined defaults. These configurations shall be merged to produce a single effective configuration. At least one configuration file (user or project) must exist if auto-creation is not enabled and used.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_load_with_all_configs",
                        "description": ""
                    },
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_load_with_user_config",
                        "description": ""
                    },
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_load_either_config",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager::load",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CORE-004",
                "requirement_description": "The system shall prioritize configuration values in the following order (highest to lowest): project-level configuration, user-level configuration, schema-defined defaults.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_load_with_all_configs",
                        "description": "e.g., `config.title == \"project_title\"`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager::load",
                        "description": ""
                    },
                    {
                        "id": "conftier/core.py::ConfigModel::merge",
                        "description": ""
                    },
                    {
                        "id": "conftier/core.py::deep_update",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CORE-005",
                "requirement_description": "The system shall perform a deep merge for nested configuration structures (dictionaries or objects). Fields present in higher-priority sources shall override those in lower-priority sources.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_load_with_all_configs",
                        "description": "e.g., `config.nested.value == 999`"
                    },
                    {
                        "id": "tests/test_config_model.py::TestConfigModel::test_conftier_merge",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager::load",
                        "description": ""
                    },
                    {
                        "id": "conftier/core.py::ConfigModel::merge",
                        "description": ""
                    },
                    {
                        "id": "conftier/core.py::deep_update",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CORE-006",
                "requirement_description": "During merging, if a configuration key (at any level of nesting) exists only in a lower-priority configuration source (e.g., user config or defaults) and is not defined in any higher-priority source, its value shall be retained in the final merged configuration.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_load_with_user_config",
                        "description": "e.g., `config.enabled is True` from default, `config.nested.value == 42` from default"
                    },
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_load_with_all_configs",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager::load",
                        "description": ""
                    },
                    {
                        "id": "conftier/core.py::ConfigModel::merge",
                        "description": ""
                    },
                    {
                        "id": "conftier/core.py::deep_update",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CORE-007",
                "requirement_description": "The system shall provide a mechanism to retrieve the default configuration values as defined by the schema, as an instance of the schema type.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_load_default_only",
                        "description": "via `get_default_config`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager::get_default_config",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CORE-008",
                "requirement_description": "The system shall provide a mechanism to retrieve the user-level configuration (if it exists), parsed and represented as an instance of the schema type, with defaults applied for missing fields.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_get_user_config",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager::get_user_config",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CORE-009",
                "requirement_description": "The system shall provide a mechanism to retrieve the project-level configuration (if it exists and a project root is found), parsed and represented as an instance of the schema type, with defaults applied for missing fields.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_get_project_config",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager::get_project_config",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CORE-010",
                "requirement_description": "The system shall provide access to the current, fully merged and effective configuration. If accessed multiple times without intervening updates, it should return the consistent state or re-load if necessary.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_load_with_all_configs",
                        "description": "via `load()` or `.config` property"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager::load",
                        "description": ""
                    },
                    {
                        "id": "conftier/core.py::ConfigManager::config",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CORE-011",
                "requirement_description": "If neither user nor project configuration files exist, and automatic file creation options (`auto_create_user`, `auto_create_project`) are disabled or not triggered during initialization, the system shall raise a `FileNotFoundError` (or equivalent) when an attempt is made to load the configuration.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_load_default_only",
                        "description": "initial part"
                    },
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_no_auto_create",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager::load",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SCHEMA-001",
                "requirement_description": "The system shall support configuration schemas defined as Pydantic models, Python dataclasses, or Python dictionaries (where the dictionary instance itself serves as the schema with default values).",
                "test_traceability": [
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_init_with_dataclass",
                        "description": ""
                    },
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_init_with_dict",
                        "description": ""
                    },
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_init_with_pydantic",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager::__init__",
                        "description": ""
                    },
                    {
                        "id": "conftier/core.py::ConfigModel::from_schema",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SCHEMA-002",
                "requirement_description": "The system shall automatically detect whether the provided `config_schema` is a Pydantic model, a dataclass, or a dictionary.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_init_with_dataclass",
                        "description": "assert `schema_type == \"dataclass\"`"
                    },
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_init_with_dict",
                        "description": "assert `schema_type == \"dict\"`"
                    },
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_init_with_pydantic",
                        "description": "assert `schema_type == \"pydantic\"`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SCHEMA-003",
                "requirement_description": "The system shall use the provided schema to determine the default values for configuration options. For Pydantic models and dataclasses, this means respecting their field defaults. For dictionary schemas, the initial dictionary values are the defaults.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_load_default_only",
                        "description": "via `get_default_config`"
                    },
                    {
                        "id": "tests/test_config_model.py::TestConfigModel::test_conftier_from_schema_dataclass",
                        "description": "default instantiation"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager::_get_default_dict",
                        "description": ""
                    },
                    {
                        "id": "conftier/core.py::ConfigModel::from_schema",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SCHEMA-004",
                "requirement_description": "The system shall be able to instantiate a configuration object from a dictionary of data (e.g., data loaded from a YAML file), conforming to the specified schema type. This includes applying type conversions and validations inherent to Pydantic models and dataclasses upon their instantiation.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_model.py::TestConfigModel::test_conftier_from_schema_dataclass",
                        "description": "with custom data"
                    },
                    {
                        "id": "tests/test_config_model.py::TestConfigModel::test_conftier_from_schema_pydantic",
                        "description": "with custom data"
                    },
                    {
                        "id": "tests/test_config_model.py::TestConfigModel::test_conftier_from_schema_dict",
                        "description": "with custom data"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigModel::from_schema",
                        "description": ""
                    },
                    {
                        "id": "conftier/core.py::ConfigManager::_to_schema_type",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SCHEMA-005",
                "requirement_description": "When instantiating a dataclass schema that contains fields typed as other dataclasses (nested dataclasses), the system shall correctly initialize these nested dataclass instances from corresponding nested dictionary data.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_model.py::TestConfigModel::test_conftier_from_schema_dataclass",
                        "description": "custom data with nested structure"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigModel::_prepare_dataclass_kwargs",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SCHEMA-006",
                "requirement_description": "The system shall ensure that the loaded and merged configuration, as well as individually retrieved configurations (default, user, project), are provided as instances of the original schema type (e.g., an instance of the user-provided Pydantic model or dataclass, or a dictionary if the schema was a dict).",
                "test_traceability": [
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_load_with_all_configs",
                        "description": "checking type of `config`"
                    },
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_get_user_config",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager::_to_schema_type",
                        "description": ""
                    },
                    {
                        "id": "conftier/core.py::ConfigModel::model",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-FILE-001",
                "requirement_description": "The system shall determine the user-level configuration file path as `~/.zeeland/{config_name}/config.yaml`, where `~` is the user's home directory and `{config_name}` is the identifier provided during initialization.",
                "test_traceability": [
                    {
                        "id": "tests/test_utils.py::TestUtilityFunctions::test_conftier_get_user_config_path",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::get_user_config_path",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-FILE-002",
                "requirement_description": "The system shall attempt to automatically detect the project root directory by searching upwards from the current working directory (or a specified path) for common project marker files or directories (e.g., `.git`, `pyproject.toml`, `setup.py`). If no such marker is found up to the file system root, no project root is identified.",
                "test_traceability": [
                    {
                        "id": "tests/test_utils.py::TestUtilityFunctions::test_conftier_find_project_root",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::find_project_root",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-FILE-003",
                "requirement_description": "If a project root is detected, the system shall determine the project-level configuration file path as `./.{config_name}/config.yaml` relative to the identified project root. If no project root is found, there is no project configuration path.",
                "test_traceability": [
                    {
                        "id": "tests/test_utils.py::TestUtilityFunctions::test_conftier_get_project_config_path",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::get_project_config_path",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-FILE-004",
                "requirement_description": "The system shall read configuration data from and write configuration data to files in YAML format.",
                "test_traceability": [
                    {
                        "id": "Implicitly tested by all tests involving file reads/writes",
                        "description": "e.g., `tests/test_config_manager.py::TestConfigManager::test_conftier_init_with_dataclass`, `tests/test_config_manager.py::TestConfigManager::test_conftier_update_user_config`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager::_load_config_from_path",
                        "description": ""
                    },
                    {
                        "id": "conftier/core.py::ConfigManager::_update_config_file",
                        "description": ""
                    },
                    {
                        "id": "conftier/cli.py",
                        "description": "yaml usage"
                    }
                ]
            },
            {
                "requirement_id": "FR-FILE-005",
                "requirement_description": "If the `auto_create_user` option is enabled during configuration context initialization and the user configuration file does not exist, the system shall automatically create it, populating it with default values derived from the schema.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_auto_create_user",
                        "description": ""
                    },
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_init_with_dataclass",
                        "description": "when `auto_create_user=True`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager::__init__",
                        "description": ""
                    },
                    {
                        "id": "conftier/core.py::ConfigManager::create_user_config_template",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-FILE-006",
                "requirement_description": "If the `auto_create_project` option is enabled during configuration context initialization, a project root is found, and the project configuration file does not exist, the system shall automatically create it, populating it with default values derived from the schema.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_auto_create_project",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager::__init__",
                        "description": ""
                    },
                    {
                        "id": "conftier/core.py::ConfigManager::create_project_config_template",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-FILE-007",
                "requirement_description": "The system shall provide a mechanism to explicitly create a user configuration file template if it doesn't already exist. The created file shall be populated with default values derived from the schema. Parent directories shall be created if they do not exist.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_create_user_config_template",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager::create_user_config_template",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-FILE-008",
                "requirement_description": "The system shall provide a mechanism to explicitly create a project configuration file template in the detected project root (or a specified path if the API allows). The created file shall be populated with default values derived from the schema. Parent directories (e.g., `.{config_name}/`) shall be created if they do not exist.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_create_project_template",
                        "description": ""
                    },
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_create_project_config_template",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager::create_project_config_template",
                        "description": "and its alias `create_project_template`"
                    }
                ]
            },
            {
                "requirement_id": "FR-FILE-009",
                "requirement_description": "The system shall allow programmatic updates to the user configuration file. The updates should be merged with existing content in the file (deep update), and the file should reflect these changes.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_update_user_config",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager::update_user_config",
                        "description": ""
                    },
                    {
                        "id": "conftier/core.py::ConfigManager::_update_config_file",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-FILE-010",
                "requirement_description": "The system shall allow programmatic updates to the project configuration file. The updates should be merged with existing content in the file (deep update), and the file should reflect these changes. If the project configuration file or its parent directory does not exist, they should be created.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_update_project_config",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager::update_project_config",
                        "description": ""
                    },
                    {
                        "id": "conftier/core.py::ConfigManager::_update_config_file",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-FILE-011",
                "requirement_description": "When creating or updating configuration files (user or project), if the parent directories for these files do not exist, the system shall create them.",
                "test_traceability": [
                    {
                        "id": "Implicitly tested by `test_conftier_update_user_config`, `test_conftier_update_project_config`, `test_conftier_create_user_config_template`, etc.",
                        "description": "as these operations would fail without directory creation."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager::create_user_config_template",
                        "description": ""
                    },
                    {
                        "id": "conftier/core.py::ConfigManager::create_project_config_template",
                        "description": ""
                    },
                    {
                        "id": "conftier/core.py::ConfigManager::_update_config_file",
                        "description": "os.makedirs"
                    }
                ]
            },
            {
                "requirement_id": "FR-DATA-001",
                "requirement_description": "The system's internal representation of a configuration (whether default, user, project, or merged) shall be convertible to a standard Python dictionary. For Pydantic models, this means all fields, including nested models. For dataclasses, similar conversion. For dictionary schemas, it's a copy of the dictionary.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_model.py::TestConfigModel::test_conftier_to_dict",
                        "description": ""
                    },
                    {
                        "id": "tests/test_config_model.py::TestConfigModel::test_conftier_to_dict_pydantic",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigModel::to_dict",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DATA-002",
                "requirement_description": "The system shall allow retrieval of a specific configuration value from a configuration model instance using its key (attribute name or dictionary key).",
                "test_traceability": [
                    {
                        "id": "tests/test_config_model.py::TestConfigModel::test_conftier_get_value",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigModel::get_value",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DATA-003",
                "requirement_description": "The system shall support retrieving values from nested structures within a configuration model instance using a dot-delimited string key (e.g., \"parent.child.key\").",
                "test_traceability": [
                    {
                        "id": "tests/test_config_model.py::TestConfigModel::test_conftier_get_value",
                        "description": "e.g., `nested.name`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigModel::get_value",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DATA-004",
                "requirement_description": "If a requested key (simple or nested) does not exist in the configuration model instance, the system shall return `None` (or an equivalent indicator of absence) without raising an error.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_model.py::TestConfigModel::test_conftier_get_value",
                        "description": "e.g., `nonexistent`, `nested.nonexistent`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigModel::get_value",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DATA-005",
                "requirement_description": "The system shall allow in-place modification of a configuration model instance using a dictionary of new data. This update should be deep, meaning nested structures are also updated.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_model.py::TestConfigModel::test_conftier_update",
                        "description": ""
                    },
                    {
                        "id": "tests/test_config_model.py::TestConfigModel::test_conftier_update_pydantic",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigModel::update",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DATA-006",
                "requirement_description": "The system shall support merging one configuration model instance with another, producing a new configuration model instance. The merging logic should be deep, with values from the \"other\" model overriding the base model's values where keys conflict.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_model.py::TestConfigModel::test_conftier_merge",
                        "description": ""
                    },
                    {
                        "id": "tests/test_config_model.py::TestConfigModel::test_conftier_merge_pydantic",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigModel::merge",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-001",
                "requirement_description": "The system shall provide a CLI command (e.g., `conftier init_project <config_name>`) to initialize a project-level configuration file.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis of `conftier/cli.py::init_project`",
                        "description": "No direct corresponding original test case."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/cli.py::init_project",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-002",
                "requirement_description": "The `init_project` CLI command shall accept an optional path argument (e.g., `--path <path>`) to specify the project directory. If not provided, it shall default to the current working directory.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis of `conftier/cli.py::init_project`",
                        "description": "No direct corresponding original test case."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/cli.py::init_project",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-003",
                "requirement_description": "The `init_project` CLI command shall create a `.{config_name}/config.yaml` file in the target project directory if it does not already exist. The created file shall contain an empty YAML mapping (e.g., `{}`). Parent directories shall be created if necessary.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis of `conftier/cli.py::init_project`",
                        "description": "No direct corresponding original test case."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/cli.py::init_project",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-004",
                "requirement_description": "If the project configuration file already exists, the `init_project` CLI command shall not overwrite it and should notify the user.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis of `conftier/cli.py::init_project`",
                        "description": "No direct corresponding original test case."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/cli.py::init_project",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-005",
                "requirement_description": "The system shall provide a CLI command (e.g., `conftier show_config <config_name>`) to display the contents of the user and project configuration files.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis of `conftier/cli.py::show_config`",
                        "description": "No direct corresponding original test case."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/cli.py::show_config",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-006",
                "requirement_description": "The `show_config` CLI command shall display the content of the user configuration file for the given `config_name` if it exists. If not, it shall indicate that the user config was not found.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis of `conftier/cli.py::show_config`",
                        "description": "No direct corresponding original test case."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/cli.py::show_config",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-007",
                "requirement_description": "The `show_config` CLI command shall display the content of the project configuration file for the given `config_name` if it exists (and project root is found). If not, it shall indicate that the project config was not found.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis of `conftier/cli.py::show_config`",
                        "description": "No direct corresponding original test case."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/cli.py::show_config",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-008",
                "requirement_description": "If neither user nor project configuration files are found for the given `config_name`, the `show_config` CLI command shall notify the user accordingly.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis of `conftier/cli.py::show_config`",
                        "description": "No direct corresponding original test case."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/cli.py::show_config",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-009",
                "requirement_description": "The system shall provide a CLI command (e.g., `conftier set_config <config_name> --key <key> --value <value>`) to set or update a specific configuration value.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis of `conftier/cli.py::set_config`",
                        "description": "No direct corresponding original test case."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/cli.py::set_config",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-010",
                "requirement_description": "The `set_config` CLI command shall target the user configuration file by default. It shall support an option (e.g., `--project`) to target the project configuration file instead.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis of `conftier/cli.py::set_config`",
                        "description": "No direct corresponding original test case."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/cli.py::set_config",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-011",
                "requirement_description": "The `set_config` CLI command shall accept a `key` argument that supports dot notation (e.g., `parent.child.key`) for specifying nested values to be set or updated.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis of `conftier/cli.py::set_config`",
                        "description": "No direct corresponding original test case."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/cli.py::set_config",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-012",
                "requirement_description": "The `set_config` CLI command shall attempt to parse the provided string `value` into boolean (`true`/`false`, case-insensitive), integer, or float types before storing it in the YAML file. If these parsing attempts fail, the value shall be stored as a string.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis of `conftier/cli.py::set_config` and indirectly supported by tests manipulating typed data",
                        "description": "e.g., `tests/test_config_manager.py::TestConfigManager::test_conftier_update_user_config`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/cli.py::set_config",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-013",
                "requirement_description": "If the target configuration file (user or project) or its parent directories do not exist, the `set_config` CLI command shall create them before writing the value.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis of `conftier/cli.py::set_config`",
                        "description": "No direct corresponding original test case."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/cli.py::set_config",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-014",
                "requirement_description": "If the `set_config` CLI command is instructed to target the project configuration but no project root can be found, it shall notify the user and not attempt to write the configuration.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis of `conftier/cli.py::set_config`",
                        "description": "No direct corresponding original test case."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/cli.py::set_config",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "NFR-001",
                "requirement_description": "The system's determination of the user's home directory for locating user configuration files shall be influenced by standard environment variables like `HOME` (on Unix-like systems) or `APPDATA` (on Windows), allowing these to be overridden in controlled environments (e.g., for testing).",
                "test_traceability": [
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::temp_home_dir",
                        "description": "fixture manipulates `HOME`/`APPDATA`"
                    },
                    {
                        "id": "tests/test_utils.py::TestUtilityFunctions::test_conftier_get_user_config_path",
                        "description": "uses monkeypatch for env vars"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::get_user_config_path",
                        "description": "uses `os.path.expanduser` which respects these environment variables"
                    }
                ]
            },
            {
                "requirement_id": "EIR-001",
                "requirement_description": "All configuration files read and written by the system must adhere to the YAML syntax. The content should be representable as nested key-value pairs corresponding to the defined schema.",
                "test_traceability": [
                    {
                        "id": "Implicit in all tests that read/write config files",
                        "description": "e.g., `tests/test_config_manager.py::TestConfigManager::test_conftier_init_with_dataclass`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py",
                        "description": "usage of `yaml.safe_load`, `yaml.dump`"
                    }
                ]
            },
            {
                "requirement_id": "EIR-002",
                "requirement_description": "User-specific configuration files must be stored at `~/.zeeland/{config_name}/config.yaml`.",
                "test_traceability": [
                    {
                        "id": "tests/test_utils.py::TestUtilityFunctions::test_conftier_get_user_config_path",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::get_user_config_path",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-003",
                "requirement_description": "Project-specific configuration files must be stored at `./.{config_name}/config.yaml` relative to the detected project root.",
                "test_traceability": [
                    {
                        "id": "tests/test_utils.py::TestUtilityFunctions::test_conftier_get_project_config_path",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::get_project_config_path",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-004",
                "requirement_description": "The system must provide a command-line interface with subcommands and options as detailed in section 3.1.5 (FR-CLI-001 to FR-CLI-014).",
                "test_traceability": [
                    {
                        "id": "Primarily derived from source code analysis of `conftier/cli.py`",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/cli.py",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "DR-001",
                "requirement_description": "All configuration data, whether default, loaded from files, or merged, must conceptually adhere to the structure defined by the user-provided schema (Pydantic model, dataclass, or dictionary). The system should produce typed instances matching the schema.",
                "test_traceability": [
                    {
                        "id": "tests/test_config_manager.py::TestConfigManager::test_conftier_load_with_all_configs",
                        "description": ""
                    },
                    {
                        "id": "tests/test_config_model.py::TestConfigModel::test_conftier_from_schema_dataclass",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "conftier/core.py::ConfigManager",
                        "description": ""
                    },
                    {
                        "id": "conftier/core.py::ConfigModel",
                        "description": ""
                    }
                ]
            }
        ],
        "full_code_skeleton": "--- File: conftier/core.py ---\n```python\nclass ConfigModel:\n    \"\"\"\n    A unified configuration model that wraps Pydantic models, dataclasses, and\n    dictionaries.\n\n    This class provides a consistent interface for different types of configuration\n    models, handling validation, serialization, and nested structure management.\n    \"\"\"\n\n    def __init__(self, schema_type: SchemaType, model_instance: Any):\n        \"\"\"\n        Initialize a ConfigModel\n\n        Args:\n            schema_type: Type of schema ('pydantic', 'dataclass', or 'dict')\n            model_instance: The actual model instance\n        \"\"\"\n        pass\n\n    @classmethod\n    def from_schema(\n        cls, schema: Type[Any], data: Optional[Dict[str, Any]] = None\n    ) -> \"ConfigModel\":\n        \"\"\"\n        Create a ConfigModel from a schema type and data\n\n        Args:\n            schema: The schema type (Pydantic model, dataclass, or dict)\n            data: Optional data to initialize the model with\n\n        Returns:\n            Initialized ConfigModel\n        \"\"\"\n        pass\n\n    @staticmethod\n    def _prepare_dataclass_kwargs(\n        dataclass_type: Type[Any], data: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"Prepare kwargs for dataclass initialization with proper handling of nested\n        dataclasses.\n\n        Args:\n            dataclass_type: Target dataclass type\n            data: Data dictionary\n\n        Returns:\n            Dictionary of kwargs suitable for initializing the dataclass\n        \"\"\"\n        pass\n\n    @property\n    def model(self) -> Any:\n        \"\"\"Get the underlying model instance\"\"\"\n        pass\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"\n        Convert the model to a dictionary\n\n        Returns:\n            Dictionary representation of the model\n        \"\"\"\n        pass\n\n    def get_value(self, key: str) -> Any:\n        \"\"\"\n        Get a value from the model by key\n\n        Args:\n            key: Key to get (supports dot notation for nested access)\n\n        Returns:\n            Value at the specified key\n        \"\"\"\n        pass\n\n    def update(self, data: Dict[str, Any]) -> None:\n        \"\"\"\n        Update the model with new data\n\n        Args:\n            data: Dictionary of values to update\n        \"\"\"\n        pass\n\n    def merge(self, other: \"ConfigModel\") -> \"ConfigModel\":\n        \"\"\"\n        Merge with another ConfigModel\n\n        Args:\n            other: Another ConfigModel to merge with\n\n        Returns:\n            New ConfigModel with merged data\n        \"\"\"\n        pass\n\n\nclass ConfigManager(Generic[T]):\n    \"\"\"\n    Core configuration manager that handles loading, merging, and accessing\n    configurations.\n    \"\"\"\n\n    def __init__(\n        self,\n        config_name: str,\n        config_schema: Type[T],  # Supports pydantic.BaseModel, dataclass, or dict\n        version: str = \"1.0.0\",\n        auto_create_user: bool = False,\n        auto_create_project: bool = False,\n    ):\n        \"\"\"\n        Initialize the configuration manager\n\n        Args:\n            config_name: Framework name, used to determine config file paths\n            config_schema: Configuration schema definition (pydantic model, dataclass,\n                or dict)\n            version: Configuration schema version\n            auto_create_user: Whether to automatically create user config file if not\n            exists auto_create_project: Whether to automatically create project config\n            file if not exists.\n        \"\"\"\n        pass\n\n    def _get_default_dict(self) -> Dict[str, Any]:\n        \"\"\"Get default configuration as a dictionary\"\"\"\n        pass\n\n    def _to_schema_type(self, config_dict: Dict[str, Any]) -> T:\n        \"\"\"Convert dictionary to the schema type\"\"\"\n        pass\n\n    def load(self) -> T:\n        \"\"\"\n        Load and merge all configuration levels\n\n        Returns:\n            Merged final configuration object (same type as schema)\n\n        Raises:\n            FileNotFoundError: If both user and project configuration files don't exist\n            and auto_create options are disabled\n        \"\"\"\n        pass\n\n    @property\n    def config(self) -> T:\n        \"\"\"\n        Get the current merged configuration\n\n        Returns:\n            Current effective configuration object\n        \"\"\"\n        pass\n\n    def get_default_config(self) -> T:\n        \"\"\"\n        Get the default configuration\n\n        Returns:\n            Default configuration object based on schema\n        \"\"\"\n        pass\n\n    def _load_config_from_path(\n        self, config_path: Optional[Path]\n    ) -> Tuple[Optional[ConfigModel], Optional[T]]:\n        \"\"\"\n        Helper method to load configuration from a path\n\n        Args:\n            config_path: Path to the configuration file\n\n        Returns:\n            Tuple of (ConfigModel, typed config object) or (None, None) if not available\n        \"\"\"\n        pass\n\n    def get_user_config(self) -> Optional[T]:\n        \"\"\"\n        Get the user-level configuration\n\n        Returns:\n            User configuration object or None if not available\n        \"\"\"\n        pass\n\n    def get_project_config(self) -> Optional[T]:\n        \"\"\"\n        Get the project-level configuration\n\n        Returns:\n            Project configuration object or None if not available\n        \"\"\"\n        pass\n\n    def _update_config_file(\n        self,\n        config_path: Path,\n        config_model: Optional[ConfigModel],\n        config_update: Dict[str, Any],\n    ) -> Tuple[ConfigModel, T]:\n        \"\"\"\n        Helper method for updating configuration files\n\n        Args:\n            config_path: Path to the configuration file\n            config_model: Existing config model or None\n            config_update: Updates to apply to the configuration\n\n        Returns:\n            Tuple of (updated ConfigModel, typed config object)\n        \"\"\"\n        pass\n\n    def update_user_config(self, config_update: Dict[str, Any]) -> None:\n        \"\"\"\n        Update the user-level configuration\n\n        Args:\n            config_update: Configuration dictionary to update\n        \"\"\"\n        pass\n\n    def update_project_config(self, config_update: Dict[str, Any]) -> None:\n        \"\"\"\n        Update the project-level configuration\n\n        Args:\n            config_update: Configuration dictionary to update\n        \"\"\"\n        pass\n\n    def create_user_config_template(self) -> ConfigPath:\n        \"\"\"Create a user configuration template if it doesn't exist\n\n        Returns:\n            Path to the created configuration file\n        \"\"\"\n        pass\n\n    def create_project_config_template(self, path: Optional[str] = None) -> ConfigPath:\n        \"\"\"Create a project configuration template\n\n        Args:\n            path: Optional project path, defaults to current directory\n\n        Returns:\n            Path to the created configuration file\n        \"\"\"\n        pass\n\n    def create_project_template(self, path: Optional[str] = None) -> ConfigPath:\n        \"\"\"Create a project configuration template (deprecated)\n\n        Use create_project_config_template instead.\n\n        Args:\n            path: Optional project path, defaults to current directory\n\n        Returns:\n            Path to the created configuration file\n        \"\"\"\n        pass\n\n\ndef get_user_config_path(config_name: str) -> Path:\n    \"\"\"Get the path to the user-level configuration file\"\"\"\n    pass\n\n\ndef get_project_config_path(\n    config_name: str, project_path: Optional[str] = None\n) -> Optional[Path]:\n    \"\"\"Get the path to the project-level configuration file\"\"\"\n    pass\n\n\ndef find_project_root() -> Optional[Path]:\n    \"\"\"Find the project root directory by looking for common project files\n    like .git, pyproject.toml, etc.\n    \"\"\"\n    pass\n\n\ndef merge_configs_dict(\n    default_config: Dict[str, Any],\n    user_config: Dict[str, Any],\n    project_config: Dict[str, Any],\n) -> Dict[str, Any]:\n    \"\"\"Merge multiple configuration levels\n\n    Args:\n        default_config: Default configuration\n        user_config: User-level configuration\n        project_config: Project-level configuration\n\n    Returns:\n        Merged configuration dictionary\n    \"\"\"\n    pass\n\n\ndef deep_update(\n    base_dict: Dict[str, Any], update_dict: Dict[str, Any]\n) -> Dict[str, Any]:\n    \"\"\"Recursively update a dictionary\n\n    Args:\n        base_dict: The base dictionary to update\n        update_dict: The dictionary with updates to apply\n\n    Returns:\n        Updated dictionary\n    \"\"\"\n    pass\n```\n--- File: conftier/__init__.py ---\n```python\ndef get_version() -> str:\n    try:\n        pass\n    except importlib_metadata.PackageNotFoundError:  # pragma: no cover\n        pass\n```\n--- File: conftier/cli.py ---\n```python\ndef conftier():\n    \"\"\"Conftier configuration management tool\"\"\"\n    pass\n\n\ndef init_project(config_name: str, path: Optional[str] = None):\n    \"\"\"Initialize project configuration template\"\"\"\n    pass\n\n\ndef show_config(config_name: str):\n    \"\"\"Show current effective configuration and its sources\"\"\"\n    pass\n\n\ndef set_config(config_name: str, key: str, value: str, project: bool = False):\n    \"\"\"Set a configuration value\"\"\"\n    pass\n```\n--- File: conftier/utils/__init__.py ---\n```python\ndef get_default_storage_path(module_name: str = \"\") -> str:\n    pass\n```\n--- File: conftier/utils/logger.py ---\n```python\nclass Color(Enum):\n    DEFAULT = \"default\"\n    GREEN = \"green\"\n    YELLOW = \"yellow\"\n    RED = \"red\"\n\n\nclass Logger(logging.Logger, metaclass=Singleton):\n    \"\"\"A custom logger class that extends logging.Logger with color output\n    capabilities.\"\"\"\n\n    def __init__(self, name: str = \"conftier\", level: int = logging.DEBUG) -> None:\n        \"\"\"Initialize the logger with file and console handlers.\n\n        Args:\n            name: Logger name, defaults to \"conftier\"\n            level: Logging level, defaults to DEBUG\n        \"\"\"\n        pass\n\n    def _setup_file_handler(self) -> None:\n        \"\"\"Set up rotating file handler with formatting.\"\"\"\n        pass\n\n    def color_info(\n        self, message: str, color: Color = Color.DEFAULT, *args, **kwargs\n    ) -> None:\n        \"\"\"Log info message and print to console with optional color.\n\n        Args:\n            message: The message to log\n            color: Color enum value for console output\n            *args: Additional args passed to logger\n            **kwargs: Additional kwargs passed to logger\n        \"\"\"\n        pass\n\n\ndef handle_exception(exc_type, exc_value, exc_tb) -> None:\n    \"\"\"Handle uncaught exceptions by logging them.\n\n    Args:\n        exc_type: Exception type\n        exc_value: Exception value\n        exc_tb: Exception traceback\n    \"\"\"\n    pass\n```\n--- File: examples/basic_usage.py ---\n```python\n@dataclass\nclass ModelConfig:\n    model_name: str = \"gpt-4\"\n    api_key: str = \"\"\n    api_base: Optional[str] = None\n\n\n@dataclass\nclass ExampleConfig:\n    model_config: ModelConfig = ModelConfig()\n    prompt_template: str = \"This is default prompt template\"\n    enable_feature: bool = True\n\n\ndef main_with_dataclass():\n    \"\"\"Example using dataclasses\"\"\"\n    pass\n\n\nclass LLMConfig(BaseModel):\n    model_name: str = \"gpt-4\"\n    api_key: str = \"\"\n    api_base: Optional[str] = None\n\n\nclass PydanticExampleConfig(BaseModel):\n    llm_config: LLMConfig = LLMConfig()\n    prompt_template: str = \"This is default prompt template\"\n    enable_feature: bool = True\n\n\ndef main_with_pydantic():\n    \"\"\"Example using pydantic\"\"\"\n    pass\n\n\ndef main_with_pydantic():\n    pass\n```",
        "minimal_code_skeleton": "--- File: conftier/core.py ---\n```python\nclass ConfigModel:\n    \"\"\"\n    A unified configuration model that wraps Pydantic models, dataclasses, and\n    dictionaries.\n\n    This class provides a consistent interface for different types of configuration\n    models, handling validation, serialization, and nested structure management.\n    \"\"\"\n\n    def __init__(self, schema_type: SchemaType, model_instance: Any):\n        \"\"\"\n        Initialize a ConfigModel\n\n        Args:\n            schema_type: Type of schema ('pydantic', 'dataclass', or 'dict')\n            model_instance: The actual model instance\n        \"\"\"\n        pass\n\n    @classmethod\n    def from_schema(\n        cls, schema: Type[Any], data: Optional[Dict[str, Any]] = None\n    ) -> \"ConfigModel\":\n        \"\"\"\n        Create a ConfigModel from a schema type and data\n\n        Args:\n            schema: The schema type (Pydantic model, dataclass, or dict)\n            data: Optional data to initialize the model with\n\n        Returns:\n            Initialized ConfigModel\n        \"\"\"\n        pass\n\n    @property\n    def model(self) -> Any:\n        \"\"\"Get the underlying model instance\"\"\"\n        pass\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"\n        Convert the model to a dictionary\n\n        Returns:\n            Dictionary representation of the model\n        \"\"\"\n        pass\n\n    def get_value(self, key: str) -> Any:\n        \"\"\"\n        Get a value from the model by key\n\n        Args:\n            key: Key to get (supports dot notation for nested access)\n\n        Returns:\n            Value at the specified key\n        \"\"\"\n        pass\n\n    def update(self, data: Dict[str, Any]) -> None:\n        \"\"\"\n        Update the model with new data\n\n        Args:\n            data: Dictionary of values to update\n        \"\"\"\n        pass\n\n    def merge(self, other: \"ConfigModel\") -> \"ConfigModel\":\n        \"\"\"\n        Merge with another ConfigModel\n\n        Args:\n            other: Another ConfigModel to merge with\n\n        Returns:\n            New ConfigModel with merged data\n        \"\"\"\n        pass\n\n\nclass ConfigManager(Generic[T]):\n    \"\"\"\n    Core configuration manager that handles loading, merging, and accessing\n    configurations.\n    \"\"\"\n\n    def __init__(\n        self,\n        config_name: str,\n        config_schema: Type[T],  # Supports pydantic.BaseModel, dataclass, or dict\n        version: str = \"1.0.0\",\n        auto_create_user: bool = False,\n        auto_create_project: bool = False,\n    ):\n        \"\"\"\n        Initialize the configuration manager\n\n        Args:\n            config_name: Framework name, used to determine config file paths\n            config_schema: Configuration schema definition (pydantic model, dataclass,\n                or dict)\n            version: Configuration schema version\n            auto_create_user: Whether to automatically create user config file if not\n            exists auto_create_project: Whether to automatically create project config\n            file if not exists.\n        \"\"\"\n        pass\n\n    def load(self) -> T:\n        \"\"\"\n        Load and merge all configuration levels\n\n        Returns:\n            Merged final configuration object (same type as schema)\n\n        Raises:\n            FileNotFoundError: If both user and project configuration files don't exist\n            and auto_create options are disabled\n        \"\"\"\n        pass\n\n    def get_default_config(self) -> T:\n        \"\"\"\n        Get the default configuration\n\n        Returns:\n            Default configuration object based on schema\n        \"\"\"\n        pass\n\n    def get_user_config(self) -> Optional[T]:\n        \"\"\"\n        Get the user-level configuration\n\n        Returns:\n            User configuration object or None if not available\n        \"\"\"\n        pass\n\n    def get_project_config(self) -> Optional[T]:\n        \"\"\"\n        Get the project-level configuration\n\n        Returns:\n            Project configuration object or None if not available\n        \"\"\"\n        pass\n\n    def update_user_config(self, config_update: Dict[str, Any]) -> None:\n        \"\"\"\n        Update the user-level configuration\n\n        Args:\n            config_update: Configuration dictionary to update\n        \"\"\"\n        pass\n\n    def update_project_config(self, config_update: Dict[str, Any]) -> None:\n        \"\"\"\n        Update the project-level configuration\n\n        Args:\n            config_update: Configuration dictionary to update\n        \"\"\"\n        pass\n\n    def create_user_config_template(self) -> str:\n        \"\"\"Create a user configuration template if it doesn't exist\n\n        Returns:\n            Path to the created configuration file\n        \"\"\"\n        pass\n\n    def create_project_config_template(self, path: Optional[str] = None) -> str:\n        \"\"\"Create a project configuration template\n\n        Args:\n            path: Optional project path, defaults to current directory\n\n        Returns:\n            Path to the created configuration file\n        \"\"\"\n        pass\n\n    def create_project_template(self, path: Optional[str] = None) -> str:\n        \"\"\"Create a project configuration template (deprecated)\n\n        Use create_project_config_template instead.\n\n        Args:\n            path: Optional project path, defaults to current directory\n\n        Returns:\n            Path to the created configuration file\n        \"\"\"\n        pass\n\n\ndef get_user_config_path(config_name: str) -> Path:\n    \"\"\"Get the path to the user-level configuration file\"\"\"\n    pass\n\n\ndef get_project_config_path(\n    config_name: str, project_path: Optional[str] = None\n) -> Optional[Path]:\n    \"\"\"Get the path to the project-level configuration file\"\"\"\n    pass\n\n\ndef find_project_root() -> Optional[Path]:\n    \"\"\"Find the project root directory by looking for common project files\n    like .git, pyproject.toml, etc.\n    \"\"\"\n    pass\n```",
        "minimal_test_cases": [
            {
                "test_id": "tests/test_config_manager.py::TestConfigManager::test_conftier_init_with_dataclass",
                "covers": [
                    "conftier.ConfigManager.__init__ - happy path with dataclass schema and auto_create_user"
                ]
            },
            {
                "test_id": "tests/test_config_manager.py::TestConfigManager::test_conftier_load_with_user_config",
                "covers": [
                    "conftier.ConfigManager.load - happy path with user config",
                    "conftier.ConfigManager.config - access to loaded configuration"
                ]
            },
            {
                "test_id": "tests/test_config_manager.py::TestConfigManager::test_conftier_load_default_only",
                "covers": [
                    "conftier.ConfigManager.get_default_config - happy path",
                    "conftier.ConfigManager.create_user_config_template - usage to enable loading",
                    "conftier.ConfigManager.load - behavior with no initial configs and after template creation"
                ]
            },
            {
                "test_id": "tests/test_config_manager.py::TestConfigManager::test_conftier_get_user_config",
                "covers": [
                    "conftier.ConfigManager.get_user_config - happy path"
                ]
            },
            {
                "test_id": "tests/test_config_manager.py::TestConfigManager::test_conftier_get_project_config",
                "covers": [
                    "conftier.ConfigManager.get_project_config - happy path"
                ]
            },
            {
                "test_id": "tests/test_config_manager.py::TestConfigManager::test_conftier_update_user_config",
                "covers": [
                    "conftier.ConfigManager.update_user_config - happy path"
                ]
            },
            {
                "test_id": "tests/test_config_manager.py::TestConfigManager::test_conftier_update_project_config",
                "covers": [
                    "conftier.ConfigManager.update_project_config - happy path"
                ]
            },
            {
                "test_id": "tests/test_config_manager.py::TestConfigManager::test_conftier_create_project_config_template",
                "covers": [
                    "conftier.ConfigManager.create_project_config_template - happy path"
                ]
            },
            {
                "test_id": "tests/test_config_manager.py::TestConfigManager::test_conftier_create_project_template",
                "covers": [
                    "conftier.ConfigManager.create_project_template - happy path for deprecated method"
                ]
            },
            {
                "test_id": "tests/test_config_model.py::TestConfigModel::test_conftier_from_schema_dataclass",
                "covers": [
                    "conftier.ConfigModel.from_schema - happy path with dataclass schema",
                    "conftier.ConfigModel.model - property access after creation"
                ]
            },
            {
                "test_id": "tests/test_config_model.py::TestConfigModel::test_conftier_to_dict",
                "covers": [
                    "conftier.ConfigModel.to_dict - happy path for dataclass and dict schemas"
                ]
            },
            {
                "test_id": "tests/test_config_model.py::TestConfigModel::test_conftier_get_value",
                "covers": [
                    "conftier.ConfigModel.get_value - happy path for dataclass and dict schemas, including nested and non-existent keys"
                ]
            },
            {
                "test_id": "tests/test_config_model.py::TestConfigModel::test_conftier_update",
                "covers": [
                    "conftier.ConfigModel.update - happy path for dataclass and dict schemas"
                ]
            },
            {
                "test_id": "tests/test_config_model.py::TestConfigModel::test_conftier_merge",
                "covers": [
                    "conftier.ConfigModel.merge - happy path for dataclass and dict schemas",
                    "conftier.deep_update - indirect coverage via ConfigModel.merge"
                ]
            },
            {
                "test_id": "tests/test_utils.py::TestUtilityFunctions::test_conftier_find_project_root",
                "covers": [
                    "conftier.find_project_root - happy path"
                ]
            },
            {
                "test_id": "tests/test_utils.py::TestUtilityFunctions::test_conftier_get_project_config_path",
                "covers": [
                    "conftier.get_project_config_path - happy path"
                ]
            },
            {
                "test_id": "tests/test_utils.py::TestUtilityFunctions::test_conftier_get_user_config_path",
                "covers": [
                    "conftier.get_user_config_path - happy path"
                ]
            }
        ],
        "commit_sha": "4c85c478274cbdfa344ae5119eb384ce87b85e3a",
        "full_code_skeleton_structured": [
            {
                "file_path": "conftier/core.py",
                "code": "class ConfigModel:\n    \"\"\"\n    A unified configuration model that wraps Pydantic models, dataclasses, and\n    dictionaries.\n\n    This class provides a consistent interface for different types of configuration\n    models, handling validation, serialization, and nested structure management.\n    \"\"\"\n\n    def __init__(self, schema_type: SchemaType, model_instance: Any):\n        \"\"\"\n        Initialize a ConfigModel\n\n        Args:\n            schema_type: Type of schema ('pydantic', 'dataclass', or 'dict')\n            model_instance: The actual model instance\n        \"\"\"\n        pass\n\n    @classmethod\n    def from_schema(\n        cls, schema: Type[Any], data: Optional[Dict[str, Any]] = None\n    ) -> \"ConfigModel\":\n        \"\"\"\n        Create a ConfigModel from a schema type and data\n\n        Args:\n            schema: The schema type (Pydantic model, dataclass, or dict)\n            data: Optional data to initialize the model with\n\n        Returns:\n            Initialized ConfigModel\n        \"\"\"\n        pass\n\n    @staticmethod\n    def _prepare_dataclass_kwargs(\n        dataclass_type: Type[Any], data: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"Prepare kwargs for dataclass initialization with proper handling of nested\n        dataclasses.\n\n        Args:\n            dataclass_type: Target dataclass type\n            data: Data dictionary\n\n        Returns:\n            Dictionary of kwargs suitable for initializing the dataclass\n        \"\"\"\n        pass\n\n    @property\n    def model(self) -> Any:\n        \"\"\"Get the underlying model instance\"\"\"\n        pass\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"\n        Convert the model to a dictionary\n\n        Returns:\n            Dictionary representation of the model\n        \"\"\"\n        pass\n\n    def get_value(self, key: str) -> Any:\n        \"\"\"\n        Get a value from the model by key\n\n        Args:\n            key: Key to get (supports dot notation for nested access)\n\n        Returns:\n            Value at the specified key\n        \"\"\"\n        pass\n\n    def update(self, data: Dict[str, Any]) -> None:\n        \"\"\"\n        Update the model with new data\n\n        Args:\n            data: Dictionary of values to update\n        \"\"\"\n        pass\n\n    def merge(self, other: \"ConfigModel\") -> \"ConfigModel\":\n        \"\"\"\n        Merge with another ConfigModel\n\n        Args:\n            other: Another ConfigModel to merge with\n\n        Returns:\n            New ConfigModel with merged data\n        \"\"\"\n        pass\n\n\nclass ConfigManager(Generic[T]):\n    \"\"\"\n    Core configuration manager that handles loading, merging, and accessing\n    configurations.\n    \"\"\"\n\n    def __init__(\n        self,\n        config_name: str,\n        config_schema: Type[T],  # Supports pydantic.BaseModel, dataclass, or dict\n        version: str = \"1.0.0\",\n        auto_create_user: bool = False,\n        auto_create_project: bool = False,\n    ):\n        \"\"\"\n        Initialize the configuration manager\n\n        Args:\n            config_name: Framework name, used to determine config file paths\n            config_schema: Configuration schema definition (pydantic model, dataclass,\n                or dict)\n            version: Configuration schema version\n            auto_create_user: Whether to automatically create user config file if not\n            exists auto_create_project: Whether to automatically create project config\n            file if not exists.\n        \"\"\"\n        pass\n\n    def _get_default_dict(self) -> Dict[str, Any]:\n        \"\"\"Get default configuration as a dictionary\"\"\"\n        pass\n\n    def _to_schema_type(self, config_dict: Dict[str, Any]) -> T:\n        \"\"\"Convert dictionary to the schema type\"\"\"\n        pass\n\n    def load(self) -> T:\n        \"\"\"\n        Load and merge all configuration levels\n\n        Returns:\n            Merged final configuration object (same type as schema)\n\n        Raises:\n            FileNotFoundError: If both user and project configuration files don't exist\n            and auto_create options are disabled\n        \"\"\"\n        pass\n\n    @property\n    def config(self) -> T:\n        \"\"\"\n        Get the current merged configuration\n\n        Returns:\n            Current effective configuration object\n        \"\"\"\n        pass\n\n    def get_default_config(self) -> T:\n        \"\"\"\n        Get the default configuration\n\n        Returns:\n            Default configuration object based on schema\n        \"\"\"\n        pass\n\n    def _load_config_from_path(\n        self, config_path: Optional[Path]\n    ) -> Tuple[Optional[ConfigModel], Optional[T]]:\n        \"\"\"\n        Helper method to load configuration from a path\n\n        Args:\n            config_path: Path to the configuration file\n\n        Returns:\n            Tuple of (ConfigModel, typed config object) or (None, None) if not available\n        \"\"\"\n        pass\n\n    def get_user_config(self) -> Optional[T]:\n        \"\"\"\n        Get the user-level configuration\n\n        Returns:\n            User configuration object or None if not available\n        \"\"\"\n        pass\n\n    def get_project_config(self) -> Optional[T]:\n        \"\"\"\n        Get the project-level configuration\n\n        Returns:\n            Project configuration object or None if not available\n        \"\"\"\n        pass\n\n    def _update_config_file(\n        self,\n        config_path: Path,\n        config_model: Optional[ConfigModel],\n        config_update: Dict[str, Any],\n    ) -> Tuple[ConfigModel, T]:\n        \"\"\"\n        Helper method for updating configuration files\n\n        Args:\n            config_path: Path to the configuration file\n            config_model: Existing config model or None\n            config_update: Updates to apply to the configuration\n\n        Returns:\n            Tuple of (updated ConfigModel, typed config object)\n        \"\"\"\n        pass\n\n    def update_user_config(self, config_update: Dict[str, Any]) -> None:\n        \"\"\"\n        Update the user-level configuration\n\n        Args:\n            config_update: Configuration dictionary to update\n        \"\"\"\n        pass\n\n    def update_project_config(self, config_update: Dict[str, Any]) -> None:\n        \"\"\"\n        Update the project-level configuration\n\n        Args:\n            config_update: Configuration dictionary to update\n        \"\"\"\n        pass\n\n    def create_user_config_template(self) -> ConfigPath:\n        \"\"\"Create a user configuration template if it doesn't exist\n\n        Returns:\n            Path to the created configuration file\n        \"\"\"\n        pass\n\n    def create_project_config_template(self, path: Optional[str] = None) -> ConfigPath:\n        \"\"\"Create a project configuration template\n\n        Args:\n            path: Optional project path, defaults to current directory\n\n        Returns:\n            Path to the created configuration file\n        \"\"\"\n        pass\n\n    def create_project_template(self, path: Optional[str] = None) -> ConfigPath:\n        \"\"\"Create a project configuration template (deprecated)\n\n        Use create_project_config_template instead.\n\n        Args:\n            path: Optional project path, defaults to current directory\n\n        Returns:\n            Path to the created configuration file\n        \"\"\"\n        pass\n\n\ndef get_user_config_path(config_name: str) -> Path:\n    \"\"\"Get the path to the user-level configuration file\"\"\"\n    pass\n\n\ndef get_project_config_path(\n    config_name: str, project_path: Optional[str] = None\n) -> Optional[Path]:\n    \"\"\"Get the path to the project-level configuration file\"\"\"\n    pass\n\n\ndef find_project_root() -> Optional[Path]:\n    \"\"\"Find the project root directory by looking for common project files\n    like .git, pyproject.toml, etc.\n    \"\"\"\n    pass\n\n\ndef merge_configs_dict(\n    default_config: Dict[str, Any],\n    user_config: Dict[str, Any],\n    project_config: Dict[str, Any],\n) -> Dict[str, Any]:\n    \"\"\"Merge multiple configuration levels\n\n    Args:\n        default_config: Default configuration\n        user_config: User-level configuration\n        project_config: Project-level configuration\n\n    Returns:\n        Merged configuration dictionary\n    \"\"\"\n    pass\n\n\ndef deep_update(\n    base_dict: Dict[str, Any], update_dict: Dict[str, Any]\n) -> Dict[str, Any]:\n    \"\"\"Recursively update a dictionary\n\n    Args:\n        base_dict: The base dictionary to update\n        update_dict: The dictionary with updates to apply\n\n    Returns:\n        Updated dictionary\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "conftier/__init__.py",
                "code": "def get_version() -> str:\n    try:\n        pass\n    except importlib_metadata.PackageNotFoundError:  # pragma: no cover\n        pass\n"
            },
            {
                "file_path": "conftier/cli.py",
                "code": "def conftier():\n    \"\"\"Conftier configuration management tool\"\"\"\n    pass\n\n\ndef init_project(config_name: str, path: Optional[str] = None):\n    \"\"\"Initialize project configuration template\"\"\"\n    pass\n\n\ndef show_config(config_name: str):\n    \"\"\"Show current effective configuration and its sources\"\"\"\n    pass\n\n\ndef set_config(config_name: str, key: str, value: str, project: bool = False):\n    \"\"\"Set a configuration value\"\"\"\n    pass\n"
            },
            {
                "file_path": "conftier/utils/__init__.py",
                "code": "def get_default_storage_path(module_name: str = \"\") -> str:\n    pass\n"
            },
            {
                "file_path": "conftier/utils/logger.py",
                "code": "class Color(Enum):\n    DEFAULT = \"default\"\n    GREEN = \"green\"\n    YELLOW = \"yellow\"\n    RED = \"red\"\n\n\nclass Logger(logging.Logger, metaclass=Singleton):\n    \"\"\"A custom logger class that extends logging.Logger with color output\n    capabilities.\"\"\"\n\n    def __init__(self, name: str = \"conftier\", level: int = logging.DEBUG) -> None:\n        \"\"\"Initialize the logger with file and console handlers.\n\n        Args:\n            name: Logger name, defaults to \"conftier\"\n            level: Logging level, defaults to DEBUG\n        \"\"\"\n        pass\n\n    def _setup_file_handler(self) -> None:\n        \"\"\"Set up rotating file handler with formatting.\"\"\"\n        pass\n\n    def color_info(\n        self, message: str, color: Color = Color.DEFAULT, *args, **kwargs\n    ) -> None:\n        \"\"\"Log info message and print to console with optional color.\n\n        Args:\n            message: The message to log\n            color: Color enum value for console output\n            *args: Additional args passed to logger\n            **kwargs: Additional kwargs passed to logger\n        \"\"\"\n        pass\n\n\ndef handle_exception(exc_type, exc_value, exc_tb) -> None:\n    \"\"\"Handle uncaught exceptions by logging them.\n\n    Args:\n        exc_type: Exception type\n        exc_value: Exception value\n        exc_tb: Exception traceback\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "examples/basic_usage.py",
                "code": "@dataclass\nclass ModelConfig:\n    model_name: str = \"gpt-4\"\n    api_key: str = \"\"\n    api_base: Optional[str] = None\n\n\n@dataclass\nclass ExampleConfig:\n    model_config: ModelConfig = ModelConfig()\n    prompt_template: str = \"This is default prompt template\"\n    enable_feature: bool = True\n\n\ndef main_with_dataclass():\n    \"\"\"Example using dataclasses\"\"\"\n    pass\n\n\nclass LLMConfig(BaseModel):\n    model_name: str = \"gpt-4\"\n    api_key: str = \"\"\n    api_base: Optional[str] = None\n\n\nclass PydanticExampleConfig(BaseModel):\n    llm_config: LLMConfig = LLMConfig()\n    prompt_template: str = \"This is default prompt template\"\n    enable_feature: bool = True\n\n\ndef main_with_pydantic():\n    \"\"\"Example using pydantic\"\"\"\n    pass\n\n\ndef main_with_pydantic():\n    pass\n"
            }
        ],
        "minimal_code_skeleton_structured": [
            {
                "file_path": "conftier/core.py",
                "code": "class ConfigModel:\n    \"\"\"\n    A unified configuration model that wraps Pydantic models, dataclasses, and\n    dictionaries.\n\n    This class provides a consistent interface for different types of configuration\n    models, handling validation, serialization, and nested structure management.\n    \"\"\"\n\n    def __init__(self, schema_type: SchemaType, model_instance: Any):\n        \"\"\"\n        Initialize a ConfigModel\n\n        Args:\n            schema_type: Type of schema ('pydantic', 'dataclass', or 'dict')\n            model_instance: The actual model instance\n        \"\"\"\n        pass\n\n    @classmethod\n    def from_schema(\n        cls, schema: Type[Any], data: Optional[Dict[str, Any]] = None\n    ) -> \"ConfigModel\":\n        \"\"\"\n        Create a ConfigModel from a schema type and data\n\n        Args:\n            schema: The schema type (Pydantic model, dataclass, or dict)\n            data: Optional data to initialize the model with\n\n        Returns:\n            Initialized ConfigModel\n        \"\"\"\n        pass\n\n    @property\n    def model(self) -> Any:\n        \"\"\"Get the underlying model instance\"\"\"\n        pass\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"\n        Convert the model to a dictionary\n\n        Returns:\n            Dictionary representation of the model\n        \"\"\"\n        pass\n\n    def get_value(self, key: str) -> Any:\n        \"\"\"\n        Get a value from the model by key\n\n        Args:\n            key: Key to get (supports dot notation for nested access)\n\n        Returns:\n            Value at the specified key\n        \"\"\"\n        pass\n\n    def update(self, data: Dict[str, Any]) -> None:\n        \"\"\"\n        Update the model with new data\n\n        Args:\n            data: Dictionary of values to update\n        \"\"\"\n        pass\n\n    def merge(self, other: \"ConfigModel\") -> \"ConfigModel\":\n        \"\"\"\n        Merge with another ConfigModel\n\n        Args:\n            other: Another ConfigModel to merge with\n\n        Returns:\n            New ConfigModel with merged data\n        \"\"\"\n        pass\n\n\nclass ConfigManager(Generic[T]):\n    \"\"\"\n    Core configuration manager that handles loading, merging, and accessing\n    configurations.\n    \"\"\"\n\n    def __init__(\n        self,\n        config_name: str,\n        config_schema: Type[T],  # Supports pydantic.BaseModel, dataclass, or dict\n        version: str = \"1.0.0\",\n        auto_create_user: bool = False,\n        auto_create_project: bool = False,\n    ):\n        \"\"\"\n        Initialize the configuration manager\n\n        Args:\n            config_name: Framework name, used to determine config file paths\n            config_schema: Configuration schema definition (pydantic model, dataclass,\n                or dict)\n            version: Configuration schema version\n            auto_create_user: Whether to automatically create user config file if not\n            exists auto_create_project: Whether to automatically create project config\n            file if not exists.\n        \"\"\"\n        pass\n\n    def load(self) -> T:\n        \"\"\"\n        Load and merge all configuration levels\n\n        Returns:\n            Merged final configuration object (same type as schema)\n\n        Raises:\n            FileNotFoundError: If both user and project configuration files don't exist\n            and auto_create options are disabled\n        \"\"\"\n        pass\n\n    def get_default_config(self) -> T:\n        \"\"\"\n        Get the default configuration\n\n        Returns:\n            Default configuration object based on schema\n        \"\"\"\n        pass\n\n    def get_user_config(self) -> Optional[T]:\n        \"\"\"\n        Get the user-level configuration\n\n        Returns:\n            User configuration object or None if not available\n        \"\"\"\n        pass\n\n    def get_project_config(self) -> Optional[T]:\n        \"\"\"\n        Get the project-level configuration\n\n        Returns:\n            Project configuration object or None if not available\n        \"\"\"\n        pass\n\n    def update_user_config(self, config_update: Dict[str, Any]) -> None:\n        \"\"\"\n        Update the user-level configuration\n\n        Args:\n            config_update: Configuration dictionary to update\n        \"\"\"\n        pass\n\n    def update_project_config(self, config_update: Dict[str, Any]) -> None:\n        \"\"\"\n        Update the project-level configuration\n\n        Args:\n            config_update: Configuration dictionary to update\n        \"\"\"\n        pass\n\n    def create_user_config_template(self) -> str:\n        \"\"\"Create a user configuration template if it doesn't exist\n\n        Returns:\n            Path to the created configuration file\n        \"\"\"\n        pass\n\n    def create_project_config_template(self, path: Optional[str] = None) -> str:\n        \"\"\"Create a project configuration template\n\n        Args:\n            path: Optional project path, defaults to current directory\n\n        Returns:\n            Path to the created configuration file\n        \"\"\"\n        pass\n\n    def create_project_template(self, path: Optional[str] = None) -> str:\n        \"\"\"Create a project configuration template (deprecated)\n\n        Use create_project_config_template instead.\n\n        Args:\n            path: Optional project path, defaults to current directory\n\n        Returns:\n            Path to the created configuration file\n        \"\"\"\n        pass\n\n\ndef get_user_config_path(config_name: str) -> Path:\n    \"\"\"Get the path to the user-level configuration file\"\"\"\n    pass\n\n\ndef get_project_config_path(\n    config_name: str, project_path: Optional[str] = None\n) -> Optional[Path]:\n    \"\"\"Get the path to the project-level configuration file\"\"\"\n    pass\n\n\ndef find_project_root() -> Optional[Path]:\n    \"\"\"Find the project root directory by looking for common project files\n    like .git, pyproject.toml, etc.\n    \"\"\"\n    pass\n"
            }
        ]
    },
    {
        "idx": 34596,
        "repo_name": "encypherai_encypher-ai",
        "url": "https://github.com/encypherai/encypher-ai",
        "description": "Metadata encoding and extraction for AI-generated content",
        "stars": 16,
        "forks": 1,
        "language": "python",
        "size": 1041,
        "created_at": "2025-03-22T19:34:09+00:00",
        "updated_at": "2025-04-27T10:17:19+00:00",
        "pypi_info": {
            "name": "encypher-ai",
            "version": "2.0.0",
            "url": "https://files.pythonhosted.org/packages/f8/6c/b2c1216152ff64018a9f3e6e3b90615f35c5b9becfd2f09e73af1d25026d/encypher_ai-2.0.0.tar.gz"
        },
        "error": null,
        "judge_info": {
            "language": "python",
            "is_good_project": false,
            "reason": "",
            "python_file_num": 31,
            "comment_ratio": 0.2947591145833333,
            "pyfile_content_length": 252173,
            "pyfile_code_lines": 6144,
            "test_file_exist": true,
            "test_file_content_length": 97081,
            "pytest_framework": true,
            "test_case_num": 68,
            "metadata_path": [
                "pyproject.toml"
            ],
            "readme_content_length": 14658,
            "llm_reason": "The project, EncypherAI Core, is a Python package designed to embed and extract metadata in text using Unicode variation selectors, with cryptographic signing for integrity and authenticity. \n\n**Positive Aspects for Benchmark Use:**\n1.  **Self-Contained Core Functionality:** The core logic for Unicode manipulation, metadata serialization (JSON, with custom canonicalization for signing), data compression (zlib), cryptographic operations (Ed25519 signatures via the `cryptography` library), and streaming support is inherently self-contained and does not require internet access or external APIs for its primary operations. This is crucial for a reproducible benchmark.\n2.  **Clear and Well-Defined Problem:** The goal of embedding, extracting, and verifying metadata in text is specific and understandable. The README and code structure (e.g., `UnicodeMetadata`, `StreamingHandler`, `crypto_utils`) clearly outline the functionalities to be replicated.\n3.  **Highly Testable:** The project includes a comprehensive suite of tests (unit tests for core logic, crypto, streaming, and settings; interop tests for C2PA structures). These tests can be adapted to verify the AI's reconstructed project, which is a significant advantage.\n4.  **No GUI:** The project is a library with CLI examples, making it suitable for programmatic interaction and testing, aligning with benchmark requirements.\n5.  **Appropriate Complexity (Medium):** Rebuilding this project involves several non-trivial components: understanding Unicode variation selectors, implementing text parsing for target locations, handling data serialization and compression, correctly using cryptographic libraries for signing/verification and key management concepts, and managing state for streaming data. This offers a meaningful challenge beyond simple tasks but is not excessively complex.\n6.  **Well-Understood Concepts (Mostly):** While Unicode variation selectors are somewhat niche, the underlying concepts of data embedding, digital signatures, and structured metadata (including the C2PA-inspired manifest) are established in software engineering.\n7.  **Modular Design:** The codebase is organized into logical modules (core, streaming, config, interop), which can serve as a good example or basis for the AI's implementation.\n\n**Negative Aspects and Considerations for Benchmark Scoping:**\n1.  **External Service Integrations:** The README and examples prominently feature integrations with LLMs (OpenAI, Gemini, Anthropic via LiteLLM) and a FastAPI example. These components require internet access, API keys, and potentially external service setups, making them unsuitable for a self-contained benchmark. **Mitigation:** The benchmark specification *must explicitly scope these integrations out*. The AI's task should be to rebuild the core offline library. The existing tests for LLM integrations (`test_litellm_integration.py`) are already designed to be skipped if API keys are absent, demonstrating their separability.\n2.  **C2PA-Inspired Manifest:** The 'manifest' metadata format, inspired by C2PA, introduces specific data structures. While well-defined in the code (TypedDicts in `crypto_utils.py`) and `interop/c2pa.py`, it adds to the implementation detail required.\n3.  **Cryptographic Implementation Details:** The AI must correctly use the `cryptography` library for Ed25519 operations. The existing code provides a clear reference.\n\n**Overall:**\nThe project is a strong candidate if the benchmark task is carefully scoped to rebuilding the core, offline functionalities of the `encypher-ai` library. Its combination of text processing, data transformation, cryptographic operations, and a good test suite makes it a valuable and appropriately challenging benchmark of 'Medium' difficulty. The primary risk is ensuring the AI focuses on the self-contained core and not the internet-dependent LLM/web integrations.",
            "llm_project_type": "Python library for text-based metadata embedding and verification",
            "llm_rating": 75,
            "llm_difficulty": "Medium"
        },
        "tests": {
            "repo_name": "encypherai_encypher-ai",
            "finish_test": true,
            "test_case_result": {
                "tests/core/test_crypto_utils.py::test_generate_key_pair": "passed",
                "tests/core/test_crypto_utils.py::test_load_save_keys": "passed",
                "tests/core/test_crypto_utils.py::test_load_save_keys_encrypted": "passed",
                "tests/core/test_crypto_utils.py::test_serialize_payload_basic": "passed",
                "tests/core/test_crypto_utils.py::test_serialize_payload_manifest": "passed",
                "tests/core/test_crypto_utils.py::test_serialize_payload_deterministic": "passed",
                "tests/core/test_crypto_utils.py::test_sign_and_verify_basic": "passed",
                "tests/core/test_crypto_utils.py::test_sign_and_verify_manifest": "passed",
                "tests/core/test_crypto_utils.py::test_verify_failure_wrong_key": "passed",
                "tests/core/test_crypto_utils.py::test_verify_failure_tampered_payload": "passed",
                "tests/core/test_crypto_utils.py::test_verify_failure_corrupt_signature": "passed",
                "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_verify_extract_success[basic-basic_metadata]": "passed",
                "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_verify_extract_success[manifest-manifest_metadata]": "passed",
                "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_metadata_raises_error_if_timestamp_missing": "passed",
                "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_wrong_key": "passed",
                "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_tampered_data": "passed",
                "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_failure_wrong_key": "passed",
                "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_failure_invalid_signature_format": "passed",
                "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_failure_unknown_signer_id": "passed",
                "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_failure_key_mismatch": "passed",
                "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_failure_provider_error": "passed",
                "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_unicode_metadata_extract_metadata": "passed",
                "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_unicode_metadata_extract_metadata_no_metadata": "passed",
                "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_unicode_metadata_extract_metadata_corrupted": "passed",
                "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_unicode_metadata_verify_with_manifest": "passed",
                "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_extract_metadata": "skipped",
                "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_custom_metadata": "skipped",
                "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_no_metadata_target": "skipped",
                "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_datetime_timestamp": "skipped",
                "tests/integration/test_litellm_integration.py::TestOpenAIIntegration::test_openai_completion": "skipped",
                "tests/integration/test_litellm_integration.py::TestOpenAIIntegration::test_openai_streaming": "skipped",
                "tests/integration/test_litellm_integration.py::TestAnthropicIntegration::test_anthropic_completion": "skipped",
                "tests/integration/test_llm_outputs.py::TestLLMOutputsIntegration::test_unicode_metadata_with_llm_outputs[openai-The quick brown fox jumps over the lazy dog. This is a sample output from OpenAI's GPT model that demonstrates how text might be formatted, including punctuation, spacing, and paragraph breaks.\\n\\nMultiple paragraphs might be included in the response, with varying lengths and structures. This helps test the robustness of the metadata encoding system across different text patterns.]": "skipped",
                "tests/integration/test_llm_outputs.py::TestLLMOutputsIntegration::test_unicode_metadata_with_llm_outputs[anthropic-Here's what I know about that topic:\\n\\n1. First, it's important to understand the basic principles.\\n2. Second, we should consider the historical context.\\n3. Finally, let's examine the practical applications.\\n\\nIn conclusion, this sample output from Anthropic's Claude model demonstrates different formatting styles including lists and structured content.]": "skipped",
                "tests/integration/test_llm_outputs.py::TestLLMOutputsIntegration::test_unicode_metadata_with_llm_outputs[gemini-When considering this question, I'd approach it from multiple angles:\\n\\n\\u2022 Technical feasibility\\n\\u2022 Economic implications\\n\\u2022 Ethical considerations\\n\\u2022 Social impact\\n\\nThis sample from Google's Gemini model includes bullet points and special characters to test encoding resilience.]": "skipped",
                "tests/integration/test_llm_outputs.py::TestLLMOutputsIntegration::test_unicode_metadata_with_llm_outputs[llama-To answer your question:\\nThe solution involves several steps. First, we need to analyze the problem domain. Second, we should identify potential approaches. Third, we implement the most promising solution.\\n\\nThis sample from Llama includes line breaks and a structured response format typical of instruction-tuned models.]": "skipped",
                "tests/integration/test_llm_outputs.py::TestStreamingIntegration::test_streaming_handler[openai-chunks0]": "passed",
                "tests/integration/test_llm_outputs.py::TestStreamingIntegration::test_streaming_handler[anthropic-chunks1]": "passed",
                "tests/integration/test_llm_outputs.py::TestStreamingIntegration::test_streaming_handler[gemini-chunks2]": "passed",
                "tests/integration/test_llm_outputs.py::TestStreamingIntegration::test_streaming_with_hmac[openai-chunks0]": "skipped",
                "tests/integration/test_llm_outputs.py::TestStreamingIntegration::test_streaming_with_hmac[anthropic-chunks1]": "skipped",
                "tests/integration/test_llm_outputs.py::TestStreamingIntegration::test_streaming_with_hmac[gemini-chunks2]": "skipped",
                "tests/interop/test_c2pa.py::TestC2PAInterop::test_c2pa_to_encypher_conversion": "passed",
                "tests/interop/test_c2pa.py::TestC2PAInterop::test_encypher_to_c2pa_conversion": "passed",
                "tests/interop/test_c2pa.py::TestC2PAInterop::test_error_handling": "passed",
                "tests/interop/test_c2pa.py::TestC2PAInterop::test_roundtrip_conversion": "passed",
                "tests/interop/test_c2pa.py::TestC2PAInterop::test_schema_generation": "passed",
                "tests/test_settings.py::TestSettings::test_default_settings": "passed",
                "tests/test_settings.py::TestSettings::test_load_from_file": "passed",
                "tests/test_settings.py::TestSettings::test_load_from_env": "passed",
                "tests/test_settings.py::TestSettings::test_env_overrides_file": "passed",
                "tests/test_settings.py::TestSettings::test_get_metadata_target": "passed",
                "tests/test_settings.py::TestSettings::test_to_dict": "passed",
                "tests/test_streaming_handler.py::TestStreamingHandler::test_process_text_chunk": "passed",
                "tests/test_streaming_handler.py::TestStreamingHandler::test_encode_first_chunk_only": "passed",
                "tests/test_streaming_handler.py::TestStreamingHandler::test_encode_all_chunks": "passed",
                "tests/test_streaming_handler.py::TestStreamingHandler::test_process_dict_chunk_openai": "passed",
                "tests/test_streaming_handler.py::TestStreamingHandler::test_process_dict_chunk_anthropic": "passed",
                "tests/test_streaming_handler.py::TestStreamingHandler::test_reset": "passed",
                "tests/test_streaming_handler.py::TestStreamingHandler::test_accumulation_for_small_chunks": "passed",
                "tests/test_streaming_handler.py::TestStreamingHandler::test_finalize_already_encoded": "passed",
                "tests/test_streaming_handler.py::TestStreamingHandler::test_finalize_with_no_targets": "passed",
                "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_encode_decode": "passed",
                "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_extract_metadata": "skipped",
                "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_custom_metadata": "skipped",
                "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_no_metadata_target": "skipped",
                "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_empty_text": "skipped",
                "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_datetime_timestamp": "skipped",
                "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_variation_selector_conversion": "passed",
                "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_hmac_verification": "skipped",
                "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_unicode_metadata_non_string_input": "passed"
            },
            "success_count": 51,
            "failed_count": 0,
            "error_count": 0,
            "skipped_count": 20,
            "unknown_count": 0,
            "total_count": 71,
            "success_rate": 0.7183098591549296,
            "coverage_report": {
                "covered_lines": 553,
                "num_statements": 1455,
                "percent_covered": 39.17075831969449,
                "percent_covered_display": "39",
                "missing_lines": 902,
                "excluded_lines": 0,
                "num_branches": 378,
                "num_partial_branches": 67,
                "covered_branches": 165,
                "missing_branches": 213
            },
            "coverage_result": {}
        },
        "codelines_count": 6144,
        "codefiles_count": 31,
        "code_length": 252173,
        "test_files_count": 8,
        "test_code_length": 97081,
        "structure": [
            {
                "file": "publish.py",
                "functions": [
                    {
                        "name": "run_command",
                        "docstring": "Run a shell command and print output.",
                        "comments": null,
                        "args": [
                            "command"
                        ]
                    },
                    {
                        "name": "main",
                        "docstring": "Build and publish the package using UV.",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/test_settings.py",
                "functions": [],
                "classes": [
                    {
                        "name": "TestSettings",
                        "docstring": "Test cases for Settings class.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_default_settings",
                                "docstring": "Test default settings.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_load_from_file",
                                "docstring": "Test loading settings from a file.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_load_from_env",
                                "docstring": "Test loading settings from environment variables.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "monkeypatch"
                                ]
                            },
                            {
                                "name": "test_env_overrides_file",
                                "docstring": "Test that environment variables override file settings.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "monkeypatch"
                                ]
                            },
                            {
                                "name": "test_get_metadata_target",
                                "docstring": "Test getting metadata target as enum.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_to_dict",
                                "docstring": "Test converting settings to dictionary.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/test_streaming_handler.py",
                "functions": [],
                "classes": [
                    {
                        "name": "TestStreamingHandler",
                        "docstring": "Test cases for StreamingHandler class.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_key_pair",
                                "docstring": "Generate a test key pair for signing metadata.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_public_key_provider",
                                "docstring": "Create a public key provider function for testing.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "test_key_pair"
                                ]
                            },
                            {
                                "name": "test_process_text_chunk",
                                "docstring": "Test processing a text chunk.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "test_key_pair",
                                    "test_public_key_provider"
                                ]
                            },
                            {
                                "name": "test_encode_first_chunk_only",
                                "docstring": "Test encoding only the first chunk.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "test_key_pair",
                                    "test_public_key_provider"
                                ]
                            },
                            {
                                "name": "test_encode_all_chunks",
                                "docstring": "Test encoding all chunks with accumulation.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "test_key_pair",
                                    "test_public_key_provider"
                                ]
                            },
                            {
                                "name": "test_process_dict_chunk_openai",
                                "docstring": "Test processing an OpenAI-style dictionary chunk.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "test_key_pair",
                                    "test_public_key_provider"
                                ]
                            },
                            {
                                "name": "test_process_dict_chunk_anthropic",
                                "docstring": "Test processing an Anthropic-style dictionary chunk.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "test_key_pair",
                                    "test_public_key_provider"
                                ]
                            },
                            {
                                "name": "test_reset",
                                "docstring": "Test resetting the handler.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "test_key_pair",
                                    "test_public_key_provider"
                                ]
                            },
                            {
                                "name": "test_accumulation_for_small_chunks",
                                "docstring": "Test accumulation of small chunks until enough targets are found.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "test_key_pair",
                                    "test_public_key_provider"
                                ]
                            },
                            {
                                "name": "test_finalize_already_encoded",
                                "docstring": "Test finalizing the stream when metadata has already been encoded.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "test_key_pair",
                                    "test_public_key_provider"
                                ]
                            },
                            {
                                "name": "test_finalize_with_no_targets",
                                "docstring": "Test finalizing the stream with accumulated text that has no targets.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "test_key_pair",
                                    "test_public_key_provider"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/test_unicode_metadata.py",
                "functions": [
                    {
                        "name": "key_pair_1",
                        "docstring": "Generate a key pair for testing.",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": [
                    {
                        "name": "TestUnicodeMetadata",
                        "docstring": "Test cases for UnicodeMetadata class.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_encode_decode",
                                "docstring": "Test encoding and decoding text using variation selectors.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_embed_extract_metadata",
                                "docstring": "Test embedding and extracting metadata.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_custom_metadata",
                                "docstring": "Test embedding and extracting custom metadata.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_no_metadata_target",
                                "docstring": "Test with NONE metadata target.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_empty_text",
                                "docstring": "Test with empty text.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_datetime_timestamp",
                                "docstring": "Test with datetime object as timestamp.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_variation_selector_conversion",
                                "docstring": "Test conversion between bytes and variation selectors.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_hmac_verification",
                                "docstring": "Test HMAC verification.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_unicode_metadata_non_string_input",
                                "docstring": "Test that non-string input raises TypeError for embed_metadata.",
                                "comments": "assert extracted_metadata.get(\"model_id\") == model_id\nassert int(extracted_metadata.get(\"timestamp\")) == timestamp\nVerify with incorrect key\nwrong_encoder = MetadataEncoder(hmac_secret_key=\"wrong-secret\")\nis_valid_wrong, _, _ = wrong_encoder.verify_text(encoded_text)\nCheck verification result with wrong key\nassert not is_valid_wrong, \"HMAC verification should fail with incorrect key\"",
                                "args": [
                                    "self",
                                    "key_pair_1"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/interop/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/interop/test_c2pa.py",
                "functions": [],
                "classes": [
                    {
                        "name": "TestC2PAInterop",
                        "docstring": "Test cases for C2PA interoperability functions.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "setUp",
                                "docstring": "Set up test fixtures.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_encypher_to_c2pa_conversion",
                                "docstring": "Test conversion from EncypherAI manifest to C2PA-like dictionary.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_c2pa_to_encypher_conversion",
                                "docstring": "Test conversion from C2PA-like dictionary to EncypherAI manifest.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_roundtrip_conversion",
                                "docstring": "Test roundtrip conversion (EncypherAI -> C2PA -> EncypherAI).",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_schema_generation",
                                "docstring": "Test that the schema generation function returns a valid schema.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_error_handling",
                                "docstring": "Test error handling for invalid inputs.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/integration/test_litellm_integration.py",
                "functions": [],
                "classes": [
                    {
                        "name": "TestOpenAIIntegration",
                        "docstring": "Integration tests with OpenAI models.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_openai_completion",
                                "docstring": "Test with OpenAI completion.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_openai_streaming",
                                "docstring": "Test with OpenAI streaming.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TestAnthropicIntegration",
                        "docstring": "Integration tests with Anthropic models.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_anthropic_completion",
                                "docstring": "Test with Anthropic completion.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/integration/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/integration/test_llm_outputs.py",
                "functions": [
                    {
                        "name": "test_key_pair",
                        "docstring": "Generate a key pair for integration tests.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_public_key_provider",
                        "docstring": "Provides a simple key provider for integration tests.",
                        "comments": null,
                        "args": [
                            "test_key_pair"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "TestLLMOutputsIntegration",
                        "docstring": "Integration tests with sample LLM outputs.",
                        "comments": "--- Test Classes ---",
                        "methods": [
                            {
                                "name": "test_unicode_metadata_with_llm_outputs",
                                "docstring": "Test UnicodeMetadata with various LLM outputs using signatures.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "provider",
                                    "sample_text",
                                    "test_key_pair",
                                    "test_public_key_provider"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TestStreamingIntegration",
                        "docstring": "Integration tests for embedding and verification with various LLM outputs.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_streaming_handler",
                                "docstring": "Test StreamingHandler with streaming chunks.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "provider",
                                    "chunks",
                                    "test_key_pair",
                                    "test_public_key_provider"
                                ]
                            },
                            {
                                "name": "test_streaming_with_hmac",
                                "docstring": "Test streaming with HMAC verification.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "provider",
                                    "chunks"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/core/test_crypto_utils.py",
                "functions": [
                    {
                        "name": "save_private_key",
                        "docstring": "Save a private key to a file in PEM format.\n\nArgs:\n    private_key: The private key to save\n    path: The file path to save to\n    password: Optional password for encryption",
                        "comments": "--- Helper functions to replace missing functionality ---",
                        "args": [
                            "private_key",
                            "path",
                            "password"
                        ]
                    },
                    {
                        "name": "save_public_key",
                        "docstring": "Save a public key to a file in PEM format.\n\nArgs:\n    public_key: The public key to save\n    path: The file path to save to",
                        "comments": null,
                        "args": [
                            "public_key",
                            "path"
                        ]
                    },
                    {
                        "name": "format_timestamp",
                        "docstring": "Format a datetime as an ISO 8601 string.\n\nArgs:\n    dt: The datetime to format, or None to use current time\n\nReturns:\n    ISO 8601 formatted timestamp string",
                        "comments": null,
                        "args": [
                            "dt"
                        ]
                    },
                    {
                        "name": "test_keys",
                        "docstring": "Generate a key pair for tests.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_generate_key_pair",
                        "docstring": "Test if key pair generation returns correct types.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_load_save_keys",
                        "docstring": "Test saving and loading keys using PEM format.",
                        "comments": null,
                        "args": [
                            "test_keys"
                        ]
                    },
                    {
                        "name": "test_load_save_keys_encrypted",
                        "docstring": "Test saving and loading keys with encryption.",
                        "comments": null,
                        "args": [
                            "test_keys"
                        ]
                    },
                    {
                        "name": "basic_payload_data",
                        "docstring": "Sample BasicPayload data.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "manifest_payload_data",
                        "docstring": "Sample ManifestPayload data.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_serialize_payload_basic",
                        "docstring": "Test canonical serialization of BasicPayload.",
                        "comments": null,
                        "args": [
                            "basic_payload_data"
                        ]
                    },
                    {
                        "name": "test_serialize_payload_manifest",
                        "docstring": "Test canonical serialization of ManifestPayload.",
                        "comments": null,
                        "args": [
                            "manifest_payload_data"
                        ]
                    },
                    {
                        "name": "test_serialize_payload_deterministic",
                        "docstring": "Ensure serialization produces the same bytes for the same input.",
                        "comments": null,
                        "args": [
                            "basic_payload_data"
                        ]
                    },
                    {
                        "name": "test_sign_and_verify_basic",
                        "docstring": "Test signing and verifying a BasicPayload.",
                        "comments": "--- Signing and Verification Tests ---",
                        "args": [
                            "test_keys",
                            "basic_payload_data"
                        ]
                    },
                    {
                        "name": "test_sign_and_verify_manifest",
                        "docstring": "Test signing and verifying a ManifestPayload.",
                        "comments": null,
                        "args": [
                            "test_keys",
                            "manifest_payload_data"
                        ]
                    },
                    {
                        "name": "test_verify_failure_wrong_key",
                        "docstring": "Test that verification fails with the wrong public key.",
                        "comments": null,
                        "args": [
                            "test_keys",
                            "basic_payload_data"
                        ]
                    },
                    {
                        "name": "test_verify_failure_tampered_payload",
                        "docstring": "Test that verification fails if the payload is altered after signing.",
                        "comments": null,
                        "args": [
                            "test_keys",
                            "basic_payload_data"
                        ]
                    },
                    {
                        "name": "test_verify_failure_corrupt_signature",
                        "docstring": "Test that verification fails with a corrupted signature.",
                        "comments": null,
                        "args": [
                            "test_keys",
                            "basic_payload_data"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/core/test_unicode_metadata.py",
                "functions": [
                    {
                        "name": "key_pair_1",
                        "docstring": "Generate first key pair for tests.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "key_pair_2",
                        "docstring": "Generate a second, different key pair for tests.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "sample_text",
                        "docstring": "Provides a much longer sample text with abundant targets for embedding metadata.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "basic_metadata",
                        "docstring": "Sample basic metadata.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "manifest_metadata",
                        "docstring": "Sample manifest metadata.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "public_key_provider",
                        "docstring": "Provides a function to resolve signer IDs to public keys.",
                        "comments": null,
                        "args": [
                            "key_pair_1",
                            "key_pair_2"
                        ]
                    },
                    {
                        "name": "decode_and_deserialize",
                        "docstring": "Helper to extract bytes, decompress, and deserialize for inspection.",
                        "comments": "--- Helper Function ---",
                        "args": [
                            "text"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "TestUnicodeMetadata",
                        "docstring": "Tests for the UnicodeMetadata class using signatures.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_embed_verify_extract_success",
                                "docstring": "Test successful embedding, verification, and extraction.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "key_pair_1",
                                    "sample_text",
                                    "metadata_format",
                                    "metadata_fixture",
                                    "public_key_provider",
                                    "request"
                                ]
                            },
                            {
                                "name": "test_embed_metadata_raises_error_if_timestamp_missing",
                                "docstring": "Test ValueError is raised if timestamp is not provided.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "key_pair_1",
                                    "sample_text"
                                ]
                            },
                            {
                                "name": "test_verify_wrong_key",
                                "docstring": "Test verification failure when the wrong public key is used (via provider).",
                                "comments": null,
                                "args": [
                                    "self",
                                    "key_pair_1",
                                    "key_pair_2",
                                    "sample_text",
                                    "basic_metadata",
                                    "public_key_provider"
                                ]
                            },
                            {
                                "name": "test_verify_tampered_data",
                                "docstring": "Test verification failure when the embedded data is altered.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "key_pair_1",
                                    "key_pair_2",
                                    "sample_text",
                                    "basic_metadata",
                                    "public_key_provider"
                                ]
                            },
                            {
                                "name": "test_verify_failure_wrong_key",
                                "docstring": "Test verification failure with the wrong public key.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "key_pair_1",
                                    "key_pair_2",
                                    "sample_text",
                                    "public_key_provider"
                                ]
                            },
                            {
                                "name": "test_verify_failure_invalid_signature_format",
                                "docstring": "Test verification failure with a malformed signature string.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "key_pair_1",
                                    "sample_text",
                                    "public_key_provider"
                                ]
                            },
                            {
                                "name": "test_verify_failure_unknown_signer_id",
                                "docstring": "Test verification failure when signer_id is unknown to the provider.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "key_pair_1",
                                    "sample_text",
                                    "public_key_provider"
                                ]
                            },
                            {
                                "name": "test_verify_failure_key_mismatch",
                                "docstring": "Test verification failure when provider returns wrong key type.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "key_pair_1",
                                    "sample_text"
                                ]
                            },
                            {
                                "name": "test_verify_failure_provider_error",
                                "docstring": "Test verification failure when provider raises an exception.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "key_pair_1",
                                    "sample_text"
                                ]
                            },
                            {
                                "name": "test_unicode_metadata_extract_metadata",
                                "docstring": "Test extracting metadata without verification.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "sample_text",
                                    "basic_metadata",
                                    "key_pair_1"
                                ]
                            },
                            {
                                "name": "test_unicode_metadata_extract_metadata_no_metadata",
                                "docstring": "Test extracting metadata when none is present.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "sample_text"
                                ]
                            },
                            {
                                "name": "test_unicode_metadata_extract_metadata_corrupted",
                                "docstring": "Test extracting metadata when the embedded data is corrupted.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "sample_text",
                                    "basic_metadata",
                                    "key_pair_1"
                                ]
                            },
                            {
                                "name": "test_unicode_metadata_verify_with_manifest",
                                "docstring": "Test verification with manifest metadata.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "manifest_metadata",
                                    "key_pair_1",
                                    "sample_text",
                                    "public_key_provider"
                                ]
                            },
                            {
                                "name": "test_embed_extract_metadata",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_custom_metadata",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_no_metadata_target",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_datetime_timestamp",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "sample_text",
                                "docstring": "Provides a much longer sample text with abundant targets for embedding metadata.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "encypher/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "encypher/streaming/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "encypher/streaming/handlers.py",
                "functions": [],
                "classes": [
                    {
                        "name": "StreamingHandler",
                        "docstring": "Handler for processing streaming chunks from LLM providers and encoding metadata.\n\nThis class ensures that metadata is properly encoded in streaming responses,\nhandling the complexities of partial text chunks while maintaining consistency.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the streaming handler.\n\nArgs:\n    metadata: Dictionary of metadata to encode. Must include keys required\n              by the chosen `metadata_format`.\n    target: Where to embed the metadata (whitespace, punctuation, etc.)\n    encode_first_chunk_only: Whether to encode metadata only in the first\n                             non-empty chunk. Currently, only True is fully\n                             supported for signature embedding.\n    private_key: The private key for signing the metadata.\n    signer_id: An identifier for the signer (associated with the public key).\n    metadata_format: The structure ('basic' or 'manifest') of the metadata payload.\n\nRaises:\n    ValueError: If `metadata_format` is invalid, or if `metadata` is provided\n                without `private_key` and `signer_id`.\n    TypeError: If `metadata`, `encode_first_chunk_only`, `private_key`,\n               or `signer_id` have incorrect types.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "metadata",
                                    "target",
                                    "encode_first_chunk_only",
                                    "private_key",
                                    "signer_id",
                                    "metadata_format"
                                ]
                            },
                            {
                                "name": "_has_sufficient_targets",
                                "docstring": "Check if the text has at least one suitable target for embedding metadata.\n\nArgs:\n    text: Text to check for targets\n\nReturns:\n    True if at least one suitable target is found, False otherwise",
                                "comments": null,
                                "args": [
                                    "self",
                                    "text"
                                ]
                            },
                            {
                                "name": "process_chunk",
                                "docstring": "Process a streaming chunk and encode metadata if needed.\n\nThis method handles both raw text chunks and structured chunks (like those from OpenAI).\n\nArgs:\n    chunk: Text chunk or dictionary containing a text chunk\n\nReturns:\n    Processed chunk with encoded metadata, preserving the input chunk type (str or dict).\n\nRaises:\n    ValueError: If the underlying text processing (_process_text_chunk) fails.\n    KeyError: If the expected keys ('choices', 'delta', 'content', etc.) are missing.\n    IndexError: If the 'choices' list is empty.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "chunk"
                                ]
                            },
                            {
                                "name": "_process_text_chunk",
                                "docstring": "Process a text chunk and encode metadata if needed.\n\nArgs:\n    chunk: Text chunk\n\nReturns:\n    Processed text chunk with encoded metadata\n\nRaises:\n    ValueError: If UnicodeMetadata.embed_metadata fails (e.g., not enough targets).",
                                "comments": null,
                                "args": [
                                    "self",
                                    "chunk"
                                ]
                            },
                            {
                                "name": "_process_dict_chunk",
                                "docstring": "Process a dictionary chunk and encode metadata if needed.\n\nThis handles structured chunks like those from OpenAI's streaming API.\n\nArgs:\n    chunk: Dictionary containing a text chunk\n\nReturns:\n    Processed dictionary with encoded metadata\n\nRaises:\n    ValueError: If the underlying text processing (_process_text_chunk) fails.\n    KeyError: If the expected keys ('choices', 'delta', 'content', etc.) are missing.\n    IndexError: If the 'choices' list is empty.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "chunk"
                                ]
                            },
                            {
                                "name": "finalize",
                                "docstring": "Finalize the stream and return any accumulated text with encoded metadata.\n\nThis method should be called after all chunks have been processed to handle\nany remaining accumulated text that hasn't been processed yet.\n\nReturns:\n    Processed accumulated text with encoded metadata, or None if no text accumulated\n\nRaises:\n    ValueError: If UnicodeMetadata.embed_metadata fails (e.g., not enough targets).",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "reset",
                                "docstring": "Reset the handler state.\n\nThis is useful when starting a new streaming session.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "encypher/interop/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "encypher/interop/c2pa.py",
                "functions": [
                    {
                        "name": "encypher_manifest_to_c2pa_like_dict",
                        "docstring": "Converts an EncypherAI ManifestPayload to a dictionary using field names\nconceptually aligned with C2PA assertion structures.\n\nThis function provides a conceptual bridge between EncypherAI's plain-text\nmanifest format and C2PA's rich media manifest structure, enabling potential\ninteroperability between the two approaches.\n\nArgs:\n    manifest: An EncypherAI manifest payload dictionary (can be a TypedDict ManifestPayload\n             or a regular dict with the same structure)\n\nReturns:\n    A dictionary with field names aligned with C2PA concepts, containing the\n    same information as the original manifest.\n\nExample:\n    ```python\n    from encypher.core.crypto_utils import ManifestPayload\n    from encypher.interop.c2pa import encypher_manifest_to_c2pa_like_dict\n\n    # Original EncypherAI manifest\n    manifest = ManifestPayload(\n        claim_generator=\"EncypherAI/1.1.0\",\n        assertions=[{\"label\": \"c2pa.created\", \"when\": \"2025-04-13T12:00:00Z\"}],\n        ai_assertion={\"model_id\": \"gpt-4o\", \"model_version\": \"1.0\"},\n        custom_claims={},\n        timestamp=\"2025-04-13T12:00:00Z\"\n    )\n\n    # Convert to C2PA-like structure\n    c2pa_dict = encypher_manifest_to_c2pa_like_dict(manifest)\n    ```",
                        "comments": null,
                        "args": [
                            "manifest"
                        ]
                    },
                    {
                        "name": "c2pa_like_dict_to_encypher_manifest",
                        "docstring": "Creates an EncypherAI ManifestPayload from a dictionary structured\nsimilarly to C2PA assertions. Handles missing fields gracefully.\n\nThis function provides a conceptual bridge from C2PA-like structures\nto EncypherAI's manifest format, enabling potential interoperability\nbetween the two approaches.\n\nArgs:\n    data: A dictionary with C2PA-like structure containing provenance information.\n\nReturns:\n    An EncypherAI ManifestPayload dictionary that can be used with EncypherAI's\n    embedding functions.\n\nExample:\n    ```python\n    from encypher.interop.c2pa import c2pa_like_dict_to_encypher_manifest\n\n    # C2PA-like structure\n    c2pa_data = {\n        \"claim_generator\": \"SomeApp/1.0\",\n        \"assertions\": [\n            {\n                \"label\": \"c2pa.created\",\n                \"data\": {\"timestamp\": \"2025-04-13T12:00:00Z\"}\n            },\n            {\n                \"label\": \"ai.model.info\",\n                \"data\": {\"model_id\": \"gpt-4o\", \"model_version\": \"1.0\"}\n            }\n        ],\n        \"timestamp\": \"2025-04-13T12:00:00Z\"\n    }\n\n    # Convert to EncypherAI manifest\n    manifest = c2pa_like_dict_to_encypher_manifest(c2pa_data)\n    ```",
                        "comments": null,
                        "args": [
                            "data"
                        ]
                    },
                    {
                        "name": "get_c2pa_manifest_schema",
                        "docstring": "Returns a JSON Schema representation of the C2PA-like structure used by this module.\n\nThis schema provides documentation for the expected structure of C2PA-like dictionaries\nused with the conversion functions in this module.\n\nReturns:\n    A dictionary containing the JSON Schema for C2PA-like structures.",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "encypher/config/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "encypher/config/settings.py",
                "functions": [],
                "classes": [
                    {
                        "name": "Settings",
                        "docstring": "Settings class for EncypherAI configuration.\n\nThis class handles loading configuration from environment variables\nand configuration files, with sensible defaults.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize settings from environment variables and/or config file.\n\nArgs:\n    config_file: Path to configuration file (JSON)\n    env_prefix: Prefix for environment variables",
                                "comments": null,
                                "args": [
                                    "self",
                                    "config_file",
                                    "env_prefix"
                                ]
                            },
                            {
                                "name": "_load_from_file",
                                "docstring": "Load configuration from a JSON file.\n\nArgs:\n    config_file: Path to configuration file",
                                "comments": null,
                                "args": [
                                    "self",
                                    "config_file"
                                ]
                            },
                            {
                                "name": "_load_from_env",
                                "docstring": "Load configuration from environment variables.\n\nEnvironment variables take precedence over config file values.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "get",
                                "docstring": "Get a configuration value.\n\nArgs:\n    key: Configuration key\n    default: Default value if key not found\n\nReturns:\n    Configuration value or default",
                                "comments": null,
                                "args": [
                                    "self",
                                    "key",
                                    "default"
                                ]
                            },
                            {
                                "name": "get_metadata_target",
                                "docstring": "Get the metadata target as an enum value.\n\nReturns:\n    MetadataTarget enum value",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "get_hmac_secret_key",
                                "docstring": "Get the HMAC secret key.\n\nReturns:\n    HMAC secret key",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "get_encode_first_chunk_only",
                                "docstring": "Get whether to encode metadata only in the first chunk.\n\nReturns:\n    True if encoding only the first chunk, False otherwise",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "get_timestamp_format",
                                "docstring": "Get the timestamp format.\n\nReturns:\n    Timestamp format string",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "get_logging_level",
                                "docstring": "Get the logging level.\n\nReturns:\n    Logging level string",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "get_report_usage_metrics",
                                "docstring": "Get whether to report usage metrics.\n\nReturns:\n    True if reporting usage metrics, False otherwise",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "to_dict",
                                "docstring": "Get the configuration as a dictionary.\n\nReturns:\n    Configuration dictionary",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": [
                            "DEFAULT_CONFIG"
                        ]
                    }
                ]
            },
            {
                "file": "encypher/examples/generate_keys.py",
                "functions": [
                    {
                        "name": "generate_and_print_keys",
                        "docstring": "Generates and prints Ed25519 keys and instructions.",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "encypher/examples/cli_example.py",
                "functions": [
                    {
                        "name": "count_metadata_occurrences",
                        "docstring": "Count how many times metadata appears in the text.\n\nArgs:\n    text: The text to analyze\n\nReturns:\n    int: Number of metadata occurrences",
                        "comments": null,
                        "args": [
                            "text"
                        ]
                    },
                    {
                        "name": "encode_metadata_with_count",
                        "docstring": "Wrapper around MetadataEncoder.encode_metadata that also returns the count of embeddings.\n\nReturns:\n    tuple: (encoded_text, embed_count)",
                        "comments": null,
                        "args": [
                            "encoder",
                            "text",
                            "model_id",
                            "timestamp",
                            "custom_metadata",
                            "target"
                        ]
                    },
                    {
                        "name": "encode_text",
                        "docstring": "Encode metadata into text.\n\nArgs:\n    args: Command line arguments",
                        "comments": null,
                        "args": [
                            "args"
                        ]
                    },
                    {
                        "name": "decode_text",
                        "docstring": "Decode metadata from text.",
                        "comments": null,
                        "args": [
                            "args"
                        ]
                    },
                    {
                        "name": "main",
                        "docstring": "Main entry point for the CLI.",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": [
                    {
                        "name": "TempArgs",
                        "docstring": null,
                        "comments": "Create args object with the input file",
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "input_file"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "encypher/examples/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "encypher/examples/youtube_demo.py",
                "functions": [
                    {
                        "name": "clear_screen",
                        "docstring": "Clear the terminal screen.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "print_header",
                        "docstring": "Print a stylish header for the demo.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "print_section",
                        "docstring": "Print a section title.",
                        "comments": null,
                        "args": [
                            "title"
                        ]
                    },
                    {
                        "name": "wait_for_key",
                        "docstring": "Wait for a key press to continue.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "get_display_text",
                        "docstring": "Return either the original text or encoded text based on the display flag.\n\nArgs:\n    encoded_text: Text with encoded metadata\n    original_text: Original text without metadata\n\nReturns:\n    The text to display based on DISPLAY_ORIGINAL_TEXT flag",
                        "comments": null,
                        "args": [
                            "encoded_text",
                            "original_text"
                        ]
                    },
                    {
                        "name": "format_bytes_for_display",
                        "docstring": "Format the byte representation of text for display.\n\nArgs:\n    text: The text to convert to byte representation\n    max_length: Maximum number of bytes to display\n\nReturns:\n    A formatted string showing the byte values",
                        "comments": null,
                        "args": [
                            "text",
                            "max_length"
                        ]
                    },
                    {
                        "name": "show_byte_comparison",
                        "docstring": "Display a technical comparison of byte values between original and encoded text.\n\nArgs:\n    original_text: The original text without metadata\n    encoded_text: The text with encoded metadata",
                        "comments": null,
                        "args": [
                            "original_text",
                            "encoded_text"
                        ]
                    },
                    {
                        "name": "demo_basic_encoding",
                        "docstring": "Demonstrate basic metadata encoding.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "demo_metadata_extraction",
                        "docstring": "Demonstrate metadata extraction and verification.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "demo_tamper_detection",
                        "docstring": "Demonstrate tamper detection using HMAC verification.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "demo_streaming",
                        "docstring": "Demonstrate streaming support.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "demo_real_world_use_cases",
                        "docstring": "Demonstrate real-world use cases.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "demo_conclusion",
                        "docstring": "Show conclusion and call to action.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "main",
                        "docstring": "Run the complete demo.",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "encypher/examples/fastapi_example.py",
                "functions": [],
                "classes": [
                    {
                        "name": "EncodeRequest",
                        "docstring": null,
                        "comments": "Request and response models",
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "EncodeResponse",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "DecodeRequest",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "DecodeResponse",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "StreamRequest",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "encypher/examples/litellm_integration.py",
                "functions": [],
                "classes": [
                    {
                        "name": "ChatMessage",
                        "docstring": "A chat message in the conversation.",
                        "comments": "Request and response models with enhanced documentation",
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "ChatRequest",
                        "docstring": "Request model for chat completions.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "ChatResponse",
                        "docstring": "Response model for chat completions.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "encypher/core/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "encypher/core/unicode_metadata.py",
                "functions": [],
                "classes": [
                    {
                        "name": "UnicodeMetadata",
                        "docstring": "Utility class for embedding and extracting metadata using Unicode\nvariation selectors.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "to_variation_selector",
                                "docstring": "Convert a byte to a variation selector character\n\nArgs:\n    byte: Byte value (0-255)\n\nReturns:\n    Unicode variation selector character or None if byte is out of range",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "byte"
                                ]
                            },
                            {
                                "name": "from_variation_selector",
                                "docstring": "Convert a variation selector code point to a byte\n\nArgs:\n    code_point: Unicode code point\n\nReturns:\n    Byte value (0-255) or None if not a variation selector",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "code_point"
                                ]
                            },
                            {
                                "name": "encode",
                                "docstring": "Encode text into an emoji using Unicode variation selectors\n\nArgs:\n    emoji: Base character to encode the text into\n    text: Text to encode\n\nReturns:\n    Encoded string with the text hidden in variation selectors",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "emoji",
                                    "text"
                                ]
                            },
                            {
                                "name": "decode",
                                "docstring": "Decode text from Unicode variation selectors\n\nArgs:\n    text: Text with embedded variation selectors\n\nReturns:\n    Decoded text",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "text"
                                ]
                            },
                            {
                                "name": "extract_bytes",
                                "docstring": "Extract bytes from Unicode variation selectors\n\nArgs:\n    text: Text with embedded variation selectors\n\nReturns:\n    Bytes extracted from variation selectors",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "text"
                                ]
                            },
                            {
                                "name": "_format_timestamp",
                                "docstring": "Helper to format various timestamp inputs into ISO 8601 UTC string.\n\nArgs:\n    ts: The timestamp input. Can be None, an ISO 8601 string,\n        a datetime object, a date object, or an int/float epoch\n        timestamp.\n\nReturns:\n    The timestamp formatted as an ISO 8601 string in UTC (e.g., \"YYYY-MM-DDTHH:MM:SSZ\"),\n    or None if the input was None.\n\nRaises:\n    ValueError: If the input is an invalid timestamp value or format.\n    TypeError: If the input type is not supported.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "ts"
                                ]
                            },
                            {
                                "name": "find_targets",
                                "docstring": "Find indices of characters in text where metadata can be embedded.\n\nArgs:\n    text: The text to find targets in.\n    target: Where to embed metadata ('whitespace', 'punctuation', etc.,\n            or MetadataTarget enum).\n\nReturns:\n    List of indices where metadata can be embedded.\n\nRaises:\n    ValueError: If target is an invalid string.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "text",
                                    "target"
                                ]
                            },
                            {
                                "name": "embed_metadata",
                                "docstring": "Embed metadata into text using Unicode variation selectors, signing with a private key.\n\nWhen using 'manifest' format, this method implements a C2PA-inspired approach for\ncontent provenance and authenticity, adapted specifically for plain-text environments\nwhere traditional file-based embedding methods aren't applicable. The manifest structure\nparallels C2PA's concepts of assertions, claim generators, and cryptographic integrity.\n\nArgs:\n    text: The text to embed metadata into.\n    private_key: The Ed25519 private key object for signing.\n    signer_id: A string identifying the signer/key pair (used for\n               verification lookup).\n    metadata_format: The format for the metadata payload ('basic' or 'manifest').\n                     Default is 'basic'. When set to 'manifest', uses a\n                     C2PA-inspired structured format.\n    model_id: Model identifier (used in 'basic' and optionally in\n              'manifest' ai_info).\n    timestamp: Timestamp (datetime, ISO string, int/float epoch). Stored as\n               ISO 8601 UTC string.\n               **This field is mandatory.**\n    target: Where to embed metadata ('whitespace', 'punctuation', etc.,\n            or MetadataTarget enum).\n    custom_metadata: Dictionary for custom fields (used in 'basic' payload).\n    claim_generator: Claim generator string (used in 'manifest' format).\n                     Similar to C2PA's concept of identifying the\n                     software/tool that generated the claim.\n    actions: List of action dictionaries (used in 'manifest' format).\n             Conceptually similar to C2PA assertions about operations\n             performed on the content.\n    ai_info: Dictionary with AI-specific info (used in 'manifest' format).\n             Represents a custom assertion type focused on AI-specific\n             attributes.\n    custom_claims: Dictionary for custom C2PA-like claims (used in\n                   'manifest' format).\n    distribute_across_targets: If True, distribute bits across multiple\n                               targets if needed.\n\nReturns:\n    The text with embedded metadata and digital signature.\n\nRaises:\n    ValueError: If 'timestamp' is not provided, if the target is invalid,\n                if not enough embedding locations are found, or if the\n                metadata + signature is too large.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "text",
                                    "private_key",
                                    "signer_id",
                                    "metadata_format",
                                    "model_id",
                                    "timestamp",
                                    "target",
                                    "custom_metadata",
                                    "claim_generator",
                                    "actions",
                                    "ai_info",
                                    "custom_claims",
                                    "distribute_across_targets"
                                ]
                            },
                            {
                                "name": "_bytes_to_variation_selectors",
                                "docstring": "Convert bytes into a list of Unicode variation selector characters.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "data"
                                ]
                            },
                            {
                                "name": "verify_and_extract_metadata",
                                "docstring": "Extracts embedded metadata, verifies its signature using a public key,\nand returns the payload, verification status, and signer ID.\n\nThis verification process implements a C2PA-inspired approach for content\nauthenticity verification, adapted specifically for plain-text environments.\nSimilar to how C2PA verifies digital signatures in media files to establish\nprovenance and integrity, this method verifies cryptographic signatures\nembedded directly within text using Unicode variation selectors.\n\nArgs:\n    text: Text potentially containing embedded metadata.\n    public_key_provider: A callable function that takes a signer_id (str)\n                         and returns the corresponding Ed25519PublicKey\n                         object or None if the key is not found.\n                         This resolver pattern enables flexible key management\n                         similar to C2PA's approach for signature verification.\n    return_payload_on_failure: If True, return the payload even when verification fails.\n                              If False (default), return None for the payload when verification fails.\n\nReturns:\n    A tuple containing:\n    - The extracted inner payload (Dict[str, Any], basic or manifest) or None\n      if extraction/verification fails (unless return_payload_on_failure is True).\n    - Verification status (bool): True if the signature is valid, False otherwise.\n    - The signer_id (str) found in the metadata, or None if extraction fails.\n\nRaises:\n    TypeError: If public_key_provider returns an invalid key type.\n    KeyError: If public_key_provider raises an error (e.g., key not found).\n    InvalidSignature: If the signature verification process itself fails.\n    Exception: Can propagate errors from base64 decoding or payload serialization.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "text",
                                    "public_key_provider",
                                    "return_payload_on_failure"
                                ]
                            },
                            {
                                "name": "_extract_outer_payload",
                                "docstring": "Extracts the raw OuterPayload dict from embedded bytes.\n\nFinds the metadata markers, extracts the embedded bytes, decodes the\nouter JSON structure, and returns the OuterPayload TypedDict if valid.\n\nArgs:\n    text: The text containing potentially embedded metadata.\n\nReturns:\n    The extracted OuterPayload dictionary if found and successfully parsed,\n    otherwise None.\n\nRaises:\n    (Indirectly via called methods) UnicodeDecodeError, json.JSONDecodeError, TypeError",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "text"
                                ]
                            },
                            {
                                "name": "verify_metadata",
                                "docstring": "Verify and extract metadata from text embedded using Unicode variation selectors and a public key.\n\nArgs:\n    text: Text with embedded metadata\n    public_key_provider: A callable function that takes a signer_id (str)\n                         and returns the corresponding Ed25519PublicKey\n                         object or None if the key is not found.\n    return_payload_on_failure: If True, return the payload even when verification fails.\n                              If False (default), return None for the payload when verification fails.\n\nReturns:\n    A tuple containing:\n    - The extracted inner payload (Dict[str, Any], basic or manifest) or None\n      if extraction/verification fails (unless return_payload_on_failure is True).\n    - Verification status (bool): True if the signature is valid, False otherwise.\n    - The signer_id (str) found in the metadata, or None if extraction fails.\n\nRaises:\n    TypeError: If public_key_provider returns an invalid key type.\n    KeyError: If public_key_provider raises an error (e.g., key not found).\n    InvalidSignature: If the signature verification process itself fails.\n    Exception: Can propagate errors from base64 decoding or payload serialization.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "text",
                                    "public_key_provider",
                                    "return_payload_on_failure"
                                ]
                            },
                            {
                                "name": "extract_metadata",
                                "docstring": "Extracts embedded metadata from text without verifying its signature.\n\nFinds the metadata markers, extracts the embedded bytes, decodes the\nouter JSON structure, and returns the inner 'payload' dictionary.\n\nSimilar to how C2PA allows for inspection of manifest contents separate\nfrom verification, this method enables access to the embedded provenance\ninformation without cryptographic validation. This is useful for debugging,\nanalysis, or when working with content where verification isn't the primary goal.\nWhen using the 'manifest' format, the extracted payload will contain C2PA-inspired\nstructured provenance information.\n\nArgs:\n    text: The text containing potentially embedded metadata.\n\nReturns:\n    The extracted inner metadata dictionary if found and successfully parsed,\n    otherwise None.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "text"
                                ]
                            },
                            {
                                "name": "_verify_metadata_hmac_deprecated",
                                "docstring": "Verify and extract metadata from text embedded using Unicode variation selectors and an HMAC secret key.\n\nArgs:\n    text: Text with embedded metadata\n    hmac_secret_key: HMAC secret key for verification\n\nReturns:\n    A tuple containing:\n    - The extracted inner payload (Dict[str, Any], basic or manifest) or empty dict if extraction fails.\n    - Verification status (bool): True if the signature is valid, False otherwise.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "text",
                                    "hmac_secret_key"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "encypher/core/constants.py",
                "functions": [],
                "classes": [
                    {
                        "name": "MetadataTarget",
                        "docstring": "Enum for metadata embedding targets.",
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "NONE",
                            "WHITESPACE",
                            "PUNCTUATION",
                            "FIRST_LETTER",
                            "LAST_LETTER",
                            "ALL_CHARACTERS"
                        ]
                    }
                ]
            },
            {
                "file": "encypher/core/crypto_utils.py",
                "functions": [
                    {
                        "name": "generate_key_pair",
                        "docstring": "Generates an Ed25519 key pair.\n\nReturns:\n    Tuple containing the private and public keys.",
                        "comments": "--- End TypedDict Definitions ---",
                        "args": []
                    },
                    {
                        "name": "sign_payload",
                        "docstring": "Signs the payload bytes using the private key (Ed25519).\n\nArgs:\n    private_key: The Ed25519 private key object.\n    payload_bytes: The canonical bytes of the payload to sign.\n\nReturns:\n    The signature bytes.\n\nRaises:\n    TypeError: If the provided key is not an Ed25519 private key.",
                        "comments": null,
                        "args": [
                            "private_key",
                            "payload_bytes"
                        ]
                    },
                    {
                        "name": "verify_signature",
                        "docstring": "Verifies the signature against the payload using the public key (Ed25519).\n\nArgs:\n    public_key: The Ed25519 public key object.\n    payload_bytes: The canonical bytes of the payload that was signed.\n    signature: The signature bytes to verify.\n\nReturns:\n    True if the signature is valid, False otherwise.\n\nRaises:\n    TypeError: If the provided key is not an Ed25519 public key.",
                        "comments": null,
                        "args": [
                            "public_key",
                            "payload_bytes",
                            "signature"
                        ]
                    },
                    {
                        "name": "serialize_payload",
                        "docstring": "Serializes the metadata payload dictionary into canonical JSON bytes.\nEnsures keys are sorted and uses compact separators for consistency.\n\nArgs:\n    payload: The dictionary payload.\n\nReturns:\n    UTF-8 encoded bytes of the canonical JSON string.",
                        "comments": null,
                        "args": [
                            "payload"
                        ]
                    },
                    {
                        "name": "load_private_key",
                        "docstring": "Loads an Ed25519 private key from PEM-encoded bytes or string,\nor from raw bytes (32 bytes).\n\nArgs:\n    key_data: PEM string/bytes or raw private key bytes.\n    password: Optional password for encrypted PEM keys.\n\nReturns:\n    Ed25519 private key object.\n\nRaises:\n    ValueError: If the key format is invalid or unsupported.\n    TypeError: If key_data has an invalid type.",
                        "comments": null,
                        "args": [
                            "key_data",
                            "password"
                        ]
                    },
                    {
                        "name": "load_public_key",
                        "docstring": "Loads an Ed25519 public key from PEM-encoded bytes or string,\nor from raw bytes (32 bytes).\n\nArgs:\n    key_data: PEM string/bytes or raw public key bytes.\n\nReturns:\n    Ed25519 public key object.\n\nRaises:\n    ValueError: If the key format is invalid or unsupported.\n    TypeError: If key_data has an invalid type.",
                        "comments": null,
                        "args": [
                            "key_data"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "BasicPayload",
                        "docstring": "Structure for the 'basic' metadata format payload.",
                        "comments": "--- TypedDict Definitions for Metadata Payloads ---",
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "ManifestAction",
                        "docstring": "Structure for an assertion within the 'manifest' payload.\n\nConceptually similar to C2PA assertions, these represent\noperations performed on the content. The naming convention for assertion labels\nfollows C2PA patterns (e.g., \"c2pa.created\", \"c2pa.transcribed\") to\nmaintain conceptual alignment with the broader provenance ecosystem.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "ManifestAiInfo",
                        "docstring": "Optional structure for AI-specific info within the 'manifest' payload.\n\nThis represents a custom assertion type focused on AI-specific attributes,\nsimilar to how C2PA allows for specialized assertion types. For AI-generated\ncontent, this provides critical provenance information about the model used.",
                        "comments": "Add other optional C2PA assertion fields if needed, e.g.:\nsoftwareAgent: Optional[str]\ndigitalSourceType: Optional[str]",
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "ManifestPayload",
                        "docstring": "Structure for the 'manifest' metadata format payload.\n\nInspired by the Coalition for Content Provenance and Authenticity (C2PA) manifests,\nthis structure provides a standardized way to embed provenance information\ndirectly within text content. While C2PA focuses on rich media file formats,\nEncypherAI adapts these concepts specifically for plain-text use cases where\ntraditional file embedding methods aren't applicable.\n\nThe manifest includes information about:\n- The software/tool that generated the claim (claim_generator)\n- A list of assertions about the content (conceptually similar to C2PA assertions)\n- AI-specific assertion when relevant (ai_assertion)\n- Custom claims for extensibility\n- Timestamp information",
                        "comments": "Add other relevant AI fields",
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "OuterPayload",
                        "docstring": "The complete outer structure embedded into the text.\n\nThis structure wraps either a basic payload or a C2PA-inspired manifest payload,\nadding cryptographic integrity through digital signatures. Similar to C2PA's\napproach of ensuring tamper-evidence through cryptographic signing, this\nstructure enables verification of content authenticity and integrity in\nplain-text environments.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "encypher/core/logging_config.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "encypher/utils/__init__.py",
                "functions": [],
                "classes": []
            }
        ],
        "test_cases": {
            "tests/core/test_crypto_utils.py::test_generate_key_pair": {
                "testid": "tests/core/test_crypto_utils.py::test_generate_key_pair",
                "result": "passed",
                "test_implementation": "def test_generate_key_pair():\n    \"\"\"Test if key pair generation returns correct types.\"\"\"\n    private_key, public_key = generate_key_pair()\n    assert isinstance(private_key, ed25519.Ed25519PrivateKey)\n    assert isinstance(public_key, ed25519.Ed25519PublicKey)"
            },
            "tests/core/test_crypto_utils.py::test_load_save_keys": {
                "testid": "tests/core/test_crypto_utils.py::test_load_save_keys",
                "result": "passed",
                "test_implementation": "def test_load_save_keys(test_keys):\n    \"\"\"Test saving and loading keys using PEM format.\"\"\"\n    private_key, public_key = test_keys\n    # Use tempfile for secure handling\n    with tempfile.TemporaryDirectory() as tmpdir:\n        priv_path = os.path.join(tmpdir, \"test_priv.pem\")\n        pub_path = os.path.join(tmpdir, \"test_pub.pem\")\n\n        # Save keys (PEM format implicitly)\n        save_private_key(private_key, priv_path)\n        save_public_key(public_key, pub_path)\n\n        # Read key files\n        with open(priv_path, \"rb\") as f:\n            priv_data = f.read()\n        with open(pub_path, \"rb\") as f:\n            pub_data = f.read()\n\n        # Load keys from data\n        loaded_priv = load_private_key(priv_data)\n        loaded_pub = load_public_key(pub_data)\n\n        # Check if loaded keys match original key types\n        assert isinstance(loaded_priv, ed25519.Ed25519PrivateKey)\n        assert isinstance(loaded_pub, ed25519.Ed25519PublicKey)\n\n        # Instead of comparing raw bytes, we'll sign and verify a test message\n        # to confirm the keys are functionally equivalent\n        test_message = b\"test message for key verification\"\n        original_signature = private_key.sign(test_message)\n        loaded_signature = loaded_priv.sign(test_message)\n\n        # Verify both signatures with both public keys\n        public_key.verify(original_signature, test_message)\n        public_key.verify(loaded_signature, test_message)\n        loaded_pub.verify(original_signature, test_message)\n        loaded_pub.verify(loaded_signature, test_message)"
            },
            "tests/core/test_crypto_utils.py::test_load_save_keys_encrypted": {
                "testid": "tests/core/test_crypto_utils.py::test_load_save_keys_encrypted",
                "result": "passed",
                "test_implementation": "def test_load_save_keys_encrypted(test_keys):\n    \"\"\"Test saving and loading keys with encryption.\"\"\"\n    private_key, public_key = test_keys\n    password = b\"supersecretpassword\"\n\n    with tempfile.TemporaryDirectory() as tmpdir:\n        priv_path_enc = os.path.join(tmpdir, \"test_priv_enc.pem\")\n\n        # Save encrypted private key\n        save_private_key(private_key, priv_path_enc, password=password)\n\n        # Read encrypted key file\n        with open(priv_path_enc, \"rb\") as f:\n            priv_data_enc = f.read()\n\n        # Load encrypted private key\n        loaded_priv_enc = load_private_key(priv_data_enc, password=password)\n        assert isinstance(loaded_priv_enc, ed25519.Ed25519PrivateKey)\n\n        # Verify the loaded key is functionally equivalent\n        test_message = b\"test message for encrypted key verification\"\n        original_signature = private_key.sign(test_message)\n        loaded_signature = loaded_priv_enc.sign(test_message)\n\n        public_key.verify(original_signature, test_message)\n        public_key.verify(loaded_signature, test_message)\n\n        # Test loading with wrong password\n        with pytest.raises(ValueError):\n            load_private_key(priv_data_enc, password=b\"wrongpassword\")\n\n        # Test loading without password\n        with pytest.raises(ValueError):\n            load_private_key(priv_data_enc)"
            },
            "tests/core/test_crypto_utils.py::test_serialize_payload_basic": {
                "testid": "tests/core/test_crypto_utils.py::test_serialize_payload_basic",
                "result": "passed",
                "test_implementation": "def test_serialize_payload_basic(basic_payload_data: BasicPayload):\n    \"\"\"Test canonical serialization of BasicPayload.\"\"\"\n    # Cast to Dict[str, Any] for serialize_payload\n    serialized_bytes = serialize_payload(cast(Dict[str, Any], basic_payload_data))\n    assert isinstance(serialized_bytes, bytes)\n    # Deserialize to check structure and canonical form (keys sorted)\n    data = json.loads(serialized_bytes.decode(\"utf-8\"))\n    assert list(data.keys()) == [\"custom_metadata\", \"model_id\", \"timestamp\"]\n    assert list(data[\"custom_metadata\"].keys()) == [\n        \"info\",\n        \"value\",\n    ]  # Check inner dict keys sorted\n    assert data[\"model_id\"] == basic_payload_data[\"model_id\"]"
            },
            "tests/core/test_crypto_utils.py::test_serialize_payload_manifest": {
                "testid": "tests/core/test_crypto_utils.py::test_serialize_payload_manifest",
                "result": "passed",
                "test_implementation": "def test_serialize_payload_manifest(manifest_payload_data: ManifestPayload):\n    \"\"\"Test canonical serialization of ManifestPayload.\"\"\"\n    # Cast to Dict[str, Any] for serialize_payload\n    serialized_bytes = serialize_payload(cast(Dict[str, Any], manifest_payload_data))\n    assert isinstance(serialized_bytes, bytes)\n    # Deserialize to check structure and canonical form\n    data = json.loads(serialized_bytes.decode(\"utf-8\"))\n    expected_keys = [\n        \"ai_assertion\",\n        \"assertions\",\n        \"claim_generator\",\n        \"custom_claims\",\n        \"timestamp\",\n    ]\n    assert list(data.keys()) == expected_keys\n    # Check inner structures are also sorted if they are dicts\n    assert list(data[\"assertions\"][0].keys()) == [\n        \"label\",\n        \"when\",\n    ]\n    assert list(data[\"ai_assertion\"].keys()) == [\"model_id\", \"model_version\"]\n    assert list(data[\"custom_claims\"].keys()) == [\"project_id\", \"run_type\"]\n    assert data[\"claim_generator\"] == manifest_payload_data[\"claim_generator\"]"
            },
            "tests/core/test_crypto_utils.py::test_serialize_payload_deterministic": {
                "testid": "tests/core/test_crypto_utils.py::test_serialize_payload_deterministic",
                "result": "passed",
                "test_implementation": "def test_serialize_payload_deterministic(basic_payload_data: BasicPayload):\n    \"\"\"Ensure serialization produces the same bytes for the same input.\"\"\"\n    # Cast to Dict[str, Any] for serialize_payload\n    bytes1 = serialize_payload(cast(Dict[str, Any], basic_payload_data))\n    # Create identical dict again\n    payload2 = BasicPayload(\n        timestamp=basic_payload_data[\"timestamp\"],\n        model_id=\"test_model_basic_v1.0\",\n        custom_metadata={\"value\": 123, \"info\": \"some basic custom data\"},  # Note different order\n    )\n    # Cast to Dict[str, Any] for serialize_payload\n    bytes2 = serialize_payload(cast(Dict[str, Any], payload2))\n    assert bytes1 == bytes2"
            },
            "tests/core/test_crypto_utils.py::test_sign_and_verify_basic": {
                "testid": "tests/core/test_crypto_utils.py::test_sign_and_verify_basic",
                "result": "passed",
                "test_implementation": "def test_sign_and_verify_basic(test_keys, basic_payload_data: BasicPayload):\n    \"\"\"Test signing and verifying a BasicPayload.\"\"\"\n    private_key, public_key = test_keys\n    # Cast to Dict[str, Any] for serialize_payload\n    payload_bytes = serialize_payload(cast(Dict[str, Any], basic_payload_data))\n    signer_id = \"test-signer-basic\"\n    signature = sign_payload(private_key, payload_bytes)\n\n    # Construct OuterPayload for verification structure\n    outer_payload_data = OuterPayload(\n        format=\"basic\",\n        signer_id=signer_id,\n        payload=basic_payload_data,  # Pass the original TypedDict here\n        signature=base64.urlsafe_b64encode(signature).decode(\"ascii\").rstrip(\"=\"),\n    )\n\n    # Simulate verification process (in reality, this happens within UnicodeMetadata)\n    retrieved_payload_bytes = serialize_payload(cast(Dict[str, Any], outer_payload_data[\"payload\"]))\n    retrieved_sig_bytes = base64.urlsafe_b64decode(outer_payload_data[\"signature\"] + \"===\")\n    is_valid = verify_signature(public_key, retrieved_payload_bytes, retrieved_sig_bytes)\n    assert is_valid is True"
            },
            "tests/core/test_crypto_utils.py::test_sign_and_verify_manifest": {
                "testid": "tests/core/test_crypto_utils.py::test_sign_and_verify_manifest",
                "result": "passed",
                "test_implementation": "def test_sign_and_verify_manifest(test_keys, manifest_payload_data: ManifestPayload):\n    \"\"\"Test signing and verifying a ManifestPayload.\"\"\"\n    private_key, public_key = test_keys\n    # Cast to Dict[str, Any] for serialize_payload\n    payload_bytes = serialize_payload(cast(Dict[str, Any], manifest_payload_data))\n    signer_id = \"test-signer-manifest\"\n    signature = sign_payload(private_key, payload_bytes)\n\n    # Construct OuterPayload for verification structure\n    outer_payload_data = OuterPayload(\n        format=\"manifest\",\n        signer_id=signer_id,\n        payload=manifest_payload_data,  # Pass the original TypedDict here\n        signature=base64.urlsafe_b64encode(signature).decode(\"ascii\").rstrip(\"=\"),\n    )\n\n    # Simulate verification process\n    retrieved_payload_bytes = serialize_payload(cast(Dict[str, Any], outer_payload_data[\"payload\"]))\n    retrieved_sig_bytes = base64.urlsafe_b64decode(outer_payload_data[\"signature\"] + \"===\")\n    is_valid = verify_signature(public_key, retrieved_payload_bytes, retrieved_sig_bytes)\n    assert is_valid is True"
            },
            "tests/core/test_crypto_utils.py::test_verify_failure_wrong_key": {
                "testid": "tests/core/test_crypto_utils.py::test_verify_failure_wrong_key",
                "result": "passed",
                "test_implementation": "def test_verify_failure_wrong_key(test_keys, basic_payload_data: BasicPayload):\n    \"\"\"Test that verification fails with the wrong public key.\"\"\"\n    private_key, _ = test_keys  # Use the correct private key to sign\n    # Cast to Dict[str, Any] for serialize_payload\n    payload_bytes = serialize_payload(cast(Dict[str, Any], basic_payload_data))\n    signer_id = \"test-signer-basic-wrongkey\"\n    signature = sign_payload(private_key, payload_bytes)\n\n    # Generate a DIFFERENT key pair for verification\n    _, wrong_public_key = generate_key_pair()\n\n    outer_payload_data = OuterPayload(\n        format=\"basic\",\n        signer_id=signer_id,\n        payload=basic_payload_data,\n        signature=base64.urlsafe_b64encode(signature).decode(\"ascii\").rstrip(\"=\"),\n    )\n\n    retrieved_payload_bytes = serialize_payload(cast(Dict[str, Any], outer_payload_data[\"payload\"]))\n    retrieved_sig_bytes = base64.urlsafe_b64decode(outer_payload_data[\"signature\"] + \"===\")\n    is_valid = verify_signature(wrong_public_key, retrieved_payload_bytes, retrieved_sig_bytes)\n    assert is_valid is False"
            },
            "tests/core/test_crypto_utils.py::test_verify_failure_tampered_payload": {
                "testid": "tests/core/test_crypto_utils.py::test_verify_failure_tampered_payload",
                "result": "passed",
                "test_implementation": "def test_verify_failure_tampered_payload(test_keys, basic_payload_data: BasicPayload):\n    \"\"\"Test that verification fails if the payload is altered after signing.\"\"\"\n    private_key, public_key = test_keys\n    # Cast to Dict[str, Any] for serialize_payload\n    payload_bytes = serialize_payload(cast(Dict[str, Any], basic_payload_data))\n    signer_id = \"test-signer-tampered\"\n    signature = sign_payload(private_key, payload_bytes)\n\n    # Tamper with the payload *after* signing but before outer construction\n    tampered_payload = BasicPayload(\n        timestamp=basic_payload_data[\"timestamp\"],\n        model_id=\"tampered_model_id\",  # Changed value\n        custom_metadata=basic_payload_data[\"custom_metadata\"].copy(),\n    )\n\n    outer_payload_data = OuterPayload(\n        format=\"basic\",\n        signer_id=signer_id,\n        payload=tampered_payload,  # Use the tampered payload\n        signature=base64.urlsafe_b64encode(signature).decode(\"ascii\").rstrip(\"=\"),\n    )\n\n    # Verification uses the (tampered) payload from OuterPayload\n    retrieved_payload_bytes = serialize_payload(cast(Dict[str, Any], outer_payload_data[\"payload\"]))\n    retrieved_sig_bytes = base64.urlsafe_b64decode(outer_payload_data[\"signature\"] + \"===\")\n    is_valid_tampered = verify_signature(public_key, retrieved_payload_bytes, retrieved_sig_bytes)\n    assert is_valid_tampered is False\n\n    # Also verify that serializing the *original* payload still fails against the tampered payload's signature context\n    # Although the signature was made from the original, verification compares against the *provided* (tampered) payload bytes\n    original_payload_bytes_for_check = serialize_payload(cast(Dict[str, Any], basic_payload_data))\n    verify_signature(public_key, original_payload_bytes_for_check, retrieved_sig_bytes)\n    # This might seem counter-intuitive, but verify_signature takes the bytes it's *told* correspond to the signature.\n    # Since we provide the tampered bytes during the actual verification call, it fails correctly.\n    # The important part is that the signature doesn't match the bytes derived from outer_payload_data['payload']\n    assert is_valid_tampered is False  # Re-asserting the main point"
            },
            "tests/core/test_crypto_utils.py::test_verify_failure_corrupt_signature": {
                "testid": "tests/core/test_crypto_utils.py::test_verify_failure_corrupt_signature",
                "result": "passed",
                "test_implementation": "def test_verify_failure_corrupt_signature(test_keys, basic_payload_data: BasicPayload):\n    \"\"\"Test that verification fails with a corrupted signature.\"\"\"\n    private_key, public_key = test_keys\n    # Cast to Dict[str, Any] for serialize_payload\n    payload_bytes = serialize_payload(cast(Dict[str, Any], basic_payload_data))\n    signer_id = \"test-signer-corrupt\"\n    signature = sign_payload(private_key, payload_bytes)\n\n    corrupted_signature = signature[:-1] + bytes([(signature[-1] + 1) % 256])  # Alter last byte\n\n    outer_payload_data = OuterPayload(\n        format=\"basic\",\n        signer_id=signer_id,\n        payload=basic_payload_data,\n        signature=base64.urlsafe_b64encode(corrupted_signature).decode(\"ascii\").rstrip(\"=\"),\n    )\n\n    retrieved_payload_bytes = serialize_payload(cast(Dict[str, Any], outer_payload_data[\"payload\"]))\n    retrieved_sig_bytes = base64.urlsafe_b64decode(outer_payload_data[\"signature\"] + \"===\")\n    is_valid = verify_signature(public_key, retrieved_payload_bytes, retrieved_sig_bytes)\n    assert is_valid is False"
            },
            "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_verify_extract_success[basic-basic_metadata]": {
                "testid": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_verify_extract_success[basic-basic_metadata]",
                "result": "passed",
                "test_implementation": "    def test_embed_verify_extract_success(\n        self,\n        key_pair_1,\n        sample_text,\n        metadata_format,\n        metadata_fixture,\n        public_key_provider,\n        request,  # Required to use fixture names indirectly\n    ):\n        \"\"\"Test successful embedding, verification, and extraction.\"\"\"\n        private_key, public_key = key_pair_1\n        signer_id = \"signer_1\"\n        metadata = request.getfixturevalue(metadata_fixture)\n\n        # Store original payload for comparison (handle TypedDict conversion if needed)\n        if \"timestamp\" not in metadata:\n            metadata[\"timestamp\"] = datetime.now(timezone.utc).isoformat()\n\n        original_payload = metadata.copy()\n\n        embedded_text = UnicodeMetadata.embed_metadata(\n            text=sample_text,\n            private_key=private_key,\n            signer_id=signer_id,\n            metadata_format=metadata_format,\n            target=MetadataTarget.PUNCTUATION,  # Use punctuation\n            **metadata,\n        )\n\n        assert embedded_text != sample_text\n\n        # Add debug information\n        print(f\"\\nEmbedded text length: {len(embedded_text)}\")\n        print(f\"Original text length: {len(sample_text)}\")\n\n        # Extract bytes for debugging\n        extracted_bytes = UnicodeMetadata.extract_bytes(embedded_text)\n        print(f\"Extracted bytes length: {len(extracted_bytes)}\")\n\n        # Try to decode the extracted bytes\n        try:\n            outer_data_str = extracted_bytes.decode(\"utf-8\")\n            outer_data = json.loads(outer_data_str)\n            print(f\"Outer data: {outer_data.keys()}\")\n        except Exception as e:\n            print(f\"Error decoding extracted bytes: {e}\")\n\n        extracted_payload, is_valid, extracted_signer_id = UnicodeMetadata.verify_and_extract_metadata(embedded_text, public_key_provider)\n\n        # Add more debug information\n        print(f\"Verification result: {is_valid}\")\n        print(f\"Extracted signer ID: {extracted_signer_id}\")\n        print(f\"Extracted payload: {extracted_payload}\")\n\n        assert is_valid is True\n        assert extracted_signer_id == signer_id\n        # Compare extracted payload with the original input metadata\n        # Note: Timestamp formatting might differ slightly if not ISO string initially\n        # We compare the core content\n        assert extracted_payload is not None\n        assert extracted_payload.get(\"format\") == metadata_format\n\n        # Compare relevant fields based on format\n        if metadata_format == \"basic\":\n            assert extracted_payload.get(\"model_id\") == original_payload.get(\"model_id\")\n            assert \"timestamp\" in extracted_payload\n            assert extracted_payload.get(\"custom_metadata\") == original_payload.get(\"custom_metadata\")\n        elif metadata_format == \"manifest\":\n            # Access nested manifest fields\n            manifest_payload = extracted_payload.get(\"manifest\", {})\n            assert manifest_payload.get(\"claim_generator\") == original_payload.get(\"claim_generator\")\n            # Compare actions - might need careful comparison due to structure/order\n            assert manifest_payload.get(\"actions\") == original_payload.get(\"actions\")\n            assert manifest_payload.get(\"ai_info\") == original_payload.get(\"ai_info\")\n            assert manifest_payload.get(\"custom_claims\") == original_payload.get(\"custom_claims\")"
            },
            "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_verify_extract_success[manifest-manifest_metadata]": {
                "testid": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_verify_extract_success[manifest-manifest_metadata]",
                "result": "passed",
                "test_implementation": "    def test_embed_verify_extract_success(\n        self,\n        key_pair_1,\n        sample_text,\n        metadata_format,\n        metadata_fixture,\n        public_key_provider,\n        request,  # Required to use fixture names indirectly\n    ):\n        \"\"\"Test successful embedding, verification, and extraction.\"\"\"\n        private_key, public_key = key_pair_1\n        signer_id = \"signer_1\"\n        metadata = request.getfixturevalue(metadata_fixture)\n\n        # Store original payload for comparison (handle TypedDict conversion if needed)\n        if \"timestamp\" not in metadata:\n            metadata[\"timestamp\"] = datetime.now(timezone.utc).isoformat()\n\n        original_payload = metadata.copy()\n\n        embedded_text = UnicodeMetadata.embed_metadata(\n            text=sample_text,\n            private_key=private_key,\n            signer_id=signer_id,\n            metadata_format=metadata_format,\n            target=MetadataTarget.PUNCTUATION,  # Use punctuation\n            **metadata,\n        )\n\n        assert embedded_text != sample_text\n\n        # Add debug information\n        print(f\"\\nEmbedded text length: {len(embedded_text)}\")\n        print(f\"Original text length: {len(sample_text)}\")\n\n        # Extract bytes for debugging\n        extracted_bytes = UnicodeMetadata.extract_bytes(embedded_text)\n        print(f\"Extracted bytes length: {len(extracted_bytes)}\")\n\n        # Try to decode the extracted bytes\n        try:\n            outer_data_str = extracted_bytes.decode(\"utf-8\")\n            outer_data = json.loads(outer_data_str)\n            print(f\"Outer data: {outer_data.keys()}\")\n        except Exception as e:\n            print(f\"Error decoding extracted bytes: {e}\")\n\n        extracted_payload, is_valid, extracted_signer_id = UnicodeMetadata.verify_and_extract_metadata(embedded_text, public_key_provider)\n\n        # Add more debug information\n        print(f\"Verification result: {is_valid}\")\n        print(f\"Extracted signer ID: {extracted_signer_id}\")\n        print(f\"Extracted payload: {extracted_payload}\")\n\n        assert is_valid is True\n        assert extracted_signer_id == signer_id\n        # Compare extracted payload with the original input metadata\n        # Note: Timestamp formatting might differ slightly if not ISO string initially\n        # We compare the core content\n        assert extracted_payload is not None\n        assert extracted_payload.get(\"format\") == metadata_format\n\n        # Compare relevant fields based on format\n        if metadata_format == \"basic\":\n            assert extracted_payload.get(\"model_id\") == original_payload.get(\"model_id\")\n            assert \"timestamp\" in extracted_payload\n            assert extracted_payload.get(\"custom_metadata\") == original_payload.get(\"custom_metadata\")\n        elif metadata_format == \"manifest\":\n            # Access nested manifest fields\n            manifest_payload = extracted_payload.get(\"manifest\", {})\n            assert manifest_payload.get(\"claim_generator\") == original_payload.get(\"claim_generator\")\n            # Compare actions - might need careful comparison due to structure/order\n            assert manifest_payload.get(\"actions\") == original_payload.get(\"actions\")\n            assert manifest_payload.get(\"ai_info\") == original_payload.get(\"ai_info\")\n            assert manifest_payload.get(\"custom_claims\") == original_payload.get(\"custom_claims\")"
            },
            "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_metadata_raises_error_if_timestamp_missing": {
                "testid": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_metadata_raises_error_if_timestamp_missing",
                "result": "passed",
                "test_implementation": "    def test_embed_metadata_raises_error_if_timestamp_missing(\n        self,\n        key_pair_1,\n        sample_text,\n    ):\n        \"\"\"Test ValueError is raised if timestamp is not provided.\"\"\"\n        private_key, _ = key_pair_1\n        signer_id = \"signer_1\"\n\n        with pytest.raises(ValueError) as excinfo:\n            UnicodeMetadata.embed_metadata(\n                text=sample_text,\n                private_key=private_key,\n                signer_id=signer_id,\n                metadata_format=\"basic\",  # Can be basic or manifest\n                model_id=\"test_model\",\n                timestamp=None,  # Explicitly missing\n                custom_metadata={\"data\": \"value\"},\n            )\n        # Check if the error message is as expected\n        assert \"'timestamp' must be provided\" in str(excinfo.value)"
            },
            "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_wrong_key": {
                "testid": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_wrong_key",
                "result": "passed",
                "test_implementation": "    def test_verify_wrong_key(\n        self,\n        key_pair_1,\n        key_pair_2,\n        sample_text,\n        basic_metadata,\n        public_key_provider,\n    ):\n        \"\"\"Test verification failure when the wrong public key is used (via provider).\"\"\"\n        private_key_signer1, _ = key_pair_1\n        _, public_key_signer2 = key_pair_2\n        signer_id = \"signer_1\"\n\n        # Define a provider that returns the wrong key\n        def wrong_key_provider(s_id: str) -> Optional[PublicKeyTypes]:\n            if s_id == \"signer_1\":\n                return cast(PublicKeyTypes, public_key_signer2)  # Return signer 2's key for signer 1's ID\n            return None\n\n        # Embed with key 1\n        embedded_text = UnicodeMetadata.embed_metadata(\n            text=sample_text,\n            private_key=private_key_signer1,\n            signer_id=signer_id,\n            metadata_format=\"basic\",\n            target=MetadataTarget.PUNCTUATION,  # Use punctuation\n            **basic_metadata,\n        )\n\n        # Verify with wrong key provider\n        extracted_payload, is_valid, extracted_signer_id = UnicodeMetadata.verify_and_extract_metadata(\n            embedded_text,\n            wrong_key_provider,\n            return_payload_on_failure=True,  # Return payload even when verification fails\n        )\n\n        assert is_valid is False\n        assert extracted_signer_id == signer_id\n        assert extracted_payload is not None  # Payload is extracted, but verification fails"
            },
            "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_tampered_data": {
                "testid": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_tampered_data",
                "result": "passed",
                "test_implementation": "    def test_verify_tampered_data(\n        self,\n        key_pair_1,\n        key_pair_2,\n        sample_text,\n        basic_metadata,\n        public_key_provider,\n    ):\n        \"\"\"Test verification failure when the embedded data is altered.\"\"\"\n        private_key_1, _ = key_pair_1\n        private_key_2, _ = key_pair_2\n        signer_id = \"signer_1\"\n\n        # First, embed metadata with key_pair_1\n        embedded_text = UnicodeMetadata.embed_metadata(\n            text=sample_text,\n            private_key=private_key_1,\n            signer_id=signer_id,\n            metadata_format=\"basic\",\n            target=MetadataTarget.PUNCTUATION,  # Use punctuation\n            **basic_metadata,\n        )\n\n        # Create tampered text by re-embedding the same metadata with a different key\n        # This simulates tampering with the data while keeping the same signer_id\n        tampered_text = UnicodeMetadata.embed_metadata(\n            text=sample_text,\n            private_key=private_key_2,  # Use a different key\n            signer_id=signer_id,  # But claim to be the same signer\n            metadata_format=\"basic\",\n            target=MetadataTarget.PUNCTUATION,\n            **basic_metadata,\n        )\n\n        assert tampered_text != embedded_text\n\n        # Verify the tampered text with the original signer's public key\n        extracted_payload, is_valid, extracted_signer_id = UnicodeMetadata.verify_and_extract_metadata(\n            tampered_text,\n            public_key_provider,\n            return_payload_on_failure=True,  # Return payload even when verification fails\n        )\n\n        # Verification should fail due to tampered data (wrong key used)\n        assert is_valid is False\n        # Payload should still be extracted since we're using return_payload_on_failure=True\n        assert extracted_payload is not None"
            },
            "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_failure_wrong_key": {
                "testid": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_failure_wrong_key",
                "result": "passed",
                "test_implementation": "    def test_verify_failure_wrong_key(\n        self,\n        key_pair_1,\n        key_pair_2,\n        sample_text,\n        public_key_provider,\n    ):\n        \"\"\"Test verification failure with the wrong public key.\"\"\"\n        private_key_1, _ = key_pair_1\n        signer_id = \"signer_2\"  # ID associated with key_pair_2 in the provider\n\n        encoded_text = UnicodeMetadata.embed_metadata(\n            text=sample_text,\n            private_key=private_key_1,\n            signer_id=signer_id,  # Sign with key 1, but claim to be signer 2\n            metadata_format=\"basic\",\n            model_id=\"wrong_key_test\",\n            timestamp=datetime.now(timezone.utc).isoformat(),\n            target=MetadataTarget.PUNCTUATION,  # Use punctuation\n        )\n\n        # Verification should fail because signature doesn't match public key for signer_id\n        extracted_payload, is_valid, extracted_signer_id = UnicodeMetadata.verify_and_extract_metadata(encoded_text, public_key_provider)\n\n        assert not is_valid\n        assert extracted_payload is None"
            },
            "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_failure_invalid_signature_format": {
                "testid": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_failure_invalid_signature_format",
                "result": "passed",
                "test_implementation": "    def test_verify_failure_invalid_signature_format(\n        self,\n        key_pair_1,\n        sample_text,\n        public_key_provider,\n    ):\n        \"\"\"Test verification failure with a malformed signature string.\"\"\"\n        private_key, _ = key_pair_1\n        signer_id = \"signer_1\"\n        encoded_text = UnicodeMetadata.embed_metadata(\n            text=sample_text,\n            private_key=private_key,\n            signer_id=signer_id,\n            metadata_format=\"basic\",\n            model_id=\"bad_sig_test\",\n            timestamp=datetime.now(timezone.utc).isoformat(),\n            target=MetadataTarget.PUNCTUATION,  # Use punctuation\n        )\n\n        # With the new embedding approach, we'll just modify a few variation selectors\n        # Find the first variation selector and change it\n        for i, char in enumerate(encoded_text):\n            code_point = ord(char)\n            if UnicodeMetadata.VARIATION_SELECTOR_START <= code_point <= UnicodeMetadata.VARIATION_SELECTOR_END:\n                # Replace this variation selector with a different one\n                corrupted_text = encoded_text[:i] + chr(code_point + 1) + encoded_text[i + 1 :]\n                break\n            elif UnicodeMetadata.VARIATION_SELECTOR_SUPPLEMENT_START <= code_point <= UnicodeMetadata.VARIATION_SELECTOR_SUPPLEMENT_END:\n                # Replace this variation selector with a different one\n                corrupted_text = encoded_text[:i] + chr(code_point + 1) + encoded_text[i + 1 :]\n                break\n        else:\n            # If no variation selectors found, just append an invalid one\n            corrupted_text = encoded_text + chr(UnicodeMetadata.VARIATION_SELECTOR_START)\n\n        # Verify the corrupted text\n        extracted_payload, is_valid, extracted_signer_id = UnicodeMetadata.verify_and_extract_metadata(corrupted_text, public_key_provider)\n\n        assert not is_valid\n        assert extracted_payload is None"
            },
            "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_failure_unknown_signer_id": {
                "testid": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_failure_unknown_signer_id",
                "result": "passed",
                "test_implementation": "    def test_verify_failure_unknown_signer_id(\n        self,\n        key_pair_1,\n        sample_text,\n        public_key_provider,\n    ):\n        \"\"\"Test verification failure when signer_id is unknown to the provider.\"\"\"\n        private_key, _ = key_pair_1\n        signer_id = \"signer_unknown\"  # This ID is not in the provider map\n\n        encoded_text = UnicodeMetadata.embed_metadata(\n            text=sample_text,\n            private_key=private_key,\n            signer_id=signer_id,\n            metadata_format=\"basic\",\n            model_id=\"unknown_signer_test\",\n            timestamp=datetime.now(timezone.utc).isoformat(),\n            target=MetadataTarget.PUNCTUATION,  # Use punctuation\n        )\n\n        # Verification should fail as provider returns None\n        extracted_payload, is_valid, extracted_signer_id = UnicodeMetadata.verify_and_extract_metadata(encoded_text, public_key_provider)\n\n        assert not is_valid\n        assert extracted_payload is None"
            },
            "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_failure_key_mismatch": {
                "testid": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_failure_key_mismatch",
                "result": "passed",
                "test_implementation": "    def test_verify_failure_key_mismatch(self, key_pair_1, sample_text):\n        \"\"\"Test verification failure when provider returns wrong key type.\"\"\"\n        private_key, public_key = key_pair_1  # Correctly unpack public_key\n        signer_id = \"signer_1\"\n        encoded_text = UnicodeMetadata.embed_metadata(\n            text=sample_text,\n            private_key=private_key,\n            signer_id=signer_id,\n            metadata_format=\"basic\",\n            model_id=\"key_mismatch_test\",\n            timestamp=datetime.now(timezone.utc).isoformat(),\n            target=MetadataTarget.PUNCTUATION,  # Use punctuation\n        )\n\n        # Provider returns a private key instead of public\n        def wrong_key_provider(s_id: str) -> Optional[PublicKeyTypes]:\n            if s_id == \"signer_1\":\n                return cast(PublicKeyTypes, private_key)  # Return private key for signer 1\n            return None  # Original for others\n\n        extracted_payload, is_valid, extracted_signer_id = UnicodeMetadata.verify_and_extract_metadata(encoded_text, wrong_key_provider)\n\n        assert not is_valid\n        assert extracted_payload is None"
            },
            "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_failure_provider_error": {
                "testid": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_failure_provider_error",
                "result": "passed",
                "test_implementation": "    def test_verify_failure_provider_error(self, key_pair_1, sample_text):\n        \"\"\"Test verification failure when provider raises an exception.\"\"\"\n        private_key, _ = key_pair_1\n        signer_id = \"signer_1\"\n        encoded_text = UnicodeMetadata.embed_metadata(\n            text=sample_text,\n            private_key=private_key,\n            signer_id=signer_id,\n            metadata_format=\"basic\",\n            model_id=\"provider_error_test\",\n            timestamp=datetime.now(timezone.utc).isoformat(),\n            target=MetadataTarget.PUNCTUATION,  # Use punctuation\n        )\n\n        # Provider raises an error\n        def error_provider(s_id: str) -> Optional[PublicKeyTypes]:\n            raise Exception(\"Mock provider error\")\n\n        extracted_payload, is_valid, extracted_signer_id = UnicodeMetadata.verify_and_extract_metadata(encoded_text, error_provider)\n\n        assert not is_valid\n        assert extracted_payload is None"
            },
            "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_unicode_metadata_extract_metadata": {
                "testid": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_unicode_metadata_extract_metadata",
                "result": "passed",
                "test_implementation": "    def test_unicode_metadata_extract_metadata(self, sample_text, basic_metadata, key_pair_1):\n        \"\"\"Test extracting metadata without verification.\"\"\"\n        private_key, public_key = key_pair_1\n        signer_id_to_use = \"test-key-1\"\n        # Ensure timestamp is in basic_metadata fixture before using it\n        if \"timestamp\" not in basic_metadata:\n            basic_metadata[\"timestamp\"] = datetime.now(timezone.utc).isoformat()\n        metadata_to_embed = basic_metadata  # Use the basic_metadata fixture directly\n\n        # Embed metadata - Corrected call\n        encoded_text = UnicodeMetadata.embed_metadata(\n            text=sample_text,\n            private_key=private_key,\n            signer_id=signer_id_to_use,  # Pass the signer_id\n            metadata_format=\"basic\",  # Specify format\n            target=MetadataTarget.WHITESPACE,\n            **metadata_to_embed,  # Unpack the metadata dictionary\n        )\n\n        # Extract metadata\n        extracted_metadata = UnicodeMetadata.extract_metadata(encoded_text)\n        assert extracted_metadata is not None, \"Metadata should be extracted\"\n        # Check some key metadata fields (excluding signature/key_id if not needed)\n        # Compare against metadata_to_embed\n        assert extracted_metadata.get(\"model_id\") == metadata_to_embed.get(\"model_id\")\n        assert extracted_metadata.get(\"timestamp\") is not None  # Just check presence\n        assert extracted_metadata.get(\"custom_metadata\") == metadata_to_embed.get(\"custom_metadata\")"
            },
            "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_unicode_metadata_extract_metadata_no_metadata": {
                "testid": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_unicode_metadata_extract_metadata_no_metadata",
                "result": "passed",
                "test_implementation": "    def test_unicode_metadata_extract_metadata_no_metadata(self, sample_text):\n        \"\"\"Test extracting metadata when none is present.\"\"\"\n        extracted_metadata = UnicodeMetadata.extract_metadata(sample_text)\n        assert extracted_metadata is None, \"Should return None when no metadata is embedded\""
            },
            "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_unicode_metadata_extract_metadata_corrupted": {
                "testid": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_unicode_metadata_extract_metadata_corrupted",
                "result": "passed",
                "test_implementation": "    def test_unicode_metadata_extract_metadata_corrupted(self, sample_text, basic_metadata, key_pair_1):\n        \"\"\"Test extracting metadata when the embedded data is corrupted.\"\"\"\n        private_key, public_key = key_pair_1\n        signer_id_to_use = \"test-key-1\"\n\n        # Ensure timestamp is included in the metadata\n        metadata_to_embed = {**basic_metadata}\n        if \"timestamp\" not in metadata_to_embed:\n            metadata_to_embed[\"timestamp\"] = datetime.now(timezone.utc).isoformat()\n\n        # Embed metadata\n        encoded_text = UnicodeMetadata.embed_metadata(\n            text=sample_text,\n            private_key=private_key,\n            signer_id=signer_id_to_use,\n            metadata_format=\"basic\",\n            target=MetadataTarget.WHITESPACE,\n            **metadata_to_embed,\n        )\n\n        # Create corrupted text by replacing some characters\n        # This will corrupt any embedded variation selectors\n        corrupted_text = \"\"\n        for i, char in enumerate(encoded_text):\n            # Replace every 10th character to corrupt the data\n            if i % 10 == 0 and i > 0:\n                corrupted_text += \"X\"\n            else:\n                corrupted_text += char\n\n        # Try to extract metadata from the corrupted text\n        extracted_metadata = UnicodeMetadata.extract_metadata(corrupted_text)\n        assert extracted_metadata is None, \"Should return None for corrupted data\""
            },
            "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_unicode_metadata_verify_with_manifest": {
                "testid": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_unicode_metadata_verify_with_manifest",
                "result": "passed",
                "test_implementation": "    def test_unicode_metadata_verify_with_manifest(self, manifest_metadata, key_pair_1, sample_text, public_key_provider):\n        \"\"\"Test verification with manifest metadata.\"\"\"\n        private_key, public_key = key_pair_1\n        signer_id = \"signer_1\"\n\n        encoded_text = UnicodeMetadata.embed_metadata(\n            text=sample_text,\n            private_key=private_key,\n            signer_id=signer_id,\n            metadata_format=\"manifest\",\n            **manifest_metadata,\n        )\n\n        # Verify the encoded text\n        extracted_payload, is_valid, extracted_signer_id = UnicodeMetadata.verify_and_extract_metadata(encoded_text, public_key_provider)\n\n        assert is_valid\n        assert extracted_signer_id == signer_id\n        assert extracted_payload is not None\n        assert extracted_payload.get(\"format\") == \"manifest\"\n        # Access nested manifest fields\n        manifest_payload = extracted_payload.get(\"manifest\", {})\n        assert manifest_payload.get(\"claim_generator\") == manifest_metadata.get(\"claim_generator\")\n        assert manifest_payload.get(\"actions\") == manifest_metadata.get(\"actions\")\n        assert manifest_payload.get(\"ai_info\") == manifest_metadata.get(\"ai_info\")\n        assert manifest_payload.get(\"custom_claims\") == manifest_metadata.get(\"custom_claims\")"
            },
            "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_extract_metadata": {
                "testid": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_extract_metadata",
                "result": "skipped",
                "test_implementation": "    def test_embed_extract_metadata(self):\n        pass"
            },
            "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_custom_metadata": {
                "testid": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_custom_metadata",
                "result": "skipped",
                "test_implementation": "    def test_custom_metadata(self):\n        pass"
            },
            "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_no_metadata_target": {
                "testid": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_no_metadata_target",
                "result": "skipped",
                "test_implementation": "    def test_no_metadata_target(self):\n        pass"
            },
            "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_datetime_timestamp": {
                "testid": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_datetime_timestamp",
                "result": "skipped",
                "test_implementation": "    def test_datetime_timestamp(self):\n        pass"
            },
            "tests/integration/test_litellm_integration.py::TestOpenAIIntegration::test_openai_completion": {
                "testid": "tests/integration/test_litellm_integration.py::TestOpenAIIntegration::test_openai_completion",
                "result": "skipped",
                "test_implementation": "    def test_openai_completion(self):\n        \"\"\"Test with OpenAI completion.\"\"\"\n        # Set up LiteLLM\n        litellm.api_key = OPENAI_API_KEY\n\n        # Generate completion\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n            {\"role\": \"user\", \"content\": \"Write a short paragraph about AI ethics.\"},\n        ]\n\n        response = litellm.completion(model=\"gpt-3.5-turbo\", messages=messages)\n\n        # Extract content\n        content = response.choices[0].message.content\n\n        # Prepare metadata\n        metadata = {\n            \"model_id\": \"gpt-3.5-turbo\",\n            \"timestamp\": datetime.now(timezone.utc).isoformat(),\n            \"request_id\": response.id,\n            \"usage\": {\n                \"prompt_tokens\": response.usage.prompt_tokens,\n                \"completion_tokens\": response.usage.completion_tokens,\n                \"total_tokens\": response.usage.total_tokens,\n            },\n        }\n\n        # Encode metadata\n        encoded_content = UnicodeMetadata.embed_metadata(\n            text=content,\n            model_id=metadata[\"model_id\"],\n            timestamp=metadata[\"timestamp\"],\n            target=\"whitespace\",\n            custom_metadata={k: v for k, v in metadata.items() if k not in [\"model_id\", \"timestamp\"]},\n        )\n\n        # Extract metadata\n        extracted = UnicodeMetadata.extract_metadata(encoded_content)\n\n        # Assertions\n        assert extracted[\"model_id\"] == metadata[\"model_id\"]\n        assert extracted[\"timestamp\"] == metadata[\"timestamp\"]\n        assert extracted[\"request_id\"] == metadata[\"request_id\"]\n        assert \"usage\" in extracted"
            },
            "tests/integration/test_litellm_integration.py::TestOpenAIIntegration::test_openai_streaming": {
                "testid": "tests/integration/test_litellm_integration.py::TestOpenAIIntegration::test_openai_streaming",
                "result": "skipped",
                "test_implementation": "    def test_openai_streaming(self):\n        \"\"\"Test with OpenAI streaming.\"\"\"\n        # Set up LiteLLM\n        litellm.api_key = OPENAI_API_KEY\n\n        # Prepare metadata\n        metadata = {\n            \"model_id\": \"gpt-3.5-turbo\",\n            \"timestamp\": datetime.now(timezone.utc).isoformat(),\n            \"request_id\": f\"req_{int(datetime.now().timestamp())}\",\n        }\n\n        # Initialize streaming handler\n        handler = StreamingHandler(metadata=metadata, target=\"whitespace\", encode_first_chunk_only=True)\n\n        # Generate streaming completion\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n            {\"role\": \"user\", \"content\": \"Write a short paragraph about AI ethics.\"},\n        ]\n\n        stream = litellm.completion(model=\"gpt-3.5-turbo\", messages=messages, stream=True)\n\n        # Process streaming chunks\n        processed_chunks = []\n        for chunk in stream:\n            if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:\n                content = chunk.choices[0].delta.content\n                processed_chunk = handler.process_chunk(content)\n                processed_chunks.append(processed_chunk)\n\n        # Combine all chunks\n        full_text = \"\".join(processed_chunks)\n\n        # Extract metadata\n        extracted = UnicodeMetadata.extract_metadata(full_text)\n\n        # Assertions\n        assert extracted[\"model_id\"] == metadata[\"model_id\"]\n        assert extracted[\"timestamp\"] == metadata[\"timestamp\"]\n        assert extracted[\"request_id\"] == metadata[\"request_id\"]"
            },
            "tests/integration/test_litellm_integration.py::TestAnthropicIntegration::test_anthropic_completion": {
                "testid": "tests/integration/test_litellm_integration.py::TestAnthropicIntegration::test_anthropic_completion",
                "result": "skipped",
                "test_implementation": "    def test_anthropic_completion(self):\n        \"\"\"Test with Anthropic completion.\"\"\"\n        # Set up LiteLLM\n        litellm.anthropic_api_key = ANTHROPIC_API_KEY\n\n        # Generate completion\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n            {\"role\": \"user\", \"content\": \"Write a short paragraph about AI ethics.\"},\n        ]\n\n        response = litellm.completion(model=\"claude-3-sonnet-20240229\", messages=messages)\n\n        # Extract content\n        content = response.choices[0].message.content\n\n        # Prepare metadata\n        metadata = {\n            \"model_id\": \"claude-3-sonnet-20240229\",\n            \"timestamp\": datetime.now(timezone.utc).isoformat(),\n            \"request_id\": response.id,\n            \"usage\": {\n                \"prompt_tokens\": response.usage.prompt_tokens,\n                \"completion_tokens\": response.usage.completion_tokens,\n                \"total_tokens\": response.usage.total_tokens,\n            },\n        }\n\n        # Encode metadata\n        encoded_content = UnicodeMetadata.embed_metadata(\n            text=content,\n            model_id=metadata[\"model_id\"],\n            timestamp=metadata[\"timestamp\"],\n            target=\"whitespace\",\n            custom_metadata={k: v for k, v in metadata.items() if k not in [\"model_id\", \"timestamp\"]},\n        )\n\n        # Extract metadata\n        extracted = UnicodeMetadata.extract_metadata(encoded_content)\n\n        # Assertions\n        assert extracted[\"model_id\"] == metadata[\"model_id\"]\n        assert extracted[\"timestamp\"] == metadata[\"timestamp\"]\n        assert extracted[\"request_id\"] == metadata[\"request_id\"]\n        assert \"usage\" in extracted"
            },
            "tests/integration/test_llm_outputs.py::TestLLMOutputsIntegration::test_unicode_metadata_with_llm_outputs[openai-The quick brown fox jumps over the lazy dog. This is a sample output from OpenAI's GPT model that demonstrates how text might be formatted, including punctuation, spacing, and paragraph breaks.\\n\\nMultiple paragraphs might be included in the response, with varying lengths and structures. This helps test the robustness of the metadata encoding system across different text patterns.]": {
                "testid": "tests/integration/test_llm_outputs.py::TestLLMOutputsIntegration::test_unicode_metadata_with_llm_outputs[openai-The quick brown fox jumps over the lazy dog. This is a sample output from OpenAI's GPT model that demonstrates how text might be formatted, including punctuation, spacing, and paragraph breaks.\\n\\nMultiple paragraphs might be included in the response, with varying lengths and structures. This helps test the robustness of the metadata encoding system across different text patterns.]",
                "result": "skipped",
                "test_implementation": "    def test_unicode_metadata_with_llm_outputs(self, provider, sample_text, test_key_pair, test_public_key_provider):\n        \"\"\"Test UnicodeMetadata with various LLM outputs using signatures.\"\"\"\n        private_key, public_key = test_key_pair\n        signer_id = \"integration_signer\"\n\n        # Test data (using basic format for simplicity)\n        basic_metadata = {\n            \"model_id\": f\"{provider}-model\",\n            \"timestamp\": datetime.now(timezone.utc).isoformat(),  # Use current time\n            \"custom_metadata\": {\n                \"request_id\": \"test-123\",\n                \"user_id\": \"user-456\",\n                \"cost\": 0.0023,\n                \"tokens\": 150,\n            },\n        }\n\n        # Test with different metadata targets\n        # Combine target loop with metadata format parameterization if needed\n        for target in [\n            MetadataTarget.WHITESPACE,\n            MetadataTarget.PUNCTUATION,\n            MetadataTarget.FIRST_LETTER,\n        ]:\n            # Embed metadata\n            embedded_text = UnicodeMetadata.embed_metadata(\n                text=sample_text,\n                private_key=private_key,\n                signer_id=signer_id,\n                metadata_format=\"basic\",  # Explicitly basic for this test data\n                **basic_metadata,  # Pass dict content as kwargs\n            )\n\n            # Verify text appearance is unchanged (basic check)\n            assert len(embedded_text) > len(sample_text), f\"Encoded text should be longer than original for {provider} with {target.name}\"\n\n            # Verify and Extract metadata\n            extracted_payload, is_valid, extracted_signer_id = UnicodeMetadata.verify_and_extract_metadata(embedded_text, test_public_key_provider)\n\n            # Verify extracted metadata\n            assert is_valid is True, f\"Verification failed for {provider} with {target.name}\"\n            assert extracted_signer_id == signer_id, f\"Signer ID mismatch for {provider} with {target.name}\"\n            assert extracted_payload is not None\n            assert extracted_payload.get(\"format\") == \"basic\"\n\n            inner_payload = extracted_payload.get(\"payload\")\n            assert inner_payload is not None\n            assert inner_payload.get(\"model_id\") == basic_metadata[\"model_id\"], f\"Model ID mismatch for {provider} with {target.name}\"\n            # Timestamp comparison can be tricky due to potential slight format diffs,\n            # comparing the core custom data is usually sufficient for integration tests\n            assert (\n                inner_payload.get(\"custom_metadata\") == basic_metadata[\"custom_metadata\"]\n            ), f\"Custom metadata mismatch for {provider} with {target.name}\""
            },
            "tests/integration/test_llm_outputs.py::TestLLMOutputsIntegration::test_unicode_metadata_with_llm_outputs[anthropic-Here's what I know about that topic:\\n\\n1. First, it's important to understand the basic principles.\\n2. Second, we should consider the historical context.\\n3. Finally, let's examine the practical applications.\\n\\nIn conclusion, this sample output from Anthropic's Claude model demonstrates different formatting styles including lists and structured content.]": {
                "testid": "tests/integration/test_llm_outputs.py::TestLLMOutputsIntegration::test_unicode_metadata_with_llm_outputs[anthropic-Here's what I know about that topic:\\n\\n1. First, it's important to understand the basic principles.\\n2. Second, we should consider the historical context.\\n3. Finally, let's examine the practical applications.\\n\\nIn conclusion, this sample output from Anthropic's Claude model demonstrates different formatting styles including lists and structured content.]",
                "result": "skipped",
                "test_implementation": "    def test_unicode_metadata_with_llm_outputs(self, provider, sample_text, test_key_pair, test_public_key_provider):\n        \"\"\"Test UnicodeMetadata with various LLM outputs using signatures.\"\"\"\n        private_key, public_key = test_key_pair\n        signer_id = \"integration_signer\"\n\n        # Test data (using basic format for simplicity)\n        basic_metadata = {\n            \"model_id\": f\"{provider}-model\",\n            \"timestamp\": datetime.now(timezone.utc).isoformat(),  # Use current time\n            \"custom_metadata\": {\n                \"request_id\": \"test-123\",\n                \"user_id\": \"user-456\",\n                \"cost\": 0.0023,\n                \"tokens\": 150,\n            },\n        }\n\n        # Test with different metadata targets\n        # Combine target loop with metadata format parameterization if needed\n        for target in [\n            MetadataTarget.WHITESPACE,\n            MetadataTarget.PUNCTUATION,\n            MetadataTarget.FIRST_LETTER,\n        ]:\n            # Embed metadata\n            embedded_text = UnicodeMetadata.embed_metadata(\n                text=sample_text,\n                private_key=private_key,\n                signer_id=signer_id,\n                metadata_format=\"basic\",  # Explicitly basic for this test data\n                **basic_metadata,  # Pass dict content as kwargs\n            )\n\n            # Verify text appearance is unchanged (basic check)\n            assert len(embedded_text) > len(sample_text), f\"Encoded text should be longer than original for {provider} with {target.name}\"\n\n            # Verify and Extract metadata\n            extracted_payload, is_valid, extracted_signer_id = UnicodeMetadata.verify_and_extract_metadata(embedded_text, test_public_key_provider)\n\n            # Verify extracted metadata\n            assert is_valid is True, f\"Verification failed for {provider} with {target.name}\"\n            assert extracted_signer_id == signer_id, f\"Signer ID mismatch for {provider} with {target.name}\"\n            assert extracted_payload is not None\n            assert extracted_payload.get(\"format\") == \"basic\"\n\n            inner_payload = extracted_payload.get(\"payload\")\n            assert inner_payload is not None\n            assert inner_payload.get(\"model_id\") == basic_metadata[\"model_id\"], f\"Model ID mismatch for {provider} with {target.name}\"\n            # Timestamp comparison can be tricky due to potential slight format diffs,\n            # comparing the core custom data is usually sufficient for integration tests\n            assert (\n                inner_payload.get(\"custom_metadata\") == basic_metadata[\"custom_metadata\"]\n            ), f\"Custom metadata mismatch for {provider} with {target.name}\""
            },
            "tests/integration/test_llm_outputs.py::TestLLMOutputsIntegration::test_unicode_metadata_with_llm_outputs[gemini-When considering this question, I'd approach it from multiple angles:\\n\\n\\u2022 Technical feasibility\\n\\u2022 Economic implications\\n\\u2022 Ethical considerations\\n\\u2022 Social impact\\n\\nThis sample from Google's Gemini model includes bullet points and special characters to test encoding resilience.]": {
                "testid": "tests/integration/test_llm_outputs.py::TestLLMOutputsIntegration::test_unicode_metadata_with_llm_outputs[gemini-When considering this question, I'd approach it from multiple angles:\\n\\n\\u2022 Technical feasibility\\n\\u2022 Economic implications\\n\\u2022 Ethical considerations\\n\\u2022 Social impact\\n\\nThis sample from Google's Gemini model includes bullet points and special characters to test encoding resilience.]",
                "result": "skipped",
                "test_implementation": "    def test_unicode_metadata_with_llm_outputs(self, provider, sample_text, test_key_pair, test_public_key_provider):\n        \"\"\"Test UnicodeMetadata with various LLM outputs using signatures.\"\"\"\n        private_key, public_key = test_key_pair\n        signer_id = \"integration_signer\"\n\n        # Test data (using basic format for simplicity)\n        basic_metadata = {\n            \"model_id\": f\"{provider}-model\",\n            \"timestamp\": datetime.now(timezone.utc).isoformat(),  # Use current time\n            \"custom_metadata\": {\n                \"request_id\": \"test-123\",\n                \"user_id\": \"user-456\",\n                \"cost\": 0.0023,\n                \"tokens\": 150,\n            },\n        }\n\n        # Test with different metadata targets\n        # Combine target loop with metadata format parameterization if needed\n        for target in [\n            MetadataTarget.WHITESPACE,\n            MetadataTarget.PUNCTUATION,\n            MetadataTarget.FIRST_LETTER,\n        ]:\n            # Embed metadata\n            embedded_text = UnicodeMetadata.embed_metadata(\n                text=sample_text,\n                private_key=private_key,\n                signer_id=signer_id,\n                metadata_format=\"basic\",  # Explicitly basic for this test data\n                **basic_metadata,  # Pass dict content as kwargs\n            )\n\n            # Verify text appearance is unchanged (basic check)\n            assert len(embedded_text) > len(sample_text), f\"Encoded text should be longer than original for {provider} with {target.name}\"\n\n            # Verify and Extract metadata\n            extracted_payload, is_valid, extracted_signer_id = UnicodeMetadata.verify_and_extract_metadata(embedded_text, test_public_key_provider)\n\n            # Verify extracted metadata\n            assert is_valid is True, f\"Verification failed for {provider} with {target.name}\"\n            assert extracted_signer_id == signer_id, f\"Signer ID mismatch for {provider} with {target.name}\"\n            assert extracted_payload is not None\n            assert extracted_payload.get(\"format\") == \"basic\"\n\n            inner_payload = extracted_payload.get(\"payload\")\n            assert inner_payload is not None\n            assert inner_payload.get(\"model_id\") == basic_metadata[\"model_id\"], f\"Model ID mismatch for {provider} with {target.name}\"\n            # Timestamp comparison can be tricky due to potential slight format diffs,\n            # comparing the core custom data is usually sufficient for integration tests\n            assert (\n                inner_payload.get(\"custom_metadata\") == basic_metadata[\"custom_metadata\"]\n            ), f\"Custom metadata mismatch for {provider} with {target.name}\""
            },
            "tests/integration/test_llm_outputs.py::TestLLMOutputsIntegration::test_unicode_metadata_with_llm_outputs[llama-To answer your question:\\nThe solution involves several steps. First, we need to analyze the problem domain. Second, we should identify potential approaches. Third, we implement the most promising solution.\\n\\nThis sample from Llama includes line breaks and a structured response format typical of instruction-tuned models.]": {
                "testid": "tests/integration/test_llm_outputs.py::TestLLMOutputsIntegration::test_unicode_metadata_with_llm_outputs[llama-To answer your question:\\nThe solution involves several steps. First, we need to analyze the problem domain. Second, we should identify potential approaches. Third, we implement the most promising solution.\\n\\nThis sample from Llama includes line breaks and a structured response format typical of instruction-tuned models.]",
                "result": "skipped",
                "test_implementation": "    def test_unicode_metadata_with_llm_outputs(self, provider, sample_text, test_key_pair, test_public_key_provider):\n        \"\"\"Test UnicodeMetadata with various LLM outputs using signatures.\"\"\"\n        private_key, public_key = test_key_pair\n        signer_id = \"integration_signer\"\n\n        # Test data (using basic format for simplicity)\n        basic_metadata = {\n            \"model_id\": f\"{provider}-model\",\n            \"timestamp\": datetime.now(timezone.utc).isoformat(),  # Use current time\n            \"custom_metadata\": {\n                \"request_id\": \"test-123\",\n                \"user_id\": \"user-456\",\n                \"cost\": 0.0023,\n                \"tokens\": 150,\n            },\n        }\n\n        # Test with different metadata targets\n        # Combine target loop with metadata format parameterization if needed\n        for target in [\n            MetadataTarget.WHITESPACE,\n            MetadataTarget.PUNCTUATION,\n            MetadataTarget.FIRST_LETTER,\n        ]:\n            # Embed metadata\n            embedded_text = UnicodeMetadata.embed_metadata(\n                text=sample_text,\n                private_key=private_key,\n                signer_id=signer_id,\n                metadata_format=\"basic\",  # Explicitly basic for this test data\n                **basic_metadata,  # Pass dict content as kwargs\n            )\n\n            # Verify text appearance is unchanged (basic check)\n            assert len(embedded_text) > len(sample_text), f\"Encoded text should be longer than original for {provider} with {target.name}\"\n\n            # Verify and Extract metadata\n            extracted_payload, is_valid, extracted_signer_id = UnicodeMetadata.verify_and_extract_metadata(embedded_text, test_public_key_provider)\n\n            # Verify extracted metadata\n            assert is_valid is True, f\"Verification failed for {provider} with {target.name}\"\n            assert extracted_signer_id == signer_id, f\"Signer ID mismatch for {provider} with {target.name}\"\n            assert extracted_payload is not None\n            assert extracted_payload.get(\"format\") == \"basic\"\n\n            inner_payload = extracted_payload.get(\"payload\")\n            assert inner_payload is not None\n            assert inner_payload.get(\"model_id\") == basic_metadata[\"model_id\"], f\"Model ID mismatch for {provider} with {target.name}\"\n            # Timestamp comparison can be tricky due to potential slight format diffs,\n            # comparing the core custom data is usually sufficient for integration tests\n            assert (\n                inner_payload.get(\"custom_metadata\") == basic_metadata[\"custom_metadata\"]\n            ), f\"Custom metadata mismatch for {provider} with {target.name}\""
            },
            "tests/integration/test_llm_outputs.py::TestStreamingIntegration::test_streaming_handler[openai-chunks0]": {
                "testid": "tests/integration/test_llm_outputs.py::TestStreamingIntegration::test_streaming_handler[openai-chunks0]",
                "result": "passed",
                "test_implementation": "    def test_streaming_handler(self, provider, chunks, test_key_pair, test_public_key_provider):\n        \"\"\"Test StreamingHandler with streaming chunks.\"\"\"\n        private_key, public_key = test_key_pair\n        signer_id = \"integration_signer\"\n        metadata_format = \"basic\"  # Assuming basic format for this test\n\n        # Metadata to embed\n        metadata = {\n            \"model_id\": f\"{provider}-model\",\n            \"timestamp\": datetime.now(timezone.utc).isoformat(),  # Use current time\n            \"custom_metadata\": {\n                \"request_id\": \"stream-123\",\n                \"cost\": 0.0015,\n            },\n        }\n\n        # Test with different configurations\n        encode_first_only = True\n        for target in [MetadataTarget.WHITESPACE, MetadataTarget.PUNCTUATION]:\n            # Initialize streaming handler\n            handler = StreamingHandler(\n                metadata=metadata,\n                target=target,\n                encode_first_chunk_only=encode_first_only,\n                private_key=private_key,  # Pass the key\n                signer_id=signer_id,  # Pass the signer ID\n                metadata_format=metadata_format,  # Pass the format\n            )\n\n            # Process chunks one by one to test true streaming behavior\n            processed_chunks = []\n            for chunk in chunks:\n                processed_chunk = handler.process_chunk(chunk)\n                processed_chunks.append(processed_chunk)\n\n            # Finalize to handle any remaining accumulated text\n            final_chunk = handler.finalize()\n            if final_chunk:\n                processed_chunks.append(final_chunk)\n\n            # Combine all processed chunks\n            processed_text = \"\".join(processed_chunks)\n\n            # Verify and Extract metadata from the combined processed text\n            extracted_payload, is_valid, extracted_signer_id = UnicodeMetadata.verify_and_extract_metadata(processed_text, test_public_key_provider)\n\n            # Check if metadata was extracted and verified correctly\n            assert is_valid is True, f\"Verification failed for {provider}, target={target.name}, first_only={encode_first_only}\"\n            assert extracted_signer_id == signer_id, f\"Signer ID mismatch for {provider}, target={target.name}, first_only={encode_first_only}\"\n            assert extracted_payload is not None\n            assert extracted_payload.get(\"format\") == metadata_format\n\n            # Check that the model_id in the payload matches what we embedded\n            assert (\n                extracted_payload.get(\"model_id\") == metadata[\"model_id\"]\n            ), f\"Model ID mismatch for {provider}, target={target.name}, first_only={encode_first_only}\""
            },
            "tests/integration/test_llm_outputs.py::TestStreamingIntegration::test_streaming_handler[anthropic-chunks1]": {
                "testid": "tests/integration/test_llm_outputs.py::TestStreamingIntegration::test_streaming_handler[anthropic-chunks1]",
                "result": "passed",
                "test_implementation": "    def test_streaming_handler(self, provider, chunks, test_key_pair, test_public_key_provider):\n        \"\"\"Test StreamingHandler with streaming chunks.\"\"\"\n        private_key, public_key = test_key_pair\n        signer_id = \"integration_signer\"\n        metadata_format = \"basic\"  # Assuming basic format for this test\n\n        # Metadata to embed\n        metadata = {\n            \"model_id\": f\"{provider}-model\",\n            \"timestamp\": datetime.now(timezone.utc).isoformat(),  # Use current time\n            \"custom_metadata\": {\n                \"request_id\": \"stream-123\",\n                \"cost\": 0.0015,\n            },\n        }\n\n        # Test with different configurations\n        encode_first_only = True\n        for target in [MetadataTarget.WHITESPACE, MetadataTarget.PUNCTUATION]:\n            # Initialize streaming handler\n            handler = StreamingHandler(\n                metadata=metadata,\n                target=target,\n                encode_first_chunk_only=encode_first_only,\n                private_key=private_key,  # Pass the key\n                signer_id=signer_id,  # Pass the signer ID\n                metadata_format=metadata_format,  # Pass the format\n            )\n\n            # Process chunks one by one to test true streaming behavior\n            processed_chunks = []\n            for chunk in chunks:\n                processed_chunk = handler.process_chunk(chunk)\n                processed_chunks.append(processed_chunk)\n\n            # Finalize to handle any remaining accumulated text\n            final_chunk = handler.finalize()\n            if final_chunk:\n                processed_chunks.append(final_chunk)\n\n            # Combine all processed chunks\n            processed_text = \"\".join(processed_chunks)\n\n            # Verify and Extract metadata from the combined processed text\n            extracted_payload, is_valid, extracted_signer_id = UnicodeMetadata.verify_and_extract_metadata(processed_text, test_public_key_provider)\n\n            # Check if metadata was extracted and verified correctly\n            assert is_valid is True, f\"Verification failed for {provider}, target={target.name}, first_only={encode_first_only}\"\n            assert extracted_signer_id == signer_id, f\"Signer ID mismatch for {provider}, target={target.name}, first_only={encode_first_only}\"\n            assert extracted_payload is not None\n            assert extracted_payload.get(\"format\") == metadata_format\n\n            # Check that the model_id in the payload matches what we embedded\n            assert (\n                extracted_payload.get(\"model_id\") == metadata[\"model_id\"]\n            ), f\"Model ID mismatch for {provider}, target={target.name}, first_only={encode_first_only}\""
            },
            "tests/integration/test_llm_outputs.py::TestStreamingIntegration::test_streaming_handler[gemini-chunks2]": {
                "testid": "tests/integration/test_llm_outputs.py::TestStreamingIntegration::test_streaming_handler[gemini-chunks2]",
                "result": "passed",
                "test_implementation": "    def test_streaming_handler(self, provider, chunks, test_key_pair, test_public_key_provider):\n        \"\"\"Test StreamingHandler with streaming chunks.\"\"\"\n        private_key, public_key = test_key_pair\n        signer_id = \"integration_signer\"\n        metadata_format = \"basic\"  # Assuming basic format for this test\n\n        # Metadata to embed\n        metadata = {\n            \"model_id\": f\"{provider}-model\",\n            \"timestamp\": datetime.now(timezone.utc).isoformat(),  # Use current time\n            \"custom_metadata\": {\n                \"request_id\": \"stream-123\",\n                \"cost\": 0.0015,\n            },\n        }\n\n        # Test with different configurations\n        encode_first_only = True\n        for target in [MetadataTarget.WHITESPACE, MetadataTarget.PUNCTUATION]:\n            # Initialize streaming handler\n            handler = StreamingHandler(\n                metadata=metadata,\n                target=target,\n                encode_first_chunk_only=encode_first_only,\n                private_key=private_key,  # Pass the key\n                signer_id=signer_id,  # Pass the signer ID\n                metadata_format=metadata_format,  # Pass the format\n            )\n\n            # Process chunks one by one to test true streaming behavior\n            processed_chunks = []\n            for chunk in chunks:\n                processed_chunk = handler.process_chunk(chunk)\n                processed_chunks.append(processed_chunk)\n\n            # Finalize to handle any remaining accumulated text\n            final_chunk = handler.finalize()\n            if final_chunk:\n                processed_chunks.append(final_chunk)\n\n            # Combine all processed chunks\n            processed_text = \"\".join(processed_chunks)\n\n            # Verify and Extract metadata from the combined processed text\n            extracted_payload, is_valid, extracted_signer_id = UnicodeMetadata.verify_and_extract_metadata(processed_text, test_public_key_provider)\n\n            # Check if metadata was extracted and verified correctly\n            assert is_valid is True, f\"Verification failed for {provider}, target={target.name}, first_only={encode_first_only}\"\n            assert extracted_signer_id == signer_id, f\"Signer ID mismatch for {provider}, target={target.name}, first_only={encode_first_only}\"\n            assert extracted_payload is not None\n            assert extracted_payload.get(\"format\") == metadata_format\n\n            # Check that the model_id in the payload matches what we embedded\n            assert (\n                extracted_payload.get(\"model_id\") == metadata[\"model_id\"]\n            ), f\"Model ID mismatch for {provider}, target={target.name}, first_only={encode_first_only}\""
            },
            "tests/integration/test_llm_outputs.py::TestStreamingIntegration::test_streaming_with_hmac[openai-chunks0]": {
                "testid": "tests/integration/test_llm_outputs.py::TestStreamingIntegration::test_streaming_with_hmac[openai-chunks0]",
                "result": "skipped",
                "test_implementation": "    def test_streaming_with_hmac(self, provider, chunks):\n        \"\"\"Test streaming with HMAC verification.\"\"\"\n        pass  # Test skipped"
            },
            "tests/integration/test_llm_outputs.py::TestStreamingIntegration::test_streaming_with_hmac[anthropic-chunks1]": {
                "testid": "tests/integration/test_llm_outputs.py::TestStreamingIntegration::test_streaming_with_hmac[anthropic-chunks1]",
                "result": "skipped",
                "test_implementation": "    def test_streaming_with_hmac(self, provider, chunks):\n        \"\"\"Test streaming with HMAC verification.\"\"\"\n        pass  # Test skipped"
            },
            "tests/integration/test_llm_outputs.py::TestStreamingIntegration::test_streaming_with_hmac[gemini-chunks2]": {
                "testid": "tests/integration/test_llm_outputs.py::TestStreamingIntegration::test_streaming_with_hmac[gemini-chunks2]",
                "result": "skipped",
                "test_implementation": "    def test_streaming_with_hmac(self, provider, chunks):\n        \"\"\"Test streaming with HMAC verification.\"\"\"\n        pass  # Test skipped"
            },
            "tests/interop/test_c2pa.py::TestC2PAInterop::test_c2pa_to_encypher_conversion": {
                "testid": "tests/interop/test_c2pa.py::TestC2PAInterop::test_c2pa_to_encypher_conversion",
                "result": "passed",
                "test_implementation": "    def test_c2pa_to_encypher_conversion(self):\n        \"\"\"Test conversion from C2PA-like dictionary to EncypherAI manifest.\"\"\"\n        # Convert C2PA-like dict to EncypherAI manifest\n        manifest_result = c2pa_like_dict_to_encypher_manifest(self.c2pa_dict)\n\n        # Verify core fields\n        self.assertEqual(manifest_result[\"claim_generator\"], self.c2pa_dict[\"claim_generator\"])\n        self.assertEqual(manifest_result[\"timestamp\"], self.c2pa_dict[\"timestamp\"])\n\n        # Verify assertions (converted from C2PA assertions)\n        self.assertIn(\"assertions\", manifest_result)\n        assertions = manifest_result[\"assertions\"]\n        self.assertEqual(len(assertions), 2)  # 2 regular assertions, 1 ai_assertion assertion\n\n        # Check that C2PA assertions were properly converted to assertions\n        assertion_types = set()\n        for assertion in assertions:\n            self.assertIn(\"label\", assertion)\n            self.assertIn(\"when\", assertion)\n            assertion_types.add(assertion[\"label\"])\n\n            # If this is the edited assertion, check its tool field\n            if assertion[\"label\"] == \"c2pa.edited\":\n                self.assertEqual(assertion[\"tool\"], \"ImageEditor/1.0\")\n\n        # Verify all expected assertions are present\n        self.assertIn(\"c2pa.created\", assertion_types)\n        self.assertIn(\"c2pa.edited\", assertion_types)\n\n        # Verify AI assertion\n        self.assertIn(\"ai_assertion\", manifest_result)\n        self.assertEqual(manifest_result[\"ai_assertion\"][\"model_id\"], \"claude-3-opus\")\n\n        # Verify custom claims\n        self.assertIn(\"custom_claims\", manifest_result)\n        self.assertEqual(manifest_result[\"custom_claims\"], self.c2pa_dict[\"custom_claims\"])"
            },
            "tests/interop/test_c2pa.py::TestC2PAInterop::test_encypher_to_c2pa_conversion": {
                "testid": "tests/interop/test_c2pa.py::TestC2PAInterop::test_encypher_to_c2pa_conversion",
                "result": "passed",
                "test_implementation": "    def test_encypher_to_c2pa_conversion(self):\n        \"\"\"Test conversion from EncypherAI manifest to C2PA-like dictionary.\"\"\"\n        # Convert EncypherAI manifest to C2PA-like dict\n        c2pa_result = encypher_manifest_to_c2pa_like_dict(self.encypher_manifest)\n\n        # Verify core fields\n        self.assertEqual(c2pa_result[\"claim_generator\"], self.encypher_manifest[\"claim_generator\"])\n        self.assertEqual(c2pa_result[\"timestamp\"], self.encypher_manifest[\"timestamp\"])\n        self.assertEqual(c2pa_result[\"format\"], \"application/x-encypher-ai-manifest\")\n\n        # Verify assertions\n        self.assertIn(\"assertions\", c2pa_result)\n        assertions = c2pa_result[\"assertions\"]\n        self.assertEqual(len(assertions), 3)  # 2 assertions + 1 ai_assertion\n\n        # Check that assertions were properly converted to C2PA assertions\n        assertion_labels = set()\n        for assertion in assertions:\n            self.assertIn(\"label\", assertion)\n            self.assertIn(\"data\", assertion)\n            assertion_labels.add(assertion[\"label\"])\n\n            # If this is the created assertion, check its timestamp\n            if assertion[\"label\"] == \"c2pa.created\":\n                self.assertEqual(assertion[\"data\"][\"timestamp\"], self.timestamp)\n\n            # If this is the edited assertion, check its tool field\n            if assertion[\"label\"] == \"c2pa.edited\":\n                self.assertEqual(assertion[\"data\"][\"tool\"], \"TextEditor/1.0\")\n\n        # Verify all expected assertions are present\n        self.assertIn(\"c2pa.created\", assertion_labels)\n        self.assertIn(\"c2pa.edited\", assertion_labels)\n        self.assertIn(\"ai.model.info\", assertion_labels)\n\n        # Verify custom claims\n        self.assertIn(\"custom_claims\", c2pa_result)\n        self.assertEqual(c2pa_result[\"custom_claims\"], self.encypher_manifest[\"custom_claims\"])"
            },
            "tests/interop/test_c2pa.py::TestC2PAInterop::test_error_handling": {
                "testid": "tests/interop/test_c2pa.py::TestC2PAInterop::test_error_handling",
                "result": "passed",
                "test_implementation": "    def test_error_handling(self):\n        \"\"\"Test error handling for invalid inputs.\"\"\"\n        # Test with non-dict input for encypher_manifest_to_c2pa_like_dict\n        with self.assertRaises(TypeError):\n            encypher_manifest_to_c2pa_like_dict(\"not a dict\")\n\n        # Test with non-dict input for c2pa_like_dict_to_encypher_manifest\n        with self.assertRaises(TypeError):\n            c2pa_like_dict_to_encypher_manifest(\"not a dict\")\n\n        # Test with empty dict\n        empty_result = c2pa_like_dict_to_encypher_manifest({})\n        self.assertEqual(empty_result[\"claim_generator\"], \"\")\n        self.assertEqual(empty_result[\"assertions\"], [])\n        self.assertEqual(empty_result[\"ai_assertion\"], {})\n        self.assertEqual(empty_result[\"custom_claims\"], {})\n        self.assertEqual(empty_result[\"timestamp\"], \"\")"
            },
            "tests/interop/test_c2pa.py::TestC2PAInterop::test_roundtrip_conversion": {
                "testid": "tests/interop/test_c2pa.py::TestC2PAInterop::test_roundtrip_conversion",
                "result": "passed",
                "test_implementation": "    def test_roundtrip_conversion(self):\n        \"\"\"Test roundtrip conversion (EncypherAI -> C2PA -> EncypherAI).\"\"\"\n        # Convert EncypherAI manifest to C2PA-like dict\n        c2pa_result = encypher_manifest_to_c2pa_like_dict(self.encypher_manifest)\n\n        # Convert back to EncypherAI manifest\n        manifest_result = c2pa_like_dict_to_encypher_manifest(c2pa_result)\n\n        # Verify core fields remain the same\n        self.assertEqual(\n            manifest_result[\"claim_generator\"],\n            self.encypher_manifest[\"claim_generator\"],\n        )\n        self.assertEqual(manifest_result[\"timestamp\"], self.encypher_manifest[\"timestamp\"])\n\n        # Verify assertions (may have different order, so check by assertion type)\n        original_assertions = {a[\"label\"]: a for a in self.encypher_manifest[\"assertions\"]}\n        result_assertions = {a[\"label\"]: a for a in manifest_result[\"assertions\"]}\n\n        for assertion_type, original_assertion in original_assertions.items():\n            self.assertIn(assertion_type, result_assertions)\n            result_assertion = result_assertions[assertion_type]\n            self.assertEqual(result_assertion[\"when\"], original_assertion[\"when\"])\n\n            # Check additional fields if present\n            if \"tool\" in original_assertion:\n                self.assertEqual(result_assertion[\"tool\"], original_assertion[\"tool\"])\n\n        # Verify AI assertion\n        self.assertEqual(\n            manifest_result[\"ai_assertion\"][\"model_id\"],\n            self.encypher_manifest[\"ai_assertion\"][\"model_id\"],\n        )\n\n        # Verify custom claims\n        self.assertEqual(manifest_result[\"custom_claims\"], self.encypher_manifest[\"custom_claims\"])"
            },
            "tests/interop/test_c2pa.py::TestC2PAInterop::test_schema_generation": {
                "testid": "tests/interop/test_c2pa.py::TestC2PAInterop::test_schema_generation",
                "result": "passed",
                "test_implementation": "    def test_schema_generation(self):\n        \"\"\"Test that the schema generation function returns a valid schema.\"\"\"\n        schema = get_c2pa_manifest_schema()\n\n        # Verify schema structure\n        self.assertIsInstance(schema, dict)\n        self.assertIn(\"$schema\", schema)\n        self.assertIn(\"properties\", schema)\n\n        # Verify required properties\n        self.assertIn(\"required\", schema)\n        self.assertIn(\"claim_generator\", schema[\"required\"])\n\n        # Verify key property definitions\n        properties = schema[\"properties\"]\n        self.assertIn(\"claim_generator\", properties)\n        self.assertIn(\"assertions\", properties)"
            },
            "tests/test_settings.py::TestSettings::test_default_settings": {
                "testid": "tests/test_settings.py::TestSettings::test_default_settings",
                "result": "passed",
                "test_implementation": "    def test_default_settings(self):\n        \"\"\"Test default settings.\"\"\"\n        settings = Settings()\n\n        # Check default values\n        assert settings.get(\"metadata_target\") == \"whitespace\"\n        assert settings.get(\"encode_first_chunk_only\") is True\n        assert settings.get(\"timestamp_format\") == \"%Y-%m-%dT%H:%M%z\"\n        assert settings.get(\"logging_level\") == \"INFO\"\n        assert settings.get(\"report_usage_metrics\") is False"
            },
            "tests/test_settings.py::TestSettings::test_load_from_file": {
                "testid": "tests/test_settings.py::TestSettings::test_load_from_file",
                "result": "passed",
                "test_implementation": "    def test_load_from_file(self):\n        \"\"\"Test loading settings from a file.\"\"\"\n        # Create a temporary config file\n        with tempfile.NamedTemporaryFile(mode=\"w+\", suffix=\".json\", delete=False) as temp_file:\n            config = {\n                \"metadata_target\": \"punctuation\",\n                \"encode_first_chunk_only\": False,\n                \"logging_level\": \"DEBUG\",\n            }\n            json.dump(config, temp_file)\n            temp_file_path = temp_file.name\n\n        try:\n            # Load settings from the file\n            settings = Settings(config_file=temp_file_path)\n\n            # Check values from the file\n            assert settings.get(\"metadata_target\") == \"punctuation\"\n            assert settings.get(\"encode_first_chunk_only\") is False\n            assert settings.get(\"logging_level\") == \"DEBUG\"\n\n            # Check default values for fields not in the file\n            assert settings.get(\"timestamp_format\") == \"%Y-%m-%dT%H:%M%z\"\n            assert settings.get(\"report_usage_metrics\") is False\n        finally:\n            # Clean up the temporary file\n            os.unlink(temp_file_path)"
            },
            "tests/test_settings.py::TestSettings::test_load_from_env": {
                "testid": "tests/test_settings.py::TestSettings::test_load_from_env",
                "result": "passed",
                "test_implementation": "    def test_load_from_env(self, monkeypatch):\n        \"\"\"Test loading settings from environment variables.\"\"\"\n        # Set environment variables\n        monkeypatch.setenv(\"ENCYPHER_METADATA_TARGET\", \"first_letter\")\n        monkeypatch.setenv(\"ENCYPHER_ENCODE_FIRST_CHUNK_ONLY\", \"false\")\n        monkeypatch.setenv(\"ENCYPHER_LOGGING_LEVEL\", \"WARNING\")\n\n        # Load settings\n        settings = Settings()\n\n        # Check values from environment variables\n        assert settings.get(\"metadata_target\") == \"first_letter\"\n        assert settings.get(\"encode_first_chunk_only\") is False\n        assert settings.get(\"logging_level\") == \"WARNING\""
            },
            "tests/test_settings.py::TestSettings::test_env_overrides_file": {
                "testid": "tests/test_settings.py::TestSettings::test_env_overrides_file",
                "result": "passed",
                "test_implementation": "    def test_env_overrides_file(self, monkeypatch):\n        \"\"\"Test that environment variables override file settings.\"\"\"\n        # Create a temporary config file\n        with tempfile.NamedTemporaryFile(mode=\"w+\", suffix=\".json\", delete=False) as temp_file:\n            config = {\n                \"metadata_target\": \"punctuation\",\n                \"encode_first_chunk_only\": False,\n                \"logging_level\": \"DEBUG\",\n            }\n            json.dump(config, temp_file)\n            temp_file_path = temp_file.name\n\n        try:\n            # Set environment variables\n            monkeypatch.setenv(\"ENCYPHER_METADATA_TARGET\", \"first_letter\")\n\n            # Load settings\n            settings = Settings(config_file=temp_file_path)\n\n            # Check that environment variables override file settings\n            assert settings.get(\"metadata_target\") == \"first_letter\"  # From env\n            assert settings.get(\"encode_first_chunk_only\") is False  # From file\n            assert settings.get(\"logging_level\") == \"DEBUG\"  # From file\n        finally:\n            # Clean up the temporary file\n            os.unlink(temp_file_path)"
            },
            "tests/test_settings.py::TestSettings::test_get_metadata_target": {
                "testid": "tests/test_settings.py::TestSettings::test_get_metadata_target",
                "result": "passed",
                "test_implementation": "    def test_get_metadata_target(self):\n        \"\"\"Test getting metadata target as enum.\"\"\"\n        # Test with valid target\n        settings = Settings()\n        settings.config[\"metadata_target\"] = \"punctuation\"\n\n        target = settings.get_metadata_target()\n        assert target == MetadataTarget.PUNCTUATION\n\n        # Test with invalid target\n        settings.config[\"metadata_target\"] = \"invalid_target\"\n\n        target = settings.get_metadata_target()\n        assert target == MetadataTarget.WHITESPACE  # Default"
            },
            "tests/test_settings.py::TestSettings::test_to_dict": {
                "testid": "tests/test_settings.py::TestSettings::test_to_dict",
                "result": "passed",
                "test_implementation": "    def test_to_dict(self):\n        \"\"\"Test converting settings to dictionary.\"\"\"\n        settings = Settings()\n\n        # Modify some settings\n        settings.config[\"metadata_target\"] = \"punctuation\"\n\n        # Convert to dictionary\n        config_dict = settings.to_dict()\n\n        # Check dictionary values\n        assert config_dict[\"metadata_target\"] == \"punctuation\"\n        assert config_dict[\"encode_first_chunk_only\"] is True\n        assert config_dict[\"timestamp_format\"] == \"%Y-%m-%dT%H:%M%z\"\n        assert config_dict[\"logging_level\"] == \"INFO\"\n        assert config_dict[\"report_usage_metrics\"] is False"
            },
            "tests/test_streaming_handler.py::TestStreamingHandler::test_process_text_chunk": {
                "testid": "tests/test_streaming_handler.py::TestStreamingHandler::test_process_text_chunk",
                "result": "passed",
                "test_implementation": "    def test_process_text_chunk(self, test_key_pair, test_public_key_provider):\n        \"\"\"Test processing a text chunk.\"\"\"\n        private_key, _ = test_key_pair\n        metadata = {\n            \"model_id\": \"test-model\",\n            \"timestamp\": datetime.now(timezone.utc).isoformat(),\n            \"custom_metadata\": {\"test_key\": \"test_value\"},\n        }\n\n        handler = StreamingHandler(\n            metadata=metadata,\n            target=MetadataTarget.WHITESPACE,\n            private_key=private_key,\n            signer_id=\"test_signer\",\n            metadata_format=\"basic\",\n        )\n\n        # Process a chunk\n        chunk = \"This is a test chunk with spaces.\"\n        processed_chunk = handler.process_chunk(chunk)\n\n        # Ensure the chunk is modified (metadata added)\n        assert processed_chunk != chunk\n\n        # Extract and verify metadata from processed chunk\n        extracted_payload, is_valid, extracted_signer_id = UnicodeMetadata.verify_and_extract_metadata(processed_chunk, test_public_key_provider)\n\n        # Verify signature and extracted data\n        assert is_valid is True\n        assert extracted_signer_id == \"test_signer\"\n        assert extracted_payload is not None\n        assert extracted_payload.get(\"model_id\") == metadata[\"model_id\"]\n        assert extracted_payload.get(\"format\") == \"basic\""
            },
            "tests/test_streaming_handler.py::TestStreamingHandler::test_encode_first_chunk_only": {
                "testid": "tests/test_streaming_handler.py::TestStreamingHandler::test_encode_first_chunk_only",
                "result": "passed",
                "test_implementation": "    def test_encode_first_chunk_only(self, test_key_pair, test_public_key_provider):\n        \"\"\"Test encoding only the first chunk.\"\"\"\n        private_key, _ = test_key_pair\n        metadata = {\n            \"model_id\": \"test-model\",\n            \"timestamp\": datetime.now(timezone.utc).isoformat(),\n            \"custom_metadata\": {\"test_key\": \"test_value\"},\n        }\n\n        handler = StreamingHandler(\n            metadata=metadata,\n            target=MetadataTarget.WHITESPACE,\n            encode_first_chunk_only=True,\n            private_key=private_key,\n            signer_id=\"test_signer\",\n            metadata_format=\"basic\",\n        )\n\n        # Process first chunk\n        chunk1 = \"This is the first chunk with enough spaces for embedding.\"\n        processed_chunk1 = handler.process_chunk(chunk1)\n\n        # Ensure the first chunk is modified (metadata added)\n        assert processed_chunk1 != chunk1\n        assert handler.has_encoded is True\n\n        # Process second chunk\n        chunk2 = \"This is the second chunk.\"\n        processed_chunk2 = handler.process_chunk(chunk2)\n\n        # Second chunk should not be modified\n        assert processed_chunk2 == chunk2\n\n        # Verify metadata in the first processed chunk\n        extracted_payload, is_valid, extracted_signer_id = UnicodeMetadata.verify_and_extract_metadata(processed_chunk1, test_public_key_provider)\n        assert is_valid is True\n        assert extracted_signer_id == \"test_signer\"\n        assert extracted_payload.get(\"model_id\") == metadata[\"model_id\"]"
            },
            "tests/test_streaming_handler.py::TestStreamingHandler::test_encode_all_chunks": {
                "testid": "tests/test_streaming_handler.py::TestStreamingHandler::test_encode_all_chunks",
                "result": "passed",
                "test_implementation": "    def test_encode_all_chunks(self, test_key_pair, test_public_key_provider):\n        \"\"\"Test encoding all chunks with accumulation.\"\"\"\n        private_key, _ = test_key_pair\n        metadata = {\n            \"model_id\": \"test-model\",\n            \"timestamp\": datetime.now(timezone.utc).isoformat(),\n            \"custom_metadata\": {\"test_key\": \"test_value\"},\n        }\n\n        # Note: encode_first_chunk_only=False is not fully supported in the current implementation\n        # but we can test the warning/fallback behavior\n        handler = StreamingHandler(\n            metadata=metadata,\n            target=MetadataTarget.WHITESPACE,\n            encode_first_chunk_only=False,  # This should trigger a warning and fallback\n            private_key=private_key,\n            signer_id=\"test_signer\",\n            metadata_format=\"basic\",\n        )\n\n        # Process multiple chunks\n        chunks = [\n            \"This is the first chunk.\",\n            \"This is the second chunk.\",\n            \"This is the third chunk with spaces.\",\n        ]\n\n        processed_chunks = []\n        for chunk in chunks:\n            processed_chunk = handler.process_chunk(chunk)\n            processed_chunks.append(processed_chunk)\n\n        # Since encode_first_chunk_only=False is not fully supported,\n        # we expect the chunks to be returned unmodified\n        assert processed_chunks[0] == chunks[0]\n        assert processed_chunks[1] == chunks[1]\n        assert processed_chunks[2] == chunks[2]"
            },
            "tests/test_streaming_handler.py::TestStreamingHandler::test_process_dict_chunk_openai": {
                "testid": "tests/test_streaming_handler.py::TestStreamingHandler::test_process_dict_chunk_openai",
                "result": "passed",
                "test_implementation": "    def test_process_dict_chunk_openai(self, test_key_pair, test_public_key_provider):\n        \"\"\"Test processing an OpenAI-style dictionary chunk.\"\"\"\n        private_key, _ = test_key_pair\n        metadata = {\n            \"model_id\": \"test-model\",\n            \"timestamp\": datetime.now(timezone.utc).isoformat(),\n            \"custom_metadata\": {\"test_key\": \"test_value\"},\n        }\n\n        handler = StreamingHandler(\n            metadata=metadata,\n            target=MetadataTarget.WHITESPACE,\n            private_key=private_key,\n            signer_id=\"test_signer\",\n            metadata_format=\"basic\",\n        )\n\n        # Create an OpenAI-style chunk with enough spaces for embedding\n        original_content = \"This is a test chunk with plenty of spaces for embedding metadata.\"\n        chunk = {\n            \"id\": \"chatcmpl-123\",\n            \"object\": \"chat.completion.chunk\",\n            \"created\": 1677858242,\n            \"model\": \"gpt-3.5-turbo-0613\",\n            \"choices\": [\n                {\n                    \"index\": 0,\n                    \"delta\": {\"content\": original_content},\n                    \"finish_reason\": None,\n                }\n            ],\n        }\n\n        # Process the chunk\n        processed_chunk = handler.process_chunk(chunk)\n\n        # Extract the processed content\n        processed_content = processed_chunk[\"choices\"][0][\"delta\"][\"content\"]\n\n        # Ensure the content was modified (metadata added)\n        assert processed_content != original_content\n        assert len(processed_content) > len(original_content)\n\n        # Verify other parts of the chunk remain unchanged\n        assert processed_chunk[\"id\"] == chunk[\"id\"]\n        assert processed_chunk[\"created\"] == chunk[\"created\"]\n        assert processed_chunk[\"model\"] == chunk[\"model\"]\n\n        # Verify metadata in the processed content\n        extracted_payload, is_valid, extracted_signer_id = UnicodeMetadata.verify_and_extract_metadata(processed_content, test_public_key_provider)\n        assert is_valid is True\n        assert extracted_signer_id == \"test_signer\"\n        assert extracted_payload.get(\"model_id\") == metadata[\"model_id\"]"
            },
            "tests/test_streaming_handler.py::TestStreamingHandler::test_process_dict_chunk_anthropic": {
                "testid": "tests/test_streaming_handler.py::TestStreamingHandler::test_process_dict_chunk_anthropic",
                "result": "passed",
                "test_implementation": "    def test_process_dict_chunk_anthropic(self, test_key_pair, test_public_key_provider):\n        \"\"\"Test processing an Anthropic-style dictionary chunk.\"\"\"\n        # Note: The current implementation doesn't have special handling for Anthropic format\n        # This test is kept for future implementation\n        private_key, _ = test_key_pair\n        metadata = {\n            \"model_id\": \"test-model\",\n            \"timestamp\": datetime.now(timezone.utc).isoformat(),\n            \"custom_metadata\": {\"test_key\": \"test_value\"},\n        }\n\n        handler = StreamingHandler(\n            metadata=metadata,\n            target=MetadataTarget.WHITESPACE,\n            private_key=private_key,\n            signer_id=\"test_signer\",\n            metadata_format=\"basic\",\n        )\n\n        # Create an Anthropic-style chunk\n        original_content = \"This is a test chunk with plenty of spaces for embedding metadata.\"\n        chunk = {\n            \"completion\": original_content,\n            \"stop_reason\": None,\n            \"model\": \"claude-2\",\n        }\n\n        # Process the chunk - this will likely return the original chunk since\n        # Anthropic format isn't specifically handled yet\n        processed_chunk = handler.process_chunk(chunk)\n\n        # Since we don't have specific Anthropic handling yet, we expect the chunk to be unchanged\n        assert processed_chunk == chunk"
            },
            "tests/test_streaming_handler.py::TestStreamingHandler::test_reset": {
                "testid": "tests/test_streaming_handler.py::TestStreamingHandler::test_reset",
                "result": "passed",
                "test_implementation": "    def test_reset(self, test_key_pair, test_public_key_provider):\n        \"\"\"Test resetting the handler.\"\"\"\n        private_key, _ = test_key_pair\n        metadata = {\n            \"model_id\": \"test-model\",\n            \"timestamp\": datetime.now(timezone.utc).isoformat(),\n            \"custom_metadata\": {\"test_key\": \"test_value\"},\n        }\n\n        handler = StreamingHandler(\n            metadata=metadata,\n            target=MetadataTarget.WHITESPACE,\n            private_key=private_key,\n            signer_id=\"test_signer\",\n            metadata_format=\"basic\",\n        )\n\n        # Process a chunk with enough spaces\n        chunk = \"This is a test chunk with plenty of spaces for embedding metadata.\"\n        handler.process_chunk(chunk)\n\n        # Handler should have encoded metadata\n        assert handler.has_encoded is True\n\n        # Reset the handler\n        handler.reset()\n\n        # Handler should be reset\n        assert handler.has_encoded is False\n        assert handler.accumulated_text == \"\"\n        assert handler.is_accumulating is False\n\n        # Process another chunk\n        chunk2 = \"This is another test chunk with spaces for embedding.\"\n        processed_chunk2 = handler.process_chunk(chunk2)\n\n        # Handler should encode metadata again\n        assert handler.has_encoded is True\n        assert processed_chunk2 != chunk2"
            },
            "tests/test_streaming_handler.py::TestStreamingHandler::test_accumulation_for_small_chunks": {
                "testid": "tests/test_streaming_handler.py::TestStreamingHandler::test_accumulation_for_small_chunks",
                "result": "passed",
                "test_implementation": "    def test_accumulation_for_small_chunks(self, test_key_pair, test_public_key_provider):\n        \"\"\"Test accumulation of small chunks until enough targets are found.\"\"\"\n        private_key, _ = test_key_pair\n        metadata = {\n            \"model_id\": \"test-model\",\n            \"timestamp\": datetime.now(timezone.utc).isoformat(),\n            \"custom_metadata\": {\"test_key\": \"test_value\"},\n        }\n\n        handler = StreamingHandler(\n            metadata=metadata,\n            target=MetadataTarget.WHITESPACE,\n            private_key=private_key,\n            signer_id=\"test_signer\",\n            metadata_format=\"basic\",\n        )\n\n        # Process small chunks without enough targets\n        chunk1 = \"Small\"\n        chunk2 = \"chunks\"\n        chunk3 = \"without\"\n        chunk4 = \"enough spaces for embedding.\"\n\n        # Process the first three chunks - they should be accumulated but not modified\n        processed_chunk1 = handler.process_chunk(chunk1)\n        assert processed_chunk1 == chunk1\n        assert handler.is_accumulating is True\n        assert handler.has_encoded is False\n\n        processed_chunk2 = handler.process_chunk(chunk2)\n        assert processed_chunk2 == chunk2\n        assert handler.is_accumulating is True\n        assert handler.has_encoded is False\n\n        processed_chunk3 = handler.process_chunk(chunk3)\n        assert processed_chunk3 == chunk3\n        assert handler.is_accumulating is True\n        assert handler.has_encoded is False\n\n        # Process the fourth chunk which has spaces - this should trigger embedding\n        processed_chunk4 = handler.process_chunk(chunk4)\n        assert processed_chunk4 != chunk1 + chunk2 + chunk3 + chunk4\n        assert handler.is_accumulating is False\n        assert handler.has_encoded is True\n\n        # Verify metadata in the processed content\n        extracted_payload, is_valid, extracted_signer_id = UnicodeMetadata.verify_and_extract_metadata(processed_chunk4, test_public_key_provider)\n        assert is_valid is True\n        assert extracted_signer_id == \"test_signer\"\n        assert extracted_payload.get(\"model_id\") == metadata[\"model_id\"]"
            },
            "tests/test_streaming_handler.py::TestStreamingHandler::test_finalize_already_encoded": {
                "testid": "tests/test_streaming_handler.py::TestStreamingHandler::test_finalize_already_encoded",
                "result": "passed",
                "test_implementation": "    def test_finalize_already_encoded(self, test_key_pair, test_public_key_provider):\n        \"\"\"Test finalizing the stream when metadata has already been encoded.\"\"\"\n        private_key, _ = test_key_pair\n        metadata = {\n            \"model_id\": \"test-model\",\n            \"timestamp\": datetime.now(timezone.utc).isoformat(),\n            \"custom_metadata\": {\"test_key\": \"test_value\"},\n        }\n\n        handler = StreamingHandler(\n            metadata=metadata,\n            target=MetadataTarget.WHITESPACE,\n            private_key=private_key,\n            signer_id=\"test_signer\",\n            metadata_format=\"basic\",\n        )\n\n        # Process a chunk with enough targets to trigger embedding\n        chunk = \"This chunk has enough spaces for embedding metadata.\"\n        processed_chunk = handler.process_chunk(chunk)\n\n        # Verify that metadata was embedded\n        assert processed_chunk != chunk\n        assert handler.has_encoded is True\n\n        # Finalize should return None since metadata was already embedded\n        final_text = handler.finalize()\n        assert final_text is None"
            },
            "tests/test_streaming_handler.py::TestStreamingHandler::test_finalize_with_no_targets": {
                "testid": "tests/test_streaming_handler.py::TestStreamingHandler::test_finalize_with_no_targets",
                "result": "passed",
                "test_implementation": "    def test_finalize_with_no_targets(self, test_key_pair, test_public_key_provider):\n        \"\"\"Test finalizing the stream with accumulated text that has no targets.\"\"\"\n        private_key, _ = test_key_pair\n        metadata = {\n            \"model_id\": \"test-model\",\n            \"timestamp\": datetime.now(timezone.utc).isoformat(),\n            \"custom_metadata\": {\"test_key\": \"test_value\"},\n        }\n\n        handler = StreamingHandler(\n            metadata=metadata,\n            target=MetadataTarget.WHITESPACE,  # Looking for whitespace\n            private_key=private_key,\n            signer_id=\"test_signer\",\n            metadata_format=\"basic\",\n        )\n\n        # Process chunks with no whitespace\n        chunk1 = \"Small\"\n        chunk2 = \"chunks\"\n        chunk3 = \"without-any-whitespace\"\n\n        # Process chunks - they should be accumulated but not modified\n        handler.process_chunk(chunk1)\n        handler.process_chunk(chunk2)\n        handler.process_chunk(chunk3)\n\n        # Verify that no metadata was embedded yet\n        assert handler.has_encoded is False\n        assert handler.is_accumulating is True\n\n        # Finalize should return the accumulated text unmodified\n        # since there are no targets for embedding\n        final_text = handler.finalize()\n\n        # Should return the original text since embedding will fail\n        assert final_text is not None\n        assert final_text == chunk1 + chunk2 + chunk3"
            },
            "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_encode_decode": {
                "testid": "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_encode_decode",
                "result": "passed",
                "test_implementation": "    def test_encode_decode(self):\n        \"\"\"Test encoding and decoding text using variation selectors.\"\"\"\n        original_text = \"Test text\"\n        emoji = \"🔍\"\n\n        encoded = UnicodeMetadata.encode(emoji, original_text)\n        decoded = UnicodeMetadata.decode(encoded)\n\n        assert decoded == original_text\n        assert encoded.startswith(emoji)\n        assert len(encoded) > len(emoji)"
            },
            "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_extract_metadata": {
                "testid": "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_extract_metadata",
                "result": "skipped",
                "test_implementation": "    def test_embed_extract_metadata(self):\n        \"\"\"Test embedding and extracting metadata.\"\"\"\n        text = \"This is a test text with some spaces and punctuation.\"\n        model_id = \"test-model\"\n        # Use a specific datetime and convert to timestamp\n        test_dt = datetime.fromisoformat(\"2025-03-19T10:35:00+00:00\")\n        timestamp = int(test_dt.timestamp())\n\n        # Test with different targets\n        for target in [t for t in MetadataTarget if t != MetadataTarget.NONE]:\n            encoded_text = UnicodeMetadata.embed_metadata(text=text, model_id=model_id, timestamp=timestamp, target=target)\n\n            # Ensure the text is modified (metadata added)\n            assert encoded_text != text\n\n            # Extract metadata\n            metadata = UnicodeMetadata.extract_metadata(encoded_text)\n\n            # Verify extracted metadata\n            assert metadata.get(\"model_id\") == model_id\n            # Verify the timestamp is a datetime object with the correct value\n            assert isinstance(metadata.get(\"timestamp\"), datetime)\n            assert metadata.get(\"timestamp\").replace(microsecond=0) == test_dt.replace(microsecond=0)"
            },
            "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_custom_metadata": {
                "testid": "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_custom_metadata",
                "result": "skipped",
                "test_implementation": "    def test_custom_metadata(self):\n        \"\"\"Test embedding and extracting custom metadata.\"\"\"\n        text = \"This is a test text.\"\n        custom_metadata = {\n            \"user_id\": \"test-user\",\n            \"session_id\": \"test-session\",\n            \"custom_field\": \"custom value\",\n        }\n\n        encoded_text = UnicodeMetadata.embed_metadata(text=text, custom_metadata=custom_metadata)\n\n        # Extract metadata\n        metadata = UnicodeMetadata.extract_metadata(encoded_text)\n\n        # Verify custom metadata\n        for key, value in custom_metadata.items():\n            assert metadata.get(key) == value"
            },
            "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_no_metadata_target": {
                "testid": "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_no_metadata_target",
                "result": "skipped",
                "test_implementation": "    def test_no_metadata_target(self):\n        \"\"\"Test with NONE metadata target.\"\"\"\n        text = \"This is a test text.\"\n        model_id = \"test-model\"\n\n        encoded_text = UnicodeMetadata.embed_metadata(text=text, model_id=model_id, target=MetadataTarget.NONE)\n\n        # With NONE target, the text should remain unchanged\n        assert encoded_text == text\n\n        # Extract metadata should return empty values\n        metadata = UnicodeMetadata.extract_metadata(encoded_text)\n        assert metadata.get(\"model_id\") == \"\"\n        assert metadata.get(\"timestamp\") is None"
            },
            "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_empty_text": {
                "testid": "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_empty_text",
                "result": "skipped",
                "test_implementation": "    def test_empty_text(self):\n        \"\"\"Test with empty text.\"\"\"\n        text = \"\"\n        metadata = {\"model_id\": \"test-model\", \"timestamp\": int(time.time())}\n\n        # Encode metadata\n        encoded_text = UnicodeMetadata.embed_metadata(text, metadata)\n\n        # Ensure the text is modified (metadata added)\n        assert encoded_text != text\n        assert len(encoded_text) > 0\n\n        # Decode metadata\n        extracted_metadata = UnicodeMetadata.extract_metadata(encoded_text)\n\n        # Verify extracted metadata\n        assert extracted_metadata is not None, \"Metadata should be extracted even from empty text\"\n        assert extracted_metadata.get(\"model_id\") == metadata[\"model_id\"]\n        assert int(extracted_metadata.get(\"timestamp\")) == metadata[\"timestamp\"]"
            },
            "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_datetime_timestamp": {
                "testid": "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_datetime_timestamp",
                "result": "skipped",
                "test_implementation": "    def test_datetime_timestamp(self):\n        \"\"\"Test with datetime object as timestamp.\"\"\"\n        text = \"This is a test text.\"\n        model_id = \"test-model\"\n        timestamp = datetime.now(timezone.utc)\n\n        encoded_text = UnicodeMetadata.embed_metadata(text=text, model_id=model_id, timestamp=timestamp)\n\n        # Extract metadata\n        metadata = UnicodeMetadata.extract_metadata(encoded_text)\n\n        # Verify timestamp (as datetime object in metadata)\n        assert isinstance(metadata.get(\"timestamp\"), datetime)\n        # Compare the timestamps ignoring microseconds\n        extracted_ts = metadata.get(\"timestamp\").replace(microsecond=0)\n        original_ts = timestamp.replace(microsecond=0)\n        assert extracted_ts == original_ts"
            },
            "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_variation_selector_conversion": {
                "testid": "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_variation_selector_conversion",
                "result": "passed",
                "test_implementation": "    def test_variation_selector_conversion(self):\n        \"\"\"Test conversion between bytes and variation selectors.\"\"\"\n        # Test valid byte values\n        for byte in [0, 15, 16, 255]:\n            vs = UnicodeMetadata.to_variation_selector(byte)\n            assert vs is not None\n\n            # Convert back\n            byte_back = UnicodeMetadata.from_variation_selector(ord(vs))\n            assert byte_back == byte\n\n        # Test invalid byte value\n        assert UnicodeMetadata.to_variation_selector(256) is None\n\n        # Test invalid code point\n        assert UnicodeMetadata.from_variation_selector(0x0000) is None"
            },
            "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_hmac_verification": {
                "testid": "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_hmac_verification",
                "result": "skipped",
                "test_implementation": "    def test_hmac_verification(self):\n        \"\"\"Test HMAC verification.\"\"\""
            },
            "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_unicode_metadata_non_string_input": {
                "testid": "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_unicode_metadata_non_string_input",
                "result": "passed",
                "test_implementation": "    def test_unicode_metadata_non_string_input(self, key_pair_1):\n        \"\"\"Test that non-string input raises TypeError for embed_metadata.\"\"\"\n        private_key, _ = key_pair_1\n        with pytest.raises(TypeError, match=\"Input text must be a string\"):\n            # Now the type check happens before any len() call\n            UnicodeMetadata.embed_metadata(12345, private_key, \"test-signer\")  # type: ignore\n        with pytest.raises(TypeError, match=\"Input text must be a string\"):\n            UnicodeMetadata.embed_metadata(None, private_key, \"test-signer\")  # type: ignore\n        with pytest.raises(TypeError, match=\"Input text must be a string\"):\n            UnicodeMetadata.embed_metadata([\"list\"], private_key, \"test-signer\")  # type: ignore"
            }
        },
        "SRS_document": "**Software Requirements Specification**\n\n**EncypherAI Core Library**\n\n**Table of Contents**\n1.  Introduction\n    1.1 Purpose\n    1.2 Scope\n    1.3 Definitions, Acronyms, and Abbreviations\n    1.4 Overview\n2.  Overall Description\n    2.1 Product Perspective\n    2.2 Product Functions\n    2.3 User Characteristics\n    2.4 Constraints\n    2.5 Assumptions and Dependencies\n3.  Specific Requirements\n    3.1 Functional Requirements\n        3.1.1 Key Management and Cryptography\n        3.1.2 Metadata Structure and Content\n        3.1.3 Metadata Embedding\n        3.1.4 Metadata Extraction and Verification\n        3.1.5 Streaming Functionality\n        3.1.6 Configuration Management\n        3.1.7 C2PA Interoperability\n    3.2 Non-Functional Requirements\n    3.3 External Interface Requirements\n        3.3.1 Programmatic API\n        3.3.2 Data Formats\n\n---\n\n## 1. Introduction\n\n### 1.1 Purpose\nThis Software Requirements Specification (SRS) document defines the functional and non-functional requirements for the EncypherAI Core library. Its primary goal is to serve as the sole basis for software developers to design, implement, and test the library. Developers will be assessed on their ability to produce a functionally complete system that passes a comprehensive set of test cases (public and private), based on their interpretation of this SRS.\n\n### 1.2 Scope\nThis SRS covers the core functionalities of the EncypherAI library, which include:\n*   Embedding metadata invisibly into textual content using Unicode variation selectors.\n*   Cryptographically signing embedded metadata using digital signatures.\n*   Extracting and verifying the authenticity and integrity of embedded metadata.\n*   Supporting streaming text processing for metadata embedding.\n*   Managing cryptographic keys (generation, loading).\n*   Configuring system behavior through files and environment variables.\n*   Interoperating with C2PA-like data structures for manifest information.\n\nThe scope is limited to the library's programmatic interface and its behavior as described herein. Command-line examples, demonstration scripts, and UI/FastAPI examples provided in the original source are out of scope for the library itself but inform its usage.\n\n### 1.3 Definitions, Acronyms, and Abbreviations\n*   **SRS:** Software Requirements Specification\n*   **AI:** Artificial Intelligence\n*   **LLM:** Large Language Model\n*   **C2PA:** Coalition for Content Provenance and Authenticity\n*   **Unicode VS:** Unicode Variation Selectors (characters U+FE00-FE0F and U+E0100-U+E01EF)\n*   **PEM:** Privacy Enhanced Mail (a Base64 encoding format for keys and certificates)\n*   **HMAC:** Hash-based Message Authentication Code\n*   **FR:** Functional Requirement\n*   **NFR:** Non-Functional Requirement\n*   **API:** Application Programming Interface\n*   **SDK:** Software Development Kit\n*   **UTC:** Coordinated Universal Time\n*   **ISO 8601:** International standard for date and time representation.\n*   **Signer ID:** A string identifier associated with a specific cryptographic key pair, used to retrieve the public key for verification.\n*   **Public Key Provider:** A user-supplied function responsible for resolving a Signer ID to its corresponding public key.\n*   **Metadata Target:** Specific characters or positions within text where metadata bytes are embedded (e.g., whitespace, punctuation).\n\n### 1.4 Overview\nThis document is organized into three main sections:\n*   **Section 1 (Introduction):** Provides purpose, scope, definitions, and an overview of the SRS.\n*   **Section 2 (Overall Description):** Describes the product, its functions, user characteristics, constraints, and assumptions.\n*   **Section 3 (Specific Requirements):** Details the functional, non-functional, and external interface requirements for the EncypherAI Core library.\n\nThe remaining sections of this document detail these requirements.\n\n## 2. Overall Description\n\n### 2.1 Product Perspective\nThe EncypherAI Core library is a Python software component intended to be integrated into systems that generate or process text, particularly AI-generated text. It provides a robust mechanism for embedding provenance information, timestamps, and custom data directly and invisibly within the text itself. This allows for tracking the origin and integrity of textual content without altering its human readability or requiring separate metadata files. The library leverages Unicode variation selectors for data embedding and digital signatures for ensuring authenticity and tamper-evidence.\n\n### 2.2 Product Functions\nThe EncypherAI Core library provides the following key functions:\n1.  **Cryptographic Key Management:** Generation of Ed25519 key pairs and loading of keys from standard formats.\n2.  **Metadata Definition:** Support for structured metadata payloads, including a 'basic' format and a C2PA-inspired 'manifest' format.\n3.  **Metadata Embedding:** Securely embedding defined metadata and a digital signature into input text using Unicode variation selectors at specified target locations. The embedding process is designed to be invisible to human readers.\n4.  **Metadata Extraction and Verification:** Extracting embedded metadata from text and cryptographically verifying its integrity and authenticity using the corresponding public key.\n5.  **Streaming Support:** Processing text in chunks (as in LLM streaming outputs) and embedding metadata, typically into the first suitable chunk.\n6.  **Configuration:** Allowing customization of library behavior through a hierarchical configuration system (defaults, JSON file, environment variables).\n7.  **C2PA Interoperability:** Converting between the library's manifest format and C2PA-like dictionary structures.\n\n### 2.3 User Characteristics\nThe primary users of this library are software developers who are:\n*   Building applications that generate or handle AI-generated text.\n*   Requiring mechanisms for content provenance, authenticity, and integrity verification for text.\n*   Familiar with Python programming and concepts of digital signatures and key management.\n*   Integrating the library into larger systems, potentially involving LLMs or content management platforms.\n\n### 2.4 Constraints\n*   The system must be implemented in Python (compatible with Python 3.9+ as per README).\n*   The cryptographic operations for digital signatures shall use the Ed25519 algorithm.\n*   Metadata embedding must utilize Unicode Variation Selectors (U+FE00-FE0F and U+E0100-U+E01EF) as the means for data steganography.\n*   The system's behavior regarding metadata structure, embedding, and verification must be solely based on this SRS document.\n\n### 2.5 Assumptions and Dependencies\n*   Users are responsible for securely managing their private keys. The library provides generation and loading mechanisms but not secure storage solutions.\n*   Users will provide a public key resolution mechanism (a \"public key provider\" function) for metadata verification.\n*   The effectiveness of \"invisible\" embedding relies on rendering systems correctly handling Unicode Variation Selectors (which is standard behavior).\n\n## 3. Specific Requirements\n\n### 3.1 Functional Requirements\n\n#### 3.1.1 Key Management and Cryptography\n\n**FR-KEY-001:** The system shall generate Ed25519 cryptographic key pairs, consisting of a private key and a corresponding public key.\n\n**FR-KEY-002:** The system shall load an Ed25519 private key from a PEM-encoded representation.\n*   **Description:** This includes unencrypted PKCS8 PEM format.\n\n**FR-KEY-003:** The system shall load an Ed25519 private key from an encrypted PEM-encoded representation (PKCS8), given the correct password.\n\n**FR-KEY-004:** The system shall fail to load an encrypted Ed25519 private key if an incorrect password is provided.\n*   **Description:** This attempt shall result in a `ValueError`.\n\n**FR-KEY-005:** The system shall fail to load an encrypted Ed25519 private key if no password is provided for an encrypted key.\n*   **Description:** This attempt shall result in a `ValueError`.\n\n**FR-KEY-006:** The system shall load an Ed25519 private key from its 32-byte raw binary representation.\n\n**FR-KEY-007:** The system shall load an Ed25519 public key from a PEM-encoded representation (SubjectPublicKeyInfo format).\n\n**FR-KEY-008:** The system shall load an Ed25519 public key from its 32-byte raw binary representation.\n\n**FR-CRYPTO-001:** The system shall serialize dictionary payloads into a canonical JSON byte string.\n*   **Description:** Serialization must sort keys alphabetically and use compact separators (no extra whitespace) to ensure deterministic output for signing. The output must be UTF-8 encoded.\n\n**FR-CRYPTO-002:** The system shall sign serialized payload bytes using a provided Ed25519 private key, producing a digital signature.\n\n**FR-CRYPTO-003:** The system shall verify a digital signature against serialized payload bytes using a provided Ed25519 public key.\n*   **Description:** Verification shall return true if the signature is valid for the given payload and public key, and false otherwise.\n\n**FR-CRYPTO-004:** Signature verification shall fail (return false) if the provided public key does not correspond to the private key used for signing.\n\n**FR-CRYPTO-005:** Signature verification shall fail (return false) if the payload bytes being verified differ from the payload bytes that were originally signed.\n\n**FR-CRYPTO-006:** Signature verification shall fail (return false) if the signature data is corrupted or altered.\n\n#### 3.1.2 Metadata Structure and Content\n\n**FR-STRUCT-001:** The system shall support a 'basic' metadata payload format.\n*   **Description:** The 'basic' payload includes an optional model identifier (`model_id`: string), a timestamp (`timestamp`: ISO 8601 UTC string), and an optional dictionary for custom key-value pairs (`custom_metadata`).\n\n**FR-STRUCT-002:** The system shall support a 'manifest' metadata payload format.\n*   **Description:** The 'manifest' payload is C2PA-inspired and includes a claim generator identifier (`claim_generator`: string), a list of actions (`assertions`), optional AI-specific information (`ai_assertion`), an optional dictionary for custom claims (`custom_claims`), and an overall timestamp (`timestamp`: ISO 8601 UTC string).\n\n**FR-STRUCT-003:** Actions within the 'manifest' payload (`ManifestAction`) shall include a label (`label`: string, e.g., \"c2pa.created\") and a timestamp (`when`: ISO 8601 UTC string), and may include other arbitrary key-value pairs.\n\n**FR-STRUCT-004:** AI-specific information within the 'manifest' payload (`ManifestAiInfo`) shall include a model identifier (`model_id`: string), an optional model version (`model_version`: string), and may include other arbitrary key-value pairs.\n\n**FR-STRUCT-005:** Input timestamps for metadata (e.g., overall timestamp, action 'when' timestamps) can be provided as ISO 8601 strings, Python `datetime` objects, Python `date` objects, or numeric epoch timestamps (integer or float).\n*   **Description:** All provided timestamps shall be converted to and stored as ISO 8601 UTC strings (e.g., \"YYYY-MM-DDTHH:MM:SSZ\"). If a `date` object is provided, it's assumed to be the start of that day in UTC.\n\n#### 3.1.3 Metadata Embedding\n\n**FR-EMBED-001:** The system shall embed a given metadata payload into input text.\n*   **Description:** The embedding process involves serializing the payload, signing it, and encoding the resulting data (payload, signature, signer ID, format type) using Unicode Variation Selectors.\n\n**FR-EMBED-002:** The embedding process must not visibly alter the human-readable content of the original text.\n*   **Description:** This is achieved by appending Unicode Variation Selectors to existing characters in the text.\n\n**FR-EMBED-003:** Metadata embedding shall require an Ed25519 private key and a string signer ID.\n*   **Description:** The signer ID is included in the embedded data.\n\n**FR-EMBED-004:** A timestamp must be provided for metadata embedding.\n*   **Description:** If a timestamp is not provided, the system shall raise a `ValueError`.\n\n**FR-EMBED-005:** The system shall allow specifying the characters or positions (metadata target) in the text to be used for embedding.\n*   Supported targets: Whitespace, Punctuation, First letter of words, Last letter of words, All characters.\n*   Default target: Whitespace.\n\n**FR-EMBED-006:** If the `distribute_across_targets` option is false (default behavior), the system shall embed all Unicode Variation Selectors representing the metadata payload immediately after the first identified target character in the text.\n\n**FR-EMBED-007:** If the `distribute_across_targets` option is true, the system shall embed one Unicode Variation Selector after each identified target character, distributing the metadata payload across multiple target characters.\n\n**FR-EMBED-008:** If no suitable embedding targets are found in the input text for the selected target type and distribution strategy, the system shall raise a `ValueError`.\n\n**FR-EMBED-009:** Input text for embedding must be a string. If non-string input is provided, the system shall raise a `TypeError`.\n\n**FR-EMBED-010:** The system shall represent each byte of the serialized and signed metadata payload using a single Unicode Variation Selector.\n*   **Description:** Bytes with values 0-15 shall be mapped to selectors U+FE00 to U+FE0F. Bytes with values 16-255 shall be mapped to selectors U+E0100 to U+E01EF.\n\n#### 3.1.4 Metadata Extraction and Verification\n\n**FR-EXTRACT-001:** The system shall extract and verify embedded metadata from text.\n*   **Description:** Verification requires a user-provided public key provider function. The function must accept a signer ID (string) and return the corresponding Ed25519 public key object or None if not found.\n\n**FR-EXTRACT-002:** Successful verification shall return the extracted inner metadata payload (BasicPayload or ManifestPayload), a status of `True`, and the signer ID found in the metadata.\n\n**FR-EXTRACT-003:** Verification shall fail (return status `False`) if the public key provider cannot resolve the signer ID to a public key (returns `None`).\n\n**FR-EXTRACT-004:** Verification shall fail (return status `False`) if the public key provider returns an object that is not a valid public key type.\n\n**FR-EXTRACT-005:** Verification shall fail (return status `False`) if the public key provider function raises an exception during key resolution.\n\n**FR-EXTRACT-006:** Verification shall fail (return status `False`) if the embedded signature is invalid for the extracted payload and resolved public key.\n*   **Description:** This covers cases such as data tampering, use of an incorrect signing key, or a corrupted signature.\n\n**FR-EXTRACT-007:** If verification fails, the system may optionally return the extracted payload (if `return_payload_on_failure` is true); otherwise, it returns `None` for the payload.\n\n**FR-EXTRACT-008:** The system shall allow extraction of embedded metadata from text without performing cryptographic verification.\n*   **Description:** This operation shall return the inner metadata payload (BasicPayload or ManifestPayload) if metadata is found and parsable. If no metadata is found or if it's structurally corrupted (e.g., not valid JSON after decoding bytes), it shall return `None`.\n\n**FR-EXTRACT-009:** The system shall extract embedded bytes by identifying sequences of Unicode Variation Selectors in the input text.\n*   **Description:** Bytes are reconstructed based on the code points of these selectors.\n\n#### 3.1.5 Streaming Functionality\n\n**FR-STREAM-001:** The system shall provide a streaming handler for embedding metadata into sequences of text chunks.\n\n**FR-STREAM-002:** The streaming handler shall be initialized with a metadata payload, an Ed25519 private key, a signer ID, a metadata format ('basic' or 'manifest'), an embedding target, and a boolean option `encode_first_chunk_only`.\n*   **Description:** If `metadata` is provided, `private_key` and `signer_id` must also be provided, otherwise a `ValueError` shall be raised. `metadata_format` must be 'basic' or 'manifest', otherwise a `ValueError` shall be raised. Invalid types for these parameters shall raise a `TypeError`.\n\n**FR-STREAM-003:** If the streaming handler is initialized for 'basic' metadata format and the provided metadata does not include a 'timestamp', the handler shall automatically add the current UTC time (ISO 8601 format) as the timestamp.\n\n**FR-STREAM-004:** When the `encode_first_chunk_only` option is true, the streaming handler shall embed metadata into the first processed non-empty text chunk that contains sufficient targets for embedding.\n*   **Description:** Subsequent chunks processed by the handler shall be returned unmodified.\n\n**FR-STREAM-005:** If `encode_first_chunk_only` is false, the streaming handler (in its current implementation as per source code review) shall return all text chunks unmodified.\n*   **Description:** This reflects a current limitation noted in source comments; full support for embedding across multiple chunks or at the end of a stream with this option false is not implemented.\n\n**FR-STREAM-006:** The streaming handler shall accumulate text from incoming chunks if an individual chunk (or the currently accumulated text) does not contain sufficient targets for embedding.\n*   **Description:** Once the accumulated text has sufficient targets and metadata has not yet been embedded (and `encode_first_chunk_only` is true), the handler shall embed the metadata into the accumulated text and return it as a single processed chunk. Subsequent chunks are then returned unmodified. Chunks processed before accumulation is complete are returned unmodified.\n\n**FR-STREAM-007:** The streaming handler shall support processing dictionary-based chunks that conform to the OpenAI chat completion streaming format (`{\"choices\": [{\"delta\": {\"content\": \"text_here\"}}]}`).\n*   **Description:** Metadata shall be embedded into the text content found within `choices[0].delta.content`. The dictionary structure shall otherwise be preserved.\n\n**FR-STREAM-008:** The streaming handler (in its current implementation) does not provide special processing for Anthropic-style dictionary chunks and will return them unmodified if they are not string chunks or OpenAI-style chunks.\n\n**FR-STREAM-009:** The streaming handler's `finalize` method shall attempt to embed metadata into any text accumulated if metadata has not already been embedded.\n*   **Description:** If metadata was already embedded, or if no text was accumulated, `finalize` shall return `None`. If accumulated text exists but lacks sufficient targets for embedding, it is returned unmodified.\n\n**FR-STREAM-010:** The streaming handler shall provide a `reset` method to clear its internal state (e.g., whether metadata has been encoded, accumulated text).\n\n#### 3.1.6 Configuration Management\n\n**FR-CONFIG-001:** The system shall use a default set of configuration values if no external configuration is provided.\n*   **Default values:**\n    *   `metadata_target`: \"whitespace\"\n    *   `encode_first_chunk_only`: true\n    *   `timestamp_format`: \"%Y-%m-%dT%H:%M%z\"\n    *   `logging_level`: \"INFO\"\n    *   `report_usage_metrics`: false\n\n**FR-CONFIG-002:** The system shall allow loading configuration settings from a specified JSON file.\n*   **Description:** Settings from the file will override the default values.\n\n**FR-CONFIG-003:** The system shall allow loading configuration settings from environment variables.\n*   **Description:** Environment variable names are prefixed (e.g., `ENCYPHER_`). Boolean values can be specified using \"true\"/\"false\", \"1\"/\"0\", \"yes\"/\"no\", \"y\"/\"n\" (case-insensitive).\n\n**FR-CONFIG-004:** Configuration settings from environment variables shall take precedence over settings loaded from a configuration file and default settings.\n\n**FR-CONFIG-005:** The system shall provide methods to retrieve specific configuration values, performing necessary type conversions.\n*   **Example:** Retrieving `metadata_target` as a `MetadataTarget` enum. If an invalid string value is configured for `metadata_target`, it should default to `MetadataTarget.WHITESPACE`.\n\n**FR-CONFIG-006:** The system shall provide a method to retrieve all current configuration settings as a dictionary.\n\n#### 3.1.7 C2PA Interoperability\n\n**FR-C2PA-001:** The system shall provide a utility to convert an EncypherAI manifest structure (dictionary representation of `ManifestPayload`) into a C2PA-like dictionary structure.\n*   **Description:** The conversion maps `claim_generator`, `timestamp`, `assertions`, `ai_assertion`, and `custom_claims` to corresponding fields in the C2PA-like structure, setting a `format` field to \"application/x-encypher-ai-manifest\". EncypherAI `assertions` are mapped to C2PA-like assertions where `when` becomes `data.timestamp`. The `ai_assertion` is mapped to a C2PA-like assertion with label \"ai.model.info\".\n\n**FR-C2PA-002:** The system shall provide a utility to convert a C2PA-like dictionary structure into an EncypherAI manifest structure (dictionary).\n*   **Description:** The conversion maps fields from the C2PA-like structure back to `claim_generator`, `timestamp`, `assertions`, `ai_assertion`, and `custom_claims`. C2PA-like assertions with label \"ai.model.info\" are mapped to the EncypherAI `ai_assertion`. Other assertions are mapped to EncypherAI `assertions`.\n\n**FR-C2PA-003:** The C2PA interoperability conversion functions shall correctly perform a roundtrip conversion (EncypherAI manifest -> C2PA-like -> EncypherAI manifest), preserving the semantic content of the original manifest.\n\n**FR-C2PA-004:** The system shall provide a utility to generate a JSON schema definition for the C2PA-like manifest structure used by the interoperability functions.\n\n**FR-C2PA-005:** The C2PA conversion functions shall handle invalid inputs by raising `TypeError` for non-dictionary inputs.\n\n**FR-C2PA-006:** The C2PA conversion function `c2pa_like_dict_to_encypher_manifest` shall handle an empty dictionary input by returning an EncypherAI manifest structure with empty or default values for its fields.\n\n### 3.2 Non-Functional Requirements\nNo specific non-functional requirements with dedicated, explicit original test cases (e.g., for performance, security vulnerabilities beyond cryptographic correctness, or specific usability metrics) were identified in the provided materials. Core functional requirements FR-EMBED-002 (invisibility of embedding) and cryptographic security (FR-CRYPTO-002 to FR-CRYPTO-006, FR-KEY-004, FR-KEY-005, FR-EXTRACT-003 to FR-EXTRACT-006) cover aspects related to usability (readability) and security.\n\n### 3.3 External Interface Requirements\n\n#### 3.3.1 Programmatic API\nThe system shall expose its functionalities through a Python API. Key programmatic interfaces include:\n\n**EIR-API-001: Metadata Embedding Interface**\n*   **Interface:** `encypher.core.unicode_metadata.UnicodeMetadata.embed_metadata()`\n*   **Description:** Embeds metadata into text.\n*   **Inputs:**\n    *   `text` (str): The text to embed metadata into.\n    *   `private_key` (`cryptography.hazmat.primitives.asymmetric.ed25519.Ed25519PrivateKey`): The private key for signing.\n    *   `signer_id` (str): Identifier for the signer.\n    *   `metadata_format` (Literal[\"basic\", \"manifest\"], default \"basic\"): The metadata payload format.\n    *   `model_id` (Optional[str]): Model identifier.\n    *   `timestamp` (Optional[Union[str, datetime, date, int, float]]): Timestamp for the metadata. **This is mandatory.**\n    *   `target` (Optional[Union[str, `encypher.core.constants.MetadataTarget`]]): Where to embed metadata.\n    *   `custom_metadata` (Optional[Dict[str, Any]]): For 'basic' format.\n    *   `claim_generator` (Optional[str]): For 'manifest' format.\n    *   `actions` (Optional[List[Dict[str, Any]]]): For 'manifest' format.\n    *   `ai_info` (Optional[Dict[str, Any]]]): For 'manifest' format.\n    *   `custom_claims` (Optional[Dict[str, Any]]]): For 'manifest' format.\n    *   `distribute_across_targets` (bool, default False): Whether to distribute metadata bytes across multiple target characters.\n*   **Output:** (str) The text with embedded metadata.\n\n**EIR-API-002: Metadata Verification and Extraction Interface**\n*   **Interface:** `encypher.core.unicode_metadata.UnicodeMetadata.verify_and_extract_metadata()`\n*   **Description:** Extracts and verifies embedded metadata.\n*   **Inputs:**\n    *   `text` (str): Text potentially containing embedded metadata.\n    *   `public_key_provider` (Callable[[str], Optional[`cryptography.hazmat.primitives.asymmetric.types.PublicKeyTypes`]]): Function to resolve signer ID to a public key.\n    *   `return_payload_on_failure` (bool, default False): Whether to return payload if verification fails.\n*   **Output:** Tuple[`Union[BasicPayload, ManifestPayload, None]`, bool, `Optional[str]`] (payload, is_valid, signer_id).\n\n**EIR-API-003: Metadata Extraction Interface (No Verification)**\n*   **Interface:** `encypher.core.unicode_metadata.UnicodeMetadata.extract_metadata()`\n*   **Description:** Extracts embedded metadata without verification.\n*   **Inputs:**\n    *   `text` (str): Text potentially containing embedded metadata.\n*   **Output:** `Union[BasicPayload, ManifestPayload, None]` (The extracted inner payload or None).\n\n**EIR-API-004: Streaming Handler Initialization**\n*   **Interface:** `encypher.streaming.handlers.StreamingHandler.__init__()`\n*   **Description:** Initializes a handler for streaming metadata embedding.\n*   **Inputs:**\n    *   `metadata` (Optional[Dict[str, Any]]): Metadata payload.\n    *   `target` (Union[str, `encypher.core.constants.MetadataTarget`], default \"whitespace\").\n    *   `encode_first_chunk_only` (bool, default True).\n    *   `private_key` (Optional[`cryptography.hazmat.primitives.asymmetric.types.PrivateKeyTypes`]).\n    *   `signer_id` (Optional[str]).\n    *   `metadata_format` (Literal[\"basic\", \"manifest\"], default \"basic\").\n\n**EIR-API-005: Streaming Handler Chunk Processing**\n*   **Interface:** `encypher.streaming.handlers.StreamingHandler.process_chunk()`\n*   **Description:** Processes an incoming text or dictionary chunk.\n*   **Input:** `chunk` (Union[str, Dict[str, Any]]).\n*   **Output:** `Union[str, Dict[str, Any]]` (Processed chunk).\n\n**EIR-API-006: Key Generation Interface**\n*   **Interface:** `encypher.core.crypto_utils.generate_key_pair()`\n*   **Output:** Tuple[`Ed25519PrivateKey`, `Ed25519PublicKey`]\n\n**EIR-API-007: Private Key Loading Interface**\n*   **Interface:** `encypher.core.crypto_utils.load_private_key()`\n*   **Inputs:** `key_data` (Union[bytes, str]), `password` (Optional[bytes])\n*   **Output:** `Ed25519PrivateKey`\n\n**EIR-API-008: Public Key Loading Interface**\n*   **Interface:** `encypher.core.crypto_utils.load_public_key()`\n*   **Input:** `key_data` (Union[bytes, str])\n*   **Output:** `Ed25519PublicKey`\n\n**EIR-API-009: Configuration Settings Interface**\n*   **Interface:** `encypher.config.settings.Settings()`\n*   **Description:** Provides access to configuration settings.\n\n**EIR-API-010: C2PA Interoperability Interfaces**\n*   `encypher.interop.c2pa.encypher_manifest_to_c2pa_like_dict(manifest: Dict[str, Any]) -> Dict[str, Any]`\n*   `encypher.interop.c2pa.c2pa_like_dict_to_encypher_manifest(data: Dict[str, Any]) -> Dict[str, Any]`\n*   `encypher.interop.c2pa.get_c2pa_manifest_schema() -> Dict[str, Any]`\n\n#### 3.3.2 Data Formats\n\n**EIR-DF-001: Basic Metadata Payload Structure**\n*   **Format:** JSON (when serialized)\n*   **Structure:**\n    *   `model_id`: Optional[String]\n    *   `timestamp`: String (ISO 8601 UTC format, e.g., \"YYYY-MM-DDTHH:MM:SSZ\")\n    *   `custom_metadata`: Optional[Object{String: Any}]\n\n**EIR-DF-002: Manifest Metadata Payload Structure**\n*   **Format:** JSON (when serialized)\n*   **Structure:**\n    *   `claim_generator`: String\n    *   `assertions`: Array of `ManifestAction` objects\n    *   `ai_assertion`: Optional[`ManifestAiInfo` object]\n    *   `custom_claims`: Optional[Object{String: Any}]\n    *   `timestamp`: String (ISO 8601 UTC format)\n\n**EIR-DF-003: ManifestAction Structure (within Manifest Payload)**\n*   **Format:** JSON (when serialized as part of ManifestPayload)\n*   **Structure:**\n    *   `label`: String (e.g., \"c2pa.created\")\n    *   `when`: String (ISO 8601 UTC format)\n    *   Additional dynamic key-value pairs are permitted.\n\n**EIR-DF-004: ManifestAiInfo Structure (within Manifest Payload)**\n*   **Format:** JSON (when serialized as part of ManifestPayload)\n*   **Structure:**\n    *   `model_id`: String\n    *   `model_version`: Optional[String]\n    *   Additional dynamic key-value pairs are permitted.\n\n**EIR-DF-005: Configuration File Format**\n*   **Format:** JSON\n*   **Description:** A flat JSON object where keys correspond to configuration settings (e.g., \"metadata_target\", \"encode_first_chunk_only\").\n\n**EIR-DF-006: OpenAI Streaming Chunk Format (Input to StreamingHandler)**\n*   **Format:** JSON (as a Python dictionary)\n*   **Structure (relevant part):** `{\"choices\": [{\"delta\": {\"content\": \"string_chunk_here\"}}]}`",
        "structured_requirements": [
            {
                "requirement_id": "FR-KEY-001",
                "requirement_description": "The system shall generate Ed25519 cryptographic key pairs, consisting of a private key and a corresponding public key.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_crypto_utils.py::test_generate_key_pair",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::generate_key_pair",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-KEY-002",
                "requirement_description": "The system shall load an Ed25519 private key from a PEM-encoded representation.\n*   **Description:** This includes unencrypted PKCS8 PEM format.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_crypto_utils.py::test_load_save_keys",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::load_private_key",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-KEY-003",
                "requirement_description": "The system shall load an Ed25519 private key from an encrypted PEM-encoded representation (PKCS8), given the correct password.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_crypto_utils.py::test_load_save_keys_encrypted",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::load_private_key",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-KEY-004",
                "requirement_description": "The system shall fail to load an encrypted Ed25519 private key if an incorrect password is provided.\n*   **Description:** This attempt shall result in a `ValueError`.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_crypto_utils.py::test_load_save_keys_encrypted",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::load_private_key",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-KEY-005",
                "requirement_description": "The system shall fail to load an encrypted Ed25519 private key if no password is provided for an encrypted key.\n*   **Description:** This attempt shall result in a `ValueError`.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_crypto_utils.py::test_load_save_keys_encrypted",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::load_private_key",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-KEY-006",
                "requirement_description": "The system shall load an Ed25519 private key from its 32-byte raw binary representation.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_crypto_utils.py::test_load_save_keys",
                        "description": "(implicitly, as saving/loading involves byte conversions before PEM, and `load_private_key` handles raw bytes)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::load_private_key",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-KEY-007",
                "requirement_description": "The system shall load an Ed25519 public key from a PEM-encoded representation (SubjectPublicKeyInfo format).",
                "test_traceability": [
                    {
                        "id": "tests/core/test_crypto_utils.py::test_load_save_keys",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::load_public_key",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-KEY-008",
                "requirement_description": "The system shall load an Ed25519 public key from its 32-byte raw binary representation.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_crypto_utils.py::test_load_save_keys",
                        "description": "(implicitly, as saving/loading involves byte conversions before PEM, and `load_public_key` handles raw bytes)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::load_public_key",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CRYPTO-001",
                "requirement_description": "The system shall serialize dictionary payloads into a canonical JSON byte string.\n*   **Description:** Serialization must sort keys alphabetically and use compact separators (no extra whitespace) to ensure deterministic output for signing. The output must be UTF-8 encoded.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_crypto_utils.py::test_serialize_payload_basic",
                        "description": ""
                    },
                    {
                        "id": "tests/core/test_crypto_utils.py::test_serialize_payload_manifest",
                        "description": ""
                    },
                    {
                        "id": "tests/core/test_crypto_utils.py::test_serialize_payload_deterministic",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::serialize_payload",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CRYPTO-002",
                "requirement_description": "The system shall sign serialized payload bytes using a provided Ed25519 private key, producing a digital signature.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_crypto_utils.py::test_sign_and_verify_basic",
                        "description": ""
                    },
                    {
                        "id": "tests/core/test_crypto_utils.py::test_sign_and_verify_manifest",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::sign_payload",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CRYPTO-003",
                "requirement_description": "The system shall verify a digital signature against serialized payload bytes using a provided Ed25519 public key.\n*   **Description:** Verification shall return true if the signature is valid for the given payload and public key, and false otherwise.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_crypto_utils.py::test_sign_and_verify_basic",
                        "description": ""
                    },
                    {
                        "id": "tests/core/test_crypto_utils.py::test_sign_and_verify_manifest",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::verify_signature",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CRYPTO-004",
                "requirement_description": "Signature verification shall fail (return false) if the provided public key does not correspond to the private key used for signing.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_crypto_utils.py::test_verify_failure_wrong_key",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::verify_signature",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CRYPTO-005",
                "requirement_description": "Signature verification shall fail (return false) if the payload bytes being verified differ from the payload bytes that were originally signed.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_crypto_utils.py::test_verify_failure_tampered_payload",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::verify_signature",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CRYPTO-006",
                "requirement_description": "Signature verification shall fail (return false) if the signature data is corrupted or altered.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_crypto_utils.py::test_verify_failure_corrupt_signature",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::verify_signature",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-STRUCT-001",
                "requirement_description": "The system shall support a 'basic' metadata payload format.\n*   **Description:** The 'basic' payload includes an optional model identifier (`model_id`: string), a timestamp (`timestamp`: ISO 8601 UTC string), and an optional dictionary for custom key-value pairs (`custom_metadata`).",
                "test_traceability": [
                    {
                        "id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_verify_extract_success",
                        "description": "(with `basic_metadata` fixture)"
                    },
                    {
                        "id": "tests/core/test_crypto_utils.py::basic_payload_data",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::BasicPayload",
                        "description": "(definition)"
                    }
                ]
            },
            {
                "requirement_id": "FR-STRUCT-002",
                "requirement_description": "The system shall support a 'manifest' metadata payload format.\n*   **Description:** The 'manifest' payload is C2PA-inspired and includes a claim generator identifier (`claim_generator`: string), a list of actions (`assertions`), optional AI-specific information (`ai_assertion`), an optional dictionary for custom claims (`custom_claims`), and an overall timestamp (`timestamp`: ISO 8601 UTC string).",
                "test_traceability": [
                    {
                        "id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_verify_extract_success",
                        "description": "(with `manifest_metadata` fixture)"
                    },
                    {
                        "id": "tests/core/test_crypto_utils.py::manifest_payload_data",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::ManifestPayload",
                        "description": "(definition)"
                    }
                ]
            },
            {
                "requirement_id": "FR-STRUCT-003",
                "requirement_description": "Actions within the 'manifest' payload (`ManifestAction`) shall include a label (`label`: string, e.g., \"c2pa.created\") and a timestamp (`when`: ISO 8601 UTC string), and may include other arbitrary key-value pairs.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_verify_extract_success",
                        "description": "(with `manifest_metadata` fixture)"
                    },
                    {
                        "id": "tests/core/test_crypto_utils.py::manifest_payload_data",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::ManifestAction",
                        "description": "(definition)"
                    }
                ]
            },
            {
                "requirement_id": "FR-STRUCT-004",
                "requirement_description": "AI-specific information within the 'manifest' payload (`ManifestAiInfo`) shall include a model identifier (`model_id`: string), an optional model version (`model_version`: string), and may include other arbitrary key-value pairs.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_verify_extract_success",
                        "description": "(with `manifest_metadata` fixture)"
                    },
                    {
                        "id": "tests/core/test_crypto_utils.py::manifest_payload_data",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::ManifestAiInfo",
                        "description": "(definition)"
                    }
                ]
            },
            {
                "requirement_id": "FR-STRUCT-005",
                "requirement_description": "Input timestamps for metadata (e.g., overall timestamp, action 'when' timestamps) can be provided as ISO 8601 strings, Python `datetime` objects, Python `date` objects, or numeric epoch timestamps (integer or float).\n*   **Description:** All provided timestamps shall be converted to and stored as ISO 8601 UTC strings (e.g., \"YYYY-MM-DDTHH:MM:SSZ\"). If a `date` object is provided, it's assumed to be the start of that day in UTC.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_verify_extract_success",
                        "description": "(uses `datetime.now(timezone.utc).isoformat()`)"
                    },
                    {
                        "id": "internal logic of `UnicodeMetadata._format_timestamp`",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::_format_timestamp",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EMBED-001",
                "requirement_description": "The system shall embed a given metadata payload into input text.\n*   **Description:** The embedding process involves serializing the payload, signing it, and encoding the resulting data (payload, signature, signer ID, format type) using Unicode Variation Selectors.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_verify_extract_success",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::embed_metadata",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EMBED-002",
                "requirement_description": "The embedding process must not visibly alter the human-readable content of the original text.\n*   **Description:** This is achieved by appending Unicode Variation Selectors to existing characters in the text.",
                "test_traceability": [
                    {
                        "id": "tests/integration/test_llm_outputs.py::TestLLMOutputsIntegration::test_unicode_metadata_with_llm_outputs",
                        "description": "(checks `len(embedded_text) > len(sample_text)` while visual appearance is key)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::embed_metadata",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EMBED-003",
                "requirement_description": "Metadata embedding shall require an Ed25519 private key and a string signer ID.\n*   **Description:** The signer ID is included in the embedded data.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_verify_extract_success",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::embed_metadata",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EMBED-004",
                "requirement_description": "A timestamp must be provided for metadata embedding.\n*   **Description:** If a timestamp is not provided, the system shall raise a `ValueError`.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_metadata_raises_error_if_timestamp_missing",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::embed_metadata",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EMBED-005",
                "requirement_description": "The system shall allow specifying the characters or positions (metadata target) in the text to be used for embedding.\n*   Supported targets: Whitespace, Punctuation, First letter of words, Last letter of words, All characters.\n*   Default target: Whitespace.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_verify_extract_success",
                        "description": "(uses punctuation)"
                    },
                    {
                        "id": "tests/integration/test_llm_outputs.py::TestLLMOutputsIntegration::test_unicode_metadata_with_llm_outputs",
                        "description": "(iterates targets)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::embed_metadata",
                        "description": ""
                    },
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::find_targets",
                        "description": ""
                    },
                    {
                        "id": "encypher/core/constants.py::MetadataTarget",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EMBED-006",
                "requirement_description": "If the `distribute_across_targets` option is false (default behavior), the system shall embed all Unicode Variation Selectors representing the metadata payload immediately after the first identified target character in the text.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_verify_extract_success",
                        "description": "(implicitly tests this default)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::embed_metadata",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EMBED-007",
                "requirement_description": "If the `distribute_across_targets` option is true, the system shall embed one Unicode Variation Selector after each identified target character, distributing the metadata payload across multiple target characters.",
                "test_traceability": [
                    {
                        "id": "Source code analysis. No direct test case with `distribute_across_targets=True` found in `tests/core/test_unicode_metadata.py`. (If this path is untested, it may be a lower priority or error in test coverage.)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::embed_metadata",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EMBED-008",
                "requirement_description": "If no suitable embedding targets are found in the input text for the selected target type and distribution strategy, the system shall raise a `ValueError`.",
                "test_traceability": [
                    {
                        "id": "Logic in `embed_metadata` checking `target_indices`. An explicit test for this condition (e.g., short text with no whitespace when whitespace is target) would be beneficial.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::embed_metadata",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EMBED-009",
                "requirement_description": "Input text for embedding must be a string. If non-string input is provided, the system shall raise a `TypeError`.",
                "test_traceability": [
                    {
                        "id": "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_unicode_metadata_non_string_input",
                        "description": "(from old test file, applies to current implementation)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::embed_metadata",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EMBED-010",
                "requirement_description": "The system shall represent each byte of the serialized and signed metadata payload using a single Unicode Variation Selector.\n*   **Description:** Bytes with values 0-15 shall be mapped to selectors U+FE00 to U+FE0F. Bytes with values 16-255 shall be mapped to selectors U+E0100 to U+E01EF.",
                "test_traceability": [
                    {
                        "id": "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_variation_selector_conversion",
                        "description": "(from old test file, verifies `to_variation_selector` and `from_variation_selector` which are used by `_bytes_to_variation_selectors` and `extract_bytes`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::_bytes_to_variation_selectors",
                        "description": ""
                    },
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::to_variation_selector",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXTRACT-001",
                "requirement_description": "The system shall extract and verify embedded metadata from text.\n*   **Description:** Verification requires a user-provided public key provider function. The function must accept a signer ID (string) and return the corresponding Ed25519 public key object or None if not found.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_verify_extract_success",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::verify_and_extract_metadata",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXTRACT-002",
                "requirement_description": "Successful verification shall return the extracted inner metadata payload (BasicPayload or ManifestPayload), a status of `True`, and the signer ID found in the metadata.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_verify_extract_success",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::verify_and_extract_metadata",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXTRACT-003",
                "requirement_description": "Verification shall fail (return status `False`) if the public key provider cannot resolve the signer ID to a public key (returns `None`).",
                "test_traceability": [
                    {
                        "id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_failure_unknown_signer_id",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::verify_and_extract_metadata",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXTRACT-004",
                "requirement_description": "Verification shall fail (return status `False`) if the public key provider returns an object that is not a valid public key type.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_failure_key_mismatch",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::verify_and_extract_metadata",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXTRACT-005",
                "requirement_description": "Verification shall fail (return status `False`) if the public key provider function raises an exception during key resolution.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_failure_provider_error",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::verify_and_extract_metadata",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXTRACT-006",
                "requirement_description": "Verification shall fail (return status `False`) if the embedded signature is invalid for the extracted payload and resolved public key.\n*   **Description:** This covers cases such as data tampering, use of an incorrect signing key, or a corrupted signature.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_wrong_key",
                        "description": ""
                    },
                    {
                        "id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_tampered_data",
                        "description": ""
                    },
                    {
                        "id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_failure_invalid_signature_format",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::verify_and_extract_metadata",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXTRACT-007",
                "requirement_description": "If verification fails, the system may optionally return the extracted payload (if `return_payload_on_failure` is true); otherwise, it returns `None` for the payload.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_verify_wrong_key",
                        "description": "(uses `return_payload_on_failure=True`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::verify_and_extract_metadata",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXTRACT-008",
                "requirement_description": "The system shall allow extraction of embedded metadata from text without performing cryptographic verification.\n*   **Description:** This operation shall return the inner metadata payload (BasicPayload or ManifestPayload) if metadata is found and parsable. If no metadata is found or if it's structurally corrupted (e.g., not valid JSON after decoding bytes), it shall return `None`.",
                "test_traceability": [
                    {
                        "id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_unicode_metadata_extract_metadata",
                        "description": ""
                    },
                    {
                        "id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_unicode_metadata_extract_metadata_no_metadata",
                        "description": ""
                    },
                    {
                        "id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_unicode_metadata_extract_metadata_corrupted",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::extract_metadata",
                        "description": ""
                    },
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::_extract_outer_payload",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXTRACT-009",
                "requirement_description": "The system shall extract embedded bytes by identifying sequences of Unicode Variation Selectors in the input text.\n*   **Description:** Bytes are reconstructed based on the code points of these selectors.",
                "test_traceability": [
                    {
                        "id": "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_variation_selector_conversion",
                        "description": "(from old test file, verifies `from_variation_selector` used by `extract_bytes`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::extract_bytes",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-STREAM-001",
                "requirement_description": "The system shall provide a streaming handler for embedding metadata into sequences of text chunks.",
                "test_traceability": [
                    {
                        "id": "tests/test_streaming_handler.py::TestStreamingHandler::test_process_text_chunk",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/streaming/handlers.py::StreamingHandler",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-STREAM-002",
                "requirement_description": "The streaming handler shall be initialized with a metadata payload, an Ed25519 private key, a signer ID, a metadata format ('basic' or 'manifest'), an embedding target, and a boolean option `encode_first_chunk_only`.\n*   **Description:** If `metadata` is provided, `private_key` and `signer_id` must also be provided, otherwise a `ValueError` shall be raised. `metadata_format` must be 'basic' or 'manifest', otherwise a `ValueError` shall be raised. Invalid types for these parameters shall raise a `TypeError`.",
                "test_traceability": [
                    {
                        "id": "tests/test_streaming_handler.py::TestStreamingHandler::test_process_text_chunk",
                        "description": "(initialization)"
                    },
                    {
                        "id": "constructor validation logic",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/streaming/handlers.py::StreamingHandler::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-STREAM-003",
                "requirement_description": "If the streaming handler is initialized for 'basic' metadata format and the provided metadata does not include a 'timestamp', the handler shall automatically add the current UTC time (ISO 8601 format) as the timestamp.",
                "test_traceability": [
                    {
                        "id": "Source code analysis of `StreamingHandler.__init__`.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/streaming/handlers.py::StreamingHandler::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-STREAM-004",
                "requirement_description": "When the `encode_first_chunk_only` option is true, the streaming handler shall embed metadata into the first processed non-empty text chunk that contains sufficient targets for embedding.\n*   **Description:** Subsequent chunks processed by the handler shall be returned unmodified.",
                "test_traceability": [
                    {
                        "id": "tests/test_streaming_handler.py::TestStreamingHandler::test_encode_first_chunk_only",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/streaming/handlers.py::StreamingHandler::_process_text_chunk",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-STREAM-005",
                "requirement_description": "If `encode_first_chunk_only` is false, the streaming handler (in its current implementation as per source code review) shall return all text chunks unmodified.\n*   **Description:** This reflects a current limitation noted in source comments; full support for embedding across multiple chunks or at the end of a stream with this option false is not implemented.",
                "test_traceability": [
                    {
                        "id": "tests/test_streaming_handler.py::TestStreamingHandler::test_encode_all_chunks",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/streaming/handlers.py::StreamingHandler::_process_text_chunk",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-STREAM-006",
                "requirement_description": "The streaming handler shall accumulate text from incoming chunks if an individual chunk (or the currently accumulated text) does not contain sufficient targets for embedding.\n*   **Description:** Once the accumulated text has sufficient targets and metadata has not yet been embedded (and `encode_first_chunk_only` is true), the handler shall embed the metadata into the accumulated text and return it as a single processed chunk. Subsequent chunks are then returned unmodified. Chunks processed before accumulation is complete are returned unmodified.",
                "test_traceability": [
                    {
                        "id": "tests/test_streaming_handler.py::TestStreamingHandler::test_accumulation_for_small_chunks",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/streaming/handlers.py::StreamingHandler::_process_text_chunk",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-STREAM-007",
                "requirement_description": "The streaming handler shall support processing dictionary-based chunks that conform to the OpenAI chat completion streaming format (`{\"choices\": [{\"delta\": {\"content\": \"text_here\"}}]}`).\n*   **Description:** Metadata shall be embedded into the text content found within `choices[0].delta.content`. The dictionary structure shall otherwise be preserved.",
                "test_traceability": [
                    {
                        "id": "tests/test_streaming_handler.py::TestStreamingHandler::test_process_dict_chunk_openai",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/streaming/handlers.py::StreamingHandler::_process_dict_chunk",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-STREAM-008",
                "requirement_description": "The streaming handler (in its current implementation) does not provide special processing for Anthropic-style dictionary chunks and will return them unmodified if they are not string chunks or OpenAI-style chunks.",
                "test_traceability": [
                    {
                        "id": "tests/test_streaming_handler.py::TestStreamingHandler::test_process_dict_chunk_anthropic",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/streaming/handlers.py::StreamingHandler::_process_dict_chunk",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-STREAM-009",
                "requirement_description": "The streaming handler's `finalize` method shall attempt to embed metadata into any text accumulated if metadata has not already been embedded.\n*   **Description:** If metadata was already embedded, or if no text was accumulated, `finalize` shall return `None`. If accumulated text exists but lacks sufficient targets for embedding, it is returned unmodified.",
                "test_traceability": [
                    {
                        "id": "tests/test_streaming_handler.py::TestStreamingHandler::test_finalize_already_encoded",
                        "description": ""
                    },
                    {
                        "id": "tests/test_streaming_handler.py::TestStreamingHandler::test_finalize_with_no_targets",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/streaming/handlers.py::StreamingHandler::finalize",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-STREAM-010",
                "requirement_description": "The streaming handler shall provide a `reset` method to clear its internal state (e.g., whether metadata has been encoded, accumulated text).",
                "test_traceability": [
                    {
                        "id": "tests/test_streaming_handler.py::TestStreamingHandler::test_reset",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/streaming/handlers.py::StreamingHandler::reset",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CONFIG-001",
                "requirement_description": "The system shall use a default set of configuration values if no external configuration is provided.\n*   **Default values:**\n    *   `metadata_target`: \"whitespace\"\n    *   `encode_first_chunk_only`: true\n    *   `timestamp_format`: \"%Y-%m-%dT%H:%M%z\"\n    *   `logging_level`: \"INFO\"\n    *   `report_usage_metrics`: false",
                "test_traceability": [
                    {
                        "id": "tests/test_settings.py::TestSettings::test_default_settings",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/config/settings.py::Settings::DEFAULT_CONFIG",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CONFIG-002",
                "requirement_description": "The system shall allow loading configuration settings from a specified JSON file.\n*   **Description:** Settings from the file will override the default values.",
                "test_traceability": [
                    {
                        "id": "tests/test_settings.py::TestSettings::test_load_from_file",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/config/settings.py::Settings::_load_from_file",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CONFIG-003",
                "requirement_description": "The system shall allow loading configuration settings from environment variables.\n*   **Description:** Environment variable names are prefixed (e.g., `ENCYPHER_`). Boolean values can be specified using \"true\"/\"false\", \"1\"/\"0\", \"yes\"/\"no\", \"y\"/\"n\" (case-insensitive).",
                "test_traceability": [
                    {
                        "id": "tests/test_settings.py::TestSettings::test_load_from_env",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/config/settings.py::Settings::_load_from_env",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CONFIG-004",
                "requirement_description": "Configuration settings from environment variables shall take precedence over settings loaded from a configuration file and default settings.",
                "test_traceability": [
                    {
                        "id": "tests/test_settings.py::TestSettings::test_env_overrides_file",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/config/settings.py::Settings::__init__",
                        "description": "(order of loading)"
                    }
                ]
            },
            {
                "requirement_id": "FR-CONFIG-005",
                "requirement_description": "The system shall provide methods to retrieve specific configuration values, performing necessary type conversions.\n*   **Example:** Retrieving `metadata_target` as a `MetadataTarget` enum. If an invalid string value is configured for `metadata_target`, it should default to `MetadataTarget.WHITESPACE`.",
                "test_traceability": [
                    {
                        "id": "tests/test_settings.py::TestSettings::test_get_metadata_target",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/config/settings.py::Settings::get",
                        "description": ""
                    },
                    {
                        "id": "encypher/config/settings.py::Settings::get_metadata_target",
                        "description": ""
                    },
                    {
                        "id": "etc.",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CONFIG-006",
                "requirement_description": "The system shall provide a method to retrieve all current configuration settings as a dictionary.",
                "test_traceability": [
                    {
                        "id": "tests/test_settings.py::TestSettings::test_to_dict",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/config/settings.py::Settings::to_dict",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-C2PA-001",
                "requirement_description": "The system shall provide a utility to convert an EncypherAI manifest structure (dictionary representation of `ManifestPayload`) into a C2PA-like dictionary structure.\n*   **Description:** The conversion maps `claim_generator`, `timestamp`, `assertions`, `ai_assertion`, and `custom_claims` to corresponding fields in the C2PA-like structure, setting a `format` field to \"application/x-encypher-ai-manifest\". EncypherAI `assertions` are mapped to C2PA-like assertions where `when` becomes `data.timestamp`. The `ai_assertion` is mapped to a C2PA-like assertion with label \"ai.model.info\".",
                "test_traceability": [
                    {
                        "id": "tests/interop/test_c2pa.py::TestC2PAInterop::test_encypher_to_c2pa_conversion",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/interop/c2pa.py::encypher_manifest_to_c2pa_like_dict",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-C2PA-002",
                "requirement_description": "The system shall provide a utility to convert a C2PA-like dictionary structure into an EncypherAI manifest structure (dictionary).\n*   **Description:** The conversion maps fields from the C2PA-like structure back to `claim_generator`, `timestamp`, `assertions`, `ai_assertion`, and `custom_claims`. C2PA-like assertions with label \"ai.model.info\" are mapped to the EncypherAI `ai_assertion`. Other assertions are mapped to EncypherAI `assertions`.",
                "test_traceability": [
                    {
                        "id": "tests/interop/test_c2pa.py::TestC2PAInterop::test_c2pa_to_encypher_conversion",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/interop/c2pa.py::c2pa_like_dict_to_encypher_manifest",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-C2PA-003",
                "requirement_description": "The C2PA interoperability conversion functions shall correctly perform a roundtrip conversion (EncypherAI manifest -> C2PA-like -> EncypherAI manifest), preserving the semantic content of the original manifest.",
                "test_traceability": [
                    {
                        "id": "tests/interop/test_c2pa.py::TestC2PAInterop::test_roundtrip_conversion",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/interop/c2pa.py::encypher_manifest_to_c2pa_like_dict",
                        "description": ""
                    },
                    {
                        "id": "encypher/interop/c2pa.py::c2pa_like_dict_to_encypher_manifest",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-C2PA-004",
                "requirement_description": "The system shall provide a utility to generate a JSON schema definition for the C2PA-like manifest structure used by the interoperability functions.",
                "test_traceability": [
                    {
                        "id": "tests/interop/test_c2pa.py::TestC2PAInterop::test_schema_generation",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/interop/c2pa.py::get_c2pa_manifest_schema",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-C2PA-005",
                "requirement_description": "The C2PA conversion functions shall handle invalid inputs by raising `TypeError` for non-dictionary inputs.",
                "test_traceability": [
                    {
                        "id": "tests/interop/test_c2pa.py::TestC2PAInterop::test_error_handling",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/interop/c2pa.py::encypher_manifest_to_c2pa_like_dict",
                        "description": ""
                    },
                    {
                        "id": "encypher/interop/c2pa.py::c2pa_like_dict_to_encypher_manifest",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-C2PA-006",
                "requirement_description": "The C2PA conversion function `c2pa_like_dict_to_encypher_manifest` shall handle an empty dictionary input by returning an EncypherAI manifest structure with empty or default values for its fields.",
                "test_traceability": [
                    {
                        "id": "tests/interop/test_c2pa.py::TestC2PAInterop::test_error_handling",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "encypher/interop/c2pa.py::c2pa_like_dict_to_encypher_manifest",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-API-001",
                "requirement_description": "Metadata Embedding Interface\n*   **Interface:** `encypher.core.unicode_metadata.UnicodeMetadata.embed_metadata()`\n*   **Description:** Embeds metadata into text.\n*   **Inputs:**\n    *   `text` (str): The text to embed metadata into.\n    *   `private_key` (`cryptography.hazmat.primitives.asymmetric.ed25519.Ed25519PrivateKey`): The private key for signing.\n    *   `signer_id` (str): Identifier for the signer.\n    *   `metadata_format` (Literal[\"basic\", \"manifest\"], default \"basic\"): The metadata payload format.\n    *   `model_id` (Optional[str]): Model identifier.\n    *   `timestamp` (Optional[Union[str, datetime, date, int, float]]): Timestamp for the metadata. **This is mandatory.**\n    *   `target` (Optional[Union[str, `encypher.core.constants.MetadataTarget`]]): Where to embed metadata.\n    *   `custom_metadata` (Optional[Dict[str, Any]]): For 'basic' format.\n    *   `claim_generator` (Optional[str]): For 'manifest' format.\n    *   `actions` (Optional[List[Dict[str, Any]]]): For 'manifest' format.\n    *   `ai_info` (Optional[Dict[str, Any]]]): For 'manifest' format.\n    *   `custom_claims` (Optional[Dict[str, Any]]]): For 'manifest' format.\n    *   `distribute_across_targets` (bool, default False): Whether to distribute metadata bytes across multiple target characters.\n*   **Output:** (str) The text with embedded metadata.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::embed_metadata",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-API-002",
                "requirement_description": "Metadata Verification and Extraction Interface\n*   **Interface:** `encypher.core.unicode_metadata.UnicodeMetadata.verify_and_extract_metadata()`\n*   **Description:** Extracts and verifies embedded metadata.\n*   **Inputs:**\n    *   `text` (str): Text potentially containing embedded metadata.\n    *   `public_key_provider` (Callable[[str], Optional[`cryptography.hazmat.primitives.asymmetric.types.PublicKeyTypes`]]): Function to resolve signer ID to a public key.\n    *   `return_payload_on_failure` (bool, default False): Whether to return payload if verification fails.\n*   **Output:** Tuple[`Union[BasicPayload, ManifestPayload, None]`, bool, `Optional[str]`] (payload, is_valid, signer_id).",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::verify_and_extract_metadata",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-API-003",
                "requirement_description": "Metadata Extraction Interface (No Verification)\n*   **Interface:** `encypher.core.unicode_metadata.UnicodeMetadata.extract_metadata()`\n*   **Description:** Extracts embedded metadata without verification.\n*   **Inputs:**\n    *   `text` (str): Text potentially containing embedded metadata.\n*   **Output:** `Union[BasicPayload, ManifestPayload, None]` (The extracted inner payload or None).",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "encypher/core/unicode_metadata.py::UnicodeMetadata::extract_metadata",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-API-004",
                "requirement_description": "Streaming Handler Initialization\n*   **Interface:** `encypher.streaming.handlers.StreamingHandler.__init__()`\n*   **Description:** Initializes a handler for streaming metadata embedding.\n*   **Inputs:**\n    *   `metadata` (Optional[Dict[str, Any]]): Metadata payload.\n    *   `target` (Union[str, `encypher.core.constants.MetadataTarget`], default \"whitespace\").\n    *   `encode_first_chunk_only` (bool, default True).\n    *   `private_key` (Optional[`cryptography.hazmat.primitives.asymmetric.types.PrivateKeyTypes`]).\n    *   `signer_id` (Optional[str]).\n    *   `metadata_format` (Literal[\"basic\", \"manifest\"], default \"basic\").",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "encypher/streaming/handlers.py::StreamingHandler::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-API-005",
                "requirement_description": "Streaming Handler Chunk Processing\n*   **Interface:** `encypher.streaming.handlers.StreamingHandler.process_chunk()`\n*   **Description:** Processes an incoming text or dictionary chunk.\n*   **Input:** `chunk` (Union[str, Dict[str, Any]]).\n*   **Output:** `Union[str, Dict[str, Any]]` (Processed chunk).",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "encypher/streaming/handlers.py::StreamingHandler::process_chunk",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-API-006",
                "requirement_description": "Key Generation Interface\n*   **Interface:** `encypher.core.crypto_utils.generate_key_pair()`\n*   **Output:** Tuple[`Ed25519PrivateKey`, `Ed25519PublicKey`]",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::generate_key_pair",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-API-007",
                "requirement_description": "Private Key Loading Interface\n*   **Interface:** `encypher.core.crypto_utils.load_private_key()`\n*   **Inputs:** `key_data` (Union[bytes, str]), `password` (Optional[bytes])\n*   **Output:** `Ed25519PrivateKey`",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::load_private_key",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-API-008",
                "requirement_description": "Public Key Loading Interface\n*   **Interface:** `encypher.core.crypto_utils.load_public_key()`\n*   **Input:** `key_data` (Union[bytes, str])\n*   **Output:** `Ed25519PublicKey`",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::load_public_key",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-API-009",
                "requirement_description": "Configuration Settings Interface\n*   **Interface:** `encypher.config.settings.Settings()`\n*   **Description:** Provides access to configuration settings.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "encypher/config/settings.py::Settings",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-API-010",
                "requirement_description": "C2PA Interoperability Interfaces\n*   `encypher.interop.c2pa.encypher_manifest_to_c2pa_like_dict(manifest: Dict[str, Any]) -> Dict[str, Any]`\n*   `encypher.interop.c2pa.c2pa_like_dict_to_encypher_manifest(data: Dict[str, Any]) -> Dict[str, Any]`\n*   `encypher.interop.c2pa.get_c2pa_manifest_schema() -> Dict[str, Any]`",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "encypher/interop/c2pa.py",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-DF-001",
                "requirement_description": "Basic Metadata Payload Structure\n*   **Format:** JSON (when serialized)\n*   **Structure:**\n    *   `model_id`: Optional[String]\n    *   `timestamp`: String (ISO 8601 UTC format, e.g., \"YYYY-MM-DDTHH:MM:SSZ\")\n    *   `custom_metadata`: Optional[Object{String: Any}]",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::BasicPayload",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-DF-002",
                "requirement_description": "Manifest Metadata Payload Structure\n*   **Format:** JSON (when serialized)\n*   **Structure:**\n    *   `claim_generator`: String\n    *   `assertions`: Array of `ManifestAction` objects\n    *   `ai_assertion`: Optional[`ManifestAiInfo` object]\n    *   `custom_claims`: Optional[Object{String: Any}]\n    *   `timestamp`: String (ISO 8601 UTC format)",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::ManifestPayload",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-DF-003",
                "requirement_description": "ManifestAction Structure (within Manifest Payload)\n*   **Format:** JSON (when serialized as part of ManifestPayload)\n*   **Structure:**\n    *   `label`: String (e.g., \"c2pa.created\")\n    *   `when`: String (ISO 8601 UTC format)\n    *   Additional dynamic key-value pairs are permitted.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::ManifestAction",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-DF-004",
                "requirement_description": "ManifestAiInfo Structure (within Manifest Payload)\n*   **Format:** JSON (when serialized as part of ManifestPayload)\n*   **Structure:**\n    *   `model_id`: String\n    *   `model_version`: Optional[String]\n    *   Additional dynamic key-value pairs are permitted.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "encypher/core/crypto_utils.py::ManifestAiInfo",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-DF-005",
                "requirement_description": "Configuration File Format\n*   **Format:** JSON\n*   **Description:** A flat JSON object where keys correspond to configuration settings (e.g., \"metadata_target\", \"encode_first_chunk_only\").",
                "test_traceability": [
                    {
                        "id": "tests/test_settings.py::TestSettings::test_load_from_file",
                        "description": ""
                    }
                ],
                "code_traceability": []
            },
            {
                "requirement_id": "EIR-DF-006",
                "requirement_description": "OpenAI Streaming Chunk Format (Input to StreamingHandler)\n*   **Format:** JSON (as a Python dictionary)\n*   **Structure (relevant part):** `{\"choices\": [{\"delta\": {\"content\": \"string_chunk_here\"}}]}`",
                "test_traceability": [
                    {
                        "id": "tests/test_streaming_handler.py::TestStreamingHandler::test_process_dict_chunk_openai",
                        "description": ""
                    }
                ],
                "code_traceability": []
            }
        ],
        "full_code_skeleton": "--- File: encypher/__init__.py ---\n```python\n\"\"\"\nEncypherAI Core Package\n\nA Python package for embedding and extracting metadata in text using Unicode\nvariation selectors.\nThis package provides tools for invisible metadata encoding in AI-generated text.\n\"\"\"\n```\n--- File: encypher/streaming/__init__.py ---\n```python\n\"\"\"\nStreaming support for EncypherAI metadata encoding.\n\"\"\"\n```\n--- File: encypher/streaming/handlers.py ---\n```python\n\"\"\"\nStreaming handlers for EncypherAI metadata encoding.\n\nThis module provides utilities for handling streaming responses from LLMs\nand encoding metadata into the streaming chunks.\n\"\"\"\nfrom typing import Any, Dict, List, Literal, Optional, Union\nfrom cryptography.hazmat.primitives.asymmetric.types import PrivateKeyTypes\nfrom encypher.core.unicode_metadata import MetadataTarget\n\nclass StreamingHandler:\n    \"\"\"\n    Handler for processing streaming chunks from LLM providers and encoding metadata.\n\n    This class ensures that metadata is properly encoded in streaming responses,\n    handling the complexities of partial text chunks while maintaining consistency.\n    \"\"\"\n\n    def __init__(\n        self,\n        metadata: Optional[Dict[str, Any]] = None,\n        target: Union[str, MetadataTarget] = \"whitespace\",\n        encode_first_chunk_only: bool = True,\n        # New parameters for signature-based embedding\n        private_key: Optional[PrivateKeyTypes] = None,\n        signer_id: Optional[str] = None,\n        metadata_format: Literal[\"basic\", \"manifest\"] = \"basic\",\n        # Removed hmac_secret_key\n    ):\n        \"\"\"\n        Initialize the streaming handler.\n\n        Args:\n            metadata: Dictionary of metadata to encode. Must include keys required\n                      by the chosen `metadata_format`.\n            target: Where to embed the metadata (whitespace, punctuation, etc.)\n            encode_first_chunk_only: Whether to encode metadata only in the first\n                                     non-empty chunk. Currently, only True is fully\n                                     supported for signature embedding.\n            private_key: The private key for signing the metadata.\n            signer_id: An identifier for the signer (associated with the public key).\n            metadata_format: The structure ('basic' or 'manifest') of the metadata payload.\n\n        Raises:\n            ValueError: If `metadata_format` is invalid, or if `metadata` is provided\n                        without `private_key` and `signer_id`.\n            TypeError: If `metadata`, `encode_first_chunk_only`, `private_key`,\n                       or `signer_id` have incorrect types.\n        \"\"\"\n        pass\n\n    def _has_sufficient_targets(self, text: str) -> bool:\n        \"\"\"\n        Check if the text has at least one suitable target for embedding metadata.\n\n        Args:\n            text: Text to check for targets\n\n        Returns:\n            True if at least one suitable target is found, False otherwise\n        \"\"\"\n        pass\n\n    def process_chunk(self, chunk: Union[str, Dict[str, Any]]) -> Union[str, Dict[str, Any]]:\n        \"\"\"\n        Process a streaming chunk and encode metadata if needed.\n\n        This method handles both raw text chunks and structured chunks (like those from OpenAI).\n\n        Args:\n            chunk: Text chunk or dictionary containing a text chunk\n\n        Returns:\n            Processed chunk with encoded metadata, preserving the input chunk type (str or dict).\n\n        Raises:\n            ValueError: If the underlying text processing (_process_text_chunk) fails.\n            KeyError: If the expected keys ('choices', 'delta', 'content', etc.) are missing.\n            IndexError: If the 'choices' list is empty.\n        \"\"\"\n        pass\n\n    def _process_text_chunk(self, chunk: str) -> str:\n        \"\"\"\n        Process a text chunk and encode metadata if needed.\n\n        Args:\n            chunk: Text chunk\n\n        Returns:\n            Processed text chunk with encoded metadata\n\n        Raises:\n            ValueError: If UnicodeMetadata.embed_metadata fails (e.g., not enough targets).\n        \"\"\"\n        pass\n\n    def _process_dict_chunk(self, chunk: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Process a dictionary chunk and encode metadata if needed.\n\n        This handles structured chunks like those from OpenAI's streaming API.\n\n        Args:\n            chunk: Dictionary containing a text chunk\n\n        Returns:\n            Processed dictionary with encoded metadata\n\n        Raises:\n            ValueError: If the underlying text processing (_process_text_chunk) fails.\n            KeyError: If the expected keys ('choices', 'delta', 'content', etc.) are missing.\n            IndexError: If the 'choices' list is empty.\n        \"\"\"\n        pass\n\n    def finalize(self) -> Optional[str]:\n        \"\"\"\n        Finalize the stream and return any accumulated text with encoded metadata.\n\n        This method should be called after all chunks have been processed to handle\n        any remaining accumulated text that hasn't been processed yet.\n\n        Returns:\n            Processed accumulated text with encoded metadata, or None if no text accumulated\n\n        Raises:\n            ValueError: If UnicodeMetadata.embed_metadata fails (e.g., not enough targets).\n        \"\"\"\n        pass\n\n    def reset(self) -> None:\n        \"\"\"\n        Reset the handler state.\n\n        This is useful when starting a new streaming session.\n        \"\"\"\n        pass\n```\n--- File: encypher/interop/__init__.py ---\n```python\n\"\"\"\nInteroperability utilities for EncypherAI.\n\nThis package provides tools for interoperability between EncypherAI's metadata formats\nand other content provenance standards and formats.\n\"\"\"\n```\n--- File: encypher/interop/c2pa.py ---\n```python\n\"\"\"\nC2PA Interoperability Module for EncypherAI.\n\nThis module provides utilities for conceptual interoperability between EncypherAI's\nmanifest format and C2PA-like structures. These utilities serve as a bridge for\norganizations working with both EncypherAI (for plain text) and C2PA (for rich media).\n\nNote: This module provides a conceptual mapping, not a fully C2PA-compliant implementation.\nThe goal is to demonstrate potential interoperability and provide a starting point for\norganizations that need to work with both standards.\n\"\"\"\n\nfrom typing import Any, Dict\n\ndef encypher_manifest_to_c2pa_like_dict(manifest: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Converts an EncypherAI ManifestPayload to a dictionary using field names\n    conceptually aligned with C2PA assertion structures.\n\n    This function provides a conceptual bridge between EncypherAI's plain-text\n    manifest format and C2PA's rich media manifest structure, enabling potential\n    interoperability between the two approaches.\n\n    Args:\n        manifest: An EncypherAI manifest payload dictionary (can be a TypedDict ManifestPayload\n                 or a regular dict with the same structure)\n\n    Returns:\n        A dictionary with field names aligned with C2PA concepts, containing the\n        same information as the original manifest.\n\n    Example:\n        from encypher.core.crypto_utils import ManifestPayload\n        from encypher.interop.c2pa import encypher_manifest_to_c2pa_like_dict\n\n        # Original EncypherAI manifest\n        manifest = ManifestPayload(\n            claim_generator=\"EncypherAI/1.1.0\",\n            assertions=[{\"label\": \"c2pa.created\", \"when\": \"2025-04-13T12:00:00Z\"}],\n            ai_assertion={\"model_id\": \"gpt-4o\", \"model_version\": \"1.0\"},\n            custom_claims={},\n            timestamp=\"2025-04-13T12:00:00Z\"\n        )\n\n        # Convert to C2PA-like structure\n        c2pa_dict = encypher_manifest_to_c2pa_like_dict(manifest)\n    \"\"\"\n    pass\n\ndef c2pa_like_dict_to_encypher_manifest(data: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Creates an EncypherAI ManifestPayload from a dictionary structured\n    similarly to C2PA assertions. Handles missing fields gracefully.\n\n    This function provides a conceptual bridge from C2PA-like structures\n    to EncypherAI's manifest format, enabling potential interoperability\n    between the two approaches.\n\n    Args:\n        data: A dictionary with C2PA-like structure containing provenance information.\n\n    Returns:\n        An EncypherAI ManifestPayload dictionary that can be used with EncypherAI's\n        embedding functions.\n\n    Example:\n        from encypher.interop.c2pa import c2pa_like_dict_to_encypher_manifest\n\n        # C2PA-like structure\n        c2pa_data = {\n            \"claim_generator\": \"SomeApp/1.0\",\n            \"assertions\": [\n                {\n                    \"label\": \"c2pa.created\",\n                    \"data\": {\"timestamp\": \"2025-04-13T12:00:00Z\"}\n                },\n                {\n                    \"label\": \"ai.model.info\",\n                    \"data\": {\"model_id\": \"gpt-4o\", \"model_version\": \"1.0\"}\n                }\n            ],\n            \"timestamp\": \"2025-04-13T12:00:00Z\"\n        }\n\n        # Convert to EncypherAI manifest\n        manifest = c2pa_like_dict_to_encypher_manifest(c2pa_data)\n    \"\"\"\n    pass\n\ndef get_c2pa_manifest_schema() -> Dict[str, Any]:\n    \"\"\"\n    Returns a JSON Schema representation of the C2PA-like structure used by this module.\n\n    This schema provides documentation for the expected structure of C2PA-like dictionaries\n    used with the conversion functions in this module.\n\n    Returns:\n        A dictionary containing the JSON Schema for C2PA-like structures.\n    \"\"\"\n    pass\n```\n--- File: encypher/config/__init__.py ---\n```python\n\"\"\"\nConfiguration utilities for EncypherAI.\n\"\"\"\n```\n--- File: encypher/config/settings.py ---\n```python\n\"\"\"\nConfiguration settings for EncypherAI.\n\nThis module provides a centralized configuration system that supports\nloading from environment variables and configuration files.\n\"\"\"\n\nfrom pathlib import Path\nfrom typing import Any, Dict, Optional, Union\n\nfrom encypher.core.unicode_metadata import MetadataTarget\n\n\nclass Settings:\n    \"\"\"\n    Settings class for EncypherAI configuration.\n\n    This class handles loading configuration from environment variables\n    and configuration files, with sensible defaults.\n    \"\"\"\n\n    # Default configuration values\n    DEFAULT_CONFIG = {\n        \"metadata_target\": \"whitespace\",\n        \"encode_first_chunk_only\": True,\n        \"hmac_secret_key\": \"\",\n        \"timestamp_format\": \"%Y-%m-%dT%H:%M%z\",\n        \"logging_level\": \"INFO\",\n        \"report_usage_metrics\": False,\n    }\n\n    def __init__(\n        self,\n        config_file: Optional[Union[str, Path]] = None,\n        env_prefix: str = \"ENCYPHER_\",\n    ):\n        \"\"\"\n        Initialize settings from environment variables and/or config file.\n\n        Args:\n            config_file: Path to configuration file (JSON)\n            env_prefix: Prefix for environment variables\n        \"\"\"\n        pass\n\n    def _load_from_file(self, config_file: Union[str, Path]) -> None:\n        \"\"\"\n        Load configuration from a JSON file.\n\n        Args:\n            config_file: Path to configuration file\n        \"\"\"\n        pass\n\n    def _load_from_env(self) -> None:\n        \"\"\"\n        Load configuration from environment variables.\n\n        Environment variables take precedence over config file values.\n        \"\"\"\n        pass\n\n    def get(self, key: str, default: Any = None) -> Any:\n        \"\"\"\n        Get a configuration value.\n\n        Args:\n            key: Configuration key\n            default: Default value if key not found\n\n        Returns:\n            Configuration value or default\n        \"\"\"\n        pass\n\n    def get_metadata_target(self) -> MetadataTarget:\n        \"\"\"\n        Get the metadata target as an enum value.\n\n        Returns:\n            MetadataTarget enum value\n        \"\"\"\n        pass\n\n    def get_hmac_secret_key(self) -> str:\n        \"\"\"\n        Get the HMAC secret key.\n\n        Returns:\n            HMAC secret key\n        \"\"\"\n        pass\n\n    def get_encode_first_chunk_only(self) -> bool:\n        \"\"\"\n        Get whether to encode metadata only in the first chunk.\n\n        Returns:\n            True if encoding only the first chunk, False otherwise\n        \"\"\"\n        pass\n\n    def get_timestamp_format(self) -> str:\n        \"\"\"\n        Get the timestamp format.\n\n        Returns:\n            Timestamp format string\n        \"\"\"\n        pass\n\n    def get_logging_level(self) -> str:\n        \"\"\"\n        Get the logging level.\n\n        Returns:\n            Logging level string\n        \"\"\"\n        pass\n\n    def get_report_usage_metrics(self) -> bool:\n        \"\"\"\n        Get whether to report usage metrics.\n\n        Returns:\n            True if reporting usage metrics, False otherwise\n        \"\"\"\n        pass\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"\n        Get the configuration as a dictionary.\n\n        Returns:\n            Configuration dictionary\n        \"\"\"\n        pass\n```\n--- File: encypher/examples/generate_keys.py ---\n```python\n#!/usr/bin/env python\n\"\"\"\nHelper script to generate Ed25519 key pair for EncypherAI.\n\nGenerates a private and public key pair in PEM format and a suggested key_id.\nProvides instructions for storing the private key securely (e.g., in a .env file)\nand using the public key and key_id in your application.\n\"\"\"\n\ndef generate_and_print_keys():\n    \"\"\"Generates and prints Ed25519 keys and instructions.\"\"\"\n    pass\n```\n--- File: encypher/examples/cli_example.py ---\n```python\n\"\"\"\nCommand Line Interface Example for EncypherAI\n\nThis example demonstrates how to use EncypherAI from the command line\nto encode and decode metadata in text.\n\"\"\"\n\nfrom datetime import datetime\nfrom encypher.core.unicode_metadata import MetadataTarget\n\ndef count_metadata_occurrences(text):\n    \"\"\"\n    Count how many times metadata appears in the text.\n\n    Args:\n        text: The text to analyze\n\n    Returns:\n        int: Number of metadata occurrences\n    \"\"\"\n    pass\n\ndef encode_metadata_with_count(encoder, text, model_id, timestamp, custom_metadata, target):\n    \"\"\"\n    Wrapper around MetadataEncoder.encode_metadata that also returns the count of embeddings.\n\n    Returns:\n        tuple: (encoded_text, embed_count)\n    \"\"\"\n    pass\n\ndef encode_text(args):\n    \"\"\"\n    Encode metadata into text.\n\n    Args:\n        args: Command line arguments\n    \"\"\"\n    pass\n\ndef decode_text(args):\n    \"\"\"\n    Decode metadata from text.\n    \"\"\"\n    pass\n\ndef main():\n    \"\"\"Main entry point for the CLI.\"\"\"\n    pass\n```\n--- File: encypher/examples/__init__.py ---\n```python\n\"\"\"\nExample implementations for EncypherAI.\n\"\"\"\n```\n--- File: encypher/examples/youtube_demo.py ---\n```python\n\"\"\"\nEncypherAI YouTube Demo Script\n\nA visually appealing, step-by-step demonstration of EncypherAI's core functionality\nfor use in introductory videos and presentations.\n\"\"\"\n\ndef clear_screen():\n    \"\"\"Clear the terminal screen.\"\"\"\n    pass\n\ndef print_header():\n    \"\"\"Print a stylish header for the demo.\"\"\"\n    pass\n\ndef print_section(title: str):\n    \"\"\"Print a section title.\"\"\"\n    pass\n\ndef wait_for_key():\n    \"\"\"Wait for a key press to continue.\"\"\"\n    pass\n\ndef get_display_text(encoded_text: str, original_text: str) -> str:\n    \"\"\"Return either the original text or encoded text based on the display flag.\n\n    Args:\n        encoded_text: Text with encoded metadata\n        original_text: Original text without metadata\n\n    Returns:\n        The text to display based on DISPLAY_ORIGINAL_TEXT flag\n    \"\"\"\n    pass\n\ndef format_bytes_for_display(text: str, max_length: int = 30) -> str:\n    \"\"\"Format the byte representation of text for display.\n\n    Args:\n        text: The text to convert to byte representation\n        max_length: Maximum number of bytes to display\n\n    Returns:\n        A formatted string showing the byte values\n    \"\"\"\n    pass\n\ndef show_byte_comparison(original_text: str, encoded_text: str):\n    \"\"\"Display a technical comparison of byte values between original and encoded text.\n\n    Args:\n        original_text: The original text without metadata\n        encoded_text: The text with encoded metadata\n    \"\"\"\n    pass\n\ndef demo_basic_encoding():\n    \"\"\"Demonstrate basic metadata encoding.\"\"\"\n    pass\n\ndef demo_metadata_extraction():\n    \"\"\"Demonstrate metadata extraction and verification.\"\"\"\n    pass\n\ndef demo_tamper_detection():\n    \"\"\"Demonstrate tamper detection using HMAC verification.\"\"\"\n    pass\n\ndef demo_streaming():\n    \"\"\"Demonstrate streaming support.\"\"\"\n    pass\n\ndef demo_real_world_use_cases():\n    \"\"\"Demonstrate real-world use cases.\"\"\"\n    pass\n\ndef demo_conclusion():\n    \"\"\"Show conclusion and call to action.\"\"\"\n    pass\n\ndef main():\n    \"\"\"Run the complete demo.\"\"\"\n    pass\n```\n--- File: encypher/examples/fastapi_example.py ---\n```python\n\"\"\"\nFastAPI Example Implementation for EncypherAI\n\nThis example demonstrates how to integrate EncypherAI with FastAPI\nto create a simple API that encodes metadata into text and decodes it.\n\"\"\"\n\nfrom datetime import datetime, timezone\nfrom typing import Any, Dict, List, Optional\nfrom fastapi import FastAPI, HTTPException\nfrom fastapi.responses import StreamingResponse\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import AsyncGenerator\n\nclass EncodeRequest(BaseModel):\n    text: str = Field(..., description=\"Text to encode metadata into\")\n    model_id: Optional[str] = Field(None, description=\"Model ID to embed\")\n    metadata: Optional[Dict[str, Any]] = Field(None, description=\"Additional metadata to embed\")\n    target: Optional[str] = Field(\n        \"whitespace\",\n        description=\"Where to embed metadata (whitespace, punctuation, first_letter, last_letter, all_characters)\",\n    )\n\nclass EncodeResponse(BaseModel):\n    encoded_text: str = Field(..., description=\"Text with encoded metadata\")\n    metadata: Dict[str, Any] = Field(..., description=\"Metadata that was encoded\")\n\nclass DecodeRequest(BaseModel):\n    text: str = Field(..., description=\"Text with encoded metadata to decode\")\n\nclass DecodeResponse(BaseModel):\n    original_text: str = Field(..., description=\"Original text without metadata\")\n    metadata: Optional[Dict[str, Any]] = Field(None, description=\"Extracted metadata or None if not found\")\n    is_valid: bool = Field(..., description=\"Whether the metadata is valid\")\n\nclass StreamRequest(BaseModel):\n    text_chunks: List[str] = Field(..., description=\"List of text chunks to simulate streaming\")\n    model_id: Optional[str] = Field(None, description=\"Model ID to embed\")\n    metadata: Optional[Dict[str, Any]] = Field(None, description=\"Additional metadata to embed\")\n    metadata_target: Optional[str] = Field(\"whitespace\", description=\"Where to embed metadata\")\n    encode_first_chunk_only: Optional[bool] = Field(True, description=\"Whether to encode metadata only in the first chunk\")\n\n@app.post(\"/encode\", response_model=EncodeResponse)\nasync def encode_text(request: EncodeRequest) -> EncodeResponse:\n    \"\"\"\n    Encode metadata into text using Unicode variation selectors.\n    \"\"\"\n    pass\n\n@app.post(\"/decode\", response_model=DecodeResponse)\nasync def decode_text(request: DecodeRequest) -> DecodeResponse:\n    \"\"\"\n    Decode metadata from text with embedded Unicode variation selectors.\n    \"\"\"\n    pass\n\n@app.post(\"/stream\")\nasync def stream_text(request: StreamRequest) -> StreamingResponse:\n    \"\"\"\n    Simulate streaming text with metadata encoding.\n    \"\"\"\n    pass\n```\n--- File: encypher/examples/litellm_integration.py ---\n```python\n\"\"\"\nLiteLLM Integration Example for EncypherAI\n\nThis example demonstrates how to integrate EncypherAI with LiteLLM\nto encode metadata into LLM responses.\n\"\"\"\n\nfrom datetime import datetime, timezone\nfrom typing import Any, AsyncGenerator, Dict, List, Optional, Union\nfrom fastapi import FastAPI, HTTPException\nfrom fastapi.openapi.docs import get_swagger_ui_html\nfrom fastapi.responses import HTMLResponse, StreamingResponse\nfrom pydantic import BaseModel, Field\n\n@app.get(\"/swagger\", include_in_schema=False)\nasync def custom_swagger_ui_html() -> HTMLResponse:\n    pass\n\nclass ChatMessage(BaseModel):\n    \"\"\"A chat message in the conversation.\"\"\"\n    role: str = Field(description=\"Message role (system, user, assistant)\", example=\"user\")\n    content: str = Field(description=\"Message content\", example=\"What is the capital of France?\")\n\nclass ChatRequest(BaseModel):\n    \"\"\"Request model for chat completions.\"\"\"\n    messages: List[ChatMessage] = Field(description=\"List of chat messages in the conversation\")\n    model: str = Field(description=\"LLM model to use\", example=\"gpt-3.5-turbo\")\n    temperature: Optional[float] = Field(0.7, description=\"Sampling temperature (0.0 to 1.0)\", ge=0.0, le=1.0)\n    max_tokens: Optional[int] = Field(None, description=\"Maximum tokens to generate\", gt=0)\n    stream: Optional[bool] = Field(False, description=\"Whether to stream the response\")\n    metadata_target: Optional[str] = Field(\n        \"whitespace\",\n        description=\"Where to embed metadata (whitespace, punctuation, first_letter)\",\n    )\n    encode_first_chunk_only: Optional[bool] = Field(\n        True,\n        description=\"Whether to encode metadata only in the first chunk when streaming\",\n    )\n\nclass ChatResponse(BaseModel):\n    \"\"\"Response model for chat completions.\"\"\"\n    model: str = Field(description=\"Model used for generation\", example=\"gpt-3.5-turbo\")\n    content: str = Field(description=\"Generated content with embedded metadata\")\n    metadata: Dict[str, Any] = Field(description=\"Metadata embedded in the response\")\n\n@app.post(\"/v1/chat/completions\", response_model=ChatResponse, tags=[\"chat\"])\nasync def chat_completions(\n    request: ChatRequest,\n) -> Union[ChatResponse, StreamingResponse]:\n    \"\"\"\n    Generate a chat completion with metadata encoding.\n\n    Args:\n        request (ChatRequest): The chat completion request parameters\n\n    Returns:\n        ChatResponse: The generated response with embedded metadata\n\n    Raises:\n        HTTPException: If there's an error generating the completion\n    \"\"\"\n    pass\n\nasync def stream_chat_completion(request: ChatRequest, messages: List[Dict[str, str]]) -> AsyncGenerator[str, None]:\n    \"\"\"\n    Stream a chat completion with metadata encoding.\n\n    Args:\n        request (ChatRequest): The chat completion request parameters\n        messages (List[Dict[str, str]]): LiteLLM-formatted messages\n\n    Yields:\n        Streaming response chunks with metadata\n    \"\"\"\n    pass\n\n@app.get(\"/status\", tags=[\"status\"])\nasync def get_status() -> Dict[str, Any]:\n    \"\"\"\n    Get the current status of the API.\n\n    Returns:\n        dict: Status information including version and health status\n    \"\"\"\n    pass\n```\n--- File: encypher/core/__init__.py ---\n```python\n\"\"\"\nCore encoding and decoding functionality for EncypherAI.\n\"\"\"\n```\n--- File: encypher/core/unicode_metadata.py ---\n```python\n\"\"\"\nUnicode Metadata Embedding Utility for EncypherAI\n\nThis module provides utilities for embedding metadata (model info, timestamps)\ninto text using Unicode variation selectors without affecting readability.\n\"\"\"\n\nimport re\nfrom datetime import date, datetime, timezone\nfrom typing import Any, Callable, Dict, List, Literal, Optional, Tuple, Union, cast\nfrom cryptography.hazmat.primitives.asymmetric.ed25519 import Ed25519PrivateKey\nfrom cryptography.hazmat.primitives.asymmetric.types import PrivateKeyTypes, PublicKeyTypes\nfrom deprecated import deprecated\n\nfrom .constants import MetadataTarget\nfrom .crypto_utils import BasicPayload, ManifestPayload, OuterPayload\n\nclass UnicodeMetadata:\n    \"\"\"\n    Utility class for embedding and extracting metadata using Unicode\n    variation selectors.\n    \"\"\"\n\n    # Variation selectors block (VS1-VS16: U+FE00 to U+FE0F)\n    VARIATION_SELECTOR_START: int = 0xFE00\n    VARIATION_SELECTOR_END: int = 0xFE0F\n\n    # Variation selectors supplement (VS17-VS256: U+E0100 to U+E01EF)\n    VARIATION_SELECTOR_SUPPLEMENT_START: int = 0xE0100\n    VARIATION_SELECTOR_SUPPLEMENT_END: int = 0xE01EF\n\n    @classmethod\n    def to_variation_selector(cls, byte: int) -> Optional[str]:\n        \"\"\"\n        Convert a byte to a variation selector character\n\n        Args:\n            byte: Byte value (0-255)\n\n        Returns:\n            Unicode variation selector character or None if byte is out of range\n        \"\"\"\n        pass\n\n    @classmethod\n    def from_variation_selector(cls, code_point: int) -> Optional[int]:\n        \"\"\"\n        Convert a variation selector code point to a byte\n\n        Args:\n            code_point: Unicode code point\n\n        Returns:\n            Byte value (0-255) or None if not a variation selector\n        \"\"\"\n        pass\n\n    @classmethod\n    def encode(cls, emoji: str, text: str) -> str:\n        \"\"\"\n        Encode text into an emoji using Unicode variation selectors\n\n        Args:\n            emoji: Base character to encode the text into\n            text: Text to encode\n\n        Returns:\n            Encoded string with the text hidden in variation selectors\n        \"\"\"\n        pass\n\n    @classmethod\n    def decode(cls, text: str) -> str:\n        \"\"\"\n        Decode text from Unicode variation selectors\n\n        Args:\n            text: Text with embedded variation selectors\n\n        Returns:\n            Decoded text\n        \"\"\"\n        pass\n\n    @classmethod\n    def extract_bytes(cls, text: str) -> bytes:\n        \"\"\"\n        Extract bytes from Unicode variation selectors\n\n        Args:\n            text: Text with embedded variation selectors\n\n        Returns:\n            Bytes extracted from variation selectors\n        \"\"\"\n        pass\n\n    @classmethod\n    def _format_timestamp(cls, ts: Optional[Union[str, datetime, date, int, float]]) -> Optional[str]:\n        \"\"\"Helper to format various timestamp inputs into ISO 8601 UTC string.\n\n        Args:\n            ts: The timestamp input. Can be None, an ISO 8601 string,\n                a datetime object, a date object, or an int/float epoch\n                timestamp.\n\n        Returns:\n            The timestamp formatted as an ISO 8601 string in UTC (e.g., \"YYYY-MM-DDTHH:MM:SSZ\"),\n            or None if the input was None.\n\n        Raises:\n            ValueError: If the input is an invalid timestamp value or format.\n            TypeError: If the input type is not supported.\n        \"\"\"\n        pass\n\n    @classmethod\n    def find_targets(\n        cls,\n        text: str,\n        target: Optional[Union[str, MetadataTarget]] = None,\n    ) -> List[int]:\n        \"\"\"\n        Find indices of characters in text where metadata can be embedded.\n\n        Args:\n            text: The text to find targets in.\n            target: Where to embed metadata ('whitespace', 'punctuation', etc.,\n                    or MetadataTarget enum).\n\n        Returns:\n            List of indices where metadata can be embedded.\n\n        Raises:\n            ValueError: If target is an invalid string.\n        \"\"\"\n        pass\n\n    @classmethod\n    def embed_metadata(\n        cls,\n        text: str,\n        private_key: PrivateKeyTypes,\n        signer_id: str,\n        metadata_format: Literal[\"basic\", \"manifest\"] = \"basic\",\n        model_id: Optional[str] = None,\n        timestamp: Optional[Union[str, datetime, date, int, float]] = None,\n        target: Optional[Union[str, MetadataTarget]] = None,\n        custom_metadata: Optional[Dict[str, Any]] = None,\n        claim_generator: Optional[str] = None,\n        actions: Optional[List[Dict[str, Any]]] = None,\n        ai_info: Optional[Dict[str, Any]] = None,\n        custom_claims: Optional[Dict[str, Any]] = None,\n        distribute_across_targets: bool = False,\n    ) -> str:\n        \"\"\"\n        Embed metadata into text using Unicode variation selectors, signing with a private key.\n\n        When using 'manifest' format, this method implements a C2PA-inspired approach for\n        content provenance and authenticity, adapted specifically for plain-text environments\n        where traditional file-based embedding methods aren't applicable. The manifest structure\n        parallels C2PA's concepts of assertions, claim generators, and cryptographic integrity.\n\n        Args:\n            text: The text to embed metadata into.\n            private_key: The Ed25519 private key object for signing.\n            signer_id: A string identifying the signer/key pair (used for\n                       verification lookup).\n            metadata_format: The format for the metadata payload ('basic' or 'manifest').\n                             Default is 'basic'. When set to 'manifest', uses a\n                             C2PA-inspired structured format.\n            model_id: Model identifier (used in 'basic' and optionally in\n                      'manifest' ai_info).\n            timestamp: Timestamp (datetime, ISO string, int/float epoch). Stored as\n                       ISO 8601 UTC string.\n                       **This field is mandatory.**\n            target: Where to embed metadata ('whitespace', 'punctuation', etc.,\n                    or MetadataTarget enum).\n            custom_metadata: Dictionary for custom fields (used in 'basic' payload).\n            claim_generator: Claim generator string (used in 'manifest' format).\n                             Similar to C2PA's concept of identifying the\n                             software/tool that generated the claim.\n            actions: List of action dictionaries (used in 'manifest' format).\n                     Conceptually similar to C2PA assertions about operations\n                     performed on the content.\n            ai_info: Dictionary with AI-specific info (used in 'manifest' format).\n                     Represents a custom assertion type focused on AI-specific\n                     attributes.\n            custom_claims: Dictionary for custom C2PA-like claims (used in\n                           'manifest' format).\n            distribute_across_targets: If True, distribute bits across multiple\n                                       targets if needed.\n\n        Returns:\n            The text with embedded metadata and digital signature.\n\n        Raises:\n            ValueError: If 'timestamp' is not provided, if the target is invalid,\n                        if not enough embedding locations are found, or if the\n                        metadata + signature is too large.\n        \"\"\"\n        pass\n\n    @classmethod\n    def _bytes_to_variation_selectors(cls, data: bytes) -> List[str]:\n        \"\"\"Convert bytes into a list of Unicode variation selector characters.\"\"\"\n        pass\n\n    @classmethod\n    def verify_and_extract_metadata(\n        cls,\n        text: str,\n        public_key_provider: Callable[[str], Optional[PublicKeyTypes]],\n        return_payload_on_failure: bool = False,\n    ) -> Tuple[Union[BasicPayload, ManifestPayload, None], bool, Optional[str]]:\n        \"\"\"\n        Extracts embedded metadata, verifies its signature using a public key,\n        and returns the payload, verification status, and signer ID.\n\n        This verification process implements a C2PA-inspired approach for content\n        authenticity verification, adapted specifically for plain-text environments.\n        Similar to how C2PA verifies digital signatures in media files to establish\n        provenance and integrity, this method verifies cryptographic signatures\n        embedded directly within text using Unicode variation selectors.\n\n        Args:\n            text: Text potentially containing embedded metadata.\n            public_key_provider: A callable function that takes a signer_id (str)\n                                 and returns the corresponding Ed25519PublicKey\n                                 object or None if the key is not found.\n                                 This resolver pattern enables flexible key management\n                                 similar to C2PA's approach for signature verification.\n            return_payload_on_failure: If True, return the payload even when verification fails.\n                                      If False (default), return None for the payload when verification fails.\n\n        Returns:\n            A tuple containing:\n            - The extracted inner payload (Dict[str, Any], basic or manifest) or None\n              if extraction/verification fails (unless return_payload_on_failure is True).\n            - Verification status (bool): True if the signature is valid, False otherwise.\n            - The signer_id (str) found in the metadata, or None if extraction fails.\n\n        Raises:\n            TypeError: If public_key_provider returns an invalid key type.\n            KeyError: If public_key_provider raises an error (e.g., key not found).\n            InvalidSignature: If the signature verification process itself fails.\n            Exception: Can propagate errors from base64 decoding or payload serialization.\n        \"\"\"\n        pass\n\n    @classmethod\n    def _extract_outer_payload(cls, text: str) -> Optional[OuterPayload]:\n        \"\"\"Extracts the raw OuterPayload dict from embedded bytes.\n\n        Finds the metadata markers, extracts the embedded bytes, decodes the\n        outer JSON structure, and returns the OuterPayload TypedDict if valid.\n\n        Args:\n            text: The text containing potentially embedded metadata.\n\n        Returns:\n            The extracted OuterPayload dictionary if found and successfully parsed,\n            otherwise None.\n\n        Raises:\n            (Indirectly via called methods) UnicodeDecodeError, json.JSONDecodeError, TypeError\n        \"\"\"\n        pass\n\n    @classmethod\n    def verify_metadata(\n        cls,\n        text: str,\n        public_key_provider: Callable[[str], Optional[PublicKeyTypes]],\n        return_payload_on_failure: bool = False,\n    ) -> Tuple[Union[BasicPayload, ManifestPayload, None], bool, Optional[str]]:\n        \"\"\"\n        Verify and extract metadata from text embedded using Unicode variation selectors and a public key.\n\n        Args:\n            text: Text with embedded metadata\n            public_key_provider: A callable function that takes a signer_id (str)\n                                 and returns the corresponding Ed25519PublicKey\n                                 object or None if the key is not found.\n            return_payload_on_failure: If True, return the payload even when verification fails.\n                                      If False (default), return None for the payload when verification fails.\n\n        Returns:\n            A tuple containing:\n            - The extracted inner payload (Dict[str, Any], basic or manifest) or None\n              if extraction/verification fails (unless return_payload_on_failure is True).\n            - Verification status (bool): True if the signature is valid, False otherwise.\n            - The signer_id (str) found in the metadata, or None if extraction fails.\n\n        Raises:\n            TypeError: If public_key_provider returns an invalid key type.\n            KeyError: If public_key_provider raises an error (e.g., key not found).\n            InvalidSignature: If the signature verification process itself fails.\n            Exception: Can propagate errors from base64 decoding or payload serialization.\n        \"\"\"\n        pass\n\n    @classmethod\n    def extract_metadata(cls, text: str) -> Union[BasicPayload, ManifestPayload, None]:\n        \"\"\"\n        Extracts embedded metadata from text without verifying its signature.\n\n        Finds the metadata markers, extracts the embedded bytes, decodes the\n        outer JSON structure, and returns the inner 'payload' dictionary.\n\n        Similar to how C2PA allows for inspection of manifest contents separate\n        from verification, this method enables access to the embedded provenance\n        information without cryptographic validation. This is useful for debugging,\n        analysis, or when working with content where verification isn't the primary goal.\n        When using the 'manifest' format, the extracted payload will contain C2PA-inspired\n        structured provenance information.\n\n        Args:\n            text: The text containing potentially embedded metadata.\n\n        Returns:\n            The extracted inner metadata dictionary if found and successfully parsed,\n            otherwise None.\n        \"\"\"\n        pass\n\n    @classmethod\n    @deprecated(\n        version=\"1.1.0\",\n        reason=\"HMAC verification is deprecated. Use Ed25519 digital signatures via the primary verify_metadata method.\",\n    )\n    def _verify_metadata_hmac_deprecated(cls, text: str, hmac_secret_key: str) -> Tuple[Dict[str, Any], bool]:\n        \"\"\"\n        Verify and extract metadata from text embedded using Unicode variation selectors and an HMAC secret key.\n\n        Args:\n            text: Text with embedded metadata\n            hmac_secret_key: HMAC secret key for verification\n\n        Returns:\n            A tuple containing:\n            - The extracted inner payload (Dict[str, Any], basic or manifest) or empty dict if extraction fails.\n            - Verification status (bool): True if the signature is valid, False otherwise.\n        \"\"\"\n        pass\n```\n--- File: encypher/core/constants.py ---\n```python\n\"\"\"\nConstants for the EncypherAI core module.\n\nThis module contains constants used throughout the EncypherAI core module,\nparticularly for metadata embedding and extraction.\n\"\"\"\n\nfrom enum import Enum, auto\n\nclass MetadataTarget(Enum):\n    \"\"\"Enum for metadata embedding targets.\"\"\"\n\n    NONE = auto()\n    WHITESPACE = auto()\n    PUNCTUATION = auto()\n    FIRST_LETTER = auto()\n    LAST_LETTER = auto()\n    ALL_CHARACTERS = auto()\n```\n--- File: encypher/core/crypto_utils.py ---\n```python\nfrom typing import Any, Dict, List, Literal, Optional, Tuple, TypedDict, Union, cast\nfrom cryptography.hazmat.primitives.asymmetric import ed25519\nfrom cryptography.hazmat.primitives.asymmetric.types import PrivateKeyTypes, PublicKeyTypes\n\nclass BasicPayload(TypedDict):\n    \"\"\"Structure for the 'basic' metadata format payload.\"\"\"\n\n    model_id: Optional[str]\n    timestamp: Optional[str]  # Recommended: ISO 8601 UTC format string\n    custom_metadata: Dict[str, Any]\n\nclass ManifestAction(TypedDict):\n    \"\"\"\n    Structure for an assertion within the 'manifest' payload.\n\n    Conceptually similar to C2PA assertions, these represent\n    operations performed on the content. The naming convention for assertion labels\n    follows C2PA patterns (e.g., \"c2pa.created\", \"c2pa.transcribed\") to\n    maintain conceptual alignment with the broader provenance ecosystem.\n    \"\"\"\n\n    label: str  # e.g., \"c2pa.created\", \"c2pa.transcribed\"\n    when: str  # ISO 8601 UTC format string\n    # Add other optional C2PA assertion fields if needed, e.g.:\n    # softwareAgent: Optional[str]\n    # digitalSourceType: Optional[str]\n\nclass ManifestAiInfo(TypedDict, total=False):\n    \"\"\"\n    Optional structure for AI-specific info within the 'manifest' payload.\n\n    This represents a custom assertion type focused on AI-specific attributes,\n    similar to how C2PA allows for specialized assertion types. For AI-generated\n    content, this provides critical provenance information about the model used.\n    \"\"\"\n\n    model_id: str\n    model_version: Optional[str]\n    # Add other relevant AI fields\n\nclass ManifestPayload(TypedDict):\n    \"\"\"\n    Structure for the 'manifest' metadata format payload.\n\n    Inspired by the Coalition for Content Provenance and Authenticity (C2PA) manifests,\n    this structure provides a standardized way to embed provenance information\n    directly within text content. While C2PA focuses on rich media file formats,\n    EncypherAI adapts these concepts specifically for plain-text use cases where\n    traditional file embedding methods aren't applicable.\n\n    The manifest includes information about:\n    - The software/tool that generated the claim (claim_generator)\n    - A list of assertions about the content (conceptually similar to C2PA assertions)\n    - AI-specific assertion when relevant (ai_assertion)\n    - Custom claims for extensibility\n    - Timestamp information\n    \"\"\"\n\n    claim_generator: str\n    assertions: List[ManifestAction]\n    ai_assertion: Optional[ManifestAiInfo]\n    custom_claims: Dict[str, Any]\n    timestamp: Optional[str]  # ISO 8601 UTC format string (Consider if needed alongside assertions' 'when')\n\nclass OuterPayload(TypedDict):\n    \"\"\"\n    The complete outer structure embedded into the text.\n\n    This structure wraps either a basic payload or a C2PA-inspired manifest payload,\n    adding cryptographic integrity through digital signatures. Similar to C2PA's\n    approach of ensuring tamper-evidence through cryptographic signing, this\n    structure enables verification of content authenticity and integrity in\n    plain-text environments.\n    \"\"\"\n\n    format: Literal[\"basic\", \"manifest\"]\n    signer_id: str\n    payload: Union[BasicPayload, ManifestPayload]  # The signed part\n    signature: str  # Base64 encoded signature string\n\ndef generate_key_pair() -> Tuple[ed25519.Ed25519PrivateKey, ed25519.Ed25519PublicKey]:\n    \"\"\"\n    Generates an Ed25519 key pair.\n\n    Returns:\n        Tuple containing the private and public keys.\n    \"\"\"\n    pass\n\ndef sign_payload(private_key: PrivateKeyTypes, payload_bytes: bytes) -> bytes:\n    \"\"\"\n    Signs the payload bytes using the private key (Ed25519).\n\n    Args:\n        private_key: The Ed25519 private key object.\n        payload_bytes: The canonical bytes of the payload to sign.\n\n    Returns:\n        The signature bytes.\n\n    Raises:\n        TypeError: If the provided key is not an Ed25519 private key.\n    \"\"\"\n    pass\n\ndef verify_signature(public_key: PublicKeyTypes, payload_bytes: bytes, signature: bytes) -> bool:\n    \"\"\"\n    Verifies the signature against the payload using the public key (Ed25519).\n\n    Args:\n        public_key: The Ed25519 public key object.\n        payload_bytes: The canonical bytes of the payload that was signed.\n        signature: The signature bytes to verify.\n\n    Returns:\n        True if the signature is valid, False otherwise.\n\n    Raises:\n        TypeError: If the provided key is not an Ed25519 public key.\n    \"\"\"\n    pass\n\ndef serialize_payload(payload: Dict[str, Any]) -> bytes:\n    \"\"\"\n    Serializes the metadata payload dictionary into canonical JSON bytes.\n    Ensures keys are sorted and uses compact separators for consistency.\n\n    Args:\n        payload: The dictionary payload.\n\n    Returns:\n        UTF-8 encoded bytes of the canonical JSON string.\n    \"\"\"\n    pass\n\ndef load_private_key(key_data: Union[bytes, str], password: Optional[bytes] = None) -> ed25519.Ed25519PrivateKey:\n    \"\"\"\n    Loads an Ed25519 private key from PEM-encoded bytes or string,\n    or from raw bytes (32 bytes).\n\n    Args:\n        key_data: PEM string/bytes or raw private key bytes.\n        password: Optional password for encrypted PEM keys.\n\n    Returns:\n        Ed25519 private key object.\n\n    Raises:\n        ValueError: If the key format is invalid or unsupported.\n        TypeError: If key_data has an invalid type.\n    \"\"\"\n    pass\n\ndef load_public_key(key_data: Union[bytes, str]) -> ed25519.Ed25519PublicKey:\n    \"\"\"\n    Loads an Ed25519 public key from PEM-encoded bytes or string,\n    or from raw bytes (32 bytes).\n\n    Args:\n        key_data: PEM string/bytes or raw public key bytes.\n\n    Returns:\n        Ed25519 public key object.\n\n    Raises:\n        ValueError: If the key format is invalid or unsupported.\n        TypeError: If key_data has an invalid type.\n    \"\"\"\n    pass\n```\n--- File: encypher/utils/__init__.py ---\n```python\n\"\"\"\nUtility functions for EncypherAI.\n\"\"\"\n```",
        "minimal_code_skeleton": "--- File: encypher/config/settings.py ---\n```python\nclass Settings:\n    \"\"\"\n    Settings class for EncypherAI configuration.\n\n    This class handles loading configuration from environment variables\n    and configuration files, with sensible defaults.\n    \"\"\"\n\n    def __init__(\n        self,\n        config_file: Optional[Union[str, Path]] = None,\n        env_prefix: str = \"ENCYPHER_\",\n    ):\n        \"\"\"\n        Initialize settings from environment variables and/or config file.\n\n        Args:\n            config_file: Path to configuration file (JSON)\n            env_prefix: Prefix for environment variables\n        \"\"\"\n        pass\n\n    def get(self, key: str, default: Any = None) -> Any:\n        \"\"\"\n        Get a configuration value.\n\n        Args:\n            key: Configuration key\n            default: Default value if key not found\n\n        Returns:\n            Configuration value or default\n        \"\"\"\n        pass\n\n    def get_metadata_target(self) -> MetadataTarget:\n        \"\"\"\n        Get the metadata target as an enum value.\n\n        Returns:\n            MetadataTarget enum value\n        \"\"\"\n        pass\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"\n        Get the configuration as a dictionary.\n\n        Returns:\n            Configuration dictionary\n        \"\"\"\n        pass\n```\n--- File: encypher/core/constants.py ---\n```python\nclass MetadataTarget(Enum):\n    \"\"\"Enum for metadata embedding targets.\"\"\"\n\n    NONE = auto()\n    WHITESPACE = auto()\n    PUNCTUATION = auto()\n    FIRST_LETTER = auto()\n    LAST_LETTER = auto()\n    ALL_CHARACTERS = auto()\n```\n--- File: encypher/core/crypto_utils.py ---\n```python\nclass BasicPayload(TypedDict):\n    \"\"\"Structure for the 'basic' metadata format payload.\"\"\"\n\n    model_id: Optional[str]\n    timestamp: Optional[str]  # Recommended: ISO 8601 UTC format string\n    custom_metadata: Dict[str, Any]\n\n\nclass ManifestAction(TypedDict):\n    \"\"\"\n    Structure for an assertion within the 'manifest' payload.\n\n    Conceptually similar to C2PA assertions, these represent\n    operations performed on the content. The naming convention for assertion labels\n    follows C2PA patterns (e.g., \"c2pa.created\", \"c2pa.transcribed\") to\n    maintain conceptual alignment with the broader provenance ecosystem.\n    \"\"\"\n\n    label: str  # e.g., \"c2pa.created\", \"c2pa.transcribed\"\n    when: str  # ISO 8601 UTC format string\n\n\nclass ManifestAiInfo(TypedDict, total=False):\n    \"\"\"\n    Optional structure for AI-specific info within the 'manifest' payload.\n\n    This represents a custom assertion type focused on AI-specific attributes,\n    similar to how C2PA allows for specialized assertion types. For AI-generated\n    content, this provides critical provenance information about the model used.\n    \"\"\"\n\n    model_id: str\n    model_version: Optional[str]\n\n\nclass ManifestPayload(TypedDict):\n    \"\"\"\n    Structure for the 'manifest' metadata format payload.\n\n    Inspired by the Coalition for Content Provenance and Authenticity (C2PA) manifests,\n    this structure provides a standardized way to embed provenance information\n    directly within text content. While C2PA focuses on rich media file formats,\n    EncypherAI adapts these concepts specifically for plain-text use cases where\n    traditional file embedding methods aren't applicable.\n\n    The manifest includes information about:\n    - The software/tool that generated the claim (claim_generator)\n    - A list of assertions about the content (conceptually similar to C2PA assertions)\n    - AI-specific assertion when relevant (ai_assertion)\n    - Custom claims for extensibility\n    - Timestamp information\n    \"\"\"\n\n    claim_generator: str\n    assertions: List[ManifestAction]\n    ai_assertion: Optional[ManifestAiInfo]\n    custom_claims: Dict[str, Any]\n    timestamp: Optional[str]  # ISO 8601 UTC format string (Consider if needed alongside assertions' 'when')\n\n\nclass OuterPayload(TypedDict):\n    \"\"\"\n    The complete outer structure embedded into the text.\n\n    This structure wraps either a basic payload or a C2PA-inspired manifest payload,\n    adding cryptographic integrity through digital signatures. Similar to C2PA's\n    approach of ensuring tamper-evidence through cryptographic signing, this\n    structure enables verification of content authenticity and integrity in\n    plain-text environments.\n    \"\"\"\n\n    format: Literal[\"basic\", \"manifest\"]\n    signer_id: str\n    payload: Union[BasicPayload, ManifestPayload]  # The signed part\n    signature: str  # Base64 encoded signature string\n\n\ndef generate_key_pair() -> Tuple[ed25519.Ed25519PrivateKey, ed25519.Ed25519PublicKey]:\n    \"\"\"\n    Generates an Ed25519 key pair.\n\n    Returns:\n        Tuple containing the private and public keys.\n    \"\"\"\n    pass\n\ndef sign_payload(private_key: PrivateKeyTypes, payload_bytes: bytes) -> bytes:\n    \"\"\"\n    Signs the payload bytes using the private key (Ed25519).\n\n    Args:\n        private_key: The Ed25519 private key object.\n        payload_bytes: The canonical bytes of the payload to sign.\n\n    Returns:\n        The signature bytes.\n\n    Raises:\n        TypeError: If the provided key is not an Ed25519 private key.\n    \"\"\"\n    pass\n\ndef verify_signature(public_key: PublicKeyTypes, payload_bytes: bytes, signature: bytes) -> bool:\n    \"\"\"\n    Verifies the signature against the payload using the public key (Ed25519).\n\n    Args:\n        public_key: The Ed25519 public key object.\n        payload_bytes: The canonical bytes of the payload that was signed.\n        signature: The signature bytes to verify.\n\n    Returns:\n        True if the signature is valid, False otherwise.\n\n    Raises:\n        TypeError: If the provided key is not an Ed25519 public key.\n    \"\"\"\n    pass\n\ndef serialize_payload(payload: Dict[str, Any]) -> bytes:\n    \"\"\"\n    Serializes the metadata payload dictionary into canonical JSON bytes.\n    Ensures keys are sorted and uses compact separators for consistency.\n\n    Args:\n        payload: The dictionary payload.\n\n    Returns:\n        UTF-8 encoded bytes of the canonical JSON string.\n    \"\"\"\n    pass\n\ndef load_private_key(key_data: Union[bytes, str], password: Optional[bytes] = None) -> ed25519.Ed25519PrivateKey:\n    \"\"\"\n    Loads an Ed25519 private key from PEM-encoded bytes or string,\n    or from raw bytes (32 bytes).\n\n    Args:\n        key_data: PEM string/bytes or raw private key bytes.\n        password: Optional password for encrypted PEM keys.\n\n    Returns:\n        Ed25519 private key object.\n\n    Raises:\n        ValueError: If the key format is invalid or unsupported.\n        TypeError: If key_data has an invalid type.\n    \"\"\"\n    pass\n\ndef load_public_key(key_data: Union[bytes, str]) -> ed25519.Ed25519PublicKey:\n    \"\"\"\n    Loads an Ed25519 public key from PEM-encoded bytes or string,\n    or from raw bytes (32 bytes).\n\n    Args:\n        key_data: PEM string/bytes or raw public key bytes.\n\n    Returns:\n        Ed25519 public key object.\n\n    Raises:\n        ValueError: If the key format is invalid or unsupported.\n        TypeError: If key_data has an invalid type.\n    \"\"\"\n    pass\n```\n--- File: encypher/core/unicode_metadata.py ---\n```python\nclass UnicodeMetadata:\n    \"\"\"\n    Utility class for embedding and extracting metadata using Unicode\n    variation selectors.\n    \"\"\"\n\n    VARIATION_SELECTOR_START: int = 0xFE00\n    VARIATION_SELECTOR_END: int = 0xFE0F\n    VARIATION_SELECTOR_SUPPLEMENT_START: int = 0xE0100\n    VARIATION_SELECTOR_SUPPLEMENT_END: int = 0xE01EF\n\n    @classmethod\n    def to_variation_selector(cls, byte: int) -> Optional[str]:\n        \"\"\"\n        Convert a byte to a variation selector character\n\n        Args:\n            byte: Byte value (0-255)\n\n        Returns:\n            Unicode variation selector character or None if byte is out of range\n        \"\"\"\n        pass\n\n    @classmethod\n    def from_variation_selector(cls, code_point: int) -> Optional[int]:\n        \"\"\"\n        Convert a variation selector code point to a byte\n\n        Args:\n            code_point: Unicode code point\n\n        Returns:\n            Byte value (0-255) or None if not a variation selector\n        \"\"\"\n        pass\n\n    @classmethod\n    def encode(cls, emoji: str, text: str) -> str:\n        \"\"\"\n        Encode text into an emoji using Unicode variation selectors\n\n        Args:\n            emoji: Base character to encode the text into\n            text: Text to encode\n\n        Returns:\n            Encoded string with the text hidden in variation selectors\n        \"\"\"\n        pass\n\n    @classmethod\n    def decode(cls, text: str) -> str:\n        \"\"\"\n        Decode text from Unicode variation selectors\n\n        Args:\n            text: Text with embedded variation selectors\n\n        Returns:\n            Decoded text\n        \"\"\"\n        pass\n\n    @classmethod\n    def extract_bytes(cls, text: str) -> bytes:\n        \"\"\"\n        Extract bytes from Unicode variation selectors\n\n        Args:\n            text: Text with embedded variation selectors\n\n        Returns:\n            Bytes extracted from variation selectors\n        \"\"\"\n        pass\n\n    @classmethod\n    def embed_metadata(\n        cls,\n        text: str,\n        private_key: PrivateKeyTypes,\n        signer_id: str,\n        metadata_format: Literal[\"basic\", \"manifest\"] = \"basic\",\n        model_id: Optional[str] = None,\n        timestamp: Optional[Union[str, datetime, date, int, float]] = None,\n        target: Optional[Union[str, MetadataTarget]] = None,\n        custom_metadata: Optional[Dict[str, Any]] = None,\n        claim_generator: Optional[str] = None,\n        actions: Optional[List[Dict[str, Any]]] = None,\n        ai_info: Optional[Dict[str, Any]] = None,\n        custom_claims: Optional[Dict[str, Any]] = None,\n        distribute_across_targets: bool = False,\n    ) -> str:\n        \"\"\"\n        Embed metadata into text using Unicode variation selectors, signing with a private key.\n\n        When using 'manifest' format, this method implements a C2PA-inspired approach for\n        content provenance and authenticity, adapted specifically for plain-text environments\n        where traditional file-based embedding methods aren't applicable. The manifest structure\n        parallels C2PA's concepts of assertions, claim generators, and cryptographic integrity.\n\n        Args:\n            text: The text to embed metadata into.\n            private_key: The Ed25519 private key object for signing.\n            signer_id: A string identifying the signer/key pair (used for\n                       verification lookup).\n            metadata_format: The format for the metadata payload ('basic' or 'manifest').\n                             Default is 'basic'. When set to 'manifest', uses a\n                             C2PA-inspired structured format.\n            model_id: Model identifier (used in 'basic' and optionally in\n                      'manifest' ai_info).\n            timestamp: Timestamp (datetime, ISO string, int/float epoch). Stored as\n                       ISO 8601 UTC string.\n                       **This field is mandatory.**\n            target: Where to embed metadata ('whitespace', 'punctuation', etc.,\n                    or MetadataTarget enum).\n            custom_metadata: Dictionary for custom fields (used in 'basic' payload).\n            claim_generator: Claim generator string (used in 'manifest' format).\n                             Similar to C2PA's concept of identifying the\n                             software/tool that generated the claim.\n            actions: List of action dictionaries (used in 'manifest' format).\n                     Conceptually similar to C2PA assertions about operations\n                     performed on the content.\n            ai_info: Dictionary with AI-specific info (used in 'manifest' format).\n                     Represents a custom assertion type focused on AI-specific\n                     attributes.\n            custom_claims: Dictionary for custom C2PA-like claims (used in\n                           'manifest' format).\n            distribute_across_targets: If True, distribute bits across multiple\n                                       targets if needed.\n\n        Returns:\n            The text with embedded metadata and digital signature.\n\n        Raises:\n            ValueError: If 'timestamp' is not provided, if the target is invalid,\n                        if not enough embedding locations are found, or if the\n                        metadata + signature is too large.\n        \"\"\"\n        pass\n\n    @classmethod\n    def verify_and_extract_metadata(\n        cls,\n        text: str,\n        public_key_provider: Callable[[str], Optional[PublicKeyTypes]],\n        return_payload_on_failure: bool = False,\n    ) -> Tuple[Union[BasicPayload, ManifestPayload, None], bool, Optional[str]]:\n        \"\"\"\n        Extracts embedded metadata, verifies its signature using a public key,\n        and returns the payload, verification status, and signer ID.\n\n        This verification process implements a C2PA-inspired approach for content\n        authenticity verification, adapted specifically for plain-text environments.\n        Similar to how C2PA verifies digital signatures in media files to establish\n        provenance and integrity, this method verifies cryptographic signatures\n        embedded directly within text using Unicode variation selectors.\n\n        Args:\n            text: Text potentially containing embedded metadata.\n            public_key_provider: A callable function that takes a signer_id (str)\n                                 and returns the corresponding Ed25519PublicKey\n                                 object or None if the key is not found.\n                                 This resolver pattern enables flexible key management\n                                 similar to C2PA's approach for signature verification.\n            return_payload_on_failure: If True, return the payload even when verification fails.\n                                      If False (default), return None for the payload when verification fails.\n\n        Returns:\n            A tuple containing:\n            - The extracted inner payload (Dict[str, Any], basic or manifest) or None\n              if extraction/verification fails (unless return_payload_on_failure is True).\n            - Verification status (bool): True if the signature is valid, False otherwise.\n            - The signer_id (str) found in the metadata, or None if extraction fails.\n\n        Raises:\n            TypeError: If public_key_provider returns an invalid key type.\n            KeyError: If public_key_provider raises an error (e.g., key not found).\n            InvalidSignature: If the signature verification process itself fails.\n            Exception: Can propagate errors from base64 decoding or payload serialization.\n        \"\"\"\n        pass\n\n    @classmethod\n    def extract_metadata(cls, text: str) -> Union[BasicPayload, ManifestPayload, None]:\n        \"\"\"\n        Extracts embedded metadata from text without verifying its signature.\n\n        Finds the metadata markers, extracts the embedded bytes, decodes the\n        outer JSON structure, and returns the inner 'payload' dictionary.\n\n        Similar to how C2PA allows for inspection of manifest contents separate\n        from verification, this method enables access to the embedded provenance\n        information without cryptographic validation. This is useful for debugging,\n        analysis, or when working with content where verification isn't the primary goal.\n        When using the 'manifest' format, the extracted payload will contain C2PA-inspired\n        structured provenance information.\n\n        Args:\n            text: The text containing potentially embedded metadata.\n\n        Returns:\n            The extracted inner metadata dictionary if found and successfully parsed,\n            otherwise None.\n        \"\"\"\n        pass\n```\n--- File: encypher/interop/c2pa.py ---\n```python\ndef encypher_manifest_to_c2pa_like_dict(manifest: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Converts an EncypherAI ManifestPayload to a dictionary using field names\n    conceptually aligned with C2PA assertion structures.\n\n    This function provides a conceptual bridge between EncypherAI's plain-text\n    manifest format and C2PA's rich media manifest structure, enabling potential\n    interoperability between the two approaches.\n\n    Args:\n        manifest: An EncypherAI manifest payload dictionary (can be a TypedDict ManifestPayload\n                 or a regular dict with the same structure)\n\n    Returns:\n        A dictionary with field names aligned with C2PA concepts, containing the\n        same information as the original manifest.\n\n    Example:\n        from encypher.core.crypto_utils import ManifestPayload\n        from encypher.interop.c2pa import encypher_manifest_to_c2pa_like_dict\n\n        # Original EncypherAI manifest\n        manifest = ManifestPayload(\n            claim_generator=\"EncypherAI/1.1.0\",\n            assertions=[{\"label\": \"c2pa.created\", \"when\": \"2025-04-13T12:00:00Z\"}],\n            ai_assertion={\"model_id\": \"gpt-4o\", \"model_version\": \"1.0\"},\n            custom_claims={},\n            timestamp=\"2025-04-13T12:00:00Z\"\n        )\n\n        # Convert to C2PA-like structure\n        c2pa_dict = encypher_manifest_to_c2pa_like_dict(manifest)\n    \"\"\"\n    pass\n\ndef c2pa_like_dict_to_encypher_manifest(data: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Creates an EncypherAI ManifestPayload from a dictionary structured\n    similarly to C2PA assertions. Handles missing fields gracefully.\n\n    This function provides a conceptual bridge from C2PA-like structures\n    to EncypherAI's manifest format, enabling potential interoperability\n    between the two approaches.\n\n    Args:\n        data: A dictionary with C2PA-like structure containing provenance information.\n\n    Returns:\n        An EncypherAI ManifestPayload dictionary that can be used with EncypherAI's\n        embedding functions.\n\n    Example:\n        from encypher.interop.c2pa import c2pa_like_dict_to_encypher_manifest\n\n        # C2PA-like structure\n        c2pa_data = {\n            \"claim_generator\": \"SomeApp/1.0\",\n            \"assertions\": [\n                {\n                    \"label\": \"c2pa.created\",\n                    \"data\": {\"timestamp\": \"2025-04-13T12:00:00Z\"}\n                },\n                {\n                    \"label\": \"ai.model.info\",\n                    \"data\": {\"model_id\": \"gpt-4o\", \"model_version\": \"1.0\"}\n                }\n            ],\n            \"timestamp\": \"2025-04-13T12:00:00Z\"\n        }\n\n        # Convert to EncypherAI manifest\n        manifest = c2pa_like_dict_to_encypher_manifest(c2pa_data)\n    \"\"\"\n    pass\n\ndef get_c2pa_manifest_schema() -> Dict[str, Any]:\n    \"\"\"\n    Returns a JSON Schema representation of the C2PA-like structure used by this module.\n\n    This schema provides documentation for the expected structure of C2PA-like dictionaries\n    used with the conversion functions in this module.\n\n    Returns:\n        A dictionary containing the JSON Schema for C2PA-like structures.\n    \"\"\"\n    pass\n```\n--- File: encypher/streaming/handlers.py ---\n```python\nclass StreamingHandler:\n    \"\"\"\n    Handler for processing streaming chunks from LLM providers and encoding metadata.\n\n    This class ensures that metadata is properly encoded in streaming responses,\n    handling the complexities of partial text chunks while maintaining consistency.\n    \"\"\"\n\n    def __init__(\n        self,\n        metadata: Optional[Dict[str, Any]] = None,\n        target: Union[str, MetadataTarget] = \"whitespace\",\n        encode_first_chunk_only: bool = True,\n        private_key: Optional[PrivateKeyTypes] = None,\n        signer_id: Optional[str] = None,\n        metadata_format: Literal[\"basic\", \"manifest\"] = \"basic\",\n    ):\n        \"\"\"\n        Initialize the streaming handler.\n\n        Args:\n            metadata: Dictionary of metadata to encode. Must include keys required\n                      by the chosen `metadata_format`.\n            target: Where to embed the metadata (whitespace, punctuation, etc.)\n            encode_first_chunk_only: Whether to encode metadata only in the first\n                                     non-empty chunk. Currently, only True is fully\n                                     supported for signature embedding.\n            private_key: The private key for signing the metadata.\n            signer_id: An identifier for the signer (associated with the public key).\n            metadata_format: The structure ('basic' or 'manifest') of the metadata payload.\n\n        Raises:\n            ValueError: If `metadata_format` is invalid, or if `metadata` is provided\n                        without `private_key` and `signer_id`.\n            TypeError: If `metadata`, `encode_first_chunk_only`, `private_key`,\n                       or `signer_id` have incorrect types.\n        \"\"\"\n        pass\n\n    def process_chunk(self, chunk: Union[str, Dict[str, Any]]) -> Union[str, Dict[str, Any]]:\n        \"\"\"\n        Process a streaming chunk and encode metadata if needed.\n\n        This method handles both raw text chunks and structured chunks (like those from OpenAI).\n\n        Args:\n            chunk: Text chunk or dictionary containing a text chunk\n\n        Returns:\n            Processed chunk with encoded metadata, preserving the input chunk type (str or dict).\n\n        Raises:\n            ValueError: If the underlying text processing (_process_text_chunk) fails.\n            KeyError: If the expected keys ('choices', 'delta', 'content', etc.) are missing.\n            IndexError: If the 'choices' list is empty.\n        \"\"\"\n        pass\n\n    def finalize(self) -> Optional[str]:\n        \"\"\"\n        Finalize the stream and return any accumulated text with encoded metadata.\n\n        This method should be called after all chunks have been processed to handle\n        any remaining accumulated text that hasn't been processed yet.\n\n        Returns:\n            Processed accumulated text with encoded metadata, or None if no text accumulated\n\n        Raises:\n            ValueError: If UnicodeMetadata.embed_metadata fails (e.g., not enough targets).\n        \"\"\"\n        pass\n\n    def reset(self) -> None:\n        \"\"\"\n        Reset the handler state.\n\n        This is useful when starting a new streaming session.\n        \"\"\"\n        pass\n```",
        "minimal_test_cases": [
            {
                "test_id": "tests/test_settings.py::TestSettings::test_default_settings",
                "covers": [
                    "encypher.config.settings.Settings.__init__ - default initialization",
                    "encypher.config.settings.Settings.get - getting default values for all settings"
                ]
            },
            {
                "test_id": "tests/test_settings.py::TestSettings::test_load_from_file",
                "covers": [
                    "encypher.config.settings.Settings.__init__ - initialization from JSON config file"
                ]
            },
            {
                "test_id": "tests/test_settings.py::TestSettings::test_load_from_env",
                "covers": [
                    "encypher.config.settings.Settings.__init__ - initialization from environment variables"
                ]
            },
            {
                "test_id": "tests/test_settings.py::TestSettings::test_env_overrides_file",
                "covers": [
                    "encypher.config.settings.Settings.__init__ - environment variables override file settings"
                ]
            },
            {
                "test_id": "tests/test_settings.py::TestSettings::test_get_metadata_target",
                "covers": [
                    "encypher.config.settings.Settings.get_metadata_target - getting metadata target as enum",
                    "encypher.core.unicode_metadata.MetadataTarget - usage as return type"
                ]
            },
            {
                "test_id": "tests/test_settings.py::TestSettings::test_to_dict",
                "covers": [
                    "encypher.config.settings.Settings.to_dict - converting settings to dictionary"
                ]
            },
            {
                "test_id": "tests/core/test_crypto_utils.py::test_generate_key_pair",
                "covers": [
                    "encypher.core.crypto_utils.generate_key_pair - happy path for Ed25519 key pair generation"
                ]
            },
            {
                "test_id": "tests/core/test_crypto_utils.py::test_load_save_keys",
                "covers": [
                    "encypher.core.crypto_utils.load_private_key - loading unencrypted Ed25519 private key from PEM",
                    "encypher.core.crypto_utils.load_public_key - loading Ed25519 public key from PEM"
                ]
            },
            {
                "test_id": "tests/core/test_crypto_utils.py::test_load_save_keys_encrypted",
                "covers": [
                    "encypher.core.crypto_utils.load_private_key - loading encrypted Ed25519 private key from PEM"
                ]
            },
            {
                "test_id": "tests/core/test_crypto_utils.py::test_serialize_payload_basic",
                "covers": [
                    "encypher.core.crypto_utils.serialize_payload - canonical JSON serialization for BasicPayload"
                ]
            },
            {
                "test_id": "tests/core/test_crypto_utils.py::test_serialize_payload_manifest",
                "covers": [
                    "encypher.core.crypto_utils.serialize_payload - canonical JSON serialization for ManifestPayload"
                ]
            },
            {
                "test_id": "tests/core/test_crypto_utils.py::test_sign_and_verify_basic",
                "covers": [
                    "encypher.core.crypto_utils.sign_payload - signing a BasicPayload",
                    "encypher.core.crypto_utils.verify_signature - verifying a BasicPayload signature"
                ]
            },
            {
                "test_id": "tests/core/test_crypto_utils.py::test_sign_and_verify_manifest",
                "covers": [
                    "encypher.core.crypto_utils.sign_payload - signing a ManifestPayload",
                    "encypher.core.crypto_utils.verify_signature - verifying a ManifestPayload signature"
                ]
            },
            {
                "test_id": "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_variation_selector_conversion",
                "covers": [
                    "encypher.core.unicode_metadata.UnicodeMetadata.to_variation_selector - byte to variation selector conversion",
                    "encypher.core.unicode_metadata.UnicodeMetadata.from_variation_selector - variation selector to byte conversion"
                ]
            },
            {
                "test_id": "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_encode_decode",
                "covers": [
                    "encypher.core.unicode_metadata.UnicodeMetadata.encode - encoding text into emoji (legacy)",
                    "encypher.core.unicode_metadata.UnicodeMetadata.decode - decoding text from emoji (legacy)"
                ]
            },
            {
                "test_id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_verify_extract_success[basic-basic_metadata]",
                "covers": [
                    "encypher.core.unicode_metadata.UnicodeMetadata.embed_metadata - happy path for basic format",
                    "encypher.core.unicode_metadata.UnicodeMetadata.verify_and_extract_metadata - happy path for basic format",
                    "encypher.core.unicode_metadata.UnicodeMetadata.extract_bytes - utility for extracting raw bytes",
                    "encypher.core.unicode_metadata.UnicodeMetadata.find_targets - implicitly used for target Punctuation",
                    "encypher.core.unicode_metadata.MetadataTarget - usage as argument"
                ]
            },
            {
                "test_id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_embed_verify_extract_success[manifest-manifest_metadata]",
                "covers": [
                    "encypher.core.unicode_metadata.UnicodeMetadata.embed_metadata - happy path for manifest format",
                    "encypher.core.unicode_metadata.UnicodeMetadata.verify_and_extract_metadata - happy path for manifest format"
                ]
            },
            {
                "test_id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_unicode_metadata_extract_metadata",
                "covers": [
                    "encypher.core.unicode_metadata.UnicodeMetadata.extract_metadata - extracting metadata without verification (happy path)"
                ]
            },
            {
                "test_id": "tests/core/test_unicode_metadata.py::TestUnicodeMetadata::test_unicode_metadata_extract_metadata_no_metadata",
                "covers": [
                    "encypher.core.unicode_metadata.UnicodeMetadata.extract_metadata - attempting to extract from text with no metadata"
                ]
            },
            {
                "test_id": "tests/test_unicode_metadata.py::TestUnicodeMetadata::test_unicode_metadata_non_string_input",
                "covers": [
                    "encypher.core.unicode_metadata.UnicodeMetadata.embed_metadata - error handling for non-string input text"
                ]
            },
            {
                "test_id": "tests/test_streaming_handler.py::TestStreamingHandler::test_process_text_chunk",
                "covers": [
                    "encypher.streaming.handlers.StreamingHandler.__init__ - basic initialization",
                    "encypher.streaming.handlers.StreamingHandler.process_chunk - processing a single text chunk"
                ]
            },
            {
                "test_id": "tests/test_streaming_handler.py::TestStreamingHandler::test_process_dict_chunk_openai",
                "covers": [
                    "encypher.streaming.handlers.StreamingHandler.process_chunk - processing an OpenAI-style dictionary chunk"
                ]
            },
            {
                "test_id": "tests/test_streaming_handler.py::TestStreamingHandler::test_encode_first_chunk_only",
                "covers": [
                    "encypher.streaming.handlers.StreamingHandler.__init__ - with encode_first_chunk_only=True",
                    "encypher.streaming.handlers.StreamingHandler.process_chunk - behavior with encode_first_chunk_only"
                ]
            },
            {
                "test_id": "tests/test_streaming_handler.py::TestStreamingHandler::test_accumulation_for_small_chunks",
                "covers": [
                    "encypher.streaming.handlers.StreamingHandler.process_chunk - accumulation of small chunks until encoding"
                ]
            },
            {
                "test_id": "tests/test_streaming_handler.py::TestStreamingHandler::test_finalize_with_no_targets",
                "covers": [
                    "encypher.streaming.handlers.StreamingHandler.finalize - finalizing stream with accumulated text having no targets"
                ]
            },
            {
                "test_id": "tests/test_streaming_handler.py::TestStreamingHandler::test_reset",
                "covers": [
                    "encypher.streaming.handlers.StreamingHandler.reset - resetting handler state"
                ]
            },
            {
                "test_id": "tests/interop/test_c2pa.py::TestC2PAInterop::test_encypher_to_c2pa_conversion",
                "covers": [
                    "encypher.interop.c2pa.encypher_manifest_to_c2pa_like_dict - converting Encypher manifest to C2PA-like dictionary"
                ]
            },
            {
                "test_id": "tests/interop/test_c2pa.py::TestC2PAInterop::test_c2pa_to_encypher_conversion",
                "covers": [
                    "encypher.interop.c2pa.c2pa_like_dict_to_encypher_manifest - converting C2PA-like dictionary to Encypher manifest"
                ]
            },
            {
                "test_id": "tests/interop/test_c2pa.py::TestC2PAInterop::test_schema_generation",
                "covers": [
                    "encypher.interop.c2pa.get_c2pa_manifest_schema - generating C2PA-like manifest JSON schema"
                ]
            }
        ],
        "commit_sha": "8b497fad58ef813111f3ac6c7323c4e95d654ebc",
        "full_code_skeleton_structured": [
            {
                "file_path": "encypher/__init__.py",
                "code": "\"\"\"\nEncypherAI Core Package\n\nA Python package for embedding and extracting metadata in text using Unicode\nvariation selectors.\nThis package provides tools for invisible metadata encoding in AI-generated text.\n\"\"\"\n"
            },
            {
                "file_path": "encypher/streaming/__init__.py",
                "code": "\"\"\"\nStreaming support for EncypherAI metadata encoding.\n\"\"\"\n"
            },
            {
                "file_path": "encypher/streaming/handlers.py",
                "code": "\"\"\"\nStreaming handlers for EncypherAI metadata encoding.\n\nThis module provides utilities for handling streaming responses from LLMs\nand encoding metadata into the streaming chunks.\n\"\"\"\nfrom typing import Any, Dict, List, Literal, Optional, Union\nfrom cryptography.hazmat.primitives.asymmetric.types import PrivateKeyTypes\nfrom encypher.core.unicode_metadata import MetadataTarget\n\nclass StreamingHandler:\n    \"\"\"\n    Handler for processing streaming chunks from LLM providers and encoding metadata.\n\n    This class ensures that metadata is properly encoded in streaming responses,\n    handling the complexities of partial text chunks while maintaining consistency.\n    \"\"\"\n\n    def __init__(\n        self,\n        metadata: Optional[Dict[str, Any]] = None,\n        target: Union[str, MetadataTarget] = \"whitespace\",\n        encode_first_chunk_only: bool = True,\n        # New parameters for signature-based embedding\n        private_key: Optional[PrivateKeyTypes] = None,\n        signer_id: Optional[str] = None,\n        metadata_format: Literal[\"basic\", \"manifest\"] = \"basic\",\n        # Removed hmac_secret_key\n    ):\n        \"\"\"\n        Initialize the streaming handler.\n\n        Args:\n            metadata: Dictionary of metadata to encode. Must include keys required\n                      by the chosen `metadata_format`.\n            target: Where to embed the metadata (whitespace, punctuation, etc.)\n            encode_first_chunk_only: Whether to encode metadata only in the first\n                                     non-empty chunk. Currently, only True is fully\n                                     supported for signature embedding.\n            private_key: The private key for signing the metadata.\n            signer_id: An identifier for the signer (associated with the public key).\n            metadata_format: The structure ('basic' or 'manifest') of the metadata payload.\n\n        Raises:\n            ValueError: If `metadata_format` is invalid, or if `metadata` is provided\n                        without `private_key` and `signer_id`.\n            TypeError: If `metadata`, `encode_first_chunk_only`, `private_key`,\n                       or `signer_id` have incorrect types.\n        \"\"\"\n        pass\n\n    def _has_sufficient_targets(self, text: str) -> bool:\n        \"\"\"\n        Check if the text has at least one suitable target for embedding metadata.\n\n        Args:\n            text: Text to check for targets\n\n        Returns:\n            True if at least one suitable target is found, False otherwise\n        \"\"\"\n        pass\n\n    def process_chunk(self, chunk: Union[str, Dict[str, Any]]) -> Union[str, Dict[str, Any]]:\n        \"\"\"\n        Process a streaming chunk and encode metadata if needed.\n\n        This method handles both raw text chunks and structured chunks (like those from OpenAI).\n\n        Args:\n            chunk: Text chunk or dictionary containing a text chunk\n\n        Returns:\n            Processed chunk with encoded metadata, preserving the input chunk type (str or dict).\n\n        Raises:\n            ValueError: If the underlying text processing (_process_text_chunk) fails.\n            KeyError: If the expected keys ('choices', 'delta', 'content', etc.) are missing.\n            IndexError: If the 'choices' list is empty.\n        \"\"\"\n        pass\n\n    def _process_text_chunk(self, chunk: str) -> str:\n        \"\"\"\n        Process a text chunk and encode metadata if needed.\n\n        Args:\n            chunk: Text chunk\n\n        Returns:\n            Processed text chunk with encoded metadata\n\n        Raises:\n            ValueError: If UnicodeMetadata.embed_metadata fails (e.g., not enough targets).\n        \"\"\"\n        pass\n\n    def _process_dict_chunk(self, chunk: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Process a dictionary chunk and encode metadata if needed.\n\n        This handles structured chunks like those from OpenAI's streaming API.\n\n        Args:\n            chunk: Dictionary containing a text chunk\n\n        Returns:\n            Processed dictionary with encoded metadata\n\n        Raises:\n            ValueError: If the underlying text processing (_process_text_chunk) fails.\n            KeyError: If the expected keys ('choices', 'delta', 'content', etc.) are missing.\n            IndexError: If the 'choices' list is empty.\n        \"\"\"\n        pass\n\n    def finalize(self) -> Optional[str]:\n        \"\"\"\n        Finalize the stream and return any accumulated text with encoded metadata.\n\n        This method should be called after all chunks have been processed to handle\n        any remaining accumulated text that hasn't been processed yet.\n\n        Returns:\n            Processed accumulated text with encoded metadata, or None if no text accumulated\n\n        Raises:\n            ValueError: If UnicodeMetadata.embed_metadata fails (e.g., not enough targets).\n        \"\"\"\n        pass\n\n    def reset(self) -> None:\n        \"\"\"\n        Reset the handler state.\n\n        This is useful when starting a new streaming session.\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "encypher/interop/__init__.py",
                "code": "\"\"\"\nInteroperability utilities for EncypherAI.\n\nThis package provides tools for interoperability between EncypherAI's metadata formats\nand other content provenance standards and formats.\n\"\"\"\n"
            },
            {
                "file_path": "encypher/interop/c2pa.py",
                "code": "\"\"\"\nC2PA Interoperability Module for EncypherAI.\n\nThis module provides utilities for conceptual interoperability between EncypherAI's\nmanifest format and C2PA-like structures. These utilities serve as a bridge for\norganizations working with both EncypherAI (for plain text) and C2PA (for rich media).\n\nNote: This module provides a conceptual mapping, not a fully C2PA-compliant implementation.\nThe goal is to demonstrate potential interoperability and provide a starting point for\norganizations that need to work with both standards.\n\"\"\"\n\nfrom typing import Any, Dict\n\ndef encypher_manifest_to_c2pa_like_dict(manifest: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Converts an EncypherAI ManifestPayload to a dictionary using field names\n    conceptually aligned with C2PA assertion structures.\n\n    This function provides a conceptual bridge between EncypherAI's plain-text\n    manifest format and C2PA's rich media manifest structure, enabling potential\n    interoperability between the two approaches.\n\n    Args:\n        manifest: An EncypherAI manifest payload dictionary (can be a TypedDict ManifestPayload\n                 or a regular dict with the same structure)\n\n    Returns:\n        A dictionary with field names aligned with C2PA concepts, containing the\n        same information as the original manifest.\n\n    Example:\n        from encypher.core.crypto_utils import ManifestPayload\n        from encypher.interop.c2pa import encypher_manifest_to_c2pa_like_dict\n\n        # Original EncypherAI manifest\n        manifest = ManifestPayload(\n            claim_generator=\"EncypherAI/1.1.0\",\n            assertions=[{\"label\": \"c2pa.created\", \"when\": \"2025-04-13T12:00:00Z\"}],\n            ai_assertion={\"model_id\": \"gpt-4o\", \"model_version\": \"1.0\"},\n            custom_claims={},\n            timestamp=\"2025-04-13T12:00:00Z\"\n        )\n\n        # Convert to C2PA-like structure\n        c2pa_dict = encypher_manifest_to_c2pa_like_dict(manifest)\n    \"\"\"\n    pass\n\ndef c2pa_like_dict_to_encypher_manifest(data: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Creates an EncypherAI ManifestPayload from a dictionary structured\n    similarly to C2PA assertions. Handles missing fields gracefully.\n\n    This function provides a conceptual bridge from C2PA-like structures\n    to EncypherAI's manifest format, enabling potential interoperability\n    between the two approaches.\n\n    Args:\n        data: A dictionary with C2PA-like structure containing provenance information.\n\n    Returns:\n        An EncypherAI ManifestPayload dictionary that can be used with EncypherAI's\n        embedding functions.\n\n    Example:\n        from encypher.interop.c2pa import c2pa_like_dict_to_encypher_manifest\n\n        # C2PA-like structure\n        c2pa_data = {\n            \"claim_generator\": \"SomeApp/1.0\",\n            \"assertions\": [\n                {\n                    \"label\": \"c2pa.created\",\n                    \"data\": {\"timestamp\": \"2025-04-13T12:00:00Z\"}\n                },\n                {\n                    \"label\": \"ai.model.info\",\n                    \"data\": {\"model_id\": \"gpt-4o\", \"model_version\": \"1.0\"}\n                }\n            ],\n            \"timestamp\": \"2025-04-13T12:00:00Z\"\n        }\n\n        # Convert to EncypherAI manifest\n        manifest = c2pa_like_dict_to_encypher_manifest(c2pa_data)\n    \"\"\"\n    pass\n\ndef get_c2pa_manifest_schema() -> Dict[str, Any]:\n    \"\"\"\n    Returns a JSON Schema representation of the C2PA-like structure used by this module.\n\n    This schema provides documentation for the expected structure of C2PA-like dictionaries\n    used with the conversion functions in this module.\n\n    Returns:\n        A dictionary containing the JSON Schema for C2PA-like structures.\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "encypher/config/__init__.py",
                "code": "\"\"\"\nConfiguration utilities for EncypherAI.\n\"\"\"\n"
            },
            {
                "file_path": "encypher/config/settings.py",
                "code": "\"\"\"\nConfiguration settings for EncypherAI.\n\nThis module provides a centralized configuration system that supports\nloading from environment variables and configuration files.\n\"\"\"\n\nfrom pathlib import Path\nfrom typing import Any, Dict, Optional, Union\n\nfrom encypher.core.unicode_metadata import MetadataTarget\n\n\nclass Settings:\n    \"\"\"\n    Settings class for EncypherAI configuration.\n\n    This class handles loading configuration from environment variables\n    and configuration files, with sensible defaults.\n    \"\"\"\n\n    # Default configuration values\n    DEFAULT_CONFIG = {\n        \"metadata_target\": \"whitespace\",\n        \"encode_first_chunk_only\": True,\n        \"hmac_secret_key\": \"\",\n        \"timestamp_format\": \"%Y-%m-%dT%H:%M%z\",\n        \"logging_level\": \"INFO\",\n        \"report_usage_metrics\": False,\n    }\n\n    def __init__(\n        self,\n        config_file: Optional[Union[str, Path]] = None,\n        env_prefix: str = \"ENCYPHER_\",\n    ):\n        \"\"\"\n        Initialize settings from environment variables and/or config file.\n\n        Args:\n            config_file: Path to configuration file (JSON)\n            env_prefix: Prefix for environment variables\n        \"\"\"\n        pass\n\n    def _load_from_file(self, config_file: Union[str, Path]) -> None:\n        \"\"\"\n        Load configuration from a JSON file.\n\n        Args:\n            config_file: Path to configuration file\n        \"\"\"\n        pass\n\n    def _load_from_env(self) -> None:\n        \"\"\"\n        Load configuration from environment variables.\n\n        Environment variables take precedence over config file values.\n        \"\"\"\n        pass\n\n    def get(self, key: str, default: Any = None) -> Any:\n        \"\"\"\n        Get a configuration value.\n\n        Args:\n            key: Configuration key\n            default: Default value if key not found\n\n        Returns:\n            Configuration value or default\n        \"\"\"\n        pass\n\n    def get_metadata_target(self) -> MetadataTarget:\n        \"\"\"\n        Get the metadata target as an enum value.\n\n        Returns:\n            MetadataTarget enum value\n        \"\"\"\n        pass\n\n    def get_hmac_secret_key(self) -> str:\n        \"\"\"\n        Get the HMAC secret key.\n\n        Returns:\n            HMAC secret key\n        \"\"\"\n        pass\n\n    def get_encode_first_chunk_only(self) -> bool:\n        \"\"\"\n        Get whether to encode metadata only in the first chunk.\n\n        Returns:\n            True if encoding only the first chunk, False otherwise\n        \"\"\"\n        pass\n\n    def get_timestamp_format(self) -> str:\n        \"\"\"\n        Get the timestamp format.\n\n        Returns:\n            Timestamp format string\n        \"\"\"\n        pass\n\n    def get_logging_level(self) -> str:\n        \"\"\"\n        Get the logging level.\n\n        Returns:\n            Logging level string\n        \"\"\"\n        pass\n\n    def get_report_usage_metrics(self) -> bool:\n        \"\"\"\n        Get whether to report usage metrics.\n\n        Returns:\n            True if reporting usage metrics, False otherwise\n        \"\"\"\n        pass\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"\n        Get the configuration as a dictionary.\n\n        Returns:\n            Configuration dictionary\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "encypher/examples/generate_keys.py",
                "code": "#!/usr/bin/env python\n\"\"\"\nHelper script to generate Ed25519 key pair for EncypherAI.\n\nGenerates a private and public key pair in PEM format and a suggested key_id.\nProvides instructions for storing the private key securely (e.g., in a .env file)\nand using the public key and key_id in your application.\n\"\"\"\n\ndef generate_and_print_keys():\n    \"\"\"Generates and prints Ed25519 keys and instructions.\"\"\"\n    pass\n"
            },
            {
                "file_path": "encypher/examples/cli_example.py",
                "code": "\"\"\"\nCommand Line Interface Example for EncypherAI\n\nThis example demonstrates how to use EncypherAI from the command line\nto encode and decode metadata in text.\n\"\"\"\n\nfrom datetime import datetime\nfrom encypher.core.unicode_metadata import MetadataTarget\n\ndef count_metadata_occurrences(text):\n    \"\"\"\n    Count how many times metadata appears in the text.\n\n    Args:\n        text: The text to analyze\n\n    Returns:\n        int: Number of metadata occurrences\n    \"\"\"\n    pass\n\ndef encode_metadata_with_count(encoder, text, model_id, timestamp, custom_metadata, target):\n    \"\"\"\n    Wrapper around MetadataEncoder.encode_metadata that also returns the count of embeddings.\n\n    Returns:\n        tuple: (encoded_text, embed_count)\n    \"\"\"\n    pass\n\ndef encode_text(args):\n    \"\"\"\n    Encode metadata into text.\n\n    Args:\n        args: Command line arguments\n    \"\"\"\n    pass\n\ndef decode_text(args):\n    \"\"\"\n    Decode metadata from text.\n    \"\"\"\n    pass\n\ndef main():\n    \"\"\"Main entry point for the CLI.\"\"\"\n    pass\n"
            },
            {
                "file_path": "encypher/examples/__init__.py",
                "code": "\"\"\"\nExample implementations for EncypherAI.\n\"\"\"\n"
            },
            {
                "file_path": "encypher/examples/youtube_demo.py",
                "code": "\"\"\"\nEncypherAI YouTube Demo Script\n\nA visually appealing, step-by-step demonstration of EncypherAI's core functionality\nfor use in introductory videos and presentations.\n\"\"\"\n\ndef clear_screen():\n    \"\"\"Clear the terminal screen.\"\"\"\n    pass\n\ndef print_header():\n    \"\"\"Print a stylish header for the demo.\"\"\"\n    pass\n\ndef print_section(title: str):\n    \"\"\"Print a section title.\"\"\"\n    pass\n\ndef wait_for_key():\n    \"\"\"Wait for a key press to continue.\"\"\"\n    pass\n\ndef get_display_text(encoded_text: str, original_text: str) -> str:\n    \"\"\"Return either the original text or encoded text based on the display flag.\n\n    Args:\n        encoded_text: Text with encoded metadata\n        original_text: Original text without metadata\n\n    Returns:\n        The text to display based on DISPLAY_ORIGINAL_TEXT flag\n    \"\"\"\n    pass\n\ndef format_bytes_for_display(text: str, max_length: int = 30) -> str:\n    \"\"\"Format the byte representation of text for display.\n\n    Args:\n        text: The text to convert to byte representation\n        max_length: Maximum number of bytes to display\n\n    Returns:\n        A formatted string showing the byte values\n    \"\"\"\n    pass\n\ndef show_byte_comparison(original_text: str, encoded_text: str):\n    \"\"\"Display a technical comparison of byte values between original and encoded text.\n\n    Args:\n        original_text: The original text without metadata\n        encoded_text: The text with encoded metadata\n    \"\"\"\n    pass\n\ndef demo_basic_encoding():\n    \"\"\"Demonstrate basic metadata encoding.\"\"\"\n    pass\n\ndef demo_metadata_extraction():\n    \"\"\"Demonstrate metadata extraction and verification.\"\"\"\n    pass\n\ndef demo_tamper_detection():\n    \"\"\"Demonstrate tamper detection using HMAC verification.\"\"\"\n    pass\n\ndef demo_streaming():\n    \"\"\"Demonstrate streaming support.\"\"\"\n    pass\n\ndef demo_real_world_use_cases():\n    \"\"\"Demonstrate real-world use cases.\"\"\"\n    pass\n\ndef demo_conclusion():\n    \"\"\"Show conclusion and call to action.\"\"\"\n    pass\n\ndef main():\n    \"\"\"Run the complete demo.\"\"\"\n    pass\n"
            },
            {
                "file_path": "encypher/examples/fastapi_example.py",
                "code": "\"\"\"\nFastAPI Example Implementation for EncypherAI\n\nThis example demonstrates how to integrate EncypherAI with FastAPI\nto create a simple API that encodes metadata into text and decodes it.\n\"\"\"\n\nfrom datetime import datetime, timezone\nfrom typing import Any, Dict, List, Optional\nfrom fastapi import FastAPI, HTTPException\nfrom fastapi.responses import StreamingResponse\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import AsyncGenerator\n\nclass EncodeRequest(BaseModel):\n    text: str = Field(..., description=\"Text to encode metadata into\")\n    model_id: Optional[str] = Field(None, description=\"Model ID to embed\")\n    metadata: Optional[Dict[str, Any]] = Field(None, description=\"Additional metadata to embed\")\n    target: Optional[str] = Field(\n        \"whitespace\",\n        description=\"Where to embed metadata (whitespace, punctuation, first_letter, last_letter, all_characters)\",\n    )\n\nclass EncodeResponse(BaseModel):\n    encoded_text: str = Field(..., description=\"Text with encoded metadata\")\n    metadata: Dict[str, Any] = Field(..., description=\"Metadata that was encoded\")\n\nclass DecodeRequest(BaseModel):\n    text: str = Field(..., description=\"Text with encoded metadata to decode\")\n\nclass DecodeResponse(BaseModel):\n    original_text: str = Field(..., description=\"Original text without metadata\")\n    metadata: Optional[Dict[str, Any]] = Field(None, description=\"Extracted metadata or None if not found\")\n    is_valid: bool = Field(..., description=\"Whether the metadata is valid\")\n\nclass StreamRequest(BaseModel):\n    text_chunks: List[str] = Field(..., description=\"List of text chunks to simulate streaming\")\n    model_id: Optional[str] = Field(None, description=\"Model ID to embed\")\n    metadata: Optional[Dict[str, Any]] = Field(None, description=\"Additional metadata to embed\")\n    metadata_target: Optional[str] = Field(\"whitespace\", description=\"Where to embed metadata\")\n    encode_first_chunk_only: Optional[bool] = Field(True, description=\"Whether to encode metadata only in the first chunk\")\n\n@app.post(\"/encode\", response_model=EncodeResponse)\nasync def encode_text(request: EncodeRequest) -> EncodeResponse:\n    \"\"\"\n    Encode metadata into text using Unicode variation selectors.\n    \"\"\"\n    pass\n\n@app.post(\"/decode\", response_model=DecodeResponse)\nasync def decode_text(request: DecodeRequest) -> DecodeResponse:\n    \"\"\"\n    Decode metadata from text with embedded Unicode variation selectors.\n    \"\"\"\n    pass\n\n@app.post(\"/stream\")\nasync def stream_text(request: StreamRequest) -> StreamingResponse:\n    \"\"\"\n    Simulate streaming text with metadata encoding.\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "encypher/examples/litellm_integration.py",
                "code": "\"\"\"\nLiteLLM Integration Example for EncypherAI\n\nThis example demonstrates how to integrate EncypherAI with LiteLLM\nto encode metadata into LLM responses.\n\"\"\"\n\nfrom datetime import datetime, timezone\nfrom typing import Any, AsyncGenerator, Dict, List, Optional, Union\nfrom fastapi import FastAPI, HTTPException\nfrom fastapi.openapi.docs import get_swagger_ui_html\nfrom fastapi.responses import HTMLResponse, StreamingResponse\nfrom pydantic import BaseModel, Field\n\n@app.get(\"/swagger\", include_in_schema=False)\nasync def custom_swagger_ui_html() -> HTMLResponse:\n    pass\n\nclass ChatMessage(BaseModel):\n    \"\"\"A chat message in the conversation.\"\"\"\n    role: str = Field(description=\"Message role (system, user, assistant)\", example=\"user\")\n    content: str = Field(description=\"Message content\", example=\"What is the capital of France?\")\n\nclass ChatRequest(BaseModel):\n    \"\"\"Request model for chat completions.\"\"\"\n    messages: List[ChatMessage] = Field(description=\"List of chat messages in the conversation\")\n    model: str = Field(description=\"LLM model to use\", example=\"gpt-3.5-turbo\")\n    temperature: Optional[float] = Field(0.7, description=\"Sampling temperature (0.0 to 1.0)\", ge=0.0, le=1.0)\n    max_tokens: Optional[int] = Field(None, description=\"Maximum tokens to generate\", gt=0)\n    stream: Optional[bool] = Field(False, description=\"Whether to stream the response\")\n    metadata_target: Optional[str] = Field(\n        \"whitespace\",\n        description=\"Where to embed metadata (whitespace, punctuation, first_letter)\",\n    )\n    encode_first_chunk_only: Optional[bool] = Field(\n        True,\n        description=\"Whether to encode metadata only in the first chunk when streaming\",\n    )\n\nclass ChatResponse(BaseModel):\n    \"\"\"Response model for chat completions.\"\"\"\n    model: str = Field(description=\"Model used for generation\", example=\"gpt-3.5-turbo\")\n    content: str = Field(description=\"Generated content with embedded metadata\")\n    metadata: Dict[str, Any] = Field(description=\"Metadata embedded in the response\")\n\n@app.post(\"/v1/chat/completions\", response_model=ChatResponse, tags=[\"chat\"])\nasync def chat_completions(\n    request: ChatRequest,\n) -> Union[ChatResponse, StreamingResponse]:\n    \"\"\"\n    Generate a chat completion with metadata encoding.\n\n    Args:\n        request (ChatRequest): The chat completion request parameters\n\n    Returns:\n        ChatResponse: The generated response with embedded metadata\n\n    Raises:\n        HTTPException: If there's an error generating the completion\n    \"\"\"\n    pass\n\nasync def stream_chat_completion(request: ChatRequest, messages: List[Dict[str, str]]) -> AsyncGenerator[str, None]:\n    \"\"\"\n    Stream a chat completion with metadata encoding.\n\n    Args:\n        request (ChatRequest): The chat completion request parameters\n        messages (List[Dict[str, str]]): LiteLLM-formatted messages\n\n    Yields:\n        Streaming response chunks with metadata\n    \"\"\"\n    pass\n\n@app.get(\"/status\", tags=[\"status\"])\nasync def get_status() -> Dict[str, Any]:\n    \"\"\"\n    Get the current status of the API.\n\n    Returns:\n        dict: Status information including version and health status\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "encypher/core/__init__.py",
                "code": "\"\"\"\nCore encoding and decoding functionality for EncypherAI.\n\"\"\"\n"
            },
            {
                "file_path": "encypher/core/unicode_metadata.py",
                "code": "\"\"\"\nUnicode Metadata Embedding Utility for EncypherAI\n\nThis module provides utilities for embedding metadata (model info, timestamps)\ninto text using Unicode variation selectors without affecting readability.\n\"\"\"\n\nimport re\nfrom datetime import date, datetime, timezone\nfrom typing import Any, Callable, Dict, List, Literal, Optional, Tuple, Union, cast\nfrom cryptography.hazmat.primitives.asymmetric.ed25519 import Ed25519PrivateKey\nfrom cryptography.hazmat.primitives.asymmetric.types import PrivateKeyTypes, PublicKeyTypes\nfrom deprecated import deprecated\n\nfrom .constants import MetadataTarget\nfrom .crypto_utils import BasicPayload, ManifestPayload, OuterPayload\n\nclass UnicodeMetadata:\n    \"\"\"\n    Utility class for embedding and extracting metadata using Unicode\n    variation selectors.\n    \"\"\"\n\n    # Variation selectors block (VS1-VS16: U+FE00 to U+FE0F)\n    VARIATION_SELECTOR_START: int = 0xFE00\n    VARIATION_SELECTOR_END: int = 0xFE0F\n\n    # Variation selectors supplement (VS17-VS256: U+E0100 to U+E01EF)\n    VARIATION_SELECTOR_SUPPLEMENT_START: int = 0xE0100\n    VARIATION_SELECTOR_SUPPLEMENT_END: int = 0xE01EF\n\n    @classmethod\n    def to_variation_selector(cls, byte: int) -> Optional[str]:\n        \"\"\"\n        Convert a byte to a variation selector character\n\n        Args:\n            byte: Byte value (0-255)\n\n        Returns:\n            Unicode variation selector character or None if byte is out of range\n        \"\"\"\n        pass\n\n    @classmethod\n    def from_variation_selector(cls, code_point: int) -> Optional[int]:\n        \"\"\"\n        Convert a variation selector code point to a byte\n\n        Args:\n            code_point: Unicode code point\n\n        Returns:\n            Byte value (0-255) or None if not a variation selector\n        \"\"\"\n        pass\n\n    @classmethod\n    def encode(cls, emoji: str, text: str) -> str:\n        \"\"\"\n        Encode text into an emoji using Unicode variation selectors\n\n        Args:\n            emoji: Base character to encode the text into\n            text: Text to encode\n\n        Returns:\n            Encoded string with the text hidden in variation selectors\n        \"\"\"\n        pass\n\n    @classmethod\n    def decode(cls, text: str) -> str:\n        \"\"\"\n        Decode text from Unicode variation selectors\n\n        Args:\n            text: Text with embedded variation selectors\n\n        Returns:\n            Decoded text\n        \"\"\"\n        pass\n\n    @classmethod\n    def extract_bytes(cls, text: str) -> bytes:\n        \"\"\"\n        Extract bytes from Unicode variation selectors\n\n        Args:\n            text: Text with embedded variation selectors\n\n        Returns:\n            Bytes extracted from variation selectors\n        \"\"\"\n        pass\n\n    @classmethod\n    def _format_timestamp(cls, ts: Optional[Union[str, datetime, date, int, float]]) -> Optional[str]:\n        \"\"\"Helper to format various timestamp inputs into ISO 8601 UTC string.\n\n        Args:\n            ts: The timestamp input. Can be None, an ISO 8601 string,\n                a datetime object, a date object, or an int/float epoch\n                timestamp.\n\n        Returns:\n            The timestamp formatted as an ISO 8601 string in UTC (e.g., \"YYYY-MM-DDTHH:MM:SSZ\"),\n            or None if the input was None.\n\n        Raises:\n            ValueError: If the input is an invalid timestamp value or format.\n            TypeError: If the input type is not supported.\n        \"\"\"\n        pass\n\n    @classmethod\n    def find_targets(\n        cls,\n        text: str,\n        target: Optional[Union[str, MetadataTarget]] = None,\n    ) -> List[int]:\n        \"\"\"\n        Find indices of characters in text where metadata can be embedded.\n\n        Args:\n            text: The text to find targets in.\n            target: Where to embed metadata ('whitespace', 'punctuation', etc.,\n                    or MetadataTarget enum).\n\n        Returns:\n            List of indices where metadata can be embedded.\n\n        Raises:\n            ValueError: If target is an invalid string.\n        \"\"\"\n        pass\n\n    @classmethod\n    def embed_metadata(\n        cls,\n        text: str,\n        private_key: PrivateKeyTypes,\n        signer_id: str,\n        metadata_format: Literal[\"basic\", \"manifest\"] = \"basic\",\n        model_id: Optional[str] = None,\n        timestamp: Optional[Union[str, datetime, date, int, float]] = None,\n        target: Optional[Union[str, MetadataTarget]] = None,\n        custom_metadata: Optional[Dict[str, Any]] = None,\n        claim_generator: Optional[str] = None,\n        actions: Optional[List[Dict[str, Any]]] = None,\n        ai_info: Optional[Dict[str, Any]] = None,\n        custom_claims: Optional[Dict[str, Any]] = None,\n        distribute_across_targets: bool = False,\n    ) -> str:\n        \"\"\"\n        Embed metadata into text using Unicode variation selectors, signing with a private key.\n\n        When using 'manifest' format, this method implements a C2PA-inspired approach for\n        content provenance and authenticity, adapted specifically for plain-text environments\n        where traditional file-based embedding methods aren't applicable. The manifest structure\n        parallels C2PA's concepts of assertions, claim generators, and cryptographic integrity.\n\n        Args:\n            text: The text to embed metadata into.\n            private_key: The Ed25519 private key object for signing.\n            signer_id: A string identifying the signer/key pair (used for\n                       verification lookup).\n            metadata_format: The format for the metadata payload ('basic' or 'manifest').\n                             Default is 'basic'. When set to 'manifest', uses a\n                             C2PA-inspired structured format.\n            model_id: Model identifier (used in 'basic' and optionally in\n                      'manifest' ai_info).\n            timestamp: Timestamp (datetime, ISO string, int/float epoch). Stored as\n                       ISO 8601 UTC string.\n                       **This field is mandatory.**\n            target: Where to embed metadata ('whitespace', 'punctuation', etc.,\n                    or MetadataTarget enum).\n            custom_metadata: Dictionary for custom fields (used in 'basic' payload).\n            claim_generator: Claim generator string (used in 'manifest' format).\n                             Similar to C2PA's concept of identifying the\n                             software/tool that generated the claim.\n            actions: List of action dictionaries (used in 'manifest' format).\n                     Conceptually similar to C2PA assertions about operations\n                     performed on the content.\n            ai_info: Dictionary with AI-specific info (used in 'manifest' format).\n                     Represents a custom assertion type focused on AI-specific\n                     attributes.\n            custom_claims: Dictionary for custom C2PA-like claims (used in\n                           'manifest' format).\n            distribute_across_targets: If True, distribute bits across multiple\n                                       targets if needed.\n\n        Returns:\n            The text with embedded metadata and digital signature.\n\n        Raises:\n            ValueError: If 'timestamp' is not provided, if the target is invalid,\n                        if not enough embedding locations are found, or if the\n                        metadata + signature is too large.\n        \"\"\"\n        pass\n\n    @classmethod\n    def _bytes_to_variation_selectors(cls, data: bytes) -> List[str]:\n        \"\"\"Convert bytes into a list of Unicode variation selector characters.\"\"\"\n        pass\n\n    @classmethod\n    def verify_and_extract_metadata(\n        cls,\n        text: str,\n        public_key_provider: Callable[[str], Optional[PublicKeyTypes]],\n        return_payload_on_failure: bool = False,\n    ) -> Tuple[Union[BasicPayload, ManifestPayload, None], bool, Optional[str]]:\n        \"\"\"\n        Extracts embedded metadata, verifies its signature using a public key,\n        and returns the payload, verification status, and signer ID.\n\n        This verification process implements a C2PA-inspired approach for content\n        authenticity verification, adapted specifically for plain-text environments.\n        Similar to how C2PA verifies digital signatures in media files to establish\n        provenance and integrity, this method verifies cryptographic signatures\n        embedded directly within text using Unicode variation selectors.\n\n        Args:\n            text: Text potentially containing embedded metadata.\n            public_key_provider: A callable function that takes a signer_id (str)\n                                 and returns the corresponding Ed25519PublicKey\n                                 object or None if the key is not found.\n                                 This resolver pattern enables flexible key management\n                                 similar to C2PA's approach for signature verification.\n            return_payload_on_failure: If True, return the payload even when verification fails.\n                                      If False (default), return None for the payload when verification fails.\n\n        Returns:\n            A tuple containing:\n            - The extracted inner payload (Dict[str, Any], basic or manifest) or None\n              if extraction/verification fails (unless return_payload_on_failure is True).\n            - Verification status (bool): True if the signature is valid, False otherwise.\n            - The signer_id (str) found in the metadata, or None if extraction fails.\n\n        Raises:\n            TypeError: If public_key_provider returns an invalid key type.\n            KeyError: If public_key_provider raises an error (e.g., key not found).\n            InvalidSignature: If the signature verification process itself fails.\n            Exception: Can propagate errors from base64 decoding or payload serialization.\n        \"\"\"\n        pass\n\n    @classmethod\n    def _extract_outer_payload(cls, text: str) -> Optional[OuterPayload]:\n        \"\"\"Extracts the raw OuterPayload dict from embedded bytes.\n\n        Finds the metadata markers, extracts the embedded bytes, decodes the\n        outer JSON structure, and returns the OuterPayload TypedDict if valid.\n\n        Args:\n            text: The text containing potentially embedded metadata.\n\n        Returns:\n            The extracted OuterPayload dictionary if found and successfully parsed,\n            otherwise None.\n\n        Raises:\n            (Indirectly via called methods) UnicodeDecodeError, json.JSONDecodeError, TypeError\n        \"\"\"\n        pass\n\n    @classmethod\n    def verify_metadata(\n        cls,\n        text: str,\n        public_key_provider: Callable[[str], Optional[PublicKeyTypes]],\n        return_payload_on_failure: bool = False,\n    ) -> Tuple[Union[BasicPayload, ManifestPayload, None], bool, Optional[str]]:\n        \"\"\"\n        Verify and extract metadata from text embedded using Unicode variation selectors and a public key.\n\n        Args:\n            text: Text with embedded metadata\n            public_key_provider: A callable function that takes a signer_id (str)\n                                 and returns the corresponding Ed25519PublicKey\n                                 object or None if the key is not found.\n            return_payload_on_failure: If True, return the payload even when verification fails.\n                                      If False (default), return None for the payload when verification fails.\n\n        Returns:\n            A tuple containing:\n            - The extracted inner payload (Dict[str, Any], basic or manifest) or None\n              if extraction/verification fails (unless return_payload_on_failure is True).\n            - Verification status (bool): True if the signature is valid, False otherwise.\n            - The signer_id (str) found in the metadata, or None if extraction fails.\n\n        Raises:\n            TypeError: If public_key_provider returns an invalid key type.\n            KeyError: If public_key_provider raises an error (e.g., key not found).\n            InvalidSignature: If the signature verification process itself fails.\n            Exception: Can propagate errors from base64 decoding or payload serialization.\n        \"\"\"\n        pass\n\n    @classmethod\n    def extract_metadata(cls, text: str) -> Union[BasicPayload, ManifestPayload, None]:\n        \"\"\"\n        Extracts embedded metadata from text without verifying its signature.\n\n        Finds the metadata markers, extracts the embedded bytes, decodes the\n        outer JSON structure, and returns the inner 'payload' dictionary.\n\n        Similar to how C2PA allows for inspection of manifest contents separate\n        from verification, this method enables access to the embedded provenance\n        information without cryptographic validation. This is useful for debugging,\n        analysis, or when working with content where verification isn't the primary goal.\n        When using the 'manifest' format, the extracted payload will contain C2PA-inspired\n        structured provenance information.\n\n        Args:\n            text: The text containing potentially embedded metadata.\n\n        Returns:\n            The extracted inner metadata dictionary if found and successfully parsed,\n            otherwise None.\n        \"\"\"\n        pass\n\n    @classmethod\n    @deprecated(\n        version=\"1.1.0\",\n        reason=\"HMAC verification is deprecated. Use Ed25519 digital signatures via the primary verify_metadata method.\",\n    )\n    def _verify_metadata_hmac_deprecated(cls, text: str, hmac_secret_key: str) -> Tuple[Dict[str, Any], bool]:\n        \"\"\"\n        Verify and extract metadata from text embedded using Unicode variation selectors and an HMAC secret key.\n\n        Args:\n            text: Text with embedded metadata\n            hmac_secret_key: HMAC secret key for verification\n\n        Returns:\n            A tuple containing:\n            - The extracted inner payload (Dict[str, Any], basic or manifest) or empty dict if extraction fails.\n            - Verification status (bool): True if the signature is valid, False otherwise.\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "encypher/core/constants.py",
                "code": "\"\"\"\nConstants for the EncypherAI core module.\n\nThis module contains constants used throughout the EncypherAI core module,\nparticularly for metadata embedding and extraction.\n\"\"\"\n\nfrom enum import Enum, auto\n\nclass MetadataTarget(Enum):\n    \"\"\"Enum for metadata embedding targets.\"\"\"\n\n    NONE = auto()\n    WHITESPACE = auto()\n    PUNCTUATION = auto()\n    FIRST_LETTER = auto()\n    LAST_LETTER = auto()\n    ALL_CHARACTERS = auto()\n"
            },
            {
                "file_path": "encypher/core/crypto_utils.py",
                "code": "from typing import Any, Dict, List, Literal, Optional, Tuple, TypedDict, Union, cast\nfrom cryptography.hazmat.primitives.asymmetric import ed25519\nfrom cryptography.hazmat.primitives.asymmetric.types import PrivateKeyTypes, PublicKeyTypes\n\nclass BasicPayload(TypedDict):\n    \"\"\"Structure for the 'basic' metadata format payload.\"\"\"\n\n    model_id: Optional[str]\n    timestamp: Optional[str]  # Recommended: ISO 8601 UTC format string\n    custom_metadata: Dict[str, Any]\n\nclass ManifestAction(TypedDict):\n    \"\"\"\n    Structure for an assertion within the 'manifest' payload.\n\n    Conceptually similar to C2PA assertions, these represent\n    operations performed on the content. The naming convention for assertion labels\n    follows C2PA patterns (e.g., \"c2pa.created\", \"c2pa.transcribed\") to\n    maintain conceptual alignment with the broader provenance ecosystem.\n    \"\"\"\n\n    label: str  # e.g., \"c2pa.created\", \"c2pa.transcribed\"\n    when: str  # ISO 8601 UTC format string\n    # Add other optional C2PA assertion fields if needed, e.g.:\n    # softwareAgent: Optional[str]\n    # digitalSourceType: Optional[str]\n\nclass ManifestAiInfo(TypedDict, total=False):\n    \"\"\"\n    Optional structure for AI-specific info within the 'manifest' payload.\n\n    This represents a custom assertion type focused on AI-specific attributes,\n    similar to how C2PA allows for specialized assertion types. For AI-generated\n    content, this provides critical provenance information about the model used.\n    \"\"\"\n\n    model_id: str\n    model_version: Optional[str]\n    # Add other relevant AI fields\n\nclass ManifestPayload(TypedDict):\n    \"\"\"\n    Structure for the 'manifest' metadata format payload.\n\n    Inspired by the Coalition for Content Provenance and Authenticity (C2PA) manifests,\n    this structure provides a standardized way to embed provenance information\n    directly within text content. While C2PA focuses on rich media file formats,\n    EncypherAI adapts these concepts specifically for plain-text use cases where\n    traditional file embedding methods aren't applicable.\n\n    The manifest includes information about:\n    - The software/tool that generated the claim (claim_generator)\n    - A list of assertions about the content (conceptually similar to C2PA assertions)\n    - AI-specific assertion when relevant (ai_assertion)\n    - Custom claims for extensibility\n    - Timestamp information\n    \"\"\"\n\n    claim_generator: str\n    assertions: List[ManifestAction]\n    ai_assertion: Optional[ManifestAiInfo]\n    custom_claims: Dict[str, Any]\n    timestamp: Optional[str]  # ISO 8601 UTC format string (Consider if needed alongside assertions' 'when')\n\nclass OuterPayload(TypedDict):\n    \"\"\"\n    The complete outer structure embedded into the text.\n\n    This structure wraps either a basic payload or a C2PA-inspired manifest payload,\n    adding cryptographic integrity through digital signatures. Similar to C2PA's\n    approach of ensuring tamper-evidence through cryptographic signing, this\n    structure enables verification of content authenticity and integrity in\n    plain-text environments.\n    \"\"\"\n\n    format: Literal[\"basic\", \"manifest\"]\n    signer_id: str\n    payload: Union[BasicPayload, ManifestPayload]  # The signed part\n    signature: str  # Base64 encoded signature string\n\ndef generate_key_pair() -> Tuple[ed25519.Ed25519PrivateKey, ed25519.Ed25519PublicKey]:\n    \"\"\"\n    Generates an Ed25519 key pair.\n\n    Returns:\n        Tuple containing the private and public keys.\n    \"\"\"\n    pass\n\ndef sign_payload(private_key: PrivateKeyTypes, payload_bytes: bytes) -> bytes:\n    \"\"\"\n    Signs the payload bytes using the private key (Ed25519).\n\n    Args:\n        private_key: The Ed25519 private key object.\n        payload_bytes: The canonical bytes of the payload to sign.\n\n    Returns:\n        The signature bytes.\n\n    Raises:\n        TypeError: If the provided key is not an Ed25519 private key.\n    \"\"\"\n    pass\n\ndef verify_signature(public_key: PublicKeyTypes, payload_bytes: bytes, signature: bytes) -> bool:\n    \"\"\"\n    Verifies the signature against the payload using the public key (Ed25519).\n\n    Args:\n        public_key: The Ed25519 public key object.\n        payload_bytes: The canonical bytes of the payload that was signed.\n        signature: The signature bytes to verify.\n\n    Returns:\n        True if the signature is valid, False otherwise.\n\n    Raises:\n        TypeError: If the provided key is not an Ed25519 public key.\n    \"\"\"\n    pass\n\ndef serialize_payload(payload: Dict[str, Any]) -> bytes:\n    \"\"\"\n    Serializes the metadata payload dictionary into canonical JSON bytes.\n    Ensures keys are sorted and uses compact separators for consistency.\n\n    Args:\n        payload: The dictionary payload.\n\n    Returns:\n        UTF-8 encoded bytes of the canonical JSON string.\n    \"\"\"\n    pass\n\ndef load_private_key(key_data: Union[bytes, str], password: Optional[bytes] = None) -> ed25519.Ed25519PrivateKey:\n    \"\"\"\n    Loads an Ed25519 private key from PEM-encoded bytes or string,\n    or from raw bytes (32 bytes).\n\n    Args:\n        key_data: PEM string/bytes or raw private key bytes.\n        password: Optional password for encrypted PEM keys.\n\n    Returns:\n        Ed25519 private key object.\n\n    Raises:\n        ValueError: If the key format is invalid or unsupported.\n        TypeError: If key_data has an invalid type.\n    \"\"\"\n    pass\n\ndef load_public_key(key_data: Union[bytes, str]) -> ed25519.Ed25519PublicKey:\n    \"\"\"\n    Loads an Ed25519 public key from PEM-encoded bytes or string,\n    or from raw bytes (32 bytes).\n\n    Args:\n        key_data: PEM string/bytes or raw public key bytes.\n\n    Returns:\n        Ed25519 public key object.\n\n    Raises:\n        ValueError: If the key format is invalid or unsupported.\n        TypeError: If key_data has an invalid type.\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "encypher/utils/__init__.py",
                "code": "\"\"\"\nUtility functions for EncypherAI.\n\"\"\"\n"
            }
        ],
        "minimal_code_skeleton_structured": [
            {
                "file_path": "encypher/config/settings.py",
                "code": "class Settings:\n    \"\"\"\n    Settings class for EncypherAI configuration.\n\n    This class handles loading configuration from environment variables\n    and configuration files, with sensible defaults.\n    \"\"\"\n\n    def __init__(\n        self,\n        config_file: Optional[Union[str, Path]] = None,\n        env_prefix: str = \"ENCYPHER_\",\n    ):\n        \"\"\"\n        Initialize settings from environment variables and/or config file.\n\n        Args:\n            config_file: Path to configuration file (JSON)\n            env_prefix: Prefix for environment variables\n        \"\"\"\n        pass\n\n    def get(self, key: str, default: Any = None) -> Any:\n        \"\"\"\n        Get a configuration value.\n\n        Args:\n            key: Configuration key\n            default: Default value if key not found\n\n        Returns:\n            Configuration value or default\n        \"\"\"\n        pass\n\n    def get_metadata_target(self) -> MetadataTarget:\n        \"\"\"\n        Get the metadata target as an enum value.\n\n        Returns:\n            MetadataTarget enum value\n        \"\"\"\n        pass\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"\n        Get the configuration as a dictionary.\n\n        Returns:\n            Configuration dictionary\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "encypher/core/constants.py",
                "code": "class MetadataTarget(Enum):\n    \"\"\"Enum for metadata embedding targets.\"\"\"\n\n    NONE = auto()\n    WHITESPACE = auto()\n    PUNCTUATION = auto()\n    FIRST_LETTER = auto()\n    LAST_LETTER = auto()\n    ALL_CHARACTERS = auto()\n"
            },
            {
                "file_path": "encypher/core/crypto_utils.py",
                "code": "class BasicPayload(TypedDict):\n    \"\"\"Structure for the 'basic' metadata format payload.\"\"\"\n\n    model_id: Optional[str]\n    timestamp: Optional[str]  # Recommended: ISO 8601 UTC format string\n    custom_metadata: Dict[str, Any]\n\n\nclass ManifestAction(TypedDict):\n    \"\"\"\n    Structure for an assertion within the 'manifest' payload.\n\n    Conceptually similar to C2PA assertions, these represent\n    operations performed on the content. The naming convention for assertion labels\n    follows C2PA patterns (e.g., \"c2pa.created\", \"c2pa.transcribed\") to\n    maintain conceptual alignment with the broader provenance ecosystem.\n    \"\"\"\n\n    label: str  # e.g., \"c2pa.created\", \"c2pa.transcribed\"\n    when: str  # ISO 8601 UTC format string\n\n\nclass ManifestAiInfo(TypedDict, total=False):\n    \"\"\"\n    Optional structure for AI-specific info within the 'manifest' payload.\n\n    This represents a custom assertion type focused on AI-specific attributes,\n    similar to how C2PA allows for specialized assertion types. For AI-generated\n    content, this provides critical provenance information about the model used.\n    \"\"\"\n\n    model_id: str\n    model_version: Optional[str]\n\n\nclass ManifestPayload(TypedDict):\n    \"\"\"\n    Structure for the 'manifest' metadata format payload.\n\n    Inspired by the Coalition for Content Provenance and Authenticity (C2PA) manifests,\n    this structure provides a standardized way to embed provenance information\n    directly within text content. While C2PA focuses on rich media file formats,\n    EncypherAI adapts these concepts specifically for plain-text use cases where\n    traditional file embedding methods aren't applicable.\n\n    The manifest includes information about:\n    - The software/tool that generated the claim (claim_generator)\n    - A list of assertions about the content (conceptually similar to C2PA assertions)\n    - AI-specific assertion when relevant (ai_assertion)\n    - Custom claims for extensibility\n    - Timestamp information\n    \"\"\"\n\n    claim_generator: str\n    assertions: List[ManifestAction]\n    ai_assertion: Optional[ManifestAiInfo]\n    custom_claims: Dict[str, Any]\n    timestamp: Optional[str]  # ISO 8601 UTC format string (Consider if needed alongside assertions' 'when')\n\n\nclass OuterPayload(TypedDict):\n    \"\"\"\n    The complete outer structure embedded into the text.\n\n    This structure wraps either a basic payload or a C2PA-inspired manifest payload,\n    adding cryptographic integrity through digital signatures. Similar to C2PA's\n    approach of ensuring tamper-evidence through cryptographic signing, this\n    structure enables verification of content authenticity and integrity in\n    plain-text environments.\n    \"\"\"\n\n    format: Literal[\"basic\", \"manifest\"]\n    signer_id: str\n    payload: Union[BasicPayload, ManifestPayload]  # The signed part\n    signature: str  # Base64 encoded signature string\n\n\ndef generate_key_pair() -> Tuple[ed25519.Ed25519PrivateKey, ed25519.Ed25519PublicKey]:\n    \"\"\"\n    Generates an Ed25519 key pair.\n\n    Returns:\n        Tuple containing the private and public keys.\n    \"\"\"\n    pass\n\ndef sign_payload(private_key: PrivateKeyTypes, payload_bytes: bytes) -> bytes:\n    \"\"\"\n    Signs the payload bytes using the private key (Ed25519).\n\n    Args:\n        private_key: The Ed25519 private key object.\n        payload_bytes: The canonical bytes of the payload to sign.\n\n    Returns:\n        The signature bytes.\n\n    Raises:\n        TypeError: If the provided key is not an Ed25519 private key.\n    \"\"\"\n    pass\n\ndef verify_signature(public_key: PublicKeyTypes, payload_bytes: bytes, signature: bytes) -> bool:\n    \"\"\"\n    Verifies the signature against the payload using the public key (Ed25519).\n\n    Args:\n        public_key: The Ed25519 public key object.\n        payload_bytes: The canonical bytes of the payload that was signed.\n        signature: The signature bytes to verify.\n\n    Returns:\n        True if the signature is valid, False otherwise.\n\n    Raises:\n        TypeError: If the provided key is not an Ed25519 public key.\n    \"\"\"\n    pass\n\ndef serialize_payload(payload: Dict[str, Any]) -> bytes:\n    \"\"\"\n    Serializes the metadata payload dictionary into canonical JSON bytes.\n    Ensures keys are sorted and uses compact separators for consistency.\n\n    Args:\n        payload: The dictionary payload.\n\n    Returns:\n        UTF-8 encoded bytes of the canonical JSON string.\n    \"\"\"\n    pass\n\ndef load_private_key(key_data: Union[bytes, str], password: Optional[bytes] = None) -> ed25519.Ed25519PrivateKey:\n    \"\"\"\n    Loads an Ed25519 private key from PEM-encoded bytes or string,\n    or from raw bytes (32 bytes).\n\n    Args:\n        key_data: PEM string/bytes or raw private key bytes.\n        password: Optional password for encrypted PEM keys.\n\n    Returns:\n        Ed25519 private key object.\n\n    Raises:\n        ValueError: If the key format is invalid or unsupported.\n        TypeError: If key_data has an invalid type.\n    \"\"\"\n    pass\n\ndef load_public_key(key_data: Union[bytes, str]) -> ed25519.Ed25519PublicKey:\n    \"\"\"\n    Loads an Ed25519 public key from PEM-encoded bytes or string,\n    or from raw bytes (32 bytes).\n\n    Args:\n        key_data: PEM string/bytes or raw public key bytes.\n\n    Returns:\n        Ed25519 public key object.\n\n    Raises:\n        ValueError: If the key format is invalid or unsupported.\n        TypeError: If key_data has an invalid type.\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "encypher/core/unicode_metadata.py",
                "code": "class UnicodeMetadata:\n    \"\"\"\n    Utility class for embedding and extracting metadata using Unicode\n    variation selectors.\n    \"\"\"\n\n    VARIATION_SELECTOR_START: int = 0xFE00\n    VARIATION_SELECTOR_END: int = 0xFE0F\n    VARIATION_SELECTOR_SUPPLEMENT_START: int = 0xE0100\n    VARIATION_SELECTOR_SUPPLEMENT_END: int = 0xE01EF\n\n    @classmethod\n    def to_variation_selector(cls, byte: int) -> Optional[str]:\n        \"\"\"\n        Convert a byte to a variation selector character\n\n        Args:\n            byte: Byte value (0-255)\n\n        Returns:\n            Unicode variation selector character or None if byte is out of range\n        \"\"\"\n        pass\n\n    @classmethod\n    def from_variation_selector(cls, code_point: int) -> Optional[int]:\n        \"\"\"\n        Convert a variation selector code point to a byte\n\n        Args:\n            code_point: Unicode code point\n\n        Returns:\n            Byte value (0-255) or None if not a variation selector\n        \"\"\"\n        pass\n\n    @classmethod\n    def encode(cls, emoji: str, text: str) -> str:\n        \"\"\"\n        Encode text into an emoji using Unicode variation selectors\n\n        Args:\n            emoji: Base character to encode the text into\n            text: Text to encode\n\n        Returns:\n            Encoded string with the text hidden in variation selectors\n        \"\"\"\n        pass\n\n    @classmethod\n    def decode(cls, text: str) -> str:\n        \"\"\"\n        Decode text from Unicode variation selectors\n\n        Args:\n            text: Text with embedded variation selectors\n\n        Returns:\n            Decoded text\n        \"\"\"\n        pass\n\n    @classmethod\n    def extract_bytes(cls, text: str) -> bytes:\n        \"\"\"\n        Extract bytes from Unicode variation selectors\n\n        Args:\n            text: Text with embedded variation selectors\n\n        Returns:\n            Bytes extracted from variation selectors\n        \"\"\"\n        pass\n\n    @classmethod\n    def embed_metadata(\n        cls,\n        text: str,\n        private_key: PrivateKeyTypes,\n        signer_id: str,\n        metadata_format: Literal[\"basic\", \"manifest\"] = \"basic\",\n        model_id: Optional[str] = None,\n        timestamp: Optional[Union[str, datetime, date, int, float]] = None,\n        target: Optional[Union[str, MetadataTarget]] = None,\n        custom_metadata: Optional[Dict[str, Any]] = None,\n        claim_generator: Optional[str] = None,\n        actions: Optional[List[Dict[str, Any]]] = None,\n        ai_info: Optional[Dict[str, Any]] = None,\n        custom_claims: Optional[Dict[str, Any]] = None,\n        distribute_across_targets: bool = False,\n    ) -> str:\n        \"\"\"\n        Embed metadata into text using Unicode variation selectors, signing with a private key.\n\n        When using 'manifest' format, this method implements a C2PA-inspired approach for\n        content provenance and authenticity, adapted specifically for plain-text environments\n        where traditional file-based embedding methods aren't applicable. The manifest structure\n        parallels C2PA's concepts of assertions, claim generators, and cryptographic integrity.\n\n        Args:\n            text: The text to embed metadata into.\n            private_key: The Ed25519 private key object for signing.\n            signer_id: A string identifying the signer/key pair (used for\n                       verification lookup).\n            metadata_format: The format for the metadata payload ('basic' or 'manifest').\n                             Default is 'basic'. When set to 'manifest', uses a\n                             C2PA-inspired structured format.\n            model_id: Model identifier (used in 'basic' and optionally in\n                      'manifest' ai_info).\n            timestamp: Timestamp (datetime, ISO string, int/float epoch). Stored as\n                       ISO 8601 UTC string.\n                       **This field is mandatory.**\n            target: Where to embed metadata ('whitespace', 'punctuation', etc.,\n                    or MetadataTarget enum).\n            custom_metadata: Dictionary for custom fields (used in 'basic' payload).\n            claim_generator: Claim generator string (used in 'manifest' format).\n                             Similar to C2PA's concept of identifying the\n                             software/tool that generated the claim.\n            actions: List of action dictionaries (used in 'manifest' format).\n                     Conceptually similar to C2PA assertions about operations\n                     performed on the content.\n            ai_info: Dictionary with AI-specific info (used in 'manifest' format).\n                     Represents a custom assertion type focused on AI-specific\n                     attributes.\n            custom_claims: Dictionary for custom C2PA-like claims (used in\n                           'manifest' format).\n            distribute_across_targets: If True, distribute bits across multiple\n                                       targets if needed.\n\n        Returns:\n            The text with embedded metadata and digital signature.\n\n        Raises:\n            ValueError: If 'timestamp' is not provided, if the target is invalid,\n                        if not enough embedding locations are found, or if the\n                        metadata + signature is too large.\n        \"\"\"\n        pass\n\n    @classmethod\n    def verify_and_extract_metadata(\n        cls,\n        text: str,\n        public_key_provider: Callable[[str], Optional[PublicKeyTypes]],\n        return_payload_on_failure: bool = False,\n    ) -> Tuple[Union[BasicPayload, ManifestPayload, None], bool, Optional[str]]:\n        \"\"\"\n        Extracts embedded metadata, verifies its signature using a public key,\n        and returns the payload, verification status, and signer ID.\n\n        This verification process implements a C2PA-inspired approach for content\n        authenticity verification, adapted specifically for plain-text environments.\n        Similar to how C2PA verifies digital signatures in media files to establish\n        provenance and integrity, this method verifies cryptographic signatures\n        embedded directly within text using Unicode variation selectors.\n\n        Args:\n            text: Text potentially containing embedded metadata.\n            public_key_provider: A callable function that takes a signer_id (str)\n                                 and returns the corresponding Ed25519PublicKey\n                                 object or None if the key is not found.\n                                 This resolver pattern enables flexible key management\n                                 similar to C2PA's approach for signature verification.\n            return_payload_on_failure: If True, return the payload even when verification fails.\n                                      If False (default), return None for the payload when verification fails.\n\n        Returns:\n            A tuple containing:\n            - The extracted inner payload (Dict[str, Any], basic or manifest) or None\n              if extraction/verification fails (unless return_payload_on_failure is True).\n            - Verification status (bool): True if the signature is valid, False otherwise.\n            - The signer_id (str) found in the metadata, or None if extraction fails.\n\n        Raises:\n            TypeError: If public_key_provider returns an invalid key type.\n            KeyError: If public_key_provider raises an error (e.g., key not found).\n            InvalidSignature: If the signature verification process itself fails.\n            Exception: Can propagate errors from base64 decoding or payload serialization.\n        \"\"\"\n        pass\n\n    @classmethod\n    def extract_metadata(cls, text: str) -> Union[BasicPayload, ManifestPayload, None]:\n        \"\"\"\n        Extracts embedded metadata from text without verifying its signature.\n\n        Finds the metadata markers, extracts the embedded bytes, decodes the\n        outer JSON structure, and returns the inner 'payload' dictionary.\n\n        Similar to how C2PA allows for inspection of manifest contents separate\n        from verification, this method enables access to the embedded provenance\n        information without cryptographic validation. This is useful for debugging,\n        analysis, or when working with content where verification isn't the primary goal.\n        When using the 'manifest' format, the extracted payload will contain C2PA-inspired\n        structured provenance information.\n\n        Args:\n            text: The text containing potentially embedded metadata.\n\n        Returns:\n            The extracted inner metadata dictionary if found and successfully parsed,\n            otherwise None.\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "encypher/interop/c2pa.py",
                "code": "def encypher_manifest_to_c2pa_like_dict(manifest: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Converts an EncypherAI ManifestPayload to a dictionary using field names\n    conceptually aligned with C2PA assertion structures.\n\n    This function provides a conceptual bridge between EncypherAI's plain-text\n    manifest format and C2PA's rich media manifest structure, enabling potential\n    interoperability between the two approaches.\n\n    Args:\n        manifest: An EncypherAI manifest payload dictionary (can be a TypedDict ManifestPayload\n                 or a regular dict with the same structure)\n\n    Returns:\n        A dictionary with field names aligned with C2PA concepts, containing the\n        same information as the original manifest.\n\n    Example:\n        from encypher.core.crypto_utils import ManifestPayload\n        from encypher.interop.c2pa import encypher_manifest_to_c2pa_like_dict\n\n        # Original EncypherAI manifest\n        manifest = ManifestPayload(\n            claim_generator=\"EncypherAI/1.1.0\",\n            assertions=[{\"label\": \"c2pa.created\", \"when\": \"2025-04-13T12:00:00Z\"}],\n            ai_assertion={\"model_id\": \"gpt-4o\", \"model_version\": \"1.0\"},\n            custom_claims={},\n            timestamp=\"2025-04-13T12:00:00Z\"\n        )\n\n        # Convert to C2PA-like structure\n        c2pa_dict = encypher_manifest_to_c2pa_like_dict(manifest)\n    \"\"\"\n    pass\n\ndef c2pa_like_dict_to_encypher_manifest(data: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Creates an EncypherAI ManifestPayload from a dictionary structured\n    similarly to C2PA assertions. Handles missing fields gracefully.\n\n    This function provides a conceptual bridge from C2PA-like structures\n    to EncypherAI's manifest format, enabling potential interoperability\n    between the two approaches.\n\n    Args:\n        data: A dictionary with C2PA-like structure containing provenance information.\n\n    Returns:\n        An EncypherAI ManifestPayload dictionary that can be used with EncypherAI's\n        embedding functions.\n\n    Example:\n        from encypher.interop.c2pa import c2pa_like_dict_to_encypher_manifest\n\n        # C2PA-like structure\n        c2pa_data = {\n            \"claim_generator\": \"SomeApp/1.0\",\n            \"assertions\": [\n                {\n                    \"label\": \"c2pa.created\",\n                    \"data\": {\"timestamp\": \"2025-04-13T12:00:00Z\"}\n                },\n                {\n                    \"label\": \"ai.model.info\",\n                    \"data\": {\"model_id\": \"gpt-4o\", \"model_version\": \"1.0\"}\n                }\n            ],\n            \"timestamp\": \"2025-04-13T12:00:00Z\"\n        }\n\n        # Convert to EncypherAI manifest\n        manifest = c2pa_like_dict_to_encypher_manifest(c2pa_data)\n    \"\"\"\n    pass\n\ndef get_c2pa_manifest_schema() -> Dict[str, Any]:\n    \"\"\"\n    Returns a JSON Schema representation of the C2PA-like structure used by this module.\n\n    This schema provides documentation for the expected structure of C2PA-like dictionaries\n    used with the conversion functions in this module.\n\n    Returns:\n        A dictionary containing the JSON Schema for C2PA-like structures.\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "encypher/streaming/handlers.py",
                "code": "class StreamingHandler:\n    \"\"\"\n    Handler for processing streaming chunks from LLM providers and encoding metadata.\n\n    This class ensures that metadata is properly encoded in streaming responses,\n    handling the complexities of partial text chunks while maintaining consistency.\n    \"\"\"\n\n    def __init__(\n        self,\n        metadata: Optional[Dict[str, Any]] = None,\n        target: Union[str, MetadataTarget] = \"whitespace\",\n        encode_first_chunk_only: bool = True,\n        private_key: Optional[PrivateKeyTypes] = None,\n        signer_id: Optional[str] = None,\n        metadata_format: Literal[\"basic\", \"manifest\"] = \"basic\",\n    ):\n        \"\"\"\n        Initialize the streaming handler.\n\n        Args:\n            metadata: Dictionary of metadata to encode. Must include keys required\n                      by the chosen `metadata_format`.\n            target: Where to embed the metadata (whitespace, punctuation, etc.)\n            encode_first_chunk_only: Whether to encode metadata only in the first\n                                     non-empty chunk. Currently, only True is fully\n                                     supported for signature embedding.\n            private_key: The private key for signing the metadata.\n            signer_id: An identifier for the signer (associated with the public key).\n            metadata_format: The structure ('basic' or 'manifest') of the metadata payload.\n\n        Raises:\n            ValueError: If `metadata_format` is invalid, or if `metadata` is provided\n                        without `private_key` and `signer_id`.\n            TypeError: If `metadata`, `encode_first_chunk_only`, `private_key`,\n                       or `signer_id` have incorrect types.\n        \"\"\"\n        pass\n\n    def process_chunk(self, chunk: Union[str, Dict[str, Any]]) -> Union[str, Dict[str, Any]]:\n        \"\"\"\n        Process a streaming chunk and encode metadata if needed.\n\n        This method handles both raw text chunks and structured chunks (like those from OpenAI).\n\n        Args:\n            chunk: Text chunk or dictionary containing a text chunk\n\n        Returns:\n            Processed chunk with encoded metadata, preserving the input chunk type (str or dict).\n\n        Raises:\n            ValueError: If the underlying text processing (_process_text_chunk) fails.\n            KeyError: If the expected keys ('choices', 'delta', 'content', etc.) are missing.\n            IndexError: If the 'choices' list is empty.\n        \"\"\"\n        pass\n\n    def finalize(self) -> Optional[str]:\n        \"\"\"\n        Finalize the stream and return any accumulated text with encoded metadata.\n\n        This method should be called after all chunks have been processed to handle\n        any remaining accumulated text that hasn't been processed yet.\n\n        Returns:\n            Processed accumulated text with encoded metadata, or None if no text accumulated\n\n        Raises:\n            ValueError: If UnicodeMetadata.embed_metadata fails (e.g., not enough targets).\n        \"\"\"\n        pass\n\n    def reset(self) -> None:\n        \"\"\"\n        Reset the handler state.\n\n        This is useful when starting a new streaming session.\n        \"\"\"\n        pass\n"
            }
        ]
    },
    {
        "idx": 15612,
        "repo_name": "plurch_ir_evaluation",
        "url": "https://github.com/plurch/ir_evaluation",
        "description": "Information retrieval evaluation metrics in pure python with zero dependencies",
        "stars": 8,
        "forks": 0,
        "language": "python",
        "size": 45,
        "created_at": "2025-01-07T17:39:57+00:00",
        "updated_at": "2025-02-09T19:55:42+00:00",
        "pypi_info": {
            "name": "ir_evaluation",
            "version": "1.1.0",
            "url": "https://files.pythonhosted.org/packages/96/f4/58a3c8bc1f2a44acfbc2bf34e8e941d4950aa94d6f590c273897db61ec77/ir_evaluation-1.1.0.tar.gz"
        },
        "error": null,
        "judge_info": {
            "language": "python",
            "is_good_project": false,
            "reason": "",
            "python_file_num": 4,
            "comment_ratio": 0.48128342245989303,
            "pyfile_content_length": 14844,
            "pyfile_code_lines": 374,
            "test_file_exist": true,
            "test_file_content_length": 4807,
            "pytest_framework": true,
            "test_case_num": 22,
            "metadata_path": [
                "pyproject.toml"
            ],
            "readme_content_length": 5151,
            "llm_reason": "The project is an excellent candidate for an AI 'Build from Scratch' benchmark. \nPositive Aspects:\n*   **Self-Contained & Independent:** The project's core logic is explicitly stated to be 'pure python implementations... without any library dependencies (not even numpy!)'. This is ideal as the AI-rebuilt solution would not require internet access or external APIs for its core functionality or testing. Dependencies for testing (pytest) are standard and separate from the core library logic.\n*   **Clear & Well-Defined Functionality:** It implements a set of standard and well-understood Information Retrieval (IR) metrics (Recall, Precision, F1, AP, MAP, nDCG, RR, MRR). The README and function docstrings clearly describe the purpose and inputs/outputs of each metric, making the re-implementation task specific.\n*   **Testable & Verifiable Output:** The project includes a comprehensive suite of unit tests (`tests/metrics_test.py`) using `pytest`. These tests cover various scenarios and assert specific floating-point results, providing a clear way to verify the AI's implementation.\n*   **No Graphical User Interface (GUI):** It's a Python library, intended for programmatic use, which fits the benchmark criteria.\n*   **Appropriate Complexity, Scope & Difficulty (Medium):** Re-implementing approximately 8 distinct IR metrics, each with its own mathematical formula and logic (handling lists, parameter `k`, etc.), presents a non-trivial but manageable challenge. It's more complex than a 'Hello World' example but not excessively large or requiring novel research. A human could likely build it in hours to a day.\n*   **Well-Understood Problem Domain:** IR evaluation metrics are a standard part of computer science and data science curricula.\n*   **Predominantly Code-Based Solution:** The task is to generate Python functions that implement these metrics.\n*   **Clear Structure:** The project has a simple and clear structure (`src/ir_evaluation/metrics.py` for logic, `tests/metrics_test.py` for tests).\n\nNegative Aspects or Concerns:\n*   There are no significant negative aspects that would make it unsuitable. The AI would need to be provided with the definitions or formulas for the metrics (which can be derived from the existing docstrings or standard IR literature as part of the problem specification). The potential use of the standard `math` library (e.g., for `log2` in nDCG) is perfectly acceptable and does not violate self-containment.\n\nOverall, this project is highly suitable due to its self-contained nature, clear scope, robust testability, and appropriate difficulty for an AI to replicate from scratch.",
            "llm_project_type": "Python library for Information Retrieval evaluation metrics",
            "llm_rating": 95,
            "llm_difficulty": "Medium"
        },
        "tests": {
            "repo_name": "plurch_ir_evaluation",
            "finish_test": true,
            "test_case_result": {
                "tests/metrics_test.py::TestRecall::test_recall_zero": "passed",
                "tests/metrics_test.py::TestRecall::test_recall_perfect": "passed",
                "tests/metrics_test.py::TestRecall::test_recall_k_5": "passed",
                "tests/metrics_test.py::TestRecall::test_recall_k_10": "passed",
                "tests/metrics_test.py::TestPrecision::test_precision_zero": "passed",
                "tests/metrics_test.py::TestPrecision::test_precision_k_5_perfect": "passed",
                "tests/metrics_test.py::TestPrecision::test_precision_k_5": "passed",
                "tests/metrics_test.py::TestPrecision::test_precision_k_10": "passed",
                "tests/metrics_test.py::TestF1::test_f1_zero": "passed",
                "tests/metrics_test.py::TestF1::test_f1_perfect": "passed",
                "tests/metrics_test.py::TestF1::test_f1_k_5": "passed",
                "tests/metrics_test.py::TestF1::test_f1_k_10": "passed",
                "tests/metrics_test.py::TestAveragePrecision::test_average_precision_basic": "passed",
                "tests/metrics_test.py::TestAveragePrecision::test_precision_k_5": "passed",
                "tests/metrics_test.py::TestAveragePrecision::test_precision_k_10": "passed",
                "tests/metrics_test.py::TestMeanAveragePrecision::test_mean_average_precision_basic": "passed",
                "tests/metrics_test.py::TestMeanAveragePrecision::test_mean_average_precision_pydoc": "passed",
                "tests/metrics_test.py::TestNCDG::test_ndcg_k_5": "passed",
                "tests/metrics_test.py::TestNCDG::test_ndcg_k_10": "passed",
                "tests/metrics_test.py::TestReciprocalRank::test_reciprocal_rank_k_10": "passed",
                "tests/metrics_test.py::TestReciprocalRank::test_reciprocal_rank_zero": "passed",
                "tests/metrics_test.py::TestMeanReciprocalRank::test_mean_reciprocal_rank_basic": "passed"
            },
            "success_count": 22,
            "failed_count": 0,
            "error_count": 0,
            "skipped_count": 0,
            "unknown_count": 0,
            "total_count": 22,
            "success_rate": 1.0,
            "coverage_report": {
                "covered_lines": 45,
                "num_statements": 45,
                "percent_covered": 100.0,
                "percent_covered_display": "100",
                "missing_lines": 0,
                "excluded_lines": 0,
                "num_branches": 6,
                "num_partial_branches": 0,
                "covered_branches": 6,
                "missing_branches": 0
            },
            "coverage_result": {}
        },
        "codelines_count": 374,
        "codefiles_count": 4,
        "code_length": 14844,
        "test_files_count": 1,
        "test_code_length": 4807,
        "structure": [
            {
                "file": "tests/metrics_test.py",
                "functions": [],
                "classes": [
                    {
                        "name": "TestRecall",
                        "docstring": null,
                        "comments": "intersection: {3, 4, 14}",
                        "methods": [
                            {
                                "name": "test_recall_zero",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_recall_perfect",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_recall_k_5",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_recall_k_10",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TestPrecision",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_precision_zero",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_precision_k_5_perfect",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_precision_k_5",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_precision_k_10",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TestF1",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_f1_zero",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_f1_perfect",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_f1_k_5",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_f1_k_10",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TestAveragePrecision",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_average_precision_basic",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_precision_k_5",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_precision_k_10",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TestMeanAveragePrecision",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_mean_average_precision_basic",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_mean_average_precision_pydoc",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TestNCDG",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_ndcg_k_5",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_ndcg_k_10",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TestReciprocalRank",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_reciprocal_rank_k_10",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_reciprocal_rank_zero",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TestMeanReciprocalRank",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_mean_reciprocal_rank_basic",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "src/ir_evaluation/metrics.py",
                "functions": [
                    {
                        "name": "mean_of_list",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "l"
                        ]
                    },
                    {
                        "name": "recall",
                        "docstring": "Calculate the recall@k metric.\n\nRecall is defined as the ratio of the total number of relevant items retrieved within the top-k predictions to the total number of relevant items in the entire database.\n\nRecall =  Total number of items retrieved that are relevant/Total number of relevant items in the database.\n\nArgs:\n  actual (list[int]): An array of ground truth relevant items.\n  predicted (list[int]): An array of predicted items, ordered by relevance.\n  k (int): The number of top predictions to consider.\n\nReturns:\n  float: The recall value at rank k, ranging from 0 to 1.\n         A value of 1 indicates perfect recall, while 0 indicates no relevant items retrieved.\n\nNotes:\n  - This function assumes the `predicted` array is sorted in descending order of relevance.\n  - If k is larger than the length of the `predicted` array, it will consider the entire array.",
                        "comments": null,
                        "args": [
                            "actual",
                            "predicted",
                            "k"
                        ]
                    },
                    {
                        "name": "precision",
                        "docstring": "Calculate the precision@k metric.\n\nPrecision is defined as the ratio of the total number of relevant items retrieved\nwithin the top-k predictions to the total number of returned items (k).\n\nPrecision =  Total number of items retrieved that are relevant/Total number of items that are retrieved.\n\nArgs:\n  actual (list[int]): An array of ground truth relevant items.\n  predicted (list[int]): An array of predicted items, ordered by relevance.\n  k (int): The number of top predictions to consider.\n\nReturns:\n  float: The precision value at rank k, ranging from 0 to 1.\n         A value of 1 indicates perfect precision, while 0 indicates no relevant items retrieved.\n\nNotes:\n  - This function assumes the `predicted` array is sorted in descending order of relevance.\n  - If k is larger than the length of the `predicted` array, it will consider the entire array.",
                        "comments": null,
                        "args": [
                            "actual",
                            "predicted",
                            "k"
                        ]
                    },
                    {
                        "name": "f1_score",
                        "docstring": "Calculate the F1-score @k metric.\n\nThe F1-score is calculated as the harmonic mean of precision and recall. The formula is:\nF1 = 2 * (Precision * Recall) / (Precision + Recall)\n\nThe F1 score provides a balanced view of a system's performance by taking into account both precision and recall. This is especially important when evaluating information retrieval systems, where finding all relevant documents is just as important as minimizing irrelevant ones.\n\nArgs:\n  actual (list[int]): An array of ground truth relevant items.\n  predicted (list[int]): An array of predicted items, ordered by relevance.\n  k (int): The number of top predictions to consider.\n\nReturns:\n  float: The F1 score value at rank k, ranging from 0 to 1.\n         A value of 1 indicates perfect precision and recall, while 0 indicates either precision or recall is zero.",
                        "comments": null,
                        "args": [
                            "actual",
                            "predicted",
                            "k"
                        ]
                    },
                    {
                        "name": "average_precision",
                        "docstring": "Computes the Average Precision (AP) at a specified rank `k`.\n\nAverage Precision (AP) is a metric used to evaluate the relevance of predicted rankings \nin information retrieval tasks. It is calculated as the mean of precision values at \neach rank where a relevant item is retrieved within the top `k` predictions.\n\nArgs:\n    actual (list[int]): A list of integers representing the ground truth relevant items.\n    predicted (list[int]): A list of integers representing the predicted rankings of items.\n    k (int): The maximum number of top-ranked items to consider for evaluation.\n\nReturns:\n    float: The Average Precision score. If no relevant items are retrieved within the\n    top `k` predictions, the function may raise a division by zero error or return `NaN`.",
                        "comments": null,
                        "args": [
                            "actual",
                            "predicted",
                            "k"
                        ]
                    },
                    {
                        "name": "mean_average_precision",
                        "docstring": "Computes the Mean Average Precision (MAP) at a specified rank `k`.\n\nIt is the mean of the Average Precision (AP) scores computed for multiple \nqueries.\n\nArgs:\n    actual_list (list[list[int]]): A list of lists where each inner list represents \n        the ground truth relevant items for a query\n    predicted_list (list[list[int]]): A list of lists where each inner list represents \n        the predicted rankings of items for a query\n    k (int): The maximum number of top-ranked items to consider for each prediction.\n\nReturns:\n    float: The Mean Average Precision score, which is the mean of AP scores across all \n    queries.\n\nRaises:\n    AssertionError: If the lengths of `actual_list` and `predicted_list` are not equal.",
                        "comments": null,
                        "args": [
                            "actual_list",
                            "predicted_list",
                            "k"
                        ]
                    },
                    {
                        "name": "ndcg",
                        "docstring": "Computes the Normalized Discounted Cumulative Gain (nDCG) at a specified rank `k`.\n\nnDCG evaluates the quality of a predicted ranking by comparing it to an ideal ranking \n(i.e., perfect ordering of relevant items). It accounts for the position of relevant \nitems in the ranking, giving higher weight to items appearing earlier.\n\nArgs:\n    actual (list[int]): A list of integers representing the ground truth relevant items.\n    predicted (list[int]): A list of integers representing the predicted rankings of items.\n    k (int): The maximum number of top-ranked items to consider for evaluation.\n\nReturns:\n    float: The nDCG score, which ranges from 0 to 1. A value of 1 indicates a perfect \n    ranking. Returns 0 if there are no relevant items in the top `k` predictions or if \n    the ideal DCG (iDCG) is zero.",
                        "comments": null,
                        "args": [
                            "actual",
                            "predicted",
                            "k"
                        ]
                    },
                    {
                        "name": "reciprocal_rank",
                        "docstring": "Computes the Reciprocal Rank (RR) at a specified rank `k`.\n\nReciprocal Rank (RR) assigns a score based on the reciprocal of the rank at which the first relevant item is found.\n\nArgs:\n    actual (list[int]): A list of integers representing the ground truth relevant items.\n    predicted (list[int]): A list of integers representing the predicted rankings of items.\n    k (int): The maximum number of top-ranked items to consider for evaluation.\n\nReturns:\n    float: The Reciprocal Rank score. A value of 0 is returned if no relevant items are \n    found within the top `k` predictions. Otherwise, the score is `1 / rank`, where \n    `rank` is the position (1-based) of the first relevant item.\n\nNotes:\n    - The function assumes zero-based indexing for the `predicted` list.\n    - If `k` exceeds the length of `predicted`, only the available elements in `predicted` \n      are considered.\n    - This metric focuses only on the rank of the first relevant item, ignoring others.",
                        "comments": null,
                        "args": [
                            "actual",
                            "predicted",
                            "k"
                        ]
                    },
                    {
                        "name": "mean_reciprocal_rank",
                        "docstring": "Computes the Mean Reciprocal Rank (MRR) at a specified rank `k`.\n\nIt calculates the mean of the Reciprocal Rank (RR) scores for a set of queries.\n\nArgs:\n    actual_list (list[list[int]]): A list of lists where each inner list represents the \n        ground truth relevant items for a query or task.\n    predicted_list (list[list[int]]): A list of lists where each inner list represents \n        the predicted rankings of items for a query or task.\n    k (int): The maximum number of top-ranked items to consider for each prediction.\n\nReturns:\n    float: The Mean Reciprocal Rank score, which is the average of RR scores across all \n    queries. Returns 0 if there are no queries or no relevant items in any predictions.\n\nRaises:\n    AssertionError: If the lengths of `actual_list` and `predicted_list` are not equal.",
                        "comments": null,
                        "args": [
                            "actual_list",
                            "predicted_list",
                            "k"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "src/ir_evaluation/__init__.py",
                "functions": [],
                "classes": []
            }
        ],
        "test_cases": {
            "tests/metrics_test.py::TestRecall::test_recall_zero": {
                "testid": "tests/metrics_test.py::TestRecall::test_recall_zero",
                "result": "passed",
                "test_implementation": "  def test_recall_zero(self):\n    result = recall(actual, [5,6,7,9,10], 5)\n    assert result == pytest.approx(0.0) # 0 out of 25"
            },
            "tests/metrics_test.py::TestRecall::test_recall_perfect": {
                "testid": "tests/metrics_test.py::TestRecall::test_recall_perfect",
                "result": "passed",
                "test_implementation": "  def test_recall_perfect(self):\n    actual_cloned = list(actual)\n    random.shuffle(actual_cloned) # does in place shuffle\n    result = recall(actual, actual_cloned, len(actual))\n    assert result == pytest.approx(1.0) # 5 out of 5"
            },
            "tests/metrics_test.py::TestRecall::test_recall_k_5": {
                "testid": "tests/metrics_test.py::TestRecall::test_recall_k_5",
                "result": "passed",
                "test_implementation": "  def test_recall_k_5(self):\n    result = recall(actual, predicted, 5)\n    assert result == pytest.approx(0.04) # 1 out of 25"
            },
            "tests/metrics_test.py::TestRecall::test_recall_k_10": {
                "testid": "tests/metrics_test.py::TestRecall::test_recall_k_10",
                "result": "passed",
                "test_implementation": "  def test_recall_k_10(self):\n    result = recall(actual, predicted, 10)\n    assert result == pytest.approx(0.12) # 3 out of 25"
            },
            "tests/metrics_test.py::TestPrecision::test_precision_zero": {
                "testid": "tests/metrics_test.py::TestPrecision::test_precision_zero",
                "result": "passed",
                "test_implementation": "  def test_precision_zero(self):\n    result = precision(actual, [5,6,7,9,10], 5)\n    assert result == pytest.approx(0.0) # 0 out of 25"
            },
            "tests/metrics_test.py::TestPrecision::test_precision_k_5_perfect": {
                "testid": "tests/metrics_test.py::TestPrecision::test_precision_k_5_perfect",
                "result": "passed",
                "test_implementation": "  def test_precision_k_5_perfect(self):\n    result = precision(actual, [11, 58, 31, 8, 85], 5)\n    assert result == pytest.approx(1.0) # 5 out of 5"
            },
            "tests/metrics_test.py::TestPrecision::test_precision_k_5": {
                "testid": "tests/metrics_test.py::TestPrecision::test_precision_k_5",
                "result": "passed",
                "test_implementation": "  def test_precision_k_5(self):\n    result = average_precision(actual, predicted, 5)\n    assert result == pytest.approx(0.2)"
            },
            "tests/metrics_test.py::TestPrecision::test_precision_k_10": {
                "testid": "tests/metrics_test.py::TestPrecision::test_precision_k_10",
                "result": "passed",
                "test_implementation": "  def test_precision_k_10(self):\n    result = average_precision(actual, predicted, 10)\n    assert result == pytest.approx(0.30277777777777776)"
            },
            "tests/metrics_test.py::TestF1::test_f1_zero": {
                "testid": "tests/metrics_test.py::TestF1::test_f1_zero",
                "result": "passed",
                "test_implementation": "  def test_f1_zero(self):\n    result = f1_score(actual, [5,6,7,9,10], 5)\n    assert result == pytest.approx(0.0)"
            },
            "tests/metrics_test.py::TestF1::test_f1_perfect": {
                "testid": "tests/metrics_test.py::TestF1::test_f1_perfect",
                "result": "passed",
                "test_implementation": "  def test_f1_perfect(self):\n    result = f1_score([8, 11, 31, 58, 85], [11, 58, 31, 8, 85], 5)\n    assert result == pytest.approx(1.0)"
            },
            "tests/metrics_test.py::TestF1::test_f1_k_5": {
                "testid": "tests/metrics_test.py::TestF1::test_f1_k_5",
                "result": "passed",
                "test_implementation": "  def test_f1_k_5(self):\n    result = f1_score(actual, predicted, 5)\n    assert result == pytest.approx(0.06666666666666667) # precision: 0.2, recall: 0.04"
            },
            "tests/metrics_test.py::TestF1::test_f1_k_10": {
                "testid": "tests/metrics_test.py::TestF1::test_f1_k_10",
                "result": "passed",
                "test_implementation": "  def test_f1_k_10(self):\n    result = f1_score(actual, predicted, 10)\n    assert result == pytest.approx(0.17142857142857143) # precision: 0.3, recall: 0.12"
            },
            "tests/metrics_test.py::TestAveragePrecision::test_average_precision_basic": {
                "testid": "tests/metrics_test.py::TestAveragePrecision::test_average_precision_basic",
                "result": "passed",
                "test_implementation": "  def test_average_precision_basic(self):\n    # basic inputs\n    result = average_precision([1,3,5], [1,2,3,4,5], 5)\n    assert result == pytest.approx(0.7555555555555555) # (1 + 0.67 + 0.6) / 3 = 0.75555"
            },
            "tests/metrics_test.py::TestAveragePrecision::test_precision_k_5": {
                "testid": "tests/metrics_test.py::TestAveragePrecision::test_precision_k_5",
                "result": "passed",
                "test_implementation": "  def test_precision_k_5(self):\n    result = average_precision(actual, predicted, 5)\n    assert result == pytest.approx(0.2)"
            },
            "tests/metrics_test.py::TestAveragePrecision::test_precision_k_10": {
                "testid": "tests/metrics_test.py::TestAveragePrecision::test_precision_k_10",
                "result": "passed",
                "test_implementation": "  def test_precision_k_10(self):\n    result = average_precision(actual, predicted, 10)\n    assert result == pytest.approx(0.30277777777777776)"
            },
            "tests/metrics_test.py::TestMeanAveragePrecision::test_mean_average_precision_basic": {
                "testid": "tests/metrics_test.py::TestMeanAveragePrecision::test_mean_average_precision_basic",
                "result": "passed",
                "test_implementation": "  def test_mean_average_precision_basic(self):\n    # basic inputs\n    actual_list = [\n      [1,3,5],\n      [2,4,6],\n      [7,8,9]\n    ]\n\n    predicted_list = [\n      [1,2,3,4,5],\n      [9,2,3,1,5],\n      [4,5,9,8,3]\n    ]\n    result = mean_average_precision(actual_list, predicted_list, 5)\n    # ap values: [0.7555555555555555, 0.5, 0.41666666666666663]\n    assert result == pytest.approx(0.5574074074074074)"
            },
            "tests/metrics_test.py::TestMeanAveragePrecision::test_mean_average_precision_pydoc": {
                "testid": "tests/metrics_test.py::TestMeanAveragePrecision::test_mean_average_precision_pydoc",
                "result": "passed",
                "test_implementation": "  def test_mean_average_precision_pydoc(self):\n    # inputs from pydoc string\n    actual_list = [[1, 2, 3], [2, 3, 4]]\n\n    predicted_list = [[1, 4, 2, 3], [2, 3, 5, 4]]\n    result = mean_average_precision(actual_list, predicted_list, 3)\n    # ap values: [0.8333333333333333, 1.0]\n    assert result == pytest.approx(0.9166666666666666)"
            },
            "tests/metrics_test.py::TestNCDG::test_ndcg_k_5": {
                "testid": "tests/metrics_test.py::TestNCDG::test_ndcg_k_5",
                "result": "passed",
                "test_implementation": "  def test_ndcg_k_5(self):\n    result = ndcg(actual, predicted, 5)\n    assert result == pytest.approx(0.13120507751234178)"
            },
            "tests/metrics_test.py::TestNCDG::test_ndcg_k_10": {
                "testid": "tests/metrics_test.py::TestNCDG::test_ndcg_k_10",
                "result": "passed",
                "test_implementation": "  def test_ndcg_k_10(self):\n    result = ndcg(actual, predicted, 10)\n    assert result == pytest.approx(0.23297260855707355)"
            },
            "tests/metrics_test.py::TestReciprocalRank::test_reciprocal_rank_k_10": {
                "testid": "tests/metrics_test.py::TestReciprocalRank::test_reciprocal_rank_k_10",
                "result": "passed",
                "test_implementation": "  def test_reciprocal_rank_k_10(self):\n    result = reciprocal_rank(actual, predicted, 10)\n    assert result == pytest.approx(0.2) # found at position 5"
            },
            "tests/metrics_test.py::TestReciprocalRank::test_reciprocal_rank_zero": {
                "testid": "tests/metrics_test.py::TestReciprocalRank::test_reciprocal_rank_zero",
                "result": "passed",
                "test_implementation": "  def test_reciprocal_rank_zero(self):\n    result = reciprocal_rank([1,2,3], [4,5,6,7,8], 5)\n    assert result == pytest.approx(0) # no relevant items found"
            },
            "tests/metrics_test.py::TestMeanReciprocalRank::test_mean_reciprocal_rank_basic": {
                "testid": "tests/metrics_test.py::TestMeanReciprocalRank::test_mean_reciprocal_rank_basic",
                "result": "passed",
                "test_implementation": "  def test_mean_reciprocal_rank_basic(self):\n    # basic inputs\n    actual_list = [\n      [1,3,5],\n      [2,4,6],\n      [7,8,9],\n      [7,8,9]\n    ]\n\n    predicted_list = [\n      [1,2,3,4,5],\n      [9,2,3,1,5],\n      [4,5,9,8,3],\n      [1,2,3,4,5]\n    ]\n    result = mean_reciprocal_rank(actual_list, predicted_list, 5)\n    # rr values: [1.0, 0.5, 0.333, 0]\n    assert result == pytest.approx(0.4583333333333333)"
            }
        },
        "SRS_document": "**Software Requirements Specification: Information Retrieval Evaluation Metrics Library**\n\n**1. Introduction**\n\n**1.1 Purpose**\nThis Software Requirements Specification (SRS) document defines the requirements for an Information Retrieval (IR) Evaluation Metrics Library. Its primary role is to serve as the sole specification for software developers who will be assessed on their ability to develop a complete, functional software project based on this SRS. The developers' implementations will be evaluated against a comprehensive set of original test cases, including public (provided) and private (not provided) tests.\n\nThis document aims to be exceptionally clear, unambiguous, comprehensive in functional capabilities, and appropriately abstracted to allow for independent design and implementation choices while ensuring all specified functionalities are met.\n\n**1.2 Scope**\nThe software to be developed is a Python library providing implementations of common information retrieval (IR) and recommender system evaluation metrics. The library will calculate various metrics based on lists of actual relevant items and predicted items. It is intended to be a pure Python solution with no external library dependencies (e.g., numpy).\n\nThe library will provide the following metrics:\n*   Recall@k\n*   Precision@k\n*   F1 Score@k\n*   Average Precision@k (AP)\n*   Mean Average Precision@k (MAP)\n*   Normalized Discounted Cumulative Gain@k (nDCG)\n*   Reciprocal Rank@k (RR)\n*   Mean Reciprocal Rank@k (MRR)\n\n**1.3 Definitions, Acronyms, and Abbreviations**\n*   **AP:** Average Precision\n*   **DCG:** Discounted Cumulative Gain\n*   **IDCG:** Ideal Discounted Cumulative Gain\n*   **IR:** Information Retrieval\n*   **Item ID:** An integer identifier for an item.\n*   **k:** An integer representing the number of top-ranked predictions to consider for a metric.\n*   **MAP:** Mean Average Precision\n*   **MRR:** Mean Reciprocal Rank\n*   **nDCG:** Normalized Discounted Cumulative Gain\n*   **RR:** Reciprocal Rank\n*   **SRS:** Software Requirements Specification\n\n**1.4 References**\n*   Project README (`README.md` - as provided in the prompt)\n*   Original source code (`src/ir_evaluation/metrics.py` - for LLM contextual understanding only)\n*   Original test cases (`tests/metrics_test.py` - for LLM contextual understanding and traceability)\n\n**1.5 Overview**\nThis SRS is organized into three main sections:\n*   **Section 1 (Introduction):** Provides the purpose, scope, definitions, references, and overview of the SRS.\n*   **Section 2 (Overall Description):** Describes the product perspective, functions, user characteristics, constraints, assumptions, and dependencies.\n*   **Section 3 (Specific Requirements):** Details the functional requirements of the system. Non-functional requirements are omitted as per the guideline that they must be strictly derived from explicit test cases validating them, and no such test cases were identified for NFRs separate from functional correctness.\n\n**2. Overall Description**\n\n**2.1 Product Perspective**\nThe IR Evaluation Metrics Library is a pure Python software component intended to be used by developers and researchers working on information retrieval systems, search engines, or recommender systems. It provides a set of functions to quantify the performance of ranking algorithms. The library must be implemented without any dependencies on third-party libraries beyond the Python standard library.\n\n**2.2 Product Functions**\nThe system shall provide functions to calculate the following IR evaluation metrics:\n1.  **Recall@k:** Measures the proportion of actual relevant items correctly retrieved among the top-k predictions.\n2.  **Precision@k:** Measures the proportion of retrieved top-k items that are actually relevant.\n3.  **F1 Score@k:** Computes the harmonic mean of Precision@k and Recall@k.\n4.  **Average Precision@k (AP):** Evaluates the precision at each rank where a relevant item is found, then averages these precision values.\n5.  **Mean Average Precision@k (MAP):** Computes the mean of AP scores across multiple queries or rankings.\n6.  **Normalized Discounted Cumulative Gain@k (nDCG):** Assesses ranking quality by considering the position of relevant items, giving more weight to those ranked higher, normalized against an ideal ranking.\n7.  **Reciprocal Rank@k (RR):** Measures the reciprocal of the rank of the first relevant item found.\n8.  **Mean Reciprocal Rank@k (MRR):** Computes the mean of RR scores across multiple queries or rankings.\n\nAll metric calculation functions will accept lists of item identifiers for actual relevant items and predicted items, along with the parameter `k`. They will return a floating-point number representing the calculated metric value.\n\n**2.3 User Characteristics**\nThe users of this library are software developers and researchers who need to evaluate the performance of information retrieval or recommendation systems. They are expected to have programming knowledge in Python and an understanding of IR concepts and evaluation metrics.\n\n**2.4 Constraints**\n*   **C-1:** The software must be implemented in Python. (Source: README - \"pure python implementations\")\n*   **C-2:** The software must be compatible with Python version 3.11 or higher. (Source: README - \"Requires: Python >=3.11\")\n*   **C-3:** The software must not have any external library dependencies beyond the Python standard library. (Source: README - \"without any library dependencies (not even numpy!)\")\n*   **C-4:** Input `predicted` lists are assumed to be pre-sorted by relevance, with the most relevant items appearing earliest in the list. (Source: README - \"ordered by relevance\", `metrics.py` docstrings)\n\n**2.5 Assumptions and Dependencies**\n*   **A-1:** Item identifiers are integers. (Source: Type hints `list[int]` in `metrics.py`)\n*   **A-2:** The `actual` list contains ground truth relevant item IDs. Duplicates within the `actual` list might be provided, but calculations involving the set of actual relevant items should consider only unique IDs.\n\n**3. Specific Requirements**\n\n**3.1 Functional Requirements**\n\nThis section details the functional requirements for each evaluation metric.\n\n**FR-COM-INPUTS: Common Input Parameters**\nUnless otherwise specified for a particular metric, the primary metric functions accept the following parameters:\n*   `actual` (list[int]): A list of integer item identifiers representing the ground truth relevant items for a single query.\n*   `predicted` (list[int]): A list of integer item identifiers representing the items predicted by the system, ordered by estimated relevance (most relevant first) for a single query.\n*   `k` (int): A non-negative integer representing the number of top predictions from the `predicted` list to consider for the metric calculation.\n\n**FR-RCL-1: Calculate Recall@k**\n*   **Description:** The system shall calculate Recall@k, which measures the proportion of unique actual relevant items that are found within the top `k` items of the `predicted` list.\n    The formula is: `(Number of unique relevant items in top-k predictions) / (Total number of unique actual relevant items)`\n*   **Processing Details:**\n    1.  Identify the set of unique item IDs from the `actual` list (`S_actual`).\n    2.  Consider the first `k` item IDs from the `predicted` list. If `k` is greater than the length of `predicted`, all items in `predicted` are considered. Let this sub-list be `P_top_k`.\n    3.  Identify the set of unique item IDs in `P_top_k` that are also present in `S_actual` (`S_retrieved_relevant`).\n    4.  Recall@k = `count(S_retrieved_relevant) / count(S_actual)`.\n*   **Output:** A float representing Recall@k, typically ranging from 0.0 to 1.0.\n*   **Special Conditions:**\n    *   If `count(S_actual)` is 0 (i.e., the `actual` list is empty or contains no unique items), Recall@k is undefined and will result in a division by zero.\n    *   If `k` is 0, `S_retrieved_relevant` will be empty, resulting in Recall@k = 0.0, unless `count(S_actual)` is also 0 (see above).\n\n**FR-PRC-1: Calculate Precision@k**\n*   **Description:** The system shall calculate Precision@k, which measures the proportion of items in the top `k` of the `predicted` list that are actually relevant.\n    The formula is: `(Number of unique relevant items in top-k predictions) / k`\n*   **Processing Details:**\n    1.  Identify the set of unique item IDs from the `actual` list (`S_actual`).\n    2.  Consider the first `k` item IDs from the `predicted` list. If `k` is greater than the length of `predicted`, all items in `predicted` are effectively considered for finding common items, but the denominator remains `k`. Let this sub-list be `P_top_k`.\n    3.  Identify the set of unique item IDs in `P_top_k` that are also present in `S_actual` (`S_retrieved_relevant`).\n    4.  Precision@k = `count(S_retrieved_relevant) / k`.\n*   **Output:** A float representing Precision@k, typically ranging from 0.0 to 1.0.\n*   **Special Conditions:**\n    *   If `k` is 0, Precision@k is undefined and will result in a division by zero.\n\n**FR-F1S-1: Calculate F1 Score@k**\n*   **Description:** The system shall calculate the F1 Score@k, which is the harmonic mean of Precision@k and Recall@k.\n    The formula is: `2 * (Precision@k * Recall@k) / (Precision@k + Recall@k)`\n*   **Processing Details:**\n    1.  Calculate Recall@k as per FR-RCL-1.\n    2.  Calculate Precision@k as per FR-PRC-1.\n    3.  Compute F1 Score@k using the formula above.\n*   **Output:** A float representing F1 Score@k, ranging from 0.0 to 1.0.\n*   **Special Conditions:**\n    *   If either Precision@k or Recall@k is 0, the F1 Score@k is 0.0.\n    *   If the calculation of Precision@k results in division by zero (i.e., `k=0`), F1 Score@k calculation will also be affected (inherit division by zero).\n    *   If the calculation of Recall@k results in division by zero, F1 Score@k calculation will also be affected.\n\n**FR-AP-1: Calculate Average Precision@k (AP)**\n*   **Description:** The system shall calculate Average Precision@k (AP). AP is the mean of precision values calculated at each rank `i` (from 1 to `k`) where a relevant item is found in the `predicted` list.\n*   **Processing Details:**\n    1.  Identify the set of unique item IDs from the `actual` list (`S_actual`).\n    2.  Initialize an empty list, `precision_values_at_relevant_ranks`.\n    3.  Iterate from rank `i = 1` to `k`. For each rank `i`:\n        a.  Let the item at rank `i` (0-indexed `i-1`) in `predicted` be `P_i`.\n        b.  If `P_i` is in `S_actual`:\n            i.  Calculate Precision@i for the `predicted` list up to rank `i` (using `S_actual` and current `P_1...P_i`, and `i` as the cutoff).\n            ii. Add this Precision@i value to `precision_values_at_relevant_ranks`.\n    4.  AP@k is the arithmetic mean of the values in `precision_values_at_relevant_ranks`.\n*   **Output:** A float representing AP@k.\n*   **Special Conditions:**\n    *   It is an implicit precondition that `k` does not exceed the number of items in the `predicted` list. If `k > len(predicted)`, accessing `predicted[i-1]` for `i > len(predicted)` will lead to an error.\n    *   If no relevant items are found in the `predicted` list up to `k` items (`precision_values_at_relevant_ranks` is empty), AP@k is undefined and will result in a division by zero when calculating the mean.\n    *   If `k` is 0, the list of precision values will be empty, leading to division by zero.\n\n**FR-MAP-1: Calculate Mean Average Precision@k (MAP)**\n*   **Description:** The system shall calculate Mean Average Precision@k (MAP), which is the mean of AP@k scores computed across multiple queries.\n*   **Inputs:**\n    *   `actual_list` (list[list[int]]): A list of `actual` lists. Each inner list corresponds to a single query.\n    *   `predicted_list` (list[list[int]]): A list of `predicted` lists. Each inner list corresponds to a single query, matching the order in `actual_list`.\n    *   `k` (int): A non-negative integer representing the number of top predictions to consider for each query's AP calculation.\n*   **Processing Details:**\n    1.  Initialize an empty list, `ap_scores`.\n    2.  For each pair of (`actual`, `predicted`) lists from `actual_list` and `predicted_list` respectively:\n        a.  Calculate AP@k for this pair as per FR-AP-1.\n        b.  Add the calculated AP@k to `ap_scores`.\n    3.  MAP@k is the arithmetic mean of the values in `ap_scores`.\n*   **Output:** A float representing MAP@k.\n*   **Preconditions:**\n    *   The `actual_list` and `predicted_list` must contain the same number of inner lists (queries). If this precondition is not met, the system shall raise an error (e.g., `AssertionError`).\n*   **Special Conditions:**\n    *   If `actual_list` (and thus `predicted_list`) is empty, `ap_scores` will be empty, and MAP@k is undefined (division by zero when calculating the mean).\n    *   Special conditions from FR-AP-1 (e.g., regarding `k` relative to `len(predicted)` for inner lists, or empty `precision_values_at_relevant_ranks` for an individual AP) apply to each AP calculation.\n\n**FR-NDCG-1: Calculate Normalized Discounted Cumulative Gain@k (nDCG)**\n*   **Description:** The system shall calculate Normalized Discounted Cumulative Gain@k (nDCG), which evaluates ranking quality by considering both the relevance (binary: relevant or not) and position of items, normalized by an ideal ranking.\n*   **Processing Details:**\n    1.  Identify the set of unique item IDs from the `actual` list (`S_actual`).\n    2.  Calculate Discounted Cumulative Gain (DCG@k):\n        a.  Initialize `DCG = 0.0`.\n        b.  Iterate from rank `i = 1` to `k`. For each rank `i`:\n            i.  Let the item at rank `i` (0-indexed `i-1`) in `predicted` be `P_i`.\n            ii. If `P_i` is in `S_actual`, add `1.0 / log2(i + 1)` to `DCG`. (Note: `log2` is base-2 logarithm. Rank `i` is 1-based).\n    3.  Calculate Ideal Discounted Cumulative Gain (IDCG@k):\n        a.  Initialize `IDCG = 0.0`.\n        b.  Consider an ideal ranking where all items from `S_actual` are ranked at the top, up to `min(k, count(S_actual))` positions.\n        c.  Iterate from rank `j = 1` to `min(k, count(S_actual))`. For each rank `j`:\n            i.  Add `1.0 / log2(j + 1)` to `IDCG`.\n    4.  nDCG@k = `DCG@k / IDCG@k`.\n*   **Output:** A float representing nDCG@k, typically ranging from 0.0 to 1.0.\n*   **Special Conditions:**\n    *   It is an implicit precondition that `k` does not exceed the number of items in the `predicted` list for DCG calculation. If `k > len(predicted)`, accessing `predicted[i-1]` for `i > len(predicted)` will lead to an error.\n    *   If `IDCG@k` is 0 (e.g., `S_actual` is empty, or `k=0` such that `min(k, count(S_actual))` is 0), nDCG@k is undefined and will result in a division by zero.\n    *   If `k` is 0, both DCG and IDCG will be 0, leading to `0/0` (division by zero or NaN).\n\n**FR-RR-1: Calculate Reciprocal Rank@k (RR)**\n*   **Description:** The system shall calculate Reciprocal Rank@k (RR), which is the reciprocal of the rank of the first relevant item found in the top `k` positions of the `predicted` list.\n*   **Processing Details:**\n    1.  Identify the set of unique item IDs from the `actual` list (`S_actual`).\n    2.  Iterate from rank `i = 1` to `k`. For each rank `i`:\n        a.  Let the item at rank `i` (0-indexed `i-1`) in `predicted` be `P_i`.\n        b.  If `P_i` is in `S_actual`, RR@k = `1.0 / i`. Return this value immediately.\n    3.  If no relevant item is found in the first `k` positions, RR@k = 0.0.\n*   **Output:** A float representing RR@k.\n*   **Special Conditions:**\n    *   It is an implicit precondition that `k` does not exceed the number of items in the `predicted` list. If `k > len(predicted)`, accessing `predicted[i-1]` for `i > len(predicted)` will lead to an error.\n    *   If `k` is 0, the loop will not execute, and the system shall return 0.0.\n\n**FR-MRR-1: Calculate Mean Reciprocal Rank@k (MRR)**\n*   **Description:** The system shall calculate Mean Reciprocal Rank@k (MRR), which is the mean of RR@k scores computed across multiple queries.\n*   **Inputs:**\n    *   `actual_list` (list[list[int]]): A list of `actual` lists. Each inner list corresponds to a single query.\n    *   `predicted_list` (list[list[int]]): A list of `predicted` lists. Each inner list corresponds to a single query, matching the order in `actual_list`.\n    *   `k` (int): A non-negative integer representing the number of top predictions to consider for each query's RR calculation.\n*   **Processing Details:**\n    1.  Initialize an empty list, `rr_scores`.\n    2.  For each pair of (`actual`, `predicted`) lists from `actual_list` and `predicted_list` respectively:\n        a.  Calculate RR@k for this pair as per FR-RR-1.\n        b.  Add the calculated RR@k to `rr_scores`.\n    3.  MRR@k is the arithmetic mean of the values in `rr_scores`.\n*   **Output:** A float representing MRR@k.\n*   **Preconditions:**\n    *   The `actual_list` and `predicted_list` must contain the same number of inner lists (queries). If this precondition is not met, the system shall raise an error (e.g., `AssertionError`).\n*   **Special Conditions:**\n    *   If `actual_list` (and thus `predicted_list`) is empty, `rr_scores` will be empty, and MRR@k is undefined (division by zero when calculating the mean).\n    *   Special conditions from FR-RR-1 (e.g., regarding `k` relative to `len(predicted)` for inner lists) apply to each RR calculation.\n\n**3.2 Non-Functional Requirements**\nNo non-functional requirements are specified in this document, as per the guideline that NFRs must be strictly derived from explicit original test cases directly validating them. The provided test cases primarily focus on the functional correctness of the metric calculations. Preconditions related to input integrity (e.g., matching list lengths for MAP/MRR) are specified as part of the functional requirements for those specific metrics.",
        "structured_requirements": [
            {
                "requirement_id": "C-1",
                "requirement_description": "The software must be implemented in Python. (Source: README - \"pure python implementations\")",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "C-2",
                "requirement_description": "The software must be compatible with Python version 3.11 or higher. (Source: README - \"Requires: Python >=3.11\")",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "C-3",
                "requirement_description": "The software must not have any external library dependencies beyond the Python standard library. (Source: README - \"without any library dependencies (not even numpy!)\")",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "C-4",
                "requirement_description": "Input `predicted` lists are assumed to be pre-sorted by relevance, with the most relevant items appearing earliest in the list. (Source: README - \"ordered by relevance\", `metrics.py` docstrings)",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "A-1",
                "requirement_description": "Item identifiers are integers. (Source: Type hints `list[int]` in `metrics.py`)",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "A-2",
                "requirement_description": "The `actual` list contains ground truth relevant item IDs. Duplicates within the `actual` list might be provided, but calculations involving the set of actual relevant items should consider only unique IDs.",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "FR-COM-INPUTS",
                "requirement_description": "Unless otherwise specified for a particular metric, the primary metric functions accept the following parameters:\n*   `actual` (list[int]): A list of integer item identifiers representing the ground truth relevant items for a single query.\n*   `predicted` (list[int]): A list of integer item identifiers representing the items predicted by the system, ordered by estimated relevance (most relevant first) for a single query.\n*   `k` (int): A non-negative integer representing the number of top predictions from the `predicted` list to consider for the metric calculation.",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "FR-RCL-1",
                "requirement_description": "The system shall calculate Recall@k, which measures the proportion of unique actual relevant items that are found within the top `k` items of the `predicted` list.\n    The formula is: `(Number of unique relevant items in top-k predictions) / (Total number of unique actual relevant items)`\n*   **Processing Details:**\n    1.  Identify the set of unique item IDs from the `actual` list (`S_actual`).\n    2.  Consider the first `k` item IDs from the `predicted` list. If `k` is greater than the length of `predicted`, all items in `predicted` are considered. Let this sub-list be `P_top_k`.\n    3.  Identify the set of unique item IDs in `P_top_k` that are also present in `S_actual` (`S_retrieved_relevant`).\n    4.  Recall@k = `count(S_retrieved_relevant) / count(S_actual)`.\n*   **Output:** A float representing Recall@k, typically ranging from 0.0 to 1.0.\n*   **Special Conditions:**\n    *   If `count(S_actual)` is 0 (i.e., the `actual` list is empty or contains no unique items), Recall@k is undefined and will result in a division by zero.\n    *   If `k` is 0, `S_retrieved_relevant` will be empty, resulting in Recall@k = 0.0, unless `count(S_actual)` is also 0 (see above).",
                "test_traceability": [
                    {
                        "id": "tests/metrics_test.py::TestRecall::test_recall_zero",
                        "description": ""
                    },
                    {
                        "id": "tests/metrics_test.py::TestRecall::test_recall_perfect",
                        "description": ""
                    },
                    {
                        "id": "tests/metrics_test.py::TestRecall::test_recall_k_5",
                        "description": ""
                    },
                    {
                        "id": "tests/metrics_test.py::TestRecall::test_recall_k_10",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ir_evaluation/metrics.py::recall",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PRC-1",
                "requirement_description": "The system shall calculate Precision@k, which measures the proportion of items in the top `k` of the `predicted` list that are actually relevant.\n    The formula is: `(Number of unique relevant items in top-k predictions) / k`\n*   **Processing Details:**\n    1.  Identify the set of unique item IDs from the `actual` list (`S_actual`).\n    2.  Consider the first `k` item IDs from the `predicted` list. If `k` is greater than the length of `predicted`, all items in `predicted` are effectively considered for finding common items, but the denominator remains `k`. Let this sub-list be `P_top_k`.\n    3.  Identify the set of unique item IDs in `P_top_k` that are also present in `S_actual` (`S_retrieved_relevant`).\n    4.  Precision@k = `count(S_retrieved_relevant) / k`.\n*   **Output:** A float representing Precision@k, typically ranging from 0.0 to 1.0.\n*   **Special Conditions:**\n    *   If `k` is 0, Precision@k is undefined and will result in a division by zero.",
                "test_traceability": [
                    {
                        "id": "tests/metrics_test.py::TestPrecision::test_precision_zero",
                        "description": ""
                    },
                    {
                        "id": "tests/metrics_test.py::TestPrecision::test_precision_k_5_perfect",
                        "description": ""
                    },
                    {
                        "id": "tests/metrics_test.py::TestPrecision::test_precision_k_5",
                        "description": ""
                    },
                    {
                        "id": "tests/metrics_test.py::TestPrecision::test_precision_k_10",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ir_evaluation/metrics.py::precision",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-F1S-1",
                "requirement_description": "The system shall calculate the F1 Score@k, which is the harmonic mean of Precision@k and Recall@k.\n    The formula is: `2 * (Precision@k * Recall@k) / (Precision@k + Recall@k)`\n*   **Processing Details:**\n    1.  Calculate Recall@k as per FR-RCL-1.\n    2.  Calculate Precision@k as per FR-PRC-1.\n    3.  Compute F1 Score@k using the formula above.\n*   **Output:** A float representing F1 Score@k, ranging from 0.0 to 1.0.\n*   **Special Conditions:**\n    *   If either Precision@k or Recall@k is 0, the F1 Score@k is 0.0.\n    *   If the calculation of Precision@k results in division by zero (i.e., `k=0`), F1 Score@k calculation will also be affected (inherit division by zero).\n    *   If the calculation of Recall@k results in division by zero, F1 Score@k calculation will also be affected.",
                "test_traceability": [
                    {
                        "id": "tests/metrics_test.py::TestF1::test_f1_zero",
                        "description": ""
                    },
                    {
                        "id": "tests/metrics_test.py::TestF1::test_f1_perfect",
                        "description": ""
                    },
                    {
                        "id": "tests/metrics_test.py::TestF1::test_f1_k_5",
                        "description": ""
                    },
                    {
                        "id": "tests/metrics_test.py::TestF1::test_f1_k_10",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ir_evaluation/metrics.py::f1_score",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-AP-1",
                "requirement_description": "The system shall calculate Average Precision@k (AP). AP is the mean of precision values calculated at each rank `i` (from 1 to `k`) where a relevant item is found in the `predicted` list.\n*   **Processing Details:**\n    1.  Identify the set of unique item IDs from the `actual` list (`S_actual`).\n    2.  Initialize an empty list, `precision_values_at_relevant_ranks`.\n    3.  Iterate from rank `i = 1` to `k`. For each rank `i`:\n        a.  Let the item at rank `i` (0-indexed `i-1`) in `predicted` be `P_i`.\n        b.  If `P_i` is in `S_actual`:\n            i.  Calculate Precision@i for the `predicted` list up to rank `i` (using `S_actual` and current `P_1...P_i`, and `i` as the cutoff).\n            ii. Add this Precision@i value to `precision_values_at_relevant_ranks`.\n    4.  AP@k is the arithmetic mean of the values in `precision_values_at_relevant_ranks`.\n*   **Output:** A float representing AP@k.\n*   **Special Conditions:**\n    *   It is an implicit precondition that `k` does not exceed the number of items in the `predicted` list. If `k > len(predicted)`, accessing `predicted[i-1]` for `i > len(predicted)` will lead to an error.\n    *   If no relevant items are found in the `predicted` list up to `k` items (`precision_values_at_relevant_ranks` is empty), AP@k is undefined and will result in a division by zero when calculating the mean.\n    *   If `k` is 0, the list of precision values will be empty, leading to division by zero.",
                "test_traceability": [
                    {
                        "id": "tests/metrics_test.py::TestAveragePrecision::test_average_precision_basic",
                        "description": ""
                    },
                    {
                        "id": "tests/metrics_test.py::TestAveragePrecision::test_precision_k_5",
                        "description": "(Note: test name might be misleading, it tests AP)"
                    },
                    {
                        "id": "tests/metrics_test.py::TestAveragePrecision::test_precision_k_10",
                        "description": "(Note: test name might be misleading, it tests AP)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ir_evaluation/metrics.py::average_precision",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MAP-1",
                "requirement_description": "The system shall calculate Mean Average Precision@k (MAP), which is the mean of AP@k scores computed across multiple queries.\n*   **Inputs:**\n    *   `actual_list` (list[list[int]]): A list of `actual` lists. Each inner list corresponds to a single query.\n    *   `predicted_list` (list[list[int]]): A list of `predicted` lists. Each inner list corresponds to a single query, matching the order in `actual_list`.\n    *   `k` (int): A non-negative integer representing the number of top predictions to consider for each query's AP calculation.\n*   **Processing Details:**\n    1.  Initialize an empty list, `ap_scores`.\n    2.  For each pair of (`actual`, `predicted`) lists from `actual_list` and `predicted_list` respectively:\n        a.  Calculate AP@k for this pair as per FR-AP-1.\n        b.  Add the calculated AP@k to `ap_scores`.\n    3.  MAP@k is the arithmetic mean of the values in `ap_scores`.\n*   **Output:** A float representing MAP@k.\n*   **Preconditions:**\n    *   The `actual_list` and `predicted_list` must contain the same number of inner lists (queries). If this precondition is not met, the system shall raise an error (e.g., `AssertionError`).\n*   **Special Conditions:**\n    *   If `actual_list` (and thus `predicted_list`) is empty, `ap_scores` will be empty, and MAP@k is undefined (division by zero when calculating the mean).\n    *   Special conditions from FR-AP-1 (e.g., regarding `k` relative to `len(predicted)` for inner lists, or empty `precision_values_at_relevant_ranks` for an individual AP) apply to each AP calculation.",
                "test_traceability": [
                    {
                        "id": "tests/metrics_test.py::TestMeanAveragePrecision::test_mean_average_precision_basic",
                        "description": ""
                    },
                    {
                        "id": "tests/metrics_test.py::TestMeanAveragePrecision::test_mean_average_precision_pydoc",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ir_evaluation/metrics.py::mean_average_precision",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-NDCG-1",
                "requirement_description": "The system shall calculate Normalized Discounted Cumulative Gain@k (nDCG), which evaluates ranking quality by considering both the relevance (binary: relevant or not) and position of items, normalized by an ideal ranking.\n*   **Processing Details:**\n    1.  Identify the set of unique item IDs from the `actual` list (`S_actual`).\n    2.  Calculate Discounted Cumulative Gain (DCG@k):\n        a.  Initialize `DCG = 0.0`.\n        b.  Iterate from rank `i = 1` to `k`. For each rank `i`:\n            i.  Let the item at rank `i` (0-indexed `i-1`) in `predicted` be `P_i`.\n            ii. If `P_i` is in `S_actual`, add `1.0 / log2(i + 1)` to `DCG`. (Note: `log2` is base-2 logarithm. Rank `i` is 1-based).\n    3.  Calculate Ideal Discounted Cumulative Gain (IDCG@k):\n        a.  Initialize `IDCG = 0.0`.\n        b.  Consider an ideal ranking where all items from `S_actual` are ranked at the top, up to `min(k, count(S_actual))` positions.\n        c.  Iterate from rank `j = 1` to `min(k, count(S_actual))`. For each rank `j`:\n            i.  Add `1.0 / log2(j + 1)` to `IDCG`.\n    4.  nDCG@k = `DCG@k / IDCG@k`.\n*   **Output:** A float representing nDCG@k, typically ranging from 0.0 to 1.0.\n*   **Special Conditions:**\n    *   It is an implicit precondition that `k` does not exceed the number of items in the `predicted` list for DCG calculation. If `k > len(predicted)`, accessing `predicted[i-1]` for `i > len(predicted)` will lead to an error.\n    *   If `IDCG@k` is 0 (e.g., `S_actual` is empty, or `k=0` such that `min(k, count(S_actual))` is 0), nDCG@k is undefined and will result in a division by zero.\n    *   If `k` is 0, both DCG and IDCG will be 0, leading to `0/0` (division by zero or NaN).",
                "test_traceability": [
                    {
                        "id": "tests/metrics_test.py::TestNCDG::test_ndcg_k_5",
                        "description": "(Note: test class name is TestNCDG, likely typo for TestNDCG)"
                    },
                    {
                        "id": "tests/metrics_test.py::TestNCDG::test_ndcg_k_10",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ir_evaluation/metrics.py::ndcg",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-RR-1",
                "requirement_description": "The system shall calculate Reciprocal Rank@k (RR), which is the reciprocal of the rank of the first relevant item found in the top `k` positions of the `predicted` list.\n*   **Processing Details:**\n    1.  Identify the set of unique item IDs from the `actual` list (`S_actual`).\n    2.  Iterate from rank `i = 1` to `k`. For each rank `i`:\n        a.  Let the item at rank `i` (0-indexed `i-1`) in `predicted` be `P_i`.\n        b.  If `P_i` is in `S_actual`, RR@k = `1.0 / i`. Return this value immediately.\n    3.  If no relevant item is found in the first `k` positions, RR@k = 0.0.\n*   **Output:** A float representing RR@k.\n*   **Special Conditions:**\n    *   It is an implicit precondition that `k` does not exceed the number of items in the `predicted` list. If `k > len(predicted)`, accessing `predicted[i-1]` for `i > len(predicted)` will lead to an error.\n    *   If `k` is 0, the loop will not execute, and the system shall return 0.0.",
                "test_traceability": [
                    {
                        "id": "tests/metrics_test.py::TestReciprocalRank::test_reciprocal_rank_k_10",
                        "description": ""
                    },
                    {
                        "id": "tests/metrics_test.py::TestReciprocalRank::test_reciprocal_rank_zero",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ir_evaluation/metrics.py::reciprocal_rank",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MRR-1",
                "requirement_description": "The system shall calculate Mean Reciprocal Rank@k (MRR), which is the mean of RR@k scores computed across multiple queries.\n*   **Inputs:**\n    *   `actual_list` (list[list[int]]): A list of `actual` lists. Each inner list corresponds to a single query.\n    *   `predicted_list` (list[list[int]]): A list of `predicted` lists. Each inner list corresponds to a single query, matching the order in `actual_list`.\n    *   `k` (int): A non-negative integer representing the number of top predictions to consider for each query's RR calculation.\n*   **Processing Details:**\n    1.  Initialize an empty list, `rr_scores`.\n    2.  For each pair of (`actual`, `predicted`) lists from `actual_list` and `predicted_list` respectively:\n        a.  Calculate RR@k for this pair as per FR-RR-1.\n        b.  Add the calculated RR@k to `rr_scores`.\n    3.  MRR@k is the arithmetic mean of the values in `rr_scores`.\n*   **Output:** A float representing MRR@k.\n*   **Preconditions:**\n    *   The `actual_list` and `predicted_list` must contain the same number of inner lists (queries). If this precondition is not met, the system shall raise an error (e.g., `AssertionError`).\n*   **Special Conditions:**\n    *   If `actual_list` (and thus `predicted_list`) is empty, `rr_scores` will be empty, and MRR@k is undefined (division by zero when calculating the mean).\n    *   Special conditions from FR-RR-1 (e.g., regarding `k` relative to `len(predicted)` for inner lists) apply to each RR calculation.",
                "test_traceability": [
                    {
                        "id": "tests/metrics_test.py::TestMeanReciprocalRank::test_mean_reciprocal_rank_basic",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/ir_evaluation/metrics.py::mean_reciprocal_rank",
                        "description": ""
                    }
                ]
            }
        ],
        "full_code_skeleton": "--- File: src/ir_evaluation/metrics.py ---\n```python\ndef mean_of_list(l: list[float]) -> float:\n  pass\n\ndef recall(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Calculate the recall@k metric.\n\n  Recall is defined as the ratio of the total number of relevant items retrieved within the top-k predictions to the total number of relevant items in the entire database.\n\n  Recall =  Total number of items retrieved that are relevant/Total number of relevant items in the database.\n\n  Args:\n    actual (list[int]): An array of ground truth relevant items.\n    predicted (list[int]): An array of predicted items, ordered by relevance.\n    k (int): The number of top predictions to consider.\n\n  Returns:\n    float: The recall value at rank k, ranging from 0 to 1.\n           A value of 1 indicates perfect recall, while 0 indicates no relevant items retrieved.\n\n  Notes:\n    - This function assumes the `predicted` array is sorted in descending order of relevance.\n    - If k is larger than the length of the `predicted` array, it will consider the entire array.\n  \"\"\"\n  pass\n\ndef precision(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Calculate the precision@k metric.\n\n  Precision is defined as the ratio of the total number of relevant items retrieved\n  within the top-k predictions to the total number of returned items (k).\n\n  Precision =  Total number of items retrieved that are relevant/Total number of items that are retrieved.\n\n  Args:\n    actual (list[int]): An array of ground truth relevant items.\n    predicted (list[int]): An array of predicted items, ordered by relevance.\n    k (int): The number of top predictions to consider.\n\n  Returns:\n    float: The precision value at rank k, ranging from 0 to 1.\n           A value of 1 indicates perfect precision, while 0 indicates no relevant items retrieved.\n\n  Notes:\n    - This function assumes the `predicted` array is sorted in descending order of relevance.\n    - If k is larger than the length of the `predicted` array, it will consider the entire array.\n  \"\"\"\n  pass\n\ndef f1_score(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Calculate the F1-score @k metric.\n\n  The F1-score is calculated as the harmonic mean of precision and recall. The formula is:\n  F1 = 2 * (Precision * Recall) / (Precision + Recall)\n\n  The F1 score provides a balanced view of a system's performance by taking into account both precision and recall. This is especially important when evaluating information retrieval systems, where finding all relevant documents is just as important as minimizing irrelevant ones.\n\n  Args:\n    actual (list[int]): An array of ground truth relevant items.\n    predicted (list[int]): An array of predicted items, ordered by relevance.\n    k (int): The number of top predictions to consider.\n\n  Returns:\n    float: The F1 score value at rank k, ranging from 0 to 1.\n           A value of 1 indicates perfect precision and recall, while 0 indicates either precision or recall is zero.\n  \"\"\"\n  pass\n\ndef average_precision(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Computes the Average Precision (AP) at a specified rank `k`.\n\n  Average Precision (AP) is a metric used to evaluate the relevance of predicted rankings \n  in information retrieval tasks. It is calculated as the mean of precision values at \n  each rank where a relevant item is retrieved within the top `k` predictions.\n\n  Args:\n      actual (list[int]): A list of integers representing the ground truth relevant items.\n      predicted (list[int]): A list of integers representing the predicted rankings of items.\n      k (int): The maximum number of top-ranked items to consider for evaluation.\n\n  Returns:\n      float: The Average Precision score. If no relevant items are retrieved within the\n      top `k` predictions, the function may raise a division by zero error or return `NaN`.\n  \"\"\"\n  pass\n\ndef mean_average_precision(actual_list: list[list[int]], predicted_list: list[list[int]], k: int) -> float:\n  \"\"\"\n  Computes the Mean Average Precision (MAP) at a specified rank `k`.\n\n  It is the mean of the Average Precision (AP) scores computed for multiple \n  queries.\n\n  Args:\n      actual_list (list[list[int]]): A list of lists where each inner list represents \n          the ground truth relevant items for a query\n      predicted_list (list[list[int]]): A list of lists where each inner list represents \n          the predicted rankings of items for a query\n      k (int): The maximum number of top-ranked items to consider for each prediction.\n\n  Returns:\n      float: The Mean Average Precision score, which is the mean of AP scores across all \n      queries.\n\n  Raises:\n      AssertionError: If the lengths of `actual_list` and `predicted_list` are not equal.\n  \"\"\"\n  pass\n\ndef ndcg(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Computes the Normalized Discounted Cumulative Gain (nDCG) at a specified rank `k`.\n\n  nDCG evaluates the quality of a predicted ranking by comparing it to an ideal ranking \n  (i.e., perfect ordering of relevant items). It accounts for the position of relevant \n  items in the ranking, giving higher weight to items appearing earlier.\n\n  Args:\n      actual (list[int]): A list of integers representing the ground truth relevant items.\n      predicted (list[int]): A list of integers representing the predicted rankings of items.\n      k (int): The maximum number of top-ranked items to consider for evaluation.\n\n  Returns:\n      float: The nDCG score, which ranges from 0 to 1. A value of 1 indicates a perfect \n      ranking. Returns 0 if there are no relevant items in the top `k` predictions or if \n      the ideal DCG (iDCG) is zero.\n  \"\"\"\n  pass\n\ndef reciprocal_rank(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Computes the Reciprocal Rank (RR) at a specified rank `k`.\n\n  Reciprocal Rank (RR) assigns a score based on the reciprocal of the rank at which the first relevant item is found.\n\n  Args:\n      actual (list[int]): A list of integers representing the ground truth relevant items.\n      predicted (list[int]): A list of integers representing the predicted rankings of items.\n      k (int): The maximum number of top-ranked items to consider for evaluation.\n\n  Returns:\n      float: The Reciprocal Rank score. A value of 0 is returned if no relevant items are \n      found within the top `k` predictions. Otherwise, the score is `1 / rank`, where \n      `rank` is the position (1-based) of the first relevant item.\n\n  Notes:\n      - The function assumes zero-based indexing for the `predicted` list.\n      - If `k` exceeds the length of `predicted`, only the available elements in `predicted` \n        are considered.\n      - This metric focuses only on the rank of the first relevant item, ignoring others.\n  \"\"\"\n  pass\n\ndef mean_reciprocal_rank(actual_list: list[list[int]], predicted_list: list[list[int]], k: int) -> float:\n  \"\"\"\n  Computes the Mean Reciprocal Rank (MRR) at a specified rank `k`.\n\n  It calculates the mean of the Reciprocal Rank (RR) scores for a set of queries.\n\n  Args:\n      actual_list (list[list[int]]): A list of lists where each inner list represents the \n          ground truth relevant items for a query or task.\n      predicted_list (list[list[int]]): A list of lists where each inner list represents \n          the predicted rankings of items for a query or task.\n      k (int): The maximum number of top-ranked items to consider for each prediction.\n\n  Returns:\n      float: The Mean Reciprocal Rank score, which is the average of RR scores across all \n      queries. Returns 0 if there are no queries or no relevant items in any predictions.\n\n  Raises:\n      AssertionError: If the lengths of `actual_list` and `predicted_list` are not equal.\n  \"\"\"\n  pass\n```",
        "minimal_code_skeleton": "--- File: ir_evaluation/metrics.py ---\n```python\ndef recall(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Calculate the recall@k metric.\n\n  Recall is defined as the ratio of the total number of relevant items retrieved within the top-k predictions to the total number of relevant items in the entire database.\n\n  Recall =  Total number of items retrieved that are relevant/Total number of relevant items in the database.\n\n  Args:\n    actual (list[int]): An array of ground truth relevant items.\n    predicted (list[int]): An array of predicted items, ordered by relevance.\n    k (int): The number of top predictions to consider.\n\n  Returns:\n    float: The recall value at rank k, ranging from 0 to 1.\n           A value of 1 indicates perfect recall, while 0 indicates no relevant items retrieved.\n\n  Notes:\n    - This function assumes the `predicted` array is sorted in descending order of relevance.\n    - If k is larger than the length of the `predicted` array, it will consider the entire array.\n  \"\"\"\n  pass\n\ndef precision(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Calculate the precision@k metric.\n\n  Precision is defined as the ratio of the total number of relevant items retrieved\n  within the top-k predictions to the total number of returned items (k).\n\n  Precision =  Total number of items retrieved that are relevant/Total number of items that are retrieved.\n\n  Args:\n    actual (list[int]): An array of ground truth relevant items.\n    predicted (list[int]): An array of predicted items, ordered by relevance.\n    k (int): The number of top predictions to consider.\n\n  Returns:\n    float: The precision value at rank k, ranging from 0 to 1.\n           A value of 1 indicates perfect precision, while 0 indicates no relevant items retrieved.\n\n  Notes:\n    - This function assumes the `predicted` array is sorted in descending order of relevance.\n    - If k is larger than the length of the `predicted` array, it will consider the entire array.\n  \"\"\"\n  pass\n\ndef f1_score(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Calculate the F1-score @k metric.\n\n  The F1-score is calculated as the harmonic mean of precision and recall. The formula is:\n  F1 = 2 * (Precision * Recall) / (Precision + Recall)\n\n  The F1 score provides a balanced view of a system's performance by taking into account both precision and recall. This is especially important when evaluating information retrieval systems, where finding all relevant documents is just as important as minimizing irrelevant ones.\n\n  Args:\n    actual (list[int]): An array of ground truth relevant items.\n    predicted (list[int]): An array of predicted items, ordered by relevance.\n    k (int): The number of top predictions to consider.\n\n  Returns:\n    float: The F1 score value at rank k, ranging from 0 to 1.\n           A value of 1 indicates perfect precision and recall, while 0 indicates either precision or recall is zero.\n  \"\"\"\n  pass\n\ndef average_precision(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Computes the Average Precision (AP) at a specified rank `k`.\n\n  Average Precision (AP) is a metric used to evaluate the relevance of predicted rankings \n  in information retrieval tasks. It is calculated as the mean of precision values at \n  each rank where a relevant item is retrieved within the top `k` predictions.\n\n  Args:\n      actual (list[int]): A list of integers representing the ground truth relevant items.\n      predicted (list[int]): A list of integers representing the predicted rankings of items.\n      k (int): The maximum number of top-ranked items to consider for evaluation.\n\n  Returns:\n      float: The Average Precision score. If no relevant items are retrieved within the\n      top `k` predictions, the function may raise a division by zero error or return `NaN`.\n  \"\"\"\n  pass\n\ndef mean_average_precision(actual_list: list[list[int]], predicted_list: list[list[int]], k: int) -> float:\n  \"\"\"\n  Computes the Mean Average Precision (MAP) at a specified rank `k`.\n\n  It is the mean of the Average Precision (AP) scores computed for multiple \n  queries.\n\n  Args:\n      actual_list (list[list[int]]): A list of lists where each inner list represents \n          the ground truth relevant items for a query\n      predicted_list (list[list[int]]): A list of lists where each inner list represents \n          the predicted rankings of items for a query\n      k (int): The maximum number of top-ranked items to consider for each prediction.\n\n  Returns:\n      float: The Mean Average Precision score, which is the mean of AP scores across all \n      queries.\n\n  Raises:\n      AssertionError: If the lengths of `actual_list` and `predicted_list` are not equal.\n  \"\"\"\n  pass\n\ndef ndcg(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Computes the Normalized Discounted Cumulative Gain (nDCG) at a specified rank `k`.\n\n  nDCG evaluates the quality of a predicted ranking by comparing it to an ideal ranking \n  (i.e., perfect ordering of relevant items). It accounts for the position of relevant \n  items in the ranking, giving higher weight to items appearing earlier.\n\n  Args:\n      actual (list[int]): A list of integers representing the ground truth relevant items.\n      predicted (list[int]): A list of integers representing the predicted rankings of items.\n      k (int): The maximum number of top-ranked items to consider for evaluation.\n\n  Returns:\n      float: The nDCG score, which ranges from 0 to 1. A value of 1 indicates a perfect \n      ranking. Returns 0 if there are no relevant items in the top `k` predictions or if \n      the ideal DCG (iDCG) is zero.\n  \"\"\"\n  pass\n\ndef reciprocal_rank(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Computes the Reciprocal Rank (RR) at a specified rank `k`.\n\n  Reciprocal Rank (RR) assigns a score based on the reciprocal of the rank at which the first relevant item is found.\n\n  Args:\n      actual (list[int]): A list of integers representing the ground truth relevant items.\n      predicted (list[int]): A list of integers representing the predicted rankings of items.\n      k (int): The maximum number of top-ranked items to consider for evaluation.\n\n  Returns:\n      float: The Reciprocal Rank score. A value of 0 is returned if no relevant items are \n      found within the top `k` predictions. Otherwise, the score is `1 / rank`, where \n      `rank` is the position (1-based) of the first relevant item.\n\n  Notes:\n      - The function assumes zero-based indexing for the `predicted` list.\n      - If `k` exceeds the length of `predicted`, only the available elements in `predicted` \n        are considered.\n      - This metric focuses only on the rank of the first relevant item, ignoring others.\n  \"\"\"\n  pass\n\ndef mean_reciprocal_rank(actual_list: list[list[int]], predicted_list: list[list[int]], k: int) -> float:\n  \"\"\"\n  Computes the Mean Reciprocal Rank (MRR) at a specified rank `k`.\n\n  It calculates the mean of the Reciprocal Rank (RR) scores for a set of queries.\n\n  Args:\n      actual_list (list[list[int]]): A list of lists where each inner list represents the \n          ground truth relevant items for a query or task.\n      predicted_list (list[list[int]]): A list of lists where each inner list represents \n          the predicted rankings of items for a query or task.\n      k (int): The maximum number of top-ranked items to consider for each prediction.\n\n  Returns:\n      float: The Mean Reciprocal Rank score, which is the average of RR scores across all \n      queries. Returns 0 if there are no queries or no relevant items in any predictions.\n\n  Raises:\n      AssertionError: If the lengths of `actual_list` and `predicted_list` are not equal.\n  \"\"\"\n  pass\n```",
        "minimal_test_cases": [
            {
                "test_id": "tests/metrics_test.py::TestRecall::test_recall_k_5",
                "covers": [
                    "ir_evaluation.metrics.recall - happy path, common usage with k=5"
                ]
            },
            {
                "test_id": "tests/metrics_test.py::TestPrecision::test_precision_k_5",
                "covers": [
                    "ir_evaluation.metrics.precision - happy path, common usage with k=5"
                ]
            },
            {
                "test_id": "tests/metrics_test.py::TestF1::test_f1_k_5",
                "covers": [
                    "ir_evaluation.metrics.f1_score - happy path, common usage with k=5"
                ]
            },
            {
                "test_id": "tests/metrics_test.py::TestAveragePrecision::test_average_precision_basic",
                "covers": [
                    "ir_evaluation.metrics.average_precision - happy path, basic calculation example"
                ]
            },
            {
                "test_id": "tests/metrics_test.py::TestMeanAveragePrecision::test_mean_average_precision_basic",
                "covers": [
                    "ir_evaluation.metrics.mean_average_precision - happy path, basic calculation with list inputs"
                ]
            },
            {
                "test_id": "tests/metrics_test.py::TestNCDG::test_ndcg_k_5",
                "covers": [
                    "ir_evaluation.metrics.ndcg - happy path, common usage with k=5"
                ]
            },
            {
                "test_id": "tests/metrics_test.py::TestReciprocalRank::test_reciprocal_rank_k_10",
                "covers": [
                    "ir_evaluation.metrics.reciprocal_rank - happy path, non-trivial rank example"
                ]
            },
            {
                "test_id": "tests/metrics_test.py::TestMeanReciprocalRank::test_mean_reciprocal_rank_basic",
                "covers": [
                    "ir_evaluation.metrics.mean_reciprocal_rank - happy path, basic calculation with list inputs"
                ]
            }
        ],
        "commit_sha": "b82aecdf3b306f1f5ef38ee2885a0cd68415c810",
        "full_code_skeleton_structured": [
            {
                "file_path": "src/ir_evaluation/metrics.py",
                "code": "def mean_of_list(l: list[float]) -> float:\n  pass\n\ndef recall(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Calculate the recall@k metric.\n\n  Recall is defined as the ratio of the total number of relevant items retrieved within the top-k predictions to the total number of relevant items in the entire database.\n\n  Recall =  Total number of items retrieved that are relevant/Total number of relevant items in the database.\n\n  Args:\n    actual (list[int]): An array of ground truth relevant items.\n    predicted (list[int]): An array of predicted items, ordered by relevance.\n    k (int): The number of top predictions to consider.\n\n  Returns:\n    float: The recall value at rank k, ranging from 0 to 1.\n           A value of 1 indicates perfect recall, while 0 indicates no relevant items retrieved.\n\n  Notes:\n    - This function assumes the `predicted` array is sorted in descending order of relevance.\n    - If k is larger than the length of the `predicted` array, it will consider the entire array.\n  \"\"\"\n  pass\n\ndef precision(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Calculate the precision@k metric.\n\n  Precision is defined as the ratio of the total number of relevant items retrieved\n  within the top-k predictions to the total number of returned items (k).\n\n  Precision =  Total number of items retrieved that are relevant/Total number of items that are retrieved.\n\n  Args:\n    actual (list[int]): An array of ground truth relevant items.\n    predicted (list[int]): An array of predicted items, ordered by relevance.\n    k (int): The number of top predictions to consider.\n\n  Returns:\n    float: The precision value at rank k, ranging from 0 to 1.\n           A value of 1 indicates perfect precision, while 0 indicates no relevant items retrieved.\n\n  Notes:\n    - This function assumes the `predicted` array is sorted in descending order of relevance.\n    - If k is larger than the length of the `predicted` array, it will consider the entire array.\n  \"\"\"\n  pass\n\ndef f1_score(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Calculate the F1-score @k metric.\n\n  The F1-score is calculated as the harmonic mean of precision and recall. The formula is:\n  F1 = 2 * (Precision * Recall) / (Precision + Recall)\n\n  The F1 score provides a balanced view of a system's performance by taking into account both precision and recall. This is especially important when evaluating information retrieval systems, where finding all relevant documents is just as important as minimizing irrelevant ones.\n\n  Args:\n    actual (list[int]): An array of ground truth relevant items.\n    predicted (list[int]): An array of predicted items, ordered by relevance.\n    k (int): The number of top predictions to consider.\n\n  Returns:\n    float: The F1 score value at rank k, ranging from 0 to 1.\n           A value of 1 indicates perfect precision and recall, while 0 indicates either precision or recall is zero.\n  \"\"\"\n  pass\n\ndef average_precision(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Computes the Average Precision (AP) at a specified rank `k`.\n\n  Average Precision (AP) is a metric used to evaluate the relevance of predicted rankings \n  in information retrieval tasks. It is calculated as the mean of precision values at \n  each rank where a relevant item is retrieved within the top `k` predictions.\n\n  Args:\n      actual (list[int]): A list of integers representing the ground truth relevant items.\n      predicted (list[int]): A list of integers representing the predicted rankings of items.\n      k (int): The maximum number of top-ranked items to consider for evaluation.\n\n  Returns:\n      float: The Average Precision score. If no relevant items are retrieved within the\n      top `k` predictions, the function may raise a division by zero error or return `NaN`.\n  \"\"\"\n  pass\n\ndef mean_average_precision(actual_list: list[list[int]], predicted_list: list[list[int]], k: int) -> float:\n  \"\"\"\n  Computes the Mean Average Precision (MAP) at a specified rank `k`.\n\n  It is the mean of the Average Precision (AP) scores computed for multiple \n  queries.\n\n  Args:\n      actual_list (list[list[int]]): A list of lists where each inner list represents \n          the ground truth relevant items for a query\n      predicted_list (list[list[int]]): A list of lists where each inner list represents \n          the predicted rankings of items for a query\n      k (int): The maximum number of top-ranked items to consider for each prediction.\n\n  Returns:\n      float: The Mean Average Precision score, which is the mean of AP scores across all \n      queries.\n\n  Raises:\n      AssertionError: If the lengths of `actual_list` and `predicted_list` are not equal.\n  \"\"\"\n  pass\n\ndef ndcg(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Computes the Normalized Discounted Cumulative Gain (nDCG) at a specified rank `k`.\n\n  nDCG evaluates the quality of a predicted ranking by comparing it to an ideal ranking \n  (i.e., perfect ordering of relevant items). It accounts for the position of relevant \n  items in the ranking, giving higher weight to items appearing earlier.\n\n  Args:\n      actual (list[int]): A list of integers representing the ground truth relevant items.\n      predicted (list[int]): A list of integers representing the predicted rankings of items.\n      k (int): The maximum number of top-ranked items to consider for evaluation.\n\n  Returns:\n      float: The nDCG score, which ranges from 0 to 1. A value of 1 indicates a perfect \n      ranking. Returns 0 if there are no relevant items in the top `k` predictions or if \n      the ideal DCG (iDCG) is zero.\n  \"\"\"\n  pass\n\ndef reciprocal_rank(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Computes the Reciprocal Rank (RR) at a specified rank `k`.\n\n  Reciprocal Rank (RR) assigns a score based on the reciprocal of the rank at which the first relevant item is found.\n\n  Args:\n      actual (list[int]): A list of integers representing the ground truth relevant items.\n      predicted (list[int]): A list of integers representing the predicted rankings of items.\n      k (int): The maximum number of top-ranked items to consider for evaluation.\n\n  Returns:\n      float: The Reciprocal Rank score. A value of 0 is returned if no relevant items are \n      found within the top `k` predictions. Otherwise, the score is `1 / rank`, where \n      `rank` is the position (1-based) of the first relevant item.\n\n  Notes:\n      - The function assumes zero-based indexing for the `predicted` list.\n      - If `k` exceeds the length of `predicted`, only the available elements in `predicted` \n        are considered.\n      - This metric focuses only on the rank of the first relevant item, ignoring others.\n  \"\"\"\n  pass\n\ndef mean_reciprocal_rank(actual_list: list[list[int]], predicted_list: list[list[int]], k: int) -> float:\n  \"\"\"\n  Computes the Mean Reciprocal Rank (MRR) at a specified rank `k`.\n\n  It calculates the mean of the Reciprocal Rank (RR) scores for a set of queries.\n\n  Args:\n      actual_list (list[list[int]]): A list of lists where each inner list represents the \n          ground truth relevant items for a query or task.\n      predicted_list (list[list[int]]): A list of lists where each inner list represents \n          the predicted rankings of items for a query or task.\n      k (int): The maximum number of top-ranked items to consider for each prediction.\n\n  Returns:\n      float: The Mean Reciprocal Rank score, which is the average of RR scores across all \n      queries. Returns 0 if there are no queries or no relevant items in any predictions.\n\n  Raises:\n      AssertionError: If the lengths of `actual_list` and `predicted_list` are not equal.\n  \"\"\"\n  pass\n"
            }
        ],
        "minimal_code_skeleton_structured": [
            {
                "file_path": "ir_evaluation/metrics.py",
                "code": "def recall(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Calculate the recall@k metric.\n\n  Recall is defined as the ratio of the total number of relevant items retrieved within the top-k predictions to the total number of relevant items in the entire database.\n\n  Recall =  Total number of items retrieved that are relevant/Total number of relevant items in the database.\n\n  Args:\n    actual (list[int]): An array of ground truth relevant items.\n    predicted (list[int]): An array of predicted items, ordered by relevance.\n    k (int): The number of top predictions to consider.\n\n  Returns:\n    float: The recall value at rank k, ranging from 0 to 1.\n           A value of 1 indicates perfect recall, while 0 indicates no relevant items retrieved.\n\n  Notes:\n    - This function assumes the `predicted` array is sorted in descending order of relevance.\n    - If k is larger than the length of the `predicted` array, it will consider the entire array.\n  \"\"\"\n  pass\n\ndef precision(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Calculate the precision@k metric.\n\n  Precision is defined as the ratio of the total number of relevant items retrieved\n  within the top-k predictions to the total number of returned items (k).\n\n  Precision =  Total number of items retrieved that are relevant/Total number of items that are retrieved.\n\n  Args:\n    actual (list[int]): An array of ground truth relevant items.\n    predicted (list[int]): An array of predicted items, ordered by relevance.\n    k (int): The number of top predictions to consider.\n\n  Returns:\n    float: The precision value at rank k, ranging from 0 to 1.\n           A value of 1 indicates perfect precision, while 0 indicates no relevant items retrieved.\n\n  Notes:\n    - This function assumes the `predicted` array is sorted in descending order of relevance.\n    - If k is larger than the length of the `predicted` array, it will consider the entire array.\n  \"\"\"\n  pass\n\ndef f1_score(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Calculate the F1-score @k metric.\n\n  The F1-score is calculated as the harmonic mean of precision and recall. The formula is:\n  F1 = 2 * (Precision * Recall) / (Precision + Recall)\n\n  The F1 score provides a balanced view of a system's performance by taking into account both precision and recall. This is especially important when evaluating information retrieval systems, where finding all relevant documents is just as important as minimizing irrelevant ones.\n\n  Args:\n    actual (list[int]): An array of ground truth relevant items.\n    predicted (list[int]): An array of predicted items, ordered by relevance.\n    k (int): The number of top predictions to consider.\n\n  Returns:\n    float: The F1 score value at rank k, ranging from 0 to 1.\n           A value of 1 indicates perfect precision and recall, while 0 indicates either precision or recall is zero.\n  \"\"\"\n  pass\n\ndef average_precision(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Computes the Average Precision (AP) at a specified rank `k`.\n\n  Average Precision (AP) is a metric used to evaluate the relevance of predicted rankings \n  in information retrieval tasks. It is calculated as the mean of precision values at \n  each rank where a relevant item is retrieved within the top `k` predictions.\n\n  Args:\n      actual (list[int]): A list of integers representing the ground truth relevant items.\n      predicted (list[int]): A list of integers representing the predicted rankings of items.\n      k (int): The maximum number of top-ranked items to consider for evaluation.\n\n  Returns:\n      float: The Average Precision score. If no relevant items are retrieved within the\n      top `k` predictions, the function may raise a division by zero error or return `NaN`.\n  \"\"\"\n  pass\n\ndef mean_average_precision(actual_list: list[list[int]], predicted_list: list[list[int]], k: int) -> float:\n  \"\"\"\n  Computes the Mean Average Precision (MAP) at a specified rank `k`.\n\n  It is the mean of the Average Precision (AP) scores computed for multiple \n  queries.\n\n  Args:\n      actual_list (list[list[int]]): A list of lists where each inner list represents \n          the ground truth relevant items for a query\n      predicted_list (list[list[int]]): A list of lists where each inner list represents \n          the predicted rankings of items for a query\n      k (int): The maximum number of top-ranked items to consider for each prediction.\n\n  Returns:\n      float: The Mean Average Precision score, which is the mean of AP scores across all \n      queries.\n\n  Raises:\n      AssertionError: If the lengths of `actual_list` and `predicted_list` are not equal.\n  \"\"\"\n  pass\n\ndef ndcg(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Computes the Normalized Discounted Cumulative Gain (nDCG) at a specified rank `k`.\n\n  nDCG evaluates the quality of a predicted ranking by comparing it to an ideal ranking \n  (i.e., perfect ordering of relevant items). It accounts for the position of relevant \n  items in the ranking, giving higher weight to items appearing earlier.\n\n  Args:\n      actual (list[int]): A list of integers representing the ground truth relevant items.\n      predicted (list[int]): A list of integers representing the predicted rankings of items.\n      k (int): The maximum number of top-ranked items to consider for evaluation.\n\n  Returns:\n      float: The nDCG score, which ranges from 0 to 1. A value of 1 indicates a perfect \n      ranking. Returns 0 if there are no relevant items in the top `k` predictions or if \n      the ideal DCG (iDCG) is zero.\n  \"\"\"\n  pass\n\ndef reciprocal_rank(actual: list[int], predicted: list[int], k: int) -> float:\n  \"\"\"\n  Computes the Reciprocal Rank (RR) at a specified rank `k`.\n\n  Reciprocal Rank (RR) assigns a score based on the reciprocal of the rank at which the first relevant item is found.\n\n  Args:\n      actual (list[int]): A list of integers representing the ground truth relevant items.\n      predicted (list[int]): A list of integers representing the predicted rankings of items.\n      k (int): The maximum number of top-ranked items to consider for evaluation.\n\n  Returns:\n      float: The Reciprocal Rank score. A value of 0 is returned if no relevant items are \n      found within the top `k` predictions. Otherwise, the score is `1 / rank`, where \n      `rank` is the position (1-based) of the first relevant item.\n\n  Notes:\n      - The function assumes zero-based indexing for the `predicted` list.\n      - If `k` exceeds the length of `predicted`, only the available elements in `predicted` \n        are considered.\n      - This metric focuses only on the rank of the first relevant item, ignoring others.\n  \"\"\"\n  pass\n\ndef mean_reciprocal_rank(actual_list: list[list[int]], predicted_list: list[list[int]], k: int) -> float:\n  \"\"\"\n  Computes the Mean Reciprocal Rank (MRR) at a specified rank `k`.\n\n  It calculates the mean of the Reciprocal Rank (RR) scores for a set of queries.\n\n  Args:\n      actual_list (list[list[int]]): A list of lists where each inner list represents the \n          ground truth relevant items for a query or task.\n      predicted_list (list[list[int]]): A list of lists where each inner list represents \n          the predicted rankings of items for a query or task.\n      k (int): The maximum number of top-ranked items to consider for each prediction.\n\n  Returns:\n      float: The Mean Reciprocal Rank score, which is the average of RR scores across all \n      queries. Returns 0 if there are no queries or no relevant items in any predictions.\n\n  Raises:\n      AssertionError: If the lengths of `actual_list` and `predicted_list` are not equal.\n  \"\"\"\n  pass\n"
            }
        ]
    },
    {
        "idx": 23895,
        "repo_name": "Alburrito_mongo-migrator",
        "url": "https://github.com/Alburrito/mongo-migrator",
        "description": "Simple MongoDB migration manager",
        "stars": 8,
        "forks": 0,
        "language": "python",
        "size": 150,
        "created_at": "2025-02-18T15:52:51+00:00",
        "updated_at": "2025-03-12T10:04:49+00:00",
        "pypi_info": {
            "name": "mongo-migrator",
            "version": "1.0.1",
            "url": "https://files.pythonhosted.org/packages/9d/29/217c1fe0574de00c8dbffe9682d49db2e99f2107f1235c11c1263df11da1/mongo_migrator-1.0.1.tar.gz"
        },
        "error": null,
        "judge_info": {
            "language": "python",
            "is_good_project": false,
            "reason": "",
            "python_file_num": 13,
            "comment_ratio": 0.27851580393953274,
            "pyfile_content_length": 80443,
            "pyfile_code_lines": 2183,
            "test_file_exist": true,
            "test_file_content_length": 43212,
            "pytest_framework": true,
            "test_case_num": 31,
            "metadata_path": [
                "pyproject.toml"
            ],
            "readme_content_length": 4646,
            "llm_reason": "The project, 'Mongo Migrator', is a CLI tool for managing MongoDB migrations. \n\nPositive Aspects:\n*   **Clear & Well-Defined Functionality:** The README clearly outlines the project's purpose (managing MongoDB migrations), features (create, apply, rollback, history), and CLI usage. This provides a solid specification for an AI to rebuild the project.\n*   **Testable & Verifiable Output:** The project includes a comprehensive suite of tests using `pytest` and `mock` (evident from `test_*.py` files and `conftest.py`). These tests cover configuration, database interactions, migration history logic, CLI commands, and core command logic. Crucially, `conftest.py` suggests the use of an in-memory MongoDB client for testing (likely `mongomock`), which is excellent for benchmark self-containment.\n*   **No GUI:** The project is entirely CLI-based, which is suitable for automated testing and AI generation.\n*   **Appropriate Complexity (Medium):** The project involves several components: CLI parsing (`argparse`), configuration file handling (`configparser`), file system operations (creating/reading migration scripts), managing migration history (a graph-like structure of migration nodes), and database interactions (`pymongo`). It also involves dynamic loading/execution of Python code from migration files. This is non-trivial but not excessively complex for an AI to replicate within a reasonable timeframe.\n*   **Well-Understood Problem Domain:** Database migration tools are a common type of developer utility.\n*   **Predominantly Code-Based Solution:** The task for the AI is to generate Python code to implement the tool's logic.\n*   **Self-Contained for AI-Rebuilt Solution's Testing:** The existing tests appear to use an in-memory MongoDB (e.g., `mongomock` via the `mongo_client` fixture in `conftest.py`). This means an AI-rebuilt solution can be tested in a self-contained environment without requiring a full, external MongoDB setup, by having the AI's code target the `pymongo` API which is then tested against the mock.\n*   **Manageable Dependencies:** The primary dependency is `pymongo`, which is standard and pip-installable. `configparser` is in the standard library.\n\nNegative Aspects / Concerns:\n*   **MongoDB Dependency Nuance:** While the testing can be self-contained using a mock MongoDB, the project's core purpose is to interact with MongoDB. The benchmark specification for the AI must clearly state that its solution should use the `pymongo` library and will be tested against a mock/in-memory MongoDB environment (like `mongomock`), rather than requiring the AI to set up or manage a live MongoDB instance. This is a manageable concern with clear instructions.\n*   **Dynamic Code Execution:** The tool loads and executes `upgrade` and `downgrade` functions from user-generated migration files. Implementing this dynamic loading and execution correctly is a moderately complex part of the project.\n\nOverall, the project is a strong candidate. Its well-defined scope, comprehensive tests, CLI nature, and appropriate complexity make it suitable. The MongoDB dependency is handled well for testing via mocking, making the AI's task focused on replicating the tool's logic rather than environment setup.",
            "llm_project_type": "CLI database schema migration tool for MongoDB",
            "llm_rating": 80,
            "llm_difficulty": "Medium"
        },
        "tests": {
            "repo_name": "Alburrito_mongo-migrator",
            "finish_test": true,
            "test_case_result": {
                "tests/test_cli.py::test_init": "passed",
                "tests/test_cli.py::test_create": "passed",
                "tests/test_cli.py::test_upgrade": "passed",
                "tests/test_cli.py::test_downgrade": "passed",
                "tests/test_cli.py::test_history": "passed",
                "tests/test_cli.py::test_no_subcommand": "passed",
                "tests/test_commands.py::test_init": "passed",
                "tests/test_commands.py::test_create": "passed",
                "tests/test_commands.py::test_upgrade": "passed",
                "tests/test_commands.py::test_downgrade": "passed",
                "tests/test_commands.py::test_history": "passed",
                "tests/test_config.py::test_config_loads_ok": "passed",
                "tests/test_config.py::test_config_not_found": "passed",
                "tests/test_config.py::test_config_missing_sections": "passed",
                "tests/test_config.py::test_config_missing_options": "passed",
                "tests/test_config.py::test_config_user_pass_are_optional": "passed",
                "tests/test_db.py::test_get_db_success": "passed",
                "tests/test_db.py::test_get_db_failure": "passed",
                "tests/test_db.py::test_create_version_collection": "passed",
                "tests/test_db.py::test_create_version_collection_already_exists": "passed",
                "tests/test_db.py::test_create_version_collection_already_exists_with_data": "passed",
                "tests/test_db.py::test_set_current_version": "passed",
                "tests/test_history.py::test_history_invalid_migration": "passed",
                "tests/test_history.py::test_migration_node_representation": "passed",
                "tests/test_history.py::test_is_empty_history": "passed",
                "tests/test_history.py::test_validate_history": "passed",
                "tests/test_history.py::test_get_first_version": "passed",
                "tests/test_history.py::test_get_first_node": "passed",
                "tests/test_history.py::test_get_last_version": "passed",
                "tests/test_history.py::test_get_last_node": "passed",
                "tests/test_history.py::test_get_migrations": "passed"
            },
            "success_count": 31,
            "failed_count": 0,
            "error_count": 0,
            "skipped_count": 0,
            "unknown_count": 0,
            "total_count": 31,
            "success_rate": 1.0,
            "coverage_report": {
                "covered_lines": 436,
                "num_statements": 456,
                "percent_covered": 95.01718213058419,
                "percent_covered_display": "95",
                "missing_lines": 20,
                "excluded_lines": 2,
                "num_branches": 126,
                "num_partial_branches": 5,
                "covered_branches": 117,
                "missing_branches": 9
            },
            "coverage_result": {}
        },
        "codelines_count": 2183,
        "codefiles_count": 13,
        "code_length": 80443,
        "test_files_count": 5,
        "test_code_length": 43212,
        "structure": [
            {
                "file": "setup-test-db.py",
                "functions": [
                    {
                        "name": "setup_test_db",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_config.py",
                "functions": [
                    {
                        "name": "create_config_file",
                        "docstring": "Fixture that crates and cleans  temporary config file",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_config_loads_ok",
                        "docstring": "Test that the configuration file is loaded correctly",
                        "comments": null,
                        "args": [
                            "create_config_file"
                        ]
                    },
                    {
                        "name": "test_config_not_found",
                        "docstring": "Test that the program exits when the configuration file is not found",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_config_missing_sections",
                        "docstring": "Test that the program exits when the configuration file is missing sections",
                        "comments": null,
                        "args": [
                            "create_config_file"
                        ]
                    },
                    {
                        "name": "test_config_missing_options",
                        "docstring": "Test that the program does not exit when an option is missing",
                        "comments": null,
                        "args": [
                            "create_config_file"
                        ]
                    },
                    {
                        "name": "test_config_user_pass_are_optional",
                        "docstring": "Test that the program does not exit when user and password are not provided",
                        "comments": null,
                        "args": [
                            "create_config_file"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_history.py",
                "functions": [
                    {
                        "name": "test_history_invalid_migration",
                        "docstring": "Test the history command with an invalid migration file.",
                        "comments": null,
                        "args": [
                            "mock_config",
                            "mongo_db",
                            "capfd"
                        ]
                    },
                    {
                        "name": "test_migration_node_representation",
                        "docstring": "Test the representation of a migration node.",
                        "comments": null,
                        "args": [
                            "mock_config"
                        ]
                    },
                    {
                        "name": "test_is_empty_history",
                        "docstring": "Test the is_empty method of MigrationHistory.",
                        "comments": null,
                        "args": [
                            "mongo_db",
                            "mock_config"
                        ]
                    },
                    {
                        "name": "test_validate_history",
                        "docstring": "Test the validate function of MigrationHistory.",
                        "comments": null,
                        "args": [
                            "mongo_db",
                            "mock_config"
                        ]
                    },
                    {
                        "name": "test_get_first_version",
                        "docstring": "Test the get_first_version function of MigrationHistory.",
                        "comments": null,
                        "args": [
                            "mongo_db",
                            "mock_config"
                        ]
                    },
                    {
                        "name": "test_get_first_node",
                        "docstring": "Test the get_first_node function of MigrationHistory.",
                        "comments": null,
                        "args": [
                            "mongo_db",
                            "mock_config"
                        ]
                    },
                    {
                        "name": "test_get_last_version",
                        "docstring": "Test the get_last_version function of MigrationHistory.",
                        "comments": null,
                        "args": [
                            "mongo_db",
                            "mock_config"
                        ]
                    },
                    {
                        "name": "test_get_last_node",
                        "docstring": "Test the get_last_node function of MigrationHistory.",
                        "comments": null,
                        "args": [
                            "mongo_db",
                            "mock_config"
                        ]
                    },
                    {
                        "name": "test_get_migrations",
                        "docstring": "Test the get_migrations function of MigrationHistory.",
                        "comments": null,
                        "args": [
                            "mongo_db",
                            "mock_config"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/conftest.py",
                "functions": [
                    {
                        "name": "mongo_client",
                        "docstring": "Fixture that initializes a in-memory MongoDB client.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "mongo_db",
                        "docstring": "Fixture that returns a MongoDB database.",
                        "comments": null,
                        "args": [
                            "mongo_client"
                        ]
                    },
                    {
                        "name": "mock_config",
                        "docstring": "Fixture that returns a mock configuration.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "cleanup",
                        "docstring": "Fixture that cleans up the database after each test.",
                        "comments": null,
                        "args": [
                            "mock_config"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_db.py",
                "functions": [
                    {
                        "name": "test_get_db_success",
                        "docstring": "Test successful connection to the database.",
                        "comments": null,
                        "args": [
                            "mongo_client",
                            "mock_config"
                        ]
                    },
                    {
                        "name": "test_get_db_failure",
                        "docstring": "Test failure to connect to the database.",
                        "comments": null,
                        "args": [
                            "mock_config"
                        ]
                    },
                    {
                        "name": "test_create_version_collection",
                        "docstring": "Test creation of the version collection.",
                        "comments": null,
                        "args": [
                            "mongo_db",
                            "mock_config"
                        ]
                    },
                    {
                        "name": "test_create_version_collection_already_exists",
                        "docstring": "Test behavior when the version collection already exists.",
                        "comments": null,
                        "args": [
                            "mongo_db",
                            "mock_config"
                        ]
                    },
                    {
                        "name": "test_create_version_collection_already_exists_with_data",
                        "docstring": "Test behavior when the version collection already exists with data.",
                        "comments": null,
                        "args": [
                            "mongo_db",
                            "mock_config"
                        ]
                    },
                    {
                        "name": "test_set_current_version",
                        "docstring": "Test setting the current version.",
                        "comments": null,
                        "args": [
                            "mongo_db",
                            "mock_config"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_cli.py",
                "functions": [
                    {
                        "name": "test_init",
                        "docstring": "Test the init cli.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_create",
                        "docstring": "Test the create subcommand.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_upgrade",
                        "docstring": "Test the upgrade subcommand.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_downgrade",
                        "docstring": "Test the downgrade subcommand.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_history",
                        "docstring": "Test the history subcommand.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_no_subcommand",
                        "docstring": "Test no subcommand provided.",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_commands.py",
                "functions": [
                    {
                        "name": "get_migration_params",
                        "docstring": "Extract the migration parameters from a migration file.\nRaises:\n    ValueError: If the migration file does not contain the required parameters.\nReturns:\n    dictionary with the title, version, and last_version.",
                        "comments": "Utility",
                        "args": [
                            "migration_file_path"
                        ]
                    },
                    {
                        "name": "get_current_db_version",
                        "docstring": "Get the current version of the database.\nReturns:\n    The current version of the database.",
                        "comments": null,
                        "args": [
                            "mongo_db",
                            "mock_config"
                        ]
                    },
                    {
                        "name": "modify_migration",
                        "docstring": "Modifies a file to include the provided upgrade and downgrade code.\nAt least one of the upgrade_code or downgrade_code must be provided.\nOr both\nRaises:\n    ValueError: If neither upgrade_code nor downgrade_code is provided.",
                        "comments": null,
                        "args": [
                            "migration_file_path",
                            "upgrade_code",
                            "downgrade_code"
                        ]
                    },
                    {
                        "name": "test_init",
                        "docstring": "Test the init command.",
                        "comments": "Tests",
                        "args": [
                            "mock_config",
                            "mongo_db"
                        ]
                    },
                    {
                        "name": "test_create",
                        "docstring": "Test the create command.",
                        "comments": null,
                        "args": [
                            "mock_config",
                            "mongo_db"
                        ]
                    },
                    {
                        "name": "test_upgrade",
                        "docstring": "Test the upgrade command.",
                        "comments": null,
                        "args": [
                            "mock_config",
                            "mongo_db"
                        ]
                    },
                    {
                        "name": "test_downgrade",
                        "docstring": "Test the downgrade command.",
                        "comments": null,
                        "args": [
                            "mock_config",
                            "mongo_db"
                        ]
                    },
                    {
                        "name": "test_history",
                        "docstring": "Test the history command.",
                        "comments": null,
                        "args": [
                            "mock_config",
                            "mongo_db",
                            "capfd"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "src/mongo_migrator/migration_history.py",
                "functions": [],
                "classes": [
                    {
                        "name": "MigrationNode",
                        "docstring": "Represents a migration node in the migration history tree.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Create a new migration node.\nArgs:\n    title: The title of the migration.\n    version: The version of the migration.\n    last_version: The last version of the migration. None if it is the first migration.\n    upgrade: The upgrade function of the migration.\n    downgrade: The downgrade function of the migration.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "title",
                                    "version",
                                    "last_version",
                                    "upgrade",
                                    "downgrade"
                                ]
                            },
                            {
                                "name": "add_child",
                                "docstring": "Add a child node to the current node.\nArgs:\n    child_node: The child node to add.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "child_node"
                                ]
                            },
                            {
                                "name": "upgrade",
                                "docstring": "Apply the upgrade function of the migration.\nArgs:\n    db: The database to upgrade.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "db"
                                ]
                            },
                            {
                                "name": "downgrade",
                                "docstring": "Apply the downgrade function of the migration.\nArgs:\n    db: The database to downgrade.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "db"
                                ]
                            },
                            {
                                "name": "from_file",
                                "docstring": "Parse a migration file and return the migration node.\nArgs:\n    file_path: The path to the migration file.\nRaises:\n    FileNotFoundError: If the file is not found.\n    ValueError: If the file format is invalid.\nReturns:\n    The migration node parsed from the file.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "file_path"
                                ]
                            },
                            {
                                "name": "__repr__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__str__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "MigrationHistory",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Class for managing the migration history.\nArgs:\n    migrations_dir: The directory where the migrations are stored.\nAttributes:\n    migrations_dir: The directory where the migrations are stored.\n    roots: The root nodes of the migration history.\n    migrations: A dictionary of all migrations by version.\nRaises:\n    FileNotFoundError: If a migration file is not found.\n    ValueError: If a migration file format is invalid.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "migrations_dir"
                                ]
                            },
                            {
                                "name": "_load_migrations",
                                "docstring": "Private method to load all migrations from the migrations directory.\nMigrations without a last version or without a found last_version are considered as roots.\n\nRaises:\n    FileNotFoundError: If a migration file is not found.\n    ValueError: If a migration file format is invalid.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "is_empty",
                                "docstring": "Check if the migration history is empty.\nReturns:\n    True if the history is empty, False otherwise.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "validate",
                                "docstring": "Check the migration history for bifurcations.\nThe history is valid if it is a non empty linear tree.\nArgs:\n    node: The node to start the check. If None, the check starts from the root.\nReturns:\n    True if the history is valid, False otherwise.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "node"
                                ]
                            },
                            {
                                "name": "get_first_version",
                                "docstring": "Get the first version of the migration history.\nAssumes that the migration history is valid.\nReturns:\n    The first version of the migration history.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "get_first_node",
                                "docstring": "Get the first node of the migration history.\nAssumes that the migration history is valid.\nReturns:\n    The first node of the migration history.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "get_last_version",
                                "docstring": "Get the last version of the migration history.\nAssumes that the migration history is valid.\nReturns:\n    The last version of the migration history.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "get_last_node",
                                "docstring": "Get the last node of the migration history.\nAssumes that the migration history is valid.\nReturns:\n    The last node of the migration history.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "_print_linear_tree",
                                "docstring": "Print a linear tree of the migration history.\nArgs:\n    node: The node to print.\n    level: The level of the node in the tree.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "node",
                                    "current_version",
                                    "current_found",
                                    "is_applied"
                                ]
                            },
                            {
                                "name": "print_history",
                                "docstring": "Prints the history of migrations from oldest to newest.\nArgs:\n    current_version: The current version of the database.\nRaises:\n    ValueError: If the history is invalid.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "current_version"
                                ]
                            },
                            {
                                "name": "get_migrations",
                                "docstring": "Get a list of migrations.\nAssumes that the migration history is valid.\nArgs:\n    start_version: The version to start from. If None, the first version is used.\n    to_version: The last version of the migration list. If None, the last version is used.\nReturns:\n    A list of migrations.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "start_version",
                                    "to_version"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "src/mongo_migrator/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "src/mongo_migrator/migration_template.py",
                "functions": [],
                "classes": [
                    {
                        "name": "MigrationTemplate",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "create_migration_file",
                                "docstring": "Create a new migration file.\nArgs:\n    file_path: The path to the new migration file.\n    title: The title of the migration.\n    version: The version of the migration.\n    last_version: The oldest version of the migrations.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "file_path",
                                    "title",
                                    "version",
                                    "last_version"
                                ]
                            }
                        ],
                        "attributes": [
                            "TEMPLATE"
                        ]
                    }
                ]
            },
            {
                "file": "src/mongo_migrator/db_utils.py",
                "functions": [
                    {
                        "name": "get_db",
                        "docstring": "Get the database connection using pymongo.\nArgs:\n    db_host: The hostname of the MongoDB server.\n    db_port: The port number of the MongoDB server.\n    db_name: The name of the database.\n    db_user: The username for the database if needed.\n    db_pass: The password for the database if needed.\n    verbose: Whether to print messages.\n    max_retries: The number of times to retry connecting to the database.\nRaises:\n    Exception: If the connection cannot be established.\nReturns:\n    The database connection.",
                        "comments": null,
                        "args": [
                            "db_host",
                            "db_port",
                            "db_name",
                            "db_user",
                            "db_pass",
                            "verbose",
                            "max_retries"
                        ]
                    },
                    {
                        "name": "create_version_collection",
                        "docstring": "Create the version collection in the database.\nArgs:\n    db: The database connection.\n    collection_name: The name of the collection.",
                        "comments": null,
                        "args": [
                            "db",
                            "collection_name"
                        ]
                    },
                    {
                        "name": "set_current_version",
                        "docstring": "Set the current version.\nArgs:\n    db: The database connection.\n    collection_name: The name of the version collection.\n    version: The current version.",
                        "comments": null,
                        "args": [
                            "db",
                            "collection_name",
                            "version"
                        ]
                    },
                    {
                        "name": "get_current_version",
                        "docstring": "Get the current version.\nArgs:\n    db: The database connection.\n    collection_name: The name of the version collection.\nReturns:\n    The current version.",
                        "comments": null,
                        "args": [
                            "db",
                            "collection_name"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "src/mongo_migrator/config.py",
                "functions": [],
                "classes": [
                    {
                        "name": "Config",
                        "docstring": "Class to handle the configuration file",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the Config class.\n\nDescription:\n    Loads the configuration file and provides access to the configuration values.\n    This file must be named after CONFIG_FILE attribute.\n    It also must be placed in the same directory where mongo-migrator is going to be used.\n\nExit cases:\n    If the configuration file is not found, the program will exit.\n    If any of the required sections are missing, the program will exit.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": [
                            "CONFIG_FILE"
                        ]
                    }
                ]
            },
            {
                "file": "src/mongo_migrator/cli.py",
                "functions": [
                    {
                        "name": "init",
                        "docstring": "Needs a config file named 'mongo-migrator.config' in the current directory.\nWill create a migrations directory and a migration collection in the database.",
                        "comments": null,
                        "args": [
                            "args"
                        ]
                    },
                    {
                        "name": "create",
                        "docstring": "Creates a new migration file in the migration directory.",
                        "comments": null,
                        "args": [
                            "args"
                        ]
                    },
                    {
                        "name": "upgrade",
                        "docstring": "Upgrades the database to the latest version by default.",
                        "comments": null,
                        "args": [
                            "args"
                        ]
                    },
                    {
                        "name": "downgrade",
                        "docstring": "Downgrades the database to the previous version by default.",
                        "comments": null,
                        "args": [
                            "args"
                        ]
                    },
                    {
                        "name": "history",
                        "docstring": "Shows the migration history.",
                        "comments": null,
                        "args": [
                            "args"
                        ]
                    },
                    {
                        "name": "main",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            }
        ],
        "test_cases": {
            "tests/test_cli.py::test_init": {
                "testid": "tests/test_cli.py::test_init",
                "result": "passed",
                "test_implementation": "def test_init():\n    \"\"\"Test the init cli.\"\"\"\n    test_args = [\"mongo_migration\", \"init\"]\n    with mock.patch.object(sys, \"argv\", test_args):\n        with mock.patch(\"mongo_migrator.cli.init\") as init:\n            main()\n            init.assert_called_once()"
            },
            "tests/test_cli.py::test_create": {
                "testid": "tests/test_cli.py::test_create",
                "result": "passed",
                "test_implementation": "def test_create():\n    \"\"\"Test the create subcommand.\"\"\"\n    test_args = [\"mongo-migrator\", \"create\", \"Test Migration\"]\n    with mock.patch.object(sys, \"argv\", test_args):\n        with mock.patch(\"mongo_migrator.cli.create\") as mock_create:\n            main()\n            mock_create.assert_called_once_with(mock.ANY)\n            assert mock_create.call_args[0][0].title == \"Test Migration\""
            },
            "tests/test_cli.py::test_upgrade": {
                "testid": "tests/test_cli.py::test_upgrade",
                "result": "passed",
                "test_implementation": "def test_upgrade():\n    \"\"\"Test the upgrade subcommand.\"\"\"\n    test_args = [\"mongo-migrator\", \"upgrade\"]\n    with mock.patch.object(sys, \"argv\", test_args):\n        with mock.patch(\"mongo_migrator.cli.upgrade\") as mock_upgrade:\n            main()\n            mock_upgrade.assert_called_once_with(mock.ANY)"
            },
            "tests/test_cli.py::test_downgrade": {
                "testid": "tests/test_cli.py::test_downgrade",
                "result": "passed",
                "test_implementation": "def test_downgrade():\n    \"\"\"Test the downgrade subcommand.\"\"\"\n    test_args = [\"mongo-migrator\", \"downgrade\"]\n    with mock.patch.object(sys, \"argv\", test_args):\n        with mock.patch(\"mongo_migrator.cli.downgrade\") as mock_downgrade:\n            main()\n            mock_downgrade.assert_called_once_with(mock.ANY)"
            },
            "tests/test_cli.py::test_history": {
                "testid": "tests/test_cli.py::test_history",
                "result": "passed",
                "test_implementation": "def test_history():\n    \"\"\"Test the history subcommand.\"\"\"\n    test_args = [\"mongo-migrator\", \"history\"]\n    with mock.patch.object(sys, \"argv\", test_args):\n        with mock.patch(\"mongo_migrator.cli.history\") as mock_history:\n            main()\n            mock_history.assert_called_once_with(mock.ANY)"
            },
            "tests/test_cli.py::test_no_subcommand": {
                "testid": "tests/test_cli.py::test_no_subcommand",
                "result": "passed",
                "test_implementation": "def test_no_subcommand():\n    \"\"\"Test no subcommand provided.\"\"\"\n    test_args = [\"mongo-migrator\"]\n    with mock.patch.object(sys, \"argv\", test_args):\n        with mock.patch(\"argparse.ArgumentParser.print_help\") as mock_print_help:\n            with pytest.raises(SystemExit) as pytest_wrapped_e:\n                main()\n            mock_print_help.assert_called_once()\n            assert pytest_wrapped_e.type == SystemExit\n            assert pytest_wrapped_e.value.code == 1"
            },
            "tests/test_commands.py::test_init": {
                "testid": "tests/test_commands.py::test_init",
                "result": "passed",
                "test_implementation": "def test_init(mock_config, mongo_db):\n    \"\"\"Test the init command.\"\"\"\n    with mock.patch(\"mongo_migrator.cli.Config\", return_value=mock_config):\n        # If cannot connect to db, error\n        with mock.patch(\"mongo_migrator.cli.get_db\", side_effect=Exception):\n            init_command(None)\n            assert not os.path.exists(mock_config.migrations_dir)\n\n        with mock.patch(\"mongo_migrator.cli.get_db\", return_value=mongo_db):\n            # Call the init command\n            init_command(None)\n\n            # Verify collection was successfully created\n            assert mock_config.mm_collection in mongo_db.list_collection_names()\n            documents = list(mongo_db[mock_config.mm_collection].find())\n            # There is only one document in the collection\n            assert len(documents) == 1\n            assert \"current_version\" in documents[0]\n            # The current version is not set yet since no migrations have been run\n            assert documents[0][\"current_version\"] is None\n\n            # Verify that the migrations directory was created\n            assert os.path.exists(mock_config.migrations_dir)"
            },
            "tests/test_commands.py::test_create": {
                "testid": "tests/test_commands.py::test_create",
                "result": "passed",
                "test_implementation": "def test_create(mock_config, mongo_db):\n    \"\"\"Test the create command.\"\"\"\n    with mock.patch(\"mongo_migrator.cli.Config\", return_value=mock_config):\n        with mock.patch(\"mongo_migrator.cli.get_db\", return_value=mongo_db):\n            # If no migration directory exists, error\n            args = mock.Mock()\n            args.title = \"Test migration\"\n            create_command(args)\n            assert not os.path.exists(mock_config.migrations_dir)\n\n            # Initialize the migrator\n            init_command(None)\n\n            # Try creating a new migration without title\n            args = mock.Mock()\n            args.title = None\n            create_command(args)\n            # assert no files\n            assert not os.listdir(mock_config.migrations_dir)\n\n            # Try to create a new migration but the history cant load\n            with mock.patch(\n                \"mongo_migrator.cli.MigrationHistory\", side_effect=Exception\n            ):\n                args.title = \"Test migration\"\n                create_command(args)\n                # assert no files\n                assert not os.listdir(mock_config.migrations_dir)\n\n            # Try to create a new migration but the history is not empty and not valid\n            with mock.patch(\n                \"mongo_migrator.cli.MigrationHistory.is_empty\", return_value=False\n            ):\n                with mock.patch(\n                    \"mongo_migrator.cli.MigrationHistory.validate\", return_value=False\n                ):\n                    args.title = \"Test migration\"\n                    create_command(args)\n                    # assert no files\n                    assert not os.listdir(mock_config.migrations_dir)\n\n            # Create a new correct migration\n            # Verify that the migration file was created\n            timestamp = datetime.now().strftime(\"%Y%m%d%H%M\")\n            test_title = \"Test migration\"\n            args.title = test_title\n            create_command(args)\n            migration_files = os.listdir(mock_config.migrations_dir)\n            migration_files = sorted([f for f in migration_files if f.endswith(\".py\")])\n            assert len(migration_files) == 1\n\n            # Verify that the migration file contains the correct content\n            migration_file = migration_files[0]\n            migration_file_path = os.path.join(\n                mock_config.migrations_dir, migration_file\n            )\n\n            mig_params = get_migration_params(migration_file_path)\n\n            assert mig_params[\"title\"] == args.title\n            assert mig_params[\"version\"].startswith(timestamp)\n            assert mig_params[\"last_version\"] == \"None\"\n\n            # Create another migration and verify it has the correct last version\n            args.title = \"Another migration\"\n            timestamp = datetime.now().strftime(\"%Y%m%d%H%M\")\n            create_command(args)\n            migration_files = os.listdir(mock_config.migrations_dir)\n            migration_files = sorted([f for f in migration_files if f.endswith(\".py\")])\n            assert len(migration_files) == 2\n\n            # Verify that the migration file contains the correct content\n            migration_file = migration_files[1]\n            migration_file_path = os.path.join(\n                mock_config.migrations_dir, migration_file\n            )\n\n            second_mig_params = get_migration_params(migration_file_path)\n\n            assert second_mig_params[\"title\"] == args.title\n            assert second_mig_params[\"version\"].startswith(timestamp)\n            assert second_mig_params[\"last_version\"] == mig_params[\"version\"]"
            },
            "tests/test_commands.py::test_upgrade": {
                "testid": "tests/test_commands.py::test_upgrade",
                "result": "passed",
                "test_implementation": "def test_upgrade(mock_config, mongo_db):\n    \"\"\"Test the upgrade command.\"\"\"\n    with mock.patch(\"mongo_migrator.cli.Config\", return_value=mock_config):\n        with mock.patch(\"mongo_migrator.cli.get_db\", return_value=mongo_db):\n            # If no directory exists, error\n            args = mock.Mock()\n            args.all = True\n            upgrade_command(args)\n            assert not os.path.exists(mock_config.migrations_dir)\n\n            # If no current_version exists, error\n            os.makedirs(mock_config.migrations_dir)\n            upgrade_command(args)\n            assert not os.listdir(mock_config.migrations_dir)\n\n            # Initialize the migrator\n            init_command(None)\n\n            # If cannot connect to db, error\n            with mock.patch(\"mongo_migrator.cli.get_db\", side_effect=Exception):\n                upgrade_command(args)\n                assert get_current_db_version(mongo_db, mock_config) is None\n\n            # If history cant load, error\n            with mock.patch(\n                \"mongo_migrator.cli.MigrationHistory\", side_effect=Exception\n            ):\n                upgrade_command(args)\n                assert get_current_db_version(mongo_db, mock_config) is None\n\n            # Upgrade (all)\n            # # if no migrations to run, error\n            upgrade_command(args)\n            # Check current_version is still None\n            assert get_current_db_version(mongo_db, mock_config) is None\n\n            # Create some migrations\n            migrations = []\n            for i in range(1, 6):\n                args = mock.Mock()\n                args.title = f\"Test migration {i}\"\n                create_command(args)\n\n            # Get migration info\n            migration_files = os.listdir(mock_config.migrations_dir)\n            migration_files = sorted([f for f in migration_files if f.endswith(\".py\")])\n            for i, migration_file in enumerate(migration_files):\n                migration_file_path = os.path.join(\n                    mock_config.migrations_dir, migration_file\n                )\n                upgrade_code = f\"db.create_collection('test_collection_{i+1}')\"\n                downgrade_code = f\"db.drop_collection('test_collection_{i+1}')\"\n                modify_migration(migration_file_path, upgrade_code, downgrade_code)\n                mig_params = get_migration_params(migration_file_path)\n                migrations.append(mig_params)\n\n            # if history was not valid, error\n            with mock.patch(\n                \"mongo_migrator.cli.MigrationHistory.validate\", return_value=False\n            ):\n                upgrade_command(args)\n                # Check current_version is still None\n                assert get_current_db_version(mongo_db, mock_config) is None\n\n            # upgrade (version)\n            # # Upgrade to second migration\n            args = mock.Mock()\n            args.all = False\n            args.version = migrations[1][\"version\"]\n            upgrade_command(args)\n\n            # Verify the collection in the 1st 2nd migration was created\n            for i in range(1, 3):\n                assert f\"test_collection_{i}\" in mongo_db.list_collection_names()\n            # Verify the collection in the 3rd, 4th, and 5th migrations were not created\n            for i in range(3, 6):\n                assert f\"test_collection_{i}\" not in mongo_db.list_collection_names()\n\n            # Upgrade to a non pending migration\n            args = mock.Mock()\n            args.all = False\n            args.version = migrations[0][\"version\"]\n            upgrade_command(args)\n            # Verify the collection in the 3rd migration was still not created\n            assert \"test_collection_3\" not in mongo_db.list_collection_names()\n\n            # if there was an error running the migration...\n            args = mock.Mock()\n            args.all = True\n            args.version = None\n            with mock.patch(\n                \"mongo_migrator.migration_history.MigrationNode.upgrade\",\n                side_effect=Exception,\n            ):\n                upgrade_command(args)\n            # Verify the collection in the 3rd migration was still not created\n            assert \"test_collection_3\" not in mongo_db.list_collection_names()\n            # Verify the current version is the last applied\n            assert (\n                get_current_db_version(mongo_db, mock_config)\n                == migrations[1][\"version\"]\n            )\n\n            # Upgrade to the end and verify the collection was created\n            upgrade_code = \"db.create_collection('test_collection_3')\"\n            downgrade_code = \"db.drop_collection('test_collection_3')\"\n            modify_migration(migration_file_path, upgrade_code, downgrade_code)\n            args = mock.Mock()\n            args.all = True\n            args.version = None\n            upgrade_command(args)\n            for i in range(1, 6):\n                assert f\"test_collection_{i}\" in mongo_db.list_collection_names()\n            # Verify the current version is the last applied\n            assert (\n                get_current_db_version(mongo_db, mock_config)\n                == migrations[-1][\"version\"]\n            )\n\n            # Try to upgrade again\n            upgrade_command(args)\n            # Verify the current version is still the last applied\n            assert (\n                get_current_db_version(mongo_db, mock_config)\n                == migrations[-1][\"version\"]\n            )"
            },
            "tests/test_commands.py::test_downgrade": {
                "testid": "tests/test_commands.py::test_downgrade",
                "result": "passed",
                "test_implementation": "def test_downgrade(mock_config, mongo_db):\n    \"\"\"Test the downgrade command.\"\"\"\n    with mock.patch(\"mongo_migrator.cli.Config\", return_value=mock_config):\n        with mock.patch(\"mongo_migrator.cli.get_db\", return_value=mongo_db):\n            # If no directory exists, error\n            args = mock.Mock()\n            args.single = True\n            args.all = False\n            args.version = None\n            downgrade_command(args)\n            assert not os.path.exists(mock_config.migrations_dir)\n\n            # If no current_version exists, error\n            os.makedirs(mock_config.migrations_dir)\n            downgrade_command(args)\n            assert not os.listdir(mock_config.migrations_dir)\n\n            # Initialize the migrator\n            init_command(None)\n\n            # Create some migrations\n            migrations = []\n            for i in range(1, 6):\n                args = mock.Mock()\n                args.title = f\"Test migration {i}\"\n                create_command(args)\n\n            # Get migration info\n            migration_files = os.listdir(mock_config.migrations_dir)\n            migration_files = sorted([f for f in migration_files if f.endswith(\".py\")])\n            for i, migration_file in enumerate(migration_files):\n                migration_file_path = os.path.join(\n                    mock_config.migrations_dir, migration_file\n                )\n                upgrade_code = f\"db.create_collection('test_collection_{i+1}')\"\n                downgrade_code = f\"db.drop_collection('test_collection_{i+1}')\"\n                modify_migration(migration_file_path, upgrade_code, downgrade_code)\n                mig_params = get_migration_params(migration_file_path)\n                migrations.append(mig_params)\n\n            # If cannot connect to db, error\n            with mock.patch(\"mongo_migrator.cli.get_db\", side_effect=Exception):\n                downgrade_command(args)\n                assert get_current_db_version(mongo_db, mock_config) is None\n\n            # If history cant load, error\n            with mock.patch(\n                \"mongo_migrator.cli.MigrationHistory\", side_effect=Exception\n            ):\n                downgrade_command(args)\n                assert get_current_db_version(mongo_db, mock_config) is None\n\n            # If history was not valid, error\n            with mock.patch(\n                \"mongo_migrator.cli.MigrationHistory.validate\", return_value=False\n            ):\n                downgrade_command(args)\n                # Check current_version is still None\n                assert get_current_db_version(mongo_db, mock_config) is None\n\n            # Downgrade (previous) with no migrations upgraded\n            args = mock.Mock()\n            args.single = True\n            args.all = False\n            args.version = None\n            downgrade_command(args)\n            # Nothing should happen\n            assert get_current_db_version(mongo_db, mock_config) is None\n\n            # Run the upgrades\n            args = mock.Mock()\n            args.all = True\n            args.version = None\n            upgrade_command(args)\n            assert get_current_db_version(mongo_db, mock_config) is not None\n\n            # Downgrade (previous) with all migrations upgraded\n            args = mock.Mock()\n            args.single = True\n            args.all = False\n            args.version = None\n            downgrade_command(args)\n            # Verify the last collection was dropped\n            assert \"test_collection_5\" not in mongo_db.list_collection_names()\n            # Verify the current version is the last applied\n            assert (\n                get_current_db_version(mongo_db, mock_config)\n                == migrations[3][\"version\"]\n            )\n\n            # Downgrade to non parent migration, nothing should happen\n            args = mock.Mock()\n            args.single = False\n            args.all = False\n            args.version = migrations[-1][\"version\"]\n            downgrade_command(args)\n            # Verify the collection in the 4th migration was not dropped\n            assert \"test_collection_4\" in mongo_db.list_collection_names()\n            # Verify the current version is still 4th migration\n            assert (\n                get_current_db_version(mongo_db, mock_config)\n                == migrations[3][\"version\"]\n            )\n\n            # Try downgrading to the same version\n            args = mock.Mock()\n            args.single = False\n            args.all = False\n            args.version = migrations[3][\"version\"]\n            downgrade_command(args)\n\n            # Downgrade (version)\n            args = mock.Mock()\n            args.single = False\n            args.all = False\n            args.version = migrations[2][\"version\"]\n            downgrade_command(args)\n            # Verify the collection in the fourth migration was dropped\n            assert \"test_collection_4\" not in mongo_db.list_collection_names()\n            # Verify the collection in the third migration was not dropped\n            assert \"test_collection_3\" in mongo_db.list_collection_names()\n            # Verify the current version is the third migration\n            assert (\n                get_current_db_version(mongo_db, mock_config)\n                == migrations[2][\"version\"]\n            )\n\n            # If there was an error running the migration...\n            args = mock.Mock()\n            args.single = False\n            args.all = True\n            args.version = None\n            with mock.patch(\n                \"mongo_migrator.migration_history.MigrationNode.downgrade\",\n                side_effect=Exception,\n            ):\n                downgrade_command(args)\n            # Verify the current version is the last applied\n            assert (\n                get_current_db_version(mongo_db, mock_config)\n                == migrations[2][\"version\"]\n            )\n            # Verify the collections were not dropped\n            for i in range(1, 4):\n                assert f\"test_collection_{i}\" in mongo_db.list_collection_names()\n\n            # Downgrade (all)\n            args = mock.Mock()\n            args.single = False\n            args.all = True\n            args.version = None\n            downgrade_command(args)\n            # Verify all collections were dropped\n            for i in range(1, 6):\n                assert f\"test_collection_{i}\" not in mongo_db.list_collection_names()\n            # Verify the current version is None\n            assert get_current_db_version(mongo_db, mock_config) is None\n\n            # Try to downgrade again\n            downgrade_command(args)\n            # Verify the current version is still None\n            assert get_current_db_version(mongo_db, mock_config) is None"
            },
            "tests/test_commands.py::test_history": {
                "testid": "tests/test_commands.py::test_history",
                "result": "passed",
                "test_implementation": "def test_history(mock_config, mongo_db, capfd):\n    \"\"\"Test the history command.\"\"\"\n    with mock.patch(\"mongo_migrator.cli.Config\", return_value=mock_config):\n        with mock.patch(\"mongo_migrator.cli.get_db\", return_value=mongo_db):\n            # If no directory exists, error\n            history_command(None)\n            assert not os.path.exists(mock_config.migrations_dir)\n\n            # If no current_version exists, error\n            os.makedirs(mock_config.migrations_dir)\n            history_command(None)\n            assert not os.listdir(mock_config.migrations_dir)\n\n            # Initialize the migrator\n            init_command(None)\n\n            migrations = []\n            for i in range(1, 6):\n                args = mock.Mock()\n                args.title = f\"Test migration {i}\"\n                create_command(args)\n\n            # Get migration info\n            migration_files = os.listdir(mock_config.migrations_dir)\n            migration_files = sorted([f for f in migration_files if f.endswith(\".py\")])\n            for migration_file in migration_files:\n                migration_file_path = os.path.join(\n                    mock_config.migrations_dir, migration_file\n                )\n                mig_params = get_migration_params(migration_file_path)\n                migrations.append(mig_params)\n\n            # # Run the upgrades\n            args = mock.Mock()\n            args.all = False\n            args.version = migrations[2][\"version\"]\n            upgrade_command(args)\n            assert (\n                get_current_db_version(mongo_db, mock_config)\n                == migrations[2][\"version\"]\n            )\n\n            # If cannot connect to db, error\n            with mock.patch(\"mongo_migrator.cli.get_db\", side_effect=Exception):\n                history_command(None)\n\n            # If history cant load, error\n            with mock.patch(\n                \"mongo_migrator.cli.MigrationHistory\", side_effect=Exception\n            ):\n                history_command(None)\n\n            # Verify the output\n            # First two migrations must be applied\n            # Third migration must be current\n            # Fourth and fifth migrations must be pending\n            # Title and version must match\n            expected_output = [\n                \"[+] Migration history:\",\n                f'├── (APPLIED) {migrations[0][\"version\"]} - {migrations[0][\"title\"]}',\n                f'├── (APPLIED) {migrations[1][\"version\"]} - {migrations[1][\"title\"]}',\n                f'├──>(CURRENT) {migrations[2][\"version\"]} - {migrations[2][\"title\"]}',\n                f'├── (PENDING) {migrations[3][\"version\"]} - {migrations[3][\"title\"]}',\n                f'└── (PENDING) {migrations[4][\"version\"]} - {migrations[4][\"title\"]}',\n            ]\n            expected_output_str = \"\\n\".join(expected_output)\n\n            # Capture the output of history_command\n            capfd.readouterr()  # Clear any previous captured output\n            history_command(None)\n            captured = capfd.readouterr()\n            assert captured.out.strip() == expected_output_str"
            },
            "tests/test_config.py::test_config_loads_ok": {
                "testid": "tests/test_config.py::test_config_loads_ok",
                "result": "passed",
                "test_implementation": "def test_config_loads_ok(create_config_file):\n    \"\"\"Test that the configuration file is loaded correctly\"\"\"\n    config = Config()\n\n    # Database configuration assertions\n    assert config.db_host == \"localhost\"\n    assert config.db_port == 27017\n    assert config.db_name == \"test_db\"\n    assert config.db_user == \"test_user\"\n    assert config.db_password == \"test_password\"\n\n    # Migrations configuration assertions\n    assert config.migrations_dir == \"migrations\"\n    assert config.mm_collection == \"migration_collection\""
            },
            "tests/test_config.py::test_config_not_found": {
                "testid": "tests/test_config.py::test_config_not_found",
                "result": "passed",
                "test_implementation": "def test_config_not_found():\n    \"\"\"Test that the program exits when the configuration file is not found\"\"\"\n    if os.path.exists(CONFIG_FILE):\n        os.remove(CONFIG_FILE)\n\n    with pytest.raises(SystemExit) as excinfo:\n        Config()\n\n    assert excinfo.value.code == 1"
            },
            "tests/test_config.py::test_config_missing_sections": {
                "testid": "tests/test_config.py::test_config_missing_sections",
                "result": "passed",
                "test_implementation": "def test_config_missing_sections(create_config_file):\n    \"\"\"Test that the program exits when the configuration file is missing sections\"\"\"\n    config_content = \"\"\"[database]\nhost = localhost\nport = 27017\nname = test_db\n\"\"\"\n\n    with open(CONFIG_FILE, \"w\") as file:\n        file.write(config_content)\n\n    with pytest.raises(SystemExit) as excinfo:\n        Config()\n\n    assert excinfo.value.code == 1"
            },
            "tests/test_config.py::test_config_missing_options": {
                "testid": "tests/test_config.py::test_config_missing_options",
                "result": "passed",
                "test_implementation": "def test_config_missing_options(create_config_file):\n    \"\"\"Test that the program does not exit when an option is missing\"\"\"\n    config_content = \"\"\"[database]\nhost = localhost\nport = 27017\nname = test_db\n\n[migrations]\ndirectory = migrations\ncollection = migration_collection\n\"\"\"\n\n    with open(CONFIG_FILE, \"w\") as file:\n        file.write(config_content)\n\n    config = Config()\n\n    assert config.db_user is None\n    assert config.db_password is None"
            },
            "tests/test_config.py::test_config_user_pass_are_optional": {
                "testid": "tests/test_config.py::test_config_user_pass_are_optional",
                "result": "passed",
                "test_implementation": "def test_config_user_pass_are_optional(create_config_file):\n    \"\"\"Test that the program does not exit when user and password are not provided\"\"\"\n    config_content = \"\"\"[database]\nhost = localhost\nport = 27017\nname = test_db\n\n[migrations]\ndirectory = migrations\ncollection = migration_collection\n\"\"\"\n\n    with open(CONFIG_FILE, \"w\") as file:\n        file.write(config_content)\n\n    config = Config()\n\n    assert config.db_user is None\n    assert config.db_password is None"
            },
            "tests/test_db.py::test_get_db_success": {
                "testid": "tests/test_db.py::test_get_db_success",
                "result": "passed",
                "test_implementation": "def test_get_db_success(mongo_client, mock_config):\n    \"\"\"Test successful connection to the database.\"\"\"\n    with mock.patch(\"mongo_migrator.db_utils.MongoClient\", return_value=mongo_client):\n        db = get_db(\n            db_host=mock_config.db_host,\n            db_port=mock_config.db_port,\n            db_name=mock_config.db_name,\n            db_user=mock_config.db_user,\n            db_pass=mock_config.db_password,\n            verbose=True,\n        )\n\n        assert db.name == mock_config.db_name"
            },
            "tests/test_db.py::test_get_db_failure": {
                "testid": "tests/test_db.py::test_get_db_failure",
                "result": "passed",
                "test_implementation": "def test_get_db_failure(mock_config):\n    \"\"\"Test failure to connect to the database.\"\"\"\n    with pytest.raises(Exception, match=\"Could not connect to database\"):\n        get_db(\n            db_host=mock_config.db_host,\n            db_port=mock_config.db_port,\n            db_name=mock_config.db_name,\n            db_user=mock_config.db_user,\n            db_pass=mock_config,\n        )"
            },
            "tests/test_db.py::test_create_version_collection": {
                "testid": "tests/test_db.py::test_create_version_collection",
                "result": "passed",
                "test_implementation": "def test_create_version_collection(mongo_db, mock_config):\n    \"\"\"Test creation of the version collection.\"\"\"\n    create_version_collection(mongo_db, mock_config.mm_collection)\n    assert mock_config.mm_collection in mongo_db.list_collection_names()\n    assert mongo_db[mock_config.mm_collection].count_documents({}) == 1\n    assert mongo_db[mock_config.mm_collection].find_one().get(\"current_version\") is None"
            },
            "tests/test_db.py::test_create_version_collection_already_exists": {
                "testid": "tests/test_db.py::test_create_version_collection_already_exists",
                "result": "passed",
                "test_implementation": "def test_create_version_collection_already_exists(mongo_db, mock_config):\n    \"\"\"Test behavior when the version collection already exists.\"\"\"\n    mongo_db.create_collection(mock_config.mm_collection)\n    create_version_collection(mongo_db, mock_config.mm_collection)\n    assert mock_config.mm_collection in mongo_db.list_collection_names()"
            },
            "tests/test_db.py::test_create_version_collection_already_exists_with_data": {
                "testid": "tests/test_db.py::test_create_version_collection_already_exists_with_data",
                "result": "passed",
                "test_implementation": "def test_create_version_collection_already_exists_with_data(mongo_db, mock_config):\n    \"\"\"Test behavior when the version collection already exists with data.\"\"\"\n    mongo_db.create_collection(mock_config.mm_collection)\n    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S%f\")\n    mongo_db[mock_config.mm_collection].insert_one({\"current_version\": timestamp})\n    create_version_collection(mongo_db, mock_config.mm_collection)\n    assert mock_config.mm_collection in mongo_db.list_collection_names()\n    assert mongo_db[mock_config.mm_collection].count_documents({}) == 1\n    assert (\n        mongo_db[mock_config.mm_collection].find_one().get(\"current_version\")\n        == timestamp\n    )"
            },
            "tests/test_db.py::test_set_current_version": {
                "testid": "tests/test_db.py::test_set_current_version",
                "result": "passed",
                "test_implementation": "def test_set_current_version(mongo_db, mock_config):\n    \"\"\"Test setting the current version.\"\"\"\n    collection_name = mock_config.mm_collection\n    create_version_collection(mongo_db, collection_name)\n    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S%f\")\n    set_current_version(mongo_db, collection_name, timestamp)\n    version = mongo_db[collection_name].find_one().get(\"current_version\")\n    assert version == timestamp"
            },
            "tests/test_history.py::test_history_invalid_migration": {
                "testid": "tests/test_history.py::test_history_invalid_migration",
                "result": "passed",
                "test_implementation": "def test_history_invalid_migration(mock_config, mongo_db, capfd):\n    \"\"\"Test the history command with an invalid migration file.\"\"\"\n    with mock.patch(\"mongo_migrator.cli.Config\", return_value=mock_config):\n        with mock.patch(\"mongo_migrator.cli.get_db\", return_value=mongo_db):\n            # Initialize the migrator\n            init_command(None)\n\n            # Create a migration with missing parameters\n            args = mock.Mock()\n            args.title = \"Invalid migration\"\n            create_command(args)\n            migration_files = os.listdir(mock_config.migrations_dir)\n            migration_files = sorted([f for f in migration_files if f.endswith(\".py\")])\n            migration_file = migration_files[0]\n            migration_file_path = os.path.join(\n                mock_config.migrations_dir, migration_file\n            )\n\n            # Modify the migration file to remove its parameters\n            with open(migration_file_path, \"r\") as file:\n                migration_content = file.read()\n\n            migration_content = re.sub(r\"title:\\s*(.*)\", \"\", migration_content)\n            migration_content = re.sub(r\"version:\\s*(.*)\", \"\", migration_content)\n            migration_content = re.sub(r\"last_version:\\s*(.*)\", \"\", migration_content)\n\n            with open(migration_file_path, \"w\") as file:\n                file.write(migration_content)\n\n            capfd.readouterr()\n            history_command(None)\n            captured = capfd.readouterr()\n            assert \"Invalid migration file format\" in captured.out.strip()"
            },
            "tests/test_history.py::test_migration_node_representation": {
                "testid": "tests/test_history.py::test_migration_node_representation",
                "result": "passed",
                "test_implementation": "def test_migration_node_representation(mock_config):\n    \"\"\"Test the representation of a migration node.\"\"\"\n    migration_node = MigrationNode(\n        title=\"Test migration\", version=\"1\", last_version=None\n    )\n    assert (\n        repr(migration_node)\n        == \"MigrationNode(title=Test migration, version=1, last_version=None)\"\n    )"
            },
            "tests/test_history.py::test_is_empty_history": {
                "testid": "tests/test_history.py::test_is_empty_history",
                "result": "passed",
                "test_implementation": "def test_is_empty_history(mongo_db, mock_config):\n    \"\"\"Test the is_empty method of MigrationHistory.\"\"\"\n    with mock.patch(\"mongo_migrator.cli.Config\", return_value=mock_config):\n        with mock.patch(\"mongo_migrator.cli.get_db\", return_value=mongo_db):\n            init_command(None)\n            history = MigrationHistory(mock_config.migrations_dir)\n            assert history.is_empty()\n            noderoot = MigrationNode(\n                title=\"Migration 1\", version=\"1\", last_version=None\n            )\n            history.roots.append(noderoot)\n            history.migrations[noderoot.version] = noderoot\n            assert not history.is_empty()"
            },
            "tests/test_history.py::test_validate_history": {
                "testid": "tests/test_history.py::test_validate_history",
                "result": "passed",
                "test_implementation": "def test_validate_history(mongo_db, mock_config):\n    \"\"\"Test the validate function of MigrationHistory.\"\"\"\n    with mock.patch(\"mongo_migrator.cli.Config\", return_value=mock_config):\n        with mock.patch(\"mongo_migrator.cli.get_db\", return_value=mongo_db):\n            init_command(None)\n\n            # Empty history\n            history = MigrationHistory(mock_config.migrations_dir)\n            assert not history.validate(), \"La historia vacía debería ser inválida.\"\n\n            # Create migration nodes for the following cases\n            noderoot1 = MigrationNode(\n                title=\"Migration 1\", version=\"1\", last_version=None\n            )\n            noderoot2 = MigrationNode(\n                title=\"Migration 1\", version=\"1\", last_version=\"1\"\n            )\n\n            # If there are several first migrations, the history is invalid\n            history.roots.append(noderoot1)\n            history.roots.append(noderoot2)\n            history.migrations[noderoot1.version] = noderoot1\n            history.migrations[noderoot2.version] = noderoot2\n            assert not history.validate()\n\n            # If a node has several children, the history is invalid\n            node2 = MigrationNode(title=\"Migration 2\", version=\"2\", last_version=\"1\")\n            node3 = MigrationNode(title=\"Migration 3\", version=\"3\", last_version=\"1\")\n            noderoot1.add_child(node2)\n            noderoot1.add_child(node3)\n            history.roots = [noderoot1]\n            del history.migrations[noderoot2.version]\n            history.migrations[node2.version] = node2\n            history.migrations[node3.version] = node3\n            assert not history.validate()\n\n            # Fix the history and validate it\n            history = MigrationHistory(mock_config.migrations_dir)\n            noderoot1 = MigrationNode(\n                title=\"Migration 1\", version=\"1\", last_version=None\n            )\n            node2 = MigrationNode(title=\"Migration 2\", version=\"2\", last_version=\"1\")\n            node3 = MigrationNode(title=\"Migration 3\", version=\"3\", last_version=\"2\")\n            noderoot1.add_child(node2)\n            node2.add_child(node3)\n            history.roots = [noderoot1]\n            history.migrations[noderoot1.version] = noderoot1\n            history.migrations[node2.version] = node2\n            history.migrations[node3.version] = node3\n            assert history.validate()"
            },
            "tests/test_history.py::test_get_first_version": {
                "testid": "tests/test_history.py::test_get_first_version",
                "result": "passed",
                "test_implementation": "def test_get_first_version(mongo_db, mock_config):\n    \"\"\"Test the get_first_version function of MigrationHistory.\"\"\"\n    with mock.patch(\"mongo_migrator.cli.Config\", return_value=mock_config):\n        with mock.patch(\"mongo_migrator.cli.get_db\", return_value=mongo_db):\n            init_command(None)\n\n            # Empty history\n            history = MigrationHistory(mock_config.migrations_dir)\n            assert history.get_first_version() is None\n\n            # Create migration nodes for the following cases\n            noderoot1 = MigrationNode(\n                title=\"Migration 1\", version=\"1\", last_version=None\n            )\n            node2 = MigrationNode(title=\"Migration 2\", version=\"2\", last_version=\"1\")\n            node3 = MigrationNode(title=\"Migration 3\", version=\"3\", last_version=\"2\")\n            noderoot1.add_child(node2)\n            node2.add_child(node3)\n            history.roots = [noderoot1]\n            history.migrations[noderoot1.version] = noderoot1\n            history.migrations[node2.version] = node2\n            history.migrations[node3.version] = node3\n\n            assert history.get_first_version() == \"1\""
            },
            "tests/test_history.py::test_get_first_node": {
                "testid": "tests/test_history.py::test_get_first_node",
                "result": "passed",
                "test_implementation": "def test_get_first_node(mongo_db, mock_config):\n    \"\"\"Test the get_first_node function of MigrationHistory.\"\"\"\n    with mock.patch(\"mongo_migrator.cli.Config\", return_value=mock_config):\n        with mock.patch(\"mongo_migrator.cli.get_db\", return_value=mongo_db):\n            init_command(None)\n\n            # Empty history\n            history = MigrationHistory(mock_config.migrations_dir)\n            assert history.get_first_node() is None\n\n            # Create migration nodes for the following cases\n            noderoot1 = MigrationNode(\n                title=\"Migration 1\", version=\"1\", last_version=None\n            )\n            node2 = MigrationNode(title=\"Migration 2\", version=\"2\", last_version=\"1\")\n            node3 = MigrationNode(title=\"Migration 3\", version=\"3\", last_version=\"2\")\n            noderoot1.add_child(node2)\n            node2.add_child(node3)\n            history.roots = [noderoot1]\n            history.migrations[noderoot1.version] = noderoot1\n            history.migrations[node2.version] = node2\n            history.migrations[node3.version] = node3\n\n            assert history.get_first_node() == noderoot1"
            },
            "tests/test_history.py::test_get_last_version": {
                "testid": "tests/test_history.py::test_get_last_version",
                "result": "passed",
                "test_implementation": "def test_get_last_version(mongo_db, mock_config):\n    \"\"\"Test the get_last_version function of MigrationHistory.\"\"\"\n    with mock.patch(\"mongo_migrator.cli.Config\", return_value=mock_config):\n        with mock.patch(\"mongo_migrator.cli.get_db\", return_value=mongo_db):\n            init_command(None)\n\n            # Empty history\n            history = MigrationHistory(mock_config.migrations_dir)\n            assert history.get_last_version() is None\n\n            # Create migration nodes for the following cases\n            noderoot1 = MigrationNode(\n                title=\"Migration 1\", version=\"1\", last_version=None\n            )\n            node2 = MigrationNode(title=\"Migration 2\", version=\"2\", last_version=\"1\")\n            node3 = MigrationNode(title=\"Migration 3\", version=\"3\", last_version=\"2\")\n            noderoot1.add_child(node2)\n            node2.add_child(node3)\n            history.roots = [noderoot1]\n            history.migrations[noderoot1.version] = noderoot1\n            history.migrations[node2.version] = node2\n            history.migrations[node3.version] = node3\n\n            assert history.get_last_version() == \"3\""
            },
            "tests/test_history.py::test_get_last_node": {
                "testid": "tests/test_history.py::test_get_last_node",
                "result": "passed",
                "test_implementation": "def test_get_last_node(mongo_db, mock_config):\n    \"\"\"Test the get_last_node function of MigrationHistory.\"\"\"\n    with mock.patch(\"mongo_migrator.cli.Config\", return_value=mock_config):\n        with mock.patch(\"mongo_migrator.cli.get_db\", return_value=mongo_db):\n            init_command(None)\n\n            # Empty history\n            history = MigrationHistory(mock_config.migrations_dir)\n            assert history.get_last_node() is None\n\n            # Create migration nodes for the following cases\n            noderoot1 = MigrationNode(\n                title=\"Migration 1\", version=\"1\", last_version=None\n            )\n            node2 = MigrationNode(title=\"Migration 2\", version=\"2\", last_version=\"1\")\n            node3 = MigrationNode(title=\"Migration 3\", version=\"3\", last_version=\"2\")\n            noderoot1.add_child(node2)\n            node2.add_child(node3)\n            history.roots = [noderoot1]\n            history.migrations[noderoot1.version] = noderoot1\n            history.migrations[node2.version] = node2\n            history.migrations[node3.version] = node3\n\n            assert history.get_last_node() == node3"
            },
            "tests/test_history.py::test_get_migrations": {
                "testid": "tests/test_history.py::test_get_migrations",
                "result": "passed",
                "test_implementation": "def test_get_migrations(mongo_db, mock_config):\n    \"\"\"Test the get_migrations function of MigrationHistory.\"\"\"\n    with mock.patch(\"mongo_migrator.cli.Config\", return_value=mock_config):\n        with mock.patch(\"mongo_migrator.cli.get_db\", return_value=mongo_db):\n            init_command(None)\n\n            # Create migration nodes\n            history = MigrationHistory(mock_config.migrations_dir)\n            noderoot1 = MigrationNode(\n                title=\"Migration 1\", version=\"1\", last_version=None\n            )\n            node2 = MigrationNode(title=\"Migration 2\", version=\"2\", last_version=\"1\")\n            node3 = MigrationNode(title=\"Migration 3\", version=\"3\", last_version=\"2\")\n            node4 = MigrationNode(title=\"Migration 4\", version=\"4\", last_version=\"3\")\n            node5 = MigrationNode(title=\"Migration 5\", version=\"5\", last_version=\"4\")\n            noderoot1.add_child(node2)\n            node2.add_child(node3)\n            node3.add_child(node4)\n            node4.add_child(node5)\n            history.roots = [noderoot1]\n            history.migrations[noderoot1.version] = noderoot1\n            history.migrations[node2.version] = node2\n            history.migrations[node3.version] = node3\n            history.migrations[node4.version] = node4\n            history.migrations[node5.version] = node5\n\n            assert history.get_migrations() == [noderoot1, node2, node3, node4, node5]\n\n            assert history.get_migrations(to_version=\"4\") == [\n                noderoot1,\n                node2,\n                node3,\n                node4,\n            ]\n\n            assert history.get_migrations(start_version=\"3\") == [node3, node4, node5]\n\n            assert history.get_migrations(start_version=\"2\", to_version=\"4\") == [\n                node2,\n                node3,\n                node4,\n            ]"
            }
        },
        "SRS_document": "**Software Requirements Specification**\n\n**Mongo Migrator**\n\n**Primary Goal of this SRS Document:**\nThis Software Requirements Specification (SRS) document will serve a critical role in assessing software developers. Developers will be provided with this SRS document and a designated subset of the original test cases (public tests). Their objective is to develop a complete, functional software project based *solely* on this SRS. Their final success will be rigorously measured by whether their implementation passes *all* original test cases, including a comprehensive set of private tests not initially provided to them.\n\n**Table of Contents**\n1.  Introduction\n    1.1 Purpose\n    1.2 Scope\n    1.3 Definitions, Acronyms, and Abbreviations\n    1.4 References\n    1.5 Document Overview\n2.  Overall Description\n    2.1 Product Perspective\n    2.2 Product Functions\n    2.3 User Characteristics\n    2.4 Constraints\n    2.5 Assumptions and Dependencies\n3.  Specific Requirements\n    3.1 Functional Requirements\n        3.1.1 Configuration Management\n        3.1.2 System Initialization\n        3.1.3 Migration File Management\n        3.1.4 Migration Execution\n        3.1.5 Migration History Management\n        3.1.6 Command-Line Interface Operations\n        3.1.7 General System Behavior\n    3.2 Non-Functional Requirements\n    3.3 External Interface Requirements\n        3.3.1 Configuration File Interface\n        3.3.2 Migration File Interface\n        3.3.3 Command-Line Interface (CLI)\n    3.4 Other Requirements (General Constraints)\n\n---\n\n**1. Introduction**\n\n**1.1 Purpose**\nThe purpose of this Software Requirements Specification (SRS) document is to provide a comprehensive description of the functionalities and constraints for the Mongo Migrator software. This document is intended to be used by software developers as the sole source of requirements for implementing the system. It will also form the basis for assessing the completeness and correctness of their implementation against a full suite of test cases (public and private).\n\n**1.2 Scope**\nThe Mongo Migrator is a command-line tool designed to manage MongoDB database schema migrations. It enables users to create, apply (upgrade), and revert (downgrade) migrations, as well as view the history of applied migrations. The system operates based on a configuration file and a directory of migration script files.\n\n**1.3 Definitions, Acronyms, and Abbreviations**\n*   **SRS:** Software Requirements Specification\n*   **CLI:** Command Line Interface\n*   **DB:** Database\n*   **MongoDB:** A NoSQL document database.\n*   **Migration:** A set of operations (e.g., schema changes, data transformations) applied to a database to move it from one version state to another.\n*   **Migration File:** A Python script containing the logic for an upgrade and a downgrade operation.\n*   **Version (Migration Version):** A unique identifier for a migration, typically timestamp-based.\n*   **Current DB Version:** The version identifier of the last successfully applied migration in the database.\n\n**1.4 References**\n*   Original README.md for Mongo Migrator (provided as context to the LLM)\n*   Original source code for Mongo Migrator (provided as context to the LLM)\n*   Original test cases for Mongo Migrator (provided as context to the LLM)\n\n**1.5 Document Overview**\nThis document is organized into three main sections:\n*   **Section 1 (Introduction):** Provides an overview of the SRS, including its purpose, scope, definitions, references, and document structure.\n*   **Section 2 (Overall Description):** Describes the product in general terms, including its perspective, functions, user characteristics, constraints, assumptions, and dependencies.\n*   **Section 3 (Specific Requirements):** Details all requirements, including functional, non-functional, external interface, and other constraints. Functional requirements describe *what* the system must do.\n\n---\n\n**2. Overall Description**\n\n**2.1 Product Perspective**\nMongo Migrator is a standalone command-line utility that assists developers in managing and versioning changes to their MongoDB database schemas. It interacts with a MongoDB instance as specified in its configuration file and manages migration scripts stored in a local directory.\n\n**2.2 Product Functions**\nThe Mongo Migrator provides the following key functionalities:\n*   **Initialization:** Sets up the necessary environment for managing migrations, including creating a migrations directory and a version tracking collection in the database.\n*   **Migration Creation:** Generates new migration script files based on a template, including metadata such as title, version, and the version of the preceding migration.\n*   **Migration Application (Upgrade):** Applies pending migration scripts to the database in chronological order, up to the latest available migration or a user-specified version.\n*   **Migration Reversion (Downgrade):** Reverts applied migrations in reverse chronological order, either the last one, all migrations, or down to a user-specified version.\n*   **Migration History Viewing:** Displays the history of all migrations, indicating their status (e.g., applied, current, pending) relative to the current state of the database.\n*   **Configuration Management:** Reads database connection details and migration settings from a configuration file.\n*   **Migration History Validation:** Ensures the integrity of the migration history, preventing operations if the history is inconsistent (e.g., bifurcated).\n\n**2.3 User Characteristics**\nThe primary users of Mongo Migrator are software developers and database administrators who need to manage evolving MongoDB database schemas in a controlled and versioned manner. Users are expected to be familiar with command-line interfaces and MongoDB concepts.\n\n**2.4 Constraints**\n*   The system must be operated via a command-line interface.\n*   The system relies on a configuration file (`mongo-migrator.config`) for database connection and migration settings.\n*   Migration scripts must be written in Python and adhere to a specified structure.\n*   The system requires access to a MongoDB instance (version 4.0 or higher is recommended as per original documentation).\n*   Migration history is assumed to be linear; bifurcated or non-sequential histories are treated as invalid.\n\n**2.5 Assumptions and Dependencies**\n*   Users have a Python environment installed to run the tool.\n*   Users have network access to the target MongoDB server from the environment where the tool is run.\n*   The MongoDB user specified in the configuration (if any) has sufficient permissions to perform administrative tasks such as creating collections, inserting/updating documents in the version tracking collection, and executing the operations defined within migration scripts (e.g., creating/dropping collections, inserting/updating/deleting data).\n\n---\n\n**3. Specific Requirements**\n\n**3.1 Functional Requirements**\n\n**3.1.1 Configuration Management**\n*   **FR-CONF-LOAD-001:** The system shall load configuration settings from a designated configuration file.\n    *   Details: The configuration file specifies database connection parameters and migration management settings.\n*   **FR-CONF-OPTIONAL-AUTH-002:** Database username and password configuration parameters shall be optional. If not provided, the system should attempt to connect without authentication or assume authentication is handled by other means.\n\n**3.1.2 System Initialization (`init` command)**\n*   **FR-INIT-READ-CONFIG-001:** The initialization process shall begin by reading system configuration.\n*   **FR-INIT-CREATE-MIG-DIR-002:** The system shall create a directory for storing migration files, as specified in the configuration, if it does not already exist.\n*   **FR-INIT-DB-CONNECT-003:** The system shall attempt to connect to the MongoDB database specified in the configuration.\n*   **FR-INIT-CREATE-VER-COL-004:** The system shall create a dedicated version tracking collection in the MongoDB database, as named in the configuration, if it does not already exist.\n*   **FR-INIT-VER-COL-SCHEMA-005:** If the version tracking collection is newly created, the system shall initialize it with a single document containing a field to store the current database migration version, initially set to a null or empty state.\n*   **FR-INIT-VER-COL-EXIST-006:** If the version tracking collection already exists and contains data (e.g., a current version), its existing content related to the current version shall be preserved during initialization.\n\n**3.1.3 Migration File Management (`create` command)**\n*   **FR-MFM-CREATE-FILE-001:** The system shall generate a new migration file in the configured migrations directory when requested with a title.\n*   **FR-MFM-FILE-NAMING-002:** The generated migration filename shall incorporate a unique, chronologically sortable timestamp (e.g., YYYYMMDDHHMMSSffffff) and a sanitized version of the provided migration title.\n    *   Example: `20231026103000123456_added_new_field.py`\n*   **FR-MFM-FILE-CONTENT-003:** The generated migration file shall contain predefined content including:\n    1.  Metadata: migration title, its own generated version (timestamp), and the version of the immediately preceding migration (or a null/None indicator if it's the first migration).\n    2.  Stub (template) Python functions for `upgrade(db)` and `downgrade(db)` operations.\n*   **FR-MFM-LAST-VERSION-DET-004:** When creating a new migration file, the system shall determine the version of the most recent existing migration to set as the `last_version` metadata in the new file. If no migrations exist, `last_version` shall indicate it's the first migration.\n*   **FR-MFM-CREATE-HIST-VALIDATE-005:** The system shall validate the existing migration history before creating a new migration file. If the history is invalid (e.g., bifurcated), creation shall be prevented.\n*   **FR-MFM-CREATE-NO-TITLE-006:** The system shall not create a migration file if a title is not provided.\n\n**3.1.4 Migration Execution (`upgrade` and `downgrade` commands)**\n*   **FR-MEX-DB-CONNECT-001:** Before executing migrations, the system shall connect to the MongoDB database.\n*   **FR-MEX-LOAD-HISTORY-002:** The system shall load and parse all migration files from the configured directory to build an in-memory representation of the migration history.\n*   **FR-MEX-VALIDATE-HISTORY-003:** The system shall validate the loaded migration history before proceeding with upgrade or downgrade operations. Operations shall be prevented if the history is invalid.\n*   **FR-MEX-GET-DB-VERSION-004:** The system shall retrieve the current migration version from the version tracking collection in the database.\n*   **FR-MEX-UPGRADE-ALL-005:** The system shall be able to apply all pending migrations sequentially, from the one after the current DB version up to the latest available migration.\n*   **FR-MEX-UPGRADE-TO-VERSION-006:** The system shall be able to apply pending migrations sequentially up to a specified target version.\n*   **FR-MEX-UPGRADE-EXEC-007:** For each migration being applied, the system shall execute its `upgrade(db)` procedure, passing a database connection object.\n*   **FR-MEX-UPGRADE-UPDATE-DB-VER-008:** After successfully applying a migration, the system shall update the current DB version in the version tracking collection to the version of the migration just applied.\n*   **FR-MEX-UPGRADE-NO-PENDING-009:** If there are no pending migrations to apply (either database is up-to-date or target version is already met or passed), the system shall indicate this and take no action.\n*   **FR-MEX-DOWNGRADE-LAST-010:** The system shall be able to revert the last applied migration.\n*   **FR-MEX-DOWNGRADE-TO-VERSION-011:** The system shall be able to revert applied migrations sequentially in reverse order down to (but not including) a specified target version. The database state will reflect the successful application of the target version.\n*   **FR-MEX-DOWNGRADE-ALL-012:** The system shall be able to revert all applied migrations, effectively resetting the database to its state before any migrations were applied (current DB version becomes null/empty).\n*   **FR-MEX-DOWNGRADE-EXEC-013:** For each migration being reverted, the system shall execute its `downgrade(db)` procedure, passing a database connection object.\n*   **FR-MEX-DOWNGRADE-UPDATE-DB-VER-014:** After successfully reverting a migration, the system shall update the current DB version in the version tracking collection to the version of the migration that was its predecessor (or null/empty if the first migration is reverted).\n*   **FR-MEX-DOWNGRADE-NO-APPLIED-015:** If no migrations have been applied to the database (current DB version is null/empty), the system shall indicate this and take no downgrade action.\n*   **FR-MEX-UPGRADE-ERROR-HALT-016:** If an error occurs during the execution of an `upgrade` procedure for a migration, the system shall stop further upgrades and the database version shall remain at the last successfully applied migration version.\n*   **FR-MEX-DOWNGRADE-ERROR-HALT-017:** If an error occurs during the execution of a `downgrade` procedure for a migration, the system shall stop further downgrades and the database version shall remain at the version of the migration that failed to downgrade (i.e., its `upgrade` is still considered applied).\n*   **FR-MEX-UPGRADE-TARGET-NOT-PENDING-018:** The system shall not attempt to upgrade to a specified version if that version is not a pending migration (e.g., it's already applied or doesn't exist in the forward path).\n*   **FR-MEX-DOWNGRADE-TARGET-NOT-PARENT-019:** The system shall not attempt to downgrade to a specified version if that version is not a historical parent of the current version or the current version itself.\n\n**3.1.5 Migration History Management (`history` command and internal logic)**\n*   **FR-MH-LOAD-FILES-001:** The system shall load migration details by parsing all valid Python migration files found in the configured migrations directory.\n*   **FR-MH-PARSE-METADATA-002:** For each migration file, the system shall parse metadata including its title, unique version, and the version of its preceding migration.\n*   **FR-MH-LOAD-PROCEDURES-003:** For each migration file, the system shall dynamically load the `upgrade(db)` and `downgrade(db)` procedures defined within it.\n*   **FR-MH-BUILD-SEQUENCE-004:** The system shall construct an ordered, sequential representation of migrations based on their `version` and `last_version` metadata.\n*   **FR-MH-VALIDATE-LINEAR-005:** The system shall validate that the constructed migration history is linear:\n    1.  It must not be empty (if migrations exist).\n    2.  It must have exactly one initial migration (a migration with no `last_version` or whose `last_version` is None/null).\n    3.  Each migration must have at most one direct successor (no bifurcations/branches).\n*   **FR-MH-DISPLAY-HISTORY-006:** The system shall display the migration history to the console, showing each migration's version and title.\n*   **FR-MH-DISPLAY-STATUS-007:** The displayed history shall indicate the status of each migration relative to the current DB version:\n    *   **(APPLIED):** Migrations applied prior to the current DB version.\n    *   **(CURRENT):** The migration corresponding to the current DB version.\n    *   **(PENDING):** Migrations that exist in files but have not yet been applied.\n*   **FR-MH-DISPLAY-FORMAT-008:** The history display shall follow a specific tree-like format to indicate sequence and status.\n    *   Example format:\n        ```\n        [+] Migration history:\n        ├── (APPLIED) <version1> - <title1>\n        ├──>(CURRENT) <version2> - <title2>\n        └── (PENDING) <version3> - <title3>\n        ```\n*   **FR-MH-GET-SUBSEQUENCE-009:** The system shall be able to retrieve an ordered sub-sequence of migration objects from the history, optionally filtered by a starting version and/or an ending version.\n*   **FR-MH-GET-FIRST-LAST-010:** The system shall be able to identify the first (earliest) and last (latest) migration in a valid, linear history.\n\n**3.1.6 Command-Line Interface Operations**\n*   **FR-CLI-DISPATCH-001:** The system shall dispatch to the correct functionality (init, create, upgrade, downgrade, history) based on the subcommand provided on the command line.\n*   **FR-CLI-VERSION-DISPLAY-002:** The system shall display its version information when invoked with a specific version flag (e.g., `-v` or `--version`).\n*   **FR-CLI-HELP-DISPLAY-003:** The system shall display a help message describing its usage and available commands/options when invoked with a help flag (e.g., `-h` or `--help`), or when a command is invoked incorrectly.\n\n**3.1.7 General System Behavior**\n*   **FR-GEN-STATUS-MESSAGES-001:** The system shall provide informative status messages to the console during its operations (e.g., \"Initializing migrations...\", \"Migration file created at...\", \"Running migration...\", \"Connected to database.\").\n*   **FR-GEN-ERROR-MIG-DIR-NOT-FOUND-002:** For operations requiring the migrations directory (e.g., create, upgrade, downgrade, history), if the directory does not exist, the system shall report an error and suggest running the initialization command.\n*   **FR-GEN-ERROR-DB-CONNECT-FAIL-003:** The system shall report an error if it fails to connect to the MongoDB database after attempting connection.\n*   **FR-GEN-ERROR-HISTORY-LOAD-FAIL-004:** If the system encounters an error while loading or parsing migration history (e.g., invalid file format for a migration), it shall report an error.\n*   **FR-GEN-ERROR-HISTORY-INVALID-005:** If the loaded migration history is found to be invalid (e.g., not linear), the system shall report an error and prevent operations that depend on a valid history (e.g., create, upgrade, downgrade).\n\n**3.2 Non-Functional Requirements**\n*   **NFR-ROB-CONFIG-NOT-FOUND-001:** If the configuration file is not found at the expected location, the system shall print an error message indicating this and shall terminate with an exit code of 1.\n*   **NFR-ROB-CONFIG-SECTION-MISSING-002:** If the configuration file is found but is missing required sections (e.g., `[database]` or `[migrations]`), the system shall print an error message indicating the missing section and shall terminate with an exit code of 1.\n*   **NFR-USA-NO-SUBCOMMAND-003:** If the program is invoked without any subcommand, it shall print its help message to the console and terminate with an exit code of 1.\n\n**3.3 External Interface Requirements**\n\n**3.3.1 Configuration File Interface**\n*   **EIR-CONF-FILENAME-001:** The system shall expect the configuration file to be named `mongo-migrator.config` and located in the current working directory where the tool is executed.\n*   **EIR-CONF-FORMAT-002:** The configuration file shall be in INI format.\n*   **EIR-CONF-SECTION-DB-003:** The configuration file shall contain a section named `[database]`.\n*   **EIR-CONF-DB-PARAMS-004:** The `[database]` section shall support the following keys for MongoDB connection:\n    *   `host` (string, mandatory): MongoDB host address.\n    *   `port` (integer, mandatory): MongoDB port number.\n    *   `name` (string, mandatory): The database name where migrations will be applied and version history stored.\n    *   `user` (string, optional): Username for database authentication.\n    *   `password` (string, optional): Password for database authentication.\n*   **EIR-CONF-SECTION-MIG-005:** The configuration file shall contain a section named `[migrations]`.\n*   **EIR-CONF-MIG-PARAMS-006:** The `[migrations]` section shall support the following keys:\n    *   `directory` (string, mandatory): Directory where migration script files are stored.\n    *   `collection` (string, mandatory): Name of the MongoDB collection used to store migration version information.\n\n**3.3.2 Migration File Interface**\n*   **EIR-MF-FORMAT-001:** Migration files shall be Python scripts (`.py` extension).\n*   **EIR-MF-METADATA-BLOCK-002:** Each migration file shall begin with a multi-line string comment block containing metadata. This block must include lines formatted as:\n    *   `title: <Migration Title>`\n    *   `version: <Migration Version Timestamp>`\n    *   `last_version: <Previous Migration Version Timestamp or None>`\n*   **EIR-MF-UPGRADE-FUNC-003:** Each migration file shall define a Python function `upgrade(db)`.\n    *   The `db` parameter will be a Pymongo `Database` object connected to the target database.\n    *   This function contains the logic to apply the migration.\n*   **EIR-MF-DOWNGRADE-FUNC-004:** Each migration file shall define a Python function `downgrade(db)`.\n    *   The `db` parameter will be a Pymongo `Database` object connected to the target database.\n    *   This function contains the logic to revert the migration.\n\n**3.3.3 Command-Line Interface (CLI)**\n*   **EIR-CLI-PROGRAM-NAME-001:** The system shall be invokable as `mongo_migrator` (or `mongo-migrator` as per some test contexts and README, implies flexibility or an alias). For assessment, `mongo_migrator` will be the primary.\n*   **EIR-CLI-INIT-CMD-002:** The system shall support an `init` command.\n    *   `mongo_migrator init`\n    *   Purpose: Initializes the migration environment.\n*   **EIR-CLI-CREATE-CMD-003:** The system shall support a `create` command.\n    *   `mongo_migrator create \"<migration_title>\"`\n    *   Purpose: Creates a new migration file.\n    *   Arguments:\n        *   `title` (string, mandatory): The descriptive title for the migration.\n*   **EIR-CLI-UPGRADE-CMD-004:** The system shall support an `upgrade` command.\n    *   `mongo_migrator upgrade [--version <target_version>]`\n    *   Purpose: Applies pending migrations.\n    *   Options:\n        *   `--version <target_version>` (string, optional): If provided, upgrades to this specific version. If omitted (or implicitly with `--all`), upgrades to the latest available version. The original README implies `--all` is default, but tests for `upgrade_command` pass `args.all = True` or `args.all = False` depending on `args.version`. The argparse setup in `cli.py` has `default=True` for `--all` action and a separate `--version` option. For clarity: default is to upgrade all pending migrations. If `--version` is specified, it overrides \"all\" and targets a specific version. The `args.all` in tests might be a leftover from previous arg parsing. SRS will reflect the `cli.py` `argparse` setup where `--version` implies not `--all`.\n        *   Note: The CLI definition from source (`cli.py`) has an `--all` flag (default True) and a `--version` flag. If `--version` is specified, it implies targeting a specific version rather than all.\n*   **EIR-CLI-DOWNGRADE-CMD-005:** The system shall support a `downgrade` command.\n    *   `mongo_migrator downgrade [--version <target_version>] [--all]`\n    *   Purpose: Reverts applied migrations.\n    *   Options:\n        *   `--version <target_version>` (string, optional): If provided, downgrades until the state *after* `<target_version>` was applied is reached (i.e., `<target_version>` itself is not downgraded).\n        *   `--all` (boolean flag, optional): If provided, downgrades all applied migrations.\n        *   Default behavior (if no options): Downgrades the single last applied migration (equivalent to `--single` in source, which is default True).\n        *   Note: The `cli.py` `argparse` has `--single` (default True), `--all`, and `--version`. These options are mutually exclusive in effect.\n*   **EIR-CLI-HISTORY-CMD-006:** The system shall support a `history` command.\n    *   `mongo_migrator history`\n    *   Purpose: Displays the migration history.\n*   **EIR-CLI-VERSION-OPT-007:** The system shall support a version option.\n    *   `mongo_migrator -v` or `mongo_migrator --version`\n    *   Purpose: Displays the installed version of the Mongo Migrator tool.\n*   **EIR-CLI-HELP-OPT-008:** The system shall support a help option.\n    *   `mongo_migrator -h` or `mongo_migrator --help`\n    *   `mongo_migrator <command> -h` or `mongo_migrator <command> --help`\n    *   Purpose: Displays help information for the tool or a specific command.\n\n**3.4 Other Requirements (General Constraints)**\n*   **OCR-DB-COMPAT-001:** The system must be compatible with MongoDB version 4.0 and later.\n*   **OCR-PYTHON-ENV-002:** The system must operate within a Python 3 environment. (Specific version compatibility like 3.7+ is typical for such tools, but not explicitly stated beyond \"PyPI pyversions\" which suggests broad compatibility).\n*   **OCR-LINEAR-HISTORY-003:** The system is designed to work with a linear migration history. Bifurcated or broken sequences in migration files are considered an error state.\n\n---\nEnd of SRS Document.",
        "structured_requirements": [
            {
                "requirement_id": "FR-CONF-LOAD-001",
                "requirement_description": "The system shall load configuration settings from a designated configuration file.\nDetails: The configuration file specifies database connection parameters and migration management settings.",
                "test_traceability": [
                    {
                        "id": "tests/test_config.py::test_config_loads_ok",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/config.py::Config::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CONF-OPTIONAL-AUTH-002",
                "requirement_description": "Database username and password configuration parameters shall be optional. If not provided, the system should attempt to connect without authentication or assume authentication is handled by other means.",
                "test_traceability": [
                    {
                        "id": "tests/test_config.py::test_config_missing_options",
                        "description": ""
                    },
                    {
                        "id": "tests/test_config.py::test_config_user_pass_are_optional",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/config.py::Config::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-INIT-READ-CONFIG-001",
                "requirement_description": "The initialization process shall begin by reading system configuration.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_init (implicit)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::init",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-INIT-CREATE-MIG-DIR-002",
                "requirement_description": "The system shall create a directory for storing migration files, as specified in the configuration, if it does not already exist.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_init",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::init",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-INIT-DB-CONNECT-003",
                "requirement_description": "The system shall attempt to connect to the MongoDB database specified in the configuration.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_init (implicit via `get_db` mock)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::init (calls `get_db`)",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-INIT-CREATE-VER-COL-004",
                "requirement_description": "The system shall create a dedicated version tracking collection in the MongoDB database, as named in the configuration, if it does not already exist.",
                "test_traceability": [
                    {
                        "id": "tests/test_db.py::test_create_version_collection",
                        "description": ""
                    },
                    {
                        "id": "tests/test_commands.py::test_init",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/db_utils.py::create_version_collection",
                        "description": ""
                    },
                    {
                        "id": "src/mongo_migrator/cli.py::init",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-INIT-VER-COL-SCHEMA-005",
                "requirement_description": "If the version tracking collection is newly created, the system shall initialize it with a single document containing a field to store the current database migration version, initially set to a null or empty state.",
                "test_traceability": [
                    {
                        "id": "tests/test_db.py::test_create_version_collection",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/db_utils.py::create_version_collection",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-INIT-VER-COL-EXIST-006",
                "requirement_description": "If the version tracking collection already exists and contains data (e.g., a current version), its existing content related to the current version shall be preserved during initialization.",
                "test_traceability": [
                    {
                        "id": "tests/test_db.py::test_create_version_collection_already_exists_with_data",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/db_utils.py::create_version_collection",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MFM-CREATE-FILE-001",
                "requirement_description": "The system shall generate a new migration file in the configured migrations directory when requested with a title.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_create",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::create",
                        "description": ""
                    },
                    {
                        "id": "src/mongo_migrator/migration_template.py::MigrationTemplate::create_migration_file",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MFM-FILE-NAMING-002",
                "requirement_description": "The generated migration filename shall incorporate a unique, chronologically sortable timestamp (e.g., YYYYMMDDHHMMSSffffff) and a sanitized version of the provided migration title.\nExample: `20231026103000123456_added_new_field.py`",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_create (verified by checking file name structure)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::create",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MFM-FILE-CONTENT-003",
                "requirement_description": "The generated migration file shall contain predefined content including:\n1.  Metadata: migration title, its own generated version (timestamp), and the version of the immediately preceding migration (or a null/None indicator if it's the first migration).\n2.  Stub (template) Python functions for `upgrade(db)` and `downgrade(db)` operations.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_create (verified by `get_migration_params` utility)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/migration_template.py::MigrationTemplate::TEMPLATE",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MFM-LAST-VERSION-DET-004",
                "requirement_description": "When creating a new migration file, the system shall determine the version of the most recent existing migration to set as the `last_version` metadata in the new file. If no migrations exist, `last_version` shall indicate it's the first migration.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_create",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::create (uses `MigrationHistory.get_last_version`)",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MFM-CREATE-HIST-VALIDATE-005",
                "requirement_description": "The system shall validate the existing migration history before creating a new migration file. If the history is invalid (e.g., bifurcated), creation shall be prevented.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_create (tests scenario with invalid history)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::create (uses `MigrationHistory.validate`)",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MFM-CREATE-NO-TITLE-006",
                "requirement_description": "The system shall not create a migration file if a title is not provided.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_create",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::create",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MEX-DB-CONNECT-001",
                "requirement_description": "Before executing migrations, the system shall connect to the MongoDB database.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_upgrade",
                        "description": ""
                    },
                    {
                        "id": "tests/test_commands.py::test_downgrade (implicit)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::upgrade",
                        "description": ""
                    },
                    {
                        "id": "src/mongo_migrator/cli.py::downgrade",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MEX-LOAD-HISTORY-002",
                "requirement_description": "The system shall load and parse all migration files from the configured directory to build an in-memory representation of the migration history.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_upgrade",
                        "description": ""
                    },
                    {
                        "id": "tests/test_commands.py::test_downgrade",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::upgrade",
                        "description": ""
                    },
                    {
                        "id": "src/mongo_migrator/cli.py::downgrade (uses `MigrationHistory`)",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MEX-VALIDATE-HISTORY-003",
                "requirement_description": "The system shall validate the loaded migration history before proceeding with upgrade or downgrade operations. Operations shall be prevented if the history is invalid.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_upgrade",
                        "description": ""
                    },
                    {
                        "id": "tests/test_commands.py::test_downgrade",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::upgrade",
                        "description": ""
                    },
                    {
                        "id": "src/mongo_migrator/cli.py::downgrade (uses `MigrationHistory.validate`)",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MEX-GET-DB-VERSION-004",
                "requirement_description": "The system shall retrieve the current migration version from the version tracking collection in the database.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_upgrade",
                        "description": ""
                    },
                    {
                        "id": "tests/test_commands.py::test_downgrade (implicit)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/db_utils.py::get_current_version",
                        "description": ""
                    },
                    {
                        "id": "src/mongo_migrator/cli.py::upgrade",
                        "description": ""
                    },
                    {
                        "id": "src/mongo_migrator/cli.py::downgrade",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MEX-UPGRADE-ALL-005",
                "requirement_description": "The system shall be able to apply all pending migrations sequentially, from the one after the current DB version up to the latest available migration.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_upgrade (scenario with `args.all = True`)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::upgrade",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MEX-UPGRADE-TO-VERSION-006",
                "requirement_description": "The system shall be able to apply pending migrations sequentially up to a specified target version.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_upgrade (scenario with `args.version`)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::upgrade",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MEX-UPGRADE-EXEC-007",
                "requirement_description": "For each migration being applied, the system shall execute its `upgrade(db)` procedure, passing a database connection object.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_upgrade (verified by checking DB changes)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/migration_history.py::MigrationNode::upgrade",
                        "description": ""
                    },
                    {
                        "id": "src/mongo_migrator/cli.py::upgrade",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MEX-UPGRADE-UPDATE-DB-VER-008",
                "requirement_description": "After successfully applying a migration, the system shall update the current DB version in the version tracking collection to the version of the migration just applied.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_upgrade (verified by `get_current_db_version`)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/db_utils.py::set_current_version",
                        "description": ""
                    },
                    {
                        "id": "src/mongo_migrator/cli.py::upgrade",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MEX-UPGRADE-NO-PENDING-009",
                "requirement_description": "If there are no pending migrations to apply (either database is up-to-date or target version is already met or passed), the system shall indicate this and take no action.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_upgrade (multiple scenarios)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::upgrade",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MEX-DOWNGRADE-LAST-010",
                "requirement_description": "The system shall be able to revert the last applied migration.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_downgrade (scenario with `args.single = True`)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::downgrade",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MEX-DOWNGRADE-TO-VERSION-011",
                "requirement_description": "The system shall be able to revert applied migrations sequentially in reverse order down to (but not including) a specified target version. The database state will reflect the successful application of the target version.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_downgrade (scenario with `args.version`)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::downgrade",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MEX-DOWNGRADE-ALL-012",
                "requirement_description": "The system shall be able to revert all applied migrations, effectively resetting the database to its state before any migrations were applied (current DB version becomes null/empty).",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_downgrade (scenario with `args.all = True`)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::downgrade",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MEX-DOWNGRADE-EXEC-013",
                "requirement_description": "For each migration being reverted, the system shall execute its `downgrade(db)` procedure, passing a database connection object.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_downgrade (verified by checking DB changes)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/migration_history.py::MigrationNode::downgrade",
                        "description": ""
                    },
                    {
                        "id": "src/mongo_migrator/cli.py::downgrade",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MEX-DOWNGRADE-UPDATE-DB-VER-014",
                "requirement_description": "After successfully reverting a migration, the system shall update the current DB version in the version tracking collection to the version of the migration that was its predecessor (or null/empty if the first migration is reverted).",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_downgrade (verified by `get_current_db_version`)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/db_utils.py::set_current_version",
                        "description": ""
                    },
                    {
                        "id": "src/mongo_migrator/cli.py::downgrade",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MEX-DOWNGRADE-NO-APPLIED-015",
                "requirement_description": "If no migrations have been applied to the database (current DB version is null/empty), the system shall indicate this and take no downgrade action.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_downgrade",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::downgrade",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MEX-UPGRADE-ERROR-HALT-016",
                "requirement_description": "If an error occurs during the execution of an `upgrade` procedure for a migration, the system shall stop further upgrades and the database version shall remain at the last successfully applied migration version.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_upgrade (scenario with upgrade error)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::upgrade",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MEX-DOWNGRADE-ERROR-HALT-017",
                "requirement_description": "If an error occurs during the execution of a `downgrade` procedure for a migration, the system shall stop further downgrades and the database version shall remain at the version of the migration that failed to downgrade (i.e., its `upgrade` is still considered applied).",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_downgrade (scenario with downgrade error)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::downgrade",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MEX-UPGRADE-TARGET-NOT-PENDING-018",
                "requirement_description": "The system shall not attempt to upgrade to a specified version if that version is not a pending migration (e.g., it's already applied or doesn't exist in the forward path).",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_upgrade",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::upgrade",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MEX-DOWNGRADE-TARGET-NOT-PARENT-019",
                "requirement_description": "The system shall not attempt to downgrade to a specified version if that version is not a historical parent of the current version or the current version itself.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_downgrade",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::downgrade",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MH-LOAD-FILES-001",
                "requirement_description": "The system shall load migration details by parsing all valid Python migration files found in the configured migrations directory.",
                "test_traceability": [
                    {
                        "id": "tests/test_history.py::test_history_invalid_migration (implies loading for valid ones)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/migration_history.py::MigrationHistory::_load_migrations",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MH-PARSE-METADATA-002",
                "requirement_description": "For each migration file, the system shall parse metadata including its title, unique version, and the version of its preceding migration.",
                "test_traceability": [
                    {
                        "id": "tests/test_history.py::test_history_invalid_migration (tests invalid format)",
                        "description": ""
                    },
                    {
                        "id": "tests/test_commands.py::get_migration_params (utility used in tests relies on this)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/migration_history.py::MigrationNode::from_file",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MH-LOAD-PROCEDURES-003",
                "requirement_description": "For each migration file, the system shall dynamically load the `upgrade(db)` and `downgrade(db)` procedures defined within it.",
                "test_traceability": [
                    {
                        "id": "Implicitly tested by upgrade/downgrade command tests.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/migration_history.py::MigrationNode::from_file",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MH-BUILD-SEQUENCE-004",
                "requirement_description": "The system shall construct an ordered, sequential representation of migrations based on their `version` and `last_version` metadata.",
                "test_traceability": [
                    {
                        "id": "tests/test_history.py::test_validate_history",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/migration_history.py::MigrationHistory::_load_migrations",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MH-VALIDATE-LINEAR-005",
                "requirement_description": "The system shall validate that the constructed migration history is linear:\n1.  It must not be empty (if migrations exist).\n2.  It must have exactly one initial migration (a migration with no `last_version` or whose `last_version` is None/null).\n3.  Each migration must have at most one direct successor (no bifurcations/branches).",
                "test_traceability": [
                    {
                        "id": "tests/test_history.py::test_validate_history",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/migration_history.py::MigrationHistory::validate",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MH-DISPLAY-HISTORY-006",
                "requirement_description": "The system shall display the migration history to the console, showing each migration's version and title.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_history",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::history",
                        "description": ""
                    },
                    {
                        "id": "src/mongo_migrator/migration_history.py::MigrationHistory::print_history",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MH-DISPLAY-STATUS-007",
                "requirement_description": "The displayed history shall indicate the status of each migration relative to the current DB version:\n(APPLIED): Migrations applied prior to the current DB version.\n(CURRENT): The migration corresponding to the current DB version.\n(PENDING): Migrations that exist in files but have not yet been applied.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_history",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/migration_history.py::MigrationHistory::_print_linear_tree",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MH-DISPLAY-FORMAT-008",
                "requirement_description": "The history display shall follow a specific tree-like format to indicate sequence and status.\nExample format:\n```\n[+] Migration history:\n├── (APPLIED) <version1> - <title1>\n├──>(CURRENT) <version2> - <title2>\n└── (PENDING) <version3> - <title3>\n```",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_history",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/migration_history.py::MigrationHistory::_print_linear_tree",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MH-GET-SUBSEQUENCE-009",
                "requirement_description": "The system shall be able to retrieve an ordered sub-sequence of migration objects from the history, optionally filtered by a starting version and/or an ending version.",
                "test_traceability": [
                    {
                        "id": "tests/test_history.py::test_get_migrations",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/migration_history.py::MigrationHistory::get_migrations",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MH-GET-FIRST-LAST-010",
                "requirement_description": "The system shall be able to identify the first (earliest) and last (latest) migration in a valid, linear history.",
                "test_traceability": [
                    {
                        "id": "tests/test_history.py::test_get_first_version",
                        "description": ""
                    },
                    {
                        "id": "tests/test_history.py::test_get_first_node",
                        "description": ""
                    },
                    {
                        "id": "tests/test_history.py::test_get_last_version",
                        "description": ""
                    },
                    {
                        "id": "tests/test_history.py::test_get_last_node",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/migration_history.py::MigrationHistory::get_first_node",
                        "description": ""
                    },
                    {
                        "id": "src/mongo_migrator/migration_history.py::MigrationHistory::get_last_node",
                        "description": ""
                    },
                    {
                        "id": "get_first_version",
                        "description": ""
                    },
                    {
                        "id": "get_last_version",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-DISPATCH-001",
                "requirement_description": "The system shall dispatch to the correct functionality (init, create, upgrade, downgrade, history) based on the subcommand provided on the command line.",
                "test_traceability": [
                    {
                        "id": "tests/test_cli.py::test_init",
                        "description": ""
                    },
                    {
                        "id": "tests/test_cli.py::test_create",
                        "description": ""
                    },
                    {
                        "id": "tests/test_cli.py::test_upgrade",
                        "description": ""
                    },
                    {
                        "id": "tests/test_cli.py::test_downgrade",
                        "description": ""
                    },
                    {
                        "id": "tests/test_cli.py::test_history",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::main",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-VERSION-DISPLAY-002",
                "requirement_description": "The system shall display its version information when invoked with a specific version flag (e.g., `-v` or `--version`).",
                "test_traceability": [
                    {
                        "id": "Derived from `argparse` setup in `src/mongo_migrator/cli.py::main` and standard CLI expectations. No direct test for `mongo_migrator --version` output in provided tests, but `argparse` handles this.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::main (argparse setup)",
                        "description": ""
                    },
                    {
                        "id": "src/mongo_migrator/__init__.py::__version__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-HELP-DISPLAY-003",
                "requirement_description": "The system shall display a help message describing its usage and available commands/options when invoked with a help flag (e.g., `-h` or `--help`), or when a command is invoked incorrectly.",
                "test_traceability": [
                    {
                        "id": "tests/test_cli.py::test_no_subcommand (tests part of this for no subcommand)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::main (argparse setup)",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-STATUS-MESSAGES-001",
                "requirement_description": "The system shall provide informative status messages to the console during its operations (e.g., \"Initializing migrations...\", \"Migration file created at...\", \"Running migration...\", \"Connected to database.\").",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_history (checks specific output)",
                        "description": ""
                    },
                    {
                        "id": "other tests implicitly rely on console output for debugging/understanding. Output messages are present throughout `cli.py`.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py (various print statements)",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-ERROR-MIG-DIR-NOT-FOUND-002",
                "requirement_description": "For operations requiring the migrations directory (e.g., create, upgrade, downgrade, history), if the directory does not exist, the system shall report an error and suggest running the initialization command.",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_create (no mig dir)",
                        "description": ""
                    },
                    {
                        "id": "tests/test_commands.py::test_upgrade (no mig dir)",
                        "description": ""
                    },
                    {
                        "id": "tests/test_commands.py::test_downgrade (no mig dir)",
                        "description": ""
                    },
                    {
                        "id": "tests/test_commands.py::test_history (no mig dir)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py (checks in `create`, `upgrade`, `downgrade`, `history`)",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-ERROR-DB-CONNECT-FAIL-003",
                "requirement_description": "The system shall report an error if it fails to connect to the MongoDB database after attempting connection.",
                "test_traceability": [
                    {
                        "id": "tests/test_db.py::test_get_db_failure",
                        "description": ""
                    },
                    {
                        "id": "tests/test_commands.py::test_init (error on DB connection)",
                        "description": ""
                    },
                    {
                        "id": "tests/test_commands.py::test_upgrade (error on DB connection)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/db_utils.py::get_db",
                        "description": ""
                    },
                    {
                        "id": "src/mongo_migrator/cli.py (error handling for `get_db` calls)",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-ERROR-HISTORY-LOAD-FAIL-004",
                "requirement_description": "If the system encounters an error while loading or parsing migration history (e.g., invalid file format for a migration), it shall report an error.",
                "test_traceability": [
                    {
                        "id": "tests/test_history.py::test_history_invalid_migration",
                        "description": ""
                    },
                    {
                        "id": "tests/test_commands.py::test_create (error loading history)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py (error handling for `MigrationHistory` instantiation)",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-ERROR-HISTORY-INVALID-005",
                "requirement_description": "If the loaded migration history is found to be invalid (e.g., not linear), the system shall report an error and prevent operations that depend on a valid history (e.g., create, upgrade, downgrade).",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::test_create (invalid history)",
                        "description": ""
                    },
                    {
                        "id": "tests/test_commands.py::test_upgrade (invalid history)",
                        "description": ""
                    },
                    {
                        "id": "tests/test_commands.py::test_downgrade (invalid history)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py (calls `MigrationHistory.validate`)",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "NFR-ROB-CONFIG-NOT-FOUND-001",
                "requirement_description": "If the configuration file is not found at the expected location, the system shall print an error message indicating this and shall terminate with an exit code of 1.",
                "test_traceability": [
                    {
                        "id": "tests/test_config.py::test_config_not_found",
                        "description": ""
                    }
                ],
                "code_traceability": []
            },
            {
                "requirement_id": "NFR-ROB-CONFIG-SECTION-MISSING-002",
                "requirement_description": "If the configuration file is found but is missing required sections (e.g., `[database]` or `[migrations]`), the system shall print an error message indicating the missing section and shall terminate with an exit code of 1.",
                "test_traceability": [
                    {
                        "id": "tests/test_config.py::test_config_missing_sections",
                        "description": ""
                    }
                ],
                "code_traceability": []
            },
            {
                "requirement_id": "NFR-USA-NO-SUBCOMMAND-003",
                "requirement_description": "If the program is invoked without any subcommand, it shall print its help message to the console and terminate with an exit code of 1.",
                "test_traceability": [
                    {
                        "id": "tests/test_cli.py::test_no_subcommand",
                        "description": ""
                    }
                ],
                "code_traceability": []
            },
            {
                "requirement_id": "EIR-CONF-FILENAME-001",
                "requirement_description": "The system shall expect the configuration file to be named `mongo-migrator.config` and located in the current working directory where the tool is executed.",
                "test_traceability": [
                    {
                        "id": "tests/test_config.py (uses `CONFIG_FILE = \"mongo-migrator.config.test\"` and patches `Config.CONFIG_FILE`)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/config.py::Config::CONFIG_FILE",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-CONF-FORMAT-002",
                "requirement_description": "The configuration file shall be in INI format.",
                "test_traceability": [
                    {
                        "id": "tests/test_config.py::create_config_file (writes INI format)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/config.py (uses `configparser`)",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-CONF-SECTION-DB-003",
                "requirement_description": "The configuration file shall contain a section named `[database]`.",
                "test_traceability": [
                    {
                        "id": "tests/test_config.py::test_config_loads_ok",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/config.py::Config::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-CONF-DB-PARAMS-004",
                "requirement_description": "The `[database]` section shall support the following keys for MongoDB connection:\n`host` (string, mandatory): MongoDB host address.\n`port` (integer, mandatory): MongoDB port number.\n`name` (string, mandatory): The database name where migrations will be applied and version history stored.\n`user` (string, optional): Username for database authentication.\n`password` (string, optional): Password for database authentication.",
                "test_traceability": [
                    {
                        "id": "tests/test_config.py::test_config_loads_ok",
                        "description": ""
                    },
                    {
                        "id": "tests/test_config.py::test_config_user_pass_are_optional",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/config.py::Config::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-CONF-SECTION-MIG-005",
                "requirement_description": "The configuration file shall contain a section named `[migrations]`.",
                "test_traceability": [
                    {
                        "id": "tests/test_config.py::test_config_loads_ok",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/config.py::Config::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-CONF-MIG-PARAMS-006",
                "requirement_description": "The `[migrations]` section shall support the following keys:\n`directory` (string, mandatory): Directory where migration script files are stored.\n`collection` (string, mandatory): Name of the MongoDB collection used to store migration version information.",
                "test_traceability": [
                    {
                        "id": "tests/test_config.py::test_config_loads_ok",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/config.py::Config::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-MF-FORMAT-001",
                "requirement_description": "Migration files shall be Python scripts (`.py` extension).",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py (creates and uses `.py` files)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::create (generates `.py`)",
                        "description": ""
                    },
                    {
                        "id": "src/mongo_migrator/migration_history.py (loads `.py`)",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-MF-METADATA-BLOCK-002",
                "requirement_description": "Each migration file shall begin with a multi-line string comment block containing metadata. This block must include lines formatted as:\n`title: <Migration Title>`\n`version: <Migration Version Timestamp>`\n`last_version: <Previous Migration Version Timestamp or None>`",
                "test_traceability": [
                    {
                        "id": "tests/test_commands.py::get_migration_params (utility relies on this format)",
                        "description": ""
                    },
                    {
                        "id": "tests/test_history.py::test_history_invalid_migration",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/migration_history.py::MigrationNode::from_file (parsing logic)",
                        "description": ""
                    },
                    {
                        "id": "src/mongo_migrator/migration_template.py::MigrationTemplate::TEMPLATE (generation)",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-MF-UPGRADE-FUNC-003",
                "requirement_description": "Each migration file shall define a Python function `upgrade(db)`.\nThe `db` parameter will be a Pymongo `Database` object connected to the target database.\nThis function contains the logic to apply the migration.",
                "test_traceability": [
                    {
                        "id": "Implicitly tested by `tests/test_commands.py::test_upgrade` when mock migrations are run.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/migration_history.py::MigrationNode::from_file (loads `upgrade`)",
                        "description": ""
                    },
                    {
                        "id": "src/mongo_migrator/migration_template.py::MigrationTemplate::TEMPLATE",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-MF-DOWNGRADE-FUNC-004",
                "requirement_description": "Each migration file shall define a Python function `downgrade(db)`.\nThe `db` parameter will be a Pymongo `Database` object connected to the target database.\nThis function contains the logic to revert the migration.",
                "test_traceability": [
                    {
                        "id": "Implicitly tested by `tests/test_commands.py::test_downgrade` when mock migrations are run.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/migration_history.py::MigrationNode::from_file (loads `downgrade`)",
                        "description": ""
                    },
                    {
                        "id": "src/mongo_migrator/migration_template.py::MigrationTemplate::TEMPLATE",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-CLI-PROGRAM-NAME-001",
                "requirement_description": "The system shall be invokable as `mongo_migrator` (or `mongo-migrator` as per some test contexts and README, implies flexibility or an alias). For assessment, `mongo_migrator` will be the primary.",
                "test_traceability": [
                    {
                        "id": "tests/test_cli.py (uses `mongo_migrator` or `mongo-migrator` in `test_args`)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py (argparse `prog` name usually derived from script name)",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-CLI-INIT-CMD-002",
                "requirement_description": "The system shall support an `init` command.\n`mongo_migrator init`\nPurpose: Initializes the migration environment.",
                "test_traceability": [
                    {
                        "id": "tests/test_cli.py::test_init",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::init",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-CLI-CREATE-CMD-003",
                "requirement_description": "The system shall support a `create` command.\n`mongo_migrator create \"<migration_title>\"`\nPurpose: Creates a new migration file.\nArguments:\n`title` (string, mandatory): The descriptive title for the migration.",
                "test_traceability": [
                    {
                        "id": "tests/test_cli.py::test_create",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::create",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-CLI-UPGRADE-CMD-004",
                "requirement_description": "The system shall support an `upgrade` command.\n`mongo_migrator upgrade [--version <target_version>]`\nPurpose: Applies pending migrations.\nOptions:\n`--version <target_version>` (string, optional): If provided, upgrades to this specific version. If omitted (or implicitly with `--all`), upgrades to the latest available version. The original README implies `--all` is default, but tests for `upgrade_command` pass `args.all = True` or `args.all = False` depending on `args.version`. The argparse setup in `cli.py` has `default=True` for `--all` action and a separate `--version` option. For clarity: default is to upgrade all pending migrations. If `--version` is specified, it overrides \"all\" and targets a specific version. The `args.all` in tests might be a leftover from previous arg parsing. SRS will reflect the `cli.py` `argparse` setup where `--version` implies not `--all`.\nNote: The CLI definition from source (`cli.py`) has an `--all` flag (default True) and a `--version` flag. If `--version` is specified, it implies targeting a specific version rather than all.",
                "test_traceability": [
                    {
                        "id": "tests/test_cli.py::test_upgrade",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::upgrade",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-CLI-DOWNGRADE-CMD-005",
                "requirement_description": "The system shall support a `downgrade` command.\n`mongo_migrator downgrade [--version <target_version>] [--all]`\nPurpose: Reverts applied migrations.\nOptions:\n`--version <target_version>` (string, optional): If provided, downgrades until the state *after* `<target_version>` was applied is reached (i.e., `<target_version>` itself is not downgraded).\n`--all` (boolean flag, optional): If provided, downgrades all applied migrations.\nDefault behavior (if no options): Downgrades the single last applied migration (equivalent to `--single` in source, which is default True).\nNote: The `cli.py` `argparse` has `--single` (default True), `--all`, and `--version`. These options are mutually exclusive in effect.",
                "test_traceability": [
                    {
                        "id": "tests/test_cli.py::test_downgrade",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::downgrade",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-CLI-HISTORY-CMD-006",
                "requirement_description": "The system shall support a `history` command.\n`mongo_migrator history`\nPurpose: Displays the migration history.",
                "test_traceability": [
                    {
                        "id": "tests/test_cli.py::test_history",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::history",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-CLI-VERSION-OPT-007",
                "requirement_description": "The system shall support a version option.\n`mongo_migrator -v` or `mongo_migrator --version`\nPurpose: Displays the installed version of the Mongo Migrator tool.",
                "test_traceability": [
                    {
                        "id": "Derived from `argparse` setup in `src/mongo_migrator/cli.py::main`.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::main",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-CLI-HELP-OPT-008",
                "requirement_description": "The system shall support a help option.\n`mongo_migrator -h` or `mongo_migrator --help`\n`mongo_migrator <command> -h` or `mongo_migrator <command> --help`\nPurpose: Displays help information for the tool or a specific command.",
                "test_traceability": [
                    {
                        "id": "tests/test_cli.py::test_no_subcommand (shows help for base command)",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/cli.py::main",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "OCR-DB-COMPAT-001",
                "requirement_description": "The system must be compatible with MongoDB version 4.0 and later.",
                "test_traceability": [
                    {
                        "id": "README states \"MongoDB-%3E%3D4.0\". No direct test case verifies this. Assumed constraint.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "N/A (external system dependency)",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "OCR-PYTHON-ENV-002",
                "requirement_description": "The system must operate within a Python 3 environment. (Specific version compatibility like 3.7+ is typical for such tools, but not explicitly stated beyond \"PyPI pyversions\" which suggests broad compatibility).",
                "test_traceability": [
                    {
                        "id": "Project structure and `setup.py` (if existed) or `pyproject.toml` would typically specify this. README badge `![Python Versions](https://img.shields.io/pypi/pyversions/mongo-migrator)` implies multiple Python 3 versions.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "N/A (environment constraint)",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "OCR-LINEAR-HISTORY-003",
                "requirement_description": "The system is designed to work with a linear migration history. Bifurcated or broken sequences in migration files are considered an error state.",
                "test_traceability": [
                    {
                        "id": "tests/test_history.py::test_validate_history",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/mongo_migrator/migration_history.py::MigrationHistory::validate",
                        "description": ""
                    }
                ]
            }
        ],
        "full_code_skeleton": "--- File: src/mongo_migrator/migration_history.py ---\n```python\n\"\"\"\nThis module handles the history of migrations. It detects bifurcations.\nAlso comes with functionality to validate the tree.\n\"\"\"\nfrom typing import Dict, List\n\n\nclass MigrationNode:\n    \"\"\"\n    Represents a migration node in the migration history tree.\n    \"\"\"\n\n    def __init__(\n        self,\n        title: str,\n        version: str,\n        last_version: str = None,\n        upgrade: str = None,\n        downgrade: str = None,\n    ):\n        \"\"\"\n        Create a new migration node.\n        Args:\n            title: The title of the migration.\n            version: The version of the migration.\n            last_version: The last version of the migration. None if it is the first migration.\n            upgrade: The upgrade function of the migration.\n            downgrade: The downgrade function of the migration.\n        \"\"\"\n        pass\n\n    def add_child(self, child_node: \"MigrationNode\"):\n        \"\"\"\n        Add a child node to the current node.\n        Args:\n            child_node: The child node to add.\n        \"\"\"\n        pass\n\n    def upgrade(self, db):\n        \"\"\"\n        Apply the upgrade function of the migration.\n        Args:\n            db: The database to upgrade.\n        \"\"\"\n        pass\n\n    def downgrade(self, db):\n        \"\"\"\n        Apply the downgrade function of the migration.\n        Args:\n            db: The database to downgrade.\n        \"\"\"\n        pass\n\n    @classmethod\n    def from_file(cls, file_path: str) -> \"MigrationNode\":\n        \"\"\"\n        Parse a migration file and return the migration node.\n        Args:\n            file_path: The path to the migration file.\n        Raises:\n            FileNotFoundError: If the file is not found.\n            ValueError: If the file format is invalid.\n        Returns:\n            The migration node parsed from the file.\n        \"\"\"\n        pass\n\n    def __repr__(self):\n        pass\n\n    def __str__(self):\n        pass\n\n\nclass MigrationHistory:\n\n    def __init__(self, migrations_dir: str):\n        \"\"\"\n        Class for managing the migration history.\n        Args:\n            migrations_dir: The directory where the migrations are stored.\n        Attributes:\n            migrations_dir: The directory where the migrations are stored.\n            roots: The root nodes of the migration history.\n            migrations: A dictionary of all migrations by version.\n        Raises:\n            FileNotFoundError: If a migration file is not found.\n            ValueError: If a migration file format is invalid.\n        \"\"\"\n        pass\n\n    def _load_migrations(self):\n        \"\"\"\n        Private method to load all migrations from the migrations directory.\n        Migrations without a last version or without a found last_version are considered as roots.\n\n        Raises:\n            FileNotFoundError: If a migration file is not found.\n            ValueError: If a migration file format is invalid.\n        \"\"\"\n        pass\n\n    def is_empty(self) -> bool:\n        \"\"\"\n        Check if the migration history is empty.\n        Returns:\n            True if the history is empty, False otherwise.\n        \"\"\"\n        pass\n\n    def validate(self, node: MigrationNode = None) -> bool:\n        \"\"\"\n        Check the migration history for bifurcations.\n        The history is valid if it is a non empty linear tree.\n        Args:\n            node: The node to start the check. If None, the check starts from the root.\n        Returns:\n            True if the history is valid, False otherwise.\n        \"\"\"\n        pass\n\n    def get_first_version(self) -> str:\n        \"\"\"\n        Get the first version of the migration history.\n        Assumes that the migration history is valid.\n        Returns:\n            The first version of the migration history.\n        \"\"\"\n        pass\n\n    def get_first_node(self) -> MigrationNode:\n        \"\"\"\n        Get the first node of the migration history.\n        Assumes that the migration history is valid.\n        Returns:\n            The first node of the migration history.\n        \"\"\"\n        pass\n\n    def get_last_version(self) -> str:\n        \"\"\"\n        Get the last version of the migration history.\n        Assumes that the migration history is valid.\n        Returns:\n            The last version of the migration history.\n        \"\"\"\n        pass\n\n    def get_last_node(self) -> MigrationNode:\n        \"\"\"\n        Get the last node of the migration history.\n        Assumes that the migration history is valid.\n        Returns:\n            The last node of the migration history.\n        \"\"\"\n        pass\n\n    def _print_linear_tree(\n        self,\n        node: MigrationNode,\n        current_version: str = None,\n        current_found: bool = False,\n        is_applied: bool = True,\n    ):\n        \"\"\"\n        Print a linear tree of the migration history.\n        Args:\n            node: The node to print.\n            level: The level of the node in the tree.\n        \"\"\"\n        pass\n\n    def print_history(self, current_version: str = None):\n        \"\"\"\n        Prints the history of migrations from oldest to newest.\n        Args:\n            current_version: The current version of the database.\n        Raises:\n            ValueError: If the history is invalid.\n        \"\"\"\n        pass\n\n    def get_migrations(\n        self, start_version: str = None, to_version: str = None\n    ) -> List[MigrationNode]:\n        \"\"\"\n        Get a list of migrations.\n        Assumes that the migration history is valid.\n        Args:\n            start_version: The version to start from. If None, the first version is used.\n            to_version: The last version of the migration list. If None, the last version is used.\n        Returns:\n            A list of migrations.\n        \"\"\"\n        pass\n```\n--- File: src/mongo_migrator/migration_template.py ---\n```python\n\"\"\"\nThis class handles the creation of migration files.\n\nThe create_migration_file method creates a new migration file with a template.\nThis template includes the title, version, and current version of the migration.\n\"\"\"\n\n\nclass MigrationTemplate:\n\n    @classmethod\n    def create_migration_file(\n        cls, file_path: str, title: str, version: int, last_version: int\n    ):\n        \"\"\"\n        Create a new migration file.\n        Args:\n            file_path: The path to the new migration file.\n            title: The title of the migration.\n            version: The version of the migration.\n            last_version: The oldest version of the migrations.\n        \"\"\"\n        pass\n```\n--- File: src/mongo_migrator/db_utils.py ---\n```python\n\"\"\"Module for database operations.\"\"\"\nfrom pymongo.database import Database\n\n\ndef get_db(\n    db_host: str,\n    db_port: int,\n    db_name: str,\n    db_user: str = None,\n    db_pass: str = None,\n    verbose: bool = False,\n    max_retries: int = 3,\n) -> Database:\n    \"\"\"\n    Get the database connection using pymongo.\n    Args:\n        db_host: The hostname of the MongoDB server.\n        db_port: The port number of the MongoDB server.\n        db_name: The name of the database.\n        db_user: The username for the database if needed.\n        db_pass: The password for the database if needed.\n        verbose: Whether to print messages.\n        max_retries: The number of times to retry connecting to the database.\n    Raises:\n        Exception: If the connection cannot be established.\n    Returns:\n        The database connection.\n    \"\"\"\n    pass\n\n\ndef create_version_collection(db: Database, collection_name: str) -> None:\n    \"\"\"\n    Create the version collection in the database.\n    Args:\n        db: The database connection.\n        collection_name: The name of the collection.\n    \"\"\"\n    pass\n\n\ndef set_current_version(db: Database, collection_name: str, version: str) -> None:\n    \"\"\"\n    Set the current version.\n    Args:\n        db: The database connection.\n        collection_name: The name of the version collection.\n        version: The current version.\n    \"\"\"\n    pass\n\n\ndef get_current_version(db: Database, collection_name: str) -> str:\n    \"\"\"\n    Get the current version.\n    Args:\n        db: The database connection.\n        collection_name: The name of the version collection.\n    Returns:\n        The current version.\n    \"\"\"\n    pass\n```\n--- File: src/mongo_migrator/config.py ---\n```python\n\"\"\"\nContains the utility to manage the configuration file.\n\nUsage:\n```\nfrom config import Config\nconfig = Config() # Loads the configuration\nprint(config.db_host) # Access the database host\nprint(config.db_port) # Access the database port\n...\n```\n\nAvailable variables in the Config class implementation\n\"\"\"\n\n\nclass Config:\n    \"\"\"Class to handle the configuration file\"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initialize the Config class.\n\n        Description:\n            Loads the configuration file and provides access to the configuration values.\n            This file must be named after CONFIG_FILE attribute.\n            It also must be placed in the same directory where mongo-migrator is going to be used.\n\n        Exit cases:\n            If the configuration file is not found, the program will exit.\n            If any of the required sections are missing, the program will exit.\n        \"\"\"\n        pass\n```\n--- File: src/mongo_migrator/cli.py ---\n```python\n\"\"\"\nCommand line interface for the mongo migrator\n\"\"\"\n\n\ndef init(args):\n    \"\"\"\n    Needs a config file named 'mongo-migrator.config' in the current directory.\n    Will create a migrations directory and a migration collection in the database.\n    \"\"\"\n    pass\n\n\ndef create(args):\n    \"\"\"\n    Creates a new migration file in the migration directory.\n    \"\"\"\n    pass\n\n\ndef upgrade(args):\n    \"\"\"\n    Upgrades the database to the latest version by default.\n    \"\"\"\n    pass\n\n\ndef downgrade(args):\n    \"\"\"\n    Downgrades the database to the previous version by default.\n    \"\"\"\n    pass\n\n\ndef history(args):\n    \"\"\"Shows the migration history.\"\"\"\n    pass\n\n\ndef main():\n    pass\n```",
        "minimal_code_skeleton": "--- File: mongo_migrator/config.py ---\n```python\nclass Config:\n    \"\"\"Class to handle the configuration file\"\"\"\n\n    CONFIG_FILE = \"mongo-migrator.config\"\n\n    def __init__(self):\n        \"\"\"\n        Initialize the Config class.\n\n        Description:\n            Loads the configuration file and provides access to the configuration values.\n            This file must be named after CONFIG_FILE attribute.\n            It also must be placed in the same directory where mongo-migrator is going to be used.\n\n        Exit cases:\n            If the configuration file is not found, the program will exit.\n            If any of the required sections are missing, the program will exit.\n        \"\"\"\n        pass\n```\n--- File: mongo_migrator/db_utils.py ---\n```python\ndef get_db(\n    db_host: str,\n    db_port: int,\n    db_name: str,\n    db_user: str = None,\n    db_pass: str = None,\n    verbose: bool = False,\n    max_retries: int = 3,\n) -> Database:\n    \"\"\"\n    Get the database connection using pymongo.\n    Args:\n        db_host: The hostname of the MongoDB server.\n        db_port: The port number of the MongoDB server.\n        db_name: The name of the database.\n        db_user: The username for the database if needed.\n        db_pass: The password for the database if needed.\n        verbose: Whether to print messages.\n        max_retries: The number of times to retry connecting to the database.\n    Raises:\n        Exception: If the connection cannot be established.\n    Returns:\n        The database connection.\n    \"\"\"\n    pass\n\ndef create_version_collection(db: Database, collection_name: str) -> None:\n    \"\"\"\n    Create the version collection in the database.\n    Args:\n        db: The database connection.\n        collection_name: The name of the collection.\n    \"\"\"\n    pass\n\ndef set_current_version(db: Database, collection_name: str, version: str) -> None:\n    \"\"\"\n    Set the current version.\n    Args:\n        db: The database connection.\n        collection_name: The name of the version collection.\n        version: The current version.\n    \"\"\"\n    pass\n```\n--- File: mongo_migrator/migration_history.py ---\n```python\nclass MigrationNode:\n    \"\"\"\n    Represents a migration node in the migration history tree.\n    \"\"\"\n\n    def __init__(\n        self,\n        title: str,\n        version: str,\n        last_version: str = None,\n        upgrade: str = None,\n        downgrade: str = None,\n    ):\n        \"\"\"\n        Create a new migration node.\n        Args:\n            title: The title of the migration.\n            version: The version of the migration.\n            last_version: The last version of the migration. None if it is the first migration.\n            upgrade: The upgrade function of the migration.\n            downgrade: The downgrade function of the migration.\n        \"\"\"\n        pass\n\n    def add_child(self, child_node: \"MigrationNode\"):\n        \"\"\"\n        Add a child node to the current node.\n        Args:\n            child_node: The child node to add.\n        \"\"\"\n        pass\n\n    def upgrade(self, db):\n        \"\"\"\n        Apply the upgrade function of the migration.\n        Args:\n            db: The database to upgrade.\n        \"\"\"\n        pass\n\n    def downgrade(self, db):\n        \"\"\"\n        Apply the downgrade function of the migration.\n        Args:\n            db: The database to downgrade.\n        \"\"\"\n        pass\n\n    def __repr__(self):\n        pass\n\nclass MigrationHistory:\n\n    def __init__(self, migrations_dir: str):\n        \"\"\"\n        Class for managing the migration history.\n        Args:\n            migrations_dir: The directory where the migrations are stored.\n        Attributes:\n            migrations_dir: The directory where the migrations are stored.\n            roots: The root nodes of the migration history.\n            migrations: A dictionary of all migrations by version.\n        Raises:\n            FileNotFoundError: If a migration file is not found.\n            ValueError: If a migration file format is invalid.\n        \"\"\"\n        pass\n\n    def is_empty(self) -> bool:\n        \"\"\"\n        Check if the migration history is empty.\n        Returns:\n            True if the history is empty, False otherwise.\n        \"\"\"\n        pass\n\n    def validate(self, node: MigrationNode = None) -> bool:\n        \"\"\"\n        Check the migration history for bifurcations.\n        The history is valid if it is a non empty linear tree.\n        Args:\n            node: The node to start the check. If None, the check starts from the root.\n        Returns:\n            True if the history is valid, False otherwise.\n        \"\"\"\n        pass\n\n    def get_first_version(self) -> str:\n        \"\"\"\n        Get the first version of the migration history.\n        Assumes that the migration history is valid.\n        Returns:\n            The first version of the migration history.\n        \"\"\"\n        pass\n\n    def get_first_node(self) -> MigrationNode:\n        \"\"\"\n        Get the first node of the migration history.\n        Assumes that the migration history is valid.\n        Returns:\n            The first node of the migration history.\n        \"\"\"\n        pass\n\n    def get_last_version(self) -> str:\n        \"\"\"\n        Get the last version of the migration history.\n        Assumes that the migration history is valid.\n        Returns:\n            The last version of the migration history.\n        \"\"\"\n        pass\n\n    def get_last_node(self) -> MigrationNode:\n        \"\"\"\n        Get the last node of the migration history.\n        Assumes that the migration history is valid.\n        Returns:\n            The last node of the migration history.\n        \"\"\"\n        pass\n\n    def get_migrations(\n        self, start_version: str = None, to_version: str = None\n    ) -> List[MigrationNode]:\n        \"\"\"\n        Get a list of migrations.\n        Assumes that the migration history is valid.\n        Args:\n            start_version: The version to start from. If None, the first version is used.\n            to_version: The last version of the migration list. If None, the last version is used.\n        Returns:\n            A list of migrations.\n        \"\"\"\n        pass\n```\n--- File: mongo_migrator/cli.py ---\n```python\ndef init(args):\n    \"\"\"\n    Needs a config file named 'mongo-migrator.config' in the current directory.\n    Will create a migrations directory and a migration collection in the database.\n    \"\"\"\n    pass\n\ndef create(args):\n    \"\"\"\n    Creates a new migration file in the migration directory.\n    \"\"\"\n    pass\n\ndef upgrade(args):\n    \"\"\"\n    Upgrades the database to the latest version by default.\n    \"\"\"\n    pass\n\ndef downgrade(args):\n    \"\"\"\n    Downgrades the database to the previous version by default.\n    \"\"\"\n    pass\n\ndef history(args):\n    \"\"\"Shows the migration history.\"\"\"\n    pass\n\ndef main():\n    pass\n```",
        "minimal_test_cases": [
            {
                "test_id": "tests/test_commands.py::test_init",
                "covers": [
                    "mongo_migrator.cli.init - happy path initialization (creates migration directory and DB collection)"
                ]
            },
            {
                "test_id": "tests/test_commands.py::test_create",
                "covers": [
                    "mongo_migrator.cli.create - happy path new migration file creation",
                    "mongo_migrator.migration_template.MigrationTemplate.create_migration_file - usage during cli.create",
                    "mongo_migrator.migration_history.MigrationNode.from_file - loading existing migration by MigrationHistory during subsequent cli.create"
                ]
            },
            {
                "test_id": "tests/test_commands.py::test_upgrade",
                "covers": [
                    "mongo_migrator.cli.upgrade - happy path database upgrade",
                    "mongo_migrator.db_utils.get_current_version - checking current version during cli.upgrade",
                    "mongo_migrator.migration_history.MigrationNode.upgrade - execution during cli.upgrade",
                    "mongo_migrator.migration_history.MigrationNode.__str__ - string representation for logging during cli.upgrade"
                ]
            },
            {
                "test_id": "tests/test_commands.py::test_downgrade",
                "covers": [
                    "mongo_migrator.cli.downgrade - happy path database downgrade",
                    "mongo_migrator.migration_history.MigrationNode.downgrade - execution during cli.downgrade"
                ]
            },
            {
                "test_id": "tests/test_commands.py::test_history",
                "covers": [
                    "mongo_migrator.cli.history - happy path display migration history",
                    "mongo_migrator.migration_history.MigrationHistory.print_history - usage during cli.history"
                ]
            },
            {
                "test_id": "tests/test_cli.py::test_no_subcommand",
                "covers": [
                    "mongo_migrator.cli.main - handles no subcommand (prints help and exits)"
                ]
            },
            {
                "test_id": "tests/test_config.py::test_config_loads_ok",
                "covers": [
                    "mongo_migrator.config.Config.__init__ - happy path loading valid configuration file with all options"
                ]
            },
            {
                "test_id": "tests/test_db.py::test_get_db_success",
                "covers": [
                    "mongo_migrator.db_utils.get_db - successful database connection"
                ]
            },
            {
                "test_id": "tests/test_db.py::test_create_version_collection",
                "covers": [
                    "mongo_migrator.db_utils.create_version_collection - creating new version collection when it doesn't exist"
                ]
            },
            {
                "test_id": "tests/test_db.py::test_set_current_version",
                "covers": [
                    "mongo_migrator.db_utils.set_current_version - setting current migration version in DB"
                ]
            },
            {
                "test_id": "tests/test_history.py::test_migration_node_representation",
                "covers": [
                    "mongo_migrator.migration_history.MigrationNode.__init__ - basic instantiation for representation",
                    "mongo_migrator.migration_history.MigrationNode.__repr__ - verifying string representation of MigrationNode"
                ]
            },
            {
                "test_id": "tests/test_history.py::test_validate_history",
                "covers": [
                    "mongo_migrator.migration_history.MigrationHistory.validate - validation of various migration history tree structures",
                    "mongo_migrator.migration_history.MigrationNode.add_child - adding child node to build migration tree for validation scenarios"
                ]
            },
            {
                "test_id": "tests/test_history.py::test_is_empty_history",
                "covers": [
                    "mongo_migrator.migration_history.MigrationHistory.__init__ - instantiation for empty/non-empty check scenarios",
                    "mongo_migrator.migration_history.MigrationHistory.is_empty - checking if migration history is empty or not"
                ]
            },
            {
                "test_id": "tests/test_history.py::test_get_first_version",
                "covers": [
                    "mongo_migrator.migration_history.MigrationHistory.get_first_version - retrieving the first migration version from history"
                ]
            },
            {
                "test_id": "tests/test_history.py::test_get_first_node",
                "covers": [
                    "mongo_migrator.migration_history.MigrationHistory.get_first_node - retrieving the first migration node from history"
                ]
            },
            {
                "test_id": "tests/test_history.py::test_get_last_version",
                "covers": [
                    "mongo_migrator.migration_history.MigrationHistory.get_last_version - retrieving the last migration version from history"
                ]
            },
            {
                "test_id": "tests/test_history.py::test_get_last_node",
                "covers": [
                    "mongo_migrator.migration_history.MigrationHistory.get_last_node - retrieving the last migration node from history"
                ]
            },
            {
                "test_id": "tests/test_history.py::test_get_migrations",
                "covers": [
                    "mongo_migrator.migration_history.MigrationHistory.get_migrations - retrieving list of migrations (including all, ranged)"
                ]
            }
        ],
        "commit_sha": "cf86b5e463b1295cbb3b0c54309e20afd67d8512",
        "full_code_skeleton_structured": [
            {
                "file_path": "src/mongo_migrator/migration_history.py",
                "code": "\"\"\"\nThis module handles the history of migrations. It detects bifurcations.\nAlso comes with functionality to validate the tree.\n\"\"\"\nfrom typing import Dict, List\n\n\nclass MigrationNode:\n    \"\"\"\n    Represents a migration node in the migration history tree.\n    \"\"\"\n\n    def __init__(\n        self,\n        title: str,\n        version: str,\n        last_version: str = None,\n        upgrade: str = None,\n        downgrade: str = None,\n    ):\n        \"\"\"\n        Create a new migration node.\n        Args:\n            title: The title of the migration.\n            version: The version of the migration.\n            last_version: The last version of the migration. None if it is the first migration.\n            upgrade: The upgrade function of the migration.\n            downgrade: The downgrade function of the migration.\n        \"\"\"\n        pass\n\n    def add_child(self, child_node: \"MigrationNode\"):\n        \"\"\"\n        Add a child node to the current node.\n        Args:\n            child_node: The child node to add.\n        \"\"\"\n        pass\n\n    def upgrade(self, db):\n        \"\"\"\n        Apply the upgrade function of the migration.\n        Args:\n            db: The database to upgrade.\n        \"\"\"\n        pass\n\n    def downgrade(self, db):\n        \"\"\"\n        Apply the downgrade function of the migration.\n        Args:\n            db: The database to downgrade.\n        \"\"\"\n        pass\n\n    @classmethod\n    def from_file(cls, file_path: str) -> \"MigrationNode\":\n        \"\"\"\n        Parse a migration file and return the migration node.\n        Args:\n            file_path: The path to the migration file.\n        Raises:\n            FileNotFoundError: If the file is not found.\n            ValueError: If the file format is invalid.\n        Returns:\n            The migration node parsed from the file.\n        \"\"\"\n        pass\n\n    def __repr__(self):\n        pass\n\n    def __str__(self):\n        pass\n\n\nclass MigrationHistory:\n\n    def __init__(self, migrations_dir: str):\n        \"\"\"\n        Class for managing the migration history.\n        Args:\n            migrations_dir: The directory where the migrations are stored.\n        Attributes:\n            migrations_dir: The directory where the migrations are stored.\n            roots: The root nodes of the migration history.\n            migrations: A dictionary of all migrations by version.\n        Raises:\n            FileNotFoundError: If a migration file is not found.\n            ValueError: If a migration file format is invalid.\n        \"\"\"\n        pass\n\n    def _load_migrations(self):\n        \"\"\"\n        Private method to load all migrations from the migrations directory.\n        Migrations without a last version or without a found last_version are considered as roots.\n\n        Raises:\n            FileNotFoundError: If a migration file is not found.\n            ValueError: If a migration file format is invalid.\n        \"\"\"\n        pass\n\n    def is_empty(self) -> bool:\n        \"\"\"\n        Check if the migration history is empty.\n        Returns:\n            True if the history is empty, False otherwise.\n        \"\"\"\n        pass\n\n    def validate(self, node: MigrationNode = None) -> bool:\n        \"\"\"\n        Check the migration history for bifurcations.\n        The history is valid if it is a non empty linear tree.\n        Args:\n            node: The node to start the check. If None, the check starts from the root.\n        Returns:\n            True if the history is valid, False otherwise.\n        \"\"\"\n        pass\n\n    def get_first_version(self) -> str:\n        \"\"\"\n        Get the first version of the migration history.\n        Assumes that the migration history is valid.\n        Returns:\n            The first version of the migration history.\n        \"\"\"\n        pass\n\n    def get_first_node(self) -> MigrationNode:\n        \"\"\"\n        Get the first node of the migration history.\n        Assumes that the migration history is valid.\n        Returns:\n            The first node of the migration history.\n        \"\"\"\n        pass\n\n    def get_last_version(self) -> str:\n        \"\"\"\n        Get the last version of the migration history.\n        Assumes that the migration history is valid.\n        Returns:\n            The last version of the migration history.\n        \"\"\"\n        pass\n\n    def get_last_node(self) -> MigrationNode:\n        \"\"\"\n        Get the last node of the migration history.\n        Assumes that the migration history is valid.\n        Returns:\n            The last node of the migration history.\n        \"\"\"\n        pass\n\n    def _print_linear_tree(\n        self,\n        node: MigrationNode,\n        current_version: str = None,\n        current_found: bool = False,\n        is_applied: bool = True,\n    ):\n        \"\"\"\n        Print a linear tree of the migration history.\n        Args:\n            node: The node to print.\n            level: The level of the node in the tree.\n        \"\"\"\n        pass\n\n    def print_history(self, current_version: str = None):\n        \"\"\"\n        Prints the history of migrations from oldest to newest.\n        Args:\n            current_version: The current version of the database.\n        Raises:\n            ValueError: If the history is invalid.\n        \"\"\"\n        pass\n\n    def get_migrations(\n        self, start_version: str = None, to_version: str = None\n    ) -> List[MigrationNode]:\n        \"\"\"\n        Get a list of migrations.\n        Assumes that the migration history is valid.\n        Args:\n            start_version: The version to start from. If None, the first version is used.\n            to_version: The last version of the migration list. If None, the last version is used.\n        Returns:\n            A list of migrations.\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "src/mongo_migrator/migration_template.py",
                "code": "\"\"\"\nThis class handles the creation of migration files.\n\nThe create_migration_file method creates a new migration file with a template.\nThis template includes the title, version, and current version of the migration.\n\"\"\"\n\n\nclass MigrationTemplate:\n\n    @classmethod\n    def create_migration_file(\n        cls, file_path: str, title: str, version: int, last_version: int\n    ):\n        \"\"\"\n        Create a new migration file.\n        Args:\n            file_path: The path to the new migration file.\n            title: The title of the migration.\n            version: The version of the migration.\n            last_version: The oldest version of the migrations.\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "src/mongo_migrator/db_utils.py",
                "code": "\"\"\"Module for database operations.\"\"\"\nfrom pymongo.database import Database\n\n\ndef get_db(\n    db_host: str,\n    db_port: int,\n    db_name: str,\n    db_user: str = None,\n    db_pass: str = None,\n    verbose: bool = False,\n    max_retries: int = 3,\n) -> Database:\n    \"\"\"\n    Get the database connection using pymongo.\n    Args:\n        db_host: The hostname of the MongoDB server.\n        db_port: The port number of the MongoDB server.\n        db_name: The name of the database.\n        db_user: The username for the database if needed.\n        db_pass: The password for the database if needed.\n        verbose: Whether to print messages.\n        max_retries: The number of times to retry connecting to the database.\n    Raises:\n        Exception: If the connection cannot be established.\n    Returns:\n        The database connection.\n    \"\"\"\n    pass\n\n\ndef create_version_collection(db: Database, collection_name: str) -> None:\n    \"\"\"\n    Create the version collection in the database.\n    Args:\n        db: The database connection.\n        collection_name: The name of the collection.\n    \"\"\"\n    pass\n\n\ndef set_current_version(db: Database, collection_name: str, version: str) -> None:\n    \"\"\"\n    Set the current version.\n    Args:\n        db: The database connection.\n        collection_name: The name of the version collection.\n        version: The current version.\n    \"\"\"\n    pass\n\n\ndef get_current_version(db: Database, collection_name: str) -> str:\n    \"\"\"\n    Get the current version.\n    Args:\n        db: The database connection.\n        collection_name: The name of the version collection.\n    Returns:\n        The current version.\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "src/mongo_migrator/config.py",
                "code": "\"\"\"\nContains the utility to manage the configuration file.\n\nUsage:\n"
            },
            {
                "file_path": "src/mongo_migrator/cli.py",
                "code": "\"\"\"\nCommand line interface for the mongo migrator\n\"\"\"\n\n\ndef init(args):\n    \"\"\"\n    Needs a config file named 'mongo-migrator.config' in the current directory.\n    Will create a migrations directory and a migration collection in the database.\n    \"\"\"\n    pass\n\n\ndef create(args):\n    \"\"\"\n    Creates a new migration file in the migration directory.\n    \"\"\"\n    pass\n\n\ndef upgrade(args):\n    \"\"\"\n    Upgrades the database to the latest version by default.\n    \"\"\"\n    pass\n\n\ndef downgrade(args):\n    \"\"\"\n    Downgrades the database to the previous version by default.\n    \"\"\"\n    pass\n\n\ndef history(args):\n    \"\"\"Shows the migration history.\"\"\"\n    pass\n\n\ndef main():\n    pass\n"
            }
        ],
        "minimal_code_skeleton_structured": [
            {
                "file_path": "mongo_migrator/config.py",
                "code": "class Config:\n    \"\"\"Class to handle the configuration file\"\"\"\n\n    CONFIG_FILE = \"mongo-migrator.config\"\n\n    def __init__(self):\n        \"\"\"\n        Initialize the Config class.\n\n        Description:\n            Loads the configuration file and provides access to the configuration values.\n            This file must be named after CONFIG_FILE attribute.\n            It also must be placed in the same directory where mongo-migrator is going to be used.\n\n        Exit cases:\n            If the configuration file is not found, the program will exit.\n            If any of the required sections are missing, the program will exit.\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "mongo_migrator/db_utils.py",
                "code": "def get_db(\n    db_host: str,\n    db_port: int,\n    db_name: str,\n    db_user: str = None,\n    db_pass: str = None,\n    verbose: bool = False,\n    max_retries: int = 3,\n) -> Database:\n    \"\"\"\n    Get the database connection using pymongo.\n    Args:\n        db_host: The hostname of the MongoDB server.\n        db_port: The port number of the MongoDB server.\n        db_name: The name of the database.\n        db_user: The username for the database if needed.\n        db_pass: The password for the database if needed.\n        verbose: Whether to print messages.\n        max_retries: The number of times to retry connecting to the database.\n    Raises:\n        Exception: If the connection cannot be established.\n    Returns:\n        The database connection.\n    \"\"\"\n    pass\n\ndef create_version_collection(db: Database, collection_name: str) -> None:\n    \"\"\"\n    Create the version collection in the database.\n    Args:\n        db: The database connection.\n        collection_name: The name of the collection.\n    \"\"\"\n    pass\n\ndef set_current_version(db: Database, collection_name: str, version: str) -> None:\n    \"\"\"\n    Set the current version.\n    Args:\n        db: The database connection.\n        collection_name: The name of the version collection.\n        version: The current version.\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "mongo_migrator/migration_history.py",
                "code": "class MigrationNode:\n    \"\"\"\n    Represents a migration node in the migration history tree.\n    \"\"\"\n\n    def __init__(\n        self,\n        title: str,\n        version: str,\n        last_version: str = None,\n        upgrade: str = None,\n        downgrade: str = None,\n    ):\n        \"\"\"\n        Create a new migration node.\n        Args:\n            title: The title of the migration.\n            version: The version of the migration.\n            last_version: The last version of the migration. None if it is the first migration.\n            upgrade: The upgrade function of the migration.\n            downgrade: The downgrade function of the migration.\n        \"\"\"\n        pass\n\n    def add_child(self, child_node: \"MigrationNode\"):\n        \"\"\"\n        Add a child node to the current node.\n        Args:\n            child_node: The child node to add.\n        \"\"\"\n        pass\n\n    def upgrade(self, db):\n        \"\"\"\n        Apply the upgrade function of the migration.\n        Args:\n            db: The database to upgrade.\n        \"\"\"\n        pass\n\n    def downgrade(self, db):\n        \"\"\"\n        Apply the downgrade function of the migration.\n        Args:\n            db: The database to downgrade.\n        \"\"\"\n        pass\n\n    def __repr__(self):\n        pass\n\nclass MigrationHistory:\n\n    def __init__(self, migrations_dir: str):\n        \"\"\"\n        Class for managing the migration history.\n        Args:\n            migrations_dir: The directory where the migrations are stored.\n        Attributes:\n            migrations_dir: The directory where the migrations are stored.\n            roots: The root nodes of the migration history.\n            migrations: A dictionary of all migrations by version.\n        Raises:\n            FileNotFoundError: If a migration file is not found.\n            ValueError: If a migration file format is invalid.\n        \"\"\"\n        pass\n\n    def is_empty(self) -> bool:\n        \"\"\"\n        Check if the migration history is empty.\n        Returns:\n            True if the history is empty, False otherwise.\n        \"\"\"\n        pass\n\n    def validate(self, node: MigrationNode = None) -> bool:\n        \"\"\"\n        Check the migration history for bifurcations.\n        The history is valid if it is a non empty linear tree.\n        Args:\n            node: The node to start the check. If None, the check starts from the root.\n        Returns:\n            True if the history is valid, False otherwise.\n        \"\"\"\n        pass\n\n    def get_first_version(self) -> str:\n        \"\"\"\n        Get the first version of the migration history.\n        Assumes that the migration history is valid.\n        Returns:\n            The first version of the migration history.\n        \"\"\"\n        pass\n\n    def get_first_node(self) -> MigrationNode:\n        \"\"\"\n        Get the first node of the migration history.\n        Assumes that the migration history is valid.\n        Returns:\n            The first node of the migration history.\n        \"\"\"\n        pass\n\n    def get_last_version(self) -> str:\n        \"\"\"\n        Get the last version of the migration history.\n        Assumes that the migration history is valid.\n        Returns:\n            The last version of the migration history.\n        \"\"\"\n        pass\n\n    def get_last_node(self) -> MigrationNode:\n        \"\"\"\n        Get the last node of the migration history.\n        Assumes that the migration history is valid.\n        Returns:\n            The last node of the migration history.\n        \"\"\"\n        pass\n\n    def get_migrations(\n        self, start_version: str = None, to_version: str = None\n    ) -> List[MigrationNode]:\n        \"\"\"\n        Get a list of migrations.\n        Assumes that the migration history is valid.\n        Args:\n            start_version: The version to start from. If None, the first version is used.\n            to_version: The last version of the migration list. If None, the last version is used.\n        Returns:\n            A list of migrations.\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "mongo_migrator/cli.py",
                "code": "def init(args):\n    \"\"\"\n    Needs a config file named 'mongo-migrator.config' in the current directory.\n    Will create a migrations directory and a migration collection in the database.\n    \"\"\"\n    pass\n\ndef create(args):\n    \"\"\"\n    Creates a new migration file in the migration directory.\n    \"\"\"\n    pass\n\ndef upgrade(args):\n    \"\"\"\n    Upgrades the database to the latest version by default.\n    \"\"\"\n    pass\n\ndef downgrade(args):\n    \"\"\"\n    Downgrades the database to the previous version by default.\n    \"\"\"\n    pass\n\ndef history(args):\n    \"\"\"Shows the migration history.\"\"\"\n    pass\n\ndef main():\n    pass\n"
            }
        ]
    },
    {
        "idx": 21970,
        "repo_name": "microprediction_bonding",
        "url": "https://github.com/microprediction/bonding",
        "description": "Bonding curve automated market makers",
        "stars": 7,
        "forks": 2,
        "language": "python",
        "size": 162,
        "created_at": "2025-01-23T20:00:45+00:00",
        "updated_at": "2025-01-27T19:50:28+00:00",
        "pypi_info": {
            "name": "bonding",
            "version": "0.0.5",
            "url": "https://files.pythonhosted.org/packages/c8/28/9103629e51ede32a5c7fbe059b17707507969c74bb2fa3184e0b9d638353/bonding-0.0.5.tar.gz"
        },
        "error": null,
        "judge_info": {
            "language": "python",
            "is_good_project": false,
            "reason": "",
            "python_file_num": 43,
            "comment_ratio": 0.36502347417840375,
            "pyfile_content_length": 67802,
            "pyfile_code_lines": 1704,
            "test_file_exist": true,
            "test_file_content_length": 10573,
            "pytest_framework": true,
            "test_case_num": 15,
            "metadata_path": [
                "setup.py"
            ],
            "readme_content_length": 3072,
            "llm_reason": "The project is to implement a library for bonding curves and Automated Market Makers (AMMs). \n\nPositive aspects:\n*   **Self-Contained Core Logic:** The core functionality (mathematical curve definitions, AMM operations like buy/sell, fee calculation, state management) is self-contained and does not require internet access or external APIs for its operation. Dependencies like `matplotlib` (for plotting) and `scipy` (for numerical verification in some helper methods/tests) are explicitly mentioned as optional in the README and are not essential for the AMM's primary computational logic. The AI's rebuilt solution can focus on the core library without these optional components if specified.\n*   **Clear & Well-Defined Functionality:** The project aims to implement specific mathematical bonding curves (Linear, Sqrt, Log, Exp, Growth) and an AMM system that uses these curves. The structure (base classes `BondingCurve`, `BondingCurveAMM`, and their concrete implementations) is clear. The AI's task would be to replicate these classes and their methods, including mathematical formulas for price and integrals, and the logic for AMM operations.\n*   **Testable & Verifiable Output:** The project has an extensive suite of tests (using `pytest`) covering arbitrage conditions, round-trip transactions, fee effects, integral accuracy, and scale conventions. These tests can be directly used or adapted to verify the AI's implementation, which is a significant advantage.\n*   **No Graphical User Interface (GUI):** The project is a library. While it contains optional plotting methods using `matplotlib`, the core interactions are programmatic (library imports and method calls). The benchmark can specify that GUI/plotting features are out of scope for the AI's core task.\n*   **Appropriate Complexity & Scope:** The project is non-trivial, involving mathematical concepts (calculus for integrals, specific functions), object-oriented design, and financial logic (fees, arbitrage). However, it's not excessively complex. The number of classes and methods is manageable (approx. 6 curve types, 1 main AMM class with ~20 methods, and simple AMM subclasses). Replicating this would be a good challenge for an AI, estimated to take a human a few days.\n*   **Well-Understood Problem (for implementation):** While the domain of bonding curves might be specialized, the project itself provides the specific mathematical formulas and logic to be implemented. The task is to re-code these defined models.\n*   **Predominantly Code-Based Solution:** The task is entirely about generating Python code.\n\nNegative aspects or concerns:\n*   **Mathematical Sophistication:** Correctly implementing the mathematical formulas for price and especially price integrals for various curves requires precision. The `BondingCurveAMM` class also contains a numerical solver (`_solve_for_dx` using bisection) that needs correct implementation.\n*   **Complexity of `BondingCurveAMM`:** This central class manages state, handles fees, implements various buy/sell strategies (by value or shares), and includes simulation and arbitrage-checking logic. It's moderately complex with many interrelated methods.\n*   **Clarity on Optional Features:** The benchmark specification would need to be precise about whether methods relying on optional dependencies like `matplotlib` (e.g., `BondingCurve.plot()`) or `scipy` (e.g., `BondingCurve.verify_integral_accuracy()`) are part of the AI's required deliverables. However, the core AMM functionality is independent of these and forms a solid benchmark target.\n\nOverall, the project is a good candidate. It's a well-defined, testable, and appropriately complex library whose core functionality is self-contained. The AI would be tasked to rebuild the mathematical models and the AMM simulation logic.",
            "llm_project_type": "Mathematical finance simulation library (Automated Market Maker)",
            "llm_rating": 75,
            "llm_difficulty": "Medium"
        },
        "tests": {
            "repo_name": "microprediction_bonding",
            "finish_test": true,
            "test_case_result": {
                "tests/amms/test_arbitrage.py::test_buy_shares_then_sell_shares": "passed",
                "tests/amms/test_arbitrage.py::test_all_amms_arbitrage": "passed",
                "tests/amms/test_arbitrage_log.py::test_log_bonding_curve_amm": "passed",
                "tests/amms/test_bondingcurve_arbitrage_manually.py::test_no_arbitrage_immediate_round_trip_with_fees": "passed",
                "tests/amms/test_bondingcurve_arbitrage_manually.py::test_no_arbitrage_immediate_round_trip_no_fees": "passed",
                "tests/amms/test_bondingcurve_arbitrage_manually.py::test_split_vs_single_trade_no_free_arbitrage": "passed",
                "tests/amms/test_bondingcurve_arbitrage_manually.py::test_zero_trade_no_change": "passed",
                "tests/amms/test_bondingcurve_arbitrage_manually.py::test_buy_shares_no_fees": "passed",
                "tests/amms/test_bondingcurve_arbitrage_manually.py::test_buy_shares_with_fees": "passed",
                "tests/amms/test_bondingcurve_arbitrage_manually.py::test_sell_value_no_fees": "passed",
                "tests/amms/test_buy_sell_log.py::test_buy_then_sell": "passed",
                "tests/curves/test_integral_accuracy.py::test_all_curves": "passed",
                "tests/curves/test_scale_convention.py::test_scale_conventions": "passed",
                "tests/curves/test_scale_convention.py::test_initial_price": "passed",
                "tests/test_examples.py::test_examples": "passed"
            },
            "success_count": 15,
            "failed_count": 0,
            "error_count": 0,
            "skipped_count": 0,
            "unknown_count": 0,
            "total_count": 15,
            "success_rate": 1.0,
            "coverage_report": {
                "covered_lines": 311,
                "num_statements": 546,
                "percent_covered": 54.66472303206997,
                "percent_covered_display": "55",
                "missing_lines": 235,
                "excluded_lines": 0,
                "num_branches": 140,
                "num_partial_branches": 42,
                "covered_branches": 64,
                "missing_branches": 76
            },
            "coverage_result": {}
        },
        "codelines_count": 1704,
        "codefiles_count": 43,
        "code_length": 67802,
        "test_files_count": 7,
        "test_code_length": 10573,
        "structure": [
            {
                "file": "setup.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "bonding.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/test_examples.py",
                "functions": [
                    {
                        "name": "test_examples",
                        "docstring": null,
                        "comments": "Compare incremental buying to single larger trade",
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/amms/test_arbitrage.py",
                "functions": [
                    {
                        "name": "test_buy_shares_then_sell_shares",
                        "docstring": "Test that all AMMs are importable and have the expected methods.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_all_amms_arbitrage",
                        "docstring": "Test that all AMMs are importable and have the expected methods.",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/amms/test_bondingcurve_arbitrage_manually.py",
                "functions": [
                    {
                        "name": "amm_with_fees",
                        "docstring": "Fixture for AMM instance with fees.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "amm_no_fees",
                        "docstring": "Fixture for AMM instance without fees.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_no_arbitrage_immediate_round_trip_with_fees",
                        "docstring": "Test that buying and immediately selling with fees results in scale net loss.",
                        "comments": null,
                        "args": [
                            "amm_with_fees"
                        ]
                    },
                    {
                        "name": "test_no_arbitrage_immediate_round_trip_no_fees",
                        "docstring": "Test that buying and immediately selling without fees results in breaking even.",
                        "comments": null,
                        "args": [
                            "amm_no_fees"
                        ]
                    },
                    {
                        "name": "test_split_vs_single_trade_no_free_arbitrage",
                        "docstring": "Ensure that splitting scale large trade into multiple small trades does not yield extra profit.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_zero_trade_no_change",
                        "docstring": "Test that performing scale zero-value trade does not change the state.",
                        "comments": null,
                        "args": [
                            "amm_with_fees"
                        ]
                    },
                    {
                        "name": "test_buy_shares_no_fees",
                        "docstring": "Test buying an exact number of shares when there are no fees.\n- The user calls `buy_shares(num_shares)` and pays scale certain total.\n- Then the user sells those shares.\nThey should roughly break even, ignoring tiny rounding differences.",
                        "comments": "\nAdditional Tests for the New \"buy_shares\" and \"sell_value\" Methods\n",
                        "args": [
                            "amm_no_fees"
                        ]
                    },
                    {
                        "name": "test_buy_shares_with_fees",
                        "docstring": "Test buying an exact number of shares when there is scale fee.\n- The user calls `buy_shares(num_shares)` and pays total_paid.\n- Then sells the same number of shares.\nThe net_received from selling should be less than total_paid due to fees.",
                        "comments": null,
                        "args": [
                            "amm_with_fees"
                        ]
                    },
                    {
                        "name": "test_sell_value_no_fees",
                        "docstring": "Test selling enough shares to receive scale specific amount of currency with no fees.\n- The user first buys some shares (buy_value).\n- Then the user calls `sell_value(...)` to get exactly some currency.\nCheck that the shares sold is consistent and the user breaks even if they buy and sell instantly.",
                        "comments": null,
                        "args": [
                            "amm_no_fees"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/amms/test_arbitrage_log.py",
                "functions": [
                    {
                        "name": "test_log_bonding_curve_amm",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/amms/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/amms/test_buy_sell_log.py",
                "functions": [
                    {
                        "name": "test_buy_then_sell",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/amms/debug_arbitrage_log.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/curves/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/curves/debug_numerical_integration.py",
                "functions": [
                    {
                        "name": "debug_integral",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/curves/debug_numerical_integration_log.py",
                "functions": [
                    {
                        "name": "debug_integral",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/curves/test_integral_accuracy.py",
                "functions": [
                    {
                        "name": "test_all_curves",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/curves/test_scale_convention.py",
                "functions": [
                    {
                        "name": "test_scale_conventions",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_initial_price",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "examples/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "examples/example_round_trip_value.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "examples/example_incremental_buy.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "examples/example_round_trip.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "bonding/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "bonding/amms/linearbondingcurveamm.py",
                "functions": [],
                "classes": [
                    {
                        "name": "LinearBondingCurveAMM",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "scale",
                                    "fee_rate"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "bonding/amms/allamms.py",
                "functions": [
                    {
                        "name": "all_amm_cls",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "bonding/amms/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "bonding/amms/bondingcurveamm.py",
                "functions": [],
                "classes": [
                    {
                        "name": "BondingCurveAMM",
                        "docstring": "A simple Automated Market Maker (AMM) that uses a given BondingCurve\nto determine pricing, while handling transaction fees, rounding, and state tracking.\n\nAttributes\n----------\ncurve : BondingCurve\n    The amms curve instance that defines price and integral logic.\nfee_rate : float\n    Fraction of each transaction (buy or sell) collected as fees. 0.001 => 0.1%.\nquanta : float\n    Defines the smallest currency denomination (1e-8).\nx : float\n    Current total minted/sold (the \"supply\" on the amms curve).\ntotal_cash_collected : float\n    Total amount of currency that the amms curve has collected (this excludes fees).\ntotal_fees_collected : float\n    Total amount of currency collected as fees.\nlogger : logging.Logger\n    Logger instance for logging events and errors.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the BondingCurveAMM.\n\nParameters\n----------\ncurve : BondingCurve\n    A amms curve instance (e.g. SqrtBondingCurve).\nfee_rate : float, optional\n    Fraction of each transaction (buy or sell) to be taken as fees (0.001 => 0.1%).\nquanta : float, optional\n    Defines the smallest currency denomination (1e-8). Defaults to QUANTA.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "curve",
                                    "fee_rate",
                                    "quanta"
                                ]
                            },
                            {
                                "name": "_solve_for_dx",
                                "docstring": "Solve for dx such that cost_to_move(x_start, x_start + dx) = target_cost\nusing the bisection method.\n\nReturns\n-------\nfloat\n    dx (positive if buying, negative if selling).",
                                "comments": "\nInternal solver that uses the curve's cost_to_move\n",
                                "args": [
                                    "self",
                                    "x_start",
                                    "target_cost",
                                    "tolerance",
                                    "max_iter"
                                ]
                            },
                            {
                                "name": "simulate_buy_value",
                                "docstring": "Simulate buying with `total_value` currency.\n\nReturns a dict with:\n    {\n        'quanta_used': int,\n        'breakage_fee': float,\n        'fee_amount': float,\n        'net_currency': float,   # actual currency that goes into the curve\n        'shares_received': float\n    }",
                                "comments": "\nSimulation (Hypothetical) Methods\n",
                                "args": [
                                    "self",
                                    "total_value"
                                ]
                            },
                            {
                                "name": "simulate_buy_shares",
                                "docstring": "Simulate buying exactly `num_shares`, determining how much currency is required.\n\nReturns a dict with:\n    {\n        'gross_cost': float,     # The net cost (without fees) required by the curve\n        'quanta_used': int,\n        'breakage_fee': float,\n        'fee_amount': float,\n        'total_paid': float,     # The total currency user must pay\n    }",
                                "comments": null,
                                "args": [
                                    "self",
                                    "num_shares"
                                ]
                            },
                            {
                                "name": "simulate_sell_shares",
                                "docstring": "Simulate selling `num_shares` from the current supply.\n\nReturns a dict with:\n    {\n        'gross_currency': float,\n        'quanta_used': int,\n        'breakage_fee': float,\n        'fee_amount': float,\n        'net_currency': float,\n    }",
                                "comments": null,
                                "args": [
                                    "self",
                                    "num_shares"
                                ]
                            },
                            {
                                "name": "simulate_sell_value",
                                "docstring": "Simulate selling enough shares to receive `target_value` total currency.\n\nReturns a dict with:\n    {\n        'quanta_used': int,\n        'breakage_fee': float,\n        'fee_amount': float,\n        'gross_currency': float,\n        'net_currency': float,\n        'shares_sold': float\n    }",
                                "comments": null,
                                "args": [
                                    "self",
                                    "target_value"
                                ]
                            },
                            {
                                "name": "buy_value",
                                "docstring": "The user spends `value` currency to buy shares.\nReturns the number of shares actually purchased.",
                                "comments": "\nActual Action Methods (State-Changing)\n",
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "buy_shares",
                                "docstring": "The user wants to buy exactly `num_shares`.\nReturns the total currency they actually paid.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "num_shares"
                                ]
                            },
                            {
                                "name": "sell_shares",
                                "docstring": "Sell exactly `num_shares`, returning the net currency the user receives.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "num_shares"
                                ]
                            },
                            {
                                "name": "sell_value",
                                "docstring": "Sell enough shares to receive `value` currency (in total).\nReturns the number of shares sold (positive float).",
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "get_maximum_sell_value",
                                "docstring": "Returns the maximum net currency value one can extract by selling all shares (curve.x).",
                                "comments": "\nUtility\n",
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "total_cost_at_supply",
                                "docstring": "Returns the integral of the price from 0 to x_val (or curve.x).",
                                "comments": null,
                                "args": [
                                    "self",
                                    "x_val"
                                ]
                            },
                            {
                                "name": "current_price",
                                "docstring": "Returns the instantaneous price at supply curve.x.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__repr__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "simulate_buy_value_then_sell_shares",
                                "docstring": "Simulate spending `buy_value` currency to buy shares, and then\nimmediately selling *all* those purchased shares.\n\nReturns\n-------\ndict\n    {\n        'initial_currency': float,\n        'final_currency': float,\n        'net_delta': float,\n        'buy_sim': dict,      # output of simulate_buy_value(...)\n        'sell_sim': dict,     # output of simulate_sell_shares(...)\n        'arbitrage': bool,    # True if net_delta > 0\n    }",
                                "comments": "\nArbitrage checks (Round Trip Simulations)\n",
                                "args": [
                                    "self",
                                    "buy_value"
                                ]
                            },
                            {
                                "name": "simulate_buy_shares_then_sell_shares",
                                "docstring": "Simulate buying exactly `num_shares`, then immediately selling\nthose same shares.\n\nReturns\n-------\ndict\n    {\n        'shares_bought': float,\n        'currency_spent': float,    # total_paid from buy_shares\n        'currency_received': float, # net_currency from sell_shares\n        'net_delta': float,\n        'arbitrage': bool\n    }",
                                "comments": null,
                                "args": [
                                    "self",
                                    "num_shares"
                                ]
                            },
                            {
                                "name": "simulate_sell_value_then_buy_shares",
                                "docstring": "Simulate selling enough shares to receive exactly `target_value` currency,\nthen use the *net* proceeds to buy shares again.\n\nReturns\n-------\ndict\n    {\n        'target_value': float,\n        'shares_sold': float,          # positive\n        'buy_shares_received': float,  # how many shares we get from the net currency\n        'shares_delta': float,         # (buy_shares_received - shares_sold)\n        'arbitrage': bool\n    }",
                                "comments": null,
                                "args": [
                                    "self",
                                    "target_value"
                                ]
                            },
                            {
                                "name": "simulate_sell_shares_then_buy_value",
                                "docstring": "Simulate selling exactly `shares_to_sell`, then use the net proceeds\nto buy as much as possible of the AMM (buy_value) with that currency.\n\nReturns\n-------\ndict\n    {\n        'shares_sold': float,\n        'currency_received': float,\n        'shares_bought': float,\n        'shares_delta': float,\n        'arbitrage': bool\n    }",
                                "comments": null,
                                "args": [
                                    "self",
                                    "shares_to_sell"
                                ]
                            },
                            {
                                "name": "assert_no_round_trip_arbitrage",
                                "docstring": "Runs a few sample round-trip trades with *actual* state changes\n(then reverts after each test). If any scenario yields a net profit,\nraises RuntimeError.\n\nReturns\n-------\nbool\n    True if no arbitrage found, else RuntimeError is raised.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "bonding/amms/sqrtbondingcurveamm.py",
                "functions": [],
                "classes": [
                    {
                        "name": "SqrtBondingCurveAMM",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "scale",
                                    "fee_rate"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "bonding/amms/logbondingcurveamm.py",
                "functions": [],
                "classes": [
                    {
                        "name": "LogBondingCurveAMM",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "scale",
                                    "fee_rate"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "bonding/amms/expbondingcurveamm.py",
                "functions": [],
                "classes": [
                    {
                        "name": "ExpBondingCurveAMM",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "scale : float, optional\n    Scaling parameter for the exponential bonding curve.\n    Determines roughly the x where the price doubles. Must be positive.\n    Default: 500,000.0\nfee_rate : float, optional\n    Fraction of each transaction (buy or sell) collected as fees.\n    0.001 => 0.1%.\n    Default: 0.0",
                                "comments": null,
                                "args": [
                                    "self",
                                    "scale",
                                    "fee_rate"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "bonding/amms/ammdefaultparams.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "bonding/amms/growthbondingcurveamm.py",
                "functions": [],
                "classes": [
                    {
                        "name": "GrowthBondingCurveAMM",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "scale",
                                    "fee_rate"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "bonding/curves/growthbondingcurve.py",
                "functions": [],
                "classes": [
                    {
                        "name": "GrowthBondingCurve",
                        "docstring": "A factor-based bonding curve that ensures:\n  - f(0) = 1,\n  - f(scale) = 2,\n  - price grows by fraction 'a' each time x is multiplied by c.\n\nMathematically:\n    p = ln(1 + a) / ln(c),  (requires a > -1, c > 1)\n    f(x) = 1 + (x^p / scale^p).\n\nSo:\n  1) f(0)   = 1\n  2) f(scale)= 1 + 1 = 2\n  3) strictly increasing for x>0 if p>0\n  4) simple closed-form integral\n\n\nMotivated by a suggestion of Wilson Lau\nSee https://medium.com/thoughtchains/on-single-bonding-curves-for-continuous-token-models-a167f5ffef89",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Parameters\n----------\na : float\n    Fractional growth per factor c. e.g. a=0.25 => +25% price each time x is multiplied by c.\n    Must satisfy (1+a)>0.\nc : float\n    The factor base. c>1 means 'per doubling/tripling/etc' of x.\nscale : float\n    The x-value at which price is guaranteed to be 2. Must be > 0.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "scale",
                                    "a",
                                    "c"
                                ]
                            },
                            {
                                "name": "price",
                                "docstring": "price(x) = 1 + (x^p / scale^p),  for x >= 0\nwith p = ln(1+a)/ln(c).\n\n=> f(0)=1, f(scale)=2.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "x"
                                ]
                            },
                            {
                                "name": "price_integral",
                                "docstring": "∫[0..x] price(u) du\n = ∫[0..x] [1 + (u^p / scale^p)] du\n = ∫[0..x] 1 du + ∫[0..x] [u^p / scale^p] du\n = x + (1 / scale^p) * [u^(p+1)/(p+1)] from 0..x\n = x + (x^(p+1) / [scale^p * (p+1)]),   if p != -1.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "x"
                                ]
                            },
                            {
                                "name": "__repr__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "bonding/curves/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "bonding/curves/verifyintegralaccuracy.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "bonding/curves/linearbondingcurve.py",
                "functions": [],
                "classes": [
                    {
                        "name": "LinearBondingCurve",
                        "docstring": "price(x) = m*x + b\nprice_integral(x) = ∫(m*u + b) du = m/2 * x^2 + b*x",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "scale"
                                ]
                            },
                            {
                                "name": "get_scale",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "price",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "x"
                                ]
                            },
                            {
                                "name": "price_integral",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "x"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "bonding/curves/logbondingcurve.py",
                "functions": [],
                "classes": [
                    {
                        "name": "LogBondingCurve",
                        "docstring": "Implements a logarithmic bonding curve defined by:\n    f(x) = log(e + (e^2 - e) * (x / scale))\n\nKey properties:\n---------------\n1) f(0) = log(e) = 1\n   Starts at 1 when x=0.\n\n2) f(scale) = log(e + (e^2 - e) * (scale / scale)) = log(e + e^2 - e) = log(e^2) = 2\n   Price doubles at x = scale.\n\n3) Strictly increasing for x >= 0 because derivative = (e^2 - e) / (e + (e^2 - e) * (x / scale)) > 0.\n\n4) Has an analytic integral:\n     ∫ log(e + (e^2 - e) * (u / scale)) du\n   which evaluates to:\n     (e + (e^2 - e) * (x / scale)) * (log(e + (e^2 - e) * (x / scale)) - 1) / ((e^2 - e) / scale)",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the LogBondingCurve.\n\nParameters\n----------\nscale : float, optional\n    Scaling parameter for the curve. Must be positive.\n    Determines the x at which the price doubles. Defaults to 500,000.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "scale"
                                ]
                            },
                            {
                                "name": "price",
                                "docstring": "price(x) = log(e + (e^2 - e) * (x / scale))\n\nParameters\n----------\nx : float\n    The current supply (>= 0).\n\nReturns\n-------\nfloat\n    The instantaneous price at supply x.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "x"
                                ]
                            },
                            {
                                "name": "price_integral",
                                "docstring": "The definite integral of price(u) from 0 to x:\n\n    ∫[0 to x] log(e + (e^2 - e) * (u / scale)) du\n    = (e + (e^2 - e) * (x / scale)) * (log(e + (e^2 - e) * (x / scale)) - 1) / ((e^2 - e) / scale)\n\nParameters\n----------\nx : float\n    The upper limit of integration (>= 0).\n\nReturns\n-------\nfloat\n    ∫[0 to x] log(e + (e^2 - e) * (u / scale)) du",
                                "comments": null,
                                "args": [
                                    "self",
                                    "x"
                                ]
                            },
                            {
                                "name": "__repr__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "bonding/curves/sqrtbondingcurve.py",
                "functions": [],
                "classes": [
                    {
                        "name": "SqrtBondingCurve",
                        "docstring": "Implements the sqrt(1 + 3 (x / scale)^2) amms curve logic.\n\nprice(x) = sqrt(1 + (x/scale)^2)\nprice_integral(x) = 0.5 * [ x * sqrt(1 + (x/scale)^2 ) + scale * asinh(x / scale) ]",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "scale"
                                ]
                            },
                            {
                                "name": "price",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "x"
                                ]
                            },
                            {
                                "name": "price_integral",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "x"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "bonding/curves/bondingcurve.py",
                "functions": [],
                "classes": [
                    {
                        "name": "BondingCurve",
                        "docstring": "Abstract base class for amms curves.\n\nEach concrete amms curve must define:\n  - price(x): float\n  - price_integral(x): float\n    => integral of price(u) du from 0 to x\n  - cost_to_move(x_start, x_end): float\n    => can default to price_integral(x_end) - price_integral(x_start),\n       or be overridden if desired.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "get_scale",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "price",
                                "docstring": "Return the instantaneous price at `x`.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "x"
                                ]
                            },
                            {
                                "name": "price_integral",
                                "docstring": "Return the integral of the price function from 0 to x.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "x"
                                ]
                            },
                            {
                                "name": "cost_to_move",
                                "docstring": "Return the cost to move from x_start to x_end.\nDefault implementation: difference in the integrals.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "x_start",
                                    "x_end"
                                ]
                            },
                            {
                                "name": "plot",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "x_max",
                                    "num_points"
                                ]
                            },
                            {
                                "name": "verify_integral_accuracy",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "x_values",
                                    "tolerance"
                                ]
                            },
                            {
                                "name": "verify_initial_unit_price",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "verify_scale_convention",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "bonding/curves/allcurves.py",
                "functions": [
                    {
                        "name": "all_curves_cls",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "bonding/curves/expbondingcurve.py",
                "functions": [],
                "classes": [
                    {
                        "name": "ExpBondingCurve",
                        "docstring": "Implements an exponential bonding curve defined by:\n    f(x) = (1 / (e - 1)) * e^(x / scale) + (e - 2) / (e - 1)\n\nKey properties:\n---------------\n1) f(0) = 1\n   Starts at 1 when x=0.\n\n2) f(scale) = 2\n   Price doubles at x = scale.\n\n3) Strictly increasing for x >= 0 because derivative = (1 / scale) * (1 / (e - 1)) * e^(x / scale) > 0.\n\n4) Has an analytic integral:\n     ∫[0 to x] f(u) du = (scale / (e - 1)) * (e^(x / scale) - 1) + ((e - 2) / (e - 1)) * x",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the ExpBondingCurve.\n\nParameters\n----------\nscale : float, optional\n    Scaling parameter for the curve. Must be positive.\n    Determines the x at which the price doubles. Defaults to 500,000.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "scale"
                                ]
                            },
                            {
                                "name": "price",
                                "docstring": "price(x) = (1 / (e - 1)) * e^(x / scale) + (e - 2) / (e - 1)\n\nParameters\n----------\nx : float\n    The current supply (>= 0).\n\nReturns\n-------\nfloat\n    The instantaneous price at supply x.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "x"
                                ]
                            },
                            {
                                "name": "price_integral",
                                "docstring": "The definite integral of price(u) from 0 to x:\n\n    ∫[0 to x] [(1 / (e - 1)) * e^(u / scale) + (e - 2) / (e - 1)] du\n\nWhich evaluates to:\n\n    (scale / (e - 1)) * (e^(x / scale) - 1) + ((e - 2) / (e - 1)) * x\n\nParameters\n----------\nx : float\n    The upper limit of integration (>= 0).\n\nReturns\n-------\nfloat\n    ∫[0 to x] price(u) du",
                                "comments": null,
                                "args": [
                                    "self",
                                    "x"
                                ]
                            },
                            {
                                "name": "__repr__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "bonding/curveplots/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "bonding/curveplots/matplotlibcurveplot.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "bonding/using/usingscipy.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "bonding/using/usingmatplotlib.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "bonding/using/__init__.py",
                "functions": [],
                "classes": []
            }
        ],
        "test_cases": {
            "tests/amms/test_arbitrage.py::test_buy_shares_then_sell_shares": {
                "testid": "tests/amms/test_arbitrage.py::test_buy_shares_then_sell_shares",
                "result": "passed",
                "test_implementation": "def test_buy_shares_then_sell_shares():\n    \"\"\"\n    Test that all AMMs are importable and have the expected methods.\n    \"\"\"\n    for amm in all_amm_cls():\n        amm_instance = amm(scale=10)\n        amm_instance.simulate_buy_shares_then_sell_shares(num_shares=1.0)"
            },
            "tests/amms/test_arbitrage.py::test_all_amms_arbitrage": {
                "testid": "tests/amms/test_arbitrage.py::test_all_amms_arbitrage",
                "result": "passed",
                "test_implementation": "def test_all_amms_arbitrage():\n    \"\"\"\n    Test that all AMMs are importable and have the expected methods.\n    \"\"\"\n    for amm in all_amm_cls():\n        assert hasattr(amm, 'buy_value'), f\"{amm.__name__} should have a buy_value method.\"\n        assert hasattr(amm, 'sell_shares'), f\"{amm.__name__} should have a sell_shares method.\"\n        assert hasattr(amm, 'buy_shares'), f\"{amm.__name__} should have a buy_shares method.\"\n        assert hasattr(amm, 'sell_value'), f\"{amm.__name__} should have a sell_value method.\"\n\n        amm_instance = amm(scale=10)\n        assert amm_instance.assert_no_round_trip_arbitrage()"
            },
            "tests/amms/test_arbitrage_log.py::test_log_bonding_curve_amm": {
                "testid": "tests/amms/test_arbitrage_log.py::test_log_bonding_curve_amm",
                "result": "passed",
                "test_implementation": "def test_log_bonding_curve_amm():\n    amm = LogBondingCurveAMM(scale=10)\n    assert amm.assert_no_round_trip_arbitrage()"
            },
            "tests/amms/test_bondingcurve_arbitrage_manually.py::test_no_arbitrage_immediate_round_trip_with_fees": {
                "testid": "tests/amms/test_bondingcurve_arbitrage_manually.py::test_no_arbitrage_immediate_round_trip_with_fees",
                "result": "passed",
                "test_implementation": "def test_no_arbitrage_immediate_round_trip_with_fees(amm_with_fees):\n    \"\"\"\n    Test that buying and immediately selling with fees results in scale net loss.\n    \"\"\"\n    initial_investment = 1000.0\n\n    # Buy shares with scale specific currency amount\n    shares_bought = amm_with_fees.buy_value(initial_investment)\n\n    # Immediately sell all those shares\n    net_received = amm_with_fees.sell_shares(shares_bought)\n\n    # Assert that the user receives less than they invested due to fees\n    assert net_received < initial_investment, \\\n        \"Immediate round-trip with fees should not yield scale profit.\""
            },
            "tests/amms/test_bondingcurve_arbitrage_manually.py::test_no_arbitrage_immediate_round_trip_no_fees": {
                "testid": "tests/amms/test_bondingcurve_arbitrage_manually.py::test_no_arbitrage_immediate_round_trip_no_fees",
                "result": "passed",
                "test_implementation": "def test_no_arbitrage_immediate_round_trip_no_fees(amm_no_fees):\n    \"\"\"\n    Test that buying and immediately selling without fees results in breaking even.\n    \"\"\"\n    initial_investment = 1000.0\n\n    # Buy shares with scale specific currency amount (no fees)\n    shares_bought = amm_no_fees.buy_value(initial_investment)\n\n    # Immediately sell all those shares\n    net_received = amm_no_fees.sell_shares(shares_bought)\n\n    # With zero fees, the user should roughly break even (allow small floating error).\n    assert math.isclose(net_received, initial_investment, rel_tol=1e-6), \\\n        \"Immediate round-trip with zero fees should be break-even.\""
            },
            "tests/amms/test_bondingcurve_arbitrage_manually.py::test_split_vs_single_trade_no_free_arbitrage": {
                "testid": "tests/amms/test_bondingcurve_arbitrage_manually.py::test_split_vs_single_trade_no_free_arbitrage",
                "result": "passed",
                "test_implementation": "def test_split_vs_single_trade_no_free_arbitrage():\n    \"\"\"\n    Ensure that splitting scale large trade into multiple small trades does not yield extra profit.\n    \"\"\"\n    X = 1000.0  # total currency to invest\n    N = 10  # number of splits\n\n    # Single trade approach\n    amm_single = SqrtBondingCurveAMM(scale=1000.0, fee_rate=0.001)\n    shares_single = amm_single.buy_value(X)\n    net_single = amm_single.sell_shares(shares_single)\n\n    # Split approach\n    amm_split = SqrtBondingCurveAMM(scale=1000.0, fee_rate=0.001)\n    shares_split = 0.0\n    for _ in range(N):\n        shares_split += amm_split.buy_value(X / N)\n    net_split = amm_split.sell_shares(shares_split)\n\n    # Because of the amms curve's continuity and the proportional fee,\n    # multiple smaller buys/sell should not yield strictly more net than scale single big trade\n    assert net_split <= net_single + 1e-6, \\\n        \"Multiple small buys+sell shouldn't yield strictly more net than scale single trade.\""
            },
            "tests/amms/test_bondingcurve_arbitrage_manually.py::test_zero_trade_no_change": {
                "testid": "tests/amms/test_bondingcurve_arbitrage_manually.py::test_zero_trade_no_change",
                "result": "passed",
                "test_implementation": "def test_zero_trade_no_change(amm_with_fees):\n    \"\"\"\n    Test that performing scale zero-value trade does not change the state.\n    \"\"\"\n    amm = amm_with_fees\n\n    # Initial state\n    initial_x = amm.x\n    initial_cash = amm.total_cash_collected\n    initial_fees = amm.total_fees_collected\n\n    # Perform zero buy\n    shares_bought = amm.buy_value(0.0)\n    assert shares_bought == 0.0, \"Buying with zero value should return zero shares.\"\n    assert amm.x == initial_x, \"Supply should remain unchanged after zero buy.\"\n    assert amm.total_cash_collected == initial_cash, \\\n        \"Cash collected should remain unchanged after zero buy.\"\n    assert amm.total_fees_collected == initial_fees, \\\n        \"Fees collected should remain unchanged after zero buy.\"\n\n    # Perform zero sell\n    net_received = amm.sell_shares(0.0)\n    assert net_received == 0.0, \"Selling zero shares should return zero currency.\"\n    assert amm.x == initial_x, \"Supply should remain unchanged after zero sell.\"\n    assert amm.total_cash_collected == initial_cash, \\\n        \"Cash collected should remain unchanged after zero sell.\"\n    assert amm.total_fees_collected == initial_fees, \\\n        \"Fees collected should remain unchanged after zero sell.\""
            },
            "tests/amms/test_bondingcurve_arbitrage_manually.py::test_buy_shares_no_fees": {
                "testid": "tests/amms/test_bondingcurve_arbitrage_manually.py::test_buy_shares_no_fees",
                "result": "passed",
                "test_implementation": "def test_buy_shares_no_fees(amm_no_fees):\n    \"\"\"\n    Test buying an exact number of shares when there are no fees.\n    - The user calls `buy_shares(num_shares)` and pays scale certain total.\n    - Then the user sells those shares.\n    They should roughly break even, ignoring tiny rounding differences.\n    \"\"\"\n    amm = amm_no_fees\n\n    # Suppose we want exactly 10 shares\n    shares_target = 10.0\n    total_paid = amm.buy_shares(shares_target)\n    assert total_paid > 0.0, \"Buying shares should cost some positive amount of currency.\"\n    # The supply should have increased exactly by 10\n    assert math.isclose(amm.x, shares_target, rel_tol=1e-9), \"Supply should increase by exactly 10.\"\n\n    net_received = amm.sell_shares(shares_target)\n    # No fees, so we expect net_received ~ total_paid\n    assert math.isclose(net_received, total_paid, rel_tol=1e-6), \\\n        \"Without fees, buying then selling the same shares should be near break-even.\"\n    # Supply back to zero\n    assert math.isclose(amm.x, 0.0, abs_tol=1e-9), \\\n        \"Supply should be back to zero after selling all shares.\""
            },
            "tests/amms/test_bondingcurve_arbitrage_manually.py::test_buy_shares_with_fees": {
                "testid": "tests/amms/test_bondingcurve_arbitrage_manually.py::test_buy_shares_with_fees",
                "result": "passed",
                "test_implementation": "def test_buy_shares_with_fees(amm_with_fees):\n    \"\"\"\n    Test buying an exact number of shares when there is scale fee.\n    - The user calls `buy_shares(num_shares)` and pays total_paid.\n    - Then sells the same number of shares.\n    The net_received from selling should be less than total_paid due to fees.\n    \"\"\"\n    amm = amm_with_fees\n\n    shares_target = 5.0\n    total_paid = amm.buy_shares(shares_target)\n    assert total_paid > 0.0, \"Should pay positive currency for 5 shares.\"\n\n    net_received = amm.sell_shares(shares_target)\n    assert net_received < total_paid, \\\n        \"With fees, user should not break even on immediate buy->sell round trip.\"\n    assert math.isclose(amm.x, 0.0, abs_tol=1e-9), \\\n        \"All shares sold, supply should return to 0.\""
            },
            "tests/amms/test_bondingcurve_arbitrage_manually.py::test_sell_value_no_fees": {
                "testid": "tests/amms/test_bondingcurve_arbitrage_manually.py::test_sell_value_no_fees",
                "result": "passed",
                "test_implementation": "def test_sell_value_no_fees(amm_no_fees):\n    \"\"\"\n    Test selling enough shares to receive scale specific amount of currency with no fees.\n    - The user first buys some shares (buy_value).\n    - Then the user calls `sell_value(...)` to get exactly some currency.\n    Check that the shares sold is consistent and the user breaks even if they buy and sell instantly.\n    \"\"\"\n    amm = amm_no_fees\n\n    # Buy some shares with 500 currency\n    shares_bought = amm.buy_value(500.0)"
            },
            "tests/amms/test_buy_sell_log.py::test_buy_then_sell": {
                "testid": "tests/amms/test_buy_sell_log.py::test_buy_then_sell",
                "result": "passed",
                "test_implementation": "def test_buy_then_sell():\n    amm = LogBondingCurveAMM(scale=10)\n    amm.simulate_buy_shares_then_sell_shares(num_shares=1.0)"
            },
            "tests/curves/test_integral_accuracy.py::test_all_curves": {
                "testid": "tests/curves/test_integral_accuracy.py::test_all_curves",
                "result": "passed",
                "test_implementation": "def test_all_curves():\n    # Test the integral supplied by the curve against numerical integration\n    # for all curves.\n    for curve_cls in all_curves_cls():\n        curve = curve_cls()\n        curve.verify_integral_accuracy(x_values=[0.0, 1.0, 2.0, 3.0, 4.0, 5.0], tolerance=1e-6)"
            },
            "tests/curves/test_scale_convention.py::test_scale_conventions": {
                "testid": "tests/curves/test_scale_convention.py::test_scale_conventions",
                "result": "passed",
                "test_implementation": "def test_scale_conventions():\n    # Test the integral supplied by the curve against numerical integration\n    # for all curves.\n    for curve_cls in all_curves_cls():\n        curve = curve_cls()\n        curve.verify_scale_convention()"
            },
            "tests/curves/test_scale_convention.py::test_initial_price": {
                "testid": "tests/curves/test_scale_convention.py::test_initial_price",
                "result": "passed",
                "test_implementation": "def test_initial_price():\n    # Test the integral supplied by the curve against numerical integration\n    # for all curves.\n    for curve_cls in all_curves_cls():\n        curve = curve_cls()\n        curve.verify_initial_unit_price()"
            },
            "tests/test_examples.py::test_examples": {
                "testid": "tests/test_examples.py::test_examples",
                "result": "passed",
                "test_implementation": "def test_examples():\n    total_investment_value = 1000.0  # Total currency to invest\n    n_trading_opportunities = 10  # Number of splits\n\n    # Single trade approach\n    amm_single = SqrtBondingCurveAMM(scale=1000.0, fee_rate=0.001)\n    shares_single = amm_single.buy_value(total_investment_value)\n    net_single = amm_single.sell_shares(shares_single)\n\n    # Split approach\n    amm_split = SqrtBondingCurveAMM(scale=1000.0, fee_rate=0.001)\n    shares_split = 0.0\n    for _ in range(n_trading_opportunities):\n        shares_split += amm_split.buy_value(total_investment_value / n_trading_opportunities)\n    net_split = amm_split.sell_shares(shares_split)\n\n    print(f\"net_split={net_split}, net_single={net_single}\")\n\n    assert True"
            }
        },
        "SRS_document": "**Software Requirements Specification: Bonding Curves and AMM System**\n\n**Primary Goal of this SRS Document:**\nThis Software Requirements Specification (SRS) document will serve a critical role in assessing software developers. Developers will be provided with this SRS document and a designated subset of the original test cases (public tests). Their objective is to develop a complete, functional software project based *solely* on this SRS. Their final success will be rigorously measured by whether their implementation passes *all original test cases*, including a comprehensive set of private tests not initially provided to them.\n\n**Table of Contents:**\n1. Introduction\n    1.1 Purpose\n    1.2 Scope\n    1.3 Definitions, Acronyms, and Abbreviations\n2. Overall Description\n    2.1 Product Perspective\n    2.2 Product Functions\n    2.3 User Characteristics\n    2.4 General Constraints\n    2.5 Assumptions and Dependencies\n3. Specific Requirements\n    3.1 Functional Requirements\n        3.1.1 General Bonding Curve Requirements\n        3.1.2 Specific Bonding Curve Implementations\n            3.1.2.1 Linear Bonding Curve\n            3.1.2.2 Logarithmic Bonding Curve\n            3.1.2.3 Square Root Bonding Curve\n            3.1.2.4 Growth Bonding Curve\n            3.1.2.5 Exponential Bonding Curve\n        3.1.3 General Automated Market Maker (AMM) Requirements\n        3.1.4 AMM Initialization and Configuration\n        3.1.5 AMM State Management\n        3.1.6 AMM Core Trading Operations\n        3.1.7 AMM Fee Calculation and Quanta Handling\n        3.1.8 AMM Query Operations\n        3.1.9 AMM Behavioral Constraints\n        3.1.10 Curve Utility Functions\n    3.2 Non-Functional Requirements\n        3.2.1 Accuracy Requirements\n    3.3 External Interface Requirements\n        3.3.1 Constants\n    3.4 Input Validation Requirements\n\n---\n\n**1. Introduction**\n\n**1.1 Purpose**\nThis Software Requirements Specification (SRS) document defines the functional and non-functional requirements for a system that implements various bonding curves and Automated Market Makers (AMMs) that utilize these curves. This document is intended to be used by software developers to design, implement, and test the system. Its primary purpose is to serve as the sole specification for a development task aimed at assessing developers' ability to interpret requirements and build a functional system.\n\n**1.2 Scope**\nThe system shall provide:\n*   A framework for defining and using different types of bonding curves.\n*   Implementations of several specific bonding curves: Linear, Logarithmic, Square Root, Growth, and Exponential.\n*   An Automated Market Maker (AMM) mechanism that can operate using any of the provided bonding curves.\n*   Functionality for buying and selling shares/tokens through the AMM, based on either a desired quantity of shares or a desired currency value.\n*   Mechanisms for fee collection and handling of currency quantization.\n\nThe system is not intended to provide a user interface beyond a programmatic API. It is a library to be integrated into other applications or used for simulation and analysis.\n\n**1.3 Definitions, Acronyms, and Abbreviations**\n*   **AMM:** Automated Market Maker. A system that facilitates trading of assets using a predefined algorithm (in this case, a bonding curve) to determine prices.\n*   **Bonding Curve:** A mathematical function that defines the relationship between the price of an asset and its supply.\n*   **Supply (x):** The total number of shares/tokens currently issued or outstanding for a particular asset on the bonding curve.\n*   **Scale:** A parameter for a bonding curve that influences its shape and typically defines the supply `x` at which the price `p(x)` reaches a certain multiple of its initial price `p(0)` (e.g., `p(scale) = 2 * p(0)`).\n*   **Fee Rate:** A proportional rate charged on transactions (buys or sells) by the AMM, collected as revenue.\n*   **Quanta:** The smallest indivisible unit of currency. Transactions are typically rounded to the nearest quanta.\n*   **Breakage Fee:** Currency amount lost or gained due to rounding to the nearest quanta, which is typically collected by the AMM.\n*   **SRS:** Software Requirements Specification.\n*   **FR:** Functional Requirement.\n*   **NFR:** Non-Functional Requirement.\n*   **EIR:** External Interface Requirement.\n\n**2. Overall Description**\n\n**2.1 Product Perspective**\nThe product is a software library providing building blocks for modeling and implementing tokenomics based on bonding curves. It allows for the creation of AMMs that operate according to these curves, handling aspects like fees and currency precision. It is expected to be used by developers in blockchain, DeFi, or simulation contexts.\n\n**2.2 Product Functions**\nThe major functions of the system are:\n*   Definition and calculation of price and price integrals for various bonding curves.\n*   Instantiation of AMMs with specific bonding curves, fee rates, and quanta.\n*   Execution of trades (buy/sell shares or value) through the AMM, updating its internal state (supply, cash reserves, fees collected).\n*   Ensuring trades adhere to defined fee structures and currency quantization.\n*   Preventing arbitrage opportunities within the AMM's own mechanics.\n*   Providing query methods for AMM and curve state.\n\n**2.3 User Characteristics**\nThe primary users of this system will be software developers who need to:\n*   Integrate bonding curve-based market mechanisms into their applications.\n*   Simulate or analyze the behavior of such mechanisms.\nThey are expected to be proficient in Python and familiar with financial/mathematical concepts related to market making.\n\n**2.4 General Constraints**\n*   The system shall be implemented in Python.\n*   The system must be able to support the specific bonding curve types detailed in this SRS.\n*   The AMM logic must be self-contained and operate solely based on its configured curve and parameters.\n\n**2.5 Assumptions and Dependencies**\n*   The mathematical formulas defining the price and integral for each curve type are correctly specified.\n*   Numerical stability for floating-point operations is expected within typical machine precision limits.\n*   The system may optionally use Matplotlib for plotting, but core functionality must not depend on its availability.\n*   The system may optionally use Scipy for numerical verification of integrals (during development/testing of the library itself), but core AMM functionality must not depend on its availability.\n\n**3. Specific Requirements**\n\n**3.1 Functional Requirements**\n\n**3.1.1 General Bonding Curve Requirements**\n*   **FR-BC-GEN-001:** The system shall allow a bonding curve to define an instantaneous price for a given supply `x`.\n*   **FR-BC-GEN-002:** The system shall allow a bonding curve to define the definite integral of its price function from supply 0 to a given supply `x`.\n*   **FR-BC-GEN-003:** The system shall allow a bonding curve to calculate the cost (in currency) to change the supply from a starting supply `x_start` to an ending supply `x_end`. This is typically `price_integral(x_end) - price_integral(x_start)`.\n*   **FR-BC-GEN-004:** All bonding curves shall, by convention, have an initial price of 1 when the supply `x` is 0 (i.e., `price(0) = 1`).\n*   **FR-BC-GEN-005:** All bonding curves shall, by convention, have a price of 2 when the supply `x` is equal to their configured `scale` parameter (i.e., `price(scale) = 2`).\n*   **FR-BC-GEN-006:** Bonding curve price and price integral calculations shall only accept non-negative supply values `x`. An attempt to use a negative supply `x` should be handled as an error.\n\n**3.1.2 Specific Bonding Curve Implementations**\nThe system shall provide the following bonding curve implementations, each configurable with a `scale` parameter (float, positive).\n\n    **3.1.2.1 Linear Bonding Curve**\n    *   **FR-BC-LIN-001:** The system shall provide a Linear Bonding Curve.\n    *   **FR-BC-LIN-002:** The Linear Bonding Curve's price at supply `x` shall be `(1/scale) * x + 1`.\n    *   **FR-BC-LIN-003:** The Linear Bonding Curve's price integral up to supply `x` shall be `(1/(2*scale)) * x^2 + x`.\n\n    **3.1.2.2 Logarithmic Bonding Curve**\n    *   **FR-BC-LOG-001:** The system shall provide a Logarithmic Bonding Curve.\n    *   **FR-BC-LOG-002:** The Logarithmic Bonding Curve's price at supply `x` shall follow the formula `log(e + (e^2 - e) * (x / scale))`.\n    *   **FR-BC-LOG-003:** The Logarithmic Bonding Curve's price integral up to supply `x` shall be calculated analytically consistent with its price formula.\n\n    **3.1.2.3 Square Root Bonding Curve**\n    *   **FR-BC-SQRT-001:** The system shall provide a Square Root Bonding Curve.\n    *   **FR-BC-SQRT-002:** The Square Root Bonding Curve's price at supply `x` shall follow the formula `sqrt(1 + (x/scale)^2)`.\n    *   **FR-BC-SQRT-003:** The Square Root Bonding Curve's price integral up to supply `x` shall be calculated analytically consistent with its price formula.\n\n    **3.1.2.4 Growth Bonding Curve**\n    *   **FR-BC-GRW-001:** The system shall provide a Growth Bonding Curve.\n    *   **FR-BC-GRW-002:** The Growth Bonding Curve shall be configurable with parameters `a` (float, `1+a > 0`) and `c` (float, `c > 1`) in addition to `scale`.\n    *   **FR-BC-GRW-003:** The Growth Bonding Curve's price at supply `x` shall follow the formula `1 + (x^p / scale^p)`, where `p = ln(1+a)/ln(c)`.\n    *   **FR-BC-GRW-004:** The Growth Bonding Curve's price integral up to supply `x` shall be calculated analytically consistent with its price formula.\n\n    **3.1.2.5 Exponential Bonding Curve**\n    *   **FR-BC-EXP-001:** The system shall provide an Exponential Bonding Curve.\n    *   **FR-BC-EXP-002:** The Exponential Bonding Curve's price at supply `x` shall follow the formula `(1 / (e - 1)) * e^(x / scale) + (e - 2) / (e - 1)`.\n    *   **FR-BC-EXP-003:** The Exponential Bonding Curve's price integral up to supply `x` shall be calculated analytically consistent with its price formula.\n\n**3.1.3 General Automated Market Maker (AMM) Requirements**\n*   **FR-AMM-GEN-001:** The system shall provide an Automated Market Maker (AMM) that can operate with any of the specified bonding curve types.\n*   **FR-AMM-GEN-002:** Specific AMM types (LinearBondingCurveAMM, LogBondingCurveAMM, SqrtBondingCurveAMM, ExpBondingCurveAMM, GrowthBondingCurveAMM) shall be provided, pre-configured with their respective curve types.\n\n**3.1.4 AMM Initialization and Configuration**\n*   **FR-AMM-CFG-001:** An AMM instance shall be initialized with a specific bonding curve instance.\n*   **FR-AMM-CFG-002:** An AMM instance shall be configurable with a `fee_rate` (float, typically between 0.0 and 1.0) representing the proportional fee on transactions. Default is 0.0.\n*   **FR-AMM-CFG-003:** An AMM instance shall use a configurable `quanta` value (float, positive) for currency calculations. If not specified, a default value (see EIR-CONST-001) is used.\n\n**3.1.5 AMM State Management**\n*   **FR-AMM-STM-001:** The AMM shall maintain the current total supply of shares (`x`), initialized to 0.0.\n*   **FR-AMM-STM-002:** The AMM shall track the total net cash collected by the curve (i.e., after deducting AMM fees), initialized to 0.0.\n*   **FR-AMM-STM-003:** The AMM shall track the total fees collected (transaction fees and breakage fees), initialized to 0.0.\n\n**3.1.6 AMM Core Trading Operations**\nThe AMM shall provide the following trading operations. All operations must update the AMM's state (supply, cash collected, fees collected) accordingly.\n\n*   **FR-AMM-BUYV-001:** The AMM shall allow a user to buy shares by specifying a `value` of currency they wish to spend.\n    *   The operation shall return the number of shares received.\n    *   The input `value` is processed into `quanta` units; any fractional part less than one `quanta` is considered a breakage fee.\n    *   A transaction fee, based on `fee_rate`, is calculated on the gross currency amount (after quanta adjustment).\n    *   The remaining net currency is used to determine the number of shares purchased based on the bonding curve's `cost_to_move` from the current supply `x` to `x + dx_shares`.\n*   **FR-AMM-BUYS-001:** The AMM shall allow a user to buy a specific `num_shares`.\n    *   The operation shall return the total currency amount the user must pay.\n    *   The cost to acquire `num_shares` (gross cost) is determined from the bonding curve's `cost_to_move` from `x` to `x + num_shares`.\n    *   The total currency the user must pay is calculated such that after deducting the `fee_rate` from this total payment, the remaining amount is sufficient to cover the gross cost. This total payment is rounded up to the nearest `quanta`.\n    *   Any difference arising from rounding up the total payment is considered a breakage fee.\n*   **FR-AMM-SELLS-001:** The AMM shall allow a user to sell a specific `num_shares`.\n    *   The operation shall return the net currency amount the user receives.\n    *   The gross currency obtained from selling `num_shares` is determined from the bonding curve's `cost_to_move` from `x` to `x - num_shares`.\n    *   This gross currency is then processed into `quanta` units; any fractional part less than one `quanta` is a breakage fee (retained by AMM).\n    *   A transaction fee, based on `fee_rate`, is calculated on the quanta-adjusted gross currency.\n    *   The user receives the currency after transaction fees are deducted.\n*   **FR-AMM-SELLV-001:** The AMM shall allow a user to sell shares to receive a target `value` of currency.\n    *   The operation shall return the number of shares sold (as a positive float).\n    *   The target `value` is processed into `quanta` units; any fractional part is a breakage fee.\n    *   The AMM determines the number of shares (`dx_shares`) that need to be sold such that the currency obtained from the curve, after `fee_rate` deduction and quanta adjustment, equals the target `value`.\n    *   The user cannot sell more shares than they effectively have (i.e., current supply `x`).\n*   **FR-AMM-CALC-001:** The AMM must be able to determine the quantity of shares corresponding to a given net currency amount to be credited to/debited from the bonding curve, based on the curve's cost function and current supply.\n    *   This capability is implicitly used in `buy_value` and `sell_value` operations.\n*   **FR-AMM-CALC-002:** The AMM must be able to determine the gross cost required by the bonding curve to acquire a specific number of shares from the current supply.\n    *   This capability is implicitly used in `buy_shares` operations.\n*   **FR-AMM-CALC-003:** The AMM must be able to determine the gross currency obtained from the bonding curve by selling a specific number of shares from the current supply.\n    *   This capability is implicitly used in `sell_shares` operations.\n\n\n**3.1.7 AMM Fee Calculation and Quanta Handling**\n*   **FR-AMM-FEE-001:** A proportional fee, based on the configured `fee_rate`, shall be applied to transactions.\n    *   For buy operations (`buy_value`, `buy_shares`), the fee is a percentage of the currency amount effectively used for the transaction (after initial quanta adjustment for `buy_value`, or part of the total paid for `buy_shares`).\n    *   For sell operations (`sell_shares`, `sell_value`), the fee is a percentage of the currency amount obtained from the curve (after quanta adjustment for `sell_shares`, or part of the target value for `sell_value`).\n    *   Collected fees are tracked separately.\n*   **FR-AMM-FEE-002:** Breakage fees arising from rounding currency amounts to the nearest `quanta` shall be collected by the AMM and tracked.\n    *   When buying with value (`buy_value`), input currency is floored to `quanta`; the remainder is breakage.\n    *   When buying shares (`buy_shares`), total payment is ceiled to `quanta`; the difference to ideal total (if positive) is breakage.\n    *   When selling shares (`sell_shares`), gross currency received is floored to `quanta`; the remainder is breakage.\n    *   When selling for value (`sell_value`), target currency is floored to `quanta`; the remainder is breakage.\n\n**3.1.8 AMM Query Operations**\n*   **FR-AMM-QRY-001:** The AMM shall provide a method to get the maximum net currency value a user can receive by selling all currently available shares (`x`). The returned value must be a multiple of `quanta`.\n*   **FR-AMM-QRY-002:** The AMM shall provide a method to get the total cost (price integral from 0 up to a specified supply `x_val`, or current supply `x` if not specified) according to the bonding curve.\n*   **FR-AMM-QRY-003:** The AMM shall provide a method to get the current instantaneous price from the bonding curve at the AMM's current supply `x`.\n\n**3.1.9 AMM Behavioral Constraints**\n*   **FR-AMM-ARB-001:** The AMM design shall ensure that no arbitrage profit can be made by a user through immediate round-trip trades. This includes:\n    *   Buying shares with a currency value, then immediately selling all purchased shares.\n    *   Buying a specific number of shares, then immediately selling those same shares.\n    *   Selling shares to receive a specific currency value, then immediately using that currency value to buy shares. (Requires sufficient initial shares)\n    *   Selling a specific number of shares, then immediately using the received currency to buy shares. (Requires sufficient initial shares)\n    *   In scenarios with non-zero fees, the user should incur a net loss. In scenarios with zero fees, the user should break even (within floating-point tolerances).\n*   **FR-AMM-ARB-002:** Splitting a single large trade (e.g., buying shares with value `X`) into multiple smaller sequential trades (e.g., `N` trades each buying shares with value `X/N`) and then reversing the total position should not result in a more favorable outcome (i.e., less net cost or more net proceeds) for the user compared to performing the single large trade and its reversal.\n*   **FR-AMM-ZERO-001:** Performing a buy operation with zero currency value shall result in zero shares being bought, zero currency being spent, and no change in AMM state (supply, cash collected, fees collected).\n*   **FR-AMM-ZERO-002:** Performing a sell operation with zero shares shall result in zero currency being received, zero shares being sold, and no change in AMM state.\n\n**3.1.10 Curve Utility Functions**\n*   **FR-BC-UTIL-001:** Bonding curves shall provide a utility to generate a plot of their price and price integral functions over a specified range of supply `x`. This functionality is contingent on the availability of a compatible plotting library (e.g., Matplotlib) in the environment. If the library is unavailable, the function should indicate this gracefully (e.g., print a message).\n\n**3.2 Non-Functional Requirements**\n\n**3.2.1 Accuracy Requirements**\n*   **NFR-ACC-001:** The analytical price integral calculation for all bonding curve implementations must be accurate within a relative or absolute tolerance of 1e-6 when compared to a standard numerical integration method (e.g., `scipy.integrate.quad`) over a range of `x` values including 0.0, 1.0, 2.0, 3.0, 4.0, and 5.0.\n\n**3.3 External Interface Requirements**\n\n**3.3.1 Constants**\n*   **EIR-CONST-001:** The system shall use a default currency `quanta` value of `1e-8` for AMM operations if no other `quanta` is specified during AMM initialization.\n\n**3.4 Input Validation Requirements**\n*   **FR-VALID-001:** All AMM trading operations (`buy_value`, `buy_shares`, `sell_shares`, `sell_value`) must validate that input currency values or share quantities are non-negative. Attempts to use negative values shall result in an error.\n*   **FR-VALID-002:** The `sell_shares` operation must validate that the number of shares to sell does not exceed the current AMM supply (`x`). Attempts to sell more shares than available shall result in an error.\n*   **FR-VALID-003:** The `sell_value` operation must validate that selling shares to achieve the target currency value does not require selling more shares than the current AMM supply (`x`). Attempts to do so shall result in an error.\n*   **FR-VALID-004:** Bonding curve constructors requiring a `scale` parameter must validate that `scale` is positive. Attempts to use a non-positive scale shall result in an error.\n*   **FR-VALID-005:** The `GrowthBondingCurve` constructor must validate its specific parameters: `(1+a) > 0` and `c > 1`. Attempts to use invalid parameters shall result in an error.",
        "structured_requirements": [
            {
                "requirement_id": "FR-BC-GEN-001",
                "requirement_description": "The system shall allow a bonding curve to define an instantaneous price for a given supply `x`.",
                "test_traceability": [
                    {
                        "id": "Indirectly tested by all AMM buy/sell operations and curve-specific tests.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/bondingcurve.py::BondingCurve::price",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BC-GEN-002",
                "requirement_description": "The system shall allow a bonding curve to define the definite integral of its price function from supply 0 to a given supply `x`.",
                "test_traceability": [
                    {
                        "id": "tests/curves/test_integral_accuracy.py::test_all_curves",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/bondingcurve.py::BondingCurve::price_integral",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BC-GEN-003",
                "requirement_description": "The system shall allow a bonding curve to calculate the cost (in currency) to change the supply from a starting supply `x_start` to an ending supply `x_end`. This is typically `price_integral(x_end) - price_integral(x_start)`.",
                "test_traceability": [
                    {
                        "id": "Indirectly tested by all AMM buy/sell operations.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/bondingcurve.py::BondingCurve::cost_to_move",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BC-GEN-004",
                "requirement_description": "All bonding curves shall, by convention, have an initial price of 1 when the supply `x` is 0 (i.e., `price(0) = 1`).",
                "test_traceability": [
                    {
                        "id": "tests/curves/test_scale_convention.py::test_initial_price",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/bondingcurve.py::BondingCurve::verify_initial_unit_price",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BC-GEN-005",
                "requirement_description": "All bonding curves shall, by convention, have a price of 2 when the supply `x` is equal to their configured `scale` parameter (i.e., `price(scale) = 2`).",
                "test_traceability": [
                    {
                        "id": "tests/curves/test_scale_convention.py::test_scale_conventions",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/bondingcurve.py::BondingCurve::verify_scale_convention",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BC-GEN-006",
                "requirement_description": "Bonding curve price and price integral calculations shall only accept non-negative supply values `x`. An attempt to use a negative supply `x` should be handled as an error.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis",
                        "description": "ValueError checks in curve methods"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "e.g., `bonding/curves/logbondingcurve.py::LogBondingCurve::price`",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BC-LIN-001",
                "requirement_description": "The system shall provide a Linear Bonding Curve.",
                "test_traceability": [
                    {
                        "id": "tests/curves/test_integral_accuracy.py::test_all_curves",
                        "description": "when LinearBondingCurve is included"
                    },
                    {
                        "id": "tests/curves/test_scale_convention.py",
                        "description": "when LinearBondingCurve is included"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/linearbondingcurve.py::LinearBondingCurve",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BC-LIN-002",
                "requirement_description": "The Linear Bonding Curve's price at supply `x` shall be `(1/scale) * x + 1`.",
                "test_traceability": [
                    {
                        "id": "Implicitly via `test_initial_price`",
                        "description": ""
                    },
                    {
                        "id": "`test_scale_conventions`",
                        "description": ""
                    },
                    {
                        "id": "`test_integral_accuracy`",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/linearbondingcurve.py::LinearBondingCurve::price",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BC-LIN-003",
                "requirement_description": "The Linear Bonding Curve's price integral up to supply `x` shall be `(1/(2*scale)) * x^2 + x`.",
                "test_traceability": [
                    {
                        "id": "tests/curves/test_integral_accuracy.py::test_all_curves",
                        "description": "for LinearBondingCurve"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/linearbondingcurve.py::LinearBondingCurve::price_integral",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BC-LOG-001",
                "requirement_description": "The system shall provide a Logarithmic Bonding Curve.",
                "test_traceability": [
                    {
                        "id": "tests/curves/test_integral_accuracy.py::test_all_curves",
                        "description": "for LogBondingCurve"
                    },
                    {
                        "id": "tests/curves/test_scale_convention.py",
                        "description": "for LogBondingCurve"
                    },
                    {
                        "id": "tests/curves/debug_numerical_integration_log.py::debug_integral",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/logbondingcurve.py::LogBondingCurve",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BC-LOG-002",
                "requirement_description": "The Logarithmic Bonding Curve's price at supply `x` shall follow the formula `log(e + (e^2 - e) * (x / scale))`.",
                "test_traceability": [
                    {
                        "id": "Implicitly via `test_initial_price`",
                        "description": ""
                    },
                    {
                        "id": "`test_scale_conventions`",
                        "description": ""
                    },
                    {
                        "id": "`test_integral_accuracy`",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/logbondingcurve.py::LogBondingCurve::price",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BC-LOG-003",
                "requirement_description": "The Logarithmic Bonding Curve's price integral up to supply `x` shall be calculated analytically consistent with its price formula.",
                "test_traceability": [
                    {
                        "id": "tests/curves/test_integral_accuracy.py::test_all_curves",
                        "description": "for LogBondingCurve"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/logbondingcurve.py::LogBondingCurve::price_integral",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BC-SQRT-001",
                "requirement_description": "The system shall provide a Square Root Bonding Curve.",
                "test_traceability": [
                    {
                        "id": "tests/curves/test_integral_accuracy.py::test_all_curves",
                        "description": "for SqrtBondingCurve"
                    },
                    {
                        "id": "tests/curves/test_scale_convention.py",
                        "description": "for SqrtBondingCurve"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/sqrtbondingcurve.py::SqrtBondingCurve",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BC-SQRT-002",
                "requirement_description": "The Square Root Bonding Curve's price at supply `x` shall follow the formula `sqrt(1 + (x/scale)^2)`.",
                "test_traceability": [
                    {
                        "id": "Implicitly via `test_initial_price`",
                        "description": ""
                    },
                    {
                        "id": "`test_scale_conventions`",
                        "description": ""
                    },
                    {
                        "id": "`test_integral_accuracy`",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/sqrtbondingcurve.py::SqrtBondingCurve::price",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BC-SQRT-003",
                "requirement_description": "The Square Root Bonding Curve's price integral up to supply `x` shall be calculated analytically consistent with its price formula.",
                "test_traceability": [
                    {
                        "id": "tests/curves/test_integral_accuracy.py::test_all_curves",
                        "description": "for SqrtBondingCurve"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/sqrtbondingcurve.py::SqrtBondingCurve::price_integral",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BC-GRW-001",
                "requirement_description": "The system shall provide a Growth Bonding Curve.",
                "test_traceability": [
                    {
                        "id": "tests/curves/test_integral_accuracy.py::test_all_curves",
                        "description": "for GrowthBondingCurve"
                    },
                    {
                        "id": "tests/curves/test_scale_convention.py",
                        "description": "for GrowthBondingCurve"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/growthbondingcurve.py::GrowthBondingCurve",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BC-GRW-002",
                "requirement_description": "The Growth Bonding Curve shall be configurable with parameters `a` (float, `1+a > 0`) and `c` (float, `c > 1`) in addition to `scale`.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/growthbondingcurve.py::GrowthBondingCurve::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BC-GRW-003",
                "requirement_description": "The Growth Bonding Curve's price at supply `x` shall follow the formula `1 + (x^p / scale^p)`, where `p = ln(1+a)/ln(c)`.",
                "test_traceability": [
                    {
                        "id": "Implicitly via `test_initial_price`",
                        "description": ""
                    },
                    {
                        "id": "`test_scale_conventions`",
                        "description": ""
                    },
                    {
                        "id": "`test_integral_accuracy`",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/growthbondingcurve.py::GrowthBondingCurve::price",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BC-GRW-004",
                "requirement_description": "The Growth Bonding Curve's price integral up to supply `x` shall be calculated analytically consistent with its price formula.",
                "test_traceability": [
                    {
                        "id": "tests/curves/test_integral_accuracy.py::test_all_curves",
                        "description": "for GrowthBondingCurve"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/growthbondingcurve.py::GrowthBondingCurve::price_integral",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BC-EXP-001",
                "requirement_description": "The system shall provide an Exponential Bonding Curve.",
                "test_traceability": [
                    {
                        "id": "tests/curves/test_integral_accuracy.py::test_all_curves",
                        "description": "for ExpBondingCurve"
                    },
                    {
                        "id": "tests/curves/test_scale_convention.py",
                        "description": "for ExpBondingCurve"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/expbondingcurve.py::ExpBondingCurve",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BC-EXP-002",
                "requirement_description": "The Exponential Bonding Curve's price at supply `x` shall follow the formula `(1 / (e - 1)) * e^(x / scale) + (e - 2) / (e - 1)`.",
                "test_traceability": [
                    {
                        "id": "Implicitly via `test_initial_price`",
                        "description": ""
                    },
                    {
                        "id": "`test_scale_conventions`",
                        "description": ""
                    },
                    {
                        "id": "`test_integral_accuracy`",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/expbondingcurve.py::ExpBondingCurve::price",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BC-EXP-003",
                "requirement_description": "The Exponential Bonding Curve's price integral up to supply `x` shall be calculated analytically consistent with its price formula.",
                "test_traceability": [
                    {
                        "id": "tests/curves/test_integral_accuracy.py::test_all_curves",
                        "description": "for ExpBondingCurve"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/expbondingcurve.py::ExpBondingCurve::price_integral",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-GEN-001",
                "requirement_description": "The system shall provide an Automated Market Maker (AMM) that can operate with any of the specified bonding curve types.",
                "test_traceability": [
                    {
                        "id": "tests/amms/test_arbitrage.py::test_all_amms_arbitrage",
                        "description": "checks for existence of methods across AMM types"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM",
                        "description": ""
                    },
                    {
                        "id": "bonding/amms/allamms.py",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-GEN-002",
                "requirement_description": "Specific AMM types (LinearBondingCurveAMM, LogBondingCurveAMM, SqrtBondingCurveAMM, ExpBondingCurveAMM, GrowthBondingCurveAMM) shall be provided, pre-configured with their respective curve types.",
                "test_traceability": [
                    {
                        "id": "tests/amms/test_arbitrage.py::test_buy_shares_then_sell_shares",
                        "description": "iterates through AMMs from `all_amm_cls`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/allamms.py",
                        "description": ""
                    },
                    {
                        "id": "individual AMM files",
                        "description": "e.g., `bonding/amms/linearbondingcurveamm.py`"
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-CFG-001",
                "requirement_description": "An AMM instance shall be initialized with a specific bonding curve instance.",
                "test_traceability": [
                    {
                        "id": "Derived from constructor signatures and usage in tests",
                        "description": "e.g., `tests/amms/test_bondingcurve_arbitrage_manually.py::amm_with_fees`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-CFG-002",
                "requirement_description": "An AMM instance shall be configurable with a `fee_rate` (float, typically between 0.0 and 1.0) representing the proportional fee on transactions. Default is 0.0.",
                "test_traceability": [
                    {
                        "id": "tests/amms/test_bondingcurve_arbitrage_manually.py::amm_with_fees",
                        "description": ""
                    },
                    {
                        "id": "`amm_no_fees`",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-CFG-003",
                "requirement_description": "An AMM instance shall use a configurable `quanta` value (float, positive) for currency calculations. If not specified, a default value (see EIR-CONST-001) is used.",
                "test_traceability": [
                    {
                        "id": "Derived from constructor signature",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-STM-001",
                "requirement_description": "The AMM shall maintain the current total supply of shares (`x`), initialized to 0.0.",
                "test_traceability": [
                    {
                        "id": "Implicitly tested by all trade operations that modify supply",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::x",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-STM-002",
                "requirement_description": "The AMM shall track the total net cash collected by the curve (i.e., after deducting AMM fees), initialized to 0.0.",
                "test_traceability": [
                    {
                        "id": "Implicitly tested by buy/sell operations",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::total_cash_collected",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-STM-003",
                "requirement_description": "The AMM shall track the total fees collected (transaction fees and breakage fees), initialized to 0.0.",
                "test_traceability": [
                    {
                        "id": "Implicitly tested by buy/sell operations",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::total_fees_collected",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-BUYV-001",
                "requirement_description": "The AMM shall allow a user to buy shares by specifying a `value` of currency they wish to spend.\n*   The operation shall return the number of shares received.\n*   The input `value` is processed into `quanta` units; any fractional part less than one `quanta` is considered a breakage fee.\n*   A transaction fee, based on `fee_rate`, is calculated on the gross currency amount (after quanta adjustment).\n*   The remaining net currency is used to determine the number of shares purchased based on the bonding curve's `cost_to_move` from the current supply `x` to `x + dx_shares`.",
                "test_traceability": [
                    {
                        "id": "tests/amms/test_bondingcurve_arbitrage_manually.py::test_no_arbitrage_immediate_round_trip_with_fees",
                        "description": "buy part"
                    },
                    {
                        "id": "test_no_arbitrage_immediate_round_trip_no_fees",
                        "description": "buy part"
                    },
                    {
                        "id": "tests/amms/test_bondingcurve_arbitrage_manually.py::test_zero_trade_no_change",
                        "description": "buy part"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::buy_value",
                        "description": ""
                    },
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::simulate_buy_value",
                        "description": "logic"
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-BUYS-001",
                "requirement_description": "The AMM shall allow a user to buy a specific `num_shares`.\n*   The operation shall return the total currency amount the user must pay.\n*   The cost to acquire `num_shares` (gross cost) is determined from the bonding curve's `cost_to_move` from `x` to `x + num_shares`.\n*   The total currency the user must pay is calculated such that after deducting the `fee_rate` from this total payment, the remaining amount is sufficient to cover the gross cost. This total payment is rounded up to the nearest `quanta`.\n*   Any difference arising from rounding up the total payment is considered a breakage fee.",
                "test_traceability": [
                    {
                        "id": "tests/amms/test_bondingcurve_arbitrage_manually.py::test_buy_shares_no_fees",
                        "description": ""
                    },
                    {
                        "id": "tests/amms/test_bondingcurve_arbitrage_manually.py::test_buy_shares_with_fees",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::buy_shares",
                        "description": ""
                    },
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::simulate_buy_shares",
                        "description": "logic"
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-SELLS-001",
                "requirement_description": "The AMM shall allow a user to sell a specific `num_shares`.\n*   The operation shall return the net currency amount the user receives.\n*   The gross currency obtained from selling `num_shares` is determined from the bonding curve's `cost_to_move` from `x` to `x - num_shares`.\n*   This gross currency is then processed into `quanta` units; any fractional part less than one `quanta` is a breakage fee (retained by AMM).\n*   A transaction fee, based on `fee_rate`, is calculated on the quanta-adjusted gross currency.\n*   The user receives the currency after transaction fees are deducted.",
                "test_traceability": [
                    {
                        "id": "tests/amms/test_bondingcurve_arbitrage_manually.py::test_no_arbitrage_immediate_round_trip_with_fees",
                        "description": "sell part"
                    },
                    {
                        "id": "test_no_arbitrage_immediate_round_trip_no_fees",
                        "description": "sell part"
                    },
                    {
                        "id": "tests/amms/test_bondingcurve_arbitrage_manually.py::test_zero_trade_no_change",
                        "description": "sell part"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::sell_shares",
                        "description": ""
                    },
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::simulate_sell_shares",
                        "description": "logic"
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-SELLV-001",
                "requirement_description": "The AMM shall allow a user to sell shares to receive a target `value` of currency.\n*   The operation shall return the number of shares sold (as a positive float).\n*   The target `value` is processed into `quanta` units; any fractional part is a breakage fee.\n*   The AMM determines the number of shares (`dx_shares`) that need to be sold such that the currency obtained from the curve, after `fee_rate` deduction and quanta adjustment, equals the target `value`.\n*   The user cannot sell more shares than they effectively have (i.e., current supply `x`).",
                "test_traceability": [
                    {
                        "id": "Indirectly via `bonding/amms/bondingcurveamm.py::BondingCurveAMM::simulate_sell_value_then_buy_shares`",
                        "description": "as used by `assert_no_round_trip_arbitrage`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::sell_value",
                        "description": ""
                    },
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::simulate_sell_value",
                        "description": "logic"
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-CALC-001",
                "requirement_description": "The AMM must be able to determine the quantity of shares corresponding to a given net currency amount to be credited to/debited from the bonding curve, based on the curve's cost function and current supply.\n*   This capability is implicitly used in `buy_value` and `sell_value` operations.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis of `_solve_for_dx` and its usage",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::_solve_for_dx",
                        "description": "abstraction of its purpose"
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-CALC-002",
                "requirement_description": "The AMM must be able to determine the gross cost required by the bonding curve to acquire a specific number of shares from the current supply.\n*   This capability is implicitly used in `buy_shares` operations.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis of `simulate_buy_shares`",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::simulate_buy_shares",
                        "description": "gross_cost calculation part"
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-CALC-003",
                "requirement_description": "The AMM must be able to determine the gross currency obtained from the bonding curve by selling a specific number of shares from the current supply.\n*   This capability is implicitly used in `sell_shares` operations.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis of `simulate_sell_shares`",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::simulate_sell_shares",
                        "description": "gross_currency calculation part"
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-FEE-001",
                "requirement_description": "A proportional fee, based on the configured `fee_rate`, shall be applied to transactions.\n*   For buy operations (`buy_value`, `buy_shares`), the fee is a percentage of the currency amount effectively used for the transaction (after initial quanta adjustment for `buy_value`, or part of the total paid for `buy_shares`).\n*   For sell operations (`sell_shares`, `sell_value`), the fee is a percentage of the currency amount obtained from the curve (after quanta adjustment for `sell_shares`, or part of the target value for `sell_value`).\n*   Collected fees are tracked separately.",
                "test_traceability": [
                    {
                        "id": "tests/amms/test_bondingcurve_arbitrage_manually.py::test_no_arbitrage_immediate_round_trip_with_fees",
                        "description": ""
                    },
                    {
                        "id": "test_buy_shares_with_fees",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "Logic within `simulate_buy_value`",
                        "description": ""
                    },
                    {
                        "id": "`simulate_buy_shares`",
                        "description": ""
                    },
                    {
                        "id": "`simulate_sell_shares`",
                        "description": ""
                    },
                    {
                        "id": "`simulate_sell_value`",
                        "description": "in `bonding/amms/bondingcurveamm.py`"
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-FEE-002",
                "requirement_description": "Breakage fees arising from rounding currency amounts to the nearest `quanta` shall be collected by the AMM and tracked.\n*   When buying with value (`buy_value`), input currency is floored to `quanta`; the remainder is breakage.\n*   When buying shares (`buy_shares`), total payment is ceiled to `quanta`; the difference to ideal total (if positive) is breakage.\n*   When selling shares (`sell_shares`), gross currency received is floored to `quanta`; the remainder is breakage.\n*   When selling for value (`sell_value`), target currency is floored to `quanta`; the remainder is breakage.",
                "test_traceability": [
                    {
                        "id": "Implicitly tested by operations involving fees and quanta",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "Logic within `simulate_buy_value`",
                        "description": ""
                    },
                    {
                        "id": "`simulate_buy_shares`",
                        "description": ""
                    },
                    {
                        "id": "`simulate_sell_shares`",
                        "description": ""
                    },
                    {
                        "id": "`simulate_sell_value`",
                        "description": "in `bonding/amms/bondingcurveamm.py`"
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-QRY-001",
                "requirement_description": "The AMM shall provide a method to get the maximum net currency value a user can receive by selling all currently available shares (`x`). The returned value must be a multiple of `quanta`.",
                "test_traceability": [
                    {
                        "id": "Used in `examples/example_round_trip_value.py`",
                        "description": ""
                    },
                    {
                        "id": "`bonding/amms/bondingcurveamm.py::BondingCurveAMM::assert_no_round_trip_arbitrage`",
                        "description": "conditionally"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::get_maximum_sell_value",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-QRY-002",
                "requirement_description": "The AMM shall provide a method to get the total cost (price integral from 0 up to a specified supply `x_val`, or current supply `x` if not specified) according to the bonding curve.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::total_cost_at_supply",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-QRY-003",
                "requirement_description": "The AMM shall provide a method to get the current instantaneous price from the bonding curve at the AMM's current supply `x`.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::current_price",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-ARB-001",
                "requirement_description": "The AMM design shall ensure that no arbitrage profit can be made by a user through immediate round-trip trades. This includes:\n*   Buying shares with a currency value, then immediately selling all purchased shares.\n*   Buying a specific number of shares, then immediately selling those same shares.\n*   Selling shares to receive a specific currency value, then immediately using that currency value to buy shares. (Requires sufficient initial shares)\n*   Selling a specific number of shares, then immediately using the received currency to buy shares. (Requires sufficient initial shares)\n*   In scenarios with non-zero fees, the user should incur a net loss. In scenarios with zero fees, the user should break even (within floating-point tolerances).",
                "test_traceability": [
                    {
                        "id": "tests/amms/test_arbitrage.py::test_all_amms_arbitrage",
                        "description": "calls `assert_no_round_trip_arbitrage`"
                    },
                    {
                        "id": "tests/amms/test_bondingcurve_arbitrage_manually.py::test_no_arbitrage_immediate_round_trip_with_fees",
                        "description": ""
                    },
                    {
                        "id": "tests/amms/test_bondingcurve_arbitrage_manually.py::test_no_arbitrage_immediate_round_trip_no_fees",
                        "description": ""
                    },
                    {
                        "id": "tests/amms/test_arbitrage_log.py::test_log_bonding_curve_amm",
                        "description": ""
                    },
                    {
                        "id": "tests/amms/test_buy_sell_log.py::test_buy_then_sell",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::assert_no_round_trip_arbitrage",
                        "description": "and its helper simulation methods"
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-ARB-002",
                "requirement_description": "Splitting a single large trade (e.g., buying shares with value `X`) into multiple smaller sequential trades (e.g., `N` trades each buying shares with value `X/N`) and then reversing the total position should not result in a more favorable outcome (i.e., less net cost or more net proceeds) for the user compared to performing the single large trade and its reversal.",
                "test_traceability": [
                    {
                        "id": "tests/amms/test_bondingcurve_arbitrage_manually.py::test_split_vs_single_trade_no_free_arbitrage",
                        "description": ""
                    },
                    {
                        "id": "tests/test_examples.py::test_examples",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "Derived from test case logic comparing split vs. single trades",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-ZERO-001",
                "requirement_description": "Performing a buy operation with zero currency value shall result in zero shares being bought, zero currency being spent, and no change in AMM state (supply, cash collected, fees collected).",
                "test_traceability": [
                    {
                        "id": "tests/amms/test_bondingcurve_arbitrage_manually.py::test_zero_trade_no_change",
                        "description": "buy part"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::buy_value",
                        "description": "handling of value=0"
                    }
                ]
            },
            {
                "requirement_id": "FR-AMM-ZERO-002",
                "requirement_description": "Performing a sell operation with zero shares shall result in zero currency being received, zero shares being sold, and no change in AMM state.",
                "test_traceability": [
                    {
                        "id": "tests/amms/test_bondingcurve_arbitrage_manually.py::test_zero_trade_no_change",
                        "description": "sell part"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::sell_shares",
                        "description": "handling of num_shares=0"
                    }
                ]
            },
            {
                "requirement_id": "FR-BC-UTIL-001",
                "requirement_description": "Bonding curves shall provide a utility to generate a plot of their price and price integral functions over a specified range of supply `x`. This functionality is contingent on the availability of a compatible plotting library (e.g., Matplotlib) in the environment. If the library is unavailable, the function should indicate this gracefully (e.g., print a message).",
                "test_traceability": [
                    {
                        "id": "No direct test for plot output",
                        "description": ""
                    },
                    {
                        "id": "but behavior is described. README shows usage.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/bondingcurve.py::BondingCurve::plot",
                        "description": ""
                    },
                    {
                        "id": "bonding/curveplots/matplotlibcurveplot.py",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "NFR-ACC-001",
                "requirement_description": "The analytical price integral calculation for all bonding curve implementations must be accurate within a relative or absolute tolerance of 1e-6 when compared to a standard numerical integration method (e.g., `scipy.integrate.quad`) over a range of `x` values including 0.0, 1.0, 2.0, 3.0, 4.0, and 5.0.",
                "test_traceability": [
                    {
                        "id": "tests/curves/test_integral_accuracy.py::test_all_curves",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/bondingcurve.py::BondingCurve::verify_integral_accuracy",
                        "description": ""
                    },
                    {
                        "id": "bonding/curves/verifyintegralaccuracy.py",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-CONST-001",
                "requirement_description": "The system shall use a default currency `quanta` value of `1e-8` for AMM operations if no other `quanta` is specified during AMM initialization.",
                "test_traceability": [
                    {
                        "id": "Implicitly used by AMMs if not overridden",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/ammdefaultparams.py::QUANTA",
                        "description": ""
                    },
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::__init__",
                        "description": "default parameter value"
                    }
                ]
            },
            {
                "requirement_id": "FR-VALID-001",
                "requirement_description": "All AMM trading operations (`buy_value`, `buy_shares`, `sell_shares`, `sell_value`) must validate that input currency values or share quantities are non-negative. Attempts to use negative values shall result in an error.",
                "test_traceability": [
                    {
                        "id": "Derived from `ValueError` exceptions in source code",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "e.g., `bonding/amms/bondingcurveamm.py::BondingCurveAMM::simulate_buy_value`",
                        "description": "checks `total_value < 0`"
                    }
                ]
            },
            {
                "requirement_id": "FR-VALID-002",
                "requirement_description": "The `sell_shares` operation must validate that the number of shares to sell does not exceed the current AMM supply (`x`). Attempts to sell more shares than available shall result in an error.",
                "test_traceability": [
                    {
                        "id": "Derived from `ValueError` exceptions in source code",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::simulate_sell_shares",
                        "description": "checks `num_shares > self.x`"
                    }
                ]
            },
            {
                "requirement_id": "FR-VALID-003",
                "requirement_description": "The `sell_value` operation must validate that selling shares to achieve the target currency value does not require selling more shares than the current AMM supply (`x`). Attempts to do so shall result in an error.",
                "test_traceability": [
                    {
                        "id": "Derived from `ValueError` exceptions in source code",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/amms/bondingcurveamm.py::BondingCurveAMM::sell_value",
                        "description": "checks `self.x + dx < 0`"
                    }
                ]
            },
            {
                "requirement_id": "FR-VALID-004",
                "requirement_description": "Bonding curve constructors requiring a `scale` parameter must validate that `scale` is positive. Attempts to use a non-positive scale shall result in an error.",
                "test_traceability": [
                    {
                        "id": "Derived from `ValueError` exceptions in source code",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "e.g., `bonding/curves/logbondingcurve.py::LogBondingCurve::__init__`",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-VALID-005",
                "requirement_description": "The `GrowthBondingCurve` constructor must validate its specific parameters: `(1+a) > 0` and `c > 1`. Attempts to use invalid parameters shall result in an error.",
                "test_traceability": [
                    {
                        "id": "Derived from `ValueError` exceptions in source code",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "bonding/curves/growthbondingcurve.py::GrowthBondingCurve::__init__",
                        "description": ""
                    }
                ]
            }
        ],
        "full_code_skeleton": "--- File: bonding.py ---\n```python\npass\n```\n--- File: examples/__init__.py ---\n```python\npass\n```\n--- File: bonding/__init__.py ---\n```python\npass\n```\n--- File: bonding/amms/linearbondingcurveamm.py ---\n```python\nclass LinearBondingCurveAMM(BondingCurveAMM):\n    def __init__(self, scale=500_000, fee_rate: float = 0.0):\n        pass\n```\n--- File: bonding/amms/allamms.py ---\n```python\ndef all_amm_cls():\n    pass\n```\n--- File: bonding/amms/__init__.py ---\n```python\npass\n```\n--- File: bonding/amms/bondingcurveamm.py ---\n```python\nclass BondingCurveAMM:\n    \"\"\"\n    A simple Automated Market Maker (AMM) that uses a given BondingCurve\n    to determine pricing, while handling transaction fees, rounding, and state tracking.\n\n    Attributes\n    ----------\n    curve : BondingCurve\n        The amms curve instance that defines price and integral logic.\n    fee_rate : float\n        Fraction of each transaction (buy or sell) collected as fees. 0.001 => 0.1%.\n    quanta : float\n        Defines the smallest currency denomination (1e-8).\n    x : float\n        Current total minted/sold (the \"supply\" on the amms curve).\n    total_cash_collected : float\n        Total amount of currency that the amms curve has collected (this excludes fees).\n    total_fees_collected : float\n        Total amount of currency collected as fees.\n    logger : logging.Logger\n        Logger instance for logging events and errors.\n    \"\"\"\n\n    def __init__(self, curve, fee_rate=0.0, quanta=QUANTA):\n        \"\"\"\n        Initialize the BondingCurveAMM.\n\n        Parameters\n        ----------\n        curve : BondingCurve\n            A amms curve instance (e.g. SqrtBondingCurve).\n        fee_rate : float, optional\n            Fraction of each transaction (buy or sell) to be taken as fees (0.001 => 0.1%).\n        quanta : float, optional\n            Defines the smallest currency denomination (1e-8). Defaults to QUANTA.\n        \"\"\"\n        pass\n\n    def _solve_for_dx(self, x_start: float, target_cost: float,\n                      tolerance=1e-12, max_iter=200) -> float:\n        \"\"\"\n        Solve for dx such that cost_to_move(x_start, x_start + dx) = target_cost\n        using the bisection method.\n\n        Returns\n        -------\n        float\n            dx (positive if buying, negative if selling).\n        \"\"\"\n        pass\n\n    def simulate_buy_value(self, total_value: float):\n        \"\"\"\n        Simulate buying with `total_value` currency.\n\n        Returns a dict with:\n            {\n                'quanta_used': int,\n                'breakage_fee': float,\n                'fee_amount': float,\n                'net_currency': float,   # actual currency that goes into the curve\n                'shares_received': float\n            }\n        \"\"\"\n        pass\n\n    def simulate_buy_shares(self, num_shares: float):\n        \"\"\"\n        Simulate buying exactly `num_shares`, determining how much currency is required.\n\n        Returns a dict with:\n            {\n                'gross_cost': float,     # The net cost (without fees) required by the curve\n                'quanta_used': int,\n                'breakage_fee': float,\n                'fee_amount': float,\n                'total_paid': float,     # The total currency user must pay\n            }\n        \"\"\"\n        pass\n\n    def simulate_sell_shares(self, num_shares: float):\n        \"\"\"\n        Simulate selling `num_shares` from the current supply.\n\n        Returns a dict with:\n            {\n                'gross_currency': float,\n                'quanta_used': int,\n                'breakage_fee': float,\n                'fee_amount': float,\n                'net_currency': float,\n            }\n        \"\"\"\n        pass\n\n    def simulate_sell_value(self, target_value: float):\n        \"\"\"\n        Simulate selling enough shares to receive `target_value` total currency.\n\n        Returns a dict with:\n            {\n                'quanta_used': int,\n                'breakage_fee': float,\n                'fee_amount': float,\n                'gross_currency': float,\n                'net_currency': float,\n                'shares_sold': float\n            }\n        \"\"\"\n        pass\n\n    def buy_value(self, value: float) -> float:\n        \"\"\"\n        The user spends `value` currency to buy shares.\n        Returns the number of shares actually purchased.\n        \"\"\"\n        pass\n\n    def buy_shares(self, num_shares: float) -> float:\n        \"\"\"\n        The user wants to buy exactly `num_shares`.\n        Returns the total currency they actually paid.\n        \"\"\"\n        pass\n\n    def sell_shares(self, num_shares: float) -> float:\n        \"\"\"\n        Sell exactly `num_shares`, returning the net currency the user receives.\n        \"\"\"\n        pass\n\n    def sell_value(self, value: float) -> float:\n        \"\"\"\n        Sell enough shares to receive `value` currency (in total).\n        Returns the number of shares sold (positive float).\n        \"\"\"\n        pass\n\n    def get_maximum_sell_value(self) -> float:\n        \"\"\"\n        Returns the maximum net currency value one can extract by selling all shares (curve.x).\n        \"\"\"\n        pass\n\n    def total_cost_at_supply(self, x_val: float = None) -> float:\n        \"\"\"\n        Returns the integral of the price from 0 to x_val (or curve.x).\n        \"\"\"\n        pass\n\n    def current_price(self) -> float:\n        \"\"\"\n        Returns the instantaneous price at supply curve.x.\n        \"\"\"\n        pass\n\n    def __repr__(self) -> str:\n        pass\n\n    def simulate_buy_value_then_sell_shares(self, buy_value: float = 1.0):\n        \"\"\"\n        Simulate spending `buy_value` currency to buy shares, and then\n        immediately selling *all* those purchased shares.\n\n        Returns\n        -------\n        dict\n            {\n                'initial_currency': float,\n                'final_currency': float,\n                'net_delta': float,\n                'buy_sim': dict,      # output of simulate_buy_value(...)\n                'sell_sim': dict,     # output of simulate_sell_shares(...)\n                'arbitrage': bool,    # True if net_delta > 0\n            }\n        \"\"\"\n        pass\n\n    def simulate_buy_shares_then_sell_shares(self, num_shares: float = 1.0):\n        \"\"\"\n        Simulate buying exactly `num_shares`, then immediately selling\n        those same shares.\n\n        Returns\n        -------\n        dict\n            {\n                'shares_bought': float,\n                'currency_spent': float,    # total_paid from buy_shares\n                'currency_received': float, # net_currency from sell_shares\n                'net_delta': float,\n                'arbitrage': bool\n            }\n        \"\"\"\n        pass\n\n    def simulate_sell_value_then_buy_shares(self, target_value: float = 1.0):\n        \"\"\"\n        Simulate selling enough shares to receive exactly `target_value` currency,\n        then use the *net* proceeds to buy shares again.\n\n        Returns\n        -------\n        dict\n            {\n                'target_value': float,\n                'shares_sold': float,          # positive\n                'buy_shares_received': float,  # how many shares we get from the net currency\n                'shares_delta': float,         # (buy_shares_received - shares_sold)\n                'arbitrage': bool\n            }\n        \"\"\"\n        pass\n\n    def simulate_sell_shares_then_buy_value(self, shares_to_sell: float = 1.0):\n        \"\"\"\n        Simulate selling exactly `shares_to_sell`, then use the net proceeds\n        to buy as much as possible of the AMM (buy_value) with that currency.\n\n        Returns\n        -------\n        dict\n            {\n                'shares_sold': float,\n                'currency_received': float,\n                'shares_bought': float,\n                'shares_delta': float,\n                'arbitrage': bool\n            }\n        \"\"\"\n        pass\n\n    def assert_no_round_trip_arbitrage(self) -> bool:\n        \"\"\"\n        Runs a few sample round-trip trades with *actual* state changes\n        (then reverts after each test). If any scenario yields a net profit,\n        raises RuntimeError.\n\n        Returns\n        -------\n        bool\n            True if no arbitrage found, else RuntimeError is raised.\n        \"\"\"\n        pass\n```\n--- File: bonding/amms/sqrtbondingcurveamm.py ---\n```python\nclass SqrtBondingCurveAMM(BondingCurveAMM):\n    def __init__(self, scale: float = 500_000.0, fee_rate: float = 0.0):\n        pass\n```\n--- File: bonding/amms/logbondingcurveamm.py ---\n```python\nclass LogBondingCurveAMM(BondingCurveAMM):\n    def __init__(self, scale: float = 500_000.0, fee_rate: float = 0.0):\n        pass\n```\n--- File: bonding/amms/expbondingcurveamm.py ---\n```python\nclass ExpBondingCurveAMM(BondingCurveAMM):\n\n    def __init__(self, scale: float = 500_000.0, fee_rate: float = 0.0):\n        \"\"\"\n\n        scale : float, optional\n            Scaling parameter for the exponential bonding curve.\n            Determines roughly the x where the price doubles. Must be positive.\n            Default: 500,000.0\n        fee_rate : float, optional\n            Fraction of each transaction (buy or sell) collected as fees.\n            0.001 => 0.1%.\n            Default: 0.0\n        \"\"\"\n        pass\n```\n--- File: bonding/amms/growthbondingcurveamm.py ---\n```python\nclass GrowthBondingCurveAMM(BondingCurveAMM):\n    def __init__(self, scale=500_000, fee_rate: float = 0.0):\n        pass\n```\n--- File: bonding/curves/growthbondingcurve.py ---\n```python\nclass GrowthBondingCurve(BondingCurve):\n    \"\"\"\n    A factor-based bonding curve that ensures:\n      - f(0) = 1,\n      - f(scale) = 2,\n      - price grows by fraction 'a' each time x is multiplied by c.\n\n    Mathematically:\n        p = ln(1 + a) / ln(c),  (requires a > -1, c > 1)\n        f(x) = 1 + (x^p / scale^p).\n\n    So:\n      1) f(0)   = 1\n      2) f(scale)= 1 + 1 = 2\n      3) strictly increasing for x>0 if p>0\n      4) simple closed-form integral\n\n\n    Motivated by a suggestion of Wilson Lau\n    See https://medium.com/thoughtchains/on-single-bonding-curves-for-continuous-token-models-a167f5ffef89\n\n    \"\"\"\n\n    def __init__(self,  scale=100.0, a=0.25, c=2.0):\n        \"\"\"\n        Parameters\n        ----------\n        a : float\n            Fractional growth per factor c. e.g. a=0.25 => +25% price each time x is multiplied by c.\n            Must satisfy (1+a)>0.\n        c : float\n            The factor base. c>1 means 'per doubling/tripling/etc' of x.\n        scale : float\n            The x-value at which price is guaranteed to be 2. Must be > 0.\n        \"\"\"\n        pass\n\n    def price(self, x: float) -> float:\n        \"\"\"\n        price(x) = 1 + (x^p / scale^p),  for x >= 0\n        with p = ln(1+a)/ln(c).\n\n        => f(0)=1, f(scale)=2.\n        \"\"\"\n        pass\n\n    def price_integral(self, x: float) -> float:\n        \"\"\"\n        ∫[0..x] price(u) du\n         = ∫[0..x] [1 + (u^p / scale^p)] du\n         = ∫[0..x] 1 du + ∫[0..x] [u^p / scale^p] du\n         = x + (1 / scale^p) * [u^(p+1)/(p+1)] from 0..x\n         = x + (x^(p+1) / [scale^p * (p+1)]),   if p != -1.\n        \"\"\"\n        pass\n\n    def __repr__(self):\n        pass\n```\n--- File: bonding/curves/__init__.py ---\n```python\npass\n```\n--- File: bonding/curves/verifyintegralaccuracy.py ---\n```python\ndef verify_integral_accuracy(curve, x_values: List[float], tolerance: float = 1e-6) -> bool:\n    pass\ndef verify_integral_accuracy(curve, x_values: List[float], tolerance: float = 1e-6) -> bool:\n    \"\"\"\n    Verify that the analytical price_integral matches the numerical integration\n    of the price function for a list of x_values.\n\n    Parameters\n    ----------\n    curve:  BondingCurve\n        The bonding curve to verify.\n    x_values : List[float]\n        A list of x values at which to perform the verification.\n    tolerance : float, optional\n        The maximum allowed difference between analytical and numerical integrals.\n\n    Returns\n    -------\n    bool\n        True if all verifications pass within the tolerance, False otherwise.\n\n    Raises\n    ------\n    AssertionError\n        If any verification fails.\n\n    \"\"\"\n    pass\n```\n--- File: bonding/curves/linearbondingcurve.py ---\n```python\nclass LinearBondingCurve(BondingCurve):\n    \"\"\"\n    price(x) = m*x + b\n    price_integral(x) = ∫(m*u + b) du = m/2 * x^2 + b*x\n    \"\"\"\n\n    def __init__(self, scale: float=500_000):\n        pass\n\n    def get_scale(self) -> float:\n        pass\n\n    def price(self, x: float) -> float:\n        pass\n\n    def price_integral(self, x: float) -> float:\n        pass\n```\n--- File: bonding/curves/logbondingcurve.py ---\n```python\nclass LogBondingCurve(BondingCurve):\n    \"\"\"\n    Implements a logarithmic bonding curve defined by:\n        f(x) = log(e + (e^2 - e) * (x / scale))\n\n    Key properties:\n    ---------------\n    1) f(0) = log(e) = 1\n       Starts at 1 when x=0.\n\n    2) f(scale) = log(e + (e^2 - e) * (scale / scale)) = log(e + e^2 - e) = log(e^2) = 2\n       Price doubles at x = scale.\n\n    3) Strictly increasing for x >= 0 because derivative = (e^2 - e) / (e + (e^2 - e) * (x / scale)) > 0.\n\n    4) Has an analytic integral:\n         ∫ log(e + (e^2 - e) * (u / scale)) du\n       which evaluates to:\n         (e + (e^2 - e) * (x / scale)) * (log(e + (e^2 - e) * (x / scale)) - 1) / ((e^2 - e) / scale)\n    \"\"\"\n\n    def __init__(self, scale: float = 500_000):\n        \"\"\"\n        Initialize the LogBondingCurve.\n\n        Parameters\n        ----------\n        scale : float, optional\n            Scaling parameter for the curve. Must be positive.\n            Determines the x at which the price doubles. Defaults to 500,000.\n        \"\"\"\n        pass\n\n    def price(self, x: float) -> float:\n        \"\"\"\n        price(x) = log(e + (e^2 - e) * (x / scale))\n\n        Parameters\n        ----------\n        x : float\n            The current supply (>= 0).\n\n        Returns\n        -------\n        float\n            The instantaneous price at supply x.\n        \"\"\"\n        pass\n\n    def price_integral(self, x: float) -> float:\n        \"\"\"\n        The definite integral of price(u) from 0 to x:\n\n            ∫[0 to x] log(e + (e^2 - e) * (u / scale)) du\n            = (e + (e^2 - e) * (x / scale)) * (log(e + (e^2 - e) * (x / scale)) - 1) / ((e^2 - e) / scale)\n\n        Parameters\n        ----------\n        x : float\n            The upper limit of integration (>= 0).\n\n        Returns\n        -------\n        float\n            ∫[0 to x] log(e + (e^2 - e) * (u / scale)) du\n        \"\"\"\n        pass\n\n    def __repr__(self) -> str:\n        pass\n```\n--- File: bonding/curves/sqrtbondingcurve.py ---\n```python\nclass SqrtBondingCurve(BondingCurve):\n    \"\"\"\n    Implements the sqrt(1 + 3 (x / scale)^2) amms curve logic.\n\n    price(x) = sqrt(1 + (x/scale)^2)\n    price_integral(x) = 0.5 * [ x * sqrt(1 + (x/scale)^2 ) + scale * asinh(x / scale) ]\n    \"\"\"\n\n    def __init__(self, scale: float = 500_000.0):\n        pass\n\n    def price(self, x: float) -> float:\n        pass\n\n    def price_integral(self, x: float) -> float:\n        pass\n```\n--- File: bonding/curves/bondingcurve.py ---\n```python\nclass BondingCurve(ABC):\n    \"\"\"\n    Abstract base class for amms curves.\n\n    Each concrete amms curve must define:\n      - price(x): float\n      - price_integral(x): float\n        => integral of price(u) du from 0 to x\n      - cost_to_move(x_start, x_end): float\n        => can default to price_integral(x_end) - price_integral(x_start),\n           or be overridden if desired.\n    \"\"\"\n\n    def get_scale(self) -> float:\n        pass\n\n    @abstractmethod\n    def price(self, x: float) -> float:\n        \"\"\"\n        Return the instantaneous price at `x`.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def price_integral(self, x: float) -> float:\n        \"\"\"\n        Return the integral of the price function from 0 to x.\n        \"\"\"\n        pass\n\n    def cost_to_move(self, x_start: float, x_end: float) -> float:\n        \"\"\"\n        Return the cost to move from x_start to x_end.\n        Default implementation: difference in the integrals.\n        \"\"\"\n        pass\n\n    def plot(self, x_max: float = 10, num_points: int = 1000):\n        pass\n\n    def verify_integral_accuracy(self, x_values: List[float], tolerance: float = 1e-6) -> bool:\n        pass\n\n    def verify_initial_unit_price(self):\n        \"\"\"\n        Price should double by the time we issue scale shares\n        \"\"\"\n        pass\n\n    def verify_scale_convention(self):\n        \"\"\"\n        Price should double by the time we issue scale shares\n        \"\"\"\n        pass\n```\n--- File: bonding/curves/allcurves.py ---\n```python\ndef all_curves_cls():\n    pass\n```\n--- File: bonding/curves/expbondingcurve.py ---\n```python\nclass ExpBondingCurve(BondingCurve):\n    \"\"\"\n    Implements an exponential bonding curve defined by:\n        f(x) = (1 / (e - 1)) * e^(x / scale) + (e - 2) / (e - 1)\n\n    Key properties:\n    ---------------\n    1) f(0) = 1\n       Starts at 1 when x=0.\n\n    2) f(scale) = 2\n       Price doubles at x = scale.\n\n    3) Strictly increasing for x >= 0 because derivative = (1 / scale) * (1 / (e - 1)) * e^(x / scale) > 0.\n\n    4) Has an analytic integral:\n         ∫[0 to x] f(u) du = (scale / (e - 1)) * (e^(x / scale) - 1) + ((e - 2) / (e - 1)) * x\n    \"\"\"\n\n    def __init__(self, scale: float = 500_000):\n        \"\"\"\n        Initialize the ExpBondingCurve.\n\n        Parameters\n        ----------\n        scale : float, optional\n            Scaling parameter for the curve. Must be positive.\n            Determines the x at which the price doubles. Defaults to 500,000.\n        \"\"\"\n        pass\n\n    def price(self, x: float) -> float:\n        \"\"\"\n        price(x) = (1 / (e - 1)) * e^(x / scale) + (e - 2) / (e - 1)\n\n        Parameters\n        ----------\n        x : float\n            The current supply (>= 0).\n\n        Returns\n        -------\n        float\n            The instantaneous price at supply x.\n        \"\"\"\n        pass\n\n    def price_integral(self, x: float) -> float:\n        \"\"\"\n        The definite integral of price(u) from 0 to x:\n\n            ∫[0 to x] [(1 / (e - 1)) * e^(u / scale) + (e - 2) / (e - 1)] du\n\n        Which evaluates to:\n\n            (scale / (e - 1)) * (e^(x / scale) - 1) + ((math.e - 2) / (math.e - 1)) * x\n\n        Parameters\n        ----------\n        x : float\n            The upper limit of integration (>= 0).\n\n        Returns\n        -------\n        float\n            ∫[0 to x] price(u) du\n        \"\"\"\n        pass\n\n    def __repr__(self) -> str:\n        pass\n```\n--- File: bonding/curveplots/__init__.py ---\n```python\npass\n```\n--- File: bonding/curveplots/matplotlibcurveplot.py ---\n```python\ndef matplotlib_curve_plot(curve, x_max: float = 10, num_points: int = 1000):\n    \"\"\"\n    Placeholder function if matplotlib is not available.\n    \"\"\"\n    pass\ndef matplotlib_curve_plot(curve, x_max: float = 10, num_points: int = 1000):\n    \"\"\"\n    Plots the price function and its integral for the given amms curve.\n\n    Parameters\n    ----------\n    curve : BondingCurve\n        An instance of scale BondingCurve subclass.\n    x_max : float, optional\n        The maximum value of x to plot. Defaults to 10.\n    num_points : int, optional\n        Number of points in the plot. Defaults to 1000.\n    \"\"\"\n    pass\n```\n--- File: bonding/using/usingscipy.py ---\n```python\npass\n```\n--- File: bonding/using/usingmatplotlib.py ---\n```python\npass\n```\n--- File: bonding/using/__init__.py ---\n```python\npass\n```",
        "minimal_code_skeleton": "--- File: bonding/amms/allamms.py ---\n```python\ndef all_amm_cls():\n    \"\"\"\n    Returns a list of all AMM classes defined in the package.\n    This function is used to iterate over all AMM types for testing or other purposes.\n    \"\"\"\n    pass\n\n```\n--- File: bonding/amms/ammdefaultparams.py ---\n```python\nQUANTA = 1e-8\n```\n--- File: bonding/amms/bondingcurveamm.py ---\n```python\nclass BondingCurveAMM:\n    \"\"\"\n    A simple Automated Market Maker (AMM) that uses a given BondingCurve\n    to determine pricing, while handling transaction fees, rounding, and state tracking.\n\n    Attributes\n    ----------\n    curve : BondingCurve\n        The amms curve instance that defines price and integral logic.\n    fee_rate : float\n        Fraction of each transaction (buy or sell) collected as fees. 0.001 => 0.1%.\n    quanta : float\n        Defines the smallest currency denomination (1e-8).\n    x : float\n        Current total minted/sold (the \"supply\" on the amms curve).\n    total_cash_collected : float\n        Total amount of currency that the amms curve has collected (this excludes fees).\n    total_fees_collected : float\n        Total amount of currency collected as fees.\n    logger : logging.Logger\n        Logger instance for logging events and errors.\n    \"\"\"\n\n    def __init__(self, curve, fee_rate=0.0, quanta=QUANTA):\n        \"\"\"\n        Initialize the BondingCurveAMM.\n\n        Parameters\n        ----------\n        curve : BondingCurve\n            A amms curve instance (e.g. SqrtBondingCurve).\n        fee_rate : float, optional\n            Fraction of each transaction (buy or sell) to be taken as fees (0.001 => 0.1%).\n        quanta : float, optional\n            Defines the smallest currency denomination (1e-8). Defaults to QUANTA.\n        \"\"\"\n        pass\n\n    def simulate_buy_shares_then_sell_shares(self, num_shares: float = 1.0):\n        \"\"\"\n        Simulate buying exactly `num_shares`, then immediately selling\n        those same shares.\n\n        Returns\n        -------\n        dict\n            {\n                'shares_bought': float,\n                'currency_spent': float,    # total_paid from buy_shares\n                'currency_received': float, # net_currency from sell_shares\n                'net_delta': float,\n                'arbitrage': bool\n            }\n        \"\"\"\n        pass\n\n    def buy_value(self, value: float) -> float:\n        \"\"\"\n        The user spends `value` currency to buy shares.\n        Returns the number of shares actually purchased.\n        \"\"\"\n        pass\n\n    def buy_shares(self, num_shares: float) -> float:\n        \"\"\"\n        The user wants to buy exactly `num_shares`.\n        Returns the total currency they actually paid.\n        \"\"\"\n        pass\n\n    def sell_shares(self, num_shares: float) -> float:\n        \"\"\"\n        Sell exactly `num_shares`, returning the net currency the user receives.\n        \"\"\"\n        pass\n\n    def sell_value(self, value: float) -> float:\n        \"\"\"\n        Sell enough shares to receive `value` currency (in total).\n        Returns the number of shares sold (positive float).\n        \"\"\"\n        pass\n\n    def get_maximum_sell_value(self) -> float:\n        \"\"\"\n        Returns the maximum net currency value one can extract by selling all shares (curve.x).\n        \"\"\"\n        pass\n\n    def assert_no_round_trip_arbitrage(self) -> bool:\n        \"\"\"\n        Runs a few sample round-trip trades with *actual* state changes\n        (then reverts after each test). If any scenario yields a net profit,\n        raises RuntimeError.\n\n        Returns\n        -------\n        bool\n            True if no arbitrage found, else RuntimeError is raised.\n        \"\"\"\n        pass\n\n```\n--- File: bonding/amms/expbondingcurveamm.py ---\n```python\nclass ExpBondingCurveAMM(BondingCurveAMM):\n\n    def __init__(self, scale: float = 500_000.0, fee_rate: float = 0.0):\n        \"\"\"\n\n        scale : float, optional\n            Scaling parameter for the exponential bonding curve.\n            Determines roughly the x where the price doubles. Must be positive.\n            Default: 500,000.0\n        fee_rate : float, optional\n            Fraction of each transaction (buy or sell) collected as fees.\n            0.001 => 0.1%.\n            Default: 0.0\n        \"\"\"\n        pass\n\n```\n--- File: bonding/amms/growthbondingcurveamm.py ---\n```python\nclass GrowthBondingCurveAMM(BondingCurveAMM):\n    def __init__(self, scale=500_000, fee_rate: float = 0.0):\n        pass\n\n```\n--- File: bonding/amms/linearbondingcurveamm.py ---\n```python\nclass LinearBondingCurveAMM(BondingCurveAMM):\n    def __init__(self, scale=500_000, fee_rate: float = 0.0):\n        pass\n\n```\n--- File: bonding/amms/logbondingcurveamm.py ---\n```python\nclass LogBondingCurveAMM(BondingCurveAMM):\n    def __init__(self, scale: float = 500_000.0, fee_rate: float = 0.0):\n        pass\n\n```\n--- File: bonding/amms/sqrtbondingcurveamm.py ---\n```python\nclass SqrtBondingCurveAMM(BondingCurveAMM):\n    def __init__(self, scale: float = 500_000.0, fee_rate: float = 0.0):\n        pass\n\n```\n--- File: bonding/curves/allcurves.py ---\n```python\ndef all_curves_cls():\n    \"\"\"\n    Returns a list of all BondingCurve classes defined in the package.\n    This function is used to iterate over all curve types for testing or other purposes.\n    \"\"\"\n    pass\n\n```\n--- File: bonding/curves/bondingcurve.py ---\n```python\nclass BondingCurve:\n    \"\"\"\n    Abstract base class for amms curves.\n\n    Each concrete amms curve must define:\n      - price(x): float\n      - price_integral(x): float\n        => integral of price(u) du from 0 to x\n      - cost_to_move(x_start, x_end): float\n        => can default to price_integral(x_end) - price_integral(x_start),\n           or be overridden if desired.\n    \"\"\"\n\n    def get_scale(self) -> float:\n        pass\n\n    def price(self, x: float) -> float:\n        \"\"\"\n        Return the instantaneous price at `x`.\n        \"\"\"\n        pass\n\n    def price_integral(self, x: float) -> float:\n        \"\"\"\n        Return the integral of the price function from 0 to x.\n        \"\"\"\n        pass\n\n    def cost_to_move(self, x_start: float, x_end: float) -> float:\n        \"\"\"\n        Return the cost to move from x_start to x_end.\n        Default implementation: difference in the integrals.\n        \"\"\"\n        pass\n\n    def verify_integral_accuracy(self, x_values: list[float], tolerance: float = 1e-6) -> bool:\n        pass\n\n    def verify_initial_unit_price(self):\n        pass\n\n    def verify_scale_convention(self):\n        pass\n\n```\n--- File: bonding/curves/expbondingcurve.py ---\n```python\nclass ExpBondingCurve(BondingCurve):\n    \"\"\"\n    Implements an exponential bonding curve defined by:\n        f(x) = (1 / (e - 1)) * e^(x / scale) + (e - 2) / (e - 1)\n\n    Key properties:\n    ---------------\n    1) f(0) = 1\n       Starts at 1 when x=0.\n\n    2) f(scale) = 2\n       Price doubles at x = scale.\n\n    3) Strictly increasing for x >= 0 because derivative = (1 / scale) * (1 / (e - 1)) * e^(x / scale) > 0.\n\n    4) Has an analytic integral:\n         ∫[0 to x] f(u) du = (scale / (e - 1)) * (e^(x / scale) - 1) + ((e - 2) / (e - 1)) * x\n    \"\"\"\n\n    def __init__(self, scale: float = 500_000):\n        \"\"\"\n        Initialize the ExpBondingCurve.\n\n        Parameters\n        ----------\n        scale : float, optional\n            Scaling parameter for the curve. Must be positive.\n            Determines the x at which the price doubles. Defaults to 500,000.\n        \"\"\"\n        pass\n\n    def price(self, x: float) -> float:\n        \"\"\"\n        price(x) = (1 / (e - 1)) * e^(x / scale) + (e - 2) / (e - 1)\n\n        Parameters\n        ----------\n        x : float\n            The current supply (>= 0).\n\n        Returns\n        -------\n        float\n            The instantaneous price at supply x.\n        \"\"\"\n        pass\n\n    def price_integral(self, x: float) -> float:\n        \"\"\"\n        The definite integral of price(u) from 0 to x:\n\n            ∫[0 to x] [(1 / (e - 1)) * e^(u / scale) + (e - 2) / (e - 1)] du\n\n        Which evaluates to:\n\n            (scale / (e - 1)) * (e^(x / scale) - 1) + ((e - 2) / (e - 1)) * x\n\n        Parameters\n        ----------\n        x : float\n            The upper limit of integration (>= 0).\n\n        Returns\n        -------\n        float\n            ∫[0 to x] price(u) du\n        \"\"\"\n        pass\n\n```\n--- File: bonding/curves/growthbondingcurve.py ---\n```python\nclass GrowthBondingCurve(BondingCurve):\n    \"\"\"\n    A factor-based bonding curve that ensures:\n      - f(0) = 1,\n      - f(scale) = 2,\n      - price grows by fraction 'a' each time x is multiplied by c.\n\n    Mathematically:\n        p = ln(1 + a) / ln(c),  (requires a > -1, c > 1)\n        f(x) = 1 + (x^p / scale^p).\n\n    So:\n      1) f(0)   = 1\n      2) f(scale)= 1 + 1 = 2\n      3) strictly increasing for x>0 if p>0\n      4) simple closed-form integral\n\n\n    Motivated by a suggestion of Wilson Lau\n    See https://medium.com/thoughtchains/on-single-bonding-curves-for-continuous-token-models-a167f5ffef89\n\n    \"\"\"\n\n    def __init__(self,  scale=100.0, a=0.25, c=2.0):\n        \"\"\"\n        Parameters\n        ----------\n        a : float\n            Fractional growth per factor c. e.g. a=0.25 => +25% price each time x is multiplied by c.\n            Must satisfy (1+a)>0.\n        c : float\n            The factor base. c>1 means 'per doubling/tripling/etc' of x.\n        scale : float\n            The x-value at which price is guaranteed to be 2. Must be > 0.\n        \"\"\"\n        pass\n\n    def price(self, x: float) -> float:\n        \"\"\"\n        price(x) = 1 + (x^p / scale^p),  for x >= 0\n        with p = ln(1+a)/ln(c).\n\n        => f(0)=1, f(scale)=2.\n        \"\"\"\n        pass\n\n    def price_integral(self, x: float) -> float:\n        \"\"\"\n        ∫[0..x] price(u) du\n         = ∫[0..x] [1 + (u^p / scale^p)] du\n         = ∫[0..x] 1 du + ∫[0..x] [u^p / scale^p] du\n         = x + (1 / scale^p) * [u^(p+1)/(p+1)] from 0..x\n         = x + (x^(p+1) / [scale^p * (p+1)]),   if p != -1.\n        \"\"\"\n        pass\n\n```\n--- File: bonding/curves/linearbondingcurve.py ---\n```python\nclass LinearBondingCurve(BondingCurve):\n    \"\"\"\n    price(x) = m*x + b\n    price_integral(x) = ∫(m*u + b) du = m/2 * x^2 + b*x\n    \"\"\"\n\n    def __init__(self, scale: float=500_000):\n        pass\n\n    def get_scale(self) -> float:\n        pass\n\n    def price(self, x: float) -> float:\n        pass\n\n    def price_integral(self, x: float) -> float:\n        pass\n\n```\n--- File: bonding/curves/logbondingcurve.py ---\n```python\nclass LogBondingCurve(BondingCurve):\n    \"\"\"\n    Implements a logarithmic bonding curve defined by:\n        f(x) = log(e + (e^2 - e) * (x / scale))\n\n    Key properties:\n    ---------------\n    1) f(0) = log(e) = 1\n       Starts at 1 when x=0.\n\n    2) f(scale) = log(e + (e^2 - e) * (scale / scale)) = log(e + e^2 - e) = log(e^2) = 2\n       Price doubles at x = scale.\n\n    3) Strictly increasing for x >= 0 because derivative = (e^2 - e) / (e + (e^2 - e) * (x / scale)) > 0.\n\n    4) Has an analytic integral:\n         ∫ log(e + (e^2 - e) * (u / scale)) du\n       which evaluates to:\n         (e + (e^2 - e) * (x / scale)) * (log(e + (e^2 - e) * (x / scale)) - 1) / ((e^2 - e) / scale)\n    \"\"\"\n\n    def __init__(self, scale: float = 500_000):\n        \"\"\"\n        Initialize the LogBondingCurve.\n\n        Parameters\n        ----------\n        scale : float, optional\n            Scaling parameter for the curve. Must be positive.\n            Determines the x at which the price doubles. Defaults to 500,000.\n        \"\"\"\n        pass\n\n    def price(self, x: float) -> float:\n        \"\"\"\n        price(x) = log(e + (e^2 - e) * (x / scale))\n\n        Parameters\n        ----------\n        x : float\n            The current supply (>= 0).\n\n        Returns\n        -------\n        float\n            The instantaneous price at supply x.\n        \"\"\"\n        pass\n\n    def price_integral(self, x: float) -> float:\n        \"\"\"\n        The definite integral of price(u) from 0 to x:\n\n            ∫[0 to x] log(e + (e^2 - e) * (u / scale)) du\n            = (e + (e^2 - e) * (x / scale)) * (log(e + (e^2 - e) * (x / scale)) - 1) / ((e^2 - e) / scale)\n\n        Parameters\n        ----------\n        x : float\n            The upper limit of integration (>= 0).\n\n        Returns\n        -------\n        float\n            ∫[0 to x] log(e + (e^2 - e) * (u / scale)) du\n        \"\"\"\n        pass\n\n```\n--- File: bonding/curves/sqrtbondingcurve.py ---\n```python\nclass SqrtBondingCurve(BondingCurve):\n    \"\"\"\n    Implements the sqrt(1 + 3 (x / scale)^2) amms curve logic.\n\n    price(x) = sqrt(1 + (x/scale)^2)\n    price_integral(x) = 0.5 * [ x * sqrt(1 + (x/scale)^2 ) + scale * asinh(x / scale) ]\n    \"\"\"\n\n    def __init__(self, scale: float = 500_000.0):\n        pass\n\n    def price(self, x: float) -> float:\n        pass\n\n    def price_integral(self, x: float) -> float:\n        pass\n\n```",
        "minimal_test_cases": [
            {
                "test_id": "tests/amms/test_arbitrage.py::test_all_amms_arbitrage",
                "covers": [
                    "bonding.amms.allamms.all_amm_cls - retrieving all AMM classes",
                    "bonding.amms.*AMM (all types e.g. Linear, Log, Sqrt, Exp, Growth) - instantiation for arbitrage check",
                    "bonding.amms.bondingcurveamm.BondingCurveAMM.assert_no_round_trip_arbitrage - general arbitrage integrity check for all AMM types"
                ]
            },
            {
                "test_id": "tests/curves/test_integral_accuracy.py::test_all_curves",
                "covers": [
                    "bonding.curves.allcurves.all_curves_cls - retrieving all curve classes",
                    "bonding.curves.*Curve (all types e.g. Linear, Log, Sqrt, Exp, Growth) - instantiation and testing of core `price` and `price_integral` methods",
                    "bonding.curves.bondingcurve.BondingCurve.verify_integral_accuracy - verifies analytical vs numerical integral for all curve types"
                ]
            },
            {
                "test_id": "tests/amms/test_bondingcurve_arbitrage_manually.py::test_no_arbitrage_immediate_round_trip_no_fees",
                "covers": [
                    "bonding.amms.sqrtbondingcurveamm.SqrtBondingCurveAMM.__init__ - example instantiation for AMM operations",
                    "bonding.amms.bondingcurveamm.BondingCurveAMM.buy_value - happy path (buy with currency, no fees)",
                    "bonding.amms.bondingcurveamm.BondingCurveAMM.sell_shares - happy path (sell shares, no fees, round trip)"
                ]
            },
            {
                "test_id": "tests/amms/test_bondingcurve_arbitrage_manually.py::test_buy_shares_no_fees",
                "covers": [
                    "bonding.amms.bondingcurveamm.BondingCurveAMM.buy_shares - happy path (buy specific number of shares, no fees, using SqrtBondingCurveAMM)"
                ]
            },
            {
                "test_id": "tests/amms/test_bondingcurve_arbitrage_manually.py::test_sell_value_no_fees",
                "covers": [
                    "bonding.amms.bondingcurveamm.BondingCurveAMM.sell_value - happy path (sell for specific currency value, no fees, using SqrtBondingCurveAMM)"
                ]
            },
            {
                "test_id": "tests/amms/test_arbitrage.py::test_buy_shares_then_sell_shares",
                "covers": [
                    "bonding.amms.bondingcurveamm.BondingCurveAMM.simulate_buy_shares_then_sell_shares - verifies this specific simulation logic across all AMM types"
                ]
            },
            {
                "test_id": "tests/curves/test_scale_convention.py::test_scale_conventions",
                "covers": [
                    "bonding.curves.bondingcurve.BondingCurve.verify_scale_convention - verifies price at 'scale' supply and `get_scale` method for all curve types"
                ]
            },
            {
                "test_id": "tests/curves/test_scale_convention.py::test_initial_price",
                "covers": [
                    "bonding.curves.bondingcurve.BondingCurve.verify_initial_unit_price - verifies price at zero supply for all curve types"
                ]
            }
        ],
        "commit_sha": "2503e65d39e91e6718783622cbbedae18c4cdbda",
        "full_code_skeleton_structured": [
            {
                "file_path": "bonding.py",
                "code": "pass\n"
            },
            {
                "file_path": "examples/__init__.py",
                "code": "pass\n"
            },
            {
                "file_path": "bonding/__init__.py",
                "code": "pass\n"
            },
            {
                "file_path": "bonding/amms/linearbondingcurveamm.py",
                "code": "class LinearBondingCurveAMM(BondingCurveAMM):\n    def __init__(self, scale=500_000, fee_rate: float = 0.0):\n        pass\n"
            },
            {
                "file_path": "bonding/amms/allamms.py",
                "code": "def all_amm_cls():\n    pass\n"
            },
            {
                "file_path": "bonding/amms/__init__.py",
                "code": "pass\n"
            },
            {
                "file_path": "bonding/amms/bondingcurveamm.py",
                "code": "class BondingCurveAMM:\n    \"\"\"\n    A simple Automated Market Maker (AMM) that uses a given BondingCurve\n    to determine pricing, while handling transaction fees, rounding, and state tracking.\n\n    Attributes\n    ----------\n    curve : BondingCurve\n        The amms curve instance that defines price and integral logic.\n    fee_rate : float\n        Fraction of each transaction (buy or sell) collected as fees. 0.001 => 0.1%.\n    quanta : float\n        Defines the smallest currency denomination (1e-8).\n    x : float\n        Current total minted/sold (the \"supply\" on the amms curve).\n    total_cash_collected : float\n        Total amount of currency that the amms curve has collected (this excludes fees).\n    total_fees_collected : float\n        Total amount of currency collected as fees.\n    logger : logging.Logger\n        Logger instance for logging events and errors.\n    \"\"\"\n\n    def __init__(self, curve, fee_rate=0.0, quanta=QUANTA):\n        \"\"\"\n        Initialize the BondingCurveAMM.\n\n        Parameters\n        ----------\n        curve : BondingCurve\n            A amms curve instance (e.g. SqrtBondingCurve).\n        fee_rate : float, optional\n            Fraction of each transaction (buy or sell) to be taken as fees (0.001 => 0.1%).\n        quanta : float, optional\n            Defines the smallest currency denomination (1e-8). Defaults to QUANTA.\n        \"\"\"\n        pass\n\n    def _solve_for_dx(self, x_start: float, target_cost: float,\n                      tolerance=1e-12, max_iter=200) -> float:\n        \"\"\"\n        Solve for dx such that cost_to_move(x_start, x_start + dx) = target_cost\n        using the bisection method.\n\n        Returns\n        -------\n        float\n            dx (positive if buying, negative if selling).\n        \"\"\"\n        pass\n\n    def simulate_buy_value(self, total_value: float):\n        \"\"\"\n        Simulate buying with `total_value` currency.\n\n        Returns a dict with:\n            {\n                'quanta_used': int,\n                'breakage_fee': float,\n                'fee_amount': float,\n                'net_currency': float,   # actual currency that goes into the curve\n                'shares_received': float\n            }\n        \"\"\"\n        pass\n\n    def simulate_buy_shares(self, num_shares: float):\n        \"\"\"\n        Simulate buying exactly `num_shares`, determining how much currency is required.\n\n        Returns a dict with:\n            {\n                'gross_cost': float,     # The net cost (without fees) required by the curve\n                'quanta_used': int,\n                'breakage_fee': float,\n                'fee_amount': float,\n                'total_paid': float,     # The total currency user must pay\n            }\n        \"\"\"\n        pass\n\n    def simulate_sell_shares(self, num_shares: float):\n        \"\"\"\n        Simulate selling `num_shares` from the current supply.\n\n        Returns a dict with:\n            {\n                'gross_currency': float,\n                'quanta_used': int,\n                'breakage_fee': float,\n                'fee_amount': float,\n                'net_currency': float,\n            }\n        \"\"\"\n        pass\n\n    def simulate_sell_value(self, target_value: float):\n        \"\"\"\n        Simulate selling enough shares to receive `target_value` total currency.\n\n        Returns a dict with:\n            {\n                'quanta_used': int,\n                'breakage_fee': float,\n                'fee_amount': float,\n                'gross_currency': float,\n                'net_currency': float,\n                'shares_sold': float\n            }\n        \"\"\"\n        pass\n\n    def buy_value(self, value: float) -> float:\n        \"\"\"\n        The user spends `value` currency to buy shares.\n        Returns the number of shares actually purchased.\n        \"\"\"\n        pass\n\n    def buy_shares(self, num_shares: float) -> float:\n        \"\"\"\n        The user wants to buy exactly `num_shares`.\n        Returns the total currency they actually paid.\n        \"\"\"\n        pass\n\n    def sell_shares(self, num_shares: float) -> float:\n        \"\"\"\n        Sell exactly `num_shares`, returning the net currency the user receives.\n        \"\"\"\n        pass\n\n    def sell_value(self, value: float) -> float:\n        \"\"\"\n        Sell enough shares to receive `value` currency (in total).\n        Returns the number of shares sold (positive float).\n        \"\"\"\n        pass\n\n    def get_maximum_sell_value(self) -> float:\n        \"\"\"\n        Returns the maximum net currency value one can extract by selling all shares (curve.x).\n        \"\"\"\n        pass\n\n    def total_cost_at_supply(self, x_val: float = None) -> float:\n        \"\"\"\n        Returns the integral of the price from 0 to x_val (or curve.x).\n        \"\"\"\n        pass\n\n    def current_price(self) -> float:\n        \"\"\"\n        Returns the instantaneous price at supply curve.x.\n        \"\"\"\n        pass\n\n    def __repr__(self) -> str:\n        pass\n\n    def simulate_buy_value_then_sell_shares(self, buy_value: float = 1.0):\n        \"\"\"\n        Simulate spending `buy_value` currency to buy shares, and then\n        immediately selling *all* those purchased shares.\n\n        Returns\n        -------\n        dict\n            {\n                'initial_currency': float,\n                'final_currency': float,\n                'net_delta': float,\n                'buy_sim': dict,      # output of simulate_buy_value(...)\n                'sell_sim': dict,     # output of simulate_sell_shares(...)\n                'arbitrage': bool,    # True if net_delta > 0\n            }\n        \"\"\"\n        pass\n\n    def simulate_buy_shares_then_sell_shares(self, num_shares: float = 1.0):\n        \"\"\"\n        Simulate buying exactly `num_shares`, then immediately selling\n        those same shares.\n\n        Returns\n        -------\n        dict\n            {\n                'shares_bought': float,\n                'currency_spent': float,    # total_paid from buy_shares\n                'currency_received': float, # net_currency from sell_shares\n                'net_delta': float,\n                'arbitrage': bool\n            }\n        \"\"\"\n        pass\n\n    def simulate_sell_value_then_buy_shares(self, target_value: float = 1.0):\n        \"\"\"\n        Simulate selling enough shares to receive exactly `target_value` currency,\n        then use the *net* proceeds to buy shares again.\n\n        Returns\n        -------\n        dict\n            {\n                'target_value': float,\n                'shares_sold': float,          # positive\n                'buy_shares_received': float,  # how many shares we get from the net currency\n                'shares_delta': float,         # (buy_shares_received - shares_sold)\n                'arbitrage': bool\n            }\n        \"\"\"\n        pass\n\n    def simulate_sell_shares_then_buy_value(self, shares_to_sell: float = 1.0):\n        \"\"\"\n        Simulate selling exactly `shares_to_sell`, then use the net proceeds\n        to buy as much as possible of the AMM (buy_value) with that currency.\n\n        Returns\n        -------\n        dict\n            {\n                'shares_sold': float,\n                'currency_received': float,\n                'shares_bought': float,\n                'shares_delta': float,\n                'arbitrage': bool\n            }\n        \"\"\"\n        pass\n\n    def assert_no_round_trip_arbitrage(self) -> bool:\n        \"\"\"\n        Runs a few sample round-trip trades with *actual* state changes\n        (then reverts after each test). If any scenario yields a net profit,\n        raises RuntimeError.\n\n        Returns\n        -------\n        bool\n            True if no arbitrage found, else RuntimeError is raised.\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "bonding/amms/sqrtbondingcurveamm.py",
                "code": "class SqrtBondingCurveAMM(BondingCurveAMM):\n    def __init__(self, scale: float = 500_000.0, fee_rate: float = 0.0):\n        pass\n"
            },
            {
                "file_path": "bonding/amms/logbondingcurveamm.py",
                "code": "class LogBondingCurveAMM(BondingCurveAMM):\n    def __init__(self, scale: float = 500_000.0, fee_rate: float = 0.0):\n        pass\n"
            },
            {
                "file_path": "bonding/amms/expbondingcurveamm.py",
                "code": "class ExpBondingCurveAMM(BondingCurveAMM):\n\n    def __init__(self, scale: float = 500_000.0, fee_rate: float = 0.0):\n        \"\"\"\n\n        scale : float, optional\n            Scaling parameter for the exponential bonding curve.\n            Determines roughly the x where the price doubles. Must be positive.\n            Default: 500,000.0\n        fee_rate : float, optional\n            Fraction of each transaction (buy or sell) collected as fees.\n            0.001 => 0.1%.\n            Default: 0.0\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "bonding/amms/growthbondingcurveamm.py",
                "code": "class GrowthBondingCurveAMM(BondingCurveAMM):\n    def __init__(self, scale=500_000, fee_rate: float = 0.0):\n        pass\n"
            },
            {
                "file_path": "bonding/curves/growthbondingcurve.py",
                "code": "class GrowthBondingCurve(BondingCurve):\n    \"\"\"\n    A factor-based bonding curve that ensures:\n      - f(0) = 1,\n      - f(scale) = 2,\n      - price grows by fraction 'a' each time x is multiplied by c.\n\n    Mathematically:\n        p = ln(1 + a) / ln(c),  (requires a > -1, c > 1)\n        f(x) = 1 + (x^p / scale^p).\n\n    So:\n      1) f(0)   = 1\n      2) f(scale)= 1 + 1 = 2\n      3) strictly increasing for x>0 if p>0\n      4) simple closed-form integral\n\n\n    Motivated by a suggestion of Wilson Lau\n    See https://medium.com/thoughtchains/on-single-bonding-curves-for-continuous-token-models-a167f5ffef89\n\n    \"\"\"\n\n    def __init__(self,  scale=100.0, a=0.25, c=2.0):\n        \"\"\"\n        Parameters\n        ----------\n        a : float\n            Fractional growth per factor c. e.g. a=0.25 => +25% price each time x is multiplied by c.\n            Must satisfy (1+a)>0.\n        c : float\n            The factor base. c>1 means 'per doubling/tripling/etc' of x.\n        scale : float\n            The x-value at which price is guaranteed to be 2. Must be > 0.\n        \"\"\"\n        pass\n\n    def price(self, x: float) -> float:\n        \"\"\"\n        price(x) = 1 + (x^p / scale^p),  for x >= 0\n        with p = ln(1+a)/ln(c).\n\n        => f(0)=1, f(scale)=2.\n        \"\"\"\n        pass\n\n    def price_integral(self, x: float) -> float:\n        \"\"\"\n        ∫[0..x] price(u) du\n         = ∫[0..x] [1 + (u^p / scale^p)] du\n         = ∫[0..x] 1 du + ∫[0..x] [u^p / scale^p] du\n         = x + (1 / scale^p) * [u^(p+1)/(p+1)] from 0..x\n         = x + (x^(p+1) / [scale^p * (p+1)]),   if p != -1.\n        \"\"\"\n        pass\n\n    def __repr__(self):\n        pass\n"
            },
            {
                "file_path": "bonding/curves/__init__.py",
                "code": "pass\n"
            },
            {
                "file_path": "bonding/curves/verifyintegralaccuracy.py",
                "code": "def verify_integral_accuracy(curve, x_values: List[float], tolerance: float = 1e-6) -> bool:\n    pass\ndef verify_integral_accuracy(curve, x_values: List[float], tolerance: float = 1e-6) -> bool:\n    \"\"\"\n    Verify that the analytical price_integral matches the numerical integration\n    of the price function for a list of x_values.\n\n    Parameters\n    ----------\n    curve:  BondingCurve\n        The bonding curve to verify.\n    x_values : List[float]\n        A list of x values at which to perform the verification.\n    tolerance : float, optional\n        The maximum allowed difference between analytical and numerical integrals.\n\n    Returns\n    -------\n    bool\n        True if all verifications pass within the tolerance, False otherwise.\n\n    Raises\n    ------\n    AssertionError\n        If any verification fails.\n\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "bonding/curves/linearbondingcurve.py",
                "code": "class LinearBondingCurve(BondingCurve):\n    \"\"\"\n    price(x) = m*x + b\n    price_integral(x) = ∫(m*u + b) du = m/2 * x^2 + b*x\n    \"\"\"\n\n    def __init__(self, scale: float=500_000):\n        pass\n\n    def get_scale(self) -> float:\n        pass\n\n    def price(self, x: float) -> float:\n        pass\n\n    def price_integral(self, x: float) -> float:\n        pass\n"
            },
            {
                "file_path": "bonding/curves/logbondingcurve.py",
                "code": "class LogBondingCurve(BondingCurve):\n    \"\"\"\n    Implements a logarithmic bonding curve defined by:\n        f(x) = log(e + (e^2 - e) * (x / scale))\n\n    Key properties:\n    ---------------\n    1) f(0) = log(e) = 1\n       Starts at 1 when x=0.\n\n    2) f(scale) = log(e + (e^2 - e) * (scale / scale)) = log(e + e^2 - e) = log(e^2) = 2\n       Price doubles at x = scale.\n\n    3) Strictly increasing for x >= 0 because derivative = (e^2 - e) / (e + (e^2 - e) * (x / scale)) > 0.\n\n    4) Has an analytic integral:\n         ∫ log(e + (e^2 - e) * (u / scale)) du\n       which evaluates to:\n         (e + (e^2 - e) * (x / scale)) * (log(e + (e^2 - e) * (x / scale)) - 1) / ((e^2 - e) / scale)\n    \"\"\"\n\n    def __init__(self, scale: float = 500_000):\n        \"\"\"\n        Initialize the LogBondingCurve.\n\n        Parameters\n        ----------\n        scale : float, optional\n            Scaling parameter for the curve. Must be positive.\n            Determines the x at which the price doubles. Defaults to 500,000.\n        \"\"\"\n        pass\n\n    def price(self, x: float) -> float:\n        \"\"\"\n        price(x) = log(e + (e^2 - e) * (x / scale))\n\n        Parameters\n        ----------\n        x : float\n            The current supply (>= 0).\n\n        Returns\n        -------\n        float\n            The instantaneous price at supply x.\n        \"\"\"\n        pass\n\n    def price_integral(self, x: float) -> float:\n        \"\"\"\n        The definite integral of price(u) from 0 to x:\n\n            ∫[0 to x] log(e + (e^2 - e) * (u / scale)) du\n            = (e + (e^2 - e) * (x / scale)) * (log(e + (e^2 - e) * (x / scale)) - 1) / ((e^2 - e) / scale)\n\n        Parameters\n        ----------\n        x : float\n            The upper limit of integration (>= 0).\n\n        Returns\n        -------\n        float\n            ∫[0 to x] log(e + (e^2 - e) * (u / scale)) du\n        \"\"\"\n        pass\n\n    def __repr__(self) -> str:\n        pass\n"
            },
            {
                "file_path": "bonding/curves/sqrtbondingcurve.py",
                "code": "class SqrtBondingCurve(BondingCurve):\n    \"\"\"\n    Implements the sqrt(1 + 3 (x / scale)^2) amms curve logic.\n\n    price(x) = sqrt(1 + (x/scale)^2)\n    price_integral(x) = 0.5 * [ x * sqrt(1 + (x/scale)^2 ) + scale * asinh(x / scale) ]\n    \"\"\"\n\n    def __init__(self, scale: float = 500_000.0):\n        pass\n\n    def price(self, x: float) -> float:\n        pass\n\n    def price_integral(self, x: float) -> float:\n        pass\n"
            },
            {
                "file_path": "bonding/curves/bondingcurve.py",
                "code": "class BondingCurve(ABC):\n    \"\"\"\n    Abstract base class for amms curves.\n\n    Each concrete amms curve must define:\n      - price(x): float\n      - price_integral(x): float\n        => integral of price(u) du from 0 to x\n      - cost_to_move(x_start, x_end): float\n        => can default to price_integral(x_end) - price_integral(x_start),\n           or be overridden if desired.\n    \"\"\"\n\n    def get_scale(self) -> float:\n        pass\n\n    @abstractmethod\n    def price(self, x: float) -> float:\n        \"\"\"\n        Return the instantaneous price at `x`.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def price_integral(self, x: float) -> float:\n        \"\"\"\n        Return the integral of the price function from 0 to x.\n        \"\"\"\n        pass\n\n    def cost_to_move(self, x_start: float, x_end: float) -> float:\n        \"\"\"\n        Return the cost to move from x_start to x_end.\n        Default implementation: difference in the integrals.\n        \"\"\"\n        pass\n\n    def plot(self, x_max: float = 10, num_points: int = 1000):\n        pass\n\n    def verify_integral_accuracy(self, x_values: List[float], tolerance: float = 1e-6) -> bool:\n        pass\n\n    def verify_initial_unit_price(self):\n        \"\"\"\n        Price should double by the time we issue scale shares\n        \"\"\"\n        pass\n\n    def verify_scale_convention(self):\n        \"\"\"\n        Price should double by the time we issue scale shares\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "bonding/curves/allcurves.py",
                "code": "def all_curves_cls():\n    pass\n"
            },
            {
                "file_path": "bonding/curves/expbondingcurve.py",
                "code": "class ExpBondingCurve(BondingCurve):\n    \"\"\"\n    Implements an exponential bonding curve defined by:\n        f(x) = (1 / (e - 1)) * e^(x / scale) + (e - 2) / (e - 1)\n\n    Key properties:\n    ---------------\n    1) f(0) = 1\n       Starts at 1 when x=0.\n\n    2) f(scale) = 2\n       Price doubles at x = scale.\n\n    3) Strictly increasing for x >= 0 because derivative = (1 / scale) * (1 / (e - 1)) * e^(x / scale) > 0.\n\n    4) Has an analytic integral:\n         ∫[0 to x] f(u) du = (scale / (e - 1)) * (e^(x / scale) - 1) + ((e - 2) / (e - 1)) * x\n    \"\"\"\n\n    def __init__(self, scale: float = 500_000):\n        \"\"\"\n        Initialize the ExpBondingCurve.\n\n        Parameters\n        ----------\n        scale : float, optional\n            Scaling parameter for the curve. Must be positive.\n            Determines the x at which the price doubles. Defaults to 500,000.\n        \"\"\"\n        pass\n\n    def price(self, x: float) -> float:\n        \"\"\"\n        price(x) = (1 / (e - 1)) * e^(x / scale) + (e - 2) / (e - 1)\n\n        Parameters\n        ----------\n        x : float\n            The current supply (>= 0).\n\n        Returns\n        -------\n        float\n            The instantaneous price at supply x.\n        \"\"\"\n        pass\n\n    def price_integral(self, x: float) -> float:\n        \"\"\"\n        The definite integral of price(u) from 0 to x:\n\n            ∫[0 to x] [(1 / (e - 1)) * e^(u / scale) + (e - 2) / (e - 1)] du\n\n        Which evaluates to:\n\n            (scale / (e - 1)) * (e^(x / scale) - 1) + ((math.e - 2) / (math.e - 1)) * x\n\n        Parameters\n        ----------\n        x : float\n            The upper limit of integration (>= 0).\n\n        Returns\n        -------\n        float\n            ∫[0 to x] price(u) du\n        \"\"\"\n        pass\n\n    def __repr__(self) -> str:\n        pass\n"
            },
            {
                "file_path": "bonding/curveplots/__init__.py",
                "code": "pass\n"
            },
            {
                "file_path": "bonding/curveplots/matplotlibcurveplot.py",
                "code": "def matplotlib_curve_plot(curve, x_max: float = 10, num_points: int = 1000):\n    \"\"\"\n    Placeholder function if matplotlib is not available.\n    \"\"\"\n    pass\ndef matplotlib_curve_plot(curve, x_max: float = 10, num_points: int = 1000):\n    \"\"\"\n    Plots the price function and its integral for the given amms curve.\n\n    Parameters\n    ----------\n    curve : BondingCurve\n        An instance of scale BondingCurve subclass.\n    x_max : float, optional\n        The maximum value of x to plot. Defaults to 10.\n    num_points : int, optional\n        Number of points in the plot. Defaults to 1000.\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "bonding/using/usingscipy.py",
                "code": "pass\n"
            },
            {
                "file_path": "bonding/using/usingmatplotlib.py",
                "code": "pass\n"
            },
            {
                "file_path": "bonding/using/__init__.py",
                "code": "pass\n"
            }
        ],
        "minimal_code_skeleton_structured": [
            {
                "file_path": "bonding/amms/allamms.py",
                "code": "def all_amm_cls():\n    \"\"\"\n    Returns a list of all AMM classes defined in the package.\n    This function is used to iterate over all AMM types for testing or other purposes.\n    \"\"\"\n    pass\n\n"
            },
            {
                "file_path": "bonding/amms/ammdefaultparams.py",
                "code": "QUANTA = 1e-8\n"
            },
            {
                "file_path": "bonding/amms/bondingcurveamm.py",
                "code": "class BondingCurveAMM:\n    \"\"\"\n    A simple Automated Market Maker (AMM) that uses a given BondingCurve\n    to determine pricing, while handling transaction fees, rounding, and state tracking.\n\n    Attributes\n    ----------\n    curve : BondingCurve\n        The amms curve instance that defines price and integral logic.\n    fee_rate : float\n        Fraction of each transaction (buy or sell) collected as fees. 0.001 => 0.1%.\n    quanta : float\n        Defines the smallest currency denomination (1e-8).\n    x : float\n        Current total minted/sold (the \"supply\" on the amms curve).\n    total_cash_collected : float\n        Total amount of currency that the amms curve has collected (this excludes fees).\n    total_fees_collected : float\n        Total amount of currency collected as fees.\n    logger : logging.Logger\n        Logger instance for logging events and errors.\n    \"\"\"\n\n    def __init__(self, curve, fee_rate=0.0, quanta=QUANTA):\n        \"\"\"\n        Initialize the BondingCurveAMM.\n\n        Parameters\n        ----------\n        curve : BondingCurve\n            A amms curve instance (e.g. SqrtBondingCurve).\n        fee_rate : float, optional\n            Fraction of each transaction (buy or sell) to be taken as fees (0.001 => 0.1%).\n        quanta : float, optional\n            Defines the smallest currency denomination (1e-8). Defaults to QUANTA.\n        \"\"\"\n        pass\n\n    def simulate_buy_shares_then_sell_shares(self, num_shares: float = 1.0):\n        \"\"\"\n        Simulate buying exactly `num_shares`, then immediately selling\n        those same shares.\n\n        Returns\n        -------\n        dict\n            {\n                'shares_bought': float,\n                'currency_spent': float,    # total_paid from buy_shares\n                'currency_received': float, # net_currency from sell_shares\n                'net_delta': float,\n                'arbitrage': bool\n            }\n        \"\"\"\n        pass\n\n    def buy_value(self, value: float) -> float:\n        \"\"\"\n        The user spends `value` currency to buy shares.\n        Returns the number of shares actually purchased.\n        \"\"\"\n        pass\n\n    def buy_shares(self, num_shares: float) -> float:\n        \"\"\"\n        The user wants to buy exactly `num_shares`.\n        Returns the total currency they actually paid.\n        \"\"\"\n        pass\n\n    def sell_shares(self, num_shares: float) -> float:\n        \"\"\"\n        Sell exactly `num_shares`, returning the net currency the user receives.\n        \"\"\"\n        pass\n\n    def sell_value(self, value: float) -> float:\n        \"\"\"\n        Sell enough shares to receive `value` currency (in total).\n        Returns the number of shares sold (positive float).\n        \"\"\"\n        pass\n\n    def get_maximum_sell_value(self) -> float:\n        \"\"\"\n        Returns the maximum net currency value one can extract by selling all shares (curve.x).\n        \"\"\"\n        pass\n\n    def assert_no_round_trip_arbitrage(self) -> bool:\n        \"\"\"\n        Runs a few sample round-trip trades with *actual* state changes\n        (then reverts after each test). If any scenario yields a net profit,\n        raises RuntimeError.\n\n        Returns\n        -------\n        bool\n            True if no arbitrage found, else RuntimeError is raised.\n        \"\"\"\n        pass\n\n"
            },
            {
                "file_path": "bonding/amms/expbondingcurveamm.py",
                "code": "class ExpBondingCurveAMM(BondingCurveAMM):\n\n    def __init__(self, scale: float = 500_000.0, fee_rate: float = 0.0):\n        \"\"\"\n\n        scale : float, optional\n            Scaling parameter for the exponential bonding curve.\n            Determines roughly the x where the price doubles. Must be positive.\n            Default: 500,000.0\n        fee_rate : float, optional\n            Fraction of each transaction (buy or sell) collected as fees.\n            0.001 => 0.1%.\n            Default: 0.0\n        \"\"\"\n        pass\n\n"
            },
            {
                "file_path": "bonding/amms/growthbondingcurveamm.py",
                "code": "class GrowthBondingCurveAMM(BondingCurveAMM):\n    def __init__(self, scale=500_000, fee_rate: float = 0.0):\n        pass\n\n"
            },
            {
                "file_path": "bonding/amms/linearbondingcurveamm.py",
                "code": "class LinearBondingCurveAMM(BondingCurveAMM):\n    def __init__(self, scale=500_000, fee_rate: float = 0.0):\n        pass\n\n"
            },
            {
                "file_path": "bonding/amms/logbondingcurveamm.py",
                "code": "class LogBondingCurveAMM(BondingCurveAMM):\n    def __init__(self, scale: float = 500_000.0, fee_rate: float = 0.0):\n        pass\n\n"
            },
            {
                "file_path": "bonding/amms/sqrtbondingcurveamm.py",
                "code": "class SqrtBondingCurveAMM(BondingCurveAMM):\n    def __init__(self, scale: float = 500_000.0, fee_rate: float = 0.0):\n        pass\n\n"
            },
            {
                "file_path": "bonding/curves/allcurves.py",
                "code": "def all_curves_cls():\n    \"\"\"\n    Returns a list of all BondingCurve classes defined in the package.\n    This function is used to iterate over all curve types for testing or other purposes.\n    \"\"\"\n    pass\n\n"
            },
            {
                "file_path": "bonding/curves/bondingcurve.py",
                "code": "class BondingCurve:\n    \"\"\"\n    Abstract base class for amms curves.\n\n    Each concrete amms curve must define:\n      - price(x): float\n      - price_integral(x): float\n        => integral of price(u) du from 0 to x\n      - cost_to_move(x_start, x_end): float\n        => can default to price_integral(x_end) - price_integral(x_start),\n           or be overridden if desired.\n    \"\"\"\n\n    def get_scale(self) -> float:\n        pass\n\n    def price(self, x: float) -> float:\n        \"\"\"\n        Return the instantaneous price at `x`.\n        \"\"\"\n        pass\n\n    def price_integral(self, x: float) -> float:\n        \"\"\"\n        Return the integral of the price function from 0 to x.\n        \"\"\"\n        pass\n\n    def cost_to_move(self, x_start: float, x_end: float) -> float:\n        \"\"\"\n        Return the cost to move from x_start to x_end.\n        Default implementation: difference in the integrals.\n        \"\"\"\n        pass\n\n    def verify_integral_accuracy(self, x_values: list[float], tolerance: float = 1e-6) -> bool:\n        pass\n\n    def verify_initial_unit_price(self):\n        pass\n\n    def verify_scale_convention(self):\n        pass\n\n"
            },
            {
                "file_path": "bonding/curves/expbondingcurve.py",
                "code": "class ExpBondingCurve(BondingCurve):\n    \"\"\"\n    Implements an exponential bonding curve defined by:\n        f(x) = (1 / (e - 1)) * e^(x / scale) + (e - 2) / (e - 1)\n\n    Key properties:\n    ---------------\n    1) f(0) = 1\n       Starts at 1 when x=0.\n\n    2) f(scale) = 2\n       Price doubles at x = scale.\n\n    3) Strictly increasing for x >= 0 because derivative = (1 / scale) * (1 / (e - 1)) * e^(x / scale) > 0.\n\n    4) Has an analytic integral:\n         ∫[0 to x] f(u) du = (scale / (e - 1)) * (e^(x / scale) - 1) + ((e - 2) / (e - 1)) * x\n    \"\"\"\n\n    def __init__(self, scale: float = 500_000):\n        \"\"\"\n        Initialize the ExpBondingCurve.\n\n        Parameters\n        ----------\n        scale : float, optional\n            Scaling parameter for the curve. Must be positive.\n            Determines the x at which the price doubles. Defaults to 500,000.\n        \"\"\"\n        pass\n\n    def price(self, x: float) -> float:\n        \"\"\"\n        price(x) = (1 / (e - 1)) * e^(x / scale) + (e - 2) / (e - 1)\n\n        Parameters\n        ----------\n        x : float\n            The current supply (>= 0).\n\n        Returns\n        -------\n        float\n            The instantaneous price at supply x.\n        \"\"\"\n        pass\n\n    def price_integral(self, x: float) -> float:\n        \"\"\"\n        The definite integral of price(u) from 0 to x:\n\n            ∫[0 to x] [(1 / (e - 1)) * e^(u / scale) + (e - 2) / (e - 1)] du\n\n        Which evaluates to:\n\n            (scale / (e - 1)) * (e^(x / scale) - 1) + ((e - 2) / (e - 1)) * x\n\n        Parameters\n        ----------\n        x : float\n            The upper limit of integration (>= 0).\n\n        Returns\n        -------\n        float\n            ∫[0 to x] price(u) du\n        \"\"\"\n        pass\n\n"
            },
            {
                "file_path": "bonding/curves/growthbondingcurve.py",
                "code": "class GrowthBondingCurve(BondingCurve):\n    \"\"\"\n    A factor-based bonding curve that ensures:\n      - f(0) = 1,\n      - f(scale) = 2,\n      - price grows by fraction 'a' each time x is multiplied by c.\n\n    Mathematically:\n        p = ln(1 + a) / ln(c),  (requires a > -1, c > 1)\n        f(x) = 1 + (x^p / scale^p).\n\n    So:\n      1) f(0)   = 1\n      2) f(scale)= 1 + 1 = 2\n      3) strictly increasing for x>0 if p>0\n      4) simple closed-form integral\n\n\n    Motivated by a suggestion of Wilson Lau\n    See https://medium.com/thoughtchains/on-single-bonding-curves-for-continuous-token-models-a167f5ffef89\n\n    \"\"\"\n\n    def __init__(self,  scale=100.0, a=0.25, c=2.0):\n        \"\"\"\n        Parameters\n        ----------\n        a : float\n            Fractional growth per factor c. e.g. a=0.25 => +25% price each time x is multiplied by c.\n            Must satisfy (1+a)>0.\n        c : float\n            The factor base. c>1 means 'per doubling/tripling/etc' of x.\n        scale : float\n            The x-value at which price is guaranteed to be 2. Must be > 0.\n        \"\"\"\n        pass\n\n    def price(self, x: float) -> float:\n        \"\"\"\n        price(x) = 1 + (x^p / scale^p),  for x >= 0\n        with p = ln(1+a)/ln(c).\n\n        => f(0)=1, f(scale)=2.\n        \"\"\"\n        pass\n\n    def price_integral(self, x: float) -> float:\n        \"\"\"\n        ∫[0..x] price(u) du\n         = ∫[0..x] [1 + (u^p / scale^p)] du\n         = ∫[0..x] 1 du + ∫[0..x] [u^p / scale^p] du\n         = x + (1 / scale^p) * [u^(p+1)/(p+1)] from 0..x\n         = x + (x^(p+1) / [scale^p * (p+1)]),   if p != -1.\n        \"\"\"\n        pass\n\n"
            },
            {
                "file_path": "bonding/curves/linearbondingcurve.py",
                "code": "class LinearBondingCurve(BondingCurve):\n    \"\"\"\n    price(x) = m*x + b\n    price_integral(x) = ∫(m*u + b) du = m/2 * x^2 + b*x\n    \"\"\"\n\n    def __init__(self, scale: float=500_000):\n        pass\n\n    def get_scale(self) -> float:\n        pass\n\n    def price(self, x: float) -> float:\n        pass\n\n    def price_integral(self, x: float) -> float:\n        pass\n\n"
            },
            {
                "file_path": "bonding/curves/logbondingcurve.py",
                "code": "class LogBondingCurve(BondingCurve):\n    \"\"\"\n    Implements a logarithmic bonding curve defined by:\n        f(x) = log(e + (e^2 - e) * (x / scale))\n\n    Key properties:\n    ---------------\n    1) f(0) = log(e) = 1\n       Starts at 1 when x=0.\n\n    2) f(scale) = log(e + (e^2 - e) * (scale / scale)) = log(e + e^2 - e) = log(e^2) = 2\n       Price doubles at x = scale.\n\n    3) Strictly increasing for x >= 0 because derivative = (e^2 - e) / (e + (e^2 - e) * (x / scale)) > 0.\n\n    4) Has an analytic integral:\n         ∫ log(e + (e^2 - e) * (u / scale)) du\n       which evaluates to:\n         (e + (e^2 - e) * (x / scale)) * (log(e + (e^2 - e) * (x / scale)) - 1) / ((e^2 - e) / scale)\n    \"\"\"\n\n    def __init__(self, scale: float = 500_000):\n        \"\"\"\n        Initialize the LogBondingCurve.\n\n        Parameters\n        ----------\n        scale : float, optional\n            Scaling parameter for the curve. Must be positive.\n            Determines the x at which the price doubles. Defaults to 500,000.\n        \"\"\"\n        pass\n\n    def price(self, x: float) -> float:\n        \"\"\"\n        price(x) = log(e + (e^2 - e) * (x / scale))\n\n        Parameters\n        ----------\n        x : float\n            The current supply (>= 0).\n\n        Returns\n        -------\n        float\n            The instantaneous price at supply x.\n        \"\"\"\n        pass\n\n    def price_integral(self, x: float) -> float:\n        \"\"\"\n        The definite integral of price(u) from 0 to x:\n\n            ∫[0 to x] log(e + (e^2 - e) * (u / scale)) du\n            = (e + (e^2 - e) * (x / scale)) * (log(e + (e^2 - e) * (x / scale)) - 1) / ((e^2 - e) / scale)\n\n        Parameters\n        ----------\n        x : float\n            The upper limit of integration (>= 0).\n\n        Returns\n        -------\n        float\n            ∫[0 to x] log(e + (e^2 - e) * (u / scale)) du\n        \"\"\"\n        pass\n\n"
            },
            {
                "file_path": "bonding/curves/sqrtbondingcurve.py",
                "code": "class SqrtBondingCurve(BondingCurve):\n    \"\"\"\n    Implements the sqrt(1 + 3 (x / scale)^2) amms curve logic.\n\n    price(x) = sqrt(1 + (x/scale)^2)\n    price_integral(x) = 0.5 * [ x * sqrt(1 + (x/scale)^2 ) + scale * asinh(x / scale) ]\n    \"\"\"\n\n    def __init__(self, scale: float = 500_000.0):\n        pass\n\n    def price(self, x: float) -> float:\n        pass\n\n    def price_integral(self, x: float) -> float:\n        pass\n\n"
            }
        ]
    },
    {
        "idx": 38280,
        "repo_name": "c0dearm_yaru",
        "url": "https://github.com/c0dearm/yaru",
        "description": "Write and manage your project's development scripts with modern Python syntax",
        "stars": 6,
        "forks": 2,
        "language": "python",
        "size": 65,
        "created_at": "2025-02-20T09:26:31+00:00",
        "updated_at": "2025-03-22T13:01:31+00:00",
        "pypi_info": {
            "name": "yaru",
            "version": "0.2.0",
            "url": "https://files.pythonhosted.org/packages/fa/41/c7897972e96c34cfa720844870adbb6355512313f77899396b4dd9353084/yaru-0.2.0.tar.gz"
        },
        "error": null,
        "judge_info": {
            "language": "python",
            "is_good_project": false,
            "reason": "",
            "python_file_num": 12,
            "comment_ratio": 0.07244655581947744,
            "pyfile_content_length": 27936,
            "pyfile_code_lines": 842,
            "test_file_exist": true,
            "test_file_content_length": 13857,
            "pytest_framework": true,
            "test_case_num": 20,
            "metadata_path": [
                "pyproject.toml"
            ],
            "readme_content_length": 4850,
            "llm_reason": "The YARU project is highly suitable as an AI 'Build from Scratch' benchmark.\n\nPositive aspects:\n*   **Self-Contained & Independent:** The library itself has zero external dependencies. Its core functionality (defining and parsing commands from Python functions, integrating with `argparse`, and providing a `Context.run` method for local shell execution) does not require an active internet connection or any third-party APIs/services for its operation. The AI would primarily use Python's standard library (`inspect`, `argparse`, `subprocess`).\n*   **Clear & Well-Defined Functionality:** The project's goal is to convert Python functions into CLI commands using a decorator (`@command`), automatically parsing function signatures (including type hints like `typing.Annotated`), docstrings, and comments for CLI argument configuration and help text. This is clearly explained in the README with examples, making the specification for AI replication straightforward.\n*   **Testable & Verifiable Output:** The project includes a comprehensive suite of unit tests (`tests` directory using `pytest` and `unittest.mock`) covering command creation, argument parsing, context execution, and the main CLI entry point. These tests can be directly used or adapted to verify the AI-generated solution.\n*   **No Graphical User Interface (GUI):** The project is a command-line tool and library, fitting the no-GUI requirement.\n*   **Appropriate Complexity & Scope (Medium):** Rebuilding YARU involves understanding and implementing Python decorators, function introspection (using the `inspect` module), dynamic CLI construction with `argparse` (including subparsers, custom argument types like Enums, and boolean flag handling), and basic object-oriented design (e.g., `Command`, `CommandArgument`, `Context` classes). The codebase is small and focused (around 5 core Python files in `src/yaru`), making it manageable for an AI to replicate within a reasonable timeframe, yet complex enough to be a meaningful benchmark. It's significantly more involved than a trivial example but not overwhelmingly large.\n*   **Well-Understood Problem Domain:** Creating task runners or CLI wrappers for functions is a common problem in software development, with established patterns and concepts.\n*   **Predominantly Code-Based Solution:** The task is to generate Python code for the library.\n*   **Modern Python:** Utilizes Python >= 3.12 features, making it a relevant benchmark.\n\nNegative aspects or concerns:\n*   The `Context.run` method executes shell commands. While this is a local operation and standard for such tools, the specification for the AI must be clear that the benchmark is about *rebuilding YARU's functionality to call shell commands*, not about ensuring the safety or self-containment of arbitrary commands a user might later define using the rebuilt YARU. The existing tests for `Context.run` correctly mock `subprocess.run`, mitigating this for testing the library itself.\n*   The interplay between `inspect`, `argparse`, decorators, and type hint parsing can be intricate to implement correctly, contributing to the 'Medium' difficulty. This is a desired challenge for a benchmark, not a disqualifier.\n\nOverall, YARU is an excellent candidate because it's a realistic, self-contained, well-tested, and appropriately complex Python library whose recreation would effectively test an AI's ability to understand specifications, use standard Python features for introspection and CLI building, and structure a small but functional software project.",
            "llm_project_type": "Python library for creating CLI task runners/development script managers",
            "llm_rating": 90,
            "llm_difficulty": "Medium"
        },
        "tests": {
            "repo_name": "c0dearm_yaru",
            "finish_test": true,
            "test_case_result": {
                "tests/test_argument.py::test_command_argument_init[command_argument0]": "passed",
                "tests/test_argument.py::test_command_argument_is_optional[0-True]": "passed",
                "tests/test_argument.py::test_command_argument_is_optional[None-True]": "passed",
                "tests/test_argument.py::test_command_argument_is_optional[_Empty-False]": "passed",
                "tests/test_argument.py::test_command_argument_arg_type[int]": "passed",
                "tests/test_argument.py::test_command_argument_arg_type[str]": "passed",
                "tests/test_argument.py::test_command_argument_arg_type[float]": "passed",
                "tests/test_argument.py::test_command_argument_arg_type[bool]": "passed",
                "tests/test_argument.py::test_command_argument_arg_type[MockEnum]": "passed",
                "tests/test_argument.py::test_command_argument_from_paramater_ok[parameter0-expected0]": "passed",
                "tests/test_argument.py::test_command_argument_from_paramater_ok[parameter1-expected1]": "passed",
                "tests/test_argument.py::test_command_argument_from_paramater_ok[parameter2-expected2]": "passed",
                "tests/test_argument.py::test_command_argument_from_paramater_ok[parameter3-expected3]": "passed",
                "tests/test_argument.py::test_command_argument_from_paramater_invalid[parameter0-MissingArgumentTypeHintError]": "passed",
                "tests/test_argument.py::test_command_argument_from_paramater_invalid[parameter1-InvalidAnnotationTypeError]": "passed",
                "tests/test_argument.py::test_command_argument_from_paramater_invalid[parameter2-InvalidArgumentTypeHintError]": "passed",
                "tests/test_argument.py::test_command_argument_add_to_parser[bool-False-call0]": "passed",
                "tests/test_argument.py::test_command_argument_add_to_parser[bool-_Empty-call1]": "passed",
                "tests/test_argument.py::test_command_argument_add_to_parser[int-0-call2]": "passed",
                "tests/test_argument.py::test_command_argument_add_to_parser[int-_Empty-call3]": "passed",
                "tests/test_argument.py::test_command_argument_add_to_parser[MockEnum-foo-call4]": "passed",
                "tests/test_argument.py::test_command_argument_add_to_parser[MockEnum-_Empty-call5]": "passed",
                "tests/test_argument.py::test_parse_literal_as_boolean[1-True]": "passed",
                "tests/test_argument.py::test_parse_literal_as_boolean[0-False]": "passed",
                "tests/test_argument.py::test_parse_literal_as_boolean[True-True]": "passed",
                "tests/test_argument.py::test_parse_literal_as_boolean[False-False]": "passed",
                "tests/test_argument.py::test_enum_action": "passed",
                "tests/test_command.py::test_command_init[command0]": "passed",
                "tests/test_command.py::test_command_init[command1]": "passed",
                "tests/test_command.py::test_command_parse_help": "passed",
                "tests/test_command.py::test_command_parse_description": "passed",
                "tests/test_command.py::test_command_parse_parameters": "passed",
                "tests/test_command.py::test_command_from_callable[dummy_name-dummy_name]": "passed",
                "tests/test_command.py::test_command_from_callable[None-dummy-function]": "passed",
                "tests/test_command.py::test_command_register": "passed",
                "tests/test_command.py::test_command_set_as_cli": "passed",
                "tests/test_command.py::test_command_decorator_with_args": "passed",
                "tests/test_command.py::test_command_decorator_without": "passed",
                "tests/test_context.py::test_context_run": "passed",
                "tests/test_context.py::test_context_run_fallible": "passed",
                "tests/test_init.py::test_main": "passed"
            },
            "success_count": 41,
            "failed_count": 0,
            "error_count": 0,
            "skipped_count": 0,
            "unknown_count": 0,
            "total_count": 41,
            "success_rate": 1.0,
            "coverage_report": {
                "covered_lines": 153,
                "num_statements": 158,
                "percent_covered": 97.36842105263158,
                "percent_covered_display": "97",
                "missing_lines": 5,
                "excluded_lines": 0,
                "num_branches": 32,
                "num_partial_branches": 0,
                "covered_branches": 32,
                "missing_branches": 0
            },
            "coverage_result": {}
        },
        "codelines_count": 842,
        "codefiles_count": 12,
        "code_length": 27936,
        "test_files_count": 4,
        "test_code_length": 13857,
        "structure": [
            {
                "file": "commands.py",
                "functions": [
                    {
                        "name": "run_tests",
                        "docstring": "Execute all the project's unit tests with optional coverage.",
                        "comments": null,
                        "args": [
                            "c",
                            "docs",
                            "coverage"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_command.py",
                "functions": [
                    {
                        "name": "test_command_init",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "command"
                        ]
                    },
                    {
                        "name": "test_command_parse_help",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_command_parse_description",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_command_parse_parameters",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_command_from_callable",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "name",
                            "expected"
                        ]
                    },
                    {
                        "name": "test_command_register",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_command_set_as_cli",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_command_decorator_with_args",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_command_decorator_without",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_context.py",
                "functions": [
                    {
                        "name": "test_context_run",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_context_run_fallible",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "mock_exit",
                            "mock_run"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/conftest.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/test_argument.py",
                "functions": [
                    {
                        "name": "test_command_argument_init",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "command_argument"
                        ]
                    },
                    {
                        "name": "test_command_argument_is_optional",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "default",
                            "expected"
                        ]
                    },
                    {
                        "name": "test_command_argument_arg_type",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "arg_type"
                        ]
                    },
                    {
                        "name": "test_command_argument_from_paramater_ok",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "parameter",
                            "expected"
                        ]
                    },
                    {
                        "name": "test_command_argument_from_paramater_invalid",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "parameter",
                            "exception"
                        ]
                    },
                    {
                        "name": "test_command_argument_add_to_parser",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "arg_type",
                            "default",
                            "call"
                        ]
                    },
                    {
                        "name": "test_parse_literal_as_boolean",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "literal",
                            "expected"
                        ]
                    },
                    {
                        "name": "test_enum_action",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": [
                    {
                        "name": "MockEnum",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "FOO",
                            "BAR"
                        ]
                    }
                ]
            },
            {
                "file": "tests/test_init.py",
                "functions": [
                    {
                        "name": "test_main",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "src/yaru/context.py",
                "functions": [],
                "classes": [
                    {
                        "name": "Context",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "run",
                                "docstring": "Executes the provided instructions in a shell.\n\nUnless `fallible` is set to `True`, the program will finish immediatelly with the\nsame exit code as the failed shell command.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "src/yaru/exceptions.py",
                "functions": [],
                "classes": [
                    {
                        "name": "YaruError",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "MissingArgumentTypeHintError",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "InvalidAnnotationTypeError",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "InvalidArgumentTypeHintError",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "src/yaru/__init__.py",
                "functions": [
                    {
                        "name": "main",
                        "docstring": "Main entrypoint for `yaru`. Collects the registered commands in the `commands` module and builds the cli.",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "src/yaru/argument.py",
                "functions": [
                    {
                        "name": "_parse_literal_as_boolean",
                        "docstring": "Used by argparse when a non-optional boolean is used as a command argument.\nIt interprets strings like '1', '0', 'true', 'false' as booleans.",
                        "comments": null,
                        "args": [
                            "literal"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "Arg",
                        "docstring": "Used to provide extra metadata for an argument as part of an annotated type.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "CommandArgument",
                        "docstring": "Used by the Command class to store the information concerning its cli arguments.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "default",
                                    "help",
                                    "metavar"
                                ]
                            },
                            {
                                "name": "is_optional",
                                "docstring": "`true` if the argument is optional, `false` otherwise.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "arg_type",
                                "docstring": "The type of this argument.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "from_parameter",
                                "docstring": "Builds an instance of this class given a function parameter obtained by `inspect.signature`.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "parameter"
                                ]
                            },
                            {
                                "name": "add_to_parser",
                                "docstring": "Given a command parser, adds itself as an argument of that command.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "parser"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "_EnumAction",
                        "docstring": "Argparse action for handling Enums.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__call__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "parser",
                                    "namespace",
                                    "values",
                                    "option_string"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "_Empty",
                        "docstring": "Used to represent an argument without default value.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "src/yaru/command.py",
                "functions": [
                    {
                        "name": "command",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "func"
                        ]
                    },
                    {
                        "name": "command",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "command",
                        "docstring": "Registers the given function as a `yaru` command, so that it is callable via the cli.\n\nExample:\n\n```pydoc\n>>> from yaru import command, Context\n\n>>> @command\n... def run_tests(c: Context, coverage: bool = False) -> None:\n...     c.run(\"pytest\", \"--coverage\" if coverage else \"\")\n\n```\n\nThis function can now be called from the cli as a command, like:\n```sh\nyaru run-tests --coverage\n```",
                        "comments": null,
                        "args": [
                            "func"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "Command",
                        "docstring": "Commands built and registered by the @command decorator.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "name",
                                    "func",
                                    "arguments",
                                    "help",
                                    "aliases",
                                    "prog",
                                    "usage",
                                    "description",
                                    "epilog"
                                ]
                            },
                            {
                                "name": "parse_help",
                                "docstring": "Extracts the command's help text from the function's preceding comment in a single line, cleaning up all the '#'.",
                                "comments": null,
                                "args": [
                                    "func"
                                ]
                            },
                            {
                                "name": "parse_description",
                                "docstring": "Extracts the command's description from the function's docstring.",
                                "comments": null,
                                "args": [
                                    "func"
                                ]
                            },
                            {
                                "name": "parse_parameters",
                                "docstring": "Parses the command's arguments from the function's signature.",
                                "comments": null,
                                "args": [
                                    "func"
                                ]
                            },
                            {
                                "name": "from_callable",
                                "docstring": "Create a new `Command` instance from the given function, injecting the `Context` as the first argument.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "func",
                                    "name",
                                    "aliases"
                                ]
                            },
                            {
                                "name": "registry",
                                "docstring": "Access the commands registered so far.",
                                "comments": null,
                                "args": [
                                    "cls"
                                ]
                            },
                            {
                                "name": "register",
                                "docstring": "Add the command to the registry.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "set_as_cli",
                                "docstring": "Given an argparse subparser, set the command as a cli option.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "subparsers"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            }
        ],
        "test_cases": {
            "tests/test_argument.py::test_command_argument_init[command_argument0]": {
                "testid": "tests/test_argument.py::test_command_argument_init[command_argument0]",
                "result": "passed",
                "test_implementation": "def test_command_argument_init(command_argument: CommandArgument) -> None:\n    assert command_argument.name == \"name\"\n    assert command_argument.default == 0\n    assert command_argument.help == \"help\"\n    assert command_argument.metavar == \"metavar\""
            },
            "tests/test_argument.py::test_command_argument_is_optional[0-True]": {
                "testid": "tests/test_argument.py::test_command_argument_is_optional[0-True]",
                "result": "passed",
                "test_implementation": "def test_command_argument_is_optional(\n    default: int | None | type[CommandArgument._Empty], expected: bool\n) -> None:\n    assert CommandArgument(\"name\", default=default).is_optional == expected"
            },
            "tests/test_argument.py::test_command_argument_is_optional[None-True]": {
                "testid": "tests/test_argument.py::test_command_argument_is_optional[None-True]",
                "result": "passed",
                "test_implementation": "def test_command_argument_is_optional(\n    default: int | None | type[CommandArgument._Empty], expected: bool\n) -> None:\n    assert CommandArgument(\"name\", default=default).is_optional == expected"
            },
            "tests/test_argument.py::test_command_argument_is_optional[_Empty-False]": {
                "testid": "tests/test_argument.py::test_command_argument_is_optional[_Empty-False]",
                "result": "passed",
                "test_implementation": "def test_command_argument_is_optional(\n    default: int | None | type[CommandArgument._Empty], expected: bool\n) -> None:\n    assert CommandArgument(\"name\", default=default).is_optional == expected"
            },
            "tests/test_argument.py::test_command_argument_arg_type[int]": {
                "testid": "tests/test_argument.py::test_command_argument_arg_type[int]",
                "result": "passed",
                "test_implementation": "def test_command_argument_arg_type(arg_type: type) -> None:\n    assert CommandArgument[arg_type](\"name\").arg_type is arg_type"
            },
            "tests/test_argument.py::test_command_argument_arg_type[str]": {
                "testid": "tests/test_argument.py::test_command_argument_arg_type[str]",
                "result": "passed",
                "test_implementation": "def test_command_argument_arg_type(arg_type: type) -> None:\n    assert CommandArgument[arg_type](\"name\").arg_type is arg_type"
            },
            "tests/test_argument.py::test_command_argument_arg_type[float]": {
                "testid": "tests/test_argument.py::test_command_argument_arg_type[float]",
                "result": "passed",
                "test_implementation": "def test_command_argument_arg_type(arg_type: type) -> None:\n    assert CommandArgument[arg_type](\"name\").arg_type is arg_type"
            },
            "tests/test_argument.py::test_command_argument_arg_type[bool]": {
                "testid": "tests/test_argument.py::test_command_argument_arg_type[bool]",
                "result": "passed",
                "test_implementation": "def test_command_argument_arg_type(arg_type: type) -> None:\n    assert CommandArgument[arg_type](\"name\").arg_type is arg_type"
            },
            "tests/test_argument.py::test_command_argument_arg_type[MockEnum]": {
                "testid": "tests/test_argument.py::test_command_argument_arg_type[MockEnum]",
                "result": "passed",
                "test_implementation": "def test_command_argument_arg_type(arg_type: type) -> None:\n    assert CommandArgument[arg_type](\"name\").arg_type is arg_type"
            },
            "tests/test_argument.py::test_command_argument_from_paramater_ok[parameter0-expected0]": {
                "testid": "tests/test_argument.py::test_command_argument_from_paramater_ok[parameter0-expected0]",
                "result": "passed",
                "test_implementation": "def test_command_argument_from_paramater_ok(\n    parameter: Parameter, expected: CommandArgument\n) -> None:\n    argument = CommandArgument.from_parameter(parameter)\n    assert argument.name == expected.name\n    assert argument.arg_type == expected.arg_type\n    assert argument.default == expected.default\n    assert argument.help == expected.help\n    assert argument.metavar == expected.metavar"
            },
            "tests/test_argument.py::test_command_argument_from_paramater_ok[parameter1-expected1]": {
                "testid": "tests/test_argument.py::test_command_argument_from_paramater_ok[parameter1-expected1]",
                "result": "passed",
                "test_implementation": "def test_command_argument_from_paramater_ok(\n    parameter: Parameter, expected: CommandArgument\n) -> None:\n    argument = CommandArgument.from_parameter(parameter)\n    assert argument.name == expected.name\n    assert argument.arg_type == expected.arg_type\n    assert argument.default == expected.default\n    assert argument.help == expected.help\n    assert argument.metavar == expected.metavar"
            },
            "tests/test_argument.py::test_command_argument_from_paramater_ok[parameter2-expected2]": {
                "testid": "tests/test_argument.py::test_command_argument_from_paramater_ok[parameter2-expected2]",
                "result": "passed",
                "test_implementation": "def test_command_argument_from_paramater_ok(\n    parameter: Parameter, expected: CommandArgument\n) -> None:\n    argument = CommandArgument.from_parameter(parameter)\n    assert argument.name == expected.name\n    assert argument.arg_type == expected.arg_type\n    assert argument.default == expected.default\n    assert argument.help == expected.help\n    assert argument.metavar == expected.metavar"
            },
            "tests/test_argument.py::test_command_argument_from_paramater_ok[parameter3-expected3]": {
                "testid": "tests/test_argument.py::test_command_argument_from_paramater_ok[parameter3-expected3]",
                "result": "passed",
                "test_implementation": "def test_command_argument_from_paramater_ok(\n    parameter: Parameter, expected: CommandArgument\n) -> None:\n    argument = CommandArgument.from_parameter(parameter)\n    assert argument.name == expected.name\n    assert argument.arg_type == expected.arg_type\n    assert argument.default == expected.default\n    assert argument.help == expected.help\n    assert argument.metavar == expected.metavar"
            },
            "tests/test_argument.py::test_command_argument_from_paramater_invalid[parameter0-MissingArgumentTypeHintError]": {
                "testid": "tests/test_argument.py::test_command_argument_from_paramater_invalid[parameter0-MissingArgumentTypeHintError]",
                "result": "passed",
                "test_implementation": "def test_command_argument_from_paramater_invalid(\n    parameter: Parameter, exception: type[YaruError]\n) -> None:\n    with pytest.raises(exception):\n        CommandArgument.from_parameter(parameter)"
            },
            "tests/test_argument.py::test_command_argument_from_paramater_invalid[parameter1-InvalidAnnotationTypeError]": {
                "testid": "tests/test_argument.py::test_command_argument_from_paramater_invalid[parameter1-InvalidAnnotationTypeError]",
                "result": "passed",
                "test_implementation": "def test_command_argument_from_paramater_invalid(\n    parameter: Parameter, exception: type[YaruError]\n) -> None:\n    with pytest.raises(exception):\n        CommandArgument.from_parameter(parameter)"
            },
            "tests/test_argument.py::test_command_argument_from_paramater_invalid[parameter2-InvalidArgumentTypeHintError]": {
                "testid": "tests/test_argument.py::test_command_argument_from_paramater_invalid[parameter2-InvalidArgumentTypeHintError]",
                "result": "passed",
                "test_implementation": "def test_command_argument_from_paramater_invalid(\n    parameter: Parameter, exception: type[YaruError]\n) -> None:\n    with pytest.raises(exception):\n        CommandArgument.from_parameter(parameter)"
            },
            "tests/test_argument.py::test_command_argument_add_to_parser[bool-False-call0]": {
                "testid": "tests/test_argument.py::test_command_argument_add_to_parser[bool-False-call0]",
                "result": "passed",
                "test_implementation": "def test_command_argument_add_to_parser(\n    arg_type: bool | int,\n    default: bool | type[CommandArgument._Empty] | int,\n    call: _Call,\n) -> None:\n    mock_add_argument = Mock()\n\n    argument = CommandArgument[arg_type](\n        \"name\", default=default, help=\"help\", metavar=\"metavar\"\n    )\n    argument.add_to_parser(Mock(add_argument=mock_add_argument))\n    mock_add_argument.assert_has_calls([call])"
            },
            "tests/test_argument.py::test_command_argument_add_to_parser[bool-_Empty-call1]": {
                "testid": "tests/test_argument.py::test_command_argument_add_to_parser[bool-_Empty-call1]",
                "result": "passed",
                "test_implementation": "def test_command_argument_add_to_parser(\n    arg_type: bool | int,\n    default: bool | type[CommandArgument._Empty] | int,\n    call: _Call,\n) -> None:\n    mock_add_argument = Mock()\n\n    argument = CommandArgument[arg_type](\n        \"name\", default=default, help=\"help\", metavar=\"metavar\"\n    )\n    argument.add_to_parser(Mock(add_argument=mock_add_argument))\n    mock_add_argument.assert_has_calls([call])"
            },
            "tests/test_argument.py::test_command_argument_add_to_parser[int-0-call2]": {
                "testid": "tests/test_argument.py::test_command_argument_add_to_parser[int-0-call2]",
                "result": "passed",
                "test_implementation": "def test_command_argument_add_to_parser(\n    arg_type: bool | int,\n    default: bool | type[CommandArgument._Empty] | int,\n    call: _Call,\n) -> None:\n    mock_add_argument = Mock()\n\n    argument = CommandArgument[arg_type](\n        \"name\", default=default, help=\"help\", metavar=\"metavar\"\n    )\n    argument.add_to_parser(Mock(add_argument=mock_add_argument))\n    mock_add_argument.assert_has_calls([call])"
            },
            "tests/test_argument.py::test_command_argument_add_to_parser[int-_Empty-call3]": {
                "testid": "tests/test_argument.py::test_command_argument_add_to_parser[int-_Empty-call3]",
                "result": "passed",
                "test_implementation": "def test_command_argument_add_to_parser(\n    arg_type: bool | int,\n    default: bool | type[CommandArgument._Empty] | int,\n    call: _Call,\n) -> None:\n    mock_add_argument = Mock()\n\n    argument = CommandArgument[arg_type](\n        \"name\", default=default, help=\"help\", metavar=\"metavar\"\n    )\n    argument.add_to_parser(Mock(add_argument=mock_add_argument))\n    mock_add_argument.assert_has_calls([call])"
            },
            "tests/test_argument.py::test_command_argument_add_to_parser[MockEnum-foo-call4]": {
                "testid": "tests/test_argument.py::test_command_argument_add_to_parser[MockEnum-foo-call4]",
                "result": "passed",
                "test_implementation": "def test_command_argument_add_to_parser(\n    arg_type: bool | int,\n    default: bool | type[CommandArgument._Empty] | int,\n    call: _Call,\n) -> None:\n    mock_add_argument = Mock()\n\n    argument = CommandArgument[arg_type](\n        \"name\", default=default, help=\"help\", metavar=\"metavar\"\n    )\n    argument.add_to_parser(Mock(add_argument=mock_add_argument))\n    mock_add_argument.assert_has_calls([call])"
            },
            "tests/test_argument.py::test_command_argument_add_to_parser[MockEnum-_Empty-call5]": {
                "testid": "tests/test_argument.py::test_command_argument_add_to_parser[MockEnum-_Empty-call5]",
                "result": "passed",
                "test_implementation": "def test_command_argument_add_to_parser(\n    arg_type: bool | int,\n    default: bool | type[CommandArgument._Empty] | int,\n    call: _Call,\n) -> None:\n    mock_add_argument = Mock()\n\n    argument = CommandArgument[arg_type](\n        \"name\", default=default, help=\"help\", metavar=\"metavar\"\n    )\n    argument.add_to_parser(Mock(add_argument=mock_add_argument))\n    mock_add_argument.assert_has_calls([call])"
            },
            "tests/test_argument.py::test_parse_literal_as_boolean[1-True]": {
                "testid": "tests/test_argument.py::test_parse_literal_as_boolean[1-True]",
                "result": "passed",
                "test_implementation": "def test_parse_literal_as_boolean(literal: str, expected: bool) -> None:\n    assert _parse_literal_as_boolean(literal) == expected"
            },
            "tests/test_argument.py::test_parse_literal_as_boolean[0-False]": {
                "testid": "tests/test_argument.py::test_parse_literal_as_boolean[0-False]",
                "result": "passed",
                "test_implementation": "def test_parse_literal_as_boolean(literal: str, expected: bool) -> None:\n    assert _parse_literal_as_boolean(literal) == expected"
            },
            "tests/test_argument.py::test_parse_literal_as_boolean[True-True]": {
                "testid": "tests/test_argument.py::test_parse_literal_as_boolean[True-True]",
                "result": "passed",
                "test_implementation": "def test_parse_literal_as_boolean(literal: str, expected: bool) -> None:\n    assert _parse_literal_as_boolean(literal) == expected"
            },
            "tests/test_argument.py::test_parse_literal_as_boolean[False-False]": {
                "testid": "tests/test_argument.py::test_parse_literal_as_boolean[False-False]",
                "result": "passed",
                "test_implementation": "def test_parse_literal_as_boolean(literal: str, expected: bool) -> None:\n    assert _parse_literal_as_boolean(literal) == expected"
            },
            "tests/test_argument.py::test_enum_action": {
                "testid": "tests/test_argument.py::test_enum_action",
                "result": "passed",
                "test_implementation": "def test_enum_action() -> None:\n    action, namespace = _EnumAction([], \"dest\", type=MockEnum), MagicMock()\n    action(MagicMock(), namespace, values=\"FOO\")\n    assert getattr(namespace, action.dest) == MockEnum.FOO"
            },
            "tests/test_command.py::test_command_init[command0]": {
                "testid": "tests/test_command.py::test_command_init[command0]",
                "result": "passed",
                "test_implementation": "def test_command_init(command: Command) -> None:\n    assert command.name == \"name\"\n    assert command.func == Mock\n    assert command.arguments == []\n    assert command.help == \"help\"\n    assert command.aliases == []\n    assert command.prog == \"prog\"\n    assert command.usage == \"usage\"\n    assert command.description == \"description\"\n    assert command.epilog == \"epilog\""
            },
            "tests/test_command.py::test_command_init[command1]": {
                "testid": "tests/test_command.py::test_command_init[command1]",
                "result": "passed",
                "test_implementation": "def test_command_init(command: Command) -> None:\n    assert command.name == \"name\"\n    assert command.func == Mock\n    assert command.arguments == []\n    assert command.help == \"help\"\n    assert command.aliases == []\n    assert command.prog == \"prog\"\n    assert command.usage == \"usage\"\n    assert command.description == \"description\"\n    assert command.epilog == \"epilog\""
            },
            "tests/test_command.py::test_command_parse_help": {
                "testid": "tests/test_command.py::test_command_parse_help",
                "result": "passed",
                "test_implementation": "def test_command_parse_help() -> None:\n    ### A mock function with a\n    ### pair of lines of comments\n    def function_with_comments(): ...\n\n    def function_without_comments(): ...\n\n    assert (\n        Command.parse_help(function_with_comments)\n        == \"A mock function with a pair of lines of comments\"\n    )\n    assert Command.parse_help(function_without_comments) is None"
            },
            "tests/test_command.py::test_command_parse_description": {
                "testid": "tests/test_command.py::test_command_parse_description",
                "result": "passed",
                "test_implementation": "def test_command_parse_description() -> None:\n    def function_with_docstring() -> None:\n        \"\"\"\n        A mock function with a\n        pair of lines of docstring\n        \"\"\"\n\n    def function_without_docstring(): ...\n\n    assert (\n        Command.parse_description(function_with_docstring)\n        == \"A mock function with a\\npair of lines of docstring\"\n    )\n    assert Command.parse_description(function_without_docstring) is None"
            },
            "tests/test_command.py::test_command_parse_parameters": {
                "testid": "tests/test_command.py::test_command_parse_parameters",
                "result": "passed",
                "test_implementation": "def test_command_parse_parameters() -> None:\n    def function_with_args(a: int, b: str): ...\n\n    with patch(\"yaru.command.CommandArgument.from_parameter\") as mock_from_parameter:\n        parameters = Command.parse_parameters(function_with_args)\n        mock_from_parameter.assert_has_calls(\n            [\n                call(Parameter(\"a\", Parameter.POSITIONAL_OR_KEYWORD, annotation=int)),\n                call(Parameter(\"b\", Parameter.POSITIONAL_OR_KEYWORD, annotation=str)),\n            ]\n        )\n\n    assert len(parameters) == 2"
            },
            "tests/test_command.py::test_command_from_callable[dummy_name-dummy_name]": {
                "testid": "tests/test_command.py::test_command_from_callable[dummy_name-dummy_name]",
                "result": "passed",
                "test_implementation": "def test_command_from_callable(name: str | None, expected: str) -> None:\n    def dummy_function(): ...\n\n    with (\n        patch(\"yaru.command.Command.parse_parameters\") as mock_parse_parameters,\n        patch(\"yaru.command.Command.parse_help\") as mock_parse_help,\n        patch(\"yaru.command.Command.parse_description\") as mock_parse_description,\n    ):\n        command = Command.from_callable(dummy_function, name=name)\n        mock_parse_parameters.assert_called_once_with(command.func)\n        mock_parse_help.assert_called_once_with(dummy_function)\n        mock_parse_description.assert_called_once_with(dummy_function)\n\n    assert command.name == expected\n    assert isinstance(command.func, partial)\n    assert command.func.func == dummy_function\n    assert isinstance(command.func.args[0], Context)\n    assert command.arguments == mock_parse_parameters.return_value\n    assert command.help == mock_parse_help.return_value\n    assert command.description == mock_parse_description.return_value"
            },
            "tests/test_command.py::test_command_from_callable[None-dummy-function]": {
                "testid": "tests/test_command.py::test_command_from_callable[None-dummy-function]",
                "result": "passed",
                "test_implementation": "def test_command_from_callable(name: str | None, expected: str) -> None:\n    def dummy_function(): ...\n\n    with (\n        patch(\"yaru.command.Command.parse_parameters\") as mock_parse_parameters,\n        patch(\"yaru.command.Command.parse_help\") as mock_parse_help,\n        patch(\"yaru.command.Command.parse_description\") as mock_parse_description,\n    ):\n        command = Command.from_callable(dummy_function, name=name)\n        mock_parse_parameters.assert_called_once_with(command.func)\n        mock_parse_help.assert_called_once_with(dummy_function)\n        mock_parse_description.assert_called_once_with(dummy_function)\n\n    assert command.name == expected\n    assert isinstance(command.func, partial)\n    assert command.func.func == dummy_function\n    assert isinstance(command.func.args[0], Context)\n    assert command.arguments == mock_parse_parameters.return_value\n    assert command.help == mock_parse_help.return_value\n    assert command.description == mock_parse_description.return_value"
            },
            "tests/test_command.py::test_command_register": {
                "testid": "tests/test_command.py::test_command_register",
                "result": "passed",
                "test_implementation": "def test_command_register() -> None:\n    command = Command(\"name\", Mock)\n    with patch(\"yaru.command.Command._Command__registry\", set()):\n        command.register()\n        assert Command.registry() == {command}"
            },
            "tests/test_command.py::test_command_set_as_cli": {
                "testid": "tests/test_command.py::test_command_set_as_cli",
                "result": "passed",
                "test_implementation": "def test_command_set_as_cli() -> None:\n    mock_set_defaults = Mock()\n    mock_add_to_parser = Mock()\n    mock_parser = Mock(set_defaults=mock_set_defaults)\n    mock_add_parser = Mock(return_value=mock_parser)\n    mock_subparsers = Mock(add_parser=mock_add_parser)\n    mock_argument = Mock(add_to_parser=mock_add_to_parser)\n\n    command = Command(\"name\", Mock, arguments=[mock_argument])\n    command.set_as_cli(mock_subparsers)\n    mock_add_parser.assert_called_once_with(\n        command.name,\n        help=command.help,\n        aliases=command.aliases,\n        prog=command.prog,\n        usage=command.usage,\n        description=command.description,\n        epilog=command.epilog,\n        formatter_class=RawTextHelpFormatter,\n    )\n    mock_set_defaults.assert_called_once_with(func=Mock)\n    mock_add_to_parser.assert_called_once_with(mock_add_parser.return_value)"
            },
            "tests/test_command.py::test_command_decorator_with_args": {
                "testid": "tests/test_command.py::test_command_decorator_with_args",
                "result": "passed",
                "test_implementation": "def test_command_decorator_with_args() -> None:\n    mock_register = Mock()\n    mock_func = Mock(return_value=0)\n\n    with patch(\n        \"yaru.command.Command.from_callable\", return_value=Mock(register=mock_register)\n    ) as mock_from_callable:\n        decorated = command(name=\"name\", aliases=[\"alias\"])(mock_func)\n        mock_from_callable.assert_called_once_with(\n            mock_func, name=\"name\", aliases=[\"alias\"]\n        )\n        mock_register.assert_called_once()\n\n    assert decorated(Context()) == 0"
            },
            "tests/test_command.py::test_command_decorator_without": {
                "testid": "tests/test_command.py::test_command_decorator_without",
                "result": "passed",
                "test_implementation": "def test_command_decorator_without() -> None:\n    mock_register = Mock()\n    mock_func = Mock(return_value=0)\n\n    with patch(\n        \"yaru.command.Command.from_callable\", return_value=Mock(register=mock_register)\n    ) as mock_from_callable:\n        decorated = command(mock_func)\n        mock_from_callable.assert_called_once_with(mock_func, name=None, aliases=None)\n        mock_register.assert_called_once()\n\n    assert decorated(Context()) == 0"
            },
            "tests/test_context.py::test_context_run": {
                "testid": "tests/test_context.py::test_context_run",
                "result": "passed",
                "test_implementation": "def test_context_run() -> None:\n    context = Context()\n    with patch(\"yaru.context.subprocess.run\") as mock_run:\n        context.run(\"a\", \"b\", \"c\", env={\"TEST\": \"1\"}, fallible=True)\n        mock_run.assert_called_once_with(\n            \"a b c\", env={\"TEST\": \"1\"}, check=False, shell=True\n        )"
            },
            "tests/test_context.py::test_context_run_fallible": {
                "testid": "tests/test_context.py::test_context_run_fallible",
                "result": "passed",
                "test_implementation": "def test_context_run_fallible(mock_exit, mock_run) -> None:\n    context = Context()\n    with (\n        patch(\n            \"yaru.context.subprocess.run\", side_effect=CalledProcessError(1, \"\")\n        ) as mock_run,\n        patch(\"yaru.context.exit\") as mock_exit,\n    ):\n        context.run(\"a\", \"b\", \"c\", env={\"TEST\": \"1\"}, fallible=False)\n        mock_run.assert_called_once_with(\n            \"a b c\", env={\"TEST\": \"1\"}, check=True, shell=True\n        )\n        mock_exit.assert_called_once_with(1)"
            },
            "tests/test_init.py::test_main": {
                "testid": "tests/test_init.py::test_main",
                "result": "passed",
                "test_implementation": "def test_main() -> None:\n    mock_set_as_cli = Mock()\n    mock_add_supbarsers = Mock()\n    mock_parse_args = Mock()\n    mock_parser = Mock(add_subparsers=mock_add_supbarsers, parse_args=mock_parse_args)\n\n    with (\n        patch(\"yaru.Command.registry\", return_value={Mock(set_as_cli=mock_set_as_cli)}),\n        patch(\n            \"yaru.argparse.ArgumentParser\", return_value=mock_parser\n        ) as mock_argument_parser,\n    ):\n        main()\n        mock_argument_parser.assert_called_once_with(\n            description=\"Project's development commands\"\n        )\n        mock_add_supbarsers.assert_called_once_with(dest=\"command\", required=True)\n        mock_set_as_cli.assert_called_once_with(mock_add_supbarsers.return_value)\n        mock_parse_args.assert_called_once()"
            }
        },
        "SRS_document": "# Software Requirements Specification: YARU CLI Framework\n\n## Table of Contents\n1.  [Introduction](#1-introduction)\n    1.1  [Purpose](#11-purpose)\n    1.2  [Scope](#12-scope)\n    1.3  [Definitions, Acronyms, and Abbreviations](#13-definitions-acronyms-and-abbreviations)\n    1.4  [References](#14-references)\n    1.5  [Overview](#15-overview)\n2.  [Overall Description](#2-overall-description)\n    2.1  [Product Perspective](#21-product-perspective)\n    2.2  [Product Functions](#22-product-functions)\n    2.3  [User Characteristics](#23-user-characteristics)\n    2.4  [Constraints](#24-constraints)\n    2.5  [Assumptions and Dependencies](#25-assumptions-and-dependencies)\n3.  [Specific Requirements](#3-specific-requirements)\n    3.1  [Functional Requirements](#31-functional-requirements)\n        3.1.1  [CLI Entry Point and Command Discovery](#311-cli-entry-point-and-command-discovery)\n        3.1.2  [Command Definition](#312-command-definition)\n        3.1.3  [Command Invocation and Help System](#313-command-invocation-and-help-system)\n        3.1.4  [Argument Parsing and Handling](#314-argument-parsing-and-handling)\n        3.1.5  [Context Object Functionality](#315-context-object-functionality)\n        3.1.6  [Error Handling](#316-error-handling)\n    3.2  [Non-Functional Requirements](#32-non-functional-requirements)\n    3.3  [External Interface Requirements](#33-external-interface-requirements)\n\n---\n\n## 1. Introduction\n\n### 1.1 Purpose\nThis Software Requirements Specification (SRS) document provides a comprehensive description of the functional and non-functional requirements for the YARU CLI Framework. The primary goal of this SRS is to serve as a basis for assessing software developers. Developers will use this document and a subset of original test cases to implement the YARU system. Their success will be measured against all original test cases, including private ones. Therefore, this SRS emphasizes clarity, comprehensiveness (functional), and appropriate abstraction to allow for independent design choices while ensuring full functionality.\n\n### 1.2 Scope\nThe YARU CLI Framework is a Python library that enables developers to create command-line interface (CLI) commands from Python functions. This SRS covers:\n*   The mechanism for defining CLI commands using Python decorators and type hints.\n*   The parsing of function signatures, docstrings, and comments for CLI metadata.\n*   The generation of a CLI interface for invoking these commands.\n*   The provision of a context object for executing shell commands within command functions.\n*   Handling of command-line arguments, including type validation and help text generation.\n*   Error reporting for misconfiguration or misuse.\n\nThe system is intended to be a lightweight, zero-dependency package for modern Python versions.\n\n### 1.3 Definitions, Acronyms, and Abbreviations\n*   **CLI:** Command Line Interface\n*   **SRS:** Software Requirements Specification\n*   **YARU:** The name of the software system being specified.\n*   **Decorator:** A Python language feature used to modify functions or methods.\n*   **Type Hint:** A Python language feature for indicating the expected type of a variable, function parameter, or return value.\n*   **Context:** Refers to the `yaru.Context` object providing execution capabilities to command functions.\n*   **Command Function:** A Python function decorated with `@yaru.command` to become a CLI command.\n*   **Arg Object:** An instance of `yaru.Arg`, used with `typing.Annotated` to provide metadata for command arguments.\n\n### 1.4 References\n*   Original README.md (provided as input)\n*   Original source code (provided as input for LLM contextual understanding)\n*   Original test cases (provided as input for LLM contextual understanding)\n\n### 1.5 Overview\nThis SRS is organized into three main sections:\n*   **Section 1 (Introduction):** Provides purpose, scope, definitions, references, and an overview of the document.\n*   **Section 2 (Overall Description):** Describes the product perspective, summarizes its functions, outlines user characteristics, and lists constraints, assumptions, and dependencies.\n*   **Section 3 (Specific Requirements):** Details the functional requirements, non-functional requirements (if any), and external interface requirements. Functional requirements are categorized by major system capability.\n\n## 2. Overall Description\n\n### 2.1 Product Perspective\nYARU is a Python library designed to simplify the creation of development scripts and CLI tools within a Python project. It allows developers to write plain Python functions and, with minimal effort (typically a single decorator), expose them as commands accessible from the terminal. It aims to replace or supplement traditional shell scripts or more complex CLI framework setups for project-specific tasks. It leverages Python's type hinting system for argument definition and `argparse` (or a similar mechanism) internally for CLI generation.\n\n### 2.2 Product Functions\nThe key functions of the YARU system include:\n*   **Command Registration:** Allowing Python functions to be registered as CLI commands.\n*   **Metadata Extraction:** Automatically deriving command names, help texts, and descriptions from function definitions, docstrings, and comments.\n*   **Argument Definition:** Translating Python function parameters (with type hints) into CLI arguments (positional and optional).\n*   **CLI Generation:** Building a command-line parser that lists available commands and provides help messages.\n*   **Command Execution:** Invoking the appropriate Python function with arguments parsed from the command line.\n*   **Shell Integration:** Providing a mechanism within command functions to execute arbitrary shell commands.\n\n### 2.3 User Characteristics\nThe primary users of YARU are Python developers who need to:\n*   Create and manage development scripts for their projects (e.g., for testing, building, deploying).\n*   Expose utility functions as easily invokable CLI commands.\n*   Prefer writing such scripts in Python using modern syntax.\n\nUsers are expected to be familiar with Python programming, including functions, decorators, and type hints.\n\n### 2.4 Constraints\n*   **C1:** The system shall be implemented in Python.\n*   **C2:** The system shall support Python versions 3.12 and newer.\n*   **C3:** User-defined command functions must be located within a Python module named `commands` (e.g., `commands.py` or a `commands/` directory with an `__init__.py`) at the root of the user's project. This module must be importable from the current working directory when `yaru` is invoked.\n*   **C4:** The system should aim to have zero runtime dependencies beyond the Python standard library.\n\n### 2.5 Assumptions and Dependencies\n*   **A1:** The user's project environment allows the `yaru` CLI tool to modify `sys.path` to include the current working directory, enabling the import of the user's `commands` module.\n*   **A2:** The system relies on Python's standard library features, including but not limited to `inspect` for introspection, `argparse` (or equivalent) for CLI parsing, and `subprocess` for shell command execution.\n\n## 3. Specific Requirements\n\n### 3.1 Functional Requirements\n\n#### 3.1.1 CLI Entry Point and Command Discovery\n\n**FR-CLI-001:** The system shall provide a primary executable (e.g., `yaru`) that serves as the entry point for accessing all defined commands.\n\n**FR-CLI-002:** Upon invocation, the system must locate and load command definitions from a user-project module named `commands`.\n*   The system shall add the current working directory to the Python import path to facilitate loading the `commands` module.\n\n**FR-CLI-003:** The system shall generate a main help message when invoked with a help option (e.g., `-h`, `--help`) without specifying a command.\n*   This help message shall list all registered commands and their short help texts.\n*   The main help message shall have a general description: \"Project's development commands\".\n\n#### 3.1.2 Command Definition\n\n**FR-CMD-001:** The system shall allow developers to define CLI commands by applying a `@command` decorator to Python functions.\n\n**FR-CMD-002:** The system shall automatically derive a command's name from the decorated function's name if not explicitly provided.\n*   The derivation rule is to convert the function name from snake_case to kebab-case (e.g., `my_function` becomes `my-function`).\n\n**FR-CMD-003:** The system shall allow an explicit name to be specified for a command via the `@command` decorator (e.g., `@command(name=\"custom-name\")`).\n\n**FR-CMD-004:** The system shall allow one or more aliases to be specified for a command via the `@command` decorator (e.g., `@command(aliases=[\"alias1\", \"alias2\"])`).\n\n**FR-CMD-005:** The system shall extract a short help text for a command from the comments immediately preceding the decorated function's definition.\n*   All '#' characters shall be removed from the extracted comment.\n*   If multiple comment lines exist, they should be joined into a single line of help text.\n*   If no such comments exist, the command will have no short help text.\n\n**FR-CMD-006:** The system shall extract a longer description for a command from the docstring of the decorated function.\n*   The docstring shall be cleaned (common leading whitespace removed, etc.) to produce the description.\n*   If no docstring exists, the command will have no detailed description.\n\n**FR-CMD-007:** The system shall automatically inject an instance of a `Context` object as the first argument to any decorated command function when it is invoked.\n*   Users defining command functions must declare this first parameter (e.g., `def my_command(c: Context, ...):`).\n\n**FR-CMD-008:** The system shall use a raw text formatter for displaying command help and description, preserving intentional formatting like line breaks from docstrings.\n\n**FR-CMD-009:** The system shall allow command-specific program name, usage text, and epilog text to be configurable internally for display in its help message, although direct user configuration via the `@command` decorator is not exposed.\n\n**FR-CMD-010:** All defined commands shall be registered in an internal registry, making them discoverable by the main CLI entry point.\n\n#### 3.1.3 Command Invocation and Help System\n\n**FR-INV-001:** The system shall allow invocation of a registered command by specifying its name (or alias) after the main executable (e.g., `yaru my-command`).\n\n**FR-INV-002:** The system shall provide a specific help message for each command when invoked with its name followed by a help option (e.g., `yaru my-command --help`).\n*   This help message shall include:\n    *   The command's usage pattern.\n    *   The command's long description (from docstring).\n    *   A list of its positional and optional arguments with their individual help texts (if provided).\n\n**FR-INV-003:** When a command is invoked, the system shall call the corresponding decorated Python function, passing parsed command-line arguments to it.\n\n#### 3.1.4 Argument Parsing and Handling\n\n**FR-ARG-001:** The system shall convert Python function parameters (following the initial `Context` parameter) into CLI arguments for the command.\n\n**FR-ARG-002:** Function parameters without default values shall be treated as mandatory positional CLI arguments.\n\n**FR-ARG-003:** Function parameters with default values shall be treated as optional CLI arguments (flags/options).\n*   The CLI option name shall be derived from the parameter name (e.g., `param_name` becomes `--param-name`).\n\n**FR-ARG-004:** The system shall use type hints on function parameters to determine the expected type of CLI arguments.\n*   Supported types include `int`, `str`, `float`, `bool`, and `enum.Enum` subclasses.\n\n**FR-ARG-005:** For boolean parameters with a default value (optional booleans), the system shall generate corresponding CLI flags (e.g., `--flag` and `--no-flag`).\n\n**FR-ARG-006:** For boolean parameters without a default value (positional booleans), the system shall expect a string literal that can be interpreted as a boolean (e.g., \"True\", \"False\", \"1\", \"0\").\n\n**FR-ARG-007:** For parameters typed as a subclass of `enum.Enum` (specifically `StrEnum` tested, but generally `Enum`), the system shall restrict CLI argument values to the names of the enum members.\n*   The help message for such arguments should list the available choices.\n\n**FR-ARG-008:** The system shall allow specifying help text for individual CLI arguments using `typing.Annotated` with a `yaru.Arg` object (e.g., `param: Annotated[int, Arg(help=\"Help for param\")]`).\n\n**FR-ARG-009:** The system shall allow specifying a metavar for individual CLI arguments using `typing.Annotated` with a `yaru.Arg` object (e.g., `param: Annotated[int, Arg(metavar=\"NUMBER\")]`).\n\n#### 3.1.5 Context Object Functionality\n\n**FR-CTX-001:** The `Context` object, injected into command functions, shall provide a `run` method to execute shell commands.\n*   The `run` method shall accept a variable number of string arguments, which are joined by spaces to form the full shell command.\n*   The `run` method shall execute the command in a shell environment.\n\n**FR-CTX-002:** The `Context.run` method shall accept an optional `env` parameter (a dictionary) to specify environment variables for the shell command execution.\n\n**FR-CTX-003:** If the `fallible` parameter of `Context.run` is set to `False` (or not provided, as it's the default), and the executed shell command returns a non-zero exit code, the YARU application shall terminate immediately with the same exit code as the failed shell command.\n\n**FR-CTX-004:** If the `fallible` parameter of `Context.run` is set to `True`, and the executed shell command returns a non-zero exit code, the YARU application shall not automatically terminate. The error is caught, and execution of the command function continues.\n\n#### 3.1.6 Error Handling\n\n**FR-ERR-001:** The system shall raise a `MissingArgumentTypeHintError` if a command function parameter (other than the `Context` parameter) is defined without a type hint.\n\n**FR-ERR-002:** The system shall raise an `InvalidAnnotationTypeError` if a command function parameter is annotated using `typing.Annotated` but the metadata part is not an instance of `yaru.Arg`.\n\n**FR-ERR-003:** The system shall raise an `InvalidArgumentTypeHintError` if a command function parameter's `typing.Annotated` usage is structurally incorrect for `yaru`'s interpretation (e.g., too many arguments in `Annotated`).\n*   Specifically, `Annotated` should contain the base type and optionally one `Arg` instance.\n\n**FR-ERR-004:** If a command is invoked that is not registered/defined, the CLI parsing mechanism shall report an error (e.g., \"invalid choice\").\n\n### 3.2 Non-Functional Requirements\nBased on the provided test cases and the strict rule that NFRs must be directly validated by an original test case, no specific non-functional requirements have been identified. The existing tests primarily focus on functional correctness.\n\n### 3.3 External Interface Requirements\n\n**EIR-001: Command Line Interface Structure**\nThe system shall expose its functionalities through a command-line interface.\n*   Invocation: `yaru [global options] <command> [command-specific arguments]`\n*   Global Help: `yaru -h` or `yaru --help`\n*   Command Help: `yaru <command> -h` or `yaru <command> --help`\n*   Argument Syntax:\n    *   Positional arguments: `yaru <command> value1 value2`\n    *   Optional arguments (flags): `yaru <command> --option value`\n    *   Boolean flags (optional): `yaru <command> --enable-feature` or `yaru <command> --no-enable-feature`\n\n**EIR-002: User-Defined `commands` Module**\nThe system requires user-defined commands to be placed in a Python module named `commands` (e.g., `commands.py` file or a `commands` package directory) located at the root of the project directory from which `yaru` is invoked. This module must be importable by Python.\n",
        "structured_requirements": [
            {
                "requirement_id": "FR-CLI-001",
                "requirement_description": "The system shall provide a primary executable (e.g., `yaru`) that serves as the entry point for accessing all defined commands.",
                "test_traceability": [
                    {
                        "id": "tests/test_init.py::test_main",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/__init__.py::main",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-002",
                "requirement_description": "Upon invocation, the system must locate and load command definitions from a user-project module named `commands`.\n*   The system shall add the current working directory to the Python import path to facilitate loading the `commands` module.",
                "test_traceability": [
                    {
                        "id": "tests/test_init.py::test_main",
                        "description": "(mocked import_module(\"commands\"))"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/__init__.py::main",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-003",
                "requirement_description": "The system shall generate a main help message when invoked with a help option (e.g., `-h`, `--help`) without specifying a command.\n*   This help message shall list all registered commands and their short help texts.\n*   The main help message shall have a general description: \"Project's development commands\".",
                "test_traceability": [
                    {
                        "id": "tests/test_init.py::test_main",
                        "description": "(covers ArgumentParser setup)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/__init__.py::main",
                        "description": "(Conceptual)"
                    },
                    {
                        "id": "src/yaru/command.py::Command::set_as_cli",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-CMD-001",
                "requirement_description": "The system shall allow developers to define CLI commands by applying a `@command` decorator to Python functions.",
                "test_traceability": [
                    {
                        "id": "tests/test_command.py::test_command_decorator_without",
                        "description": ""
                    },
                    {
                        "id": "tests/test_command.py::test_command_decorator_with_args",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/command.py::command",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-CMD-002",
                "requirement_description": "The system shall automatically derive a command's name from the decorated function's name if not explicitly provided.\n*   The derivation rule is to convert the function name from snake_case to kebab-case (e.g., `my_function` becomes `my-function`).",
                "test_traceability": [
                    {
                        "id": "tests/test_command.py::test_command_from_callable",
                        "description": "(where name is `None`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/command.py::Command::from_callable",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-CMD-003",
                "requirement_description": "The system shall allow an explicit name to be specified for a command via the `@command` decorator (e.g., `@command(name=\"custom-name\")`).",
                "test_traceability": [
                    {
                        "id": "tests/test_command.py::test_command_decorator_with_args",
                        "description": ""
                    },
                    {
                        "id": "tests/test_command.py::test_command_from_callable",
                        "description": "(where name is provided)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/command.py::command",
                        "description": "(Conceptual)"
                    },
                    {
                        "id": "src/yaru/command.py::Command::from_callable",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-CMD-004",
                "requirement_description": "The system shall allow one or more aliases to be specified for a command via the `@command` decorator (e.g., `@command(aliases=[\"alias1\", \"alias2\"])`).",
                "test_traceability": [
                    {
                        "id": "tests/test_command.py::test_command_decorator_with_args",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/command.py::command",
                        "description": "(Conceptual)"
                    },
                    {
                        "id": "src/yaru/command.py::Command::from_callable",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-CMD-005",
                "requirement_description": "The system shall extract a short help text for a command from the comments immediately preceding the decorated function's definition.\n*   All '#' characters shall be removed from the extracted comment.\n*   If multiple comment lines exist, they should be joined into a single line of help text.\n*   If no such comments exist, the command will have no short help text.",
                "test_traceability": [
                    {
                        "id": "tests/test_command.py::test_command_parse_help",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/command.py::Command::parse_help",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-CMD-006",
                "requirement_description": "The system shall extract a longer description for a command from the docstring of the decorated function.\n*   The docstring shall be cleaned (common leading whitespace removed, etc.) to produce the description.\n*   If no docstring exists, the command will have no detailed description.",
                "test_traceability": [
                    {
                        "id": "tests/test_command.py::test_command_parse_description",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/command.py::Command::parse_description",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-CMD-007",
                "requirement_description": "The system shall automatically inject an instance of a `Context` object as the first argument to any decorated command function when it is invoked.\n*   Users defining command functions must declare this first parameter (e.g., `def my_command(c: Context, ...):`).",
                "test_traceability": [
                    {
                        "id": "tests/test_command.py::test_command_from_callable",
                        "description": "(checks `isinstance(command.func.args[0], Context)`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/command.py::Command::from_callable",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-CMD-008",
                "requirement_description": "The system shall use a raw text formatter for displaying command help and description, preserving intentional formatting like line breaks from docstrings.",
                "test_traceability": [
                    {
                        "id": "tests/test_command.py::test_command_set_as_cli",
                        "description": "(checks `formatter_class=RawTextHelpFormatter`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/command.py::Command::set_as_cli",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-CMD-009",
                "requirement_description": "The system shall allow command-specific program name, usage text, and epilog text to be configurable internally for display in its help message, although direct user configuration via the `@command` decorator is not exposed.",
                "test_traceability": [
                    {
                        "id": "tests/test_command.py::test_command_init",
                        "description": ""
                    },
                    {
                        "id": "tests/test_command.py::test_command_set_as_cli",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/command.py::Command::__init__",
                        "description": "(Conceptual)"
                    },
                    {
                        "id": "src/yaru/command.py::Command::set_as_cli",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-CMD-010",
                "requirement_description": "All defined commands shall be registered in an internal registry, making them discoverable by the main CLI entry point.",
                "test_traceability": [
                    {
                        "id": "tests/test_command.py::test_command_register",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/command.py::Command::register",
                        "description": "(Conceptual)"
                    },
                    {
                        "id": "src/yaru/command.py::Command::registry",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-INV-001",
                "requirement_description": "The system shall allow invocation of a registered command by specifying its name (or alias) after the main executable (e.g., `yaru my-command`).",
                "test_traceability": [
                    {
                        "id": "tests/test_init.py::test_main",
                        "description": "(checks `args.func(**kwargs)`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/__init__.py::main",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-INV-002",
                "requirement_description": "The system shall provide a specific help message for each command when invoked with its name followed by a help option (e.g., `yaru my-command --help`).\n*   This help message shall include:\n    *   The command's usage pattern.\n    *   The command's long description (from docstring).\n    *   A list of its positional and optional arguments with their individual help texts (if provided).",
                "test_traceability": [
                    {
                        "id": "tests/test_command.py::test_command_set_as_cli",
                        "description": "(checks parameters passed to `add_parser`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/command.py::Command::set_as_cli",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-INV-003",
                "requirement_description": "When a command is invoked, the system shall call the corresponding decorated Python function, passing parsed command-line arguments to it.",
                "test_traceability": [
                    {
                        "id": "tests/test_init.py::test_main",
                        "description": "(checks `args.func(**kwargs)`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/__init__.py::main",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-ARG-001",
                "requirement_description": "The system shall convert Python function parameters (following the initial `Context` parameter) into CLI arguments for the command.",
                "test_traceability": [
                    {
                        "id": "tests/test_command.py::test_command_parse_parameters",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/command.py::Command::parse_parameters",
                        "description": "(Conceptual)"
                    },
                    {
                        "id": "src/yaru/argument.py::CommandArgument::from_parameter",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-ARG-002",
                "requirement_description": "Function parameters without default values shall be treated as mandatory positional CLI arguments.",
                "test_traceability": [
                    {
                        "id": "tests/test_argument.py::test_command_argument_is_optional",
                        "description": ""
                    },
                    {
                        "id": "tests/test_argument.py::test_command_argument_add_to_parser",
                        "description": "(cases where `default == CommandArgument._Empty`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/argument.py::CommandArgument::is_optional",
                        "description": "(Conceptual)"
                    },
                    {
                        "id": "src/yaru/argument.py::CommandArgument::add_to_parser",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-ARG-003",
                "requirement_description": "Function parameters with default values shall be treated as optional CLI arguments (flags/options).\n*   The CLI option name shall be derived from the parameter name (e.g., `param_name` becomes `--param-name`).",
                "test_traceability": [
                    {
                        "id": "tests/test_argument.py::test_command_argument_is_optional",
                        "description": ""
                    },
                    {
                        "id": "tests/test_argument.py::test_command_argument_add_to_parser",
                        "description": "(cases where `default != CommandArgument._Empty`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/argument.py::CommandArgument::is_optional",
                        "description": "(Conceptual)"
                    },
                    {
                        "id": "src/yaru/argument.py::CommandArgument::add_to_parser",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-ARG-004",
                "requirement_description": "The system shall use type hints on function parameters to determine the expected type of CLI arguments.\n*   Supported types include `int`, `str`, `float`, `bool`, and `enum.Enum` subclasses.",
                "test_traceability": [
                    {
                        "id": "tests/test_argument.py::test_command_argument_arg_type",
                        "description": ""
                    },
                    {
                        "id": "tests/test_argument.py::test_command_argument_from_paramater_ok",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/argument.py::CommandArgument::arg_type",
                        "description": "(Conceptual)"
                    },
                    {
                        "id": "src/yaru/argument.py::CommandArgument::add_to_parser",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-ARG-005",
                "requirement_description": "For boolean parameters with a default value (optional booleans), the system shall generate corresponding CLI flags (e.g., `--flag` and `--no-flag`).",
                "test_traceability": [
                    {
                        "id": "tests/test_argument.py::test_command_argument_add_to_parser",
                        "description": "(case: `arg_type=bool, default=False`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/argument.py::CommandArgument::add_to_parser",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-ARG-006",
                "requirement_description": "For boolean parameters without a default value (positional booleans), the system shall expect a string literal that can be interpreted as a boolean (e.g., \"True\", \"False\", \"1\", \"0\").",
                "test_traceability": [
                    {
                        "id": "tests/test_argument.py::test_command_argument_add_to_parser",
                        "description": "(case: `arg_type=bool, default=CommandArgument._Empty`)"
                    },
                    {
                        "id": "tests/test_argument.py::test_parse_literal_as_boolean",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/argument.py::CommandArgument::add_to_parser",
                        "description": "(Conceptual)"
                    },
                    {
                        "id": "src/yaru/argument.py::_parse_literal_as_boolean",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-ARG-007",
                "requirement_description": "For parameters typed as a subclass of `enum.Enum` (specifically `StrEnum` tested, but generally `Enum`), the system shall restrict CLI argument values to the names of the enum members.\n*   The help message for such arguments should list the available choices.",
                "test_traceability": [
                    {
                        "id": "tests/test_argument.py::test_command_argument_add_to_parser",
                        "description": "(cases with `MockEnum`)"
                    },
                    {
                        "id": "tests/test_argument.py::test_enum_action",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/argument.py::CommandArgument::add_to_parser",
                        "description": "(Conceptual)"
                    },
                    {
                        "id": "src/yaru/argument.py::_EnumAction",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-ARG-008",
                "requirement_description": "The system shall allow specifying help text for individual CLI arguments using `typing.Annotated` with a `yaru.Arg` object (e.g., `param: Annotated[int, Arg(help=\"Help for param\")]`).",
                "test_traceability": [
                    {
                        "id": "tests/test_argument.py::test_command_argument_from_paramater_ok",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/argument.py::Arg",
                        "description": "(Conceptual)"
                    },
                    {
                        "id": "src/yaru/argument.py::CommandArgument::from_parameter",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-ARG-009",
                "requirement_description": "The system shall allow specifying a metavar for individual CLI arguments using `typing.Annotated` with a `yaru.Arg` object (e.g., `param: Annotated[int, Arg(metavar=\"NUMBER\")]`).",
                "test_traceability": [
                    {
                        "id": "tests/test_argument.py::test_command_argument_from_paramater_ok",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/argument.py::Arg",
                        "description": "(Conceptual)"
                    },
                    {
                        "id": "src/yaru/argument.py::CommandArgument::from_parameter",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-CTX-001",
                "requirement_description": "The `Context` object, injected into command functions, shall provide a `run` method to execute shell commands.\n*   The `run` method shall accept a variable number of string arguments, which are joined by spaces to form the full shell command.\n*   The `run` method shall execute the command in a shell environment.",
                "test_traceability": [
                    {
                        "id": "tests/test_context.py::test_context_run",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/context.py::Context::run",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-CTX-002",
                "requirement_description": "The `Context.run` method shall accept an optional `env` parameter (a dictionary) to specify environment variables for the shell command execution.",
                "test_traceability": [
                    {
                        "id": "tests/test_context.py::test_context_run",
                        "description": ""
                    },
                    {
                        "id": "tests/test_context.py::test_context_run_fallible",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/context.py::Context::run",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-CTX-003",
                "requirement_description": "If the `fallible` parameter of `Context.run` is set to `False` (or not provided, as it's the default), and the executed shell command returns a non-zero exit code, the YARU application shall terminate immediately with the same exit code as the failed shell command.",
                "test_traceability": [
                    {
                        "id": "tests/test_context.py::test_context_run_fallible",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/context.py::Context::run",
                        "description": "(Conceptual) (check mechanism, `exit(e.returncode)`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-CTX-004",
                "requirement_description": "If the `fallible` parameter of `Context.run` is set to `True`, and the executed shell command returns a non-zero exit code, the YARU application shall not automatically terminate. The error is caught, and execution of the command function continues.",
                "test_traceability": [
                    {
                        "id": "tests/test_context.py::test_context_run",
                        "description": "(check `check=False`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/context.py::Context::run",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-ERR-001",
                "requirement_description": "The system shall raise a `MissingArgumentTypeHintError` if a command function parameter (other than the `Context` parameter) is defined without a type hint.",
                "test_traceability": [
                    {
                        "id": "tests/test_argument.py::test_command_argument_from_paramater_invalid",
                        "description": "(Parameter without annotation)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/argument.py::CommandArgument::from_parameter",
                        "description": "(Conceptual)"
                    },
                    {
                        "id": "src/yaru/exceptions.py::MissingArgumentTypeHintError",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-ERR-002",
                "requirement_description": "The system shall raise an `InvalidAnnotationTypeError` if a command function parameter is annotated using `typing.Annotated` but the metadata part is not an instance of `yaru.Arg`.",
                "test_traceability": [
                    {
                        "id": "tests/test_argument.py::test_command_argument_from_paramater_invalid",
                        "description": "(Parameter with `Annotated[int, str]`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/argument.py::CommandArgument::from_parameter",
                        "description": "(Conceptual)"
                    },
                    {
                        "id": "src/yaru/exceptions.py::InvalidAnnotationTypeError",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-ERR-003",
                "requirement_description": "The system shall raise an `InvalidArgumentTypeHintError` if a command function parameter's `typing.Annotated` usage is structurally incorrect for `yaru`'s interpretation (e.g., too many arguments in `Annotated`).\n*   Specifically, `Annotated` should contain the base type and optionally one `Arg` instance.",
                "test_traceability": [
                    {
                        "id": "tests/test_argument.py::test_command_argument_from_paramater_invalid",
                        "description": "(Parameter with `Annotated[int, str, str]`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/argument.py::CommandArgument::from_parameter",
                        "description": "(Conceptual)"
                    },
                    {
                        "id": "src/yaru/exceptions.py::InvalidArgumentTypeHintError",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "FR-ERR-004",
                "requirement_description": "If a command is invoked that is not registered/defined, the CLI parsing mechanism shall report an error (e.g., \"invalid choice\").",
                "test_traceability": [
                    {
                        "id": "Implicitly covered by standard `argparse` behavior which is leveraged, as seen in `tests/test_init.py::test_main` where `subparsers.add_subparsers(dest=\"command\", required=True)` is used.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/__init__.py::main",
                        "description": "(Conceptual) (argparse setup)"
                    }
                ]
            },
            {
                "requirement_id": "C1",
                "requirement_description": "The system shall be implemented in Python.",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "C2",
                "requirement_description": "The system shall support Python versions 3.12 and newer.",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "C3",
                "requirement_description": "User-defined command functions must be located within a Python module named `commands` (e.g., `commands.py` or a `commands/` directory with an `__init__.py`) at the root of the user's project. This module must be importable from the current working directory when `yaru` is invoked.",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "C4",
                "requirement_description": "The system should aim to have zero runtime dependencies beyond the Python standard library.",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "EIR-001",
                "requirement_description": "Command Line Interface Structure\nThe system shall expose its functionalities through a command-line interface.\n*   Invocation: `yaru [global options] <command> [command-specific arguments]`\n*   Global Help: `yaru -h` or `yaru --help`\n*   Command Help: `yaru <command> -h` or `yaru <command> --help`\n*   Argument Syntax:\n    *   Positional arguments: `yaru <command> value1 value2`\n    *   Optional arguments (flags): `yaru <command> --option value`\n    *   Boolean flags (optional): `yaru <command> --enable-feature` or `yaru <command> --no-enable-feature`",
                "test_traceability": [
                    {
                        "id": "General CLI structure is implicitly tested across various tests, e.g., `tests/test_init.py::test_main` for overall parsing, `tests/test_argument.py::test_command_argument_add_to_parser` for argument styles.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/__init__.py::main",
                        "description": "(Conceptual) (argparse setup)"
                    },
                    {
                        "id": "src/yaru/command.py::Command::set_as_cli",
                        "description": "(Conceptual)"
                    },
                    {
                        "id": "src/yaru/argument.py::CommandArgument::add_to_parser",
                        "description": "(Conceptual)"
                    }
                ]
            },
            {
                "requirement_id": "EIR-002",
                "requirement_description": "User-Defined `commands` Module\nThe system requires user-defined commands to be placed in a Python module named `commands` (e.g., `commands.py` file or a `commands` package directory) located at the root of the project directory from which `yaru` is invoked. This module must be importable by Python.",
                "test_traceability": [
                    {
                        "id": "tests/test_init.py::test_main",
                        "description": "(mocks `import_module(\"commands\")`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/yaru/__init__.py::main",
                        "description": "(Conceptual)"
                    }
                ]
            }
        ],
        "full_code_skeleton": "--- File: commands.py ---\n```python\ndef run_tests(\n    c: Context,\n    docs: Annotated[bool, Arg(help=\"Include doctest examples\")] = False,\n    coverage: Annotated[bool, Arg(help=\"Run with coverage report\")] = False,\n) -> None:\n    \"\"\"\n    Execute all the project's unit tests with optional coverage.\n    \"\"\"\n    pass\n```\n--- File: src/yaru/context.py ---\n```python\nclass Context:\n    def run(\n        self: Self,\n        *args: str,\n        env: dict[str, str] | None = None,\n        fallible: bool = False,\n    ) -> None:\n        \"\"\"\n        Executes the provided instructions in a shell.\n\n        Unless `fallible` is set to `True`, the program will finish immediatelly with the\n        same exit code as the failed shell command.\n        \"\"\"\n        pass\n```\n--- File: src/yaru/exceptions.py ---\n```python\nclass YaruError(Exception):\n    pass\n\n\nclass MissingArgumentTypeHintError(YaruError):\n    pass\n\n\nclass InvalidAnnotationTypeError(YaruError):\n    pass\n\n\nclass InvalidArgumentTypeHintError(YaruError):\n    pass\n```\n--- File: src/yaru/__init__.py ---\n```python\ndef main() -> None:\n    \"\"\"Main entrypoint for `yaru`. Collects the registered commands in the `commands` module and builds the cli.\"\"\"\n    pass\n```\n--- File: src/yaru/argument.py ---\n```python\nclass Arg:\n    \"\"\"Used to provide extra metadata for an argument as part of an annotated type.\"\"\"\n\n    help: str | None = None\n    metavar: str | tuple[str, ...] | None = None\n\n\nclass CommandArgument[T: int | float | str | bool | Enum]:\n    \"\"\"Used by the Command class to store the information concerning its cli arguments.\"\"\"\n\n    class _Empty:\n        \"\"\"Used to represent an argument without default value.\"\"\"\n\n        pass\n\n    def __init__(\n        self: Self,\n        name: str,\n        default: T | None | type[_Empty] = _Empty,\n        help: str | None = None,\n        metavar: str | tuple[str, ...] | None = None,\n    ) -> None:\n        pass\n\n    @property\n    def is_optional(self) -> bool:\n        \"\"\"`true` if the argument is optional, `false` otherwise.\"\"\"\n        pass\n\n    @property\n    def arg_type(self) -> type[T]:\n        \"\"\"The type of this argument.\"\"\"\n        pass\n\n    @classmethod\n    def from_parameter(\n        cls: type[Self], parameter: inspect.Parameter\n    ) -> \"CommandArgument\":\n        \"\"\"Builds an instance of this class given a function parameter obtained by `inspect.signature`.\"\"\"\n        pass\n\n    def add_to_parser(self: Self, parser: ArgumentParser) -> None:\n        \"\"\"Given a command parser, adds itself as an argument of that command.\"\"\"\n        pass\n\n\nclass _EnumAction(Action):\n    \"\"\"\n    Argparse action for handling Enums.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs) -> None:\n        pass\n\n    def __call__(\n        self,\n        parser: ArgumentParser,\n        namespace: Namespace,\n        values: str | Sequence[Any] | None,\n        option_string: str | None = None,\n    ) -> None:\n        pass\n\n\ndef _parse_literal_as_boolean(literal: str) -> bool:\n    \"\"\"\n    Used by argparse when a non-optional boolean is used as a command argument.\n    It interprets strings like '1', '0', 'true', 'false' as booleans.\n    \"\"\"\n    pass\n```\n--- File: src/yaru/command.py ---\n```python\nclass Command:\n    \"\"\"Commands built and registered by the @command decorator.\"\"\"\n\n    __registry: set[Self] = set()\n\n    def __init__(\n        self: Self,\n        name: str,\n        func: partial[Context],\n        arguments: Sequence[CommandArgument] | None = None,\n        help: str | None = None,\n        aliases: Sequence[str] | None = None,\n        prog: str | None = None,\n        usage: str | None = None,\n        description: str | None = None,\n        epilog: str | None = None,\n    ) -> None:\n        pass\n\n    @staticmethod\n    def parse_help(func: Callable) -> str | None:\n        \"\"\"Extracts the command's help text from the function's preceding comment in a single line, cleaning up all the '#'.\"\"\"\n        pass\n\n    @staticmethod\n    def parse_description(func: Callable) -> str | None:\n        \"\"\"Extracts the command's description from the function's docstring.\"\"\"\n        pass\n\n    @staticmethod\n    def parse_parameters(func: Callable) -> Sequence[CommandArgument]:\n        \"\"\"Parses the command's arguments from the function's signature.\"\"\"\n        pass\n\n    @classmethod\n    def from_callable(\n        cls: type[Self],\n        func: Callable,\n        name: str | None = None,\n        aliases: Sequence[str] | None = None,\n    ) -> Self:\n        \"\"\"Create a new `Command` instance from the given function, injecting the `Context` as the first argument.\"\"\"\n        pass\n\n    @classmethod\n    def registry(cls: type[Self]) -> set[Self]:\n        \"\"\"Access the commands registered so far.\"\"\"\n        pass\n\n    def register(self: Self) -> None:\n        \"\"\"Add the command to the registry.\"\"\"\n        pass\n\n    def set_as_cli(self: Self, subparsers: \"_SubParsersAction[ArgumentParser]\") -> None:\n        \"\"\"Given an argparse subparser, set the command as a cli option.\"\"\"\n        pass\n\n\n@overload\ndef command[**P, R](\n    func: Callable[Concatenate[Context, P], R],\n) -> Callable[Concatenate[Context, P], R]:\n    pass\n\n\n@overload\ndef command[**P, R](\n    *, name: str | None = None, aliases: Sequence[str] | None = None\n) -> Callable[\n    [Callable[Concatenate[Context, P], R]], Callable[Concatenate[Context, P], R]\n]:\n    pass\n\n\ndef command[**P, R](\n    func: Callable[Concatenate[Context, P], R] | None = None,\n    *,\n    name: str | None = None,\n    aliases: Sequence[str] | None = None,\n) -> (\n    Callable[Concatenate[Context, P], R]\n    | Callable[\n        [Callable[Concatenate[Context, P], R]], Callable[Concatenate[Context, P], R]\n    ]\n):\n    \"\"\"\n    Registers the given function as a `yaru` command, so that it is callable via the cli.\n\n    Example:\n\n    ```pydoc\n    >>> from yaru import command, Context\n\n    >>> @command\n    ... def run_tests(c: Context, coverage: bool = False) -> None:\n    ...     c.run(\"pytest\", \"--coverage\" if coverage else \"\")\n\n    ```\n\n    This function can now be called from the cli as a command, like:\n    ```sh\n    yaru run-tests --coverage\n    ```\n    \"\"\"\n    pass\n```",
        "minimal_code_skeleton": "--- File: src/yaru/__init__.py ---\n```python\ndef main() -> None:\n    \"\"\"Main entrypoint for `yaru`. Collects the registered commands in the `commands` module and builds the cli.\"\"\"\n    pass\n```\n--- File: src/yaru/argument.py ---\n```python\nfrom dataclasses import dataclass\nfrom enum import Enum\nfrom typing import Any, Self, Sequence # Assuming these standard typings are allowed for hints\n\n# Arg class was annotated with @dataclass.\n# Fields are part of the definition needed for tests to instantiate it.\n@dataclass\nclass Arg:\n    \"\"\"Used to provide extra metadata for an argument as part of an annotated type.\"\"\"\n\n    help: str | None = None\n    metavar: str | tuple[str, ...] | None = None\n\nclass CommandArgument[T: int | float | str | bool | Enum]:\n    \"\"\"Used by the Command class to store the information concerning its cli arguments.\"\"\"\n\n    class _Empty:\n        \"\"\"Used to represent an argument without default value.\"\"\"\n        pass\n\n    def __init__(\n        self: Self,\n        name: str,\n        default: T | None | type[_Empty] = _Empty,\n        help: str | None = None,\n        metavar: str | tuple[str, ...] | None = None,\n    ) -> None:\n        pass\n\n    @property\n    def is_optional(self) -> bool:\n        \"\"\"`true` if the argument is optional, `false` otherwise.\"\"\"\n        pass\n\n    @property\n    def arg_type(self) -> type[T]:\n        \"\"\"The type of this argument.\"\"\"\n        pass\n\n    @classmethod\n    def from_parameter(\n        cls: type[Self], parameter: 'inspect.Parameter'\n    ) -> \"CommandArgument\":\n        \"\"\"Builds an instance of this class given a function parameter obtained by `inspect.signature`.\"\"\"\n        pass\n\n    def add_to_parser(self: Self, parser: 'ArgumentParser') -> None:\n        \"\"\"Given a command parser, adds itself as an argument of that command.\"\"\"\n        pass\n\nclass _EnumAction: # Original inherited from argparse.Action, omitted per rules\n    \"\"\"\n    Argparse action for handling Enums.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs) -> None: # Original had type hint for self._enum_type, removed as it's an impl detail\n        pass\n\n    def __call__(\n        self,\n        parser: 'ArgumentParser',\n        namespace: 'Namespace',\n        values: str | Sequence[Any] | None,\n        option_string: str | None = None,\n    ) -> None:\n        pass\n\ndef _parse_literal_as_boolean(literal: str) -> bool:\n    \"\"\"\n    Used by argparse when a non-optional boolean is used as a command argument.\n    It interprets strings like '1', '0', 'true', 'false' as booleans.\n    \"\"\"\n    pass\n```\n--- File: src/yaru/command.py ---\n```python\nfrom typing import Callable, Concatenate, Self, Sequence # Assuming these standard typings are allowed for hints\nfrom functools import partial # For 'partial' type hint, stringifying for safety.\n\n# Forward declaration for types from other modules in this package\n# Not strictly necessary if type checker handles it, but good practice for skeleton.\nif False: # TYPE_CHECKING block alternative\n    from yaru.argument import CommandArgument\n    from yaru.context import Context\n\nclass Command:\n    \"\"\"Commands built and registered by the @command decorator.\"\"\"\n\n    def __init__(\n        self: Self,\n        name: str,\n        func: 'partial[Context]', # functools.partial\n        arguments: Sequence['CommandArgument'] | None = None,\n        help: str | None = None,\n        aliases: Sequence[str] | None = None,\n        prog: str | None = None,\n        usage: str | None = None,\n        description: str | None = None,\n        epilog: str | None = None,\n    ) -> None:\n        pass\n\n    @staticmethod\n    def parse_help(func: Callable) -> str | None:\n        \"\"\"Extracts the command's help text from the function's preceding comment in a single line, cleaning up all the '#'.\"\"\"\n        pass\n\n    @staticmethod\n    def parse_description(func: Callable) -> str | None:\n        \"\"\"Extracts the command's description from the function's docstring.\"\"\"\n        pass\n\n    @staticmethod\n    def parse_parameters(func: Callable) -> Sequence['CommandArgument']:\n        \"\"\"Parses the command's arguments from the function's signature.\"\"\"\n        pass\n\n    @classmethod\n    def from_callable(\n        cls: type[Self],\n        func: Callable,\n        name: str | None = None,\n        aliases: Sequence[str] | None = None,\n    ) -> Self:\n        \"\"\"Create a new `Command` instance from the given function, injecting the `Context` as the first argument.\"\"\"\n        pass\n\n    @classmethod\n    def registry(cls: type[Self]) -> set[Self]:\n        \"\"\"Access the commands registered so far.\"\"\"\n        pass\n\n    def register(self: Self) -> None:\n        \"\"\"Add the command to the registry.\"\"\"\n        pass\n\n    def set_as_cli(self: Self, subparsers: \"'_SubParsersAction[ArgumentParser]'\") -> None: # argparse types\n        \"\"\"Given an argparse subparser, set the command as a cli option.\"\"\"\n        pass\n\n# @overload is part of the signature, so it should be included.\nfrom typing import overload # This import is for @overload, part of the signature definition.\n\n@overload\ndef command[**P, R](\n    func: Callable[Concatenate['Context', P], R],\n) -> Callable[Concatenate['Context', P], R]: ...\n\n@overload\ndef command[**P, R](\n    *, name: str | None = None, aliases: Sequence[str] | None = None\n) -> Callable[\n    [Callable[Concatenate['Context', P], R]], Callable[Concatenate['Context', P], R]\n]: ...\n\ndef command[**P, R](\n    func: Callable[Concatenate['Context', P], R] | None = None,\n    *,\n    name: str | None = None,\n    aliases: Sequence[str] | None = None,\n) -> (\n    Callable[Concatenate['Context', P], R]\n    | Callable[\n        [Callable[Concatenate['Context', P], R]], Callable[Concatenate['Context', P], R]\n    ]\n):\n    \"\"\"\n    Registers the given function as a `yaru` command, so that it is callable via the cli.\n\n    Example:\n\n    ```pydoc\n    >>> from yaru import command, Context\n\n    >>> @command\n    ... def run_tests(c: Context, coverage: bool = False) -> None:\n    ...     c.run(\"pytest\", \"--coverage\" if coverage else \"\")\n\n    ```\n\n    This function can now be called from the cli as a command, like:\n    ```sh\n    yaru run-tests --coverage\n    ```\n    \"\"\"\n    pass\n```\n--- File: src/yaru/context.py ---\n```python\nfrom typing import Self # Assuming this standard typing is allowed for hints\n\nclass Context:\n    def run(\n        self: Self,\n        *args: str,\n        env: dict[str, str] | None = None,\n        fallible: bool = False,\n    ) -> None:\n        \"\"\"\n        Executes the provided instructions in a shell.\n\n        Unless `fallible` is set to `True`, the program will finish immediatelly with the\n        same exit code as the failed shell command.\n        \"\"\"\n        pass\n```\n--- File: src/yaru/exceptions.py ---\n```python\nclass YaruError(Exception):\n    pass\n\nclass MissingArgumentTypeHintError(YaruError):\n    pass\n\nclass InvalidAnnotationTypeError(YaruError):\n    pass\n\nclass InvalidArgumentTypeHintError(YaruError):\n    pass\n```",
        "minimal_test_cases": [
            {
                "test_id": "tests/test_argument.py::test_command_argument_from_paramater_ok[parameter3-expected3]",
                "covers": [
                    "yaru.argument.Arg.__init__ - happy path with explicit args",
                    "yaru.argument.CommandArgument.from_parameter - happy path with Annotated and Arg"
                ]
            },
            {
                "test_id": "tests/test_argument.py::test_command_argument_init[command_argument0]",
                "covers": [
                    "yaru.argument.CommandArgument.__init__ - happy path"
                ]
            },
            {
                "test_id": "tests/test_argument.py::test_command_argument_is_optional[_Empty-False]",
                "covers": [
                    "yaru.argument.CommandArgument.is_optional - happy path (required argument case)"
                ]
            },
            {
                "test_id": "tests/test_argument.py::test_command_argument_arg_type[int]",
                "covers": [
                    "yaru.argument.CommandArgument.arg_type - happy path"
                ]
            },
            {
                "test_id": "tests/test_argument.py::test_command_argument_add_to_parser[int-0-call2]",
                "covers": [
                    "yaru.argument.CommandArgument.add_to_parser - happy path (int, optional)"
                ]
            },
            {
                "test_id": "tests/test_command.py::test_command_init[command0]",
                "covers": [
                    "yaru.command.Command.__init__ - happy path"
                ]
            },
            {
                "test_id": "tests/test_command.py::test_command_parse_help",
                "covers": [
                    "yaru.command.Command.parse_help - happy path"
                ]
            },
            {
                "test_id": "tests/test_command.py::test_command_parse_description",
                "covers": [
                    "yaru.command.Command.parse_description - happy path"
                ]
            },
            {
                "test_id": "tests/test_command.py::test_command_parse_parameters",
                "covers": [
                    "yaru.command.Command.parse_parameters - happy path"
                ]
            },
            {
                "test_id": "tests/test_command.py::test_command_from_callable[dummy_name-dummy_name]",
                "covers": [
                    "yaru.command.Command.from_callable - happy path with name"
                ]
            },
            {
                "test_id": "tests/test_command.py::test_command_register",
                "covers": [
                    "yaru.command.Command.registry - happy path",
                    "yaru.command.Command.register - happy path"
                ]
            },
            {
                "test_id": "tests/test_command.py::test_command_set_as_cli",
                "covers": [
                    "yaru.command.Command.set_as_cli - happy path"
                ]
            },
            {
                "test_id": "tests/test_command.py::test_command_decorator_without",
                "covers": [
                    "yaru.command.command - happy path for decorator (simple case)"
                ]
            },
            {
                "test_id": "tests/test_context.py::test_context_run",
                "covers": [
                    "yaru.context.Context.__init__ - basic instantiation",
                    "yaru.context.Context.run - happy path (fallible=True)"
                ]
            },
            {
                "test_id": "tests/test_init.py::test_main",
                "covers": [
                    "yaru.main - happy path"
                ]
            },
            {
                "test_id": "tests/test_argument.py::test_command_argument_from_paramater_invalid[parameter0-MissingArgumentTypeHintError]",
                "covers": [
                    "yaru.exceptions.MissingArgumentTypeHintError - exercising raising on missing type hint"
                ]
            },
            {
                "test_id": "tests/test_argument.py::test_command_argument_from_paramater_invalid[parameter1-InvalidAnnotationTypeError]",
                "covers": [
                    "yaru.exceptions.InvalidAnnotationTypeError - exercising raising on invalid annotation type"
                ]
            },
            {
                "test_id": "tests/test_argument.py::test_command_argument_from_paramater_invalid[parameter2-InvalidArgumentTypeHintError]",
                "covers": [
                    "yaru.exceptions.InvalidArgumentTypeHintError - exercising raising on invalid argument type hint"
                ]
            }
        ],
        "commit_sha": "df5bf105fa9f4503e762d04ab3f2d4a14bd4245b",
        "full_code_skeleton_structured": [
            {
                "file_path": "commands.py",
                "code": "def run_tests(\n    c: Context,\n    docs: Annotated[bool, Arg(help=\"Include doctest examples\")] = False,\n    coverage: Annotated[bool, Arg(help=\"Run with coverage report\")] = False,\n) -> None:\n    \"\"\"\n    Execute all the project's unit tests with optional coverage.\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "src/yaru/context.py",
                "code": "class Context:\n    def run(\n        self: Self,\n        *args: str,\n        env: dict[str, str] | None = None,\n        fallible: bool = False,\n    ) -> None:\n        \"\"\"\n        Executes the provided instructions in a shell.\n\n        Unless `fallible` is set to `True`, the program will finish immediatelly with the\n        same exit code as the failed shell command.\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "src/yaru/exceptions.py",
                "code": "class YaruError(Exception):\n    pass\n\n\nclass MissingArgumentTypeHintError(YaruError):\n    pass\n\n\nclass InvalidAnnotationTypeError(YaruError):\n    pass\n\n\nclass InvalidArgumentTypeHintError(YaruError):\n    pass\n"
            },
            {
                "file_path": "src/yaru/__init__.py",
                "code": "def main() -> None:\n    \"\"\"Main entrypoint for `yaru`. Collects the registered commands in the `commands` module and builds the cli.\"\"\"\n    pass\n"
            },
            {
                "file_path": "src/yaru/argument.py",
                "code": "class Arg:\n    \"\"\"Used to provide extra metadata for an argument as part of an annotated type.\"\"\"\n\n    help: str | None = None\n    metavar: str | tuple[str, ...] | None = None\n\n\nclass CommandArgument[T: int | float | str | bool | Enum]:\n    \"\"\"Used by the Command class to store the information concerning its cli arguments.\"\"\"\n\n    class _Empty:\n        \"\"\"Used to represent an argument without default value.\"\"\"\n\n        pass\n\n    def __init__(\n        self: Self,\n        name: str,\n        default: T | None | type[_Empty] = _Empty,\n        help: str | None = None,\n        metavar: str | tuple[str, ...] | None = None,\n    ) -> None:\n        pass\n\n    @property\n    def is_optional(self) -> bool:\n        \"\"\"`true` if the argument is optional, `false` otherwise.\"\"\"\n        pass\n\n    @property\n    def arg_type(self) -> type[T]:\n        \"\"\"The type of this argument.\"\"\"\n        pass\n\n    @classmethod\n    def from_parameter(\n        cls: type[Self], parameter: inspect.Parameter\n    ) -> \"CommandArgument\":\n        \"\"\"Builds an instance of this class given a function parameter obtained by `inspect.signature`.\"\"\"\n        pass\n\n    def add_to_parser(self: Self, parser: ArgumentParser) -> None:\n        \"\"\"Given a command parser, adds itself as an argument of that command.\"\"\"\n        pass\n\n\nclass _EnumAction(Action):\n    \"\"\"\n    Argparse action for handling Enums.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs) -> None:\n        pass\n\n    def __call__(\n        self,\n        parser: ArgumentParser,\n        namespace: Namespace,\n        values: str | Sequence[Any] | None,\n        option_string: str | None = None,\n    ) -> None:\n        pass\n\n\ndef _parse_literal_as_boolean(literal: str) -> bool:\n    \"\"\"\n    Used by argparse when a non-optional boolean is used as a command argument.\n    It interprets strings like '1', '0', 'true', 'false' as booleans.\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "src/yaru/command.py",
                "code": "class Command:\n    \"\"\"Commands built and registered by the @command decorator.\"\"\"\n\n    __registry: set[Self] = set()\n\n    def __init__(\n        self: Self,\n        name: str,\n        func: partial[Context],\n        arguments: Sequence[CommandArgument] | None = None,\n        help: str | None = None,\n        aliases: Sequence[str] | None = None,\n        prog: str | None = None,\n        usage: str | None = None,\n        description: str | None = None,\n        epilog: str | None = None,\n    ) -> None:\n        pass\n\n    @staticmethod\n    def parse_help(func: Callable) -> str | None:\n        \"\"\"Extracts the command's help text from the function's preceding comment in a single line, cleaning up all the '#'.\"\"\"\n        pass\n\n    @staticmethod\n    def parse_description(func: Callable) -> str | None:\n        \"\"\"Extracts the command's description from the function's docstring.\"\"\"\n        pass\n\n    @staticmethod\n    def parse_parameters(func: Callable) -> Sequence[CommandArgument]:\n        \"\"\"Parses the command's arguments from the function's signature.\"\"\"\n        pass\n\n    @classmethod\n    def from_callable(\n        cls: type[Self],\n        func: Callable,\n        name: str | None = None,\n        aliases: Sequence[str] | None = None,\n    ) -> Self:\n        \"\"\"Create a new `Command` instance from the given function, injecting the `Context` as the first argument.\"\"\"\n        pass\n\n    @classmethod\n    def registry(cls: type[Self]) -> set[Self]:\n        \"\"\"Access the commands registered so far.\"\"\"\n        pass\n\n    def register(self: Self) -> None:\n        \"\"\"Add the command to the registry.\"\"\"\n        pass\n\n    def set_as_cli(self: Self, subparsers: \"_SubParsersAction[ArgumentParser]\") -> None:\n        \"\"\"Given an argparse subparser, set the command as a cli option.\"\"\"\n        pass\n\n\n@overload\ndef command[**P, R](\n    func: Callable[Concatenate[Context, P], R],\n) -> Callable[Concatenate[Context, P], R]:\n    pass\n\n\n@overload\ndef command[**P, R](\n    *, name: str | None = None, aliases: Sequence[str] | None = None\n) -> Callable[\n    [Callable[Concatenate[Context, P], R]], Callable[Concatenate[Context, P], R]\n]:\n    pass\n\n\ndef command[**P, R](\n    func: Callable[Concatenate[Context, P], R] | None = None,\n    *,\n    name: str | None = None,\n    aliases: Sequence[str] | None = None,\n) -> (\n    Callable[Concatenate[Context, P], R]\n    | Callable[\n        [Callable[Concatenate[Context, P], R]], Callable[Concatenate[Context, P], R]\n    ]\n):\n    \"\"\"\n    Registers the given function as a `yaru` command, so that it is callable via the cli.\n\n    Example:\n\n    "
            }
        ],
        "minimal_code_skeleton_structured": [
            {
                "file_path": "src/yaru/__init__.py",
                "code": "def main() -> None:\n    \"\"\"Main entrypoint for `yaru`. Collects the registered commands in the `commands` module and builds the cli.\"\"\"\n    pass\n"
            },
            {
                "file_path": "src/yaru/argument.py",
                "code": "from dataclasses import dataclass\nfrom enum import Enum\nfrom typing import Any, Self, Sequence # Assuming these standard typings are allowed for hints\n\n# Arg class was annotated with @dataclass.\n# Fields are part of the definition needed for tests to instantiate it.\n@dataclass\nclass Arg:\n    \"\"\"Used to provide extra metadata for an argument as part of an annotated type.\"\"\"\n\n    help: str | None = None\n    metavar: str | tuple[str, ...] | None = None\n\nclass CommandArgument[T: int | float | str | bool | Enum]:\n    \"\"\"Used by the Command class to store the information concerning its cli arguments.\"\"\"\n\n    class _Empty:\n        \"\"\"Used to represent an argument without default value.\"\"\"\n        pass\n\n    def __init__(\n        self: Self,\n        name: str,\n        default: T | None | type[_Empty] = _Empty,\n        help: str | None = None,\n        metavar: str | tuple[str, ...] | None = None,\n    ) -> None:\n        pass\n\n    @property\n    def is_optional(self) -> bool:\n        \"\"\"`true` if the argument is optional, `false` otherwise.\"\"\"\n        pass\n\n    @property\n    def arg_type(self) -> type[T]:\n        \"\"\"The type of this argument.\"\"\"\n        pass\n\n    @classmethod\n    def from_parameter(\n        cls: type[Self], parameter: 'inspect.Parameter'\n    ) -> \"CommandArgument\":\n        \"\"\"Builds an instance of this class given a function parameter obtained by `inspect.signature`.\"\"\"\n        pass\n\n    def add_to_parser(self: Self, parser: 'ArgumentParser') -> None:\n        \"\"\"Given a command parser, adds itself as an argument of that command.\"\"\"\n        pass\n\nclass _EnumAction: # Original inherited from argparse.Action, omitted per rules\n    \"\"\"\n    Argparse action for handling Enums.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs) -> None: # Original had type hint for self._enum_type, removed as it's an impl detail\n        pass\n\n    def __call__(\n        self,\n        parser: 'ArgumentParser',\n        namespace: 'Namespace',\n        values: str | Sequence[Any] | None,\n        option_string: str | None = None,\n    ) -> None:\n        pass\n\ndef _parse_literal_as_boolean(literal: str) -> bool:\n    \"\"\"\n    Used by argparse when a non-optional boolean is used as a command argument.\n    It interprets strings like '1', '0', 'true', 'false' as booleans.\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "src/yaru/command.py",
                "code": "from typing import Callable, Concatenate, Self, Sequence # Assuming these standard typings are allowed for hints\nfrom functools import partial # For 'partial' type hint, stringifying for safety.\n\n# Forward declaration for types from other modules in this package\n# Not strictly necessary if type checker handles it, but good practice for skeleton.\nif False: # TYPE_CHECKING block alternative\n    from yaru.argument import CommandArgument\n    from yaru.context import Context\n\nclass Command:\n    \"\"\"Commands built and registered by the @command decorator.\"\"\"\n\n    def __init__(\n        self: Self,\n        name: str,\n        func: 'partial[Context]', # functools.partial\n        arguments: Sequence['CommandArgument'] | None = None,\n        help: str | None = None,\n        aliases: Sequence[str] | None = None,\n        prog: str | None = None,\n        usage: str | None = None,\n        description: str | None = None,\n        epilog: str | None = None,\n    ) -> None:\n        pass\n\n    @staticmethod\n    def parse_help(func: Callable) -> str | None:\n        \"\"\"Extracts the command's help text from the function's preceding comment in a single line, cleaning up all the '#'.\"\"\"\n        pass\n\n    @staticmethod\n    def parse_description(func: Callable) -> str | None:\n        \"\"\"Extracts the command's description from the function's docstring.\"\"\"\n        pass\n\n    @staticmethod\n    def parse_parameters(func: Callable) -> Sequence['CommandArgument']:\n        \"\"\"Parses the command's arguments from the function's signature.\"\"\"\n        pass\n\n    @classmethod\n    def from_callable(\n        cls: type[Self],\n        func: Callable,\n        name: str | None = None,\n        aliases: Sequence[str] | None = None,\n    ) -> Self:\n        \"\"\"Create a new `Command` instance from the given function, injecting the `Context` as the first argument.\"\"\"\n        pass\n\n    @classmethod\n    def registry(cls: type[Self]) -> set[Self]:\n        \"\"\"Access the commands registered so far.\"\"\"\n        pass\n\n    def register(self: Self) -> None:\n        \"\"\"Add the command to the registry.\"\"\"\n        pass\n\n    def set_as_cli(self: Self, subparsers: \"'_SubParsersAction[ArgumentParser]'\") -> None: # argparse types\n        \"\"\"Given an argparse subparser, set the command as a cli option.\"\"\"\n        pass\n\n# @overload is part of the signature, so it should be included.\nfrom typing import overload # This import is for @overload, part of the signature definition.\n\n@overload\ndef command[**P, R](\n    func: Callable[Concatenate['Context', P], R],\n) -> Callable[Concatenate['Context', P], R]: ...\n\n@overload\ndef command[**P, R](\n    *, name: str | None = None, aliases: Sequence[str] | None = None\n) -> Callable[\n    [Callable[Concatenate['Context', P], R]], Callable[Concatenate['Context', P], R]\n]: ...\n\ndef command[**P, R](\n    func: Callable[Concatenate['Context', P], R] | None = None,\n    *,\n    name: str | None = None,\n    aliases: Sequence[str] | None = None,\n) -> (\n    Callable[Concatenate['Context', P], R]\n    | Callable[\n        [Callable[Concatenate['Context', P], R]], Callable[Concatenate['Context', P], R]\n    ]\n):\n    \"\"\"\n    Registers the given function as a `yaru` command, so that it is callable via the cli.\n\n    Example:\n\n    "
            },
            {
                "file_path": "src/yaru/context.py",
                "code": "from typing import Self # Assuming this standard typing is allowed for hints\n\nclass Context:\n    def run(\n        self: Self,\n        *args: str,\n        env: dict[str, str] | None = None,\n        fallible: bool = False,\n    ) -> None:\n        \"\"\"\n        Executes the provided instructions in a shell.\n\n        Unless `fallible` is set to `True`, the program will finish immediatelly with the\n        same exit code as the failed shell command.\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "src/yaru/exceptions.py",
                "code": "class YaruError(Exception):\n    pass\n\nclass MissingArgumentTypeHintError(YaruError):\n    pass\n\nclass InvalidAnnotationTypeError(YaruError):\n    pass\n\nclass InvalidArgumentTypeHintError(YaruError):\n    pass\n"
            }
        ]
    },
    {
        "idx": 25663,
        "repo_name": "ethanlchristensen_streamlit-rich-message-history",
        "url": "https://github.com/ethanlchristensen/streamlit-rich-message-history",
        "description": "A way to manage messages within a streamlit app that contain many different datatypes.",
        "stars": 5,
        "forks": 0,
        "language": "python",
        "size": 304,
        "created_at": "2025-03-15T05:08:34+00:00",
        "updated_at": "2025-04-13T17:11:13+00:00",
        "pypi_info": {
            "name": "streamlit-rich-message-history",
            "version": "0.1.6",
            "url": "https://files.pythonhosted.org/packages/b6/da/366acf6b49ca4cda168fc85e2ce81dbefef6db761e69974beaf224375a0a/streamlit_rich_message_history-0.1.6.tar.gz"
        },
        "error": null,
        "judge_info": {
            "language": "python",
            "is_good_project": false,
            "reason": "",
            "python_file_num": 13,
            "comment_ratio": 0.4442036836403034,
            "pyfile_content_length": 70459,
            "pyfile_code_lines": 1846,
            "test_file_exist": true,
            "test_file_content_length": 14849,
            "pytest_framework": true,
            "test_case_num": 23,
            "metadata_path": [
                "pyproject.toml"
            ],
            "readme_content_length": 4523,
            "llm_reason": "The project is a well-defined Python library for enhancing Streamlit applications, specifically for displaying rich chat messages. \n\nPositive aspects:\n1.  **Clear Functionality:** The project's purpose and API (managing message history, different message types, various content components like text, dataframes, plots, code, and custom components) are clearly described in the README and demonstrated through examples.\n2.  **Testable & Verifiable:** The project includes a good suite of unit tests (`test_history.py`, `test_messages.py`, `test_components.py`, `test_custom_components.py`). Crucially, these tests mock the Streamlit dependency (e.g., `patch('streamlit.chat_message')`, `patch('...components.st')`), allowing the library's core logic to be tested in a self-contained manner without needing a running Streamlit application. This is a major advantage for benchmark suitability.\n3.  **Appropriate Complexity (Medium):** The project involves several interacting classes (`MessageHistory`, `Message`, `MessageComponent`, `ComponentRegistry`), an enum (`ComponentType`), logic for component type detection, and a system for registering custom components (types, detectors, renderers, and dynamic methods on the `Message` class). This offers a meaningful programming challenge without being excessively complex or requiring esoteric algorithms.\n4.  **Self-Contained Core Logic:** While the library is designed *for* Streamlit, its own logic for managing message structures, component types, and preparing content for Streamlit rendering functions can be developed and tested independently, as evidenced by the mocked tests.\n5.  **Manageable Scope:** The codebase is of a reasonable size, and its functionality could plausibly be re-implemented by an AI within a few hours to a couple of days for a human developer.\n6.  **Standard Dependencies:** Relies on common Python packages like `pandas`, `numpy`, `matplotlib`, `plotly`, and `streamlit` itself, all installable via pip.\n7.  **No Specialized Hardware:** Runs on standard CPUs.\n8.  **No GUI Rebuilding:** The AI's task is to rebuild the library, which calls Streamlit functions, not to implement a GUI itself.\n\nNegative aspects or concerns:\n1.  **Streamlit Ecosystem Dependency:** The library is inherently designed to work within the Streamlit ecosystem. While tests mock Streamlit, the AI would need to generate code that correctly calls `st.*` functions, implying some awareness of the target framework's API. However, since the task is to replicate *this specific project*, the AI would have the original project as a reference for these interactions.\n2.  **External URLs in Examples:** Some README examples (e.g., `add_video` with a YouTube URL) use external resources. The benchmark specification would need to clarify that the AI's focus is on replicating the library's capability to *call* the relevant Streamlit function (e.g., `st.video`), and testing should ideally use local/mocked data for such components, rather than requiring live internet access for testing the library's core logic. The library itself doesn't fetch these URLs; it passes them to Streamlit.\n\nOverall, the project is a strong candidate. The presence of comprehensive, mock-based unit tests significantly mitigates concerns about the Streamlit dependency for the purpose of benchmarking the AI's ability to reconstruct the library's logic.",
            "llm_project_type": "Python library for Streamlit providing rich chat message display capabilities",
            "llm_rating": 85,
            "llm_difficulty": "Medium"
        },
        "tests": {
            "repo_name": "ethanlchristensen_streamlit-rich-message-history",
            "finish_test": true,
            "test_case_result": {
                "tests/components/test_components.py::test_text_component_detection": "passed",
                "tests/components/test_components.py::test_dataframe_component_detection": "passed",
                "tests/components/test_components.py::test_error_component_detection": "passed",
                "tests/components/test_components.py::test_metric_component_detection": "passed",
                "tests/components/test_components.py::test_table_component_detection": "passed",
                "tests/components/test_components.py::test_series_component_detection": "passed",
                "tests/components/test_components.py::test_list_component_detection": "passed",
                "tests/components/test_components.py::test_tuple_component_detection": "passed",
                "tests/components/test_components.py::test_matplotlib_figure_detection": "passed",
                "tests/components/test_custom_components.py::TestCustomComponents::test_register_component_type": "passed",
                "tests/components/test_custom_components.py::TestCustomComponents::test_register_component_detector": "passed",
                "tests/components/test_custom_components.py::TestCustomComponents::test_register_component_renderer": "passed",
                "tests/components/test_custom_components.py::TestCustomComponents::test_register_component_method": "passed",
                "tests/components/test_custom_components.py::TestCustomComponents::test_custom_method_with_custom_function": "passed",
                "tests/components/test_custom_components.py::TestCustomComponents::test_component_detection_with_custom_detector": "passed",
                "tests/components/test_custom_components.py::TestCustomComponents::test_custom_renderer_is_called": "passed",
                "tests/components/test_custom_components.py::TestCustomComponents::test_custom_method_usage_in_message": "passed",
                "tests/components/test_custom_components.py::TestCustomComponents::test_message_history_with_custom_components": "passed",
                "tests/components/test_custom_components.py::TestCustomComponents::test_error_handling_for_custom_components": "passed",
                "tests/test_history.py::test_history_add_message": "passed",
                "tests/test_history.py::test_history_render_last": "passed",
                "tests/test_messages.py::test_message_chaining": "passed",
                "tests/test_messages.py::test_message_add_methods": "passed"
            },
            "success_count": 23,
            "failed_count": 0,
            "error_count": 0,
            "skipped_count": 0,
            "unknown_count": 0,
            "total_count": 23,
            "success_rate": 1.0,
            "coverage_report": {
                "covered_lines": 204,
                "num_statements": 477,
                "percent_covered": 37.881219903691814,
                "percent_covered_display": "38",
                "missing_lines": 273,
                "excluded_lines": 0,
                "num_branches": 146,
                "num_partial_branches": 12,
                "covered_branches": 32,
                "missing_branches": 114
            },
            "coverage_result": {}
        },
        "codelines_count": 1846,
        "codefiles_count": 13,
        "code_length": 70459,
        "test_files_count": 4,
        "test_code_length": 14849,
        "structure": [
            {
                "file": "release.py",
                "functions": [
                    {
                        "name": "run_command",
                        "docstring": "Run a command and return the output",
                        "comments": null,
                        "args": [
                            "command",
                            "exit_on_error"
                        ]
                    },
                    {
                        "name": "get_current_version",
                        "docstring": "Get the current version from Poetry",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "backup_file",
                        "docstring": "Create a temporary backup of a file",
                        "comments": null,
                        "args": [
                            "file_path"
                        ]
                    },
                    {
                        "name": "check_files_changed",
                        "docstring": "Check if a file has changed compared to its backup",
                        "comments": null,
                        "args": [
                            "file_path",
                            "backup_path"
                        ]
                    },
                    {
                        "name": "main",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_history.py",
                "functions": [
                    {
                        "name": "test_history_add_message",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_history_render_last",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/test_messages.py",
                "functions": [
                    {
                        "name": "test_message_chaining",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_message_add_methods",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/components/test_components.py",
                "functions": [
                    {
                        "name": "test_text_component_detection",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_dataframe_component_detection",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_error_component_detection",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_metric_component_detection",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_table_component_detection",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_series_component_detection",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_list_component_detection",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_tuple_component_detection",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_matplotlib_figure_detection",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/components/test_custom_components.py",
                "functions": [],
                "classes": [
                    {
                        "name": "TestCustomComponents",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "setup_method",
                                "docstring": "Save original registry state before each test.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "teardown_method",
                                "docstring": "Restore original registry state after each test.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_register_component_type",
                                "docstring": "Test registering a new component type.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_register_component_detector",
                                "docstring": "Test registering a detector for a custom component type.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_register_component_renderer",
                                "docstring": "Test registering a renderer for a custom component type.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_register_component_method",
                                "docstring": "Test registering a custom component method to the Message class.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_custom_method_with_custom_function",
                                "docstring": "Test registering a component method with a custom function.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_component_detection_with_custom_detector",
                                "docstring": "Test that custom component detection works properly.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "mock_chat_message"
                                ]
                            },
                            {
                                "name": "test_custom_renderer_is_called",
                                "docstring": "Test that custom renderers are called for custom component types.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "mock_chat_message"
                                ]
                            },
                            {
                                "name": "test_custom_method_usage_in_message",
                                "docstring": "Test using a custom method in a Message.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "mock_chat_message"
                                ]
                            },
                            {
                                "name": "test_message_history_with_custom_components",
                                "docstring": "Test using custom components with MessageHistory.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_error_handling_for_custom_components",
                                "docstring": "Test error handling when rendering custom components.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "mock_st",
                                    "mock_chat_message"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "docs/source/conf.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "streamlit_rich_message_history/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "streamlit_rich_message_history/utils.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "streamlit_rich_message_history/history.py",
                "functions": [],
                "classes": [
                    {
                        "name": "MessageHistory",
                        "docstring": "Class to store and manage a history of messages in a Streamlit application.\n\nThe MessageHistory class provides a convenient way to maintain a conversation-like\ninterface in Streamlit apps, with support for different types of messages (user,\nassistant, error) and rich content components.\n\nIt manages the addition, storage, and rendering of messages, as well as the\nregistration of custom component types, detectors, and renderers.\n\nAttributes:\n    messages: A list of Message objects that comprise the conversation history",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize an empty message history.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "add_message",
                                "docstring": "Add a message to the history.\n\nArgs:\n    message: The Message object to add to the history\n\nReturns:\n    Message: The added message, allowing for method chaining",
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "add_user_message_create",
                                "docstring": "Create and add a new user message with text.\n\nArgs:\n    avatar: Avatar image URL or emoji for the user\n    text: The text content of the user message\n\nReturns:\n    UserMessage: The created user message",
                                "comments": null,
                                "args": [
                                    "self",
                                    "avatar",
                                    "text"
                                ]
                            },
                            {
                                "name": "add_user_message",
                                "docstring": "Add a pre-created user message to the history.\n\nArgs:\n    message: The UserMessage object to add to the history",
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "add_assistant_message_create",
                                "docstring": "Create and add a new empty assistant message.\n\nThis creates an assistant message that can be populated with\ncomponents after creation.\n\nArgs:\n    avatar: Avatar image URL or emoji for the assistant\n\nReturns:\n    AssistantMessage: The created assistant message",
                                "comments": null,
                                "args": [
                                    "self",
                                    "avatar"
                                ]
                            },
                            {
                                "name": "add_assistant_message",
                                "docstring": "Add a pre-created assistant message to the history.\n\nArgs:\n    message: The AssistantMessage object to add to the history",
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "add_error_message",
                                "docstring": "Create and add an error message to the history.\n\nArgs:\n    avatar: Avatar image URL or emoji for the error message\n    error_text: The error text to display\n\nReturns:\n    ErrorMessage: The created error message",
                                "comments": null,
                                "args": [
                                    "self",
                                    "avatar",
                                    "error_text"
                                ]
                            },
                            {
                                "name": "render_all",
                                "docstring": "Render all messages in the history to the Streamlit UI.\n\nThis renders each message in sequence, from first to last.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "render_last",
                                "docstring": "Render only the last n messages in the history.\n\nArgs:\n    n: Number of most recent messages to render (default: 1)",
                                "comments": null,
                                "args": [
                                    "self",
                                    "n"
                                ]
                            },
                            {
                                "name": "clear",
                                "docstring": "Clear all messages from the history, resetting it to empty.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "register_component_type",
                                "docstring": "Register a new component type for use in messages.\n\nThis allows extending the library with custom component types\nthat can be detected and rendered appropriately.\n\nArgs:\n    name: The name of the new component type\n\nReturns:\n    ComponentType: The created component type enum value",
                                "comments": null,
                                "args": [
                                    "name"
                                ]
                            },
                            {
                                "name": "register_component_detector",
                                "docstring": "Register a detector function for a component type.\n\nThe detector function determines whether a given content\nshould be treated as the specified component type.\n\nArgs:\n    component_type: The component type to register a detector for\n    detector: A function that takes (content, kwargs) and returns True if\n             the content should be treated as this component type",
                                "comments": null,
                                "args": [
                                    "component_type",
                                    "detector"
                                ]
                            },
                            {
                                "name": "register_component_renderer",
                                "docstring": "Register a renderer function for a component type.\n\nThe renderer function handles displaying the component in the Streamlit UI.\n\nArgs:\n    component_type: The component type to register a renderer for\n    renderer: A function that takes (content, kwargs) and renders\n             the component in the Streamlit app",
                                "comments": null,
                                "args": [
                                    "component_type",
                                    "renderer"
                                ]
                            },
                            {
                                "name": "register_component_method",
                                "docstring": "Register a new component method to the Message class.\n\nThis allows adding custom methods to Message objects for adding\nspecific types of components with a convenient API.\n\nArgs:\n    method_name: The name of the method to add (e.g., 'add_chart')\n    component_type: The component type this method will create\n    method_func: Optional custom function to use for the method\n                (if None, a default implementation will be used)",
                                "comments": null,
                                "args": [
                                    "method_name",
                                    "component_type",
                                    "method_func"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "streamlit_rich_message_history/enums.py",
                "functions": [],
                "classes": [
                    {
                        "name": "ComponentType",
                        "docstring": "Enum defining the possible message component types.\n\nThese types correspond to different ways content can be displayed in messages,\nsuch as text, dataframes, charts, etc.\n\nAttributes:\n    TEXT: Plain text content\n    DATAFRAME: Pandas DataFrame display\n    SERIES: Pandas Series display\n    MATPLOTLIB_FIGURE: Matplotlib plot\n    PLOTLY_FIGURE: Plotly chart\n    NUMBER: Numeric value\n    ERROR: Error message\n    CODE: Code snippet with syntax highlighting\n    METRIC: Metric with optional delta\n    TABLE: Static table display\n    JSON: JSON data viewer\n    HTML: HTML content\n    LIST: List of items\n    TUPLE: Tuple of items\n    DICT: Dictionary of items",
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "TEXT",
                            "DATAFRAME",
                            "SERIES",
                            "MATPLOTLIB_FIGURE",
                            "PLOTLY_FIGURE",
                            "NUMBER",
                            "ERROR",
                            "CODE",
                            "METRIC",
                            "TABLE",
                            "JSON",
                            "HTML",
                            "LIST",
                            "TUPLE",
                            "DICT"
                        ]
                    },
                    {
                        "name": "ComponentRegistry",
                        "docstring": "Registry to manage custom component types, detectors, and renderers.\n\nThis class provides static methods for registering and retrieving:\n- Custom component types (extending ComponentType)\n- Type detection functions that identify content types\n- Rendering functions that display specific content types\n\nThe registry is a central point for extending the package with custom components.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "register_component_type",
                                "docstring": "Register a new component type with the given name.\nIf a component type with this name already exists, returns the existing type\nwith a warning instead of raising an exception.\n\nArgs:\n    name: String identifier for the new component type\n\nReturns:\n    ComponentType: The newly created component type or existing component type\n\nExamples:\n    >>> IMAGE_TYPE = ComponentRegistry.register_component_type(\"image\")\n    >>> # IMAGE_TYPE can now be used like a standard ComponentType\n    >>> # Registering the same type again will return the existing type\n    >>> SAME_IMAGE_TYPE = ComponentRegistry.register_component_type(\"image\")\n    >>> # A warning will be printed and SAME_IMAGE_TYPE == IMAGE_TYPE",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "name"
                                ]
                            },
                            {
                                "name": "register_detector",
                                "docstring": "Register a detector function for a component type.\n\nThe detector function determines if content should be treated as this component type.\n\nArgs:\n    comp_type: The component type to register a detector for\n    detector: Function that takes content and kwargs and returns True if the\n            content should be handled as this component type\n\nExamples:\n    >>> def image_detector(content, kwargs):\n            return isinstance(content, PIL.Image.Image)\n    >>> ComponentRegistry.register_detector(IMAGE_TYPE, image_detector)",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "comp_type",
                                    "detector"
                                ]
                            },
                            {
                                "name": "register_renderer",
                                "docstring": "Register a renderer function for a component type.\n\nThe renderer function handles displaying the content in a Streamlit app.\n\nArgs:\n    comp_type: The component type to register a renderer for\n    renderer: Function that takes content and kwargs and renders it in Streamlit\n\nExamples:\n    >>> def image_renderer(content, kwargs):\n            st.image(content, **{k: v for k, v in kwargs.items()\n                             if k in ['caption', 'width', 'use_column_width']})\n    >>> ComponentRegistry.register_renderer(IMAGE_TYPE, image_renderer)",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "comp_type",
                                    "renderer"
                                ]
                            },
                            {
                                "name": "get_custom_type",
                                "docstring": "Get a custom component type by name.\n\nArgs:\n    name: String identifier of the component type\n\nReturns:\n    ComponentType: The component type if found, None otherwise",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "name"
                                ]
                            },
                            {
                                "name": "get_all_types",
                                "docstring": "Get all component types (built-in and custom).\n\nReturns:\n    list: List containing all ComponentType values",
                                "comments": null,
                                "args": [
                                    "cls"
                                ]
                            },
                            {
                                "name": "get_detector",
                                "docstring": "Get the detector function for a component type.\n\nArgs:\n    comp_type: The component type to get the detector for\n\nReturns:\n    Callable: The detector function if registered, None otherwise",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "comp_type"
                                ]
                            },
                            {
                                "name": "get_renderer",
                                "docstring": "Get the renderer function for a component type.\n\nArgs:\n    comp_type: The component type to get the renderer for\n\nReturns:\n    Callable: The renderer function if registered, None otherwise",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "comp_type"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "streamlit_rich_message_history/components.py",
                "functions": [],
                "classes": [
                    {
                        "name": "MessageComponent",
                        "docstring": "Base class for all message components with automatic type detection.\n\nThis class handles the automatic detection, proper rendering, and error handling\nfor different types of content within a message in a Streamlit application.\n\nAttributes:\n    content: The actual content to be displayed\n    component_type: The type of component (automatically detected if not specified)\n    title: Optional title for the component\n    description: Optional description text for the component\n    expanded: Whether expandable sections should be expanded by default\n    kwargs: Additional keyword arguments for rendering",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize a new message component.\n\nArgs:\n    content: The content to be displayed\n    component_type: Manually specify the component type (auto-detected if None)\n    title: Optional title for the component (creates an expander if provided)\n    description: Optional description text for the component\n    expanded: Whether expandable sections should be expanded by default\n    **kwargs: Additional keyword arguments that control rendering behavior\n              Special flags include:\n              - is_error: Treat string content as an error message\n              - is_code: Treat string content as code with syntax highlighting\n              - language: The programming language for code highlighting\n              - is_metric: Treat numeric content as a metric\n              - is_table: Treat content as a static table\n              - is_json: Treat dictionaries or lists as JSON data\n              - is_html: Treat string content as HTML",
                                "comments": null,
                                "args": [
                                    "self",
                                    "content",
                                    "component_type",
                                    "title",
                                    "description",
                                    "expanded"
                                ]
                            },
                            {
                                "name": "_detect_component_type",
                                "docstring": "Detect the appropriate component type based on content.\n\nThis method uses a combination of registered custom detectors and built-in\ntype detection logic to determine the most appropriate component type\nfor the given content.\n\nArgs:\n    content: The content to detect the type for\n\nReturns:\n    ComponentType: The detected component type",
                                "comments": null,
                                "args": [
                                    "self",
                                    "content"
                                ]
                            },
                            {
                                "name": "render",
                                "docstring": "Render the component with appropriate context.\n\nIf a title is provided, the component is wrapped in an expander.\nIf a description is provided, it's shown before the content.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "_render_content",
                                "docstring": "Render the component based on its detected type.\n\nThis method handles the rendering of all built-in component types\nand delegates to custom renderers for custom component types.\nIt also includes error handling to prevent component rendering errors\nfrom breaking the entire application.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "_render_collection_item",
                                "docstring": "Render a single item from a collection.\n\nArgs:\n    item: The item to render\n    index: Optional index or key for error reporting",
                                "comments": null,
                                "args": [
                                    "self",
                                    "item",
                                    "index"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "streamlit_rich_message_history/messages.py",
                "functions": [],
                "classes": [
                    {
                        "name": "Message",
                        "docstring": "Class representing a message with multiple components.\n\nThis is the core class for creating rich messages with various content types.\nA message represents a single chat bubble/entry that can contain multiple\ncomponents (text, code, charts, tables, etc.).\n\nAttributes:\n    user: The sender of the message ('user', 'assistant', etc.)\n    avatar: Avatar image for the message sender\n    components: List of MessageComponent objects in this message",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize a new message.\n\nArgs:\n    user: The sender of the message ('user', 'assistant', etc.)\n    avatar: Avatar image for the message sender (URL or emoji)",
                                "comments": null,
                                "args": [
                                    "self",
                                    "user",
                                    "avatar"
                                ]
                            },
                            {
                                "name": "add",
                                "docstring": "Add a component to the message with automatic type detection.\n\nThis is the core method for adding content. All specific add_* methods\nultimately call this method with appropriate flags.\n\nArgs:\n    content: The content to add to the message\n    **kwargs: Additional keyword arguments that control rendering behavior\n              Special flags include:\n              - is_error: Treat string content as an error message\n              - is_code: Treat string content as code with syntax highlighting\n              - language: The programming language for code highlighting\n              - is_metric: Treat numeric content as a metric\n              - is_table: Treat content as a static table\n              - is_json: Treat dictionaries or lists as JSON data\n              - is_html: Treat string content as HTML\n\nReturns:\n    Message: Self, for method chaining",
                                "comments": null,
                                "args": [
                                    "self",
                                    "content"
                                ]
                            },
                            {
                                "name": "add_text",
                                "docstring": "Add a text component to the message.\n\nArgs:\n    text: The text content (supports markdown)\n    **kwargs: Additional keyword arguments for the component\n              Common ones include:\n              - title: A title for the text\n              - description: A description\n\nReturns:\n    Message: Self, for method chaining\n\nExamples:\n    >>> message.add_text(\"Hello, **world**!\")\n    >>> message.add_text(\"Expandable content\", title=\"Section Title\")",
                                "comments": null,
                                "args": [
                                    "self",
                                    "text"
                                ]
                            },
                            {
                                "name": "add_error",
                                "docstring": "Add an error component to the message.\n\nArgs:\n    error_text: The error message to display\n    **kwargs: Additional keyword arguments for the component\n\nReturns:\n    Message: Self, for method chaining\n\nExamples:\n    >>> message.add_error(\"File not found: example.txt\")",
                                "comments": null,
                                "args": [
                                    "self",
                                    "error_text"
                                ]
                            },
                            {
                                "name": "add_code",
                                "docstring": "Add a code component to the message.\n\nArgs:\n    code: The code snippet to display\n    language: Programming language for syntax highlighting (default: 'python')\n    **kwargs: Additional keyword arguments for the component\n\nReturns:\n    Message: Self, for method chaining\n\nExamples:\n    >>> message.add_code(\"def hello(): print('Hello world')\")\n    >>> message.add_code(\"<div>Hello</div>\", language=\"html\")",
                                "comments": null,
                                "args": [
                                    "self",
                                    "code",
                                    "language"
                                ]
                            },
                            {
                                "name": "add_dataframe",
                                "docstring": "Add a dataframe component to the message.\n\nArgs:\n    df: The pandas DataFrame to display\n    **kwargs: Additional keyword arguments for the component\n              Common ones include:\n              - use_container_width: Whether to use the full container width\n              - height: Height of the dataframe in pixels\n\nReturns:\n    Message: Self, for method chaining\n\nExamples:\n    >>> message.add_dataframe(pd.DataFrame({'A': [1, 2], 'B': [3, 4]}))\n    >>> message.add_dataframe(df, height=300)",
                                "comments": null,
                                "args": [
                                    "self",
                                    "df"
                                ]
                            },
                            {
                                "name": "add_series",
                                "docstring": "Add a series component to the message.\n\nArgs:\n    series: The pandas Series to display\n    **kwargs: Additional keyword arguments for the component\n\nReturns:\n    Message: Self, for method chaining\n\nExamples:\n    >>> message.add_series(pd.Series([1, 2, 3, 4]))",
                                "comments": null,
                                "args": [
                                    "self",
                                    "series"
                                ]
                            },
                            {
                                "name": "add_matplotlib_figure",
                                "docstring": "Add a matplotlib figure component to the message.\n\nArgs:\n    fig: The matplotlib Figure to display\n    **kwargs: Additional keyword arguments for the component\n\nReturns:\n    Message: Self, for method chaining\n\nExamples:\n    >>> fig, ax = plt.subplots()\n    >>> ax.plot([1, 2, 3, 4])\n    >>> message.add_matplotlib_figure(fig)",
                                "comments": null,
                                "args": [
                                    "self",
                                    "fig"
                                ]
                            },
                            {
                                "name": "add_plotly_figure",
                                "docstring": "Add a plotly figure component to the message.\n\nArgs:\n    fig: The plotly Figure to display\n    **kwargs: Additional keyword arguments for the component\n              Common ones include:\n              - use_container_width: Whether to use the full container width\n              - height: Height of the chart in pixels\n\nReturns:\n    Message: Self, for method chaining\n\nExamples:\n    >>> fig = go.Figure(data=go.Bar(y=[2, 3, 1]))\n    >>> message.add_plotly_figure(fig)",
                                "comments": null,
                                "args": [
                                    "self",
                                    "fig"
                                ]
                            },
                            {
                                "name": "add_number",
                                "docstring": "Add a number component to the message.\n\nArgs:\n    number: The number to display\n    **kwargs: Additional keyword arguments for the component\n              Common ones include:\n              - format: Format string (e.g., \"{:.2f}%\" for percentage)\n              - title: Label for the number\n\nReturns:\n    Message: Self, for method chaining\n\nExamples:\n    >>> message.add_number(42)\n    >>> message.add_number(3.14159, format=\"{:.2f}\", title=\"Pi\")",
                                "comments": null,
                                "args": [
                                    "self",
                                    "number"
                                ]
                            },
                            {
                                "name": "add_metric",
                                "docstring": "Add a metric component to the message.\n\nArgs:\n    value: The value of the metric\n    label: Label for the metric\n    **kwargs: Additional keyword arguments for the component\n              Common ones include:\n              - delta: Delta value to show\n              - delta_color: Color for delta ('normal', 'inverse', 'off')\n\nReturns:\n    Message: Self, for method chaining\n\nExamples:\n    >>> message.add_metric(42, \"Answer\")\n    >>> message.add_metric(103.5, \"Temperature\", delta=2.5)",
                                "comments": null,
                                "args": [
                                    "self",
                                    "value",
                                    "label"
                                ]
                            },
                            {
                                "name": "add_table",
                                "docstring": "Add a static table component to the message.\n\nArgs:\n    data: The data to display as a table\n    **kwargs: Additional keyword arguments for the component\n\nReturns:\n    Message: Self, for method chaining\n\nExamples:\n    >>> message.add_table(pd.DataFrame({'A': [1, 2], 'B': [3, 4]}))\n    >>> message.add_table([[1, 2], [3, 4]])",
                                "comments": null,
                                "args": [
                                    "self",
                                    "data"
                                ]
                            },
                            {
                                "name": "add_json",
                                "docstring": "Add a JSON component to the message.\n\nArgs:\n    data: The data to display as JSON\n    **kwargs: Additional keyword arguments for the component\n\nReturns:\n    Message: Self, for method chaining\n\nExamples:\n    >>> message.add_json({\"name\": \"John\", \"age\": 30})\n    >>> message.add_json([1, 2, 3, {\"nested\": True}])",
                                "comments": null,
                                "args": [
                                    "self",
                                    "data"
                                ]
                            },
                            {
                                "name": "add_html",
                                "docstring": "Add an HTML component to the message.\n\nArgs:\n    html_content: The HTML content to display\n    **kwargs: Additional keyword arguments for the component\n              Common ones include:\n              - height: Height of the HTML content in pixels\n              - scrolling: Whether to enable scrolling\n\nReturns:\n    Message: Self, for method chaining\n\nExamples:\n    >>> message.add_html(\"<h1>Hello World</h1>\")\n    >>> message.add_html(\"<div>Content</div>\", height=300, scrolling=True)",
                                "comments": null,
                                "args": [
                                    "self",
                                    "html_content"
                                ]
                            },
                            {
                                "name": "add_list",
                                "docstring": "Add a list of items to the message.\n\nEach item in the list will be rendered as its own component.\n\nArgs:\n    items: The list of items to display\n    **kwargs: Additional keyword arguments for the component\n\nReturns:\n    Message: Self, for method chaining\n\nExamples:\n    >>> message.add_list([\"Text\", 42, pd.DataFrame({'A': [1]})])",
                                "comments": null,
                                "args": [
                                    "self",
                                    "items"
                                ]
                            },
                            {
                                "name": "add_tuple",
                                "docstring": "Add a tuple of items to the message.\n\nEach item in the tuple will be rendered as its own component.\n\nArgs:\n    items: The tuple of items to display\n    **kwargs: Additional keyword arguments for the component\n\nReturns:\n    Message: Self, for method chaining\n\nExamples:\n    >>> message.add_tuple((\"Text\", 42, pd.DataFrame({'A': [1]})))",
                                "comments": null,
                                "args": [
                                    "self",
                                    "items"
                                ]
                            },
                            {
                                "name": "add_dict",
                                "docstring": "Add a dictionary of items to the message.\n\nEach value in the dictionary will be rendered as its own component.\n\nArgs:\n    items: The dictionary of items to display\n    **kwargs: Additional keyword arguments for the component\n\nReturns:\n    Message: Self, for method chaining\n\nExamples:\n    >>> message.add_dict({\"text\": \"Hello\", \"number\": 42})",
                                "comments": null,
                                "args": [
                                    "self",
                                    "items"
                                ]
                            },
                            {
                                "name": "add_custom",
                                "docstring": "Add a custom component type.\n\nThis method is used for components registered through the ComponentRegistry.\n\nArgs:\n    content: The content to display\n    component_type: The registered component type name\n    **kwargs: Additional keyword arguments for the component\n\nReturns:\n    Message: Self, for method chaining\n\nRaises:\n    ValueError: If the component type is not registered\n\nExamples:\n    >>> # After registering an 'image' component type:\n    >>> message.add_custom(my_pil_image, \"image\", width=300)",
                                "comments": null,
                                "args": [
                                    "self",
                                    "content",
                                    "component_type"
                                ]
                            },
                            {
                                "name": "render",
                                "docstring": "Render the message with all its components.\n\nThis method displays the message in a Streamlit app using st.chat_message\nand renders all components within it.\n\nRaises:\n    Displays an error message in the UI if rendering fails",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "register_component_method",
                                "docstring": "Register a new component method for the Message class.\nThis method dynamically adds a new add_* method to the Message class\nfor a custom component type. If a method with this name already exists,\nreturns the existing method with a warning instead of raising an exception.\n\nArgs:\n    method_name: Name of the method to add (typically 'add_xyz')\n    component_type: The component type to associate with this method\n    method_func: Optional custom function for the method\n                If None, a default implementation is created\n\nReturns:\n    Callable: The created or existing method function\n\nExamples:\n    >>> IMAGE_TYPE = ComponentRegistry.register_component_type(\"image\")\n    >>> Message.register_component_method(\"add_image\", IMAGE_TYPE)\n    >>> # Now message.add_image() is available\n    >>> # Registering the same method again will return the existing method\n    >>> Message.register_component_method(\"add_image\", IMAGE_TYPE)\n    >>> # A warning will be printed and the existing method will be returned",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "method_name",
                                    "component_type",
                                    "method_func"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "UserMessage",
                        "docstring": "Convenience class for user messages.\n\nThis class creates a Message with the 'user' role pre-configured,\nmaking it easier to create user messages in a chat interface.\n\nAttributes:\n    user: Always set to 'user'\n    avatar: Avatar image for the user\n    components: List of MessageComponent objects in this message",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize a new user message.\n\nArgs:\n    avatar: Avatar image for the user (URL or emoji)\n    text: Optional initial text for the message. If provided,\n          adds a text component automatically.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "avatar",
                                    "text"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "AssistantMessage",
                        "docstring": "Convenience class for assistant messages.\n\nThis class creates a Message with the 'assistant' role pre-configured,\nmaking it easier to create assistant/AI responses in a chat interface.\n\nAttributes:\n    user: Always set to 'assistant'\n    avatar: Avatar image for the assistant\n    components: List of MessageComponent objects in this message",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize a new assistant message.\n\nArgs:\n    avatar: Avatar image for the assistant (URL or emoji)",
                                "comments": null,
                                "args": [
                                    "self",
                                    "avatar"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "ErrorMessage",
                        "docstring": "Convenience class for error messages.\n\nThis class creates a Message with the 'error' role pre-configured\nand automatically adds an error component, making it easier to\ndisplay errors in a chat interface.\n\nAttributes:\n    user: Always set to 'error'\n    avatar: Avatar image for error messages\n    components: List of MessageComponent objects in this message",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize a new error message.\n\nArgs:\n    avatar: Avatar image for the error message (URL or emoji)\n    error_text: The error message to display",
                                "comments": null,
                                "args": [
                                    "self",
                                    "avatar",
                                    "error_text"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            }
        ],
        "test_cases": {
            "tests/components/test_components.py::test_text_component_detection": {
                "testid": "tests/components/test_components.py::test_text_component_detection",
                "result": "passed",
                "test_implementation": "def test_text_component_detection():\n    component = MessageComponent(\"Hello World\")\n    assert component.component_type == ComponentType.TEXT"
            },
            "tests/components/test_components.py::test_dataframe_component_detection": {
                "testid": "tests/components/test_components.py::test_dataframe_component_detection",
                "result": "passed",
                "test_implementation": "def test_dataframe_component_detection():\n    df = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]})\n    component = MessageComponent(df)\n    assert component.component_type == ComponentType.DATAFRAME"
            },
            "tests/components/test_components.py::test_error_component_detection": {
                "testid": "tests/components/test_components.py::test_error_component_detection",
                "result": "passed",
                "test_implementation": "def test_error_component_detection():\n    component = MessageComponent(\"Error message\", is_error=True)\n    assert component.component_type == ComponentType.ERROR"
            },
            "tests/components/test_components.py::test_metric_component_detection": {
                "testid": "tests/components/test_components.py::test_metric_component_detection",
                "result": "passed",
                "test_implementation": "def test_metric_component_detection():\n    component = MessageComponent(42, is_metric=True, title=\"Answer\")\n    assert component.component_type == ComponentType.METRIC"
            },
            "tests/components/test_components.py::test_table_component_detection": {
                "testid": "tests/components/test_components.py::test_table_component_detection",
                "result": "passed",
                "test_implementation": "def test_table_component_detection():\n    data = [[\"Alice\", 25], [\"Bob\", 30]]\n    component = MessageComponent(data, is_table=True)\n    assert component.component_type == ComponentType.TABLE"
            },
            "tests/components/test_components.py::test_series_component_detection": {
                "testid": "tests/components/test_components.py::test_series_component_detection",
                "result": "passed",
                "test_implementation": "def test_series_component_detection():\n    series = pd.Series([1, 2, 3, 4])\n    component = MessageComponent(series)\n    assert component.component_type == ComponentType.SERIES"
            },
            "tests/components/test_components.py::test_list_component_detection": {
                "testid": "tests/components/test_components.py::test_list_component_detection",
                "result": "passed",
                "test_implementation": "def test_list_component_detection():\n    items = [\"item1\", \"item2\", \"item3\"]\n    component = MessageComponent(items)\n    assert component.component_type == ComponentType.LIST"
            },
            "tests/components/test_components.py::test_tuple_component_detection": {
                "testid": "tests/components/test_components.py::test_tuple_component_detection",
                "result": "passed",
                "test_implementation": "def test_tuple_component_detection():\n    items = (\"item1\", \"item2\", \"item3\")\n    component = MessageComponent(items)\n    assert component.component_type == ComponentType.TUPLE"
            },
            "tests/components/test_components.py::test_matplotlib_figure_detection": {
                "testid": "tests/components/test_components.py::test_matplotlib_figure_detection",
                "result": "passed",
                "test_implementation": "def test_matplotlib_figure_detection():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3], [4, 5, 6])\n    component = MessageComponent(fig)\n    assert component.component_type == ComponentType.MATPLOTLIB_FIGURE"
            },
            "tests/components/test_custom_components.py::TestCustomComponents::test_register_component_type": {
                "testid": "tests/components/test_custom_components.py::TestCustomComponents::test_register_component_type",
                "result": "passed",
                "test_implementation": "    def test_register_component_type(self):\n        \"\"\"Test registering a new component type.\"\"\"\n        # Register a new component type\n        image_type = MessageHistory.register_component_type(\"image\")\n\n        # Verify the type was registered\n        assert isinstance(image_type, ComponentType)\n        assert image_type.value == \"image\"\n        assert ComponentRegistry.get_custom_type(\"image\") == image_type"
            },
            "tests/components/test_custom_components.py::TestCustomComponents::test_register_component_detector": {
                "testid": "tests/components/test_custom_components.py::TestCustomComponents::test_register_component_detector",
                "result": "passed",
                "test_implementation": "    def test_register_component_detector(self):\n        \"\"\"Test registering a detector for a custom component type.\"\"\"\n        # Create a component type\n        image_type = MessageHistory.register_component_type(\"image\")\n\n        # Create a detector function for PIL images\n        def is_pil_image(content, kwargs):\n            return hasattr(content, \"mode\") and hasattr(content, \"size\")\n\n        # Register the detector\n        MessageHistory.register_component_detector(image_type, is_pil_image)\n\n        # Verify the detector was registered\n        assert ComponentRegistry.get_detector(image_type) == is_pil_image"
            },
            "tests/components/test_custom_components.py::TestCustomComponents::test_register_component_renderer": {
                "testid": "tests/components/test_custom_components.py::TestCustomComponents::test_register_component_renderer",
                "result": "passed",
                "test_implementation": "    def test_register_component_renderer(self):\n        \"\"\"Test registering a renderer for a custom component type.\"\"\"\n        # Create a component type\n        image_type = MessageHistory.register_component_type(\"image\")\n\n        # Create a renderer function\n        def render_image(content, kwargs):\n            # In a real implementation, this would call st.image\n            pass\n\n        # Register the renderer\n        MessageHistory.register_component_renderer(image_type, render_image)\n\n        # Verify the renderer was registered\n        assert ComponentRegistry.get_renderer(image_type) == render_image"
            },
            "tests/components/test_custom_components.py::TestCustomComponents::test_register_component_method": {
                "testid": "tests/components/test_custom_components.py::TestCustomComponents::test_register_component_method",
                "result": "passed",
                "test_implementation": "    def test_register_component_method(self):\n        \"\"\"Test registering a custom component method to the Message class.\"\"\"\n        # Create a component type\n        image_type = MessageHistory.register_component_type(\"image\")\n\n        # Register a method for adding images\n        MessageHistory.register_component_method(\"add_image\", image_type)\n\n        # Verify the method was registered\n        assert hasattr(Message, \"add_image\")\n        assert \"add_image\" in Message._custom_component_methods\n        assert Message._custom_component_methods[\"add_image\"] == image_type"
            },
            "tests/components/test_custom_components.py::TestCustomComponents::test_custom_method_with_custom_function": {
                "testid": "tests/components/test_custom_components.py::TestCustomComponents::test_custom_method_with_custom_function",
                "result": "passed",
                "test_implementation": "    def test_custom_method_with_custom_function(self):\n        \"\"\"Test registering a component method with a custom function.\"\"\"\n        # Create a component type\n        chart_type = MessageHistory.register_component_type(\"custom_chart\")\n\n        # Create a custom method function\n        def add_custom_chart(self, data, title=None, **kwargs):\n            \"\"\"Add a custom chart component with special processing.\"\"\"\n            # Process the data before adding\n            processed_data = {\"chart_data\": data, \"processed\": True}\n            return self.add_custom(\n                processed_data, component_type=chart_type.value, title=title, **kwargs\n            )\n\n        # Register the method with the custom function\n        MessageHistory.register_component_method(\n            \"add_custom_chart\", chart_type, add_custom_chart\n        )\n\n        # Verify the method works as expected\n        message = Message(\"user\", \"👤\")\n        with patch.object(message, \"add_custom\") as mock_add_custom:\n            message.add_custom_chart([1, 2, 3], title=\"My Chart\")\n            mock_add_custom.assert_called_once_with(\n                {\"chart_data\": [1, 2, 3], \"processed\": True},\n                component_type=chart_type.value,\n                title=\"My Chart\",\n            )"
            },
            "tests/components/test_custom_components.py::TestCustomComponents::test_component_detection_with_custom_detector": {
                "testid": "tests/components/test_custom_components.py::TestCustomComponents::test_component_detection_with_custom_detector",
                "result": "passed",
                "test_implementation": "    def test_component_detection_with_custom_detector(self, mock_chat_message):\n        \"\"\"Test that custom component detection works properly.\"\"\"\n        # Create a mock context manager for st.chat_message\n        mock_context = MagicMock()\n        mock_chat_message.return_value = mock_context\n\n        # Create a component type and detector\n        special_type = MessageHistory.register_component_type(\"special\")\n\n        def is_special(content, kwargs):\n            return isinstance(content, dict) and content.get(\"special\") is True\n\n        MessageHistory.register_component_detector(special_type, is_special)\n\n        # Create a component with content that should be detected as special\n        with patch(\"streamlit_rich_message_history.components.st\"):\n            component = MessageComponent({\"special\": True})\n\n            # Verify the component was detected as the special type\n            assert component.component_type == special_type"
            },
            "tests/components/test_custom_components.py::TestCustomComponents::test_custom_renderer_is_called": {
                "testid": "tests/components/test_custom_components.py::TestCustomComponents::test_custom_renderer_is_called",
                "result": "passed",
                "test_implementation": "    def test_custom_renderer_is_called(self, mock_chat_message):\n        \"\"\"Test that custom renderers are called for custom component types.\"\"\"\n        # Create a mock context manager for st.chat_message\n        mock_context = MagicMock()\n        mock_chat_message.return_value = mock_context\n\n        # Create a component type, detector, and renderer\n        special_type = MessageHistory.register_component_type(\"special\")\n\n        def is_special(content, kwargs):\n            return isinstance(content, dict) and content.get(\"special\") is True\n\n        renderer_mock = MagicMock()\n\n        MessageHistory.register_component_detector(special_type, is_special)\n        MessageHistory.register_component_renderer(special_type, renderer_mock)\n\n        # Create and render a component\n        component = MessageComponent({\"special\": True})\n\n        with patch(\"streamlit_rich_message_history.components.st\"):\n            component._render_content()\n\n            # Verify the renderer was called\n            renderer_mock.assert_called_once_with({\"special\": True}, {})"
            },
            "tests/components/test_custom_components.py::TestCustomComponents::test_custom_method_usage_in_message": {
                "testid": "tests/components/test_custom_components.py::TestCustomComponents::test_custom_method_usage_in_message",
                "result": "passed",
                "test_implementation": "    def test_custom_method_usage_in_message(self, mock_chat_message):\n        \"\"\"Test using a custom method in a Message.\"\"\"\n        # Create a mock context manager for st.chat_message\n        mock_context = MagicMock()\n        mock_chat_message.return_value = mock_context\n\n        # Register custom component\n        badge_type = MessageHistory.register_component_type(\"badge\")\n\n        MessageHistory.register_component_method(\"add_badge\", badge_type)\n\n        # Create a message and use the custom method\n        message = UserMessage(\"👤\", \"Hello\")\n\n        with patch.object(message, \"add_custom\") as mock_add_custom:\n            message.add_badge({\"label\": \"New\", \"color\": \"green\"})\n\n            # Verify add_custom was called with the right parameters\n            mock_add_custom.assert_called_once_with(\n                {\"label\": \"New\", \"color\": \"green\"}, component_type=\"badge\"\n            )"
            },
            "tests/components/test_custom_components.py::TestCustomComponents::test_message_history_with_custom_components": {
                "testid": "tests/components/test_custom_components.py::TestCustomComponents::test_message_history_with_custom_components",
                "result": "passed",
                "test_implementation": "    def test_message_history_with_custom_components(self):\n        \"\"\"Test using custom components with MessageHistory.\"\"\"\n        # Register custom component\n        alert_type = MessageHistory.register_component_type(\"alert\")\n\n        def render_alert(content, kwargs):\n            # This would render an alert in a real implementation\n            pass\n\n        MessageHistory.register_component_renderer(alert_type, render_alert)\n        MessageHistory.register_component_method(\"add_alert\", alert_type)\n\n        # Create a message history and add messages with custom components\n        history = MessageHistory()\n        user_msg = history.add_user_message_create(\"👤\", \"Check this out:\")\n\n        with patch.object(user_msg, \"add_custom\") as mock_add_custom:\n            user_msg.add_alert({\"level\": \"warning\", \"message\": \"Low disk space\"})\n\n            # Verify add_custom was called correctly\n            mock_add_custom.assert_called_once_with(\n                {\"level\": \"warning\", \"message\": \"Low disk space\"},\n                component_type=\"alert\",\n            )"
            },
            "tests/components/test_custom_components.py::TestCustomComponents::test_error_handling_for_custom_components": {
                "testid": "tests/components/test_custom_components.py::TestCustomComponents::test_error_handling_for_custom_components",
                "result": "passed",
                "test_implementation": "    def test_error_handling_for_custom_components(self, mock_st, mock_chat_message):\n        \"\"\"Test error handling when rendering custom components.\"\"\"\n        # Create a mock context manager for st.chat_message\n        mock_context = MagicMock()\n        mock_chat_message.return_value = mock_context\n\n        # Create a component type with a renderer that raises an exception\n        crash_type = MessageHistory.register_component_type(\"crash\")\n\n        def crash_renderer(content, kwargs):\n            raise ValueError(\"Simulated error in custom renderer\")\n\n        MessageHistory.register_component_renderer(crash_type, crash_renderer)\n\n        # Create a component and render it\n        component = MessageComponent({\"data\": \"test\"}, component_type=crash_type)\n        component._render_content()\n\n        # Verify error was displayed\n        mock_st.error.assert_called_once()\n        assert \"error\" in mock_st.error.call_args[0][0].lower()\n\n        # Verify debug info was shown\n        mock_st.expander.assert_called()"
            },
            "tests/test_history.py::test_history_add_message": {
                "testid": "tests/test_history.py::test_history_add_message",
                "result": "passed",
                "test_implementation": "def test_history_add_message():\n    history = MessageHistory()\n    message = Message(user=\"user\", avatar=\"😈\")\n    history.add_message(message)\n\n    assert len(history.messages) == 1\n    assert history.messages[0] is message"
            },
            "tests/test_history.py::test_history_render_last": {
                "testid": "tests/test_history.py::test_history_render_last",
                "result": "passed",
                "test_implementation": "def test_history_render_last():\n    history = MessageHistory()\n    message1 = Message(user=\"user\", avatar=\"😈\")\n    message2 = Message(user=\"assistant\", avatar=\"☃️\")\n\n    history.add_message(message1)\n    history.add_message(message2)\n\n    # This test would need mocking as render will interact with Streamlit\n    # Just testing the basic functionality without rendering\n    assert len(history.messages) == 2\n    assert history.messages[-1] is message2"
            },
            "tests/test_messages.py::test_message_chaining": {
                "testid": "tests/test_messages.py::test_message_chaining",
                "result": "passed",
                "test_implementation": "def test_message_chaining():\n    message = Message(user=\"user\", avatar=\"😈\")\n    result = message.add_text(\"Hello\").add_metric(42, \"Answer\")\n    assert result is message  # Method chaining returns the message\n    assert len(message.components) == 2"
            },
            "tests/test_messages.py::test_message_add_methods": {
                "testid": "tests/test_messages.py::test_message_add_methods",
                "result": "passed",
                "test_implementation": "def test_message_add_methods():\n    message = Message(user=\"assistant\", avatar=\"☃️\")\n    message.add_text(\"Text message\")\n    message.add_error(\"Error message\")\n    message.add_metric(99, \"Score\")\n\n    assert len(message.components) == 3\n    assert message.components[0].component_type == ComponentType.TEXT\n    assert message.components[1].component_type == ComponentType.ERROR\n    assert message.components[2].component_type == ComponentType.METRIC"
            }
        },
        "SRS_document": "**Software Requirements Specification**\n\n**Streamlit Rich Message History Library**\n\n**1. Introduction**\n\n**1.1 Purpose**\nThis Software Requirements Specification (SRS) document defines the functional and non-functional requirements for the Streamlit Rich Message History library. The primary goal of this SRS is to serve as the sole specification for software developers who will be tasked with developing a complete, functional software project based on these requirements. Their success will be measured by whether their implementation passes a comprehensive set of original test cases, including public tests provided with this SRS and private tests withheld until final assessment. Therefore, this document emphasizes clarity, comprehensiveness, and appropriate abstraction to allow for independent design and implementation choices while ensuring all specified functionalities are met.\n\n**1.2 Scope**\nThe software to be developed is a Python library designed for use within Streamlit applications. Its core purpose is to enable the creation, management, and rendering of rich, multi-component chat messages. Key functionalities include:\n*   Maintaining a history of chat messages.\n*   Supporting different message senders (e.g., user, assistant).\n*   Allowing messages to contain multiple distinct content components (e.g., text, dataframes, code, plots).\n*   Automatically detecting the type of content for common data types.\n*   Rendering messages and their components within the Streamlit user interface.\n*   Providing an extensibility mechanism for developers to define, detect, and render custom content types.\n\nThe system will not include functionalities outside of this scope, such as user authentication, data persistence beyond the application session, or advanced natural language processing. The `release.py` script and documentation generation tooling (`docs/source/conf.py`) from the original source are considered outside the scope of the library's user-facing functional requirements.\n\n**1.3 Definitions, Acronyms, Abbreviations**\n*   **SRS:** Software Requirements Specification\n*   **Streamlit:** An open-source Python library for creating web applications for machine learning and data science.\n*   **Message:** A single entry in a chat conversation, associated with a sender and containing one or more components.\n*   **Component:** A distinct piece of content within a message (e.g., a paragraph of text, a table, an image).\n*   **Message History:** An ordered collection of messages representing a conversation.\n*   **Avatar:** An icon or image representing a message sender.\n*   **UI:** User Interface.\n*   **API:** Application Programming Interface.\n*   **FR:** Functional Requirement.\n*   **NFR:** Non-Functional Requirement.\n*   **EIR:** External Interface Requirement.\n*   **Pandas:** A Python data analysis library; DataFrame and Series are common data structures from this library.\n*   **Matplotlib:** A Python plotting library.\n*   **Plotly:** A Python graphing library.\n\n**1.4 References**\n*   Original README.md (provided as context)\n*   Original Source Code (provided as context for LLM analysis only)\n*   Original Test Cases (subset provided to developers, full set used for final assessment)\n\n**1.5 Overview**\nThis SRS is organized into three main sections:\n*   **Section 1 (Introduction):** Provides the purpose, scope, definitions, references, and overview of the SRS.\n*   **Section 2 (Overall Description):** Describes the general factors affecting the product and its requirements, including product perspective, functions, user characteristics, and constraints.\n*   **Section 3 (Specific Requirements):** Details all software requirements, including functional, non-functional, and external interface requirements. Functional requirements are grouped by major capability.\n\n**2. Overall Description**\n\n**2.1 Product Perspective**\nThe Streamlit Rich Message History library is a Python package intended to be used as a component within larger Streamlit applications. It provides a specialized set of tools to enhance chat-like interfaces by enabling richer content within messages and managing the conversation flow. It relies on the Streamlit framework for rendering its output.\n\n**2.2 Product Functions**\nThe major functional capabilities of the library include:\n*   **Message History Management:** Storing, adding, and clearing sequences of messages.\n*   **Message Creation and Structuring:** Defining messages with sender information (user, avatar) and an ordered collection of diverse content components.\n*   **Content Component Handling:** Supporting a variety of built-in content types (text, code, DataFrames, plots, etc.) and allowing for automatic type detection.\n*   **Rendering:** Displaying messages and their components within a Streamlit application, using appropriate Streamlit UI elements.\n*   **Extensibility:** Allowing developers to define, detect, render, and easily add custom content types to messages.\n*   **Error Handling:** Gracefully managing and reporting errors during component and message rendering.\n\n**2.3 User Characteristics**\nThe primary users of this library are Python developers building applications with Streamlit who need to implement or enhance chat-like interfaces with rich content capabilities. Users are expected to be familiar with Python programming and the basics of the Streamlit framework.\n\n**2.4 Constraints**\n*   The library must be implemented in Python.\n*   The library's rendering capabilities must integrate with and utilize the Streamlit framework. Specific Streamlit calls for rendering are an output of the system, not an input constraint on internal design beyond achieving the specified visual outcome.\n*   The library is intended for in-memory message history management within a single Streamlit application session; it does not provide built-in persistence across sessions.\n\n**2.5 Assumptions and Dependencies**\n*   The system will operate in an environment where Python and the Streamlit library are installed and functional.\n*   Dependencies such as Pandas, Matplotlib, and Plotly are assumed to be available if components utilizing them are used. The library itself might not directly depend on them but should support content from them.\n*   Users will provide valid content appropriate for the chosen component types or rely on the system's type detection.\n\n**3. Specific Requirements**\n\n**3.1 Functional Requirements**\n\n**3.1.1 Core Message History Management (FR-MH)**\n\n*   **FR-MH-001: Message Storage**\n    *   The system shall maintain an ordered collection of messages, representing the history of a conversation.\n\n*   **FR-MH-002: Add Message to History**\n    *   The system shall allow adding a generic message object to the end of the message history.\n\n*   **FR-MH-003: Add User Message (Convenience)**\n    *   The system shall provide a convenience mechanism to create a new user-type message, optionally with initial text content, and add it to the history.\n\n*   **FR-MH-004: Add Assistant Message (Convenience)**\n    *   The system shall provide a convenience mechanism to create a new assistant-type message and add it to the history. This message is initially empty of components, allowing them to be added subsequently.\n\n*   **FR-MH-005: Add Error Message (Convenience)**\n    *   The system shall provide a convenience mechanism to create a new error-type message with specified error text and add it to the history.\n\n*   **FR-MH-006: Render All Messages**\n    *   The system shall provide a capability to render all messages currently stored in the history, in their chronological order, within the Streamlit UI.\n\n*   **FR-MH-007: Render Last N Messages**\n    *   The system shall provide a capability to render a specified number (N) of the most recent messages from the history, in their chronological order, within the Streamlit UI.\n\n*   **FR-MH-008: Clear History**\n    *   The system shall provide a capability to remove all messages from the history, resetting it to an empty state.\n\n**3.1.2 Message Structure and Composition (FR-MSG)**\n\n*   **FR-MSG-001: Message Attributes (User, Avatar)**\n    *   Each message shall be associated with a user identifier (e.g., 'user', 'assistant', 'error') and an avatar (URL or emoji) representing the sender.\n\n*   **FR-MSG-002: Message Component Collection**\n    *   Each message shall support an ordered collection of content components.\n\n*   **FR-MSG-003: Add Generic Content (Automatic Type Detection)**\n    *   The system shall allow adding generic content to a message. The system will attempt to automatically determine the type of this content for appropriate rendering (see FR-COMP-DETECT-001).\n\n*   **FR-MSG-004: Chaining of Add Methods**\n    *   Methods for adding components to a message shall return a reference to the message object itself, allowing for fluent method chaining.\n\n*   **FR-MSG-005: User Message Specialization**\n    *   The system shall provide a specialized message type for user-initiated messages, pre-configured with a 'user' role. It shall allow optional initial text content upon creation.\n\n*   **FR-MSG-006: Assistant Message Specialization**\n    *   The system shall provide a specialized message type for assistant-generated messages, pre-configured with an 'assistant' role.\n\n*   **FR-MSG-007: Error Message Specialization**\n    *   The system shall provide a specialized message type for displaying errors, pre-configured with an 'error' role. It shall automatically include an error component based on provided error text.\n\n**3.1.3 Content Component Handling (FR-COMP)**\n\n    **3.1.3.1 General Component Properties**\n\n*   **FR-COMP-GEN-001: Component Content**\n    *   Each component shall encapsulate specific content to be rendered (e.g., text, a DataFrame, a plot).\n\n*   **FR-COMP-GEN-002: Optional Component Title**\n    *   A component may optionally be associated with a title string.\n\n*   **FR-COMP-GEN-003: Optional Component Description**\n    *   A component may optionally be associated with a description string (supports Markdown).\n\n*   **FR-COMP-GEN-004: Optional Component Expansion State**\n    *   If a component has a title, its rendered output may be collapsible (e.g., within an expander). The system shall allow specifying whether such a component is initially rendered in an expanded state.\n\n    **3.1.3.2 Built-in Content Type Support**\n    For each `add_X` method on a message, the system shall provide the capability to incorporate the specified content type as a component within the message.\n\n*   **FR-COMP-TEXT-001: Add Text/Markdown Content**\n    *   The system shall allow adding plain text or Markdown-formatted text content to a message.\n\n*   **FR-COMP-ERROR-001: Add Error Content**\n    *   The system shall allow adding error message text content to a message, specifically designated as an error type.\n\n*   **FR-COMP-CODE-001: Add Code Content**\n    *   The system shall allow adding code snippets to a message, with an optional programming language specification for syntax highlighting. If no language is specified, a default (e.g., \"python\") should be assumed or handled appropriately by the rendering mechanism.\n\n*   **FR-COMP-DF-001: Add Pandas DataFrame Content**\n    *   The system shall allow adding Pandas DataFrame objects as content to a message.\n\n*   **FR-COMP-SERIES-001: Add Pandas Series Content**\n    *   The system shall allow adding Pandas Series objects as content to a message.\n\n*   **FR-COMP-MPL-001: Add Matplotlib Figure Content**\n    *   The system shall allow adding Matplotlib Figure objects as content to a message.\n\n*   **FR-COMP-PLOTLY-001: Add Plotly Figure Content**\n    *   The system shall allow adding Plotly Figure objects (or compatible dictionary representations) as content to a message.\n\n*   **FR-COMP-NUM-001: Add Numeric Content**\n    *   The system shall allow adding numerical content (integer or float) to a message.\n\n*   **FR-COMP-METRIC-001: Add Metric Content**\n    *   The system shall allow adding metric content to a message, including a primary value, an optional label (title), an optional delta value, and an optional delta color indicator.\n\n*   **FR-COMP-TABLE-001: Add Static Table Content**\n    *   The system shall allow adding data to be displayed as a static table (e.g., from a list of lists or a Pandas DataFrame intended for static display).\n\n*   **FR-COMP-JSON-001: Add JSON Content**\n    *   The system shall allow adding Python dictionaries or lists to be displayed as formatted JSON content.\n\n*   **FR-COMP-HTML-001: Add HTML Content**\n    *   The system shall allow adding raw HTML strings as content to a message.\n\n*   **FR-COMP-LIST-001: Add List Content**\n    *   The system shall allow adding Python lists as content. Each item in the list should be treated as a sub-component and rendered individually according to its own type.\n\n*   **FR-COMP-TUPLE-001: Add Tuple Content**\n    *   The system shall allow adding Python tuples as content. Each item in the tuple should be treated as a sub-component and rendered individually according to its own type.\n\n*   **FR-COMP-DICT-001: Add Dictionary Content**\n    *   The system shall allow adding Python dictionaries as content. Each value in the dictionary should be treated as a sub-component (associated with its key, if applicable for rendering context) and rendered individually according to its own type.\n\n    **3.1.3.3 Content Type Detection**\n\n*   **FR-COMP-DETECT-001: Automatic Content Type Detection**\n    *   When content is added to a message without an explicit component type specification, the system shall automatically attempt to determine the most appropriate built-in component type based on the content's Python data type (e.g., `str`, `pandas.DataFrame`, `matplotlib.figure.Figure`, `list`, `tuple`, `dict`, `int`, `float`). This also includes Plotly figures.\n\n*   **FR-COMP-DETECT-002: Kwarg-based Type Hinting**\n    *   The system shall allow specific keyword arguments (e.g., `is_error`, `is_code`, `is_metric`, `is_table`, `is_json`, `is_html`) passed during content addition to override or guide the automatic type detection for ambiguous content types (like strings or basic data structures).\n\n    **3.1.3.4 Component Rendering**\n\n*   **FR-COMP-RENDER-001: General Component Rendering**\n    *   The system shall render each component within a message according to its determined type using appropriate Streamlit UI elements.\n\n*   **FR-COMP-RENDER-002: Text/Markdown Rendering**\n    *   Text and Markdown content shall be rendered as formatted text, supporting Streamlit's Markdown capabilities.\n\n*   **FR-COMP-RENDER-003: Error Rendering**\n    *   Error-designated content shall be rendered using Streamlit's error display element.\n\n*   **FR-COMP-RENDER-004: Code Rendering**\n    *   Code content shall be rendered in a code block, with syntax highlighting applied according to the specified language, using Streamlit's code display element.\n\n*   **FR-COMP-RENDER-005: DataFrame Rendering**\n    *   Pandas DataFrame content shall be rendered as an interactive table using Streamlit's DataFrame display element. Optional configuration for container width and height shall be supported.\n\n*   **FR-COMP-RENDER-006: Series Rendering**\n    *   Pandas Series content shall be rendered as a table (e.g., by converting to a DataFrame) using Streamlit's DataFrame display element.\n\n*   **FR-COMP-RENDER-007: Matplotlib Figure Rendering**\n    *   Matplotlib Figure objects shall be rendered as static plots using Streamlit's Pyplot display element.\n\n*   **FR-COMP-RENDER-008: Plotly Figure Rendering**\n    *   Plotly Figure objects shall be rendered as interactive charts using Streamlit's Plotly chart display element. Optional configuration for container width and height shall be supported.\n\n*   **FR-COMP-RENDER-009: Number Rendering**\n    *   Numeric content shall be rendered as text. An optional formatting string and title (label) shall be supported.\n\n*   **FR-COMP-RENDER-010: Metric Rendering**\n    *   Metric content (value, label, delta, delta_color) shall be rendered using Streamlit's metric display element. The label corresponds to the component's title.\n\n*   **FR-COMP-RENDER-011: Table Rendering**\n    *   Static table content shall be rendered using Streamlit's static table display element.\n\n*   **FR-COMP-RENDER-012: JSON Rendering**\n    *   JSON-designated content (dictionaries or lists) shall be rendered using Streamlit's JSON display element.\n\n*   **FR-COMP-RENDER-013: HTML Rendering**\n    *   HTML content shall be rendered directly as HTML using Streamlit's HTML display element. Optional configuration for height and scrolling shall be supported.\n\n*   **FR-COMP-RENDER-014: List/Tuple/Dict Item Rendering**\n    *   For list, tuple, or dictionary components, each item (or value, for dictionaries) shall be rendered recursively as an individual component, applying the same type detection and rendering logic.\n\n*   **FR-COMP-RENDER-015: Expander for Titled Components**\n    *   If a component has a title, its rendered content shall be wrapped in a Streamlit expander UI element, using the component's title as the expander label. The initial expansion state shall be configurable (see FR-COMP-GEN-004).\n\n*   **FR-COMP-RENDER-016: Description Display**\n    *   If a component has a description, this description (Markdown supported) shall be rendered above the main component content.\n\n**3.1.4 Extensibility for Custom Components (FR-EXT)**\n\n*   **FR-EXT-001: Register Custom Component Type Name**\n    *   The system shall provide a mechanism to define and register new, uniquely named component types beyond the built-in set.\n\n*   **FR-EXT-002: Register Custom Type Detector Function**\n    *   The system shall allow developers to register a custom detector function for any component type (built-in or custom). This function will take content and keyword arguments, and return true if the content should be treated as the associated component type.\n\n*   **FR-EXT-003: Register Custom Type Renderer Function**\n    *   The system shall allow developers to register a custom renderer function for any component type (built-in or custom). This function will take content and keyword arguments, and be responsible for rendering the component using Streamlit UI elements.\n\n*   **FR-EXT-004: Register Custom 'add' Method for Messages**\n    *   The system shall allow developers to dynamically add new methods (e.g., `add_custom_type`) to message objects. These methods will facilitate adding content of a specific (often custom) component type. A default implementation can be provided if a custom function is not specified, which simply adds the content as the associated custom type.\n\n*   **FR-EXT-005: Use Custom Detector in Type Detection**\n    *   When automatically detecting component types (FR-COMP-DETECT-001), the system shall prioritize registered custom detector functions before falling back to built-in detection logic.\n\n*   **FR-EXT-006: Use Custom Renderer for Rendering**\n    *   When rendering a component, if a custom renderer function is registered for its type, that custom renderer shall be used.\n\n*   **FR-EXT-007: Add Custom Content via Generic 'add_custom'**\n    *   Messages shall provide a method (e.g., `add_custom`) to add content explicitly specifying its (custom) component type by name. This requires the custom component type to be registered.\n\n*   **FR-EXT-008: Add Custom Content via Registered Custom Method**\n    *   If a custom 'add' method has been registered (FR-EXT-004), invoking this method on a message object shall correctly add the content, associating it with the component type defined during method registration.\n\n*   **FR-EXT-009: Custom Component Type Name Uniqueness Warning**\n    *   If an attempt is made to register a custom component type name that already exists (either as a built-in or previously registered custom type), the system shall issue a warning and utilize the existing type definition rather than overwriting or erroring.\n\n*   **FR-EXT-010: Custom Message Method Name Uniqueness Warning**\n    *   If an attempt is made to register a custom message method name (FR-EXT-004) that already exists on the Message class, the system shall issue a warning and utilize the existing method rather than overwriting or erroring (unless it's the generic 'add_custom' method itself).\n\n\n**3.1.5 System-Level Error Handling (FR-ERR)**\n\n*   **FR-ERR-001: Message Rendering Error Handling**\n    *   The system shall gracefully handle errors that occur during the rendering of an entire message (e.g., an issue with the Streamlit chat message context). If such an error occurs, the system shall:\n        1.  Display a system-level error message within the chat UI, clearly indicating the failure (e.g., using a default error avatar and user identifier).\n        2.  Provide access to detailed diagnostic information, such as a stack trace, typically within an expandable section of the error display.\n\n*   **FR-ERR-002: Component Rendering Error Handling**\n    *   The system shall gracefully handle errors occurring during the rendering of an individual component (built-in or custom). If a component fails to render, the system shall:\n        1.  Display a user-friendly error message within the Streamlit UI indicating the component rendering failure.\n        2.  Provide access to detailed diagnostic information, such as a stack trace, typically within an expandable section.\n        3.  Attempt to display a debug representation (e.g., `repr()_ or `str()`) of the problematic component's original content, if possible, within an expandable section.\n    *   This error handling must apply to both built-in and custom component renderers, as well as items within collection components (lists, tuples, dicts).\n\n**3.2 Non-Functional Requirements (NFRs)**\nNo non-functional requirements have been identified that are directly and explicitly validated by the provided original test cases. All provided tests primarily verify functional correctness.\n\n**3.3 External Interface Requirements (EIR)**\n\n**3.3.1 Programmatic API**\nThe system shall expose its functionalities (message history management, message creation, component addition, custom type registration, rendering initiation) through a Python API. The detailed interfaces for these capabilities are implicitly defined by the functional requirements (e.g., methods on `MessageHistory`, `Message` classes).\n\n**3.3.2 Streamlit Integration**\n\n*   **EIR-STRMLT-001: Message Display Integration**\n    *   Messages rendered by the system shall utilize Streamlit's `st.chat_message` context (or an equivalent mechanism) for display, integrating visually with typical Streamlit chat applications. This includes displaying the sender's avatar and user identifier.\n\n*   **EIR-STRMLT-002: Component Display Integration**\n    *   Individual components within messages shall be rendered using appropriate `st.*` Streamlit functions to display their content (e.g., `st.markdown`, `st.dataframe`, `st.pyplot`, `st.expander`).\n\n**3.4 Data Requirements**\nThere are no specific data storage or format requirements beyond the data passed as content to components and the in-memory structures used to manage message history and component definitions during an application session. Data types supported for content are outlined in the functional requirements (e.g., strings, Pandas objects, figures).",
        "structured_requirements": [
            {
                "requirement_id": "FR-MH-001",
                "requirement_description": "Message Storage\nThe system shall maintain an ordered collection of messages, representing the history of a conversation.",
                "test_traceability": [
                    {
                        "id": "tests/test_history.py::test_history_add_message",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/history.py::MessageHistory::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MH-002",
                "requirement_description": "Add Message to History\nThe system shall allow adding a generic message object to the end of the message history.",
                "test_traceability": [
                    {
                        "id": "tests/test_history.py::test_history_add_message",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/history.py::MessageHistory::add_message",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MH-003",
                "requirement_description": "Add User Message (Convenience)\nThe system shall provide a convenience mechanism to create a new user-type message, optionally with initial text content, and add it to the history.",
                "test_traceability": [
                    {
                        "id": "tests/components/test_custom_components.py::TestCustomComponents::test_message_history_with_custom_components",
                        "description": "demonstrates `add_user_message_create`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/history.py::MessageHistory::add_user_message_create",
                        "description": ""
                    },
                    {
                        "id": "streamlit_rich_message_history/history.py::MessageHistory::add_user_message",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MH-004",
                "requirement_description": "Add Assistant Message (Convenience)\nThe system shall provide a convenience mechanism to create a new assistant-type message and add it to the history. This message is initially empty of components, allowing them to be added subsequently.",
                "test_traceability": [
                    {
                        "id": "[README example implicitly uses this. No direct isolated test. Functionality derived from source code analysis.]",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/history.py::MessageHistory::add_assistant_message_create",
                        "description": ""
                    },
                    {
                        "id": "streamlit_rich_message_history/history.py::MessageHistory::add_assistant_message",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MH-005",
                "requirement_description": "Add Error Message (Convenience)\nThe system shall provide a convenience mechanism to create a new error-type message with specified error text and add it to the history.",
                "test_traceability": [
                    {
                        "id": "[No direct isolated test. Functionality derived from source code analysis.]",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/history.py::MessageHistory::add_error_message",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MH-006",
                "requirement_description": "Render All Messages\nThe system shall provide a capability to render all messages currently stored in the history, in their chronological order, within the Streamlit UI.",
                "test_traceability": [
                    {
                        "id": "[README example uses this. Rendering itself requires Streamlit environment, tests mock/avoid direct render calls.]",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/history.py::MessageHistory::render_all",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MH-007",
                "requirement_description": "Render Last N Messages\nThe system shall provide a capability to render a specified number (N) of the most recent messages from the history, in their chronological order, within the Streamlit UI.",
                "test_traceability": [
                    {
                        "id": "tests/test_history.py::test_history_render_last",
                        "description": "verifies correct message selection, not actual rendering"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/history.py::MessageHistory::render_last",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MH-008",
                "requirement_description": "Clear History\nThe system shall provide a capability to remove all messages from the history, resetting it to an empty state.",
                "test_traceability": [
                    {
                        "id": "[No direct isolated test. Functionality derived from source code analysis.]",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/history.py::MessageHistory::clear",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MSG-001",
                "requirement_description": "Message Attributes (User, Avatar)\nEach message shall be associated with a user identifier (e.g., 'user', 'assistant', 'error') and an avatar (URL or emoji) representing the sender.",
                "test_traceability": [
                    {
                        "id": "tests/test_history.py::test_history_add_message",
                        "description": ""
                    },
                    {
                        "id": "tests/test_messages.py::test_message_chaining",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MSG-002",
                "requirement_description": "Message Component Collection\nEach message shall support an ordered collection of content components.",
                "test_traceability": [
                    {
                        "id": "tests/test_messages.py::test_message_chaining",
                        "description": ""
                    },
                    {
                        "id": "tests/test_messages.py::test_message_add_methods",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::__init__",
                        "description": ""
                    },
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::add",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MSG-003",
                "requirement_description": "Add Generic Content (Automatic Type Detection)\nThe system shall allow adding generic content to a message. The system will attempt to automatically determine the type of this content for appropriate rendering (see FR-COMP-DETECT-001).",
                "test_traceability": [
                    {
                        "id": "Implicitly tested by all `add_X` methods in `tests/test_messages.py`.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::add",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MSG-004",
                "requirement_description": "Chaining of Add Methods\nMethods for adding components to a message shall return a reference to the message object itself, allowing for fluent method chaining.",
                "test_traceability": [
                    {
                        "id": "tests/test_messages.py::test_message_chaining",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::add",
                        "description": "and all `add_*` methods that call it"
                    }
                ]
            },
            {
                "requirement_id": "FR-MSG-005",
                "requirement_description": "User Message Specialization\nThe system shall provide a specialized message type for user-initiated messages, pre-configured with a 'user' role. It shall allow optional initial text content upon creation.",
                "test_traceability": [
                    {
                        "id": "tests/components/test_custom_components.py::TestCustomComponents::test_custom_method_usage_in_message",
                        "description": "uses UserMessage"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::UserMessage",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MSG-006",
                "requirement_description": "Assistant Message Specialization\nThe system shall provide a specialized message type for assistant-generated messages, pre-configured with an 'assistant' role.",
                "test_traceability": [
                    {
                        "id": "tests/test_messages.py::test_message_add_methods",
                        "description": "uses AssistantMessage indirectly via Message"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::AssistantMessage",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MSG-007",
                "requirement_description": "Error Message Specialization\nThe system shall provide a specialized message type for displaying errors, pre-configured with an 'error' role. It shall automatically include an error component based on provided error text.",
                "test_traceability": [
                    {
                        "id": "[No direct isolated test. Functionality derived from source code analysis.]",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::ErrorMessage",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-GEN-001",
                "requirement_description": "Component Content\nEach component shall encapsulate specific content to be rendered (e.g., text, a DataFrame, a plot).",
                "test_traceability": [
                    {
                        "id": "All tests in `tests/components/test_components.py` create components with content.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-GEN-002",
                "requirement_description": "Optional Component Title\nA component may optionally be associated with a title string.",
                "test_traceability": [
                    {
                        "id": "tests/components/test_components.py::test_metric_component_detection",
                        "description": "uses `title` for metric label"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-GEN-003",
                "requirement_description": "Optional Component Description\nA component may optionally be associated with a description string (supports Markdown).",
                "test_traceability": [
                    {
                        "id": "[No direct isolated test. Functionality derived from source code analysis.]",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-GEN-004",
                "requirement_description": "Optional Component Expansion State\nIf a component has a title, its rendered output may be collapsible (e.g., within an expander). The system shall allow specifying whether such a component is initially rendered in an expanded state.",
                "test_traceability": [
                    {
                        "id": "[No direct isolated test. Functionality derived from source code analysis.]",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-TEXT-001",
                "requirement_description": "Add Text/Markdown Content\nThe system shall allow adding plain text or Markdown-formatted text content to a message.",
                "test_traceability": [
                    {
                        "id": "tests/test_messages.py::test_message_add_methods",
                        "description": ""
                    },
                    {
                        "id": "tests/components/test_components.py::test_text_component_detection",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::add_text",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-ERROR-001",
                "requirement_description": "Add Error Content\nThe system shall allow adding error message text content to a message, specifically designated as an error type.",
                "test_traceability": [
                    {
                        "id": "tests/test_messages.py::test_message_add_methods",
                        "description": ""
                    },
                    {
                        "id": "tests/components/test_components.py::test_error_component_detection",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::add_error",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-CODE-001",
                "requirement_description": "Add Code Content\nThe system shall allow adding code snippets to a message, with an optional programming language specification for syntax highlighting. If no language is specified, a default (e.g., \"python\") should be assumed or handled appropriately by the rendering mechanism.",
                "test_traceability": [
                    {
                        "id": "[README example uses this. No direct isolated test. Functionality derived from source code analysis.]",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::add_code",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-DF-001",
                "requirement_description": "Add Pandas DataFrame Content\nThe system shall allow adding Pandas DataFrame objects as content to a message.",
                "test_traceability": [
                    {
                        "id": "tests/components/test_components.py::test_dataframe_component_detection",
                        "description": ""
                    },
                    {
                        "id": "README example.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::add_dataframe",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-SERIES-001",
                "requirement_description": "Add Pandas Series Content\nThe system shall allow adding Pandas Series objects as content to a message.",
                "test_traceability": [
                    {
                        "id": "tests/components/test_components.py::test_series_component_detection",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::add_series",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-MPL-001",
                "requirement_description": "Add Matplotlib Figure Content\nThe system shall allow adding Matplotlib Figure objects as content to a message.",
                "test_traceability": [
                    {
                        "id": "tests/components/test_components.py::test_matplotlib_figure_detection",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::add_matplotlib_figure",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-PLOTLY-001",
                "requirement_description": "Add Plotly Figure Content\nThe system shall allow adding Plotly Figure objects (or compatible dictionary representations) as content to a message.",
                "test_traceability": [
                    {
                        "id": "[README example implicitly uses this. No direct isolated test. Functionality derived from source code analysis.]",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::add_plotly_figure",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-NUM-001",
                "requirement_description": "Add Numeric Content\nThe system shall allow adding numerical content (integer or float) to a message.",
                "test_traceability": [
                    {
                        "id": "[No direct isolated test for `add_number`. `add_metric` uses numeric content. Functionality derived from source code analysis.]",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::add_number",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-METRIC-001",
                "requirement_description": "Add Metric Content\nThe system shall allow adding metric content to a message, including a primary value, an optional label (title), an optional delta value, and an optional delta color indicator.",
                "test_traceability": [
                    {
                        "id": "tests/test_messages.py::test_message_add_methods",
                        "description": ""
                    },
                    {
                        "id": "tests/components/test_components.py::test_metric_component_detection",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::add_metric",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-TABLE-001",
                "requirement_description": "Add Static Table Content\nThe system shall allow adding data to be displayed as a static table (e.g., from a list of lists or a Pandas DataFrame intended for static display).",
                "test_traceability": [
                    {
                        "id": "tests/components/test_components.py::test_table_component_detection",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::add_table",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-JSON-001",
                "requirement_description": "Add JSON Content\nThe system shall allow adding Python dictionaries or lists to be displayed as formatted JSON content.",
                "test_traceability": [
                    {
                        "id": "[No direct isolated test. Functionality derived from source code analysis.]",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::add_json",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-HTML-001",
                "requirement_description": "Add HTML Content\nThe system shall allow adding raw HTML strings as content to a message.",
                "test_traceability": [
                    {
                        "id": "[No direct isolated test. Functionality derived from source code analysis.]",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::add_html",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-LIST-001",
                "requirement_description": "Add List Content\nThe system shall allow adding Python lists as content. Each item in the list should be treated as a sub-component and rendered individually according to its own type.",
                "test_traceability": [
                    {
                        "id": "tests/components/test_components.py::test_list_component_detection",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::add_list",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-TUPLE-001",
                "requirement_description": "Add Tuple Content\nThe system shall allow adding Python tuples as content. Each item in the tuple should be treated as a sub-component and rendered individually according to its own type.",
                "test_traceability": [
                    {
                        "id": "tests/components/test_components.py::test_tuple_component_detection",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::add_tuple",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-DICT-001",
                "requirement_description": "Add Dictionary Content\nThe system shall allow adding Python dictionaries as content. Each value in the dictionary should be treated as a sub-component (associated with its key, if applicable for rendering context) and rendered individually according to its own type.",
                "test_traceability": [
                    {
                        "id": "[No direct isolated test for dict *values* rendering. `_detect_component_type` has logic for dicts. Functionality derived from source code analysis.]",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::add_dict",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-DETECT-001",
                "requirement_description": "Automatic Content Type Detection\nWhen content is added to a message without an explicit component type specification, the system shall automatically attempt to determine the most appropriate built-in component type based on the content's Python data type (e.g., `str`, `pandas.DataFrame`, `matplotlib.figure.Figure`, `list`, `tuple`, `dict`, `int`, `float`). This also includes Plotly figures.",
                "test_traceability": [
                    {
                        "id": "tests/components/test_components.py::test_text_component_detection",
                        "description": ""
                    },
                    {
                        "id": "tests/components/test_components.py::test_dataframe_component_detection",
                        "description": ""
                    },
                    {
                        "id": "tests/components/test_components.py::test_series_component_detection",
                        "description": ""
                    },
                    {
                        "id": "tests/components/test_components.py::test_matplotlib_figure_detection",
                        "description": ""
                    },
                    {
                        "id": "tests/components/test_components.py::test_list_component_detection",
                        "description": ""
                    },
                    {
                        "id": "tests/components/test_components.py::test_tuple_component_detection",
                        "description": "Detection for Plotly, Number, Dict is implemented but lacks specific isolated tests in `test_components.py`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::_detect_component_type",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-DETECT-002",
                "requirement_description": "Kwarg-based Type Hinting\nThe system shall allow specific keyword arguments (e.g., `is_error`, `is_code`, `is_metric`, `is_table`, `is_json`, `is_html`) passed during content addition to override or guide the automatic type detection for ambiguous content types (like strings or basic data structures).",
                "test_traceability": [
                    {
                        "id": "tests/components/test_components.py::test_error_component_detection",
                        "description": "`is_error`"
                    },
                    {
                        "id": "tests/components/test_components.py::test_metric_component_detection",
                        "description": "`is_metric`"
                    },
                    {
                        "id": "tests/components/test_components.py::test_table_component_detection",
                        "description": "Detection using `is_code`, `is_json`, `is_html` is implemented but lacks specific isolated tests"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::_detect_component_type",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-RENDER-001",
                "requirement_description": "General Component Rendering\nThe system shall render each component within a message according to its determined type using appropriate Streamlit UI elements.",
                "test_traceability": [
                    {
                        "id": "Mocked/indirectly tested via component structure; actual rendering depends on Streamlit.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::render",
                        "description": ""
                    },
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::_render_content",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-RENDER-002",
                "requirement_description": "Text/Markdown Rendering\nText and Markdown content shall be rendered as formatted text, supporting Streamlit's Markdown capabilities.",
                "test_traceability": [
                    {
                        "id": "Implicitly covered by `FR-COMP-TEXT-001`.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::_render_content",
                        "description": "calls `st.markdown`"
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-RENDER-003",
                "requirement_description": "Error Rendering\nError-designated content shall be rendered using Streamlit's error display element.",
                "test_traceability": [
                    {
                        "id": "Implicitly covered by `FR-COMP-ERROR-001`.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::_render_content",
                        "description": "calls `st.error`"
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-RENDER-004",
                "requirement_description": "Code Rendering\nCode content shall be rendered in a code block, with syntax highlighting applied according to the specified language, using Streamlit's code display element.",
                "test_traceability": [
                    {
                        "id": "Implicitly covered by `FR-COMP-CODE-001`.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::_render_content",
                        "description": "calls `st.code`"
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-RENDER-005",
                "requirement_description": "DataFrame Rendering\nPandas DataFrame content shall be rendered as an interactive table using Streamlit's DataFrame display element. Optional configuration for container width and height shall be supported.",
                "test_traceability": [
                    {
                        "id": "Implicitly covered by `FR-COMP-DF-001`.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::_render_content",
                        "description": "calls `st.dataframe`"
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-RENDER-006",
                "requirement_description": "Series Rendering\nPandas Series content shall be rendered as a table (e.g., by converting to a DataFrame) using Streamlit's DataFrame display element.",
                "test_traceability": [
                    {
                        "id": "Implicitly covered by `FR-COMP-SERIES-001`.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::_render_content",
                        "description": "calls `st.dataframe` on `series.to_frame()`"
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-RENDER-007",
                "requirement_description": "Matplotlib Figure Rendering\nMatplotlib Figure objects shall be rendered as static plots using Streamlit's Pyplot display element.",
                "test_traceability": [
                    {
                        "id": "Implicitly covered by `FR-COMP-MPL-001`.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::_render_content",
                        "description": "calls `st.pyplot`"
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-RENDER-008",
                "requirement_description": "Plotly Figure Rendering\nPlotly Figure objects shall be rendered as interactive charts using Streamlit's Plotly chart display element. Optional configuration for container width and height shall be supported.",
                "test_traceability": [
                    {
                        "id": "Implicitly covered by `FR-COMP-PLOTLY-001`.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::_render_content",
                        "description": "calls `st.plotly_chart`"
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-RENDER-009",
                "requirement_description": "Number Rendering\nNumeric content shall be rendered as text. An optional formatting string and title (label) shall be supported.",
                "test_traceability": [
                    {
                        "id": "Implicitly covered by `FR-COMP-NUM-001`.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::_render_content",
                        "description": "calls `st.write`"
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-RENDER-010",
                "requirement_description": "Metric Rendering\nMetric content (value, label, delta, delta_color) shall be rendered using Streamlit's metric display element. The label corresponds to the component's title.",
                "test_traceability": [
                    {
                        "id": "Implicitly covered by `FR-COMP-METRIC-001`.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::_render_content",
                        "description": "calls `st.metric`"
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-RENDER-011",
                "requirement_description": "Table Rendering\nStatic table content shall be rendered using Streamlit's static table display element.",
                "test_traceability": [
                    {
                        "id": "Implicitly covered by `FR-COMP-TABLE-001`.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::_render_content",
                        "description": "calls `st.table`"
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-RENDER-012",
                "requirement_description": "JSON Rendering\nJSON-designated content (dictionaries or lists) shall be rendered using Streamlit's JSON display element.",
                "test_traceability": [
                    {
                        "id": "Implicitly covered by `FR-COMP-JSON-001`.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::_render_content",
                        "description": "calls `st.json`"
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-RENDER-013",
                "requirement_description": "HTML Rendering\nHTML content shall be rendered directly as HTML using Streamlit's HTML display element. Optional configuration for height and scrolling shall be supported.",
                "test_traceability": [
                    {
                        "id": "Implicitly covered by `FR-COMP-HTML-001`.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::_render_content",
                        "description": "calls `st.html`"
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-RENDER-014",
                "requirement_description": "List/Tuple/Dict Item Rendering\nFor list, tuple, or dictionary components, each item (or value, for dictionaries) shall be rendered recursively as an individual component, applying the same type detection and rendering logic.",
                "test_traceability": [
                    {
                        "id": "Implicitly covered by `FR-COMP-LIST-001`, `FR-COMP-TUPLE-001`, `FR-COMP-DICT-001`.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::_render_content",
                        "description": ""
                    },
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::_render_collection_item",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-RENDER-015",
                "requirement_description": "Expander for Titled Components\nIf a component has a title, its rendered content shall be wrapped in a Streamlit expander UI element, using the component's title as the expander label. The initial expansion state shall be configurable (see FR-COMP-GEN-004).",
                "test_traceability": [
                    {
                        "id": "[No direct isolated test. Functionality derived from source code analysis.]",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::render",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-COMP-RENDER-016",
                "requirement_description": "Description Display\nIf a component has a description, this description (Markdown supported) shall be rendered above the main component content.",
                "test_traceability": [
                    {
                        "id": "[No direct isolated test. Functionality derived from source code analysis.]",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::render",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXT-001",
                "requirement_description": "Register Custom Component Type Name\nThe system shall provide a mechanism to define and register new, uniquely named component types beyond the built-in set.",
                "test_traceability": [
                    {
                        "id": "tests/components/test_custom_components.py::TestCustomComponents::test_register_component_type",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/history.py::MessageHistory::register_component_type",
                        "description": ""
                    },
                    {
                        "id": "streamlit_rich_message_history/enums.py::ComponentRegistry::register_component_type",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXT-002",
                "requirement_description": "Register Custom Type Detector Function\nThe system shall allow developers to register a custom detector function for any component type (built-in or custom). This function will take content and keyword arguments, and return true if the content should be treated as the associated component type.",
                "test_traceability": [
                    {
                        "id": "tests/components/test_custom_components.py::TestCustomComponents::test_register_component_detector",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/history.py::MessageHistory::register_component_detector",
                        "description": ""
                    },
                    {
                        "id": "streamlit_rich_message_history/enums.py::ComponentRegistry::register_detector",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXT-003",
                "requirement_description": "Register Custom Type Renderer Function\nThe system shall allow developers to register a custom renderer function for any component type (built-in or custom). This function will take content and keyword arguments, and be responsible for rendering the component using Streamlit UI elements.",
                "test_traceability": [
                    {
                        "id": "tests/components/test_custom_components.py::TestCustomComponents::test_register_component_renderer",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/history.py::MessageHistory::register_component_renderer",
                        "description": ""
                    },
                    {
                        "id": "streamlit_rich_message_history/enums.py::ComponentRegistry::register_renderer",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXT-004",
                "requirement_description": "Register Custom 'add' Method for Messages\nThe system shall allow developers to dynamically add new methods (e.g., `add_custom_type`) to message objects. These methods will facilitate adding content of a specific (often custom) component type. A default implementation can be provided if a custom function is not specified, which simply adds the content as the associated custom type.",
                "test_traceability": [
                    {
                        "id": "tests/components/test_custom_components.py::TestCustomComponents::test_register_component_method",
                        "description": ""
                    },
                    {
                        "id": "tests/components/test_custom_components.py::TestCustomComponents::test_custom_method_with_custom_function",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/history.py::MessageHistory::register_component_method",
                        "description": ""
                    },
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::register_component_method",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXT-005",
                "requirement_description": "Use Custom Detector in Type Detection\nWhen automatically detecting component types (FR-COMP-DETECT-001), the system shall prioritize registered custom detector functions before falling back to built-in detection logic.",
                "test_traceability": [
                    {
                        "id": "tests/components/test_custom_components.py::TestCustomComponents::test_component_detection_with_custom_detector",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::_detect_component_type",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXT-006",
                "requirement_description": "Use Custom Renderer for Rendering\nWhen rendering a component, if a custom renderer function is registered for its type, that custom renderer shall be used.",
                "test_traceability": [
                    {
                        "id": "tests/components/test_custom_components.py::TestCustomComponents::test_custom_renderer_is_called",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::_render_content",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXT-007",
                "requirement_description": "Add Custom Content via Generic 'add_custom'\nMessages shall provide a method (e.g., `add_custom`) to add content explicitly specifying its (custom) component type by name. This requires the custom component type to be registered.",
                "test_traceability": [
                    {
                        "id": "tests/components/test_custom_components.py::TestCustomComponents::test_custom_method_usage_in_message",
                        "description": "mock `add_custom`"
                    },
                    {
                        "id": "tests/components/test_custom_components.py::TestCustomComponents::test_message_history_with_custom_components",
                        "description": "mock `add_custom`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::add_custom",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXT-008",
                "requirement_description": "Add Custom Content via Registered Custom Method\nIf a custom 'add' method has been registered (FR-EXT-004), invoking this method on a message object shall correctly add the content, associating it with the component type defined during method registration.",
                "test_traceability": [
                    {
                        "id": "tests/components/test_custom_components.py::TestCustomComponents::test_custom_method_usage_in_message",
                        "description": ""
                    },
                    {
                        "id": "tests/components/test_custom_components.py::TestCustomComponents::test_message_history_with_custom_components",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "Dynamically added methods via `streamlit_rich_message_history/messages.py::Message::register_component_method`",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXT-009",
                "requirement_description": "Custom Component Type Name Uniqueness Warning\nIf an attempt is made to register a custom component type name that already exists (either as a built-in or previously registered custom type), the system shall issue a warning and utilize the existing type definition rather than overwriting or erroring.",
                "test_traceability": [
                    {
                        "id": "Implicitly covered by the setup/teardown and test logic in `tests/components/test_custom_components.py::TestCustomComponents::test_register_component_type` which would fail if warnings were errors or if re-registration failed. The code explicitly warns.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/enums.py::ComponentRegistry::register_component_type",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXT-010",
                "requirement_description": "Custom Message Method Name Uniqueness Warning\nIf an attempt is made to register a custom message method name (FR-EXT-004) that already exists on the Message class, the system shall issue a warning and utilize the existing method rather than overwriting or erroring (unless it's the generic 'add_custom' method itself).",
                "test_traceability": [
                    {
                        "id": "Implicitly covered by the setup/teardown and test logic in `tests/components/test_custom_components.py::TestCustomComponents::test_register_component_method`. The code explicitly warns.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::register_component_method",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ERR-001",
                "requirement_description": "Message Rendering Error Handling\nThe system shall gracefully handle errors that occur during the rendering of an entire message (e.g., an issue with the Streamlit chat message context). If such an error occurs, the system shall:\n        1.  Display a system-level error message within the chat UI, clearly indicating the failure (e.g., using a default error avatar and user identifier).\n        2.  Provide access to detailed diagnostic information, such as a stack trace, typically within an expandable section of the error display.",
                "test_traceability": [
                    {
                        "id": "[No direct isolated test for this specific top-level message render failure. Functionality derived from source code analysis.]",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::render",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ERR-002",
                "requirement_description": "Component Rendering Error Handling\nThe system shall gracefully handle errors occurring during the rendering of an individual component (built-in or custom). If a component fails to render, the system shall:\n        1.  Display a user-friendly error message within the Streamlit UI indicating the component rendering failure.\n        2.  Provide access to detailed diagnostic information, such as a stack trace, typically within an expandable section.\n        3.  Attempt to display a debug representation (e.g., `repr()_ or `str()`) of the problematic component's original content, if possible, within an expandable section.\n    *   This error handling must apply to both built-in and custom component renderers, as well as items within collection components (lists, tuples, dicts).",
                "test_traceability": [
                    {
                        "id": "tests/components/test_custom_components.py::TestCustomComponents::test_error_handling_for_custom_components",
                        "description": "tests for custom renderers"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::_render_content",
                        "description": ""
                    },
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::_render_collection_item",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-STRMLT-001",
                "requirement_description": "Message Display Integration\nMessages rendered by the system shall utilize Streamlit's `st.chat_message` context (or an equivalent mechanism) for display, integrating visually with typical Streamlit chat applications. This includes displaying the sender's avatar and user identifier.",
                "test_traceability": [
                    {
                        "id": "Mocked in tests like `tests/components/test_custom_components.py::TestCustomComponents::test_component_detection_with_custom_detector`.",
                        "description": "Actual UI is an outcome."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/messages.py::Message::render",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-STRMLT-002",
                "requirement_description": "Component Display Integration\nIndividual components within messages shall be rendered using appropriate `st.*` Streamlit functions to display their content (e.g., `st.markdown`, `st.dataframe`, `st.pyplot`, `st.expander`).",
                "test_traceability": [
                    {
                        "id": "Mocked in various tests. Actual UI is an outcome.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::_render_content",
                        "description": ""
                    },
                    {
                        "id": "streamlit_rich_message_history/components.py::MessageComponent::render",
                        "description": ""
                    }
                ]
            }
        ],
        "full_code_skeleton": "--- File: release.py ---\n```python\ndef run_command(command, exit_on_error=True):\n    \"\"\"Run a command and return the output\"\"\"\n    pass\n\ndef get_current_version():\n    \"\"\"Get the current version from Poetry\"\"\"\n    pass\n\ndef backup_file(file_path):\n    \"\"\"Create a temporary backup of a file\"\"\"\n    pass\n\ndef check_files_changed(file_path, backup_path):\n    \"\"\"Check if a file has changed compared to its backup\"\"\"\n    pass\n\ndef main():\n    pass\n```\n--- File: streamlit_rich_message_history/__init__.py ---\n```python\n\"\"\"\nStreamlit Rich Message History\n==============================\n\nA package for creating and managing rich, multi-component chat messages in Streamlit.\n\"\"\"\n```\n--- File: streamlit_rich_message_history/history.py ---\n```python\nclass MessageHistory:\n    \"\"\"\n    Class to store and manage a history of messages in a Streamlit application.\n\n    The MessageHistory class provides a convenient way to maintain a conversation-like\n    interface in Streamlit apps, with support for different types of messages (user,\n    assistant, error) and rich content components.\n\n    It manages the addition, storage, and rendering of messages, as well as the\n    registration of custom component types, detectors, and renderers.\n\n    Attributes:\n        messages: A list of Message objects that comprise the conversation history\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize an empty message history.\"\"\"\n        pass\n\n    def add_message(self, message: Message):\n        \"\"\"\n        Add a message to the history.\n\n        Args:\n            message: The Message object to add to the history\n\n        Returns:\n            Message: The added message, allowing for method chaining\n        \"\"\"\n        pass\n\n    def add_user_message_create(self, avatar: str, text: str) -> UserMessage:\n        \"\"\"\n        Create and add a new user message with text.\n\n        Args:\n            avatar: Avatar image URL or emoji for the user\n            text: The text content of the user message\n\n        Returns:\n            UserMessage: The created user message\n        \"\"\"\n        pass\n\n    def add_user_message(self, message: UserMessage) -> None:\n        \"\"\"\n        Add a pre-created user message to the history.\n\n        Args:\n            message: The UserMessage object to add to the history\n        \"\"\"\n        pass\n\n    def add_assistant_message_create(self, avatar: str) -> AssistantMessage:\n        \"\"\"\n        Create and add a new empty assistant message.\n\n        This creates an assistant message that can be populated with\n        components after creation.\n\n        Args:\n            avatar: Avatar image URL or emoji for the assistant\n\n        Returns:\n            AssistantMessage: The created assistant message\n        \"\"\"\n        pass\n\n    def add_assistant_message(self, message: AssistantMessage) -> None:\n        \"\"\"\n        Add a pre-created assistant message to the history.\n\n        Args:\n            message: The AssistantMessage object to add to the history\n        \"\"\"\n        pass\n\n    def add_error_message(self, avatar: str, error_text: str) -> ErrorMessage:\n        \"\"\"\n        Create and add an error message to the history.\n\n        Args:\n            avatar: Avatar image URL or emoji for the error message\n            error_text: The error text to display\n\n        Returns:\n            ErrorMessage: The created error message\n        \"\"\"\n        pass\n\n    def render_all(self):\n        \"\"\"\n        Render all messages in the history to the Streamlit UI.\n\n        This renders each message in sequence, from first to last.\n        \"\"\"\n        pass\n\n    def render_last(self, n: int = 1):\n        \"\"\"\n        Render only the last n messages in the history.\n\n        Args:\n            n: Number of most recent messages to render (default: 1)\n        \"\"\"\n        pass\n\n    def clear(self):\n        \"\"\"Clear all messages from the history, resetting it to empty.\"\"\"\n        pass\n\n    @staticmethod\n    def register_component_type(name: str) -> ComponentType:\n        \"\"\"\n        Register a new component type for use in messages.\n\n        This allows extending the library with custom component types\n        that can be detected and rendered appropriately.\n\n        Args:\n            name: The name of the new component type\n\n        Returns:\n            ComponentType: The created component type enum value\n        \"\"\"\n        pass\n\n    @staticmethod\n    def register_component_detector(\n        component_type: ComponentType, detector: Callable[[Any, dict], bool]\n    ) -> None:\n        \"\"\"\n        Register a detector function for a component type.\n\n        The detector function determines whether a given content\n        should be treated as the specified component type.\n\n        Args:\n            component_type: The component type to register a detector for\n            detector: A function that takes (content, kwargs) and returns True if\n                     the content should be treated as this component type\n        \"\"\"\n        pass\n\n    @staticmethod\n    def register_component_renderer(\n        component_type: ComponentType, renderer: Callable[[Any, dict], None]\n    ) -> None:\n        \"\"\"\n        Register a renderer function for a component type.\n\n        The renderer function handles displaying the component in the Streamlit UI.\n\n        Args:\n            component_type: The component type to register a renderer for\n            renderer: A function that takes (content, kwargs) and renders\n                     the component in the Streamlit app\n        \"\"\"\n        pass\n\n    @staticmethod\n    def register_component_method(\n        method_name: str,\n        component_type: ComponentType,\n        method_func: Optional[Callable] = None,\n    ) -> None:\n        \"\"\"\n        Register a new component method to the Message class.\n\n        This allows adding custom methods to Message objects for adding\n        specific types of components with a convenient API.\n\n        Args:\n            method_name: The name of the method to add (e.g., 'add_chart')\n            component_type: The component type this method will create\n            method_func: Optional custom function to use for the method\n                        (if None, a default implementation will be used)\n        \"\"\"\n        pass\n```\n--- File: streamlit_rich_message_history/enums.py ---\n```python\n\"\"\"\nComponent type definitions and registry for the streamlit_rich_message_history package.\n\nThis module defines the core component types and provides a registry system\nfor extending the package with custom component types, detectors, and renderers.\n\"\"\"\nfrom typing import Any, Callable, Dict, Optional\n\nclass ComponentType(Enum):\n    \"\"\"\n    Enum defining the possible message component types.\n\n    These types correspond to different ways content can be displayed in messages,\n    such as text, dataframes, charts, etc.\n\n    Attributes:\n        TEXT: Plain text content\n        DATAFRAME: Pandas DataFrame display\n        SERIES: Pandas Series display\n        MATPLOTLIB_FIGURE: Matplotlib plot\n        PLOTLY_FIGURE: Plotly chart\n        NUMBER: Numeric value\n        ERROR: Error message\n        CODE: Code snippet with syntax highlighting\n        METRIC: Metric with optional delta\n        TABLE: Static table display\n        JSON: JSON data viewer\n        HTML: HTML content\n        LIST: List of items\n        TUPLE: Tuple of items\n        DICT: Dictionary of items\n    \"\"\"\n\n    TEXT = \"text\"\n    DATAFRAME = \"dataframe\"\n    SERIES = \"series\"\n    MATPLOTLIB_FIGURE = \"matplotlib_figure\"\n    PLOTLY_FIGURE = \"plotly_figure\"\n    NUMBER = \"number\"\n    ERROR = \"error\"\n    CODE = \"code\"\n    METRIC = \"metric\"\n    TABLE = \"table\"\n    JSON = \"json\"\n    HTML = \"html\"\n    LIST = \"list\"\n    TUPLE = \"tuple\"\n    DICT = \"dict\"\n\nclass ComponentRegistry:\n    \"\"\"\n    Registry to manage custom component types, detectors, and renderers.\n\n    This class provides static methods for registering and retrieving:\n    - Custom component types (extending ComponentType)\n    - Type detection functions that identify content types\n    - Rendering functions that display specific content types\n\n    The registry is a central point for extending the package with custom components.\n    \"\"\"\n\n    _custom_types: Dict[str, ComponentType] = {}\n    _type_detectors: Dict[ComponentType, Callable[[Any, Dict[str, Any]], bool]] = {}\n    _renderers: Dict[ComponentType, Callable[[Any, Dict[str, Any]], None]] = {}\n\n    @classmethod\n    def register_component_type(cls, name: str) -> ComponentType:\n        \"\"\"\n        Register a new component type with the given name.\n        If a component type with this name already exists, returns the existing type\n        with a warning instead of raising an exception.\n\n        Args:\n            name: String identifier for the new component type\n\n        Returns:\n            ComponentType: The newly created component type or existing component type\n\n        Examples:\n            >>> IMAGE_TYPE = ComponentRegistry.register_component_type(\"image\")\n            >>> # IMAGE_TYPE can now be used like a standard ComponentType\n            >>> # Registering the same type again will return the existing type\n            >>> SAME_IMAGE_TYPE = ComponentRegistry.register_component_type(\"image\")\n            >>> # A warning will be printed and SAME_IMAGE_TYPE == IMAGE_TYPE\n        \"\"\"\n        pass\n\n    @classmethod\n    def register_detector(\n        cls, comp_type: ComponentType, detector: Callable[[Any, Dict[str, Any]], bool]\n    ) -> None:\n        \"\"\"\n        Register a detector function for a component type.\n\n        The detector function determines if content should be treated as this component type.\n\n        Args:\n            comp_type: The component type to register a detector for\n            detector: Function that takes content and kwargs and returns True if the\n                    content should be handled as this component type\n\n        Examples:\n            >>> def image_detector(content, kwargs):\n                    return isinstance(content, PIL.Image.Image)\n            >>> ComponentRegistry.register_detector(IMAGE_TYPE, image_detector)\n        \"\"\"\n        pass\n\n    @classmethod\n    def register_renderer(\n        cls, comp_type: ComponentType, renderer: Callable[[Any, Dict[str, Any]], None]\n    ) -> None:\n        \"\"\"\n        Register a renderer function for a component type.\n\n        The renderer function handles displaying the content in a Streamlit app.\n\n        Args:\n            comp_type: The component type to register a renderer for\n            renderer: Function that takes content and kwargs and renders it in Streamlit\n\n        Examples:\n            >>> def image_renderer(content, kwargs):\n                    st.image(content, **{k: v for k, v in kwargs.items()\n                                     if k in ['caption', 'width', 'use_column_width']})\n            >>> ComponentRegistry.register_renderer(IMAGE_TYPE, image_renderer)\n        \"\"\"\n        pass\n\n    @classmethod\n    def get_custom_type(cls, name: str) -> Optional[ComponentType]:\n        \"\"\"\n        Get a custom component type by name.\n\n        Args:\n            name: String identifier of the component type\n\n        Returns:\n            ComponentType: The component type if found, None otherwise\n        \"\"\"\n        pass\n\n    @classmethod\n    def get_all_types(cls) -> list:\n        \"\"\"\n        Get all component types (built-in and custom).\n\n        Returns:\n            list: List containing all ComponentType values\n        \"\"\"\n        pass\n\n    @classmethod\n    def get_detector(cls, comp_type: ComponentType) -> Optional[Callable]:\n        \"\"\"\n        Get the detector function for a component type.\n\n        Args:\n            comp_type: The component type to get the detector for\n\n        Returns:\n            Callable: The detector function if registered, None otherwise\n        \"\"\"\n        pass\n\n    @classmethod\n    def get_renderer(cls, comp_type: ComponentType) -> Optional[Callable]:\n        \"\"\"\n        Get the renderer function for a component type.\n\n        Args:\n            comp_type: The component type to get the renderer for\n\n        Returns:\n            Callable: The renderer function if registered, None otherwise\n        \"\"\"\n        pass\n```\n--- File: streamlit_rich_message_history/components.py ---\n```python\n\"\"\"\nComponent handling for the streamlit_rich_message_history package.\n\nThis module defines the core MessageComponent class that detects, processes, and\nrenders different types of content in a Streamlit application.\n\"\"\"\nfrom typing import Any, Optional, Union\n\nclass MessageComponent:\n    \"\"\"\n    Base class for all message components with automatic type detection.\n\n    This class handles the automatic detection, proper rendering, and error handling\n    for different types of content within a message in a Streamlit application.\n\n    Attributes:\n        content: The actual content to be displayed\n        component_type: The type of component (automatically detected if not specified)\n        title: Optional title for the component\n        description: Optional description text for the component\n        expanded: Whether expandable sections should be expanded by default\n        kwargs: Additional keyword arguments for rendering\n    \"\"\"\n\n    def __init__(\n        self,\n        content: Any,\n        component_type: Optional[ComponentType] = None,\n        title: Optional[str] = None,\n        description: Optional[str] = None,\n        expanded: bool = False,\n        **kwargs,\n    ):\n        \"\"\"\n        Initialize a new message component.\n\n        Args:\n            content: The content to be displayed\n            component_type: Manually specify the component type (auto-detected if None)\n            title: Optional title for the component (creates an expander if provided)\n            description: Optional description text for the component\n            expanded: Whether expandable sections should be expanded by default\n            **kwargs: Additional keyword arguments that control rendering behavior\n                      Special flags include:\n                      - is_error: Treat string content as an error message\n                      - is_code: Treat string content as code with syntax highlighting\n                      - language: The programming language for code highlighting\n                      - is_metric: Treat numeric content as a metric\n                      - is_table: Treat content as a static table\n                      - is_json: Treat dictionaries or lists as JSON data\n                      - is_html: Treat string content as HTML\n        \"\"\"\n        pass\n\n    def _detect_component_type(self, content: Any) -> ComponentType:\n        \"\"\"\n        Detect the appropriate component type based on content.\n\n        This method uses a combination of registered custom detectors and built-in\n        type detection logic to determine the most appropriate component type\n        for the given content.\n\n        Args:\n            content: The content to detect the type for\n\n        Returns:\n            ComponentType: The detected component type\n        \"\"\"\n        pass\n\n    def render(self):\n        \"\"\"\n        Render the component with appropriate context.\n\n        If a title is provided, the component is wrapped in an expander.\n        If a description is provided, it's shown before the content.\n        \"\"\"\n        pass\n\n    def _render_content(self):\n        \"\"\"\n        Render the component based on its detected type.\n\n        This method handles the rendering of all built-in component types\n        and delegates to custom renderers for custom component types.\n        It also includes error handling to prevent component rendering errors\n        from breaking the entire application.\n        \"\"\"\n        pass\n\n    def _render_collection_item(\n        self, item: Any, index: Optional[Union[int, str]] = None\n    ):\n        \"\"\"\n        Render a single item from a collection.\n\n        Args:\n            item: The item to render\n            index: Optional index or key for error reporting\n        \"\"\"\n        pass\n```\n--- File: streamlit_rich_message_history/messages.py ---\n```python\n\"\"\"\nMessage classes for the streamlit_rich_message_history package.\n\nThis module defines the Message class and its derivatives (UserMessage, AssistantMessage,\nErrorMessage) which represent chat messages with rich content components.\n\"\"\"\nfrom typing import Any, Callable, Dict, List, Optional, Tuple, Union\n\nclass Message:\n    \"\"\"\n    Class representing a message with multiple components.\n\n    This is the core class for creating rich messages with various content types.\n    A message represents a single chat bubble/entry that can contain multiple\n    components (text, code, charts, tables, etc.).\n\n    Attributes:\n        user: The sender of the message ('user', 'assistant', etc.)\n        avatar: Avatar image for the message sender\n        components: List of MessageComponent objects in this message\n    \"\"\"\n\n    _custom_component_methods: Dict[str, ComponentType] = {}\n\n    def __init__(self, user: str, avatar: str):\n        \"\"\"\n        Initialize a new message.\n\n        Args:\n            user: The sender of the message ('user', 'assistant', etc.)\n            avatar: Avatar image for the message sender (URL or emoji)\n        \"\"\"\n        pass\n\n    def add(self, content: Any, **kwargs):\n        \"\"\"\n        Add a component to the message with automatic type detection.\n\n        This is the core method for adding content. All specific add_* methods\n        ultimately call this method with appropriate flags.\n\n        Args:\n            content: The content to add to the message\n            **kwargs: Additional keyword arguments that control rendering behavior\n                      Special flags include:\n                      - is_error: Treat string content as an error message\n                      - is_code: Treat string content as code with syntax highlighting\n                      - language: The programming language for code highlighting\n                      - is_metric: Treat numeric content as a metric\n                      - is_table: Treat content as a static table\n                      - is_json: Treat dictionaries or lists as JSON data\n                      - is_html: Treat string content as HTML\n\n        Returns:\n            Message: Self, for method chaining\n        \"\"\"\n        pass\n\n    def add_text(self, text: str, **kwargs):\n        \"\"\"\n        Add a text component to the message.\n\n        Args:\n            text: The text content (supports markdown)\n            **kwargs: Additional keyword arguments for the component\n                      Common ones include:\n                      - title: A title for the text\n                      - description: A description\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_text(\"Hello, **world**!\")\n            >>> message.add_text(\"Expandable content\", title=\"Section Title\")\n        \"\"\"\n        pass\n\n    def add_error(self, error_text: str, **kwargs):\n        \"\"\"\n        Add an error component to the message.\n\n        Args:\n            error_text: The error message to display\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_error(\"File not found: example.txt\")\n        \"\"\"\n        pass\n\n    def add_code(self, code: str, language: str = \"python\", **kwargs):\n        \"\"\"\n        Add a code component to the message.\n\n        Args:\n            code: The code snippet to display\n            language: Programming language for syntax highlighting (default: 'python')\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_code(\"def hello(): print('Hello world')\")\n            >>> message.add_code(\"<div>Hello</div>\", language=\"html\")\n        \"\"\"\n        pass\n\n    def add_dataframe(self, df: pd.DataFrame, **kwargs):\n        \"\"\"\n        Add a dataframe component to the message.\n\n        Args:\n            df: The pandas DataFrame to display\n            **kwargs: Additional keyword arguments for the component\n                      Common ones include:\n                      - use_container_width: Whether to use the full container width\n                      - height: Height of the dataframe in pixels\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_dataframe(pd.DataFrame({'A': [1, 2], 'B': [3, 4]}))\n            >>> message.add_dataframe(df, height=300)\n        \"\"\"\n        pass\n\n    def add_series(self, series: pd.Series, **kwargs):\n        \"\"\"\n        Add a series component to the message.\n\n        Args:\n            series: The pandas Series to display\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_series(pd.Series([1, 2, 3, 4]))\n        \"\"\"\n        pass\n\n    def add_matplotlib_figure(self, fig: plt.Figure, **kwargs):\n        \"\"\"\n        Add a matplotlib figure component to the message.\n\n        Args:\n            fig: The matplotlib Figure to display\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> fig, ax = plt.subplots()\n            >>> ax.plot([1, 2, 3, 4])\n            >>> message.add_matplotlib_figure(fig)\n        \"\"\"\n        pass\n\n    def add_plotly_figure(self, fig: Union[go.Figure, dict], **kwargs):\n        \"\"\"\n        Add a plotly figure component to the message.\n\n        Args:\n            fig: The plotly Figure to display\n            **kwargs: Additional keyword arguments for the component\n                      Common ones include:\n                      - use_container_width: Whether to use the full container width\n                      - height: Height of the chart in pixels\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> fig = go.Figure(data=go.Bar(y=[2, 3, 1]))\n            >>> message.add_plotly_figure(fig)\n        \"\"\"\n        pass\n\n    def add_number(self, number: Union[int, float], **kwargs):\n        \"\"\"\n        Add a number component to the message.\n\n        Args:\n            number: The number to display\n            **kwargs: Additional keyword arguments for the component\n                      Common ones include:\n                      - format: Format string (e.g., \"{:.2f}%\" for percentage)\n                      - title: Label for the number\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_number(42)\n            >>> message.add_number(3.14159, format=\"{:.2f}\", title=\"Pi\")\n        \"\"\"\n        pass\n\n    def add_metric(self, value: Any, label: Optional[str] = None, **kwargs):\n        \"\"\"\n        Add a metric component to the message.\n\n        Args:\n            value: The value of the metric\n            label: Label for the metric\n            **kwargs: Additional keyword arguments for the component\n                      Common ones include:\n                      - delta: Delta value to show\n                      - delta_color: Color for delta ('normal', 'inverse', 'off')\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_metric(42, \"Answer\")\n            >>> message.add_metric(103.5, \"Temperature\", delta=2.5)\n        \"\"\"\n        pass\n\n    def add_table(self, data: Any, **kwargs):\n        \"\"\"\n        Add a static table component to the message.\n\n        Args:\n            data: The data to display as a table\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_table(pd.DataFrame({'A': [1, 2], 'B': [3, 4]}))\n            >>> message.add_table([[1, 2], [3, 4]])\n        \"\"\"\n        pass\n\n    def add_json(self, data: Union[Dict, List], **kwargs):\n        \"\"\"\n        Add a JSON component to the message.\n\n        Args:\n            data: The data to display as JSON\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_json({\"name\": \"John\", \"age\": 30})\n            >>> message.add_json([1, 2, 3, {\"nested\": True}])\n        \"\"\"\n        pass\n\n    def add_html(self, html_content: str, **kwargs):\n        \"\"\"\n        Add an HTML component to the message.\n\n        Args:\n            html_content: The HTML content to display\n            **kwargs: Additional keyword arguments for the component\n                      Common ones include:\n                      - height: Height of the HTML content in pixels\n                      - scrolling: Whether to enable scrolling\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_html(\"<h1>Hello World</h1>\")\n            >>> message.add_html(\"<div>Content</div>\", height=300, scrolling=True)\n        \"\"\"\n        pass\n\n    def add_list(self, items: List[Any], **kwargs):\n        \"\"\"\n        Add a list of items to the message.\n\n        Each item in the list will be rendered as its own component.\n\n        Args:\n            items: The list of items to display\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_list([\"Text\", 42, pd.DataFrame({'A': [1]})])\n        \"\"\"\n        pass\n\n    def add_tuple(self, items: Tuple[Any, ...], **kwargs):\n        \"\"\"\n        Add a tuple of items to the message.\n\n        Each item in the tuple will be rendered as its own component.\n\n        Args:\n            items: The tuple of items to display\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_tuple((\"Text\", 42, pd.DataFrame({'A': [1]})))\n        \"\"\"\n        pass\n\n    def add_dict(self, items: Dict[str, Any], **kwargs):\n        \"\"\"\n        Add a dictionary of items to the message.\n\n        Each value in the dictionary will be rendered as its own component.\n\n        Args:\n            items: The dictionary of items to display\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_dict({\"text\": \"Hello\", \"number\": 42})\n        \"\"\"\n        pass\n\n    def add_custom(self, content: Any, component_type: str, **kwargs):\n        \"\"\"\n        Add a custom component type.\n\n        This method is used for components registered through the ComponentRegistry.\n\n        Args:\n            content: The content to display\n            component_type: The registered component type name\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Raises:\n            ValueError: If the component type is not registered\n\n        Examples:\n            >>> # After registering an 'image' component type:\n            >>> message.add_custom(my_pil_image, \"image\", width=300)\n        \"\"\"\n        pass\n\n    def render(self):\n        \"\"\"\n        Render the message with all its components.\n\n        This method displays the message in a Streamlit app using st.chat_message\n        and renders all components within it.\n\n        Raises:\n            Displays an error message in the UI if rendering fails\n        \"\"\"\n        pass\n\n    @classmethod\n    def register_component_method(\n        cls,\n        method_name: str,\n        component_type: ComponentType,\n        method_func: Optional[Callable] = None,\n    ):\n        \"\"\"\n        Register a new component method for the Message class.\n        This method dynamically adds a new add_* method to the Message class\n        for a custom component type. If a method with this name already exists,\n        returns the existing method with a warning instead of raising an exception.\n\n        Args:\n            method_name: Name of the method to add (typically 'add_xyz')\n            component_type: The component type to associate with this method\n            method_func: Optional custom function for the method\n                        If None, a default implementation is created\n\n        Returns:\n            Callable: The created or existing method function\n\n        Examples:\n            >>> IMAGE_TYPE = ComponentRegistry.register_component_type(\"image\")\n            >>> Message.register_component_method(\"add_image\", IMAGE_TYPE)\n            >>> # Now message.add_image() is available\n            >>> # Registering the same method again will return the existing method\n            >>> Message.register_component_method(\"add_image\", IMAGE_TYPE)\n            >>> # A warning will be printed and the existing method will be returned\n        \"\"\"\n        pass\n\nclass UserMessage(Message):\n    \"\"\"\n    Convenience class for user messages.\n\n    This class creates a Message with the 'user' role pre-configured,\n    making it easier to create user messages in a chat interface.\n\n    Attributes:\n        user: Always set to 'user'\n        avatar: Avatar image for the user\n        components: List of MessageComponent objects in this message\n    \"\"\"\n\n    def __init__(self, avatar: str, text: Optional[str] = None):\n        \"\"\"\n        Initialize a new user message.\n\n        Args:\n            avatar: Avatar image for the user (URL or emoji)\n            text: Optional initial text for the message. If provided,\n                  adds a text component automatically.\n        \"\"\"\n        pass\n\nclass AssistantMessage(Message):\n    \"\"\"\n    Convenience class for assistant messages.\n\n    This class creates a Message with the 'assistant' role pre-configured,\n    making it easier to create assistant/AI responses in a chat interface.\n\n    Attributes:\n        user: Always set to 'assistant'\n        avatar: Avatar image for the assistant\n        components: List of MessageComponent objects in this message\n    \"\"\"\n\n    def __init__(self, avatar: str):\n        \"\"\"\n        Initialize a new assistant message.\n\n        Args:\n            avatar: Avatar image for the assistant (URL or emoji)\n        \"\"\"\n        pass\n\nclass ErrorMessage(Message):\n    \"\"\"\n    Convenience class for error messages.\n\n    This class creates a Message with the 'error' role pre-configured\n    and automatically adds an error component, making it easier to\n    display errors in a chat interface.\n\n    Attributes:\n        user: Always set to 'error'\n        avatar: Avatar image for error messages\n        components: List of MessageComponent objects in this message\n    \"\"\"\n\n    def __init__(self, avatar: str, error_text: str):\n        \"\"\"\n        Initialize a new error message.\n\n        Args:\n            avatar: Avatar image for the error message (URL or emoji)\n            error_text: The error message to display\n        \"\"\"\n        pass\n```",
        "minimal_code_skeleton": "--- File: streamlit_rich_message_history/components.py ---\n```python\nclass MessageComponent:\n    \"\"\"\n    Base class for all message components with automatic type detection.\n\n    This class handles the automatic detection, proper rendering, and error handling\n    for different types of content within a message in a Streamlit application.\n\n    Attributes:\n        content: The actual content to be displayed\n        component_type: The type of component (automatically detected if not specified)\n        title: Optional title for the component\n        description: Optional description text for the component\n        expanded: Whether expandable sections should be expanded by default\n        kwargs: Additional keyword arguments for rendering\n    \"\"\"\n\n    def __init__(\n        self,\n        content: Any,\n        component_type: Optional[ComponentType] = None,\n        title: Optional[str] = None,\n        description: Optional[str] = None,\n        expanded: bool = False,\n        **kwargs,\n    ):\n        \"\"\"\n        Initialize a new message component.\n\n        Args:\n            content: The content to be displayed\n            component_type: Manually specify the component type (auto-detected if None)\n            title: Optional title for the component (creates an expander if provided)\n            description: Optional description text for the component\n            expanded: Whether expandable sections should be expanded by default\n            **kwargs: Additional keyword arguments that control rendering behavior\n                      Special flags include:\n                      - is_error: Treat string content as an error message\n                      - is_code: Treat string content as code with syntax highlighting\n                      - language: The programming language for code highlighting\n                      - is_metric: Treat numeric content as a metric\n                      - is_table: Treat content as a static table\n                      - is_json: Treat dictionaries or lists as JSON data\n                      - is_html: Treat string content as HTML\n        \"\"\"\n        pass\n\n    def _render_content(self):\n        \"\"\"\n        Render the component based on its detected type.\n\n        This method handles the rendering of all built-in component types\n        and delegates to custom renderers for custom component types.\n        It also includes error handling to prevent component rendering errors\n        from breaking the entire application.\n        \"\"\"\n        pass\n```\n--- File: streamlit_rich_message_history/enums.py ---\n```python\nclass ComponentType(Enum):\n    \"\"\"\n    Enum defining the possible message component types.\n\n    These types correspond to different ways content can be displayed in messages,\n    such as text, dataframes, charts, etc.\n\n    Attributes:\n        TEXT: Plain text content\n        DATAFRAME: Pandas DataFrame display\n        SERIES: Pandas Series display\n        MATPLOTLIB_FIGURE: Matplotlib plot\n        PLOTLY_FIGURE: Plotly chart\n        NUMBER: Numeric value\n        ERROR: Error message\n        CODE: Code snippet with syntax highlighting\n        METRIC: Metric with optional delta\n        TABLE: Static table display\n        JSON: JSON data viewer\n        HTML: HTML content\n        LIST: List of items\n        TUPLE: Tuple of items\n        DICT: Dictionary of items\n    \"\"\"\n\n    TEXT = \"text\"\n    DATAFRAME = \"dataframe\"\n    SERIES = \"series\"\n    MATPLOTLIB_FIGURE = \"matplotlib_figure\"\n    PLOTLY_FIGURE = \"plotly_figure\"\n    NUMBER = \"number\"\n    ERROR = \"error\"\n    CODE = \"code\"\n    METRIC = \"metric\"\n    TABLE = \"table\"\n    JSON = \"json\"\n    HTML = \"html\"\n    LIST = \"list\"\n    TUPLE = \"tuple\"\n    DICT = \"dict\"\n\n\nclass ComponentRegistry:\n    \"\"\"\n    Registry to manage custom component types, detectors, and renderers.\n\n    This class provides static methods for registering and retrieving:\n    - Custom component types (extending ComponentType)\n    - Type detection functions that identify content types\n    - Rendering functions that display specific content types\n\n    The registry is a central point for extending the package with custom components.\n    \"\"\"\n\n    _custom_types: Dict[str, ComponentType] = {}\n    _type_detectors: Dict[ComponentType, Callable[[Any, Dict[str, Any]], bool]] = {}\n    _renderers: Dict[ComponentType, Callable[[Any, Dict[str, Any]], None]] = {}\n\n    @classmethod\n    def get_custom_type(cls, name: str) -> Optional[ComponentType]:\n        \"\"\"\n        Get a custom component type by name.\n\n        Args:\n            name: String identifier of the component type\n\n        Returns:\n            ComponentType: The component type if found, None otherwise\n        \"\"\"\n        pass\n\n    @classmethod\n    def get_detector(cls, comp_type: ComponentType) -> Optional[Callable]:\n        \"\"\"\n        Get the detector function for a component type.\n\n        Args:\n            comp_type: The component type to get the detector for\n\n        Returns:\n            Callable: The detector function if registered, None otherwise\n        \"\"\"\n        pass\n\n    @classmethod\n    def get_renderer(cls, comp_type: ComponentType) -> Optional[Callable]:\n        \"\"\"\n        Get the renderer function for a component type.\n\n        Args:\n            comp_type: The component type to get the renderer for\n\n        Returns:\n            Callable: The renderer function if registered, None otherwise\n        \"\"\"\n        pass\n```\n--- File: streamlit_rich_message_history/history.py ---\n```python\nclass MessageHistory:\n    \"\"\"\n    Class to store and manage a history of messages in a Streamlit application.\n\n    The MessageHistory class provides a convenient way to maintain a conversation-like\n    interface in Streamlit apps, with support for different types of messages (user,\n    assistant, error) and rich content components.\n\n    It manages the addition, storage, and rendering of messages, as well as the\n    registration of custom component types, detectors, and renderers.\n\n    Attributes:\n        messages: A list of Message objects that comprise the conversation history\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize an empty message history.\"\"\"\n        pass\n\n    def add_message(self, message: Message):\n        \"\"\"\n        Add a message to the history.\n\n        Args:\n            message: The Message object to add to the history\n\n        Returns:\n            Message: The added message, allowing for method chaining\n        \"\"\"\n        pass\n\n    def add_user_message_create(self, avatar: str, text: str) -> UserMessage:\n        \"\"\"\n        Create and add a new user message with text.\n\n        Args:\n            avatar: Avatar image URL or emoji for the user\n            text: The text content of the user message\n\n        Returns:\n            UserMessage: The created user message\n        \"\"\"\n        pass\n\n    @staticmethod\n    def register_component_type(name: str) -> ComponentType:\n        \"\"\"\n        Register a new component type for use in messages.\n\n        This allows extending the library with custom component types\n        that can be detected and rendered appropriately.\n\n        Args:\n            name: The name of the new component type\n\n        Returns:\n            ComponentType: The created component type enum value\n        \"\"\"\n        pass\n\n    @staticmethod\n    def register_component_detector(\n        component_type: ComponentType, detector: Callable[[Any, dict], bool]\n    ) -> None:\n        \"\"\"\n        Register a detector function for a component type.\n\n        The detector function determines whether a given content\n        should be treated as the specified component type.\n\n        Args:\n            component_type: The component type to register a detector for\n            detector: A function that takes (content, kwargs) and returns True if\n                     the content should be treated as this component type\n        \"\"\"\n        pass\n\n    @staticmethod\n    def register_component_renderer(\n        component_type: ComponentType, renderer: Callable[[Any, dict], None]\n    ) -> None:\n        \"\"\"\n        Register a renderer function for a component type.\n\n        The renderer function handles displaying the component in the Streamlit UI.\n\n        Args:\n            component_type: The component type to register a renderer for\n            renderer: A function that takes (content, kwargs) and renders\n                     the component in the Streamlit app\n        \"\"\"\n        pass\n\n    @staticmethod\n    def register_component_method(\n        method_name: str,\n        component_type: ComponentType,\n        method_func: Optional[Callable] = None,\n    ) -> None:\n        \"\"\"\n        Register a new component method to the Message class.\n\n        This allows adding custom methods to Message objects for adding\n        specific types of components with a convenient API.\n\n        Args:\n            method_name: The name of the method to add (e.g., 'add_chart')\n            component_type: The component type this method will create\n            method_func: Optional custom function to use for the method\n                        (if None, a default implementation will be used)\n        \"\"\"\n        pass\n```\n--- File: streamlit_rich_message_history/messages.py ---\n```python\nclass Message:\n    \"\"\"\n    Class representing a message with multiple components.\n\n    This is the core class for creating rich messages with various content types.\n    A message represents a single chat bubble/entry that can contain multiple\n    components (text, code, charts, tables, etc.).\n\n    Attributes:\n        user: The sender of the message ('user', 'assistant', etc.)\n        avatar: Avatar image for the message sender\n        components: List of MessageComponent objects in this message\n    \"\"\"\n\n    def __init__(self, user: str, avatar: str):\n        \"\"\"\n        Initialize a new message.\n\n        Args:\n            user: The sender of the message ('user', 'assistant', etc.)\n            avatar: Avatar image for the message sender (URL or emoji)\n        \"\"\"\n        pass\n\n    _custom_component_methods: Dict[str, ComponentType] = {}\n\n    def add_text(self, text: str, **kwargs):\n        \"\"\"\n        Add a text component to the message.\n\n        Args:\n            text: The text content (supports markdown)\n            **kwargs: Additional keyword arguments for the component\n                      Common ones include:\n                      - title: A title for the text\n                      - description: A description\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_text(\"Hello, **world**!\")\n            >>> message.add_text(\"Expandable content\", title=\"Section Title\")\n        \"\"\"\n        pass\n\n    def add_error(self, error_text: str, **kwargs):\n        \"\"\"\n        Add an error component to the message.\n\n        Args:\n            error_text: The error message to display\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_error(\"File not found: example.txt\")\n        \"\"\"\n        pass\n\n    def add_metric(self, value: Any, label: Optional[str] = None, **kwargs):\n        \"\"\"\n        Add a metric component to the message.\n\n        Args:\n            value: The value of the metric\n            label: Label for the metric\n            **kwargs: Additional keyword arguments for the component\n                      Common ones include:\n                      - delta: Delta value to show\n                      - delta_color: Color for delta ('normal', 'inverse', 'off')\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_metric(42, \"Answer\")\n            >>> message.add_metric(103.5, \"Temperature\", delta=2.5)\n        \"\"\"\n        pass\n\n    def add_custom(self, content: Any, component_type: str, **kwargs):\n        \"\"\"\n        Add a custom component type.\n\n        This method is used for components registered through the ComponentRegistry.\n\n        Args:\n            content: The content to display\n            component_type: The registered component type name\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Raises:\n            ValueError: If the component type is not registered\n\n        Examples:\n            >>> # After registering an 'image' component type:\n            >>> message.add_custom(my_pil_image, \"image\", width=300)\n        \"\"\"\n        pass\n\n\nclass UserMessage(Message):\n    \"\"\"\n    Convenience class for user messages.\n\n    This class creates a Message with the 'user' role pre-configured,\n    making it easier to create user messages in a chat interface.\n\n    Attributes:\n        user: Always set to 'user'\n        avatar: Avatar image for the user\n        components: List of MessageComponent objects in this message\n    \"\"\"\n\n    def __init__(self, avatar: str, text: Optional[str] = None):\n        \"\"\"\n        Initialize a new user message.\n\n        Args:\n            avatar: Avatar image for the user (URL or emoji)\n            text: Optional initial text for the message. If provided,\n                  adds a text component automatically.\n        \"\"\"\n        pass\n```",
        "minimal_test_cases": [
            {
                "test_id": "tests/components/test_components.py::test_text_component_detection",
                "covers": [
                    "streamlit_rich_message_history.components.MessageComponent.__init__ - happy path for text auto-detection",
                    "streamlit_rich_message_history.enums.ComponentType - usage (e.g., ComponentType.TEXT)"
                ]
            },
            {
                "test_id": "tests/components/test_custom_components.py::TestCustomComponents::test_custom_renderer_is_called",
                "covers": [
                    "streamlit_rich_message_history.components.MessageComponent.render - testing custom renderer pathway"
                ]
            },
            {
                "test_id": "tests/components/test_custom_components.py::TestCustomComponents::test_register_component_type",
                "covers": [
                    "streamlit_rich_message_history.history.MessageHistory.register_component_type - happy path",
                    "streamlit_rich_message_history.enums.ComponentRegistry.register_component_type - via MessageHistory",
                    "streamlit_rich_message_history.enums.ComponentRegistry.get_custom_type - via MessageHistory"
                ]
            },
            {
                "test_id": "tests/components/test_custom_components.py::TestCustomComponents::test_register_component_detector",
                "covers": [
                    "streamlit_rich_message_history.history.MessageHistory.register_component_detector - happy path",
                    "streamlit_rich_message_history.enums.ComponentRegistry.register_detector - via MessageHistory",
                    "streamlit_rich_message_history.enums.ComponentRegistry.get_detector - via MessageHistory"
                ]
            },
            {
                "test_id": "tests/components/test_custom_components.py::TestCustomComponents::test_register_component_renderer",
                "covers": [
                    "streamlit_rich_message_history.history.MessageHistory.register_component_renderer - happy path",
                    "streamlit_rich_message_history.enums.ComponentRegistry.register_renderer - via MessageHistory",
                    "streamlit_rich_message_history.enums.ComponentRegistry.get_renderer - via MessageHistory"
                ]
            },
            {
                "test_id": "tests/test_history.py::test_history_add_message",
                "covers": [
                    "streamlit_rich_message_history.history.MessageHistory.__init__ - happy path",
                    "streamlit_rich_message_history.history.MessageHistory.add_message - happy path",
                    "streamlit_rich_message_history.messages.Message.__init__ - basic instantiation"
                ]
            },
            {
                "test_id": "tests/components/test_custom_components.py::TestCustomComponents::test_message_history_with_custom_components",
                "covers": [
                    "streamlit_rich_message_history.history.MessageHistory.add_user_message_create - happy path"
                ]
            },
            {
                "test_id": "tests/test_history.py::test_history_render_last",
                "covers": [
                    "streamlit_rich_message_history.history.MessageHistory.render_last - basic functionality",
                    "streamlit_rich_message_history.messages.Message.render - implicit call during history rendering"
                ]
            },
            {
                "test_id": "tests/components/test_custom_components.py::TestCustomComponents::test_register_component_method",
                "covers": [
                    "streamlit_rich_message_history.history.MessageHistory.register_component_method - happy path",
                    "streamlit_rich_message_history.messages.Message.register_component_method - via MessageHistory"
                ]
            },
            {
                "test_id": "tests/test_messages.py::test_message_chaining",
                "covers": [
                    "streamlit_rich_message_history.messages.Message.add_text - happy path and chaining",
                    "streamlit_rich_message_history.messages.Message.add_metric - happy path and chaining",
                    "streamlit_rich_message_history.messages.Message.add - implicit usage by add_text/add_metric"
                ]
            },
            {
                "test_id": "tests/test_messages.py::test_message_add_methods",
                "covers": [
                    "streamlit_rich_message_history.messages.AssistantMessage.__init__ - happy path",
                    "streamlit_rich_message_history.messages.Message.add_error - happy path"
                ]
            },
            {
                "test_id": "tests/components/test_custom_components.py::TestCustomComponents::test_custom_method_usage_in_message",
                "covers": [
                    "streamlit_rich_message_history.messages.UserMessage.__init__ - happy path",
                    "streamlit_rich_message_history.messages.Message.add_custom - usage via dynamic method"
                ]
            }
        ],
        "commit_sha": "6077779927745b8efb78b5dad3ce9958b5ef0ae4",
        "full_code_skeleton_structured": [
            {
                "file_path": "release.py",
                "code": "def run_command(command, exit_on_error=True):\n    \"\"\"Run a command and return the output\"\"\"\n    pass\n\ndef get_current_version():\n    \"\"\"Get the current version from Poetry\"\"\"\n    pass\n\ndef backup_file(file_path):\n    \"\"\"Create a temporary backup of a file\"\"\"\n    pass\n\ndef check_files_changed(file_path, backup_path):\n    \"\"\"Check if a file has changed compared to its backup\"\"\"\n    pass\n\ndef main():\n    pass\n"
            },
            {
                "file_path": "streamlit_rich_message_history/__init__.py",
                "code": "\"\"\"\nStreamlit Rich Message History\n==============================\n\nA package for creating and managing rich, multi-component chat messages in Streamlit.\n\"\"\"\n"
            },
            {
                "file_path": "streamlit_rich_message_history/history.py",
                "code": "class MessageHistory:\n    \"\"\"\n    Class to store and manage a history of messages in a Streamlit application.\n\n    The MessageHistory class provides a convenient way to maintain a conversation-like\n    interface in Streamlit apps, with support for different types of messages (user,\n    assistant, error) and rich content components.\n\n    It manages the addition, storage, and rendering of messages, as well as the\n    registration of custom component types, detectors, and renderers.\n\n    Attributes:\n        messages: A list of Message objects that comprise the conversation history\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize an empty message history.\"\"\"\n        pass\n\n    def add_message(self, message: Message):\n        \"\"\"\n        Add a message to the history.\n\n        Args:\n            message: The Message object to add to the history\n\n        Returns:\n            Message: The added message, allowing for method chaining\n        \"\"\"\n        pass\n\n    def add_user_message_create(self, avatar: str, text: str) -> UserMessage:\n        \"\"\"\n        Create and add a new user message with text.\n\n        Args:\n            avatar: Avatar image URL or emoji for the user\n            text: The text content of the user message\n\n        Returns:\n            UserMessage: The created user message\n        \"\"\"\n        pass\n\n    def add_user_message(self, message: UserMessage) -> None:\n        \"\"\"\n        Add a pre-created user message to the history.\n\n        Args:\n            message: The UserMessage object to add to the history\n        \"\"\"\n        pass\n\n    def add_assistant_message_create(self, avatar: str) -> AssistantMessage:\n        \"\"\"\n        Create and add a new empty assistant message.\n\n        This creates an assistant message that can be populated with\n        components after creation.\n\n        Args:\n            avatar: Avatar image URL or emoji for the assistant\n\n        Returns:\n            AssistantMessage: The created assistant message\n        \"\"\"\n        pass\n\n    def add_assistant_message(self, message: AssistantMessage) -> None:\n        \"\"\"\n        Add a pre-created assistant message to the history.\n\n        Args:\n            message: The AssistantMessage object to add to the history\n        \"\"\"\n        pass\n\n    def add_error_message(self, avatar: str, error_text: str) -> ErrorMessage:\n        \"\"\"\n        Create and add an error message to the history.\n\n        Args:\n            avatar: Avatar image URL or emoji for the error message\n            error_text: The error text to display\n\n        Returns:\n            ErrorMessage: The created error message\n        \"\"\"\n        pass\n\n    def render_all(self):\n        \"\"\"\n        Render all messages in the history to the Streamlit UI.\n\n        This renders each message in sequence, from first to last.\n        \"\"\"\n        pass\n\n    def render_last(self, n: int = 1):\n        \"\"\"\n        Render only the last n messages in the history.\n\n        Args:\n            n: Number of most recent messages to render (default: 1)\n        \"\"\"\n        pass\n\n    def clear(self):\n        \"\"\"Clear all messages from the history, resetting it to empty.\"\"\"\n        pass\n\n    @staticmethod\n    def register_component_type(name: str) -> ComponentType:\n        \"\"\"\n        Register a new component type for use in messages.\n\n        This allows extending the library with custom component types\n        that can be detected and rendered appropriately.\n\n        Args:\n            name: The name of the new component type\n\n        Returns:\n            ComponentType: The created component type enum value\n        \"\"\"\n        pass\n\n    @staticmethod\n    def register_component_detector(\n        component_type: ComponentType, detector: Callable[[Any, dict], bool]\n    ) -> None:\n        \"\"\"\n        Register a detector function for a component type.\n\n        The detector function determines whether a given content\n        should be treated as the specified component type.\n\n        Args:\n            component_type: The component type to register a detector for\n            detector: A function that takes (content, kwargs) and returns True if\n                     the content should be treated as this component type\n        \"\"\"\n        pass\n\n    @staticmethod\n    def register_component_renderer(\n        component_type: ComponentType, renderer: Callable[[Any, dict], None]\n    ) -> None:\n        \"\"\"\n        Register a renderer function for a component type.\n\n        The renderer function handles displaying the component in the Streamlit UI.\n\n        Args:\n            component_type: The component type to register a renderer for\n            renderer: A function that takes (content, kwargs) and renders\n                     the component in the Streamlit app\n        \"\"\"\n        pass\n\n    @staticmethod\n    def register_component_method(\n        method_name: str,\n        component_type: ComponentType,\n        method_func: Optional[Callable] = None,\n    ) -> None:\n        \"\"\"\n        Register a new component method to the Message class.\n\n        This allows adding custom methods to Message objects for adding\n        specific types of components with a convenient API.\n\n        Args:\n            method_name: The name of the method to add (e.g., 'add_chart')\n            component_type: The component type this method will create\n            method_func: Optional custom function to use for the method\n                        (if None, a default implementation will be used)\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "streamlit_rich_message_history/enums.py",
                "code": "\"\"\"\nComponent type definitions and registry for the streamlit_rich_message_history package.\n\nThis module defines the core component types and provides a registry system\nfor extending the package with custom component types, detectors, and renderers.\n\"\"\"\nfrom typing import Any, Callable, Dict, Optional\n\nclass ComponentType(Enum):\n    \"\"\"\n    Enum defining the possible message component types.\n\n    These types correspond to different ways content can be displayed in messages,\n    such as text, dataframes, charts, etc.\n\n    Attributes:\n        TEXT: Plain text content\n        DATAFRAME: Pandas DataFrame display\n        SERIES: Pandas Series display\n        MATPLOTLIB_FIGURE: Matplotlib plot\n        PLOTLY_FIGURE: Plotly chart\n        NUMBER: Numeric value\n        ERROR: Error message\n        CODE: Code snippet with syntax highlighting\n        METRIC: Metric with optional delta\n        TABLE: Static table display\n        JSON: JSON data viewer\n        HTML: HTML content\n        LIST: List of items\n        TUPLE: Tuple of items\n        DICT: Dictionary of items\n    \"\"\"\n\n    TEXT = \"text\"\n    DATAFRAME = \"dataframe\"\n    SERIES = \"series\"\n    MATPLOTLIB_FIGURE = \"matplotlib_figure\"\n    PLOTLY_FIGURE = \"plotly_figure\"\n    NUMBER = \"number\"\n    ERROR = \"error\"\n    CODE = \"code\"\n    METRIC = \"metric\"\n    TABLE = \"table\"\n    JSON = \"json\"\n    HTML = \"html\"\n    LIST = \"list\"\n    TUPLE = \"tuple\"\n    DICT = \"dict\"\n\nclass ComponentRegistry:\n    \"\"\"\n    Registry to manage custom component types, detectors, and renderers.\n\n    This class provides static methods for registering and retrieving:\n    - Custom component types (extending ComponentType)\n    - Type detection functions that identify content types\n    - Rendering functions that display specific content types\n\n    The registry is a central point for extending the package with custom components.\n    \"\"\"\n\n    _custom_types: Dict[str, ComponentType] = {}\n    _type_detectors: Dict[ComponentType, Callable[[Any, Dict[str, Any]], bool]] = {}\n    _renderers: Dict[ComponentType, Callable[[Any, Dict[str, Any]], None]] = {}\n\n    @classmethod\n    def register_component_type(cls, name: str) -> ComponentType:\n        \"\"\"\n        Register a new component type with the given name.\n        If a component type with this name already exists, returns the existing type\n        with a warning instead of raising an exception.\n\n        Args:\n            name: String identifier for the new component type\n\n        Returns:\n            ComponentType: The newly created component type or existing component type\n\n        Examples:\n            >>> IMAGE_TYPE = ComponentRegistry.register_component_type(\"image\")\n            >>> # IMAGE_TYPE can now be used like a standard ComponentType\n            >>> # Registering the same type again will return the existing type\n            >>> SAME_IMAGE_TYPE = ComponentRegistry.register_component_type(\"image\")\n            >>> # A warning will be printed and SAME_IMAGE_TYPE == IMAGE_TYPE\n        \"\"\"\n        pass\n\n    @classmethod\n    def register_detector(\n        cls, comp_type: ComponentType, detector: Callable[[Any, Dict[str, Any]], bool]\n    ) -> None:\n        \"\"\"\n        Register a detector function for a component type.\n\n        The detector function determines if content should be treated as this component type.\n\n        Args:\n            comp_type: The component type to register a detector for\n            detector: Function that takes content and kwargs and returns True if the\n                    content should be handled as this component type\n\n        Examples:\n            >>> def image_detector(content, kwargs):\n                    return isinstance(content, PIL.Image.Image)\n            >>> ComponentRegistry.register_detector(IMAGE_TYPE, image_detector)\n        \"\"\"\n        pass\n\n    @classmethod\n    def register_renderer(\n        cls, comp_type: ComponentType, renderer: Callable[[Any, Dict[str, Any]], None]\n    ) -> None:\n        \"\"\"\n        Register a renderer function for a component type.\n\n        The renderer function handles displaying the content in a Streamlit app.\n\n        Args:\n            comp_type: The component type to register a renderer for\n            renderer: Function that takes content and kwargs and renders it in Streamlit\n\n        Examples:\n            >>> def image_renderer(content, kwargs):\n                    st.image(content, **{k: v for k, v in kwargs.items()\n                                     if k in ['caption', 'width', 'use_column_width']})\n            >>> ComponentRegistry.register_renderer(IMAGE_TYPE, image_renderer)\n        \"\"\"\n        pass\n\n    @classmethod\n    def get_custom_type(cls, name: str) -> Optional[ComponentType]:\n        \"\"\"\n        Get a custom component type by name.\n\n        Args:\n            name: String identifier of the component type\n\n        Returns:\n            ComponentType: The component type if found, None otherwise\n        \"\"\"\n        pass\n\n    @classmethod\n    def get_all_types(cls) -> list:\n        \"\"\"\n        Get all component types (built-in and custom).\n\n        Returns:\n            list: List containing all ComponentType values\n        \"\"\"\n        pass\n\n    @classmethod\n    def get_detector(cls, comp_type: ComponentType) -> Optional[Callable]:\n        \"\"\"\n        Get the detector function for a component type.\n\n        Args:\n            comp_type: The component type to get the detector for\n\n        Returns:\n            Callable: The detector function if registered, None otherwise\n        \"\"\"\n        pass\n\n    @classmethod\n    def get_renderer(cls, comp_type: ComponentType) -> Optional[Callable]:\n        \"\"\"\n        Get the renderer function for a component type.\n\n        Args:\n            comp_type: The component type to get the renderer for\n\n        Returns:\n            Callable: The renderer function if registered, None otherwise\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "streamlit_rich_message_history/components.py",
                "code": "\"\"\"\nComponent handling for the streamlit_rich_message_history package.\n\nThis module defines the core MessageComponent class that detects, processes, and\nrenders different types of content in a Streamlit application.\n\"\"\"\nfrom typing import Any, Optional, Union\n\nclass MessageComponent:\n    \"\"\"\n    Base class for all message components with automatic type detection.\n\n    This class handles the automatic detection, proper rendering, and error handling\n    for different types of content within a message in a Streamlit application.\n\n    Attributes:\n        content: The actual content to be displayed\n        component_type: The type of component (automatically detected if not specified)\n        title: Optional title for the component\n        description: Optional description text for the component\n        expanded: Whether expandable sections should be expanded by default\n        kwargs: Additional keyword arguments for rendering\n    \"\"\"\n\n    def __init__(\n        self,\n        content: Any,\n        component_type: Optional[ComponentType] = None,\n        title: Optional[str] = None,\n        description: Optional[str] = None,\n        expanded: bool = False,\n        **kwargs,\n    ):\n        \"\"\"\n        Initialize a new message component.\n\n        Args:\n            content: The content to be displayed\n            component_type: Manually specify the component type (auto-detected if None)\n            title: Optional title for the component (creates an expander if provided)\n            description: Optional description text for the component\n            expanded: Whether expandable sections should be expanded by default\n            **kwargs: Additional keyword arguments that control rendering behavior\n                      Special flags include:\n                      - is_error: Treat string content as an error message\n                      - is_code: Treat string content as code with syntax highlighting\n                      - language: The programming language for code highlighting\n                      - is_metric: Treat numeric content as a metric\n                      - is_table: Treat content as a static table\n                      - is_json: Treat dictionaries or lists as JSON data\n                      - is_html: Treat string content as HTML\n        \"\"\"\n        pass\n\n    def _detect_component_type(self, content: Any) -> ComponentType:\n        \"\"\"\n        Detect the appropriate component type based on content.\n\n        This method uses a combination of registered custom detectors and built-in\n        type detection logic to determine the most appropriate component type\n        for the given content.\n\n        Args:\n            content: The content to detect the type for\n\n        Returns:\n            ComponentType: The detected component type\n        \"\"\"\n        pass\n\n    def render(self):\n        \"\"\"\n        Render the component with appropriate context.\n\n        If a title is provided, the component is wrapped in an expander.\n        If a description is provided, it's shown before the content.\n        \"\"\"\n        pass\n\n    def _render_content(self):\n        \"\"\"\n        Render the component based on its detected type.\n\n        This method handles the rendering of all built-in component types\n        and delegates to custom renderers for custom component types.\n        It also includes error handling to prevent component rendering errors\n        from breaking the entire application.\n        \"\"\"\n        pass\n\n    def _render_collection_item(\n        self, item: Any, index: Optional[Union[int, str]] = None\n    ):\n        \"\"\"\n        Render a single item from a collection.\n\n        Args:\n            item: The item to render\n            index: Optional index or key for error reporting\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "streamlit_rich_message_history/messages.py",
                "code": "\"\"\"\nMessage classes for the streamlit_rich_message_history package.\n\nThis module defines the Message class and its derivatives (UserMessage, AssistantMessage,\nErrorMessage) which represent chat messages with rich content components.\n\"\"\"\nfrom typing import Any, Callable, Dict, List, Optional, Tuple, Union\n\nclass Message:\n    \"\"\"\n    Class representing a message with multiple components.\n\n    This is the core class for creating rich messages with various content types.\n    A message represents a single chat bubble/entry that can contain multiple\n    components (text, code, charts, tables, etc.).\n\n    Attributes:\n        user: The sender of the message ('user', 'assistant', etc.)\n        avatar: Avatar image for the message sender\n        components: List of MessageComponent objects in this message\n    \"\"\"\n\n    _custom_component_methods: Dict[str, ComponentType] = {}\n\n    def __init__(self, user: str, avatar: str):\n        \"\"\"\n        Initialize a new message.\n\n        Args:\n            user: The sender of the message ('user', 'assistant', etc.)\n            avatar: Avatar image for the message sender (URL or emoji)\n        \"\"\"\n        pass\n\n    def add(self, content: Any, **kwargs):\n        \"\"\"\n        Add a component to the message with automatic type detection.\n\n        This is the core method for adding content. All specific add_* methods\n        ultimately call this method with appropriate flags.\n\n        Args:\n            content: The content to add to the message\n            **kwargs: Additional keyword arguments that control rendering behavior\n                      Special flags include:\n                      - is_error: Treat string content as an error message\n                      - is_code: Treat string content as code with syntax highlighting\n                      - language: The programming language for code highlighting\n                      - is_metric: Treat numeric content as a metric\n                      - is_table: Treat content as a static table\n                      - is_json: Treat dictionaries or lists as JSON data\n                      - is_html: Treat string content as HTML\n\n        Returns:\n            Message: Self, for method chaining\n        \"\"\"\n        pass\n\n    def add_text(self, text: str, **kwargs):\n        \"\"\"\n        Add a text component to the message.\n\n        Args:\n            text: The text content (supports markdown)\n            **kwargs: Additional keyword arguments for the component\n                      Common ones include:\n                      - title: A title for the text\n                      - description: A description\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_text(\"Hello, **world**!\")\n            >>> message.add_text(\"Expandable content\", title=\"Section Title\")\n        \"\"\"\n        pass\n\n    def add_error(self, error_text: str, **kwargs):\n        \"\"\"\n        Add an error component to the message.\n\n        Args:\n            error_text: The error message to display\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_error(\"File not found: example.txt\")\n        \"\"\"\n        pass\n\n    def add_code(self, code: str, language: str = \"python\", **kwargs):\n        \"\"\"\n        Add a code component to the message.\n\n        Args:\n            code: The code snippet to display\n            language: Programming language for syntax highlighting (default: 'python')\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_code(\"def hello(): print('Hello world')\")\n            >>> message.add_code(\"<div>Hello</div>\", language=\"html\")\n        \"\"\"\n        pass\n\n    def add_dataframe(self, df: pd.DataFrame, **kwargs):\n        \"\"\"\n        Add a dataframe component to the message.\n\n        Args:\n            df: The pandas DataFrame to display\n            **kwargs: Additional keyword arguments for the component\n                      Common ones include:\n                      - use_container_width: Whether to use the full container width\n                      - height: Height of the dataframe in pixels\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_dataframe(pd.DataFrame({'A': [1, 2], 'B': [3, 4]}))\n            >>> message.add_dataframe(df, height=300)\n        \"\"\"\n        pass\n\n    def add_series(self, series: pd.Series, **kwargs):\n        \"\"\"\n        Add a series component to the message.\n\n        Args:\n            series: The pandas Series to display\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_series(pd.Series([1, 2, 3, 4]))\n        \"\"\"\n        pass\n\n    def add_matplotlib_figure(self, fig: plt.Figure, **kwargs):\n        \"\"\"\n        Add a matplotlib figure component to the message.\n\n        Args:\n            fig: The matplotlib Figure to display\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> fig, ax = plt.subplots()\n            >>> ax.plot([1, 2, 3, 4])\n            >>> message.add_matplotlib_figure(fig)\n        \"\"\"\n        pass\n\n    def add_plotly_figure(self, fig: Union[go.Figure, dict], **kwargs):\n        \"\"\"\n        Add a plotly figure component to the message.\n\n        Args:\n            fig: The plotly Figure to display\n            **kwargs: Additional keyword arguments for the component\n                      Common ones include:\n                      - use_container_width: Whether to use the full container width\n                      - height: Height of the chart in pixels\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> fig = go.Figure(data=go.Bar(y=[2, 3, 1]))\n            >>> message.add_plotly_figure(fig)\n        \"\"\"\n        pass\n\n    def add_number(self, number: Union[int, float], **kwargs):\n        \"\"\"\n        Add a number component to the message.\n\n        Args:\n            number: The number to display\n            **kwargs: Additional keyword arguments for the component\n                      Common ones include:\n                      - format: Format string (e.g., \"{:.2f}%\" for percentage)\n                      - title: Label for the number\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_number(42)\n            >>> message.add_number(3.14159, format=\"{:.2f}\", title=\"Pi\")\n        \"\"\"\n        pass\n\n    def add_metric(self, value: Any, label: Optional[str] = None, **kwargs):\n        \"\"\"\n        Add a metric component to the message.\n\n        Args:\n            value: The value of the metric\n            label: Label for the metric\n            **kwargs: Additional keyword arguments for the component\n                      Common ones include:\n                      - delta: Delta value to show\n                      - delta_color: Color for delta ('normal', 'inverse', 'off')\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_metric(42, \"Answer\")\n            >>> message.add_metric(103.5, \"Temperature\", delta=2.5)\n        \"\"\"\n        pass\n\n    def add_table(self, data: Any, **kwargs):\n        \"\"\"\n        Add a static table component to the message.\n\n        Args:\n            data: The data to display as a table\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_table(pd.DataFrame({'A': [1, 2], 'B': [3, 4]}))\n            >>> message.add_table([[1, 2], [3, 4]])\n        \"\"\"\n        pass\n\n    def add_json(self, data: Union[Dict, List], **kwargs):\n        \"\"\"\n        Add a JSON component to the message.\n\n        Args:\n            data: The data to display as JSON\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_json({\"name\": \"John\", \"age\": 30})\n            >>> message.add_json([1, 2, 3, {\"nested\": True}])\n        \"\"\"\n        pass\n\n    def add_html(self, html_content: str, **kwargs):\n        \"\"\"\n        Add an HTML component to the message.\n\n        Args:\n            html_content: The HTML content to display\n            **kwargs: Additional keyword arguments for the component\n                      Common ones include:\n                      - height: Height of the HTML content in pixels\n                      - scrolling: Whether to enable scrolling\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_html(\"<h1>Hello World</h1>\")\n            >>> message.add_html(\"<div>Content</div>\", height=300, scrolling=True)\n        \"\"\"\n        pass\n\n    def add_list(self, items: List[Any], **kwargs):\n        \"\"\"\n        Add a list of items to the message.\n\n        Each item in the list will be rendered as its own component.\n\n        Args:\n            items: The list of items to display\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_list([\"Text\", 42, pd.DataFrame({'A': [1]})])\n        \"\"\"\n        pass\n\n    def add_tuple(self, items: Tuple[Any, ...], **kwargs):\n        \"\"\"\n        Add a tuple of items to the message.\n\n        Each item in the tuple will be rendered as its own component.\n\n        Args:\n            items: The tuple of items to display\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_tuple((\"Text\", 42, pd.DataFrame({'A': [1]})))\n        \"\"\"\n        pass\n\n    def add_dict(self, items: Dict[str, Any], **kwargs):\n        \"\"\"\n        Add a dictionary of items to the message.\n\n        Each value in the dictionary will be rendered as its own component.\n\n        Args:\n            items: The dictionary of items to display\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_dict({\"text\": \"Hello\", \"number\": 42})\n        \"\"\"\n        pass\n\n    def add_custom(self, content: Any, component_type: str, **kwargs):\n        \"\"\"\n        Add a custom component type.\n\n        This method is used for components registered through the ComponentRegistry.\n\n        Args:\n            content: The content to display\n            component_type: The registered component type name\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Raises:\n            ValueError: If the component type is not registered\n\n        Examples:\n            >>> # After registering an 'image' component type:\n            >>> message.add_custom(my_pil_image, \"image\", width=300)\n        \"\"\"\n        pass\n\n    def render(self):\n        \"\"\"\n        Render the message with all its components.\n\n        This method displays the message in a Streamlit app using st.chat_message\n        and renders all components within it.\n\n        Raises:\n            Displays an error message in the UI if rendering fails\n        \"\"\"\n        pass\n\n    @classmethod\n    def register_component_method(\n        cls,\n        method_name: str,\n        component_type: ComponentType,\n        method_func: Optional[Callable] = None,\n    ):\n        \"\"\"\n        Register a new component method for the Message class.\n        This method dynamically adds a new add_* method to the Message class\n        for a custom component type. If a method with this name already exists,\n        returns the existing method with a warning instead of raising an exception.\n\n        Args:\n            method_name: Name of the method to add (typically 'add_xyz')\n            component_type: The component type to associate with this method\n            method_func: Optional custom function for the method\n                        If None, a default implementation is created\n\n        Returns:\n            Callable: The created or existing method function\n\n        Examples:\n            >>> IMAGE_TYPE = ComponentRegistry.register_component_type(\"image\")\n            >>> Message.register_component_method(\"add_image\", IMAGE_TYPE)\n            >>> # Now message.add_image() is available\n            >>> # Registering the same method again will return the existing method\n            >>> Message.register_component_method(\"add_image\", IMAGE_TYPE)\n            >>> # A warning will be printed and the existing method will be returned\n        \"\"\"\n        pass\n\nclass UserMessage(Message):\n    \"\"\"\n    Convenience class for user messages.\n\n    This class creates a Message with the 'user' role pre-configured,\n    making it easier to create user messages in a chat interface.\n\n    Attributes:\n        user: Always set to 'user'\n        avatar: Avatar image for the user\n        components: List of MessageComponent objects in this message\n    \"\"\"\n\n    def __init__(self, avatar: str, text: Optional[str] = None):\n        \"\"\"\n        Initialize a new user message.\n\n        Args:\n            avatar: Avatar image for the user (URL or emoji)\n            text: Optional initial text for the message. If provided,\n                  adds a text component automatically.\n        \"\"\"\n        pass\n\nclass AssistantMessage(Message):\n    \"\"\"\n    Convenience class for assistant messages.\n\n    This class creates a Message with the 'assistant' role pre-configured,\n    making it easier to create assistant/AI responses in a chat interface.\n\n    Attributes:\n        user: Always set to 'assistant'\n        avatar: Avatar image for the assistant\n        components: List of MessageComponent objects in this message\n    \"\"\"\n\n    def __init__(self, avatar: str):\n        \"\"\"\n        Initialize a new assistant message.\n\n        Args:\n            avatar: Avatar image for the assistant (URL or emoji)\n        \"\"\"\n        pass\n\nclass ErrorMessage(Message):\n    \"\"\"\n    Convenience class for error messages.\n\n    This class creates a Message with the 'error' role pre-configured\n    and automatically adds an error component, making it easier to\n    display errors in a chat interface.\n\n    Attributes:\n        user: Always set to 'error'\n        avatar: Avatar image for error messages\n        components: List of MessageComponent objects in this message\n    \"\"\"\n\n    def __init__(self, avatar: str, error_text: str):\n        \"\"\"\n        Initialize a new error message.\n\n        Args:\n            avatar: Avatar image for the error message (URL or emoji)\n            error_text: The error message to display\n        \"\"\"\n        pass\n"
            }
        ],
        "minimal_code_skeleton_structured": [
            {
                "file_path": "streamlit_rich_message_history/components.py",
                "code": "class MessageComponent:\n    \"\"\"\n    Base class for all message components with automatic type detection.\n\n    This class handles the automatic detection, proper rendering, and error handling\n    for different types of content within a message in a Streamlit application.\n\n    Attributes:\n        content: The actual content to be displayed\n        component_type: The type of component (automatically detected if not specified)\n        title: Optional title for the component\n        description: Optional description text for the component\n        expanded: Whether expandable sections should be expanded by default\n        kwargs: Additional keyword arguments for rendering\n    \"\"\"\n\n    def __init__(\n        self,\n        content: Any,\n        component_type: Optional[ComponentType] = None,\n        title: Optional[str] = None,\n        description: Optional[str] = None,\n        expanded: bool = False,\n        **kwargs,\n    ):\n        \"\"\"\n        Initialize a new message component.\n\n        Args:\n            content: The content to be displayed\n            component_type: Manually specify the component type (auto-detected if None)\n            title: Optional title for the component (creates an expander if provided)\n            description: Optional description text for the component\n            expanded: Whether expandable sections should be expanded by default\n            **kwargs: Additional keyword arguments that control rendering behavior\n                      Special flags include:\n                      - is_error: Treat string content as an error message\n                      - is_code: Treat string content as code with syntax highlighting\n                      - language: The programming language for code highlighting\n                      - is_metric: Treat numeric content as a metric\n                      - is_table: Treat content as a static table\n                      - is_json: Treat dictionaries or lists as JSON data\n                      - is_html: Treat string content as HTML\n        \"\"\"\n        pass\n\n    def _render_content(self):\n        \"\"\"\n        Render the component based on its detected type.\n\n        This method handles the rendering of all built-in component types\n        and delegates to custom renderers for custom component types.\n        It also includes error handling to prevent component rendering errors\n        from breaking the entire application.\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "streamlit_rich_message_history/enums.py",
                "code": "class ComponentType(Enum):\n    \"\"\"\n    Enum defining the possible message component types.\n\n    These types correspond to different ways content can be displayed in messages,\n    such as text, dataframes, charts, etc.\n\n    Attributes:\n        TEXT: Plain text content\n        DATAFRAME: Pandas DataFrame display\n        SERIES: Pandas Series display\n        MATPLOTLIB_FIGURE: Matplotlib plot\n        PLOTLY_FIGURE: Plotly chart\n        NUMBER: Numeric value\n        ERROR: Error message\n        CODE: Code snippet with syntax highlighting\n        METRIC: Metric with optional delta\n        TABLE: Static table display\n        JSON: JSON data viewer\n        HTML: HTML content\n        LIST: List of items\n        TUPLE: Tuple of items\n        DICT: Dictionary of items\n    \"\"\"\n\n    TEXT = \"text\"\n    DATAFRAME = \"dataframe\"\n    SERIES = \"series\"\n    MATPLOTLIB_FIGURE = \"matplotlib_figure\"\n    PLOTLY_FIGURE = \"plotly_figure\"\n    NUMBER = \"number\"\n    ERROR = \"error\"\n    CODE = \"code\"\n    METRIC = \"metric\"\n    TABLE = \"table\"\n    JSON = \"json\"\n    HTML = \"html\"\n    LIST = \"list\"\n    TUPLE = \"tuple\"\n    DICT = \"dict\"\n\n\nclass ComponentRegistry:\n    \"\"\"\n    Registry to manage custom component types, detectors, and renderers.\n\n    This class provides static methods for registering and retrieving:\n    - Custom component types (extending ComponentType)\n    - Type detection functions that identify content types\n    - Rendering functions that display specific content types\n\n    The registry is a central point for extending the package with custom components.\n    \"\"\"\n\n    _custom_types: Dict[str, ComponentType] = {}\n    _type_detectors: Dict[ComponentType, Callable[[Any, Dict[str, Any]], bool]] = {}\n    _renderers: Dict[ComponentType, Callable[[Any, Dict[str, Any]], None]] = {}\n\n    @classmethod\n    def get_custom_type(cls, name: str) -> Optional[ComponentType]:\n        \"\"\"\n        Get a custom component type by name.\n\n        Args:\n            name: String identifier of the component type\n\n        Returns:\n            ComponentType: The component type if found, None otherwise\n        \"\"\"\n        pass\n\n    @classmethod\n    def get_detector(cls, comp_type: ComponentType) -> Optional[Callable]:\n        \"\"\"\n        Get the detector function for a component type.\n\n        Args:\n            comp_type: The component type to get the detector for\n\n        Returns:\n            Callable: The detector function if registered, None otherwise\n        \"\"\"\n        pass\n\n    @classmethod\n    def get_renderer(cls, comp_type: ComponentType) -> Optional[Callable]:\n        \"\"\"\n        Get the renderer function for a component type.\n\n        Args:\n            comp_type: The component type to get the renderer for\n\n        Returns:\n            Callable: The renderer function if registered, None otherwise\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "streamlit_rich_message_history/history.py",
                "code": "class MessageHistory:\n    \"\"\"\n    Class to store and manage a history of messages in a Streamlit application.\n\n    The MessageHistory class provides a convenient way to maintain a conversation-like\n    interface in Streamlit apps, with support for different types of messages (user,\n    assistant, error) and rich content components.\n\n    It manages the addition, storage, and rendering of messages, as well as the\n    registration of custom component types, detectors, and renderers.\n\n    Attributes:\n        messages: A list of Message objects that comprise the conversation history\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize an empty message history.\"\"\"\n        pass\n\n    def add_message(self, message: Message):\n        \"\"\"\n        Add a message to the history.\n\n        Args:\n            message: The Message object to add to the history\n\n        Returns:\n            Message: The added message, allowing for method chaining\n        \"\"\"\n        pass\n\n    def add_user_message_create(self, avatar: str, text: str) -> UserMessage:\n        \"\"\"\n        Create and add a new user message with text.\n\n        Args:\n            avatar: Avatar image URL or emoji for the user\n            text: The text content of the user message\n\n        Returns:\n            UserMessage: The created user message\n        \"\"\"\n        pass\n\n    @staticmethod\n    def register_component_type(name: str) -> ComponentType:\n        \"\"\"\n        Register a new component type for use in messages.\n\n        This allows extending the library with custom component types\n        that can be detected and rendered appropriately.\n\n        Args:\n            name: The name of the new component type\n\n        Returns:\n            ComponentType: The created component type enum value\n        \"\"\"\n        pass\n\n    @staticmethod\n    def register_component_detector(\n        component_type: ComponentType, detector: Callable[[Any, dict], bool]\n    ) -> None:\n        \"\"\"\n        Register a detector function for a component type.\n\n        The detector function determines whether a given content\n        should be treated as the specified component type.\n\n        Args:\n            component_type: The component type to register a detector for\n            detector: A function that takes (content, kwargs) and returns True if\n                     the content should be treated as this component type\n        \"\"\"\n        pass\n\n    @staticmethod\n    def register_component_renderer(\n        component_type: ComponentType, renderer: Callable[[Any, dict], None]\n    ) -> None:\n        \"\"\"\n        Register a renderer function for a component type.\n\n        The renderer function handles displaying the component in the Streamlit UI.\n\n        Args:\n            component_type: The component type to register a renderer for\n            renderer: A function that takes (content, kwargs) and renders\n                     the component in the Streamlit app\n        \"\"\"\n        pass\n\n    @staticmethod\n    def register_component_method(\n        method_name: str,\n        component_type: ComponentType,\n        method_func: Optional[Callable] = None,\n    ) -> None:\n        \"\"\"\n        Register a new component method to the Message class.\n\n        This allows adding custom methods to Message objects for adding\n        specific types of components with a convenient API.\n\n        Args:\n            method_name: The name of the method to add (e.g., 'add_chart')\n            component_type: The component type this method will create\n            method_func: Optional custom function to use for the method\n                        (if None, a default implementation will be used)\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "streamlit_rich_message_history/messages.py",
                "code": "class Message:\n    \"\"\"\n    Class representing a message with multiple components.\n\n    This is the core class for creating rich messages with various content types.\n    A message represents a single chat bubble/entry that can contain multiple\n    components (text, code, charts, tables, etc.).\n\n    Attributes:\n        user: The sender of the message ('user', 'assistant', etc.)\n        avatar: Avatar image for the message sender\n        components: List of MessageComponent objects in this message\n    \"\"\"\n\n    def __init__(self, user: str, avatar: str):\n        \"\"\"\n        Initialize a new message.\n\n        Args:\n            user: The sender of the message ('user', 'assistant', etc.)\n            avatar: Avatar image for the message sender (URL or emoji)\n        \"\"\"\n        pass\n\n    _custom_component_methods: Dict[str, ComponentType] = {}\n\n    def add_text(self, text: str, **kwargs):\n        \"\"\"\n        Add a text component to the message.\n\n        Args:\n            text: The text content (supports markdown)\n            **kwargs: Additional keyword arguments for the component\n                      Common ones include:\n                      - title: A title for the text\n                      - description: A description\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_text(\"Hello, **world**!\")\n            >>> message.add_text(\"Expandable content\", title=\"Section Title\")\n        \"\"\"\n        pass\n\n    def add_error(self, error_text: str, **kwargs):\n        \"\"\"\n        Add an error component to the message.\n\n        Args:\n            error_text: The error message to display\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_error(\"File not found: example.txt\")\n        \"\"\"\n        pass\n\n    def add_metric(self, value: Any, label: Optional[str] = None, **kwargs):\n        \"\"\"\n        Add a metric component to the message.\n\n        Args:\n            value: The value of the metric\n            label: Label for the metric\n            **kwargs: Additional keyword arguments for the component\n                      Common ones include:\n                      - delta: Delta value to show\n                      - delta_color: Color for delta ('normal', 'inverse', 'off')\n\n        Returns:\n            Message: Self, for method chaining\n\n        Examples:\n            >>> message.add_metric(42, \"Answer\")\n            >>> message.add_metric(103.5, \"Temperature\", delta=2.5)\n        \"\"\"\n        pass\n\n    def add_custom(self, content: Any, component_type: str, **kwargs):\n        \"\"\"\n        Add a custom component type.\n\n        This method is used for components registered through the ComponentRegistry.\n\n        Args:\n            content: The content to display\n            component_type: The registered component type name\n            **kwargs: Additional keyword arguments for the component\n\n        Returns:\n            Message: Self, for method chaining\n\n        Raises:\n            ValueError: If the component type is not registered\n\n        Examples:\n            >>> # After registering an 'image' component type:\n            >>> message.add_custom(my_pil_image, \"image\", width=300)\n        \"\"\"\n        pass\n\n\nclass UserMessage(Message):\n    \"\"\"\n    Convenience class for user messages.\n\n    This class creates a Message with the 'user' role pre-configured,\n    making it easier to create user messages in a chat interface.\n\n    Attributes:\n        user: Always set to 'user'\n        avatar: Avatar image for the user\n        components: List of MessageComponent objects in this message\n    \"\"\"\n\n    def __init__(self, avatar: str, text: Optional[str] = None):\n        \"\"\"\n        Initialize a new user message.\n\n        Args:\n            avatar: Avatar image for the user (URL or emoji)\n            text: Optional initial text for the message. If provided,\n                  adds a text component automatically.\n        \"\"\"\n        pass\n"
            }
        ]
    }
]