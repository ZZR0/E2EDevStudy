[
    {
        "idx": 88982,
        "repo_name": "simonw_files-to-prompt",
        "url": "https://github.com/simonw/files-to-prompt",
        "description": "Concatenate a directory full of files into a single prompt for use with LLMs",
        "stars": 1613,
        "forks": 108,
        "language": "python",
        "size": 49,
        "created_at": "2024-03-22T15:42:41+00:00",
        "updated_at": "2025-04-27T01:55:16+00:00",
        "pypi_info": {
            "name": "files-to-prompt",
            "version": "0.6",
            "url": "https://files.pythonhosted.org/packages/b9/4f/81fc86a88dc9e0cf6ea1ac2c561c0ac48b46d314cbbc2db5c8844b4b448b/files_to_prompt-0.6.tar.gz"
        },
        "judge_info": {
            "language": "python",
            "is_good_project": false,
            "reason": "",
            "python_file_num": 4,
            "comment_ratio": 0.2362002567394095,
            "pyfile_content_length": 26266,
            "pyfile_code_lines": 779,
            "test_file_exist": true,
            "test_file_content_length": 16707,
            "pytest_framework": true,
            "test_case_num": 14,
            "metadata_path": [
                "pyproject.toml"
            ],
            "readme_content_length": 6629,
            "llm_reason": "Positive Aspects:\n*   **Self-Contained:** The project operates entirely on the local file system, requiring no internet connection or external APIs for its core functionality or testing. Dependencies (`click`, `pytest` for tests) are standard PyPI packages.\n*   **Clear Functionality:** The README provides a very clear description of the tool's purpose, usage, and command-line options. The goal (concatenate files with specific formatting and filtering) is well-defined.\n*   **Testable:** The project includes a comprehensive test suite (`tests/test_files_to_prompt.py`) using `pytest` and `CliRunner`, covering various options, edge cases (hidden files, gitignore, binary files), and output formats. This makes verification of an AI-generated solution straightforward.\n*   **No GUI:** It is a command-line interface (CLI) tool, suitable for programmatic interaction and testing.\n*   **Appropriate Complexity:** The task involves file system traversal, argument parsing (using `click`), conditional logic for options, different output formatting (plain, XML, Markdown), and handling `.gitignore` rules. This is non-trivial but manageable, fitting the 'Medium' difficulty level for an AI to replicate.\n*   **Well-Understood Domain:** File processing and CLI tool creation are common programming tasks.\n*   **Code-Based:** The core task is generating Python code for the CLI tool.\n\nNegative Aspects:\n*   The implementation of `.gitignore` parsing logic, while a standard requirement for such tools, adds a layer of complexity compared to basic file concatenation. However, it's a well-defined sub-problem and doesn't require external services.\n\nOverall Assessment:\nThis project is an excellent candidate for a 'build from scratch' benchmark. It is self-contained, clearly specified, testable, and has a suitable (Medium) level of complexity for evaluating an AI assistant's ability to build a realistic CLI utility.",
            "llm_project_type": "CLI utility for file system processing and content aggregation",
            "llm_rating": 90,
            "llm_difficulty": "Medium"
        },
        "tests": {
            "repo_name": "simonw_files-to-prompt",
            "finish_test": true,
            "test_case_result": {
                "tests/test_files_to_prompt.py::test_basic_functionality": "passed",
                "tests/test_files_to_prompt.py::test_include_hidden": "passed",
                "tests/test_files_to_prompt.py::test_ignore_gitignore": "passed",
                "tests/test_files_to_prompt.py::test_multiple_paths": "passed",
                "tests/test_files_to_prompt.py::test_ignore_patterns": "passed",
                "tests/test_files_to_prompt.py::test_specific_extensions": "passed",
                "tests/test_files_to_prompt.py::test_mixed_paths_with_options": "passed",
                "tests/test_files_to_prompt.py::test_binary_file_warning": "passed",
                "tests/test_files_to_prompt.py::test_xml_format_dir[args0]": "passed",
                "tests/test_files_to_prompt.py::test_xml_format_dir[args1]": "passed",
                "tests/test_files_to_prompt.py::test_output_option[-o]": "passed",
                "tests/test_files_to_prompt.py::test_output_option[--output]": "passed",
                "tests/test_files_to_prompt.py::test_line_numbers": "passed",
                "tests/test_files_to_prompt.py::test_reading_paths_from_stdin[test_dir1/file1.txt\\ntest_dir2/file2.txt-extra_args0]": "passed",
                "tests/test_files_to_prompt.py::test_reading_paths_from_stdin[test_dir1/file1.txt\\ntest_dir2/file2.txt-extra_args1]": "passed",
                "tests/test_files_to_prompt.py::test_reading_paths_from_stdin[test_dir1/file1.txt\\x00test_dir2/file2.txt-extra_args2]": "passed",
                "tests/test_files_to_prompt.py::test_reading_paths_from_stdin[test_dir1/file1.txt\\x00test_dir2/file2.txt-extra_args3]": "passed",
                "tests/test_files_to_prompt.py::test_paths_from_arguments_and_stdin": "passed",
                "tests/test_files_to_prompt.py::test_markdown[-m]": "passed",
                "tests/test_files_to_prompt.py::test_markdown[--markdown]": "passed"
            },
            "success_count": 20,
            "failed_count": 0,
            "error_count": 0,
            "skipped_count": 0,
            "unknown_count": 0,
            "total_count": 20,
            "success_rate": 1.0,
            "coverage_report": {
                "covered_lines": 125,
                "num_statements": 136,
                "percent_covered": 90.20618556701031,
                "percent_covered_display": "90",
                "missing_lines": 11,
                "excluded_lines": 0,
                "num_branches": 58,
                "num_partial_branches": 6,
                "covered_branches": 50,
                "missing_branches": 8
            },
            "coverage_result": {}
        },
        "codelines_count": 779,
        "codefiles_count": 4,
        "code_length": 26266,
        "test_files_count": 1,
        "test_code_length": 16707,
        "class_diagram": "@startuml\n@enduml",
        "structure": [
            {
                "file": "tests/test_files_to_prompt.py",
                "functions": [
                    {
                        "name": "filenames_from_cxml",
                        "docstring": "Return set of filenames from <source>...</source> tags",
                        "comments": null,
                        "args": [
                            "cxml_string"
                        ]
                    },
                    {
                        "name": "test_basic_functionality",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "tmpdir"
                        ]
                    },
                    {
                        "name": "test_include_hidden",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "tmpdir"
                        ]
                    },
                    {
                        "name": "test_ignore_gitignore",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "tmpdir"
                        ]
                    },
                    {
                        "name": "test_multiple_paths",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "tmpdir"
                        ]
                    },
                    {
                        "name": "test_ignore_patterns",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "tmpdir"
                        ]
                    },
                    {
                        "name": "test_specific_extensions",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "tmpdir"
                        ]
                    },
                    {
                        "name": "test_mixed_paths_with_options",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "tmpdir"
                        ]
                    },
                    {
                        "name": "test_binary_file_warning",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "tmpdir"
                        ]
                    },
                    {
                        "name": "test_xml_format_dir",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "tmpdir",
                            "args"
                        ]
                    },
                    {
                        "name": "test_output_option",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "tmpdir",
                            "arg"
                        ]
                    },
                    {
                        "name": "test_line_numbers",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "tmpdir"
                        ]
                    },
                    {
                        "name": "test_reading_paths_from_stdin",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "tmpdir",
                            "input",
                            "extra_args"
                        ]
                    },
                    {
                        "name": "test_paths_from_arguments_and_stdin",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "tmpdir"
                        ]
                    },
                    {
                        "name": "test_markdown",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "tmpdir",
                            "option"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "files_to_prompt/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "files_to_prompt/__main__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "files_to_prompt/cli.py",
                "functions": [
                    {
                        "name": "should_ignore",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "path",
                            "gitignore_rules"
                        ]
                    },
                    {
                        "name": "read_gitignore",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "path"
                        ]
                    },
                    {
                        "name": "add_line_numbers",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "content"
                        ]
                    },
                    {
                        "name": "print_path",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "writer",
                            "path",
                            "content",
                            "cxml",
                            "markdown",
                            "line_numbers"
                        ]
                    },
                    {
                        "name": "print_default",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "writer",
                            "path",
                            "content",
                            "line_numbers"
                        ]
                    },
                    {
                        "name": "print_as_xml",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "writer",
                            "path",
                            "content",
                            "line_numbers"
                        ]
                    },
                    {
                        "name": "print_as_markdown",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "writer",
                            "path",
                            "content",
                            "line_numbers"
                        ]
                    },
                    {
                        "name": "process_path",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "path",
                            "extensions",
                            "include_hidden",
                            "ignore_files_only",
                            "ignore_gitignore",
                            "gitignore_rules",
                            "ignore_patterns",
                            "writer",
                            "claude_xml",
                            "markdown",
                            "line_numbers"
                        ]
                    },
                    {
                        "name": "read_paths_from_stdin",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "use_null_separator"
                        ]
                    },
                    {
                        "name": "cli",
                        "docstring": "Takes one or more paths to files or directories and outputs every file,\nrecursively, each one preceded with its filename like this:\n\n\b\n    path/to/file.py\n    ----\n    Contents of file.py goes here\n    ---\n    path/to/file2.py\n    ---\n    ...\n\nIf the `--cxml` flag is provided, the output will be structured as follows:\n\n\b\n    <documents>\n    <document path=\"path/to/file1.txt\">\n    Contents of file1.txt\n    </document>\n    <document path=\"path/to/file2.txt\">\n    Contents of file2.txt\n    </document>\n    ...\n    </documents>\n\nIf the `--markdown` flag is provided, the output will be structured as follows:\n\n\b\n    path/to/file1.py\n    ```python\n    Contents of file1.py\n    ```",
                        "comments": null,
                        "args": [
                            "paths",
                            "extensions",
                            "include_hidden",
                            "ignore_files_only",
                            "ignore_gitignore",
                            "ignore_patterns",
                            "output_file",
                            "claude_xml",
                            "markdown",
                            "line_numbers",
                            "null"
                        ]
                    }
                ],
                "classes": []
            }
        ],
        "test_cases": {
            "tests/test_files_to_prompt.py::test_basic_functionality": {
                "testid": "tests/test_files_to_prompt.py::test_basic_functionality",
                "result": "passed",
                "test_implementation": "def test_basic_functionality(tmpdir):\n    runner = CliRunner()\n    with tmpdir.as_cwd():\n        os.makedirs(\"test_dir\")\n        with open(\"test_dir/file1.txt\", \"w\") as f:\n            f.write(\"Contents of file1\")\n        with open(\"test_dir/file2.txt\", \"w\") as f:\n            f.write(\"Contents of file2\")\n\n        result = runner.invoke(cli, [\"test_dir\"])\n        assert result.exit_code == 0\n        assert \"test_dir/file1.txt\" in result.output\n        assert \"Contents of file1\" in result.output\n        assert \"test_dir/file2.txt\" in result.output\n        assert \"Contents of file2\" in result.output"
            },
            "tests/test_files_to_prompt.py::test_include_hidden": {
                "testid": "tests/test_files_to_prompt.py::test_include_hidden",
                "result": "passed",
                "test_implementation": "def test_include_hidden(tmpdir):\n    runner = CliRunner()\n    with tmpdir.as_cwd():\n        os.makedirs(\"test_dir\")\n        with open(\"test_dir/.hidden.txt\", \"w\") as f:\n            f.write(\"Contents of hidden file\")\n\n        result = runner.invoke(cli, [\"test_dir\"])\n        assert result.exit_code == 0\n        assert \"test_dir/.hidden.txt\" not in result.output\n\n        result = runner.invoke(cli, [\"test_dir\", \"--include-hidden\"])\n        assert result.exit_code == 0\n        assert \"test_dir/.hidden.txt\" in result.output\n        assert \"Contents of hidden file\" in result.output"
            },
            "tests/test_files_to_prompt.py::test_ignore_gitignore": {
                "testid": "tests/test_files_to_prompt.py::test_ignore_gitignore",
                "result": "passed",
                "test_implementation": "def test_ignore_gitignore(tmpdir):\n    runner = CliRunner()\n    with tmpdir.as_cwd():\n        os.makedirs(\"test_dir\")\n        os.makedirs(\"test_dir/nested_include\")\n        os.makedirs(\"test_dir/nested_ignore\")\n        with open(\"test_dir/.gitignore\", \"w\") as f:\n            f.write(\"ignored.txt\")\n        with open(\"test_dir/ignored.txt\", \"w\") as f:\n            f.write(\"This file should be ignored\")\n        with open(\"test_dir/included.txt\", \"w\") as f:\n            f.write(\"This file should be included\")\n        with open(\"test_dir/nested_include/included2.txt\", \"w\") as f:\n            f.write(\"This nested file should be included\")\n        with open(\"test_dir/nested_ignore/.gitignore\", \"w\") as f:\n            f.write(\"nested_ignore.txt\")\n        with open(\"test_dir/nested_ignore/nested_ignore.txt\", \"w\") as f:\n            f.write(\"This nested file should not be included\")\n        with open(\"test_dir/nested_ignore/actually_include.txt\", \"w\") as f:\n            f.write(\"This nested file should actually be included\")\n\n        result = runner.invoke(cli, [\"test_dir\", \"-c\"])\n        assert result.exit_code == 0\n        filenames = filenames_from_cxml(result.output)\n\n        assert filenames == {\n            \"test_dir/included.txt\",\n            \"test_dir/nested_include/included2.txt\",\n            \"test_dir/nested_ignore/actually_include.txt\",\n        }\n\n        result2 = runner.invoke(cli, [\"test_dir\", \"-c\", \"--ignore-gitignore\"])\n        assert result2.exit_code == 0\n        filenames2 = filenames_from_cxml(result2.output)\n\n        assert filenames2 == {\n            \"test_dir/included.txt\",\n            \"test_dir/ignored.txt\",\n            \"test_dir/nested_include/included2.txt\",\n            \"test_dir/nested_ignore/nested_ignore.txt\",\n            \"test_dir/nested_ignore/actually_include.txt\",\n        }"
            },
            "tests/test_files_to_prompt.py::test_multiple_paths": {
                "testid": "tests/test_files_to_prompt.py::test_multiple_paths",
                "result": "passed",
                "test_implementation": "def test_multiple_paths(tmpdir):\n    runner = CliRunner()\n    with tmpdir.as_cwd():\n        os.makedirs(\"test_dir1\")\n        with open(\"test_dir1/file1.txt\", \"w\") as f:\n            f.write(\"Contents of file1\")\n        os.makedirs(\"test_dir2\")\n        with open(\"test_dir2/file2.txt\", \"w\") as f:\n            f.write(\"Contents of file2\")\n        with open(\"single_file.txt\", \"w\") as f:\n            f.write(\"Contents of single file\")\n\n        result = runner.invoke(cli, [\"test_dir1\", \"test_dir2\", \"single_file.txt\"])\n        assert result.exit_code == 0\n        assert \"test_dir1/file1.txt\" in result.output\n        assert \"Contents of file1\" in result.output\n        assert \"test_dir2/file2.txt\" in result.output\n        assert \"Contents of file2\" in result.output\n        assert \"single_file.txt\" in result.output\n        assert \"Contents of single file\" in result.output"
            },
            "tests/test_files_to_prompt.py::test_ignore_patterns": {
                "testid": "tests/test_files_to_prompt.py::test_ignore_patterns",
                "result": "passed",
                "test_implementation": "def test_ignore_patterns(tmpdir):\n    runner = CliRunner()\n    with tmpdir.as_cwd():\n        os.makedirs(\"test_dir\", exist_ok=True)\n        with open(\"test_dir/file_to_ignore.txt\", \"w\") as f:\n            f.write(\"This file should be ignored due to ignore patterns\")\n        with open(\"test_dir/file_to_include.txt\", \"w\") as f:\n            f.write(\"This file should be included\")\n\n        result = runner.invoke(cli, [\"test_dir\", \"--ignore\", \"*.txt\"])\n        assert result.exit_code == 0\n        assert \"test_dir/file_to_ignore.txt\" not in result.output\n        assert \"This file should be ignored due to ignore patterns\" not in result.output\n        assert \"test_dir/file_to_include.txt\" not in result.output\n\n        os.makedirs(\"test_dir/test_subdir\", exist_ok=True)\n        with open(\"test_dir/test_subdir/any_file.txt\", \"w\") as f:\n            f.write(\"This entire subdirectory should be ignored due to ignore patterns\")\n        result = runner.invoke(cli, [\"test_dir\", \"--ignore\", \"*subdir*\"])\n        assert result.exit_code == 0\n        assert \"test_dir/test_subdir/any_file.txt\" not in result.output\n        assert (\n            \"This entire subdirectory should be ignored due to ignore patterns\"\n            not in result.output\n        )\n        assert \"test_dir/file_to_include.txt\" in result.output\n        assert \"This file should be included\" in result.output\n        assert \"This file should be included\" in result.output\n\n        result = runner.invoke(\n            cli, [\"test_dir\", \"--ignore\", \"*subdir*\", \"--ignore-files-only\"]\n        )\n        assert result.exit_code == 0\n        assert \"test_dir/test_subdir/any_file.txt\" in result.output\n\n        result = runner.invoke(cli, [\"test_dir\", \"--ignore\", \"\"])"
            },
            "tests/test_files_to_prompt.py::test_specific_extensions": {
                "testid": "tests/test_files_to_prompt.py::test_specific_extensions",
                "result": "passed",
                "test_implementation": "def test_specific_extensions(tmpdir):\n    runner = CliRunner()\n    with tmpdir.as_cwd():\n        # Write one.txt one.py two/two.txt two/two.py three.md\n        os.makedirs(\"test_dir/two\")\n        with open(\"test_dir/one.txt\", \"w\") as f:\n            f.write(\"This is one.txt\")\n        with open(\"test_dir/one.py\", \"w\") as f:\n            f.write(\"This is one.py\")\n        with open(\"test_dir/two/two.txt\", \"w\") as f:\n            f.write(\"This is two/two.txt\")\n        with open(\"test_dir/two/two.py\", \"w\") as f:\n            f.write(\"This is two/two.py\")\n        with open(\"test_dir/three.md\", \"w\") as f:\n            f.write(\"This is three.md\")\n\n        # Try with -e py -e md\n        result = runner.invoke(cli, [\"test_dir\", \"-e\", \"py\", \"-e\", \"md\"])\n        assert result.exit_code == 0\n        assert \".txt\" not in result.output\n        assert \"test_dir/one.py\" in result.output\n        assert \"test_dir/two/two.py\" in result.output\n        assert \"test_dir/three.md\" in result.output"
            },
            "tests/test_files_to_prompt.py::test_mixed_paths_with_options": {
                "testid": "tests/test_files_to_prompt.py::test_mixed_paths_with_options",
                "result": "passed",
                "test_implementation": "def test_mixed_paths_with_options(tmpdir):\n    runner = CliRunner()\n    with tmpdir.as_cwd():\n        os.makedirs(\"test_dir\")\n        with open(\"test_dir/.gitignore\", \"w\") as f:\n            f.write(\"ignored_in_gitignore.txt\\n.hidden_ignored_in_gitignore.txt\")\n        with open(\"test_dir/ignored_in_gitignore.txt\", \"w\") as f:\n            f.write(\"This file should be ignored by .gitignore\")\n        with open(\"test_dir/.hidden_ignored_in_gitignore.txt\", \"w\") as f:\n            f.write(\"This hidden file should be ignored by .gitignore\")\n        with open(\"test_dir/included.txt\", \"w\") as f:\n            f.write(\"This file should be included\")\n        with open(\"test_dir/.hidden_included.txt\", \"w\") as f:\n            f.write(\"This hidden file should be included\")\n        with open(\"single_file.txt\", \"w\") as f:\n            f.write(\"Contents of single file\")\n\n        result = runner.invoke(cli, [\"test_dir\", \"single_file.txt\"])\n        assert result.exit_code == 0\n        assert \"test_dir/ignored_in_gitignore.txt\" not in result.output\n        assert \"test_dir/.hidden_ignored_in_gitignore.txt\" not in result.output\n        assert \"test_dir/included.txt\" in result.output\n        assert \"test_dir/.hidden_included.txt\" not in result.output\n        assert \"single_file.txt\" in result.output\n        assert \"Contents of single file\" in result.output\n\n        result = runner.invoke(cli, [\"test_dir\", \"single_file.txt\", \"--include-hidden\"])\n        assert result.exit_code == 0\n        assert \"test_dir/ignored_in_gitignore.txt\" not in result.output\n        assert \"test_dir/.hidden_ignored_in_gitignore.txt\" not in result.output\n        assert \"test_dir/included.txt\" in result.output\n        assert \"test_dir/.hidden_included.txt\" in result.output\n        assert \"single_file.txt\" in result.output\n        assert \"Contents of single file\" in result.output\n\n        result = runner.invoke(\n            cli, [\"test_dir\", \"single_file.txt\", \"--ignore-gitignore\"]\n        )\n        assert result.exit_code == 0\n        assert \"test_dir/ignored_in_gitignore.txt\" in result.output\n        assert \"test_dir/.hidden_ignored_in_gitignore.txt\" not in result.output\n        assert \"test_dir/included.txt\" in result.output\n        assert \"test_dir/.hidden_included.txt\" not in result.output\n        assert \"single_file.txt\" in result.output\n        assert \"Contents of single file\" in result.output\n\n        result = runner.invoke(\n            cli,\n            [\"test_dir\", \"single_file.txt\", \"--ignore-gitignore\", \"--include-hidden\"],\n        )\n        assert result.exit_code == 0\n        assert \"test_dir/ignored_in_gitignore.txt\" in result.output\n        assert \"test_dir/.hidden_ignored_in_gitignore.txt\" in result.output\n        assert \"test_dir/included.txt\" in result.output\n        assert \"test_dir/.hidden_included.txt\" in result.output\n        assert \"single_file.txt\" in result.output\n        assert \"Contents of single file\" in result.output"
            },
            "tests/test_files_to_prompt.py::test_binary_file_warning": {
                "testid": "tests/test_files_to_prompt.py::test_binary_file_warning",
                "result": "passed",
                "test_implementation": "def test_binary_file_warning(tmpdir):\n    runner = CliRunner(mix_stderr=False)\n    with tmpdir.as_cwd():\n        os.makedirs(\"test_dir\")\n        with open(\"test_dir/binary_file.bin\", \"wb\") as f:\n            f.write(b\"\\xff\")\n        with open(\"test_dir/text_file.txt\", \"w\") as f:\n            f.write(\"This is a text file\")\n\n        result = runner.invoke(cli, [\"test_dir\"])\n        assert result.exit_code == 0\n\n        stdout = result.stdout\n        stderr = result.stderr\n\n        assert \"test_dir/text_file.txt\" in stdout\n        assert \"This is a text file\" in stdout\n        assert \"\\ntest_dir/binary_file.bin\" not in stdout\n        assert (\n            \"Warning: Skipping file test_dir/binary_file.bin due to UnicodeDecodeError\"\n            in stderr\n        )"
            },
            "tests/test_files_to_prompt.py::test_xml_format_dir[args0]": {
                "testid": "tests/test_files_to_prompt.py::test_xml_format_dir[args0]",
                "result": "passed",
                "test_implementation": "def test_xml_format_dir(tmpdir, args):\n    runner = CliRunner()\n    with tmpdir.as_cwd():\n        os.makedirs(\"test_dir\")\n        with open(\"test_dir/file1.txt\", \"w\") as f:\n            f.write(\"Contents of file1.txt\")\n        with open(\"test_dir/file2.txt\", \"w\") as f:\n            f.write(\"Contents of file2.txt\")\n        result = runner.invoke(cli, args + [\"--cxml\"])\n        assert result.exit_code == 0\n        actual = result.output\n        expected = \"\"\"\n<documents>\n<document index=\"1\">\n<source>test_dir/file1.txt</source>\n<document_content>\nContents of file1.txt\n</document_content>\n</document>\n<document index=\"2\">\n<source>test_dir/file2.txt</source>\n<document_content>\nContents of file2.txt\n</document_content>\n</document>\n</documents>\n\"\"\"\n        assert expected.strip() == actual.strip()"
            },
            "tests/test_files_to_prompt.py::test_xml_format_dir[args1]": {
                "testid": "tests/test_files_to_prompt.py::test_xml_format_dir[args1]",
                "result": "passed",
                "test_implementation": "def test_xml_format_dir(tmpdir, args):\n    runner = CliRunner()\n    with tmpdir.as_cwd():\n        os.makedirs(\"test_dir\")\n        with open(\"test_dir/file1.txt\", \"w\") as f:\n            f.write(\"Contents of file1.txt\")\n        with open(\"test_dir/file2.txt\", \"w\") as f:\n            f.write(\"Contents of file2.txt\")\n        result = runner.invoke(cli, args + [\"--cxml\"])\n        assert result.exit_code == 0\n        actual = result.output\n        expected = \"\"\"\n<documents>\n<document index=\"1\">\n<source>test_dir/file1.txt</source>\n<document_content>\nContents of file1.txt\n</document_content>\n</document>\n<document index=\"2\">\n<source>test_dir/file2.txt</source>\n<document_content>\nContents of file2.txt\n</document_content>\n</document>\n</documents>\n\"\"\"\n        assert expected.strip() == actual.strip()"
            },
            "tests/test_files_to_prompt.py::test_output_option[-o]": {
                "testid": "tests/test_files_to_prompt.py::test_output_option[-o]",
                "result": "passed",
                "test_implementation": "def test_output_option(tmpdir, arg):\n    runner = CliRunner()\n    with tmpdir.as_cwd():\n        os.makedirs(\"test_dir\")\n        with open(\"test_dir/file1.txt\", \"w\") as f:\n            f.write(\"Contents of file1.txt\")\n        with open(\"test_dir/file2.txt\", \"w\") as f:\n            f.write(\"Contents of file2.txt\")\n        output_file = \"output.txt\"\n        result = runner.invoke(\n            cli, [\"test_dir\", arg, output_file], catch_exceptions=False\n        )\n        assert result.exit_code == 0\n        assert not result.output\n        with open(output_file, \"r\") as f:\n            actual = f.read()\n        expected = \"\"\"\ntest_dir/file1.txt\n---\nContents of file1.txt\n\n---\ntest_dir/file2.txt\n---\nContents of file2.txt\n\n---\n\"\"\"\n        assert expected.strip() == actual.strip()"
            },
            "tests/test_files_to_prompt.py::test_output_option[--output]": {
                "testid": "tests/test_files_to_prompt.py::test_output_option[--output]",
                "result": "passed",
                "test_implementation": "def test_output_option(tmpdir, arg):\n    runner = CliRunner()\n    with tmpdir.as_cwd():\n        os.makedirs(\"test_dir\")\n        with open(\"test_dir/file1.txt\", \"w\") as f:\n            f.write(\"Contents of file1.txt\")\n        with open(\"test_dir/file2.txt\", \"w\") as f:\n            f.write(\"Contents of file2.txt\")\n        output_file = \"output.txt\"\n        result = runner.invoke(\n            cli, [\"test_dir\", arg, output_file], catch_exceptions=False\n        )\n        assert result.exit_code == 0\n        assert not result.output\n        with open(output_file, \"r\") as f:\n            actual = f.read()\n        expected = \"\"\"\ntest_dir/file1.txt\n---\nContents of file1.txt\n\n---\ntest_dir/file2.txt\n---\nContents of file2.txt\n\n---\n\"\"\"\n        assert expected.strip() == actual.strip()"
            },
            "tests/test_files_to_prompt.py::test_line_numbers": {
                "testid": "tests/test_files_to_prompt.py::test_line_numbers",
                "result": "passed",
                "test_implementation": "def test_line_numbers(tmpdir):\n    runner = CliRunner()\n    with tmpdir.as_cwd():\n        os.makedirs(\"test_dir\")\n        test_content = \"First line\\nSecond line\\nThird line\\nFourth line\\n\"\n        with open(\"test_dir/multiline.txt\", \"w\") as f:\n            f.write(test_content)\n\n        result = runner.invoke(cli, [\"test_dir\"])\n        assert result.exit_code == 0\n        assert \"1  First line\" not in result.output\n        assert test_content in result.output\n\n        result = runner.invoke(cli, [\"test_dir\", \"-n\"])\n        assert result.exit_code == 0\n        assert \"1  First line\" in result.output\n        assert \"2  Second line\" in result.output\n        assert \"3  Third line\" in result.output\n        assert \"4  Fourth line\" in result.output\n\n        result = runner.invoke(cli, [\"test_dir\", \"--line-numbers\"])\n        assert result.exit_code == 0\n        assert \"1  First line\" in result.output\n        assert \"2  Second line\" in result.output\n        assert \"3  Third line\" in result.output\n        assert \"4  Fourth line\" in result.output"
            },
            "tests/test_files_to_prompt.py::test_reading_paths_from_stdin[test_dir1/file1.txt\\ntest_dir2/file2.txt-extra_args0]": {
                "testid": "tests/test_files_to_prompt.py::test_reading_paths_from_stdin[test_dir1/file1.txt\\ntest_dir2/file2.txt-extra_args0]",
                "result": "passed",
                "test_implementation": "def test_reading_paths_from_stdin(tmpdir, input, extra_args):\n    runner = CliRunner()\n    with tmpdir.as_cwd():\n        # Create test files\n        os.makedirs(\"test_dir1\")\n        os.makedirs(\"test_dir2\")\n        with open(\"test_dir1/file1.txt\", \"w\") as f:\n            f.write(\"Contents of file1\")\n        with open(\"test_dir2/file2.txt\", \"w\") as f:\n            f.write(\"Contents of file2\")\n\n        # Test space-separated paths from stdin\n        result = runner.invoke(cli, args=extra_args, input=input)\n        assert result.exit_code == 0\n        assert \"test_dir1/file1.txt\" in result.output\n        assert \"Contents of file1\" in result.output\n        assert \"test_dir2/file2.txt\" in result.output\n        assert \"Contents of file2\" in result.output"
            },
            "tests/test_files_to_prompt.py::test_reading_paths_from_stdin[test_dir1/file1.txt\\ntest_dir2/file2.txt-extra_args1]": {
                "testid": "tests/test_files_to_prompt.py::test_reading_paths_from_stdin[test_dir1/file1.txt\\ntest_dir2/file2.txt-extra_args1]",
                "result": "passed",
                "test_implementation": "def test_reading_paths_from_stdin(tmpdir, input, extra_args):\n    runner = CliRunner()\n    with tmpdir.as_cwd():\n        # Create test files\n        os.makedirs(\"test_dir1\")\n        os.makedirs(\"test_dir2\")\n        with open(\"test_dir1/file1.txt\", \"w\") as f:\n            f.write(\"Contents of file1\")\n        with open(\"test_dir2/file2.txt\", \"w\") as f:\n            f.write(\"Contents of file2\")\n\n        # Test space-separated paths from stdin\n        result = runner.invoke(cli, args=extra_args, input=input)\n        assert result.exit_code == 0\n        assert \"test_dir1/file1.txt\" in result.output\n        assert \"Contents of file1\" in result.output\n        assert \"test_dir2/file2.txt\" in result.output\n        assert \"Contents of file2\" in result.output"
            },
            "tests/test_files_to_prompt.py::test_reading_paths_from_stdin[test_dir1/file1.txt\\x00test_dir2/file2.txt-extra_args2]": {
                "testid": "tests/test_files_to_prompt.py::test_reading_paths_from_stdin[test_dir1/file1.txt\\x00test_dir2/file2.txt-extra_args2]",
                "result": "passed",
                "test_implementation": "def test_reading_paths_from_stdin(tmpdir, input, extra_args):\n    runner = CliRunner()\n    with tmpdir.as_cwd():\n        # Create test files\n        os.makedirs(\"test_dir1\")\n        os.makedirs(\"test_dir2\")\n        with open(\"test_dir1/file1.txt\", \"w\") as f:\n            f.write(\"Contents of file1\")\n        with open(\"test_dir2/file2.txt\", \"w\") as f:\n            f.write(\"Contents of file2\")\n\n        # Test space-separated paths from stdin\n        result = runner.invoke(cli, args=extra_args, input=input)\n        assert result.exit_code == 0\n        assert \"test_dir1/file1.txt\" in result.output\n        assert \"Contents of file1\" in result.output\n        assert \"test_dir2/file2.txt\" in result.output\n        assert \"Contents of file2\" in result.output"
            },
            "tests/test_files_to_prompt.py::test_reading_paths_from_stdin[test_dir1/file1.txt\\x00test_dir2/file2.txt-extra_args3]": {
                "testid": "tests/test_files_to_prompt.py::test_reading_paths_from_stdin[test_dir1/file1.txt\\x00test_dir2/file2.txt-extra_args3]",
                "result": "passed",
                "test_implementation": "def test_reading_paths_from_stdin(tmpdir, input, extra_args):\n    runner = CliRunner()\n    with tmpdir.as_cwd():\n        # Create test files\n        os.makedirs(\"test_dir1\")\n        os.makedirs(\"test_dir2\")\n        with open(\"test_dir1/file1.txt\", \"w\") as f:\n            f.write(\"Contents of file1\")\n        with open(\"test_dir2/file2.txt\", \"w\") as f:\n            f.write(\"Contents of file2\")\n\n        # Test space-separated paths from stdin\n        result = runner.invoke(cli, args=extra_args, input=input)\n        assert result.exit_code == 0\n        assert \"test_dir1/file1.txt\" in result.output\n        assert \"Contents of file1\" in result.output\n        assert \"test_dir2/file2.txt\" in result.output\n        assert \"Contents of file2\" in result.output"
            },
            "tests/test_files_to_prompt.py::test_paths_from_arguments_and_stdin": {
                "testid": "tests/test_files_to_prompt.py::test_paths_from_arguments_and_stdin",
                "result": "passed",
                "test_implementation": "def test_paths_from_arguments_and_stdin(tmpdir):\n    runner = CliRunner()\n    with tmpdir.as_cwd():\n        # Create test files\n        os.makedirs(\"test_dir1\")\n        os.makedirs(\"test_dir2\")\n        with open(\"test_dir1/file1.txt\", \"w\") as f:\n            f.write(\"Contents of file1\")\n        with open(\"test_dir2/file2.txt\", \"w\") as f:\n            f.write(\"Contents of file2\")\n\n        # Test paths from arguments and stdin\n        result = runner.invoke(\n            cli,\n            args=[\"test_dir1\"],\n            input=\"test_dir2/file2.txt\",\n        )\n        assert result.exit_code == 0\n        assert \"test_dir1/file1.txt\" in result.output\n        assert \"Contents of file1\" in result.output\n        assert \"test_dir2/file2.txt\" in result.output\n        assert \"Contents of file2\" in result.output"
            },
            "tests/test_files_to_prompt.py::test_markdown[-m]": {
                "testid": "tests/test_files_to_prompt.py::test_markdown[-m]",
                "result": "passed",
                "test_implementation": "def test_markdown(tmpdir, option):\n    runner = CliRunner()\n    with tmpdir.as_cwd():\n        os.makedirs(\"test_dir\")\n        with open(\"test_dir/python.py\", \"w\") as f:\n            f.write(\"This is python\")\n        with open(\"test_dir/python_with_quad_backticks.py\", \"w\") as f:\n            f.write(\"This is python with ```` in it already\")\n        with open(\"test_dir/code.js\", \"w\") as f:\n            f.write(\"This is javascript\")\n        with open(\"test_dir/code.unknown\", \"w\") as f:\n            f.write(\"This is an unknown file type\")\n        result = runner.invoke(cli, [\"test_dir\", option])\n        assert result.exit_code == 0\n        actual = result.output\n        expected = (\n            \"test_dir/code.js\\n\"\n            \"```javascript\\n\"\n            \"This is javascript\\n\"\n            \"```\\n\"\n            \"test_dir/code.unknown\\n\"\n            \"```\\n\"\n            \"This is an unknown file type\\n\"\n            \"```\\n\"\n            \"test_dir/python.py\\n\"\n            \"```python\\n\"\n            \"This is python\\n\"\n            \"```\\n\"\n            \"test_dir/python_with_quad_backticks.py\\n\"\n            \"`````python\\n\"\n            \"This is python with ```` in it already\\n\"\n            \"`````\\n\"\n        )\n        assert expected.strip() == actual.strip()"
            },
            "tests/test_files_to_prompt.py::test_markdown[--markdown]": {
                "testid": "tests/test_files_to_prompt.py::test_markdown[--markdown]",
                "result": "passed",
                "test_implementation": "def test_markdown(tmpdir, option):\n    runner = CliRunner()\n    with tmpdir.as_cwd():\n        os.makedirs(\"test_dir\")\n        with open(\"test_dir/python.py\", \"w\") as f:\n            f.write(\"This is python\")\n        with open(\"test_dir/python_with_quad_backticks.py\", \"w\") as f:\n            f.write(\"This is python with ```` in it already\")\n        with open(\"test_dir/code.js\", \"w\") as f:\n            f.write(\"This is javascript\")\n        with open(\"test_dir/code.unknown\", \"w\") as f:\n            f.write(\"This is an unknown file type\")\n        result = runner.invoke(cli, [\"test_dir\", option])\n        assert result.exit_code == 0\n        actual = result.output\n        expected = (\n            \"test_dir/code.js\\n\"\n            \"```javascript\\n\"\n            \"This is javascript\\n\"\n            \"```\\n\"\n            \"test_dir/code.unknown\\n\"\n            \"```\\n\"\n            \"This is an unknown file type\\n\"\n            \"```\\n\"\n            \"test_dir/python.py\\n\"\n            \"```python\\n\"\n            \"This is python\\n\"\n            \"```\\n\"\n            \"test_dir/python_with_quad_backticks.py\\n\"\n            \"`````python\\n\"\n            \"This is python with ```` in it already\\n\"\n            \"`````\\n\"\n        )\n        assert expected.strip() == actual.strip()"
            }
        },
        "SRS_document": "**Software Requirements Specification: files-to-prompt**\n\n**Table of Contents:**\n1.  Introduction\n    1.1 Purpose\n    1.2 Scope\n    1.3 Definitions, Acronyms, and Abbreviations\n    1.4 References\n    1.5 Overview\n2.  Overall Description\n    2.1 Product Perspective\n    2.2 Product Functions Summary\n    2.3 User Characteristics\n    2.4 Constraints\n    2.5 Assumptions and Dependencies\n3.  Specific Requirements\n    3.1 Functional Requirements\n        3.1.1 Core Processing\n        3.1.2 Output Formatting\n        3.1.3 File and Directory Filtering/Ignoring\n        3.1.4 Input Handling\n        3.1.5 Command-Line Interface Operations\n        3.1.6 Error Handling and Warnings\n    3.2 Non-Functional Requirements\n    3.3 External Interface Requirements\n\n---\n\n## 1. Introduction\n\n### 1.1 Purpose\nThis Software Requirements Specification (SRS) document defines the requirements for the `files-to-prompt` command-line utility. Its primary purpose is to serve as a definitive guide for software developers who will be tasked with implementing this utility. Developers will use this SRS and a subset of original test cases to build the software, which will then be assessed against a complete set of original (including private) test cases. Therefore, this document emphasizes clarity, comprehensiveness of functionality, and appropriate abstraction of implementation details.\n\n### 1.2 Scope\nThe `files-to-prompt` utility is designed to concatenate the content of specified files and files within specified directories into a single text output. It provides various options for filtering files, handling hidden files, respecting `.gitignore` rules, and formatting the output (default, XML, Markdown). The utility can accept input paths as command-line arguments or from standard input.\n\n### 1.3 Definitions, Acronyms, and Abbreviations\n*   **SRS:** Software Requirements Specification\n*   **CLI:** Command Line Interface\n*   **LLM:** Large Language Model\n*   **XML:** Extensible Markup Language\n*   **fnmatch:** A type of pattern matching similar to that used in Unix shells.\n*   **NUL character:** The null character (ASCII 0), often used as a delimiter.\n*   **stdin:** Standard Input stream.\n*   **stdout:** Standard Output stream.\n*   **stderr:** Standard Error stream.\n*   **.gitignore:** A file used by the Git version control system to specify intentionally untracked files that Git should ignore.\n\n### 1.4 References\n*   Original README document for `files-to-prompt`.\n*   Original source code of `files-to-prompt`.\n*   Original test suite for `files-to-prompt`.\n\n### 1.5 Overview\nThis document is organized into three main sections:\n*   **Section 1 (Introduction):** Provides an overview of the SRS, including its purpose, scope, definitions, and references.\n*   **Section 2 (Overall Description):** Describes the general factors affecting the product and its requirements, such as product perspective, functions, user characteristics, constraints, and assumptions.\n*   **Section 3 (Specific Requirements):** Details all functional and non-functional requirements of the software. This section is critical for development and assessment.\n\n---\n\n## 2. Overall Description\n\n### 2.1 Product Perspective\nThe `files-to-prompt` software is a command-line utility that functions as a text aggregation tool. It operates independently and is invoked from a system's command-line shell. Its primary role is to prepare and consolidate textual content from various file system locations into a structured output, suitable for tasks like providing context to LLMs or general text processing.\n\n### 2.2 Product Functions Summary\nThe system shall provide the following key functionalities:\n*   Processing of one or more file and/or directory paths.\n*   Recursive traversal of directories to identify files.\n*   Concatenation of the content of identified text files.\n*   Multiple output formatting options: a default plain text format, an XML-based format, and a Markdown format.\n*   Filtering mechanisms to include/exclude files based on:\n    *   File extensions.\n    *   Hidden status of files and directories.\n    *   Rules defined in `.gitignore` files.\n    *   User-specified ignore patterns (using `fnmatch` syntax).\n*   Acceptance of input paths from command-line arguments and/or standard input.\n*   Optional line numbering for file content in the output.\n*   Capability to write the consolidated output to a specified file instead of standard output.\n*   Handling of non-text (binary) files by skipping them and issuing a warning.\n\n### 2.3 User Characteristics\nThe intended users of `files-to-prompt` are individuals comfortable working with command-line interfaces. This includes:\n*   Software developers.\n*   Data scientists.\n*   Researchers.\n*   Anyone needing to aggregate text from multiple files for LLMs or other purposes.\nUsers are expected to understand basic file system concepts (paths, directories, hidden files) and pattern matching (for ignore options).\n\n### 2.4 Constraints\n*   **C-1:** The system is designed primarily for processing text files. When encountering files it cannot decode as UTF-8 text (e.g., binary files), it should skip them rather than attempting to process their content.\n*   **C-2:** File and directory ignore patterns specified by the user must conform to `fnmatch` syntax.\n*   **C-3:** The system's behavior regarding `.gitignore` files should emulate the standard interpretation of such files (e.g., patterns apply to files and directories relative to the `.gitignore` file's location, later rules can override earlier ones, comments and blank lines are ignored).\n\n### 2.5 Assumptions and Dependencies\n*   **A-1:** The system assumes it operates in an environment with access to a file system.\n*   **A-2:** The system requires read permissions for the input files and directories it is instructed to process.\n*   **A-3:** If outputting to a file, the system requires write permissions for the specified output file path.\n*   **A-4:** The system relies on the underlying operating system for file I/O operations, path resolution, and directory traversal.\n\n---\n\n## 3. Specific Requirements\n\n### 3.1 Functional Requirements\n\n#### 3.1.1 Core Processing\n\n*   **FR-CORE-001:** The system shall be able to process one or more individual file paths provided as input.\n\n*   **FR-CORE-002:** The system shall be able to process one or more directory paths provided as input, recursively including files from subdirectories.\n\n*   **FR-CORE-003:** The system shall read the content of each processed text file and concatenate these contents into a single output stream or file.\n\n*   **FR-CORE-004:** The system shall process multiple top-level input paths (files or directories) in the order they are provided (command-line arguments first, then stdin paths, maintaining their respective internal order).\n\n*   **FR-CORE-005:** Files found within a single processed directory (at the same level) shall be processed and output in alphabetical order of their filenames.\n\n#### 3.1.2 Output Formatting\n\n*   **FR-OUT-001:** By default, the system shall format the output for each file as follows:\n    1.  The relative path to the file, followed by a newline.\n    2.  A separator line consisting of three hyphens (`---`), followed by a newline.\n    3.  The content of the file, followed by a newline.\n    4.  An empty line (a single newline character).\n    5.  A separator line consisting of three hyphens (`---`), followed by a newline.\n\n*   **FR-OUT-002:** If the Claude XML output option (`-c/--cxml`) is specified, the system shall format the entire output as a single XML structure:\n    1.  A root `<documents>` tag.\n    2.  For each processed file, a `<document>` tag.\n        *   This `<document>` tag must have an `index` attribute, starting at \"1\" for the first file and incrementing sequentially for each subsequent file within a single invocation of the tool.\n        *   Inside `<document>`, a `<source>` tag containing the relative path to the file.\n        *   Inside `<document>`, a `<document_content>` tag containing the file's content.\n    3.  A closing `</documents>` tag.\n\n*   **FR-OUT-003:** If the Markdown output option (`-m/--markdown`) is specified, the system shall format the output for each file as follows:\n    1.  The relative path to the file, followed by a newline.\n    2.  A Markdown fenced code block opening, e.g., ` ```language `.\n        *   The system shall attempt to determine the `language` identifier based on the file's extension (e.g., `.py` becomes `python`). If the extension is unknown, the language identifier shall be omitted (e.g., ` ``` `).\n        *   If the file's content itself contains the standard triple-backtick sequence (```), the system shall use a greater number of backticks for the enclosing fenced code block (e.g., ` ```` ` or ` ````` `) to ensure correct rendering.\n    3.  The content of the file, followed by a newline.\n    4.  A Markdown fenced code block closing, matching the number of backticks used in the opening.\n\n*   **FR-OUT-004:** If an output file path is specified (`-o/--output`), the system shall write all concatenated content to this file instead of standard output. If the output file option is used, there should be no output to standard output (excluding potential error messages to standard error).\n\n*   **FR-OUT-005:** If the line numbering option (`-n/--line-numbers`) is specified, the system shall prepend line numbers to each line of the file content in the output.\n    *   Line numbers shall start from 1 for each file.\n    *   Line numbers shall be right-aligned with padding according to the total number of lines in the current file (e.g., if a file has 99 lines, line 1 will be \" 1\"; if it has 100 lines, line 1 will be \"  1\").\n    *   Each line number shall be followed by two space characters and then the original line content.\n    *   This applies to default, XML, and Markdown output formats.\n\n#### 3.1.3 File and Directory Filtering/Ignoring\n\n*   **FR-FILTER-001:** The system shall allow users to specify one or more file extensions (`-e/--extension`). If specified, only files matching one of these extensions (case-sensitive, including the leading dot, e.g., `.txt`, `.py`) shall be processed.\n\n*   **FR-FILTER-002:** By default, the system shall exclude files and directories whose names begin with a dot (`.`) (hidden files/directories). If the `--include-hidden` option is specified, such files and directories shall be included in processing, subject to other filtering rules.\n\n*   **FR-FILTER-003:** By default, the system shall identify and respect rules defined in `.gitignore` files to exclude specified files and directories from processing.\n\n*   **FR-FILTER-004:** The system shall apply `.gitignore` rules from a `.gitignore` file located in a directory to all files and subdirectories within that directory. `.gitignore` files found in subdirectories can add to or override rules from parent directories for items within their respective subdirectory scopes.\n\n*   **FR-FILTER-005:** If the `--ignore-gitignore` option is specified, the system shall not read or apply any `.gitignore` rules, effectively processing all files that are not excluded by other filter options (like `--ignore` or `--extension`).\n\n*   **FR-FILTER-006:** The system shall allow users to specify one or more ignore patterns (`--ignore <pattern>`). These patterns use `fnmatch` syntax.\n    *   By default, if a directory name matches an ignore pattern, that directory and all its contents will be excluded.\n    *   If a file name matches an ignore pattern, that file will be excluded.\n\n*   **FR-FILTER-007:** If the `--ignore-files-only` option is specified in conjunction with `--ignore` patterns, the ignore patterns shall only be applied to file names, not directory names. Directories matching an ignore pattern will still be traversed.\n\n#### 3.1.4 Input Handling\n\n*   **FR-IN-001:** The system shall be able to read paths from standard input (stdin) if no paths are provided as command-line arguments or in addition to them. By default, paths read from stdin are expected to be separated by whitespace.\n\n*   **FR-IN-002:** If the NUL separator option (`-0` or `--null`) is specified, the system shall read paths from stdin separated by the NUL character. Empty path strings resulting from splitting by NUL should be ignored.\n\n*   **FR-IN-003:** The system shall process paths provided as command-line arguments before processing paths read from standard input.\n\n#### 3.1.5 Command-Line Interface Operations\n\n*   **FR-CLI-001:** The system shall provide a help message detailing its usage, options, and arguments when invoked with a help flag (e.g., `--help`).\n\n*   **FR-CLI-002:** The system shall display its version number when invoked with a version flag (e.g., `--version`).\n\n#### 3.1.6 Error Handling and Warnings\n\n*   **FR-ERR-001:** If the system encounters a file that cannot be decoded as UTF-8 text (e.g., a binary file or a file with unsupported encoding), it shall skip that file and print a warning message to standard error (stderr). The warning message should identify the path of the skipped file and the reason (UnicodeDecodeError). Processing of other files should continue.\n\n*   **FR-ERR-002:** If any input path specified as a command-line argument does not exist in the file system, the system shall report an error and terminate.\n\n### 3.2 Non-Functional Requirements\nNo non-functional requirements are specified, as per the instruction that NFRs must ONLY be included if they have a strictly corresponding, explicit original test case that directly validates them, and no such test cases were identified for typical NFR categories like performance, security, or specific usability metrics beyond CLI argument parsing (covered in Functional Requirements).\n\n### 3.3 External Interface Requirements\n*   **EI-001: Command-Line Interface:** The system shall provide a command-line interface as described by its options and arguments in section 3.1.\n*   **EI-002: File System Interaction:** The system shall interact with the local file system to read files and directories as specified by user input.\n*   **EI-003: Standard Streams:** The system shall use standard output (stdout) for its primary output by default, and standard error (stderr) for warning and error messages. It can read input paths from standard input (stdin).\n*   **EI-004: fnmatch Patterns:** User-provided ignore patterns (`--ignore`) must conform to the syntax supported by `fnmatch`. (This is also a constraint C-2).\n*   **EI-005: .gitignore File Format:** The system shall interpret `.gitignore` files according to common conventions (e.g., one pattern per line, `#` for comments, handling of leading/trailing slashes for directory/file matching).\n\n---\nEnd of SRS Document.",
        "structured_requirements": [
            {
                "requirement_id": "FR-CORE-001",
                "requirement_description": "The system shall be able to process one or more individual file paths provided as input.",
                "test_traceability": [
                    {
                        "id": "tests/test_files_to_prompt.py::test_basic_functionality",
                        "description": ""
                    },
                    {
                        "id": "tests/test_files_to_prompt.py::test_multiple_paths",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::process_path",
                        "description": "handles file case"
                    }
                ]
            },
            {
                "requirement_id": "FR-CORE-002",
                "requirement_description": "The system shall be able to process one or more directory paths provided as input, recursively including files from subdirectories.",
                "test_traceability": [
                    {
                        "id": "tests/test_files_to_prompt.py::test_basic_functionality",
                        "description": ""
                    },
                    {
                        "id": "tests/test_files_to_prompt.py::test_multiple_paths",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::process_path",
                        "description": "handles directory case using os.walk"
                    }
                ]
            },
            {
                "requirement_id": "FR-CORE-003",
                "requirement_description": "The system shall read the content of each processed text file and concatenate these contents into a single output stream or file.",
                "test_traceability": [
                    {
                        "id": "tests/test_files_to_prompt.py::test_basic_functionality",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::process_path",
                        "description": "file reading logic"
                    }
                ]
            },
            {
                "requirement_id": "FR-CORE-004",
                "requirement_description": "The system shall process multiple top-level input paths (files or directories) in the order they are provided (command-line arguments first, then stdin paths, maintaining their respective internal order).",
                "test_traceability": [
                    {
                        "id": "tests/test_files_to_prompt.py::test_multiple_paths",
                        "description": ""
                    },
                    {
                        "id": "tests/test_files_to_prompt.py::test_paths_from_arguments_and_stdin",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::cli",
                        "description": "iteration over `paths` list which combines args and stdin paths in order"
                    }
                ]
            },
            {
                "requirement_id": "FR-CORE-005",
                "requirement_description": "Files found within a single processed directory (at the same level) shall be processed and output in alphabetical order of their filenames.",
                "test_traceability": [
                    {
                        "id": "tests/test_files_to_prompt.py::test_basic_functionality",
                        "description": "implicitly, by checking output order consistency"
                    },
                    {
                        "id": "tests/test_files_to_prompt.py::test_markdown",
                        "description": "demonstrates sorted output"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::process_path",
                        "description": "use of `sorted(files)`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-OUT-001",
                "requirement_description": "By default, the system shall format the output for each file as follows:\n    1.  The relative path to the file, followed by a newline.\n    2.  A separator line consisting of three hyphens (`---`), followed by a newline.\n    3.  The content of the file, followed by a newline.\n    4.  An empty line (a single newline character).\n    5.  A separator line consisting of three hyphens (`---`), followed by a newline.",
                "test_traceability": [
                    {
                        "id": "tests/test_files_to_prompt.py::test_basic_functionality",
                        "description": ""
                    },
                    {
                        "id": "tests/test_files_to_prompt.py::test_output_option",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::print_default",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-OUT-002",
                "requirement_description": "If the Claude XML output option (`-c/--cxml`) is specified, the system shall format the entire output as a single XML structure:\n    1.  A root `<documents>` tag.\n    2.  For each processed file, a `<document>` tag.\n        *   This `<document>` tag must have an `index` attribute, starting at \"1\" for the first file and incrementing sequentially for each subsequent file within a single invocation of the tool.\n        *   Inside `<document>`, a `<source>` tag containing the relative path to the file.\n        *   Inside `<document>`, a `<document_content>` tag containing the file's content.\n    3.  A closing `</documents>` tag.",
                "test_traceability": [
                    {
                        "id": "tests/test_files_to_prompt.py::test_xml_format_dir",
                        "description": ""
                    },
                    {
                        "id": "tests/test_files_to_prompt.py::test_ignore_gitignore",
                        "description": "uses cxml for assertion"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::print_as_xml",
                        "description": ""
                    },
                    {
                        "id": "files_to_prompt/cli.py::cli",
                        "description": "handles global_index reset and wrapper tags"
                    }
                ]
            },
            {
                "requirement_id": "FR-OUT-003",
                "requirement_description": "If the Markdown output option (`-m/--markdown`) is specified, the system shall format the output for each file as follows:\n    1.  The relative path to the file, followed by a newline.\n    2.  A Markdown fenced code block opening, e.g., ` ```language `.\n        *   The system shall attempt to determine the `language` identifier based on the file's extension (e.g., `.py` becomes `python`). If the extension is unknown, the language identifier shall be omitted (e.g., ` ``` `).\n        *   If the file's content itself contains the standard triple-backtick sequence (```), the system shall use a greater number of backticks for the enclosing fenced code block (e.g., ` ```` ` or ` ````` `) to ensure correct rendering.\n    3.  The content of the file, followed by a newline.\n    4.  A Markdown fenced code block closing, matching the number of backticks used in the opening.",
                "test_traceability": [
                    {
                        "id": "tests/test_files_to_prompt.py::test_markdown",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::print_as_markdown",
                        "description": ""
                    },
                    {
                        "id": "files_to_prompt/cli.py::EXT_TO_LANG",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-OUT-004",
                "requirement_description": "If an output file path is specified (`-o/--output`), the system shall write all concatenated content to this file instead of standard output. If the output file option is used, there should be no output to standard output (excluding potential error messages to standard error).",
                "test_traceability": [
                    {
                        "id": "tests/test_files_to_prompt.py::test_output_option",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::cli",
                        "description": "output file handling"
                    }
                ]
            },
            {
                "requirement_id": "FR-OUT-005",
                "requirement_description": "If the line numbering option (`-n/--line-numbers`) is specified, the system shall prepend line numbers to each line of the file content in the output.\n    *   Line numbers shall start from 1 for each file.\n    *   Line numbers shall be right-aligned with padding according to the total number of lines in the current file (e.g., if a file has 99 lines, line 1 will be \" 1\"; if it has 100 lines, line 1 will be \"  1\").\n    *   Each line number shall be followed by two space characters and then the original line content.\n    *   This applies to default, XML, and Markdown output formats.",
                "test_traceability": [
                    {
                        "id": "tests/test_files_to_prompt.py::test_line_numbers",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::add_line_numbers",
                        "description": ""
                    },
                    {
                        "id": "files_to_prompt/cli.py::print_default",
                        "description": ""
                    },
                    {
                        "id": "files_to_prompt/cli.py::print_as_xml",
                        "description": ""
                    },
                    {
                        "id": "files_to_prompt/cli.py::print_as_markdown",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-FILTER-001",
                "requirement_description": "The system shall allow users to specify one or more file extensions (`-e/--extension`). If specified, only files matching one of these extensions (case-sensitive, including the leading dot, e.g., `.txt`, `.py`) shall be processed.",
                "test_traceability": [
                    {
                        "id": "tests/test_files_to_prompt.py::test_specific_extensions",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::process_path",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-FILTER-002",
                "requirement_description": "By default, the system shall exclude files and directories whose names begin with a dot (`.`) (hidden files/directories). If the `--include-hidden` option is specified, such files and directories shall be included in processing, subject to other filtering rules.",
                "test_traceability": [
                    {
                        "id": "tests/test_files_to_prompt.py::test_include_hidden",
                        "description": ""
                    },
                    {
                        "id": "tests/test_files_to_prompt.py::test_mixed_paths_with_options",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::process_path",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-FILTER-003",
                "requirement_description": "By default, the system shall identify and respect rules defined in `.gitignore` files to exclude specified files and directories from processing.",
                "test_traceability": [
                    {
                        "id": "tests/test_files_to_prompt.py::test_ignore_gitignore",
                        "description": ""
                    },
                    {
                        "id": "tests/test_files_to_prompt.py::test_mixed_paths_with_options",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::process_path",
                        "description": ""
                    },
                    {
                        "id": "files_to_prompt/cli.py::should_ignore",
                        "description": ""
                    },
                    {
                        "id": "files_to_prompt/cli.py::read_gitignore",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-FILTER-004",
                "requirement_description": "The system shall apply `.gitignore` rules from a `.gitignore` file located in a directory to all files and subdirectories within that directory. `.gitignore` files found in subdirectories can add to or override rules from parent directories for items within their respective subdirectory scopes.",
                "test_traceability": [
                    {
                        "id": "tests/test_files_to_prompt.py::test_ignore_gitignore",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::process_path",
                        "description": "reads gitignore for each `root`)"
                    },
                    {
                        "id": "files_to_prompt/cli.py::read_gitignore",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-FILTER-005",
                "requirement_description": "If the `--ignore-gitignore` option is specified, the system shall not read or apply any `.gitignore` rules, effectively processing all files that are not excluded by other filter options (like `--ignore` or `--extension`).",
                "test_traceability": [
                    {
                        "id": "tests/test_files_to_prompt.py::test_ignore_gitignore",
                        "description": ""
                    },
                    {
                        "id": "tests/test_files_to_prompt.py::test_mixed_paths_with_options",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::process_path",
                        "description": ""
                    },
                    {
                        "id": "files_to_prompt/cli.py::cli",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-FILTER-006",
                "requirement_description": "The system shall allow users to specify one or more ignore patterns (`--ignore <pattern>`). These patterns use `fnmatch` syntax.\n    *   By default, if a directory name matches an ignore pattern, that directory and all its contents will be excluded.\n    *   If a file name matches an ignore pattern, that file will be excluded.",
                "test_traceability": [
                    {
                        "id": "tests/test_files_to_prompt.py::test_ignore_patterns",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::process_path",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-FILTER-007",
                "requirement_description": "If the `--ignore-files-only` option is specified in conjunction with `--ignore` patterns, the ignore patterns shall only be applied to file names, not directory names. Directories matching an ignore pattern will still be traversed.",
                "test_traceability": [
                    {
                        "id": "tests/test_files_to_prompt.py::test_ignore_patterns",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::process_path",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-IN-001",
                "requirement_description": "The system shall be able to read paths from standard input (stdin) if no paths are provided as command-line arguments or in addition to them. By default, paths read from stdin are expected to be separated by whitespace.",
                "test_traceability": [
                    {
                        "id": "tests/test_files_to_prompt.py::test_reading_paths_from_stdin",
                        "description": "newline separation tested, which is whitespace"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::read_paths_from_stdin",
                        "description": ""
                    },
                    {
                        "id": "files_to_prompt/cli.py::cli",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-IN-002",
                "requirement_description": "If the NUL separator option (`-0` or `--null`) is specified, the system shall read paths from stdin separated by the NUL character. Empty path strings resulting from splitting by NUL should be ignored.",
                "test_traceability": [
                    {
                        "id": "tests/test_files_to_prompt.py::test_reading_paths_from_stdin",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::read_paths_from_stdin",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-IN-003",
                "requirement_description": "The system shall process paths provided as command-line arguments before processing paths read from standard input.",
                "test_traceability": [
                    {
                        "id": "tests/test_files_to_prompt.py::test_paths_from_arguments_and_stdin",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::cli",
                        "description": "order of `paths = [*paths, *stdin_paths]`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-001",
                "requirement_description": "The system shall provide a help message detailing its usage, options, and arguments when invoked with a help flag (e.g., `--help`).",
                "test_traceability": [
                    {
                        "id": "None",
                        "description": "Implicitly provided by Click framework, not directly tested in provided suite"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::cli",
                        "description": "inherent Click functionality"
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-002",
                "requirement_description": "The system shall display its version number when invoked with a version flag (e.g., `--version`).",
                "test_traceability": [
                    {
                        "id": "None",
                        "description": "Implicitly provided by Click framework, not directly tested in provided suite"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::cli",
                        "description": "due to `@click.version_option()`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-ERR-001",
                "requirement_description": "If the system encounters a file that cannot be decoded as UTF-8 text (e.g., a binary file or a file with unsupported encoding), it shall skip that file and print a warning message to standard error (stderr). The warning message should identify the path of the skipped file and the reason (UnicodeDecodeError). Processing of other files should continue.",
                "test_traceability": [
                    {
                        "id": "tests/test_files_to_prompt.py::test_binary_file_warning",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::process_path",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ERR-002",
                "requirement_description": "If any input path specified as a command-line argument does not exist in the file system, the system shall report an error and terminate.",
                "test_traceability": [
                    {
                        "id": "None",
                        "description": "Implicitly handled by `click.Path(exists=True)`, not directly tested for error message in provided suite, but invocation would fail"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "files_to_prompt/cli.py::cli",
                        "description": "parameter `paths` uses `type=click.Path(exists=True)`)"
                    }
                ]
            },
            {
                "requirement_id": "EI-001",
                "requirement_description": "Command-Line Interface: The system shall provide a command-line interface as described by its options and arguments in section 3.1.",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "EI-002",
                "requirement_description": "File System Interaction: The system shall interact with the local file system to read files and directories as specified by user input.",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "EI-003",
                "requirement_description": "Standard Streams: The system shall use standard output (stdout) for its primary output by default, and standard error (stderr) for warning and error messages. It can read input paths from standard input (stdin).",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "EI-004",
                "requirement_description": "fnmatch Patterns: User-provided ignore patterns (`--ignore`) must conform to the syntax supported by `fnmatch`. (This is also a constraint C-2).",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "EI-005",
                "requirement_description": ".gitignore File Format: The system shall interpret `.gitignore` files according to common conventions (e.g., one pattern per line, `#` for comments, handling of leading/trailing slashes for directory/file matching).",
                "test_traceability": [],
                "code_traceability": []
            }
        ],
        "commit_sha": "1b234ff6dccb2ca3e56b5c256696558fb85306dc",
        "full_code_skeleton": "--- File: files_to_prompt/cli.py ---\n```python\ndef should_ignore(path, gitignore_rules):\n    pass\n\ndef read_gitignore(path):\n    pass\n\ndef add_line_numbers(content):\n    pass\n\ndef print_path(writer, path, content, cxml, markdown, line_numbers):\n    pass\n\ndef print_default(writer, path, content, line_numbers):\n    pass\n\ndef print_as_xml(writer, path, content, line_numbers):\n    pass\n\ndef print_as_markdown(writer, path, content, line_numbers):\n    pass\n\ndef process_path(\n    path,\n    extensions,\n    include_hidden,\n    ignore_files_only,\n    ignore_gitignore,\n    gitignore_rules,\n    ignore_patterns,\n    writer,\n    claude_xml,\n    markdown,\n    line_numbers=False,\n):\n    pass\n\ndef read_paths_from_stdin(use_null_separator):\n    pass\n\n@click.command()\n@click.argument(\"paths\", nargs=-1, type=click.Path(exists=True))\n@click.option(\"extensions\", \"-e\", \"--extension\", multiple=True)\n@click.option(\n    \"--include-hidden\",\n    is_flag=True,\n    help=\"Include files and folders starting with .\",\n)\n@click.option(\n    \"--ignore-files-only\",\n    is_flag=True,\n    help=\"--ignore option only ignores files\",\n)\n@click.option(\n    \"--ignore-gitignore\",\n    is_flag=True,\n    help=\"Ignore .gitignore files and include all files\",\n)\n@click.option(\n    \"ignore_patterns\",\n    \"--ignore\",\n    multiple=True,\n    default=[],\n    help=\"List of patterns to ignore\",\n)\n@click.option(\n    \"output_file\",\n    \"-o\",\n    \"--output\",\n    type=click.Path(writable=True),\n    help=\"Output to a file instead of stdout\",\n)\n@click.option(\n    \"claude_xml\",\n    \"-c\",\n    \"--cxml\",\n    is_flag=True,\n    help=\"Output in XML-ish format suitable for Claude's long context window.\",\n)\n@click.option(\n    \"markdown\",\n    \"-m\",\n    \"--markdown\",\n    is_flag=True,\n    help=\"Output Markdown with fenced code blocks\",\n)\n@click.option(\n    \"line_numbers\",\n    \"-n\",\n    \"--line-numbers\",\n    is_flag=True,\n    help=\"Add line numbers to the output\",\n)\n@click.option(\n    \"--null\",\n    \"-0\",\n    is_flag=True,\n    help=\"Use NUL character as separator when reading from stdin\",\n)\n@click.version_option()\ndef cli(\n    paths,\n    extensions,\n    include_hidden,\n    ignore_files_only,\n    ignore_gitignore,\n    ignore_patterns,\n    output_file,\n    claude_xml,\n    markdown,\n    line_numbers,\n    null,\n):\n    \"\"\"\n    Takes one or more paths to files or directories and outputs every file,\n    recursively, each one preceded with its filename like this:\n\n    \\b\n        path/to/file.py\n        ----\n        Contents of file.py goes here\n        ---\n        path/to/file2.py\n        ---\n        ...\n\n    If the `--cxml` flag is provided, the output will be structured as follows:\n\n    \\b\n        <documents>\n        <document path=\"path/to/file1.txt\">\n        Contents of file1.txt\n        </document>\n        <document path=\"path/to/file2.txt\">\n        Contents of file2.txt\n        </document>\n        ...\n        </documents>\n\n    If the `--markdown` flag is provided, the output will be structured as follows:\n\n    \\b\n        path/to/file1.py\n        Contents of file1.py\n    \"\"\"\n    pass\n```",
        "full_code_skeleton_structured": [
            {
                "file_path": "files_to_prompt/cli.py",
                "code": "def should_ignore(path, gitignore_rules):\n    pass\n\ndef read_gitignore(path):\n    pass\n\ndef add_line_numbers(content):\n    pass\n\ndef print_path(writer, path, content, cxml, markdown, line_numbers):\n    pass\n\ndef print_default(writer, path, content, line_numbers):\n    pass\n\ndef print_as_xml(writer, path, content, line_numbers):\n    pass\n\ndef print_as_markdown(writer, path, content, line_numbers):\n    pass\n\ndef process_path(\n    path,\n    extensions,\n    include_hidden,\n    ignore_files_only,\n    ignore_gitignore,\n    gitignore_rules,\n    ignore_patterns,\n    writer,\n    claude_xml,\n    markdown,\n    line_numbers=False,\n):\n    pass\n\ndef read_paths_from_stdin(use_null_separator):\n    pass\n\n@click.command()\n@click.argument(\"paths\", nargs=-1, type=click.Path(exists=True))\n@click.option(\"extensions\", \"-e\", \"--extension\", multiple=True)\n@click.option(\n    \"--include-hidden\",\n    is_flag=True,\n    help=\"Include files and folders starting with .\",\n)\n@click.option(\n    \"--ignore-files-only\",\n    is_flag=True,\n    help=\"--ignore option only ignores files\",\n)\n@click.option(\n    \"--ignore-gitignore\",\n    is_flag=True,\n    help=\"Ignore .gitignore files and include all files\",\n)\n@click.option(\n    \"ignore_patterns\",\n    \"--ignore\",\n    multiple=True,\n    default=[],\n    help=\"List of patterns to ignore\",\n)\n@click.option(\n    \"output_file\",\n    \"-o\",\n    \"--output\",\n    type=click.Path(writable=True),\n    help=\"Output to a file instead of stdout\",\n)\n@click.option(\n    \"claude_xml\",\n    \"-c\",\n    \"--cxml\",\n    is_flag=True,\n    help=\"Output in XML-ish format suitable for Claude's long context window.\",\n)\n@click.option(\n    \"markdown\",\n    \"-m\",\n    \"--markdown\",\n    is_flag=True,\n    help=\"Output Markdown with fenced code blocks\",\n)\n@click.option(\n    \"line_numbers\",\n    \"-n\",\n    \"--line-numbers\",\n    is_flag=True,\n    help=\"Add line numbers to the output\",\n)\n@click.option(\n    \"--null\",\n    \"-0\",\n    is_flag=True,\n    help=\"Use NUL character as separator when reading from stdin\",\n)\n@click.version_option()\ndef cli(\n    paths,\n    extensions,\n    include_hidden,\n    ignore_files_only,\n    ignore_gitignore,\n    ignore_patterns,\n    output_file,\n    claude_xml,\n    markdown,\n    line_numbers,\n    null,\n):\n    \"\"\"\n    Takes one or more paths to files or directories and outputs every file,\n    recursively, each one preceded with its filename like this:\n\n    \\b\n        path/to/file.py\n        ----\n        Contents of file.py goes here\n        ---\n        path/to/file2.py\n        ---\n        ...\n\n    If the `--cxml` flag is provided, the output will be structured as follows:\n\n    \\b\n        <documents>\n        <document path=\"path/to/file1.txt\">\n        Contents of file1.txt\n        </document>\n        <document path=\"path/to/file2.txt\">\n        Contents of file2.txt\n        </document>\n        ...\n        </documents>\n\n    If the `--markdown` flag is provided, the output will be structured as follows:\n\n    \\b\n        path/to/file1.py\n        Contents of file1.py\n    \"\"\"\n    pass\n"
            }
        ],
        "minimal_code_skeleton": "--- File: files_to_prompt/cli.py ---\n```python\n@click.command()\n@click.argument(\"paths\", nargs=-1, type=click.Path(exists=True))\n@click.option(\"extensions\", \"-e\", \"--extension\", multiple=True)\n@click.option(\n    \"--include-hidden\",\n    is_flag=True,\n    help=\"Include files and folders starting with .\",\n)\n@click.option(\n    \"--ignore-files-only\",\n    is_flag=True,\n    help=\"--ignore option only ignores files\",\n)\n@click.option(\n    \"--ignore-gitignore\",\n    is_flag=True,\n    help=\"Ignore .gitignore files and include all files\",\n)\n@click.option(\n    \"ignore_patterns\",\n    \"--ignore\",\n    multiple=True,\n    default=[],\n    help=\"List of patterns to ignore\",\n)\n@click.option(\n    \"output_file\",\n    \"-o\",\n    \"--output\",\n    type=click.Path(writable=True),\n    help=\"Output to a file instead of stdout\",\n)\n@click.option(\n    \"claude_xml\",\n    \"-c\",\n    \"--cxml\",\n    is_flag=True,\n    help=\"Output in XML-ish format suitable for Claude's long context window.\",\n)\n@click.option(\n    \"markdown\",\n    \"-m\",\n    \"--markdown\",\n    is_flag=True,\n    help=\"Output Markdown with fenced code blocks\",\n)\n@click.option(\n    \"line_numbers\",\n    \"-n\",\n    \"--line-numbers\",\n    is_flag=True,\n    help=\"Add line numbers to the output\",\n)\n@click.option(\n    \"--null\",\n    \"-0\",\n    is_flag=True,\n    help=\"Use NUL character as separator when reading from stdin\",\n)\n@click.version_option()\ndef cli(\n    paths,\n    extensions,\n    include_hidden,\n    ignore_files_only,\n    ignore_gitignore,\n    ignore_patterns,\n    output_file,\n    claude_xml,\n    markdown,\n    line_numbers,\n    null,\n):\n    \"\"\"\n    Takes one or more paths to files or directories and outputs every file,\n    recursively, each one preceded with its filename like this:\n\n    \\b\n        path/to/file.py\n        ----\n        Contents of file.py goes here\n        ---\n        path/to/file2.py\n        ---\n        ...\n\n    If the `--cxml` flag is provided, the output will be structured as follows:\n\n    \\b\n        <documents>\n        <document path=\"path/to/file1.txt\">\n        Contents of file1.txt\n        </document>\n        <document path=\"path/to/file2.txt\">\n        Contents of file2.txt\n        </document>\n        ...\n        </documents>\n\n    If the `--markdown` flag is provided, the output will be structured as follows:\n\n    \\b\n        path/to/file1.py\n        Contents of file1.py\n    \"\"\"\n    pass\n```",
        "minimal_code_skeleton_structured": [
            {
                "file_path": "files_to_prompt/cli.py",
                "code": "@click.command()\n@click.argument(\"paths\", nargs=-1, type=click.Path(exists=True))\n@click.option(\"extensions\", \"-e\", \"--extension\", multiple=True)\n@click.option(\n    \"--include-hidden\",\n    is_flag=True,\n    help=\"Include files and folders starting with .\",\n)\n@click.option(\n    \"--ignore-files-only\",\n    is_flag=True,\n    help=\"--ignore option only ignores files\",\n)\n@click.option(\n    \"--ignore-gitignore\",\n    is_flag=True,\n    help=\"Ignore .gitignore files and include all files\",\n)\n@click.option(\n    \"ignore_patterns\",\n    \"--ignore\",\n    multiple=True,\n    default=[],\n    help=\"List of patterns to ignore\",\n)\n@click.option(\n    \"output_file\",\n    \"-o\",\n    \"--output\",\n    type=click.Path(writable=True),\n    help=\"Output to a file instead of stdout\",\n)\n@click.option(\n    \"claude_xml\",\n    \"-c\",\n    \"--cxml\",\n    is_flag=True,\n    help=\"Output in XML-ish format suitable for Claude's long context window.\",\n)\n@click.option(\n    \"markdown\",\n    \"-m\",\n    \"--markdown\",\n    is_flag=True,\n    help=\"Output Markdown with fenced code blocks\",\n)\n@click.option(\n    \"line_numbers\",\n    \"-n\",\n    \"--line-numbers\",\n    is_flag=True,\n    help=\"Add line numbers to the output\",\n)\n@click.option(\n    \"--null\",\n    \"-0\",\n    is_flag=True,\n    help=\"Use NUL character as separator when reading from stdin\",\n)\n@click.version_option()\ndef cli(\n    paths,\n    extensions,\n    include_hidden,\n    ignore_files_only,\n    ignore_gitignore,\n    ignore_patterns,\n    output_file,\n    claude_xml,\n    markdown,\n    line_numbers,\n    null,\n):\n    \"\"\"\n    Takes one or more paths to files or directories and outputs every file,\n    recursively, each one preceded with its filename like this:\n\n    \\b\n        path/to/file.py\n        ----\n        Contents of file.py goes here\n        ---\n        path/to/file2.py\n        ---\n        ...\n\n    If the `--cxml` flag is provided, the output will be structured as follows:\n\n    \\b\n        <documents>\n        <document path=\"path/to/file1.txt\">\n        Contents of file1.txt\n        </document>\n        <document path=\"path/to/file2.txt\">\n        Contents of file2.txt\n        </document>\n        ...\n        </documents>\n\n    If the `--markdown` flag is provided, the output will be structured as follows:\n\n    \\b\n        path/to/file1.py\n        Contents of file1.py\n    \"\"\"\n    pass\n"
            }
        ],
        "minimal_test_cases": [
            {
                "test_id": "tests/test_files_to_prompt.py::test_basic_functionality",
                "covers": [
                    "files_to_prompt.cli.cli - basic operation with directory input, default format"
                ]
            },
            {
                "test_id": "tests/test_files_to_prompt.py::test_include_hidden",
                "covers": [
                    "files_to_prompt.cli.cli - --include-hidden option for hidden files/directories"
                ]
            },
            {
                "test_id": "tests/test_files_to_prompt.py::test_ignore_gitignore",
                "covers": [
                    "files_to_prompt.cli.cli - --ignore-gitignore option to bypass .gitignore files"
                ]
            },
            {
                "test_id": "tests/test_files_to_prompt.py::test_multiple_paths",
                "covers": [
                    "files_to_prompt.cli.cli - handling multiple path arguments (files and directories)"
                ]
            },
            {
                "test_id": "tests/test_files_to_prompt.py::test_ignore_patterns",
                "covers": [
                    "files_to_prompt.cli.cli - --ignore option for custom ignore patterns",
                    "files_to_prompt.cli.cli - --ignore-files-only option with --ignore"
                ]
            },
            {
                "test_id": "tests/test_files_to_prompt.py::test_specific_extensions",
                "covers": [
                    "files_to_prompt.cli.cli - -e/--extension option to filter by file extensions"
                ]
            },
            {
                "test_id": "tests/test_files_to_prompt.py::test_binary_file_warning",
                "covers": [
                    "files_to_prompt.cli.cli - handling of binary files (UnicodeDecodeError warning)"
                ]
            },
            {
                "test_id": "tests/test_files_to_prompt.py::test_xml_format_dir[args0]",
                "covers": [
                    "files_to_prompt.cli.cli - -c/--cxml option for XML-ish output format"
                ]
            },
            {
                "test_id": "tests/test_files_to_prompt.py::test_output_option[-o]",
                "covers": [
                    "files_to_prompt.cli.cli - -o/--output option to write to a file"
                ]
            },
            {
                "test_id": "tests/test_files_to_prompt.py::test_line_numbers",
                "covers": [
                    "files_to_prompt.cli.cli - -n/--line-numbers option to prepend line numbers"
                ]
            },
            {
                "test_id": "tests/test_files_to_prompt.py::test_reading_paths_from_stdin[test_dir1/file1.txt\\ntest_dir2/file2.txt-extra_args0]",
                "covers": [
                    "files_to_prompt.cli.cli - reading newline-separated paths from stdin"
                ]
            },
            {
                "test_id": "tests/test_files_to_prompt.py::test_reading_paths_from_stdin[test_dir1/file1.txt\\x00test_dir2/file2.txt-extra_args2]",
                "covers": [
                    "files_to_prompt.cli.cli - reading NUL-separated paths from stdin using --null"
                ]
            },
            {
                "test_id": "tests/test_files_to_prompt.py::test_paths_from_arguments_and_stdin",
                "covers": [
                    "files_to_prompt.cli.cli - combining paths from command-line arguments and stdin"
                ]
            },
            {
                "test_id": "tests/test_files_to_prompt.py::test_markdown[-m]",
                "covers": [
                    "files_to_prompt.cli.cli - -m/--markdown option for Markdown fenced code block output"
                ]
            }
        ]
    },
    {
        "idx": 4592,
        "repo_name": "pomponchik_emptylog",
        "url": "https://github.com/pomponchik/emptylog",
        "description": "Mimicking the logger protocol",
        "stars": 27,
        "forks": 0,
        "language": "python",
        "size": 154,
        "created_at": "2024-02-11T13:30:03+00:00",
        "updated_at": "2025-03-03T04:10:56+00:00",
        "pypi_info": {
            "name": "emptylog",
            "version": "0.0.9",
            "url": "https://files.pythonhosted.org/packages/af/e0/eb0a85ccd55ac8f101710d14c01ff853da850da890ec5098c1b4a0a60f71/emptylog-0.0.9.tar.gz"
        },
        "judge_info": {
            "language": "python",
            "is_good_project": false,
            "reason": "",
            "python_file_num": 18,
            "comment_ratio": 0.02392947103274559,
            "pyfile_content_length": 30374,
            "pyfile_code_lines": 794,
            "test_file_exist": true,
            "test_file_content_length": 19934,
            "pytest_framework": true,
            "test_case_num": 33,
            "metadata_path": [
                "pyproject.toml"
            ],
            "readme_content_length": 10688,
            "llm_reason": "The 'emptylog' project is a strong candidate for an AI 'Build from Scratch' benchmark.\n\n**Positive Aspects:**\n*   **Self-Contained & Independent:** The core library functionality (providing various logger implementations like `EmptyLogger`, `MemoryLogger`, `PrintingLogger`, and `LoggersGroup`) does not require an active internet connection, external APIs, or complex third-party services for its operation or testing. Dependencies for the library itself appear to be limited to the Python standard library. Testing the rebuilt library would use standard tools like `pytest`.\n*   **Clear & Well-Defined Functionality:** The README clearly explains the purpose and functionality of each component: the `LoggerProtocol`, the different logger types, and the logger summation feature. This provides a good basis for the AI's task specification.\n*   **Testable & Verifiable Output:** The project has a comprehensive suite of unit tests (as seen in `tests/`) that cover various aspects of the library. The `MemoryLogger` is specifically designed to facilitate testing of logging behavior. These existing tests can be adapted to verify the AI-rebuilt project.\n*   **No Graphical User Interface (GUI):** The project is a library, and its interaction is programmatic (API calls), not GUI-based.\n*   **Appropriate Complexity, Scope & Difficulty:** The project involves implementing several interconnected classes (`EmptyLogger`, `MemoryLogger`, `PrintingLogger`, `LoggersGroup`, `LoggerProtocol`, `AbstractLogger`, `LoggerCallData`, `LoggerAccumulatedData`), including features like operator overloading (`+` for logger summation) and protocol definitions. This is non-trivial and offers a meaningful challenge (rated 'Medium'), but it's not excessively complex. A human developer could likely replicate it in a few hours to a day. The codebase is modular and of a manageable size (around 9 core Python files in the `emptylog` package).\n*   **Well-Understood Problem Domain:** Logging, logger protocols, stubs, and in-memory versions for testing are common concepts in software development.\n*   **Predominantly Code-Based Solution:** The task for the AI would be to generate Python code for the classes and functions described.\n\n**Negative Aspects or Concerns:**\n*   **Timestamp in PrintingLogger:** The `PrintingLogger` includes a timestamp in its output, which introduces non-determinism. However, the existing tests demonstrate ways to handle this (e.g., by checking the format or using a custom callback). This detail would need to be clearly specified to the AI.\n*   **Operator Overloading and Group Logic:** The `__add__` and `__radd__` methods for logger summation, and the internal logic of `LoggersGroup` (how it stores and delegates to other loggers, including flattening), represent the more complex parts of the project. The AI would need to correctly implement this behavior based on the specification derived from the original project.\n*   **Type Hints and Protocols:** The project uses Python's `typing.Protocol`. The AI would need to be capable of understanding and generating code that uses these features correctly.\n\nOverall, the project is well-structured, has clear goals, is inherently self-contained for its core logic, and is very testable. The 'Medium' difficulty makes it a suitable and interesting benchmark task for an AI Code Assistant.",
            "llm_project_type": "Python utility library for enhanced and testable logging",
            "llm_rating": 80,
            "llm_difficulty": "Medium"
        },
        "tests": {
            "repo_name": "pomponchik_emptylog",
            "finish_test": true,
            "test_case_result": {
                "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger0-first_logger0]": "passed",
                "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger0-first_logger1]": "passed",
                "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger0-first_logger2]": "passed",
                "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger1-first_logger0]": "passed",
                "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger1-first_logger1]": "passed",
                "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger1-first_logger2]": "passed",
                "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger2-first_logger0]": "passed",
                "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger2-first_logger1]": "passed",
                "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger2-first_logger2]": "passed",
                "tests/test_abstract_logger.py::test_sum_of_inner_loggers[logging-first_logger0]": "passed",
                "tests/test_abstract_logger.py::test_sum_of_inner_loggers[logging-first_logger1]": "passed",
                "tests/test_abstract_logger.py::test_sum_of_inner_loggers[logging-first_logger2]": "passed",
                "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger4-first_logger0]": "passed",
                "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger4-first_logger1]": "passed",
                "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger4-first_logger2]": "passed",
                "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger5-first_logger0]": "passed",
                "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger5-first_logger1]": "passed",
                "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger5-first_logger2]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger0-logging]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger0-first_logger1]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger0-first_logger2]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger1-logging]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger1-first_logger1]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger1-first_logger2]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger2-logging]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger2-first_logger1]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger2-first_logger2]": "passed",
                "tests/test_abstract_logger.py::test_all_loggers_are_instances_of_abstract_logger[logger0]": "passed",
                "tests/test_abstract_logger.py::test_all_loggers_are_instances_of_abstract_logger[logger1]": "passed",
                "tests/test_abstract_logger.py::test_all_loggers_are_instances_of_abstract_logger[logger2]": "passed",
                "tests/test_abstract_logger.py::test_all_loggers_are_instances_of_abstract_logger[logger3]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[1-logger0]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[1-logger1]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[1-logger2]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[1-logger3]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[kek-logger0]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[kek-logger1]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[kek-logger2]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[kek-logger3]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[None-logger0]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[None-logger1]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[None-logger2]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[None-logger3]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[1-logger0]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[1-logger1]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[1-logger2]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[1-logger3]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[kek-logger0]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[kek-logger1]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[kek-logger2]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[kek-logger3]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[None-logger0]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[None-logger1]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[None-logger2]": "passed",
                "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[None-logger3]": "passed",
                "tests/test_abstract_logger.py::test_sum_of_three_loggers": "passed",
                "tests/test_accumulated_data.py::test_fill_accumulated_data_and_check_size": "passed",
                "tests/test_call_data.py::test_create_call_data_and_check_the_data": "passed",
                "tests/test_empty_logger.py::test_search_callable_attributes": "passed",
                "tests/test_empty_logger.py::test_repr_empty_logger": "passed",
                "tests/test_loggers_group.py::test_len_of_group": "passed",
                "tests/test_loggers_group.py::test_create_group_with_not_loggers[1-A logger group can only be created from loggers. You passed 1 (int).]": "passed",
                "tests/test_loggers_group.py::test_create_group_with_not_loggers[kek-A logger group can only be created from loggers. You passed 'kek' (str).]": "passed",
                "tests/test_loggers_group.py::test_create_group_with_not_loggers[None-A logger group can only be created from loggers. You passed None (NoneType).]": "passed",
                "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>0]": "passed",
                "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>1]": "passed",
                "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>2]": "passed",
                "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>3]": "passed",
                "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>4]": "passed",
                "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>5]": "passed",
                "tests/test_loggers_group.py::test_repr_loggers_group": "passed",
                "tests/test_loggers_group.py::test_empty_group_plus_empty_group": "passed",
                "tests/test_loggers_group.py::test_not_empty_group_plus_empty_group": "passed",
                "tests/test_loggers_group.py::test_empty_group_plus_not_empty_group": "passed",
                "tests/test_loggers_group.py::test_empty_group_plus_another_logger": "passed",
                "tests/test_loggers_group.py::test_another_logger_plus_empty_group": "passed",
                "tests/test_loggers_group.py::test_empty_group_plus_third_party_logger[third_party_logger0]": "passed",
                "tests/test_loggers_group.py::test_empty_group_plus_third_party_logger[logging]": "passed",
                "tests/test_loggers_group.py::test_empty_group_plus_third_party_logger[third_party_logger2]": "passed",
                "tests/test_loggers_group.py::test_third_party_logger_plus_empty_group[third_party_logger0]": "passed",
                "tests/test_loggers_group.py::test_third_party_logger_plus_empty_group[logging]": "passed",
                "tests/test_loggers_group.py::test_third_party_logger_plus_empty_group[third_party_logger2]": "passed",
                "tests/test_loggers_group.py::test_iteration_by_group[loggers0]": "passed",
                "tests/test_loggers_group.py::test_iteration_by_group[loggers1]": "passed",
                "tests/test_loggers_group.py::test_iteration_by_group[loggers2]": "passed",
                "tests/test_loggers_group.py::test_iteration_by_group[loggers3]": "passed",
                "tests/test_memory_logger.py::test_memory_logger_is_logger": "passed",
                "tests/test_memory_logger.py::test_memory_logger_is_working": "passed",
                "tests/test_memory_logger.py::test_repr_memory_logger": "passed",
                "tests/test_printing_logger.py::test_printing_logger_is_logger": "passed",
                "tests/test_printing_logger.py::test_check_simple_output[debug- | DEBUG     | kek]": "passed",
                "tests/test_printing_logger.py::test_check_simple_output[info- | INFO      | kek]": "passed",
                "tests/test_printing_logger.py::test_check_simple_output[warning- | WARNING   | kek]": "passed",
                "tests/test_printing_logger.py::test_check_simple_output[error- | ERROR     | kek]": "passed",
                "tests/test_printing_logger.py::test_check_simple_output[exception- | EXCEPTION | kek]": "passed",
                "tests/test_printing_logger.py::test_check_simple_output[critical- | CRITICAL  | kek]": "passed",
                "tests/test_printing_logger.py::test_check_simple_output[debug- * DEBUG     * kek]": "passed",
                "tests/test_printing_logger.py::test_check_simple_output[info- * INFO      * kek]": "passed",
                "tests/test_printing_logger.py::test_check_simple_output[warning- * WARNING   * kek]": "passed",
                "tests/test_printing_logger.py::test_check_simple_output[error- * ERROR     * kek]": "passed",
                "tests/test_printing_logger.py::test_check_simple_output[exception- * EXCEPTION * kek]": "passed",
                "tests/test_printing_logger.py::test_check_simple_output[critical- * CRITICAL  * kek]": "passed",
                "tests/test_printing_logger.py::test_forward_output[<lambda>- | DEBUG     | kek]": "passed",
                "tests/test_printing_logger.py::test_forward_output[<lambda>- | INFO      | kek]": "passed",
                "tests/test_printing_logger.py::test_forward_output[<lambda>- | WARNING   | kek]": "passed",
                "tests/test_printing_logger.py::test_forward_output[<lambda>- | ERROR     | kek]": "passed",
                "tests/test_printing_logger.py::test_forward_output[<lambda>- | EXCEPTION | kek]": "passed",
                "tests/test_printing_logger.py::test_forward_output[<lambda>- | CRITICAL  | kek]": "passed",
                "tests/test_printing_logger.py::test_multiple_lines[debug- | DEBUG     | kek]": "passed",
                "tests/test_printing_logger.py::test_multiple_lines[info- | INFO      | kek]": "passed",
                "tests/test_printing_logger.py::test_multiple_lines[warning- | WARNING   | kek]": "passed",
                "tests/test_printing_logger.py::test_multiple_lines[error- | ERROR     | kek]": "passed",
                "tests/test_printing_logger.py::test_multiple_lines[exception- | EXCEPTION | kek]": "passed",
                "tests/test_printing_logger.py::test_multiple_lines[critical- | CRITICAL  | kek]": "passed",
                "tests/test_printing_logger.py::test_repr_printing_logger": "passed",
                "tests/test_protocols.py::test_positive_examples_of_runtime_check": "passed",
                "tests/test_protocols.py::test_negative_examples_of_runtime_check": "passed",
                "tests/test_protocols.py::test_loguru_logger_is_logger": "passed"
            },
            "success_count": 118,
            "failed_count": 0,
            "error_count": 0,
            "skipped_count": 0,
            "unknown_count": 0,
            "total_count": 118,
            "success_rate": 1.0,
            "coverage_report": {
                "covered_lines": 134,
                "num_statements": 134,
                "percent_covered": 100.0,
                "percent_covered_display": "100",
                "missing_lines": 0,
                "excluded_lines": 5,
                "num_branches": 34,
                "num_partial_branches": 0,
                "covered_branches": 34,
                "missing_branches": 0
            },
            "coverage_result": {}
        },
        "codelines_count": 794,
        "codefiles_count": 18,
        "code_length": 30374,
        "test_files_count": 8,
        "test_code_length": 19934,
        "class_diagram": "@startuml\nclass LoggersGroup {\n    loggers: Tuple[LoggerProtocol, Unknown]\n    __init__(): Unknown\n    __repr__(): str\n    __len__(): int\n    __iter__(): GroupIterator\n    debug(message): Unknown\n    info(message): Unknown\n    warning(message): Unknown\n    error(message): Unknown\n    exception(message): Unknown\n    critical(message): Unknown\n    run_loggers(get_method, message): Unknown\n}\nclass AbstractLogger {\n    __repr__(): str\n    __add__(other): LoggersGroup\n    __radd__(other): LoggersGroup\n}\nclass LoggerProtocol {\n    debug(message): Unknown\n    info(message): Unknown\n    warning(message): Unknown\n    error(message): Unknown\n    exception(message): Unknown\n    critical(message): Unknown\n}\nclass LoggerMethodProtocol {\n    __call__(message): Unknown\n}\nclass MemoryLogger {\n    __init__(): Unknown\n    debug(message): Unknown\n    info(message): Unknown\n    warning(message): Unknown\n    error(message): Unknown\n    exception(message): Unknown\n    critical(message): Unknown\n}\nclass PrintingLogger {\n    __init__(printing_callback, separator): Unknown\n    debug(message): Unknown\n    info(message): Unknown\n    warning(message): Unknown\n    error(message): Unknown\n    exception(message): Unknown\n    critical(message): Unknown\n    create_line(level, message): str\n}\nclass LoggerAccumulatedData {\n    debug: List[LoggerCallData]\n    info: List[LoggerCallData]\n    warning: List[LoggerCallData]\n    error: List[LoggerCallData]\n    exception: List[LoggerCallData]\n    critical: List[LoggerCallData]\n    __len__(): int\n}\nclass LoggerCallData {\n    message: str\n    args: Tuple[Any, Unknown]\n    kwargs: Dict[str, Any]\n}\nclass EmptyLogger {\n}\nAbstractLogger --> LoggersGroup\nAbstractLogger --> LoggerProtocol\nMemoryLogger --> LoggerAccumulatedData\nAbstractLogger <|-- LoggersGroup\nAbstractLogger <|-- EmptyLogger\nAbstractLogger <|-- MemoryLogger\nLoggerProtocol <|-- AbstractLogger\nAbstractLogger <|-- PrintingLogger\nMemoryLogger ..> LoggerAccumulatedData\nAbstractLogger ..> LoggerProtocol\nAbstractLogger ..> LoggersGroup\n@enduml",
        "structure": [
            {
                "file": "tests/test_memory_logger.py",
                "functions": [
                    {
                        "name": "test_memory_logger_is_logger",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_memory_logger_is_working",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_repr_memory_logger",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_loggers_group.py",
                "functions": [
                    {
                        "name": "test_len_of_group",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_create_group_with_not_loggers",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "wrong_logger",
                            "exception_message"
                        ]
                    },
                    {
                        "name": "test_run_group_of_memory_loggers",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "get_method"
                        ]
                    },
                    {
                        "name": "test_repr_loggers_group",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_empty_group_plus_empty_group",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_not_empty_group_plus_empty_group",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_empty_group_plus_not_empty_group",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_empty_group_plus_another_logger",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_another_logger_plus_empty_group",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_empty_group_plus_third_party_logger",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "third_party_logger"
                        ]
                    },
                    {
                        "name": "test_third_party_logger_plus_empty_group",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "third_party_logger"
                        ]
                    },
                    {
                        "name": "test_iteration_by_group",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "loggers"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/test_empty_logger.py",
                "functions": [
                    {
                        "name": "test_search_callable_attributes",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_repr_empty_logger",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_protocols.py",
                "functions": [
                    {
                        "name": "test_positive_examples_of_runtime_check",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_negative_examples_of_runtime_check",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_loguru_logger_is_logger",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_abstract_logger.py",
                "functions": [
                    {
                        "name": "test_sum_of_inner_loggers",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "first_logger",
                            "second_logger"
                        ]
                    },
                    {
                        "name": "test_sum_with_another_loggers_as_first_operand",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "first_logger",
                            "second_logger"
                        ]
                    },
                    {
                        "name": "test_all_loggers_are_instances_of_abstract_logger",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "logger"
                        ]
                    },
                    {
                        "name": "test_sum_with_wrong_first_operand",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "logger",
                            "wrong_operand"
                        ]
                    },
                    {
                        "name": "test_sum_with_wrong_second_operand",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "logger",
                            "wrong_operand"
                        ]
                    },
                    {
                        "name": "test_sum_of_three_loggers",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_printing_logger.py",
                "functions": [
                    {
                        "name": "test_printing_logger_is_logger",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_check_simple_output",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "method",
                            "result_tail"
                        ]
                    },
                    {
                        "name": "test_forward_output",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "get_method",
                            "result_tail"
                        ]
                    },
                    {
                        "name": "test_multiple_lines",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "method",
                            "result_tail"
                        ]
                    },
                    {
                        "name": "test_repr_printing_logger",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_call_data.py",
                "functions": [
                    {
                        "name": "test_create_call_data_and_check_the_data",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_accumulated_data.py",
                "functions": [
                    {
                        "name": "test_fill_accumulated_data_and_check_size",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "emptylog/loggers_group.py",
                "functions": [],
                "classes": [
                    {
                        "name": "LoggersGroup",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__repr__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__len__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__iter__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "debug",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "info",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "warning",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "error",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "exception",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "critical",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "run_loggers",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "get_method",
                                    "message"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "emptylog/abstract_logger.py",
                "functions": [],
                "classes": [
                    {
                        "name": "AbstractLogger",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "__repr__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__add__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "__radd__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "emptylog/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "emptylog/protocols.py",
                "functions": [],
                "classes": [
                    {
                        "name": "LoggerProtocol",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "debug",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "info",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "warning",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "error",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "exception",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "critical",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "LoggerMethodProtocol",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "__call__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "emptylog/memory_logger.py",
                "functions": [],
                "classes": [
                    {
                        "name": "MemoryLogger",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "debug",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "info",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "warning",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "error",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "exception",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "critical",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "emptylog/printing_logger.py",
                "functions": [],
                "classes": [
                    {
                        "name": "PrintingLogger",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "printing_callback",
                                    "separator"
                                ]
                            },
                            {
                                "name": "debug",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "info",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "warning",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "error",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "exception",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "critical",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "message"
                                ]
                            },
                            {
                                "name": "create_line",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "level",
                                    "message"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "emptylog/accumulated_data.py",
                "functions": [],
                "classes": [
                    {
                        "name": "LoggerAccumulatedData",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "__len__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "emptylog/call_data.py",
                "functions": [],
                "classes": [
                    {
                        "name": "LoggerCallData",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "emptylog/empty_logger.py",
                "functions": [],
                "classes": [
                    {
                        "name": "EmptyLogger",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            }
        ],
        "test_cases": {
            "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger0-first_logger0]": {
                "testid": "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger0-first_logger0]",
                "result": "passed",
                "test_implementation": "def test_sum_of_inner_loggers(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger0-first_logger1]": {
                "testid": "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger0-first_logger1]",
                "result": "passed",
                "test_implementation": "def test_sum_of_inner_loggers(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger0-first_logger2]": {
                "testid": "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger0-first_logger2]",
                "result": "passed",
                "test_implementation": "def test_sum_of_inner_loggers(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger1-first_logger0]": {
                "testid": "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger1-first_logger0]",
                "result": "passed",
                "test_implementation": "def test_sum_of_inner_loggers(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger1-first_logger1]": {
                "testid": "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger1-first_logger1]",
                "result": "passed",
                "test_implementation": "def test_sum_of_inner_loggers(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger1-first_logger2]": {
                "testid": "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger1-first_logger2]",
                "result": "passed",
                "test_implementation": "def test_sum_of_inner_loggers(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger2-first_logger0]": {
                "testid": "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger2-first_logger0]",
                "result": "passed",
                "test_implementation": "def test_sum_of_inner_loggers(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger2-first_logger1]": {
                "testid": "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger2-first_logger1]",
                "result": "passed",
                "test_implementation": "def test_sum_of_inner_loggers(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger2-first_logger2]": {
                "testid": "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger2-first_logger2]",
                "result": "passed",
                "test_implementation": "def test_sum_of_inner_loggers(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_of_inner_loggers[logging-first_logger0]": {
                "testid": "tests/test_abstract_logger.py::test_sum_of_inner_loggers[logging-first_logger0]",
                "result": "passed",
                "test_implementation": "def test_sum_of_inner_loggers(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_of_inner_loggers[logging-first_logger1]": {
                "testid": "tests/test_abstract_logger.py::test_sum_of_inner_loggers[logging-first_logger1]",
                "result": "passed",
                "test_implementation": "def test_sum_of_inner_loggers(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_of_inner_loggers[logging-first_logger2]": {
                "testid": "tests/test_abstract_logger.py::test_sum_of_inner_loggers[logging-first_logger2]",
                "result": "passed",
                "test_implementation": "def test_sum_of_inner_loggers(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger4-first_logger0]": {
                "testid": "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger4-first_logger0]",
                "result": "passed",
                "test_implementation": "def test_sum_of_inner_loggers(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger4-first_logger1]": {
                "testid": "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger4-first_logger1]",
                "result": "passed",
                "test_implementation": "def test_sum_of_inner_loggers(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger4-first_logger2]": {
                "testid": "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger4-first_logger2]",
                "result": "passed",
                "test_implementation": "def test_sum_of_inner_loggers(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger5-first_logger0]": {
                "testid": "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger5-first_logger0]",
                "result": "passed",
                "test_implementation": "def test_sum_of_inner_loggers(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger5-first_logger1]": {
                "testid": "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger5-first_logger1]",
                "result": "passed",
                "test_implementation": "def test_sum_of_inner_loggers(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger5-first_logger2]": {
                "testid": "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger5-first_logger2]",
                "result": "passed",
                "test_implementation": "def test_sum_of_inner_loggers(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger0-logging]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger0-logging]",
                "result": "passed",
                "test_implementation": "def test_sum_with_another_loggers_as_first_operand(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger0-first_logger1]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger0-first_logger1]",
                "result": "passed",
                "test_implementation": "def test_sum_with_another_loggers_as_first_operand(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger0-first_logger2]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger0-first_logger2]",
                "result": "passed",
                "test_implementation": "def test_sum_with_another_loggers_as_first_operand(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger1-logging]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger1-logging]",
                "result": "passed",
                "test_implementation": "def test_sum_with_another_loggers_as_first_operand(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger1-first_logger1]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger1-first_logger1]",
                "result": "passed",
                "test_implementation": "def test_sum_with_another_loggers_as_first_operand(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger1-first_logger2]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger1-first_logger2]",
                "result": "passed",
                "test_implementation": "def test_sum_with_another_loggers_as_first_operand(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger2-logging]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger2-logging]",
                "result": "passed",
                "test_implementation": "def test_sum_with_another_loggers_as_first_operand(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger2-first_logger1]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger2-first_logger1]",
                "result": "passed",
                "test_implementation": "def test_sum_with_another_loggers_as_first_operand(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger2-first_logger2]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger2-first_logger2]",
                "result": "passed",
                "test_implementation": "def test_sum_with_another_loggers_as_first_operand(first_logger, second_logger):\n    sum = first_logger + second_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert sum is not first_logger\n    assert sum is not second_logger\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger"
            },
            "tests/test_abstract_logger.py::test_all_loggers_are_instances_of_abstract_logger[logger0]": {
                "testid": "tests/test_abstract_logger.py::test_all_loggers_are_instances_of_abstract_logger[logger0]",
                "result": "passed",
                "test_implementation": "def test_all_loggers_are_instances_of_abstract_logger(logger):\n    assert isinstance(logger, AbstractLogger)"
            },
            "tests/test_abstract_logger.py::test_all_loggers_are_instances_of_abstract_logger[logger1]": {
                "testid": "tests/test_abstract_logger.py::test_all_loggers_are_instances_of_abstract_logger[logger1]",
                "result": "passed",
                "test_implementation": "def test_all_loggers_are_instances_of_abstract_logger(logger):\n    assert isinstance(logger, AbstractLogger)"
            },
            "tests/test_abstract_logger.py::test_all_loggers_are_instances_of_abstract_logger[logger2]": {
                "testid": "tests/test_abstract_logger.py::test_all_loggers_are_instances_of_abstract_logger[logger2]",
                "result": "passed",
                "test_implementation": "def test_all_loggers_are_instances_of_abstract_logger(logger):\n    assert isinstance(logger, AbstractLogger)"
            },
            "tests/test_abstract_logger.py::test_all_loggers_are_instances_of_abstract_logger[logger3]": {
                "testid": "tests/test_abstract_logger.py::test_all_loggers_are_instances_of_abstract_logger[logger3]",
                "result": "passed",
                "test_implementation": "def test_all_loggers_are_instances_of_abstract_logger(logger):\n    assert isinstance(logger, AbstractLogger)"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[1-logger0]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[1-logger0]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_first_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        wrong_operand + logger"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[1-logger1]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[1-logger1]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_first_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        wrong_operand + logger"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[1-logger2]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[1-logger2]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_first_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        wrong_operand + logger"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[1-logger3]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[1-logger3]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_first_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        wrong_operand + logger"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[kek-logger0]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[kek-logger0]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_first_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        wrong_operand + logger"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[kek-logger1]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[kek-logger1]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_first_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        wrong_operand + logger"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[kek-logger2]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[kek-logger2]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_first_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        wrong_operand + logger"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[kek-logger3]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[kek-logger3]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_first_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        wrong_operand + logger"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[None-logger0]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[None-logger0]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_first_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        wrong_operand + logger"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[None-logger1]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[None-logger1]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_first_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        wrong_operand + logger"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[None-logger2]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[None-logger2]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_first_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        wrong_operand + logger"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[None-logger3]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[None-logger3]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_first_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        wrong_operand + logger"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[1-logger0]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[1-logger0]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_second_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        logger + wrong_operand"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[1-logger1]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[1-logger1]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_second_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        logger + wrong_operand"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[1-logger2]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[1-logger2]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_second_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        logger + wrong_operand"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[1-logger3]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[1-logger3]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_second_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        logger + wrong_operand"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[kek-logger0]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[kek-logger0]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_second_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        logger + wrong_operand"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[kek-logger1]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[kek-logger1]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_second_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        logger + wrong_operand"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[kek-logger2]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[kek-logger2]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_second_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        logger + wrong_operand"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[kek-logger3]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[kek-logger3]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_second_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        logger + wrong_operand"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[None-logger0]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[None-logger0]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_second_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        logger + wrong_operand"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[None-logger1]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[None-logger1]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_second_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        logger + wrong_operand"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[None-logger2]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[None-logger2]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_second_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        logger + wrong_operand"
            },
            "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[None-logger3]": {
                "testid": "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[None-logger3]",
                "result": "passed",
                "test_implementation": "def test_sum_with_wrong_second_operand(logger, wrong_operand):\n    with pytest.raises(NotImplementedError, match=full_match('The addition operation is defined only for loggers.')):\n        logger + wrong_operand"
            },
            "tests/test_abstract_logger.py::test_sum_of_three_loggers": {
                "testid": "tests/test_abstract_logger.py::test_sum_of_three_loggers",
                "result": "passed",
                "test_implementation": "def test_sum_of_three_loggers():\n    first_logger = EmptyLogger()\n    second_logger = MemoryLogger()\n    third_logger = PrintingLogger()\n\n    sum = first_logger + second_logger + third_logger\n\n    assert isinstance(sum, LoggersGroup)\n\n    assert len(sum) == 3\n    assert len(sum.loggers) == 3\n\n    assert sum.loggers[0] is first_logger\n    assert sum.loggers[1] is second_logger\n    assert sum.loggers[2] is third_logger"
            },
            "tests/test_accumulated_data.py::test_fill_accumulated_data_and_check_size": {
                "testid": "tests/test_accumulated_data.py::test_fill_accumulated_data_and_check_size",
                "result": "passed",
                "test_implementation": "def test_fill_accumulated_data_and_check_size():\n    data = LoggerAccumulatedData()\n\n    lists = [\n        data.debug,\n        data.info,\n        data.warning,\n        data.error,\n        data.exception,\n        data.critical,\n    ]\n\n    logs_sum = 0\n\n    for index, logs_list in enumerate(lists):\n        assert len(data) == logs_sum\n\n        for _ in range(index + 1):\n            logs_list.append(LoggerCallData('some message', (), {}))\n            logs_sum += 1\n\n            assert len(data) == logs_sum\n\n    assert len(data) == 21"
            },
            "tests/test_call_data.py::test_create_call_data_and_check_the_data": {
                "testid": "tests/test_call_data.py::test_create_call_data_and_check_the_data",
                "result": "passed",
                "test_implementation": "def test_create_call_data_and_check_the_data():\n    data = LoggerCallData('kek', (), {})\n\n    assert data.message == 'kek'\n    assert data.args == ()\n    assert data.kwargs == {}"
            },
            "tests/test_empty_logger.py::test_search_callable_attributes": {
                "testid": "tests/test_empty_logger.py::test_search_callable_attributes",
                "result": "passed",
                "test_implementation": "def test_search_callable_attributes():\n    attribute_names = [\n        'debug',\n        'info',\n        'warning',\n        'error',\n        'exception',\n        'critical',\n    ]\n\n    empty_logger = EmptyLogger()\n    real_logger = logging.getLogger('kek')\n\n    for name in attribute_names:\n        for logger in [empty_logger, real_logger]:\n            method = getattr(logger, name)\n\n            assert callable(method)\n\n            method('kek')\n            method('kek %s', 'lol')\n            method('kek %s', 'lol', extra={'lol': 'kek'})"
            },
            "tests/test_empty_logger.py::test_repr_empty_logger": {
                "testid": "tests/test_empty_logger.py::test_repr_empty_logger",
                "result": "passed",
                "test_implementation": "def test_repr_empty_logger():\n    assert repr(EmptyLogger()) == 'EmptyLogger()'"
            },
            "tests/test_loggers_group.py::test_len_of_group": {
                "testid": "tests/test_loggers_group.py::test_len_of_group",
                "result": "passed",
                "test_implementation": "def test_len_of_group():\n    assert len(LoggersGroup()) == 0\n    assert len(LoggersGroup(MemoryLogger())) == 1\n    assert len(LoggersGroup(MemoryLogger(), MemoryLogger())) == 2\n    assert len(LoggersGroup(MemoryLogger(), MemoryLogger(), MemoryLogger())) == 3\n    assert len(LoggersGroup(MemoryLogger(), MemoryLogger(), MemoryLogger(), MemoryLogger())) == 4\n\n    assert len(LoggersGroup() + LoggersGroup()) == 0\n    assert len(LoggersGroup() + MemoryLogger()) == 1\n    assert len(MemoryLogger() + MemoryLogger()) == 2\n    assert len(MemoryLogger() + MemoryLogger() + MemoryLogger()) == 3"
            },
            "tests/test_loggers_group.py::test_create_group_with_not_loggers[1-A logger group can only be created from loggers. You passed 1 (int).]": {
                "testid": "tests/test_loggers_group.py::test_create_group_with_not_loggers[1-A logger group can only be created from loggers. You passed 1 (int).]",
                "result": "passed",
                "test_implementation": "def test_create_group_with_not_loggers(wrong_logger, exception_message):\n    with pytest.raises(TypeError, match=full_match(exception_message)):\n        LoggersGroup(wrong_logger)"
            },
            "tests/test_loggers_group.py::test_create_group_with_not_loggers[kek-A logger group can only be created from loggers. You passed 'kek' (str).]": {
                "testid": "tests/test_loggers_group.py::test_create_group_with_not_loggers[kek-A logger group can only be created from loggers. You passed 'kek' (str).]",
                "result": "passed",
                "test_implementation": "def test_create_group_with_not_loggers(wrong_logger, exception_message):\n    with pytest.raises(TypeError, match=full_match(exception_message)):\n        LoggersGroup(wrong_logger)"
            },
            "tests/test_loggers_group.py::test_create_group_with_not_loggers[None-A logger group can only be created from loggers. You passed None (NoneType).]": {
                "testid": "tests/test_loggers_group.py::test_create_group_with_not_loggers[None-A logger group can only be created from loggers. You passed None (NoneType).]",
                "result": "passed",
                "test_implementation": "def test_create_group_with_not_loggers(wrong_logger, exception_message):\n    with pytest.raises(TypeError, match=full_match(exception_message)):\n        LoggersGroup(wrong_logger)"
            },
            "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>0]": {
                "testid": "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>0]",
                "result": "passed",
                "test_implementation": "def test_run_group_of_memory_loggers(get_method):\n    first_internal_logger = MemoryLogger()\n    second_internal_logger = MemoryLogger()\n    group = LoggersGroup(first_internal_logger, second_internal_logger)\n\n    get_method(group)('lol', 'kek', cheburek='pek')\n\n    for internal_logger in first_internal_logger, second_internal_logger:\n        assert len(get_method(internal_logger.data)) == 1\n        assert get_method(internal_logger.data)[0].message == 'lol'\n        assert get_method(internal_logger.data)[0].args == ('kek',)\n        assert get_method(internal_logger.data)[0].kwargs == {'cheburek': 'pek'}"
            },
            "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>1]": {
                "testid": "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>1]",
                "result": "passed",
                "test_implementation": "def test_run_group_of_memory_loggers(get_method):\n    first_internal_logger = MemoryLogger()\n    second_internal_logger = MemoryLogger()\n    group = LoggersGroup(first_internal_logger, second_internal_logger)\n\n    get_method(group)('lol', 'kek', cheburek='pek')\n\n    for internal_logger in first_internal_logger, second_internal_logger:\n        assert len(get_method(internal_logger.data)) == 1\n        assert get_method(internal_logger.data)[0].message == 'lol'\n        assert get_method(internal_logger.data)[0].args == ('kek',)\n        assert get_method(internal_logger.data)[0].kwargs == {'cheburek': 'pek'}"
            },
            "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>2]": {
                "testid": "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>2]",
                "result": "passed",
                "test_implementation": "def test_run_group_of_memory_loggers(get_method):\n    first_internal_logger = MemoryLogger()\n    second_internal_logger = MemoryLogger()\n    group = LoggersGroup(first_internal_logger, second_internal_logger)\n\n    get_method(group)('lol', 'kek', cheburek='pek')\n\n    for internal_logger in first_internal_logger, second_internal_logger:\n        assert len(get_method(internal_logger.data)) == 1\n        assert get_method(internal_logger.data)[0].message == 'lol'\n        assert get_method(internal_logger.data)[0].args == ('kek',)\n        assert get_method(internal_logger.data)[0].kwargs == {'cheburek': 'pek'}"
            },
            "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>3]": {
                "testid": "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>3]",
                "result": "passed",
                "test_implementation": "def test_run_group_of_memory_loggers(get_method):\n    first_internal_logger = MemoryLogger()\n    second_internal_logger = MemoryLogger()\n    group = LoggersGroup(first_internal_logger, second_internal_logger)\n\n    get_method(group)('lol', 'kek', cheburek='pek')\n\n    for internal_logger in first_internal_logger, second_internal_logger:\n        assert len(get_method(internal_logger.data)) == 1\n        assert get_method(internal_logger.data)[0].message == 'lol'\n        assert get_method(internal_logger.data)[0].args == ('kek',)\n        assert get_method(internal_logger.data)[0].kwargs == {'cheburek': 'pek'}"
            },
            "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>4]": {
                "testid": "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>4]",
                "result": "passed",
                "test_implementation": "def test_run_group_of_memory_loggers(get_method):\n    first_internal_logger = MemoryLogger()\n    second_internal_logger = MemoryLogger()\n    group = LoggersGroup(first_internal_logger, second_internal_logger)\n\n    get_method(group)('lol', 'kek', cheburek='pek')\n\n    for internal_logger in first_internal_logger, second_internal_logger:\n        assert len(get_method(internal_logger.data)) == 1\n        assert get_method(internal_logger.data)[0].message == 'lol'\n        assert get_method(internal_logger.data)[0].args == ('kek',)\n        assert get_method(internal_logger.data)[0].kwargs == {'cheburek': 'pek'}"
            },
            "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>5]": {
                "testid": "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>5]",
                "result": "passed",
                "test_implementation": "def test_run_group_of_memory_loggers(get_method):\n    first_internal_logger = MemoryLogger()\n    second_internal_logger = MemoryLogger()\n    group = LoggersGroup(first_internal_logger, second_internal_logger)\n\n    get_method(group)('lol', 'kek', cheburek='pek')\n\n    for internal_logger in first_internal_logger, second_internal_logger:\n        assert len(get_method(internal_logger.data)) == 1\n        assert get_method(internal_logger.data)[0].message == 'lol'\n        assert get_method(internal_logger.data)[0].args == ('kek',)\n        assert get_method(internal_logger.data)[0].kwargs == {'cheburek': 'pek'}"
            },
            "tests/test_loggers_group.py::test_repr_loggers_group": {
                "testid": "tests/test_loggers_group.py::test_repr_loggers_group",
                "result": "passed",
                "test_implementation": "def test_repr_loggers_group():\n    assert repr(LoggersGroup()) == 'LoggersGroup()'\n    assert repr(LoggersGroup(LoggersGroup())) == 'LoggersGroup(LoggersGroup())'\n    assert repr(LoggersGroup(MemoryLogger())) == 'LoggersGroup(MemoryLogger())'\n    assert repr(LoggersGroup(MemoryLogger(), MemoryLogger())) == 'LoggersGroup(MemoryLogger(), MemoryLogger())'\n    assert repr(LoggersGroup(MemoryLogger(), MemoryLogger(), MemoryLogger())) == 'LoggersGroup(MemoryLogger(), MemoryLogger(), MemoryLogger())'"
            },
            "tests/test_loggers_group.py::test_empty_group_plus_empty_group": {
                "testid": "tests/test_loggers_group.py::test_empty_group_plus_empty_group",
                "result": "passed",
                "test_implementation": "def test_empty_group_plus_empty_group():\n    assert type(LoggersGroup() + LoggersGroup()) is LoggersGroup\n    assert (LoggersGroup() + LoggersGroup()).loggers == ()"
            },
            "tests/test_loggers_group.py::test_not_empty_group_plus_empty_group": {
                "testid": "tests/test_loggers_group.py::test_not_empty_group_plus_empty_group",
                "result": "passed",
                "test_implementation": "def test_not_empty_group_plus_empty_group():\n    first_internal_logger = MemoryLogger()\n    second_internal_logger = MemoryLogger()\n\n    assert type(LoggersGroup(first_internal_logger) + LoggersGroup()) is LoggersGroup\n    assert type(LoggersGroup(first_internal_logger, second_internal_logger) + LoggersGroup()) is LoggersGroup\n\n    assert len((LoggersGroup(first_internal_logger) + LoggersGroup()).loggers) == 1\n    assert len((LoggersGroup(first_internal_logger, second_internal_logger) + LoggersGroup()).loggers) == 2\n\n    assert (LoggersGroup(first_internal_logger) + LoggersGroup()).loggers[0] is first_internal_logger\n    assert (LoggersGroup(first_internal_logger, second_internal_logger) + LoggersGroup()).loggers[0] is first_internal_logger\n    assert (LoggersGroup(first_internal_logger, second_internal_logger) + LoggersGroup()).loggers[1] is second_internal_logger"
            },
            "tests/test_loggers_group.py::test_empty_group_plus_not_empty_group": {
                "testid": "tests/test_loggers_group.py::test_empty_group_plus_not_empty_group",
                "result": "passed",
                "test_implementation": "def test_empty_group_plus_not_empty_group():\n    first_internal_logger = MemoryLogger()\n    second_internal_logger = MemoryLogger()\n\n    assert type(LoggersGroup() + LoggersGroup(first_internal_logger)) is LoggersGroup\n    assert type(LoggersGroup() + LoggersGroup(first_internal_logger, second_internal_logger)) is LoggersGroup\n\n    assert len((LoggersGroup() + LoggersGroup(first_internal_logger)).loggers) == 1\n    assert len((LoggersGroup() + LoggersGroup(first_internal_logger, second_internal_logger)).loggers) == 2\n\n    assert (LoggersGroup() + LoggersGroup(first_internal_logger)).loggers[0] is first_internal_logger\n    assert (LoggersGroup() + LoggersGroup(first_internal_logger, second_internal_logger)).loggers[0] is first_internal_logger\n    assert (LoggersGroup() + LoggersGroup(first_internal_logger, second_internal_logger)).loggers[1] is second_internal_logger"
            },
            "tests/test_loggers_group.py::test_empty_group_plus_another_logger": {
                "testid": "tests/test_loggers_group.py::test_empty_group_plus_another_logger",
                "result": "passed",
                "test_implementation": "def test_empty_group_plus_another_logger():\n    another_logger = MemoryLogger()\n\n    assert type(LoggersGroup() + another_logger) is LoggersGroup\n    assert len((LoggersGroup() + another_logger).loggers) == 1\n    assert (LoggersGroup() + another_logger).loggers[0] is another_logger"
            },
            "tests/test_loggers_group.py::test_another_logger_plus_empty_group": {
                "testid": "tests/test_loggers_group.py::test_another_logger_plus_empty_group",
                "result": "passed",
                "test_implementation": "def test_another_logger_plus_empty_group():\n    another_logger = MemoryLogger()\n\n    assert type(another_logger + LoggersGroup()) is LoggersGroup\n    assert len((another_logger + LoggersGroup()).loggers) == 1\n    assert len(another_logger + LoggersGroup()) == 1\n    assert (another_logger + LoggersGroup()).loggers[0] is another_logger"
            },
            "tests/test_loggers_group.py::test_empty_group_plus_third_party_logger[third_party_logger0]": {
                "testid": "tests/test_loggers_group.py::test_empty_group_plus_third_party_logger[third_party_logger0]",
                "result": "passed",
                "test_implementation": "def test_empty_group_plus_third_party_logger(third_party_logger):\n    first_group = LoggersGroup()\n\n    sum = first_group + third_party_logger\n\n    assert type(sum) is LoggersGroup\n    assert sum is not first_group\n    assert len(sum.loggers) == 1\n    assert len(sum) == 1\n    assert sum.loggers[0] is third_party_logger"
            },
            "tests/test_loggers_group.py::test_empty_group_plus_third_party_logger[logging]": {
                "testid": "tests/test_loggers_group.py::test_empty_group_plus_third_party_logger[logging]",
                "result": "passed",
                "test_implementation": "def test_empty_group_plus_third_party_logger(third_party_logger):\n    first_group = LoggersGroup()\n\n    sum = first_group + third_party_logger\n\n    assert type(sum) is LoggersGroup\n    assert sum is not first_group\n    assert len(sum.loggers) == 1\n    assert len(sum) == 1\n    assert sum.loggers[0] is third_party_logger"
            },
            "tests/test_loggers_group.py::test_empty_group_plus_third_party_logger[third_party_logger2]": {
                "testid": "tests/test_loggers_group.py::test_empty_group_plus_third_party_logger[third_party_logger2]",
                "result": "passed",
                "test_implementation": "def test_empty_group_plus_third_party_logger(third_party_logger):\n    first_group = LoggersGroup()\n\n    sum = first_group + third_party_logger\n\n    assert type(sum) is LoggersGroup\n    assert sum is not first_group\n    assert len(sum.loggers) == 1\n    assert len(sum) == 1\n    assert sum.loggers[0] is third_party_logger"
            },
            "tests/test_loggers_group.py::test_third_party_logger_plus_empty_group[third_party_logger0]": {
                "testid": "tests/test_loggers_group.py::test_third_party_logger_plus_empty_group[third_party_logger0]",
                "result": "passed",
                "test_implementation": "def test_third_party_logger_plus_empty_group(third_party_logger):\n    first_group = LoggersGroup()\n\n    sum = third_party_logger + first_group\n\n    assert type(sum) is LoggersGroup\n    assert sum is not first_group\n    assert len(sum.loggers) == 1\n    assert len(sum) == 1\n    assert sum.loggers[0] is third_party_logger"
            },
            "tests/test_loggers_group.py::test_third_party_logger_plus_empty_group[logging]": {
                "testid": "tests/test_loggers_group.py::test_third_party_logger_plus_empty_group[logging]",
                "result": "passed",
                "test_implementation": "def test_third_party_logger_plus_empty_group(third_party_logger):\n    first_group = LoggersGroup()\n\n    sum = third_party_logger + first_group\n\n    assert type(sum) is LoggersGroup\n    assert sum is not first_group\n    assert len(sum.loggers) == 1\n    assert len(sum) == 1\n    assert sum.loggers[0] is third_party_logger"
            },
            "tests/test_loggers_group.py::test_third_party_logger_plus_empty_group[third_party_logger2]": {
                "testid": "tests/test_loggers_group.py::test_third_party_logger_plus_empty_group[third_party_logger2]",
                "result": "passed",
                "test_implementation": "def test_third_party_logger_plus_empty_group(third_party_logger):\n    first_group = LoggersGroup()\n\n    sum = third_party_logger + first_group\n\n    assert type(sum) is LoggersGroup\n    assert sum is not first_group\n    assert len(sum.loggers) == 1\n    assert len(sum) == 1\n    assert sum.loggers[0] is third_party_logger"
            },
            "tests/test_loggers_group.py::test_iteration_by_group[loggers0]": {
                "testid": "tests/test_loggers_group.py::test_iteration_by_group[loggers0]",
                "result": "passed",
                "test_implementation": "def test_iteration_by_group(loggers):\n    group = LoggersGroup(*loggers)\n\n    assert loggers == [x for x in group]"
            },
            "tests/test_loggers_group.py::test_iteration_by_group[loggers1]": {
                "testid": "tests/test_loggers_group.py::test_iteration_by_group[loggers1]",
                "result": "passed",
                "test_implementation": "def test_iteration_by_group(loggers):\n    group = LoggersGroup(*loggers)\n\n    assert loggers == [x for x in group]"
            },
            "tests/test_loggers_group.py::test_iteration_by_group[loggers2]": {
                "testid": "tests/test_loggers_group.py::test_iteration_by_group[loggers2]",
                "result": "passed",
                "test_implementation": "def test_iteration_by_group(loggers):\n    group = LoggersGroup(*loggers)\n\n    assert loggers == [x for x in group]"
            },
            "tests/test_loggers_group.py::test_iteration_by_group[loggers3]": {
                "testid": "tests/test_loggers_group.py::test_iteration_by_group[loggers3]",
                "result": "passed",
                "test_implementation": "def test_iteration_by_group(loggers):\n    group = LoggersGroup(*loggers)\n\n    assert loggers == [x for x in group]"
            },
            "tests/test_memory_logger.py::test_memory_logger_is_logger": {
                "testid": "tests/test_memory_logger.py::test_memory_logger_is_logger",
                "result": "passed",
                "test_implementation": "def test_memory_logger_is_logger():\n    assert isinstance(MemoryLogger(), LoggerProtocol)"
            },
            "tests/test_memory_logger.py::test_memory_logger_is_working": {
                "testid": "tests/test_memory_logger.py::test_memory_logger_is_working",
                "result": "passed",
                "test_implementation": "def test_memory_logger_is_working():\n    attribute_names = [\n        'debug',\n        'info',\n        'warning',\n        'error',\n        'exception',\n        'critical',\n    ]\n\n    logger = MemoryLogger()\n\n    for name in attribute_names:\n        method = getattr(logger, name)\n\n        assert callable(method)\n\n        for number in range(3):\n            method(f'kek_{name}', 'lol', 'cheburek', name, pek='mek', kekokek=name)\n\n    assert len(logger.data.debug) == 3\n    assert len(logger.data.info) == 3\n    assert len(logger.data.warning) == 3\n    assert len(logger.data.error) == 3\n    assert len(logger.data.exception) == 3\n    assert len(logger.data.critical) == 3\n\n    assert logger.data.debug[0] == logger.data.debug[1] == logger.data.debug[2]\n    assert logger.data.info[0] == logger.data.info[1] == logger.data.info[2]\n    assert logger.data.warning[0] == logger.data.warning[1] == logger.data.warning[2]\n    assert logger.data.error[0] == logger.data.error[1] == logger.data.error[2]\n    assert logger.data.exception[0] == logger.data.exception[1] == logger.data.exception[2]\n    assert logger.data.critical[0] == logger.data.critical[1] == logger.data.critical[2]\n\n    assert logger.data.debug[0] == LoggerCallData(message='kek_debug', args=('lol', 'cheburek', 'debug'), kwargs={'pek': 'mek', 'kekokek': 'debug'})\n    assert logger.data.info[0] == LoggerCallData(message='kek_info', args=('lol', 'cheburek', 'info'), kwargs={'pek': 'mek', 'kekokek': 'info'})\n    assert logger.data.warning[0] == LoggerCallData(message='kek_warning', args=('lol', 'cheburek', 'warning'), kwargs={'pek': 'mek', 'kekokek': 'warning'})\n    assert logger.data.error[0] == LoggerCallData(message='kek_error', args=('lol', 'cheburek', 'error'), kwargs={'pek': 'mek', 'kekokek': 'error'})\n    assert logger.data.exception[0] == LoggerCallData(message='kek_exception', args=('lol', 'cheburek', 'exception'), kwargs={'pek': 'mek', 'kekokek': 'exception'})\n    assert logger.data.critical[0] == LoggerCallData(message='kek_critical', args=('lol', 'cheburek', 'critical'), kwargs={'pek': 'mek', 'kekokek': 'critical'})"
            },
            "tests/test_memory_logger.py::test_repr_memory_logger": {
                "testid": "tests/test_memory_logger.py::test_repr_memory_logger",
                "result": "passed",
                "test_implementation": "def test_repr_memory_logger():\n    assert repr(MemoryLogger()) == 'MemoryLogger()'"
            },
            "tests/test_printing_logger.py::test_printing_logger_is_logger": {
                "testid": "tests/test_printing_logger.py::test_printing_logger_is_logger",
                "result": "passed",
                "test_implementation": "def test_printing_logger_is_logger():\n    assert isinstance(PrintingLogger(), LoggerProtocol)"
            },
            "tests/test_printing_logger.py::test_check_simple_output[debug- | DEBUG     | kek]": {
                "testid": "tests/test_printing_logger.py::test_check_simple_output[debug- | DEBUG     | kek]",
                "result": "passed",
                "test_implementation": "def test_check_simple_output(method, result_tail):\n    # this code is adapted from there: https://stackoverflow.com/a/66683635\n    remove_suffix = lambda input_string, suffix: input_string[:-len(suffix)] if suffix and input_string.endswith(suffix) else input_string  # noqa: E731\n\n    buffer = io.StringIO()\n    with redirect_stdout(buffer):\n        method('kek')\n\n    printed = buffer.getvalue()\n\n    assert printed.endswith(result_tail + '\\n')\n\n    time_stamp = remove_suffix(printed, result_tail + '\\n') # expected format: 2024-07-08 19:09:48.226667\n\n    assert len(time_stamp.split()) == 2\n\n    date = time_stamp.split()[0]\n    time = time_stamp.split()[1]\n\n    assert re.match(r'[\\d]{4}-[\\d]{2}-[\\d]{2}', date) is not None\n\n    time_before_dot = time.split('.')[0]\n    time_after_dot = time.split('.')[1]\n\n    assert len(time.split('.')) == 2\n    assert re.match(r'[\\d]{2}:[\\d]{2}:[\\d]{2}', time_before_dot) is not None\n    assert time_after_dot.isdigit()"
            },
            "tests/test_printing_logger.py::test_check_simple_output[info- | INFO      | kek]": {
                "testid": "tests/test_printing_logger.py::test_check_simple_output[info- | INFO      | kek]",
                "result": "passed",
                "test_implementation": "def test_check_simple_output(method, result_tail):\n    # this code is adapted from there: https://stackoverflow.com/a/66683635\n    remove_suffix = lambda input_string, suffix: input_string[:-len(suffix)] if suffix and input_string.endswith(suffix) else input_string  # noqa: E731\n\n    buffer = io.StringIO()\n    with redirect_stdout(buffer):\n        method('kek')\n\n    printed = buffer.getvalue()\n\n    assert printed.endswith(result_tail + '\\n')\n\n    time_stamp = remove_suffix(printed, result_tail + '\\n') # expected format: 2024-07-08 19:09:48.226667\n\n    assert len(time_stamp.split()) == 2\n\n    date = time_stamp.split()[0]\n    time = time_stamp.split()[1]\n\n    assert re.match(r'[\\d]{4}-[\\d]{2}-[\\d]{2}', date) is not None\n\n    time_before_dot = time.split('.')[0]\n    time_after_dot = time.split('.')[1]\n\n    assert len(time.split('.')) == 2\n    assert re.match(r'[\\d]{2}:[\\d]{2}:[\\d]{2}', time_before_dot) is not None\n    assert time_after_dot.isdigit()"
            },
            "tests/test_printing_logger.py::test_check_simple_output[warning- | WARNING   | kek]": {
                "testid": "tests/test_printing_logger.py::test_check_simple_output[warning- | WARNING   | kek]",
                "result": "passed",
                "test_implementation": "def test_check_simple_output(method, result_tail):\n    # this code is adapted from there: https://stackoverflow.com/a/66683635\n    remove_suffix = lambda input_string, suffix: input_string[:-len(suffix)] if suffix and input_string.endswith(suffix) else input_string  # noqa: E731\n\n    buffer = io.StringIO()\n    with redirect_stdout(buffer):\n        method('kek')\n\n    printed = buffer.getvalue()\n\n    assert printed.endswith(result_tail + '\\n')\n\n    time_stamp = remove_suffix(printed, result_tail + '\\n') # expected format: 2024-07-08 19:09:48.226667\n\n    assert len(time_stamp.split()) == 2\n\n    date = time_stamp.split()[0]\n    time = time_stamp.split()[1]\n\n    assert re.match(r'[\\d]{4}-[\\d]{2}-[\\d]{2}', date) is not None\n\n    time_before_dot = time.split('.')[0]\n    time_after_dot = time.split('.')[1]\n\n    assert len(time.split('.')) == 2\n    assert re.match(r'[\\d]{2}:[\\d]{2}:[\\d]{2}', time_before_dot) is not None\n    assert time_after_dot.isdigit()"
            },
            "tests/test_printing_logger.py::test_check_simple_output[error- | ERROR     | kek]": {
                "testid": "tests/test_printing_logger.py::test_check_simple_output[error- | ERROR     | kek]",
                "result": "passed",
                "test_implementation": "def test_check_simple_output(method, result_tail):\n    # this code is adapted from there: https://stackoverflow.com/a/66683635\n    remove_suffix = lambda input_string, suffix: input_string[:-len(suffix)] if suffix and input_string.endswith(suffix) else input_string  # noqa: E731\n\n    buffer = io.StringIO()\n    with redirect_stdout(buffer):\n        method('kek')\n\n    printed = buffer.getvalue()\n\n    assert printed.endswith(result_tail + '\\n')\n\n    time_stamp = remove_suffix(printed, result_tail + '\\n') # expected format: 2024-07-08 19:09:48.226667\n\n    assert len(time_stamp.split()) == 2\n\n    date = time_stamp.split()[0]\n    time = time_stamp.split()[1]\n\n    assert re.match(r'[\\d]{4}-[\\d]{2}-[\\d]{2}', date) is not None\n\n    time_before_dot = time.split('.')[0]\n    time_after_dot = time.split('.')[1]\n\n    assert len(time.split('.')) == 2\n    assert re.match(r'[\\d]{2}:[\\d]{2}:[\\d]{2}', time_before_dot) is not None\n    assert time_after_dot.isdigit()"
            },
            "tests/test_printing_logger.py::test_check_simple_output[exception- | EXCEPTION | kek]": {
                "testid": "tests/test_printing_logger.py::test_check_simple_output[exception- | EXCEPTION | kek]",
                "result": "passed",
                "test_implementation": "def test_check_simple_output(method, result_tail):\n    # this code is adapted from there: https://stackoverflow.com/a/66683635\n    remove_suffix = lambda input_string, suffix: input_string[:-len(suffix)] if suffix and input_string.endswith(suffix) else input_string  # noqa: E731\n\n    buffer = io.StringIO()\n    with redirect_stdout(buffer):\n        method('kek')\n\n    printed = buffer.getvalue()\n\n    assert printed.endswith(result_tail + '\\n')\n\n    time_stamp = remove_suffix(printed, result_tail + '\\n') # expected format: 2024-07-08 19:09:48.226667\n\n    assert len(time_stamp.split()) == 2\n\n    date = time_stamp.split()[0]\n    time = time_stamp.split()[1]\n\n    assert re.match(r'[\\d]{4}-[\\d]{2}-[\\d]{2}', date) is not None\n\n    time_before_dot = time.split('.')[0]\n    time_after_dot = time.split('.')[1]\n\n    assert len(time.split('.')) == 2\n    assert re.match(r'[\\d]{2}:[\\d]{2}:[\\d]{2}', time_before_dot) is not None\n    assert time_after_dot.isdigit()"
            },
            "tests/test_printing_logger.py::test_check_simple_output[critical- | CRITICAL  | kek]": {
                "testid": "tests/test_printing_logger.py::test_check_simple_output[critical- | CRITICAL  | kek]",
                "result": "passed",
                "test_implementation": "def test_check_simple_output(method, result_tail):\n    # this code is adapted from there: https://stackoverflow.com/a/66683635\n    remove_suffix = lambda input_string, suffix: input_string[:-len(suffix)] if suffix and input_string.endswith(suffix) else input_string  # noqa: E731\n\n    buffer = io.StringIO()\n    with redirect_stdout(buffer):\n        method('kek')\n\n    printed = buffer.getvalue()\n\n    assert printed.endswith(result_tail + '\\n')\n\n    time_stamp = remove_suffix(printed, result_tail + '\\n') # expected format: 2024-07-08 19:09:48.226667\n\n    assert len(time_stamp.split()) == 2\n\n    date = time_stamp.split()[0]\n    time = time_stamp.split()[1]\n\n    assert re.match(r'[\\d]{4}-[\\d]{2}-[\\d]{2}', date) is not None\n\n    time_before_dot = time.split('.')[0]\n    time_after_dot = time.split('.')[1]\n\n    assert len(time.split('.')) == 2\n    assert re.match(r'[\\d]{2}:[\\d]{2}:[\\d]{2}', time_before_dot) is not None\n    assert time_after_dot.isdigit()"
            },
            "tests/test_printing_logger.py::test_check_simple_output[debug- * DEBUG     * kek]": {
                "testid": "tests/test_printing_logger.py::test_check_simple_output[debug- * DEBUG     * kek]",
                "result": "passed",
                "test_implementation": "def test_check_simple_output(method, result_tail):\n    # this code is adapted from there: https://stackoverflow.com/a/66683635\n    remove_suffix = lambda input_string, suffix: input_string[:-len(suffix)] if suffix and input_string.endswith(suffix) else input_string  # noqa: E731\n\n    buffer = io.StringIO()\n    with redirect_stdout(buffer):\n        method('kek')\n\n    printed = buffer.getvalue()\n\n    assert printed.endswith(result_tail + '\\n')\n\n    time_stamp = remove_suffix(printed, result_tail + '\\n') # expected format: 2024-07-08 19:09:48.226667\n\n    assert len(time_stamp.split()) == 2\n\n    date = time_stamp.split()[0]\n    time = time_stamp.split()[1]\n\n    assert re.match(r'[\\d]{4}-[\\d]{2}-[\\d]{2}', date) is not None\n\n    time_before_dot = time.split('.')[0]\n    time_after_dot = time.split('.')[1]\n\n    assert len(time.split('.')) == 2\n    assert re.match(r'[\\d]{2}:[\\d]{2}:[\\d]{2}', time_before_dot) is not None\n    assert time_after_dot.isdigit()"
            },
            "tests/test_printing_logger.py::test_check_simple_output[info- * INFO      * kek]": {
                "testid": "tests/test_printing_logger.py::test_check_simple_output[info- * INFO      * kek]",
                "result": "passed",
                "test_implementation": "def test_check_simple_output(method, result_tail):\n    # this code is adapted from there: https://stackoverflow.com/a/66683635\n    remove_suffix = lambda input_string, suffix: input_string[:-len(suffix)] if suffix and input_string.endswith(suffix) else input_string  # noqa: E731\n\n    buffer = io.StringIO()\n    with redirect_stdout(buffer):\n        method('kek')\n\n    printed = buffer.getvalue()\n\n    assert printed.endswith(result_tail + '\\n')\n\n    time_stamp = remove_suffix(printed, result_tail + '\\n') # expected format: 2024-07-08 19:09:48.226667\n\n    assert len(time_stamp.split()) == 2\n\n    date = time_stamp.split()[0]\n    time = time_stamp.split()[1]\n\n    assert re.match(r'[\\d]{4}-[\\d]{2}-[\\d]{2}', date) is not None\n\n    time_before_dot = time.split('.')[0]\n    time_after_dot = time.split('.')[1]\n\n    assert len(time.split('.')) == 2\n    assert re.match(r'[\\d]{2}:[\\d]{2}:[\\d]{2}', time_before_dot) is not None\n    assert time_after_dot.isdigit()"
            },
            "tests/test_printing_logger.py::test_check_simple_output[warning- * WARNING   * kek]": {
                "testid": "tests/test_printing_logger.py::test_check_simple_output[warning- * WARNING   * kek]",
                "result": "passed",
                "test_implementation": "def test_check_simple_output(method, result_tail):\n    # this code is adapted from there: https://stackoverflow.com/a/66683635\n    remove_suffix = lambda input_string, suffix: input_string[:-len(suffix)] if suffix and input_string.endswith(suffix) else input_string  # noqa: E731\n\n    buffer = io.StringIO()\n    with redirect_stdout(buffer):\n        method('kek')\n\n    printed = buffer.getvalue()\n\n    assert printed.endswith(result_tail + '\\n')\n\n    time_stamp = remove_suffix(printed, result_tail + '\\n') # expected format: 2024-07-08 19:09:48.226667\n\n    assert len(time_stamp.split()) == 2\n\n    date = time_stamp.split()[0]\n    time = time_stamp.split()[1]\n\n    assert re.match(r'[\\d]{4}-[\\d]{2}-[\\d]{2}', date) is not None\n\n    time_before_dot = time.split('.')[0]\n    time_after_dot = time.split('.')[1]\n\n    assert len(time.split('.')) == 2\n    assert re.match(r'[\\d]{2}:[\\d]{2}:[\\d]{2}', time_before_dot) is not None\n    assert time_after_dot.isdigit()"
            },
            "tests/test_printing_logger.py::test_check_simple_output[error- * ERROR     * kek]": {
                "testid": "tests/test_printing_logger.py::test_check_simple_output[error- * ERROR     * kek]",
                "result": "passed",
                "test_implementation": "def test_check_simple_output(method, result_tail):\n    # this code is adapted from there: https://stackoverflow.com/a/66683635\n    remove_suffix = lambda input_string, suffix: input_string[:-len(suffix)] if suffix and input_string.endswith(suffix) else input_string  # noqa: E731\n\n    buffer = io.StringIO()\n    with redirect_stdout(buffer):\n        method('kek')\n\n    printed = buffer.getvalue()\n\n    assert printed.endswith(result_tail + '\\n')\n\n    time_stamp = remove_suffix(printed, result_tail + '\\n') # expected format: 2024-07-08 19:09:48.226667\n\n    assert len(time_stamp.split()) == 2\n\n    date = time_stamp.split()[0]\n    time = time_stamp.split()[1]\n\n    assert re.match(r'[\\d]{4}-[\\d]{2}-[\\d]{2}', date) is not None\n\n    time_before_dot = time.split('.')[0]\n    time_after_dot = time.split('.')[1]\n\n    assert len(time.split('.')) == 2\n    assert re.match(r'[\\d]{2}:[\\d]{2}:[\\d]{2}', time_before_dot) is not None\n    assert time_after_dot.isdigit()"
            },
            "tests/test_printing_logger.py::test_check_simple_output[exception- * EXCEPTION * kek]": {
                "testid": "tests/test_printing_logger.py::test_check_simple_output[exception- * EXCEPTION * kek]",
                "result": "passed",
                "test_implementation": "def test_check_simple_output(method, result_tail):\n    # this code is adapted from there: https://stackoverflow.com/a/66683635\n    remove_suffix = lambda input_string, suffix: input_string[:-len(suffix)] if suffix and input_string.endswith(suffix) else input_string  # noqa: E731\n\n    buffer = io.StringIO()\n    with redirect_stdout(buffer):\n        method('kek')\n\n    printed = buffer.getvalue()\n\n    assert printed.endswith(result_tail + '\\n')\n\n    time_stamp = remove_suffix(printed, result_tail + '\\n') # expected format: 2024-07-08 19:09:48.226667\n\n    assert len(time_stamp.split()) == 2\n\n    date = time_stamp.split()[0]\n    time = time_stamp.split()[1]\n\n    assert re.match(r'[\\d]{4}-[\\d]{2}-[\\d]{2}', date) is not None\n\n    time_before_dot = time.split('.')[0]\n    time_after_dot = time.split('.')[1]\n\n    assert len(time.split('.')) == 2\n    assert re.match(r'[\\d]{2}:[\\d]{2}:[\\d]{2}', time_before_dot) is not None\n    assert time_after_dot.isdigit()"
            },
            "tests/test_printing_logger.py::test_check_simple_output[critical- * CRITICAL  * kek]": {
                "testid": "tests/test_printing_logger.py::test_check_simple_output[critical- * CRITICAL  * kek]",
                "result": "passed",
                "test_implementation": "def test_check_simple_output(method, result_tail):\n    # this code is adapted from there: https://stackoverflow.com/a/66683635\n    remove_suffix = lambda input_string, suffix: input_string[:-len(suffix)] if suffix and input_string.endswith(suffix) else input_string  # noqa: E731\n\n    buffer = io.StringIO()\n    with redirect_stdout(buffer):\n        method('kek')\n\n    printed = buffer.getvalue()\n\n    assert printed.endswith(result_tail + '\\n')\n\n    time_stamp = remove_suffix(printed, result_tail + '\\n') # expected format: 2024-07-08 19:09:48.226667\n\n    assert len(time_stamp.split()) == 2\n\n    date = time_stamp.split()[0]\n    time = time_stamp.split()[1]\n\n    assert re.match(r'[\\d]{4}-[\\d]{2}-[\\d]{2}', date) is not None\n\n    time_before_dot = time.split('.')[0]\n    time_after_dot = time.split('.')[1]\n\n    assert len(time.split('.')) == 2\n    assert re.match(r'[\\d]{2}:[\\d]{2}:[\\d]{2}', time_before_dot) is not None\n    assert time_after_dot.isdigit()"
            },
            "tests/test_printing_logger.py::test_forward_output[<lambda>- | DEBUG     | kek]": {
                "testid": "tests/test_printing_logger.py::test_forward_output[<lambda>- | DEBUG     | kek]",
                "result": "passed",
                "test_implementation": "def test_forward_output(get_method, result_tail):\n    # this code is adapted from there: https://stackoverflow.com/a/66683635\n    remove_suffix = lambda input_string, suffix: input_string[:-len(suffix)] if suffix and input_string.endswith(suffix) else input_string  # noqa: E731\n\n    counter = 0\n    last_line = ''\n\n    def callback(line):\n        nonlocal counter\n        nonlocal last_line\n        counter += 1\n        last_line = line\n\n    logger = PrintingLogger(printing_callback=callback)\n    method = get_method(logger)\n\n    buffer = io.StringIO()\n    with redirect_stdout(buffer):\n        method('kek')\n\n    assert buffer.getvalue() == ''\n\n    assert last_line.endswith(result_tail + '\\n')\n\n    time_stamp = remove_suffix(last_line, result_tail + '\\n') # expected format: 2024-07-08 19:09:48.226667\n\n    assert len(time_stamp.split()) == 2\n\n    date = time_stamp.split()[0]\n    time = time_stamp.split()[1]\n\n    assert re.match(r'[\\d]{4}-[\\d]{2}-[\\d]{2}', date) is not None\n\n    time_before_dot = time.split('.')[0]\n    time_after_dot = time.split('.')[1]\n\n    assert len(time.split('.')) == 2\n    assert re.match(r'[\\d]{2}:[\\d]{2}:[\\d]{2}', time_before_dot) is not None\n    assert time_after_dot.isdigit()"
            },
            "tests/test_printing_logger.py::test_forward_output[<lambda>- | INFO      | kek]": {
                "testid": "tests/test_printing_logger.py::test_forward_output[<lambda>- | INFO      | kek]",
                "result": "passed",
                "test_implementation": "def test_forward_output(get_method, result_tail):\n    # this code is adapted from there: https://stackoverflow.com/a/66683635\n    remove_suffix = lambda input_string, suffix: input_string[:-len(suffix)] if suffix and input_string.endswith(suffix) else input_string  # noqa: E731\n\n    counter = 0\n    last_line = ''\n\n    def callback(line):\n        nonlocal counter\n        nonlocal last_line\n        counter += 1\n        last_line = line\n\n    logger = PrintingLogger(printing_callback=callback)\n    method = get_method(logger)\n\n    buffer = io.StringIO()\n    with redirect_stdout(buffer):\n        method('kek')\n\n    assert buffer.getvalue() == ''\n\n    assert last_line.endswith(result_tail + '\\n')\n\n    time_stamp = remove_suffix(last_line, result_tail + '\\n') # expected format: 2024-07-08 19:09:48.226667\n\n    assert len(time_stamp.split()) == 2\n\n    date = time_stamp.split()[0]\n    time = time_stamp.split()[1]\n\n    assert re.match(r'[\\d]{4}-[\\d]{2}-[\\d]{2}', date) is not None\n\n    time_before_dot = time.split('.')[0]\n    time_after_dot = time.split('.')[1]\n\n    assert len(time.split('.')) == 2\n    assert re.match(r'[\\d]{2}:[\\d]{2}:[\\d]{2}', time_before_dot) is not None\n    assert time_after_dot.isdigit()"
            },
            "tests/test_printing_logger.py::test_forward_output[<lambda>- | WARNING   | kek]": {
                "testid": "tests/test_printing_logger.py::test_forward_output[<lambda>- | WARNING   | kek]",
                "result": "passed",
                "test_implementation": "def test_forward_output(get_method, result_tail):\n    # this code is adapted from there: https://stackoverflow.com/a/66683635\n    remove_suffix = lambda input_string, suffix: input_string[:-len(suffix)] if suffix and input_string.endswith(suffix) else input_string  # noqa: E731\n\n    counter = 0\n    last_line = ''\n\n    def callback(line):\n        nonlocal counter\n        nonlocal last_line\n        counter += 1\n        last_line = line\n\n    logger = PrintingLogger(printing_callback=callback)\n    method = get_method(logger)\n\n    buffer = io.StringIO()\n    with redirect_stdout(buffer):\n        method('kek')\n\n    assert buffer.getvalue() == ''\n\n    assert last_line.endswith(result_tail + '\\n')\n\n    time_stamp = remove_suffix(last_line, result_tail + '\\n') # expected format: 2024-07-08 19:09:48.226667\n\n    assert len(time_stamp.split()) == 2\n\n    date = time_stamp.split()[0]\n    time = time_stamp.split()[1]\n\n    assert re.match(r'[\\d]{4}-[\\d]{2}-[\\d]{2}', date) is not None\n\n    time_before_dot = time.split('.')[0]\n    time_after_dot = time.split('.')[1]\n\n    assert len(time.split('.')) == 2\n    assert re.match(r'[\\d]{2}:[\\d]{2}:[\\d]{2}', time_before_dot) is not None\n    assert time_after_dot.isdigit()"
            },
            "tests/test_printing_logger.py::test_forward_output[<lambda>- | ERROR     | kek]": {
                "testid": "tests/test_printing_logger.py::test_forward_output[<lambda>- | ERROR     | kek]",
                "result": "passed",
                "test_implementation": "def test_forward_output(get_method, result_tail):\n    # this code is adapted from there: https://stackoverflow.com/a/66683635\n    remove_suffix = lambda input_string, suffix: input_string[:-len(suffix)] if suffix and input_string.endswith(suffix) else input_string  # noqa: E731\n\n    counter = 0\n    last_line = ''\n\n    def callback(line):\n        nonlocal counter\n        nonlocal last_line\n        counter += 1\n        last_line = line\n\n    logger = PrintingLogger(printing_callback=callback)\n    method = get_method(logger)\n\n    buffer = io.StringIO()\n    with redirect_stdout(buffer):\n        method('kek')\n\n    assert buffer.getvalue() == ''\n\n    assert last_line.endswith(result_tail + '\\n')\n\n    time_stamp = remove_suffix(last_line, result_tail + '\\n') # expected format: 2024-07-08 19:09:48.226667\n\n    assert len(time_stamp.split()) == 2\n\n    date = time_stamp.split()[0]\n    time = time_stamp.split()[1]\n\n    assert re.match(r'[\\d]{4}-[\\d]{2}-[\\d]{2}', date) is not None\n\n    time_before_dot = time.split('.')[0]\n    time_after_dot = time.split('.')[1]\n\n    assert len(time.split('.')) == 2\n    assert re.match(r'[\\d]{2}:[\\d]{2}:[\\d]{2}', time_before_dot) is not None\n    assert time_after_dot.isdigit()"
            },
            "tests/test_printing_logger.py::test_forward_output[<lambda>- | EXCEPTION | kek]": {
                "testid": "tests/test_printing_logger.py::test_forward_output[<lambda>- | EXCEPTION | kek]",
                "result": "passed",
                "test_implementation": "def test_forward_output(get_method, result_tail):\n    # this code is adapted from there: https://stackoverflow.com/a/66683635\n    remove_suffix = lambda input_string, suffix: input_string[:-len(suffix)] if suffix and input_string.endswith(suffix) else input_string  # noqa: E731\n\n    counter = 0\n    last_line = ''\n\n    def callback(line):\n        nonlocal counter\n        nonlocal last_line\n        counter += 1\n        last_line = line\n\n    logger = PrintingLogger(printing_callback=callback)\n    method = get_method(logger)\n\n    buffer = io.StringIO()\n    with redirect_stdout(buffer):\n        method('kek')\n\n    assert buffer.getvalue() == ''\n\n    assert last_line.endswith(result_tail + '\\n')\n\n    time_stamp = remove_suffix(last_line, result_tail + '\\n') # expected format: 2024-07-08 19:09:48.226667\n\n    assert len(time_stamp.split()) == 2\n\n    date = time_stamp.split()[0]\n    time = time_stamp.split()[1]\n\n    assert re.match(r'[\\d]{4}-[\\d]{2}-[\\d]{2}', date) is not None\n\n    time_before_dot = time.split('.')[0]\n    time_after_dot = time.split('.')[1]\n\n    assert len(time.split('.')) == 2\n    assert re.match(r'[\\d]{2}:[\\d]{2}:[\\d]{2}', time_before_dot) is not None\n    assert time_after_dot.isdigit()"
            },
            "tests/test_printing_logger.py::test_forward_output[<lambda>- | CRITICAL  | kek]": {
                "testid": "tests/test_printing_logger.py::test_forward_output[<lambda>- | CRITICAL  | kek]",
                "result": "passed",
                "test_implementation": "def test_forward_output(get_method, result_tail):\n    # this code is adapted from there: https://stackoverflow.com/a/66683635\n    remove_suffix = lambda input_string, suffix: input_string[:-len(suffix)] if suffix and input_string.endswith(suffix) else input_string  # noqa: E731\n\n    counter = 0\n    last_line = ''\n\n    def callback(line):\n        nonlocal counter\n        nonlocal last_line\n        counter += 1\n        last_line = line\n\n    logger = PrintingLogger(printing_callback=callback)\n    method = get_method(logger)\n\n    buffer = io.StringIO()\n    with redirect_stdout(buffer):\n        method('kek')\n\n    assert buffer.getvalue() == ''\n\n    assert last_line.endswith(result_tail + '\\n')\n\n    time_stamp = remove_suffix(last_line, result_tail + '\\n') # expected format: 2024-07-08 19:09:48.226667\n\n    assert len(time_stamp.split()) == 2\n\n    date = time_stamp.split()[0]\n    time = time_stamp.split()[1]\n\n    assert re.match(r'[\\d]{4}-[\\d]{2}-[\\d]{2}', date) is not None\n\n    time_before_dot = time.split('.')[0]\n    time_after_dot = time.split('.')[1]\n\n    assert len(time.split('.')) == 2\n    assert re.match(r'[\\d]{2}:[\\d]{2}:[\\d]{2}', time_before_dot) is not None\n    assert time_after_dot.isdigit()"
            },
            "tests/test_printing_logger.py::test_multiple_lines[debug- | DEBUG     | kek]": {
                "testid": "tests/test_printing_logger.py::test_multiple_lines[debug- | DEBUG     | kek]",
                "result": "passed",
                "test_implementation": "def test_multiple_lines(method, result_tail):\n    number_of_iterations = 10\n    lines = []\n\n    for number in range(number_of_iterations):\n        buffer = io.StringIO()\n        with redirect_stdout(buffer):\n            method('kek')\n\n        lines.append(buffer.getvalue())\n\n    assert len(lines) == number_of_iterations\n\n    assert all([x.endswith(result_tail + '\\n') for x in lines])"
            },
            "tests/test_printing_logger.py::test_multiple_lines[info- | INFO      | kek]": {
                "testid": "tests/test_printing_logger.py::test_multiple_lines[info- | INFO      | kek]",
                "result": "passed",
                "test_implementation": "def test_multiple_lines(method, result_tail):\n    number_of_iterations = 10\n    lines = []\n\n    for number in range(number_of_iterations):\n        buffer = io.StringIO()\n        with redirect_stdout(buffer):\n            method('kek')\n\n        lines.append(buffer.getvalue())\n\n    assert len(lines) == number_of_iterations\n\n    assert all([x.endswith(result_tail + '\\n') for x in lines])"
            },
            "tests/test_printing_logger.py::test_multiple_lines[warning- | WARNING   | kek]": {
                "testid": "tests/test_printing_logger.py::test_multiple_lines[warning- | WARNING   | kek]",
                "result": "passed",
                "test_implementation": "def test_multiple_lines(method, result_tail):\n    number_of_iterations = 10\n    lines = []\n\n    for number in range(number_of_iterations):\n        buffer = io.StringIO()\n        with redirect_stdout(buffer):\n            method('kek')\n\n        lines.append(buffer.getvalue())\n\n    assert len(lines) == number_of_iterations\n\n    assert all([x.endswith(result_tail + '\\n') for x in lines])"
            },
            "tests/test_printing_logger.py::test_multiple_lines[error- | ERROR     | kek]": {
                "testid": "tests/test_printing_logger.py::test_multiple_lines[error- | ERROR     | kek]",
                "result": "passed",
                "test_implementation": "def test_multiple_lines(method, result_tail):\n    number_of_iterations = 10\n    lines = []\n\n    for number in range(number_of_iterations):\n        buffer = io.StringIO()\n        with redirect_stdout(buffer):\n            method('kek')\n\n        lines.append(buffer.getvalue())\n\n    assert len(lines) == number_of_iterations\n\n    assert all([x.endswith(result_tail + '\\n') for x in lines])"
            },
            "tests/test_printing_logger.py::test_multiple_lines[exception- | EXCEPTION | kek]": {
                "testid": "tests/test_printing_logger.py::test_multiple_lines[exception- | EXCEPTION | kek]",
                "result": "passed",
                "test_implementation": "def test_multiple_lines(method, result_tail):\n    number_of_iterations = 10\n    lines = []\n\n    for number in range(number_of_iterations):\n        buffer = io.StringIO()\n        with redirect_stdout(buffer):\n            method('kek')\n\n        lines.append(buffer.getvalue())\n\n    assert len(lines) == number_of_iterations\n\n    assert all([x.endswith(result_tail + '\\n') for x in lines])"
            },
            "tests/test_printing_logger.py::test_multiple_lines[critical- | CRITICAL  | kek]": {
                "testid": "tests/test_printing_logger.py::test_multiple_lines[critical- | CRITICAL  | kek]",
                "result": "passed",
                "test_implementation": "def test_multiple_lines(method, result_tail):\n    number_of_iterations = 10\n    lines = []\n\n    for number in range(number_of_iterations):\n        buffer = io.StringIO()\n        with redirect_stdout(buffer):\n            method('kek')\n\n        lines.append(buffer.getvalue())\n\n    assert len(lines) == number_of_iterations\n\n    assert all([x.endswith(result_tail + '\\n') for x in lines])"
            },
            "tests/test_printing_logger.py::test_repr_printing_logger": {
                "testid": "tests/test_printing_logger.py::test_repr_printing_logger",
                "result": "passed",
                "test_implementation": "def test_repr_printing_logger():\n    assert repr(PrintingLogger()) == 'PrintingLogger()'"
            },
            "tests/test_protocols.py::test_positive_examples_of_runtime_check": {
                "testid": "tests/test_protocols.py::test_positive_examples_of_runtime_check",
                "result": "passed",
                "test_implementation": "def test_positive_examples_of_runtime_check():\n    assert isinstance(logging, LoggerProtocol)\n    assert isinstance(logging.getLogger('kek'), LoggerProtocol)\n    assert isinstance(logging.getLogger('lol'), LoggerProtocol)\n    assert isinstance(EmptyLogger(), LoggerProtocol)\n    assert isinstance(LoggersGroup(), LoggerProtocol)\n    assert isinstance(MemoryLogger(), LoggerProtocol)\n    assert isinstance(PrintingLogger(), LoggerProtocol)"
            },
            "tests/test_protocols.py::test_negative_examples_of_runtime_check": {
                "testid": "tests/test_protocols.py::test_negative_examples_of_runtime_check",
                "result": "passed",
                "test_implementation": "def test_negative_examples_of_runtime_check():\n    assert not isinstance(1, LoggerProtocol)\n    assert not isinstance('logging', LoggerProtocol)"
            },
            "tests/test_protocols.py::test_loguru_logger_is_logger": {
                "testid": "tests/test_protocols.py::test_loguru_logger_is_logger",
                "result": "passed",
                "test_implementation": "def test_loguru_logger_is_logger():\n    assert isinstance(loguru_logger, LoggerProtocol)"
            }
        },
        "SRS_document": "# Software Requirements Specification: `emptylog` Logging Library\n\n## 1. Introduction\n\n### 1.1 Purpose\nThis Software Requirements Specification (SRS) document provides a comprehensive description of the functionalities for the `emptylog` Python library. Its primary purpose is to serve as the sole source of requirements for software developers who will implement the library. Developer success will be measured by their implementation passing a complete set of test cases (public and private), based on their interpretation of this SRS. Therefore, this document prioritizes clarity, comprehensiveness regarding functionality, and an appropriate level of abstraction, focusing on *what* the system must do rather than *how* it is implemented internally.\n\n### 1.2 Scope\nThe scope of this SRS covers the `emptylog` library, which includes:\n*   A universal logger protocol definition.\n*   An `EmptyLogger` implementation that performs no operations.\n*   A `MemoryLogger` implementation that records log calls for inspection.\n*   A `PrintingLogger` implementation that outputs log messages to the console.\n*   A `LoggersGroup` mechanism for combining multiple loggers, which itself acts as a logger.\n*   The ability to combine library-provided loggers with each other and with external logger objects that conform to the logger protocol.\n\nThe library is intended to extend the capabilities of standard Python logging, with a strong emphasis on making logging easily testable.\n\n### 1.3 Definitions, Acronyms, and Abbreviations\n*   **SRS**: Software Requirements Specification.\n*   **Logger**: An object that provides methods for recording messages at different severity levels.\n*   **Logger Protocol**: A defined interface specifying a set of standard logging methods that logger objects must implement.\n*   **Log Level**: A category indicating the severity or nature of a log message (e.g., DEBUG, INFO, WARNING, ERROR, EXCEPTION, CRITICAL).\n*   **Log Message**: The primary string content associated with a log event.\n*   **Positional Arguments (`*args`)**: Additional unnamed arguments passed to a logging method.\n*   **Keyword Arguments (`**kwargs`)**: Additional named arguments passed to a logging method.\n\n### 1.4 References\n*   The original README.md for the `emptylog` project (provides contextual overview).\n*   The original test suite for the `emptylog` project (informs functional requirements and their verification).\n\n### 1.5 Overview\nThis SRS is organized into three main sections:\n*   **Section 1 (Introduction):** Provides background, scope, definitions, and an overview of the document.\n*   **Section 2 (Overall Description):** Describes the product perspective, its key features, intended users, and any high-level constraints or assumptions.\n*   **Section 3 (Specific Requirements):** Details all requirements, categorized into Interface Requirements, Functional Requirements, and Non-Functional Requirements. Functional requirements are the core of this document, describing the system's behavior and capabilities.\n\n## 2. Overall Description\n\n### 2.1 Product Perspective\nThe `emptylog` library is a Python package designed to enhance and supplement Python's built-in logging capabilities. It focuses on providing logger implementations that are particularly useful for testing and development, allowing developers to verify logging behavior as part of their automated tests. It also introduces a common protocol for logger objects to promote interoperability.\n\n### 2.2 Product Features\nThe `emptylog` library provides the following key features:\n1.  **Universal Logger Protocol:** A runtime-checkable protocol defining standard logging methods.\n2.  **Empty Logger:** A \"no-op\" logger implementation.\n3.  **Memory Logger:** A logger that stores all log calls in memory for later inspection.\n4.  **Printing Logger:** A simple logger that prints formatted log messages to the standard output or a custom callback.\n5.  **Logger Summation/Grouping:** Allows multiple logger objects (from this library or external) to be combined into a single logger group, which dispatches calls to all its members.\n\n### 2.3 User Characteristics\nThe primary users of the `emptylog` library are Python developers who need to:\n*   Implement logging in their applications or libraries.\n*   Write tests to verify logging behavior.\n*   Use a flexible logging solution that can be adapted for different contexts (e.g., disabling logging easily, capturing logs for tests, simple console output).\n\n### 2.4 Constraints\n*   The system shall be developed in Python.\n*   The system should be compatible with Python versions that support `typing.Protocol` and `typing.runtime_checkable` (either natively or via `typing_extensions`).\n\n### 2.5 Assumptions and Dependencies\n*   Developers using this library will have a Python environment set up.\n*   The library's core functionality does not depend on external packages beyond the Python standard library and `typing_extensions` (for compatibility with older Python versions).\n\n## 3. Specific Requirements\n\n### 3.1 Interface Requirements\n\n#### 3.1.1 Logger Protocol Definition\nThe system shall define a logger protocol that specifies the interface for all logger objects.\n\n*   **IR-LP-1:** The logger protocol shall define the following six logging methods, each accepting a `message` string, variable positional arguments (`*args`), and variable keyword arguments (`**kwargs`), and returning no value (`None`):\n    *   `debug(message: str, *args: Any, **kwargs: Any) -> None`\n    *   `info(message: str, *args: Any, **kwargs: Any) -> None`\n    *   `warning(message: str, *args: Any, **kwargs: Any) -> None`\n    *   `error(message: str, *args: Any, **kwargs: Any) -> None`\n    *   `exception(message: str, *args: Any, **kwargs: Any) -> None`\n    *   `critical(message: str, *args: Any, **kwargs: Any) -> None`\n*   **IR-LP-2:** The logger protocol shall be runtime-checkable using `isinstance()`. Objects implementing the specified six logging methods with compatible signatures shall be considered instances of this protocol.\n*   **IR-LP-3:** Objects that do not implement the logger protocol shall not be considered instances of this protocol when checked with `isinstance()`.\n### 3.2 Functional Requirements\n\n#### 3.2.1 General Logger Characteristics\nThe following requirements apply to `EmptyLogger`, `MemoryLogger`, `PrintingLogger`, and `LoggersGroup` provided by this library.\n\n*   **FR-GEN-1:** Each logger type (`EmptyLogger`, `MemoryLogger`, `PrintingLogger`, `LoggersGroup`) shall implement the `LoggerProtocol` (as defined in IR-LP-1).\n*   **FR-GEN-2:** Each logger type shall provide a canonical string representation (e.g., via `repr()`) that identifies the logger's type. For `LoggersGroup`, this representation should also indicate the contained loggers.\n#### 3.2.2 Empty Logger\nThe system shall provide an `EmptyLogger`.\n\n*   **FR-EL-1:** The `EmptyLogger` shall implement all logging methods (`debug`, `info`, `warning`, `error`, `exception`, `critical`) as defined in the `LoggerProtocol` (IR-LP-1).\n*   **FR-EL-2:** Calling any logging method on an `EmptyLogger` instance shall perform no action and have no observable side effects (e.g., no output, no data storage, no exceptions raised for valid calls).\n#### 3.2.3 Memory Logger\nThe system shall provide a `MemoryLogger` that records log calls.\n\n*   **FR-ML-1:** The `MemoryLogger` shall implement all logging methods (`debug`, `info`, `warning`, `error`, `exception`, `critical`) as defined in the `LoggerProtocol` (IR-LP-1).\n*   **FR-ML-2:** Each call to a logging method on a `MemoryLogger` instance shall be recorded.\n*   **FR-ML-3:** Each recorded log call shall store:\n    1.  The original log message string.\n    2.  A tuple of the positional arguments (`*args`) passed to the logging method.\n    3.  A dictionary of the keyword arguments (`**kwargs`) passed to the logging method.\n*   **FR-ML-4:** Recorded log calls shall be organized and retrievable by the log level of the method that was called (e.g., all calls to `debug()` are stored together, all calls to `info()` are stored together).\n    *   The `MemoryLogger` shall expose a container for these recorded calls (e.g., an attribute, referred to as `data` in README/tests).\n    *   This container shall have distinct attributes for each log level (`debug`, `info`, `warning`, `error`, `exception`, `critical`).\n    *   Each of these level-specific attributes shall hold a list of the corresponding recorded log calls (as described in FR-ML-3), in the order they were received.\n*   **FR-ML-5:** The `MemoryLogger` shall provide a mechanism to determine the total number of log calls recorded across all levels (e.g., via `len()` on its `data` attribute).\n#### 3.2.4 Printing Logger\nThe system shall provide a `PrintingLogger` that outputs log messages.\n\n*   **FR-PL-1:** The `PrintingLogger` shall implement all logging methods (`debug`, `info`, `warning`, `error`, `exception`, `critical`) as defined in the `LoggerProtocol` (IR-LP-1).\n*   **FR-PL-2:** When a logging method is called on a `PrintingLogger` instance, it shall generate a formatted string and output it.\n*   **FR-PL-3:** The default output format for the log string shall be: `\"{timestamp} {separator} {level} {separator} {message}\\n\"`.\n    *   `{timestamp}`: The current date and time of the log call. Must include year, month, day, hour, minute, second, and sub-second (microsecond) precision.\n    *   `{separator}`: A separator string, configurable at logger initialization (default is `|`).\n    *   `{level}`: The log level name (e.g., \"DEBUG\", \"INFO\"), left-justified and padded with spaces to a consistent width (9 characters).\n    *   `{message}`: The original log message string passed to the logging method. Positional (`*args`) and keyword (`**kwargs`) arguments are not used for message formatting.\n    *   The string must end with a newline character.\n*   **FR-PL-4:** The `PrintingLogger` shall allow configuration of the separator string used in the output format during its initialization.\n*   **FR-PL-5:** By default, the `PrintingLogger` shall output the formatted log string to the standard output (e.g., using `print()`).\n*   **FR-PL-6:** The `PrintingLogger` shall allow a custom callback function to be provided during its initialization. If provided, this callback function shall be invoked with the formatted log string (including the trailing newline) instead of printing to standard output.\n#### 3.2.5 Logger Group (`LoggersGroup`)\nThe system shall provide a `LoggersGroup` that combines multiple loggers.\n\n*   **FR-LG-1:** A `LoggersGroup` shall implement all logging methods (`debug`, `info`, `warning`, `error`, `exception`, `critical`) as defined in the `LoggerProtocol` (IR-LP-1).\n*   **FR-LG-2:** A `LoggersGroup` can be instantiated by providing zero or more logger objects (which must conform to `LoggerProtocol`) as arguments.\n*   **FR-LG-3:** If any argument provided during `LoggersGroup` instantiation is not a `LoggerProtocol`-compliant object, the system shall raise a `TypeError`. The error message should indicate the problematic argument and its type.\n*   **FR-LG-4:** When a logging method is called on a `LoggersGroup` instance, the group shall call the same logging method on each of its contained logger objects, forwarding the original `message`, `*args`, and `**kwargs`.\n    *   The calls to contained loggers should occur in the order the loggers were provided during the group's instantiation or addition.\n*   **FR-LG-5:** The system shall allow determination of the number of loggers contained within a `LoggersGroup` instance (e.g., via `len()`).\n*   **FR-LG-6:** A `LoggersGroup` instance shall be iterable, yielding its contained logger objects in the order they were added/defined.\n#### 3.2.6 Logger Combination (Addition)\nThe system shall allow loggers to be combined using the addition operator (`+`).\n\n*   **FR-LC-1:** The addition operator (`+`) shall be supported between two `LoggerProtocol`-compliant objects.\n    *   This includes addition between instances of `EmptyLogger`, `MemoryLogger`, `PrintingLogger`, `LoggersGroup`, and compatible external loggers.\n*   **FR-LC-2:** The result of adding two logger objects shall be a new `LoggersGroup` instance.\n*   **FR-LC-3:** If `loggerA` is added to `loggerB` (`loggerA + loggerB`), the resulting `LoggersGroup` shall contain `loggerA` first, then `loggerB`.\n    *   If `loggerA` is itself a `LoggersGroup`, its contained loggers are added, followed by `loggerB` (or its contained loggers if `loggerB` is also a group). The resulting group should be \"flat\" (not nested `LoggersGroup` instances within the `loggers` collection of the outer group).\n*   **FR-LC-4:** Adding multiple loggers sequentially (e.g., `logger1 + logger2 + logger3`) shall result in a single `LoggersGroup` containing all operand loggers in the order of addition, maintaining a flat structure.\n*   **FR-LC-5:** Attempting to add a `LoggerProtocol`-compliant object with an object that does not conform to the `LoggerProtocol` (on either side of the `+` operator) shall result in a `NotImplementedError` (or a `TypeError` if the non-logger type doesn't implement reverse addition).\n### 3.3 Non-Functional Requirements\nThere are no non-functional requirements explicitly specified or validated by dedicated test cases in the provided materials. All requirements are functional or interface-related.\n\n*(Self-correction during thought process: The `Lock` in `LoggersGroup` suggests an intent for thread-safety. However, as per the strict rule \"NFRs are ONLY included if directly verified by a test case,\" and the absence of explicit concurrency tests, this cannot be listed as an NFR. The lock is an implementation detail ensuring FR-LG-4 functions correctly under potential concurrency, rather than a tested NFR itself.)*",
        "structured_requirements": [
            {
                "requirement_id": "IR-LP-1",
                "requirement_description": "The logger protocol shall define the following six logging methods, each accepting a `message` string, variable positional arguments (`*args`), and variable keyword arguments (`**kwargs`), and returning no value (`None`):\n    *   `debug(message: str, *args: Any, **kwargs: Any) -> None`\n    *   `info(message: str, *args: Any, **kwargs: Any) -> None`\n    *   `warning(message: str, *args: Any, **kwargs: Any) -> None`\n    *   `error(message: str, *args: Any, **kwargs: Any) -> None`\n    *   `exception(message: str, *args: Any, **kwargs: Any) -> None`\n    *   `critical(message: str, *args: Any, **kwargs: Any) -> None`",
                "test_traceability": [
                    {
                        "id": "tests/test_protocols.py::test_positive_examples_of_runtime_check",
                        "description": ""
                    },
                    {
                        "id": "tests/test_empty_logger.py::test_search_callable_attributes",
                        "description": ""
                    },
                    {
                        "id": "tests/test_memory_logger.py::test_memory_logger_is_working",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/protocols.py::LoggerProtocol",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "IR-LP-2",
                "requirement_description": "The logger protocol shall be runtime-checkable using `isinstance()`. Objects implementing the specified six logging methods with compatible signatures shall be considered instances of this protocol.",
                "test_traceability": [
                    {
                        "id": "tests/test_protocols.py::test_positive_examples_of_runtime_check",
                        "description": ""
                    },
                    {
                        "id": "tests/test_protocols.py::test_loguru_logger_is_logger",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/protocols.py::LoggerProtocol",
                        "description": "due to @runtime_checkable"
                    }
                ]
            },
            {
                "requirement_id": "IR-LP-3",
                "requirement_description": "Objects that do not implement the logger protocol shall not be considered instances of this protocol when checked with `isinstance()`.",
                "test_traceability": [
                    {
                        "id": "tests/test_protocols.py::test_negative_examples_of_runtime_check",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/protocols.py::LoggerProtocol",
                        "description": "due to @runtime_checkable"
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-1",
                "requirement_description": "Each logger type (`EmptyLogger`, `MemoryLogger`, `PrintingLogger`, `LoggersGroup`) shall implement the `LoggerProtocol` (as defined in IR-LP-1).",
                "test_traceability": [
                    {
                        "id": "tests/test_protocols.py::test_positive_examples_of_runtime_check",
                        "description": ""
                    },
                    {
                        "id": "tests/test_memory_logger.py::test_memory_logger_is_logger",
                        "description": ""
                    },
                    {
                        "id": "tests/test_printing_logger.py::test_printing_logger_is_logger",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/empty_logger.py::EmptyLogger",
                        "description": ""
                    },
                    {
                        "id": "emptylog/memory_logger.py::MemoryLogger",
                        "description": ""
                    },
                    {
                        "id": "emptylog/printing_logger.py::PrintingLogger",
                        "description": ""
                    },
                    {
                        "id": "emptylog/loggers_group.py::LoggersGroup",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-2",
                "requirement_description": "Each logger type shall provide a canonical string representation (e.g., via `repr()`) that identifies the logger's type. For `LoggersGroup`, this representation should also indicate the contained loggers.",
                "test_traceability": [
                    {
                        "id": "tests/test_empty_logger.py::test_repr_empty_logger",
                        "description": ""
                    },
                    {
                        "id": "tests/test_memory_logger.py::test_repr_memory_logger",
                        "description": ""
                    },
                    {
                        "id": "tests/test_printing_logger.py::test_repr_printing_logger",
                        "description": ""
                    },
                    {
                        "id": "tests/test_loggers_group.py::test_repr_loggers_group",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/abstract_logger.py::AbstractLogger::__repr__",
                        "description": ""
                    },
                    {
                        "id": "emptylog/loggers_group.py::LoggersGroup::__repr__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EL-1",
                "requirement_description": "The `EmptyLogger` shall implement all logging methods (`debug`, `info`, `warning`, `error`, `exception`, `critical`) as defined in the `LoggerProtocol` (IR-LP-1).",
                "test_traceability": [
                    {
                        "id": "tests/test_empty_logger.py::test_search_callable_attributes",
                        "description": "verifies callability"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/empty_logger.py::EmptyLogger",
                        "description": "inherits methods that do nothing by default from Protocol if not overridden, but EmptyLogger is a direct pass-through to AbstractLogger which implements Protocol"
                    },
                    {
                        "id": "emptylog/abstract_logger.py::AbstractLogger",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EL-2",
                "requirement_description": "Calling any logging method on an `EmptyLogger` instance shall perform no action and have no observable side effects (e.g., no output, no data storage, no exceptions raised for valid calls).",
                "test_traceability": [
                    {
                        "id": "tests/test_empty_logger.py::test_search_callable_attributes",
                        "description": "implicitly tests no exceptions"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/empty_logger.py::EmptyLogger",
                        "description": "by not implementing any specific logic in its methods"
                    }
                ]
            },
            {
                "requirement_id": "FR-ML-1",
                "requirement_description": "The `MemoryLogger` shall implement all logging methods (`debug`, `info`, `warning`, `error`, `exception`, `critical`) as defined in the `LoggerProtocol` (IR-LP-1).",
                "test_traceability": [
                    {
                        "id": "tests/test_memory_logger.py::test_memory_logger_is_working",
                        "description": "verifies callability for all methods"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/memory_logger.py::MemoryLogger",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ML-2",
                "requirement_description": "Each call to a logging method on a `MemoryLogger` instance shall be recorded.",
                "test_traceability": [
                    {
                        "id": "tests/test_memory_logger.py::test_memory_logger_is_working",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/memory_logger.py::MemoryLogger::debug",
                        "description": ""
                    },
                    {
                        "id": "::info",
                        "description": ""
                    },
                    {
                        "id": "::warning",
                        "description": ""
                    },
                    {
                        "id": "::error",
                        "description": ""
                    },
                    {
                        "id": "::exception",
                        "description": ""
                    },
                    {
                        "id": "::critical",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ML-3",
                "requirement_description": "Each recorded log call shall store:\n    1.  The original log message string.\n    2.  A tuple of the positional arguments (`*args`) passed to the logging method.\n    3.  A dictionary of the keyword arguments (`**kwargs`) passed to the logging method.",
                "test_traceability": [
                    {
                        "id": "tests/test_memory_logger.py::test_memory_logger_is_working",
                        "description": ""
                    },
                    {
                        "id": "tests/test_call_data.py::test_create_call_data_and_check_the_data",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/memory_logger.py::MemoryLogger",
                        "description": "methods use `LoggerCallData`"
                    },
                    {
                        "id": "emptylog/call_data.py::LoggerCallData",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ML-4",
                "requirement_description": "Recorded log calls shall be organized and retrievable by the log level of the method that was called (e.g., all calls to `debug()` are stored together, all calls to `info()` are stored together).\n    *   The `MemoryLogger` shall expose a container for these recorded calls (e.g., an attribute, referred to as `data` in README/tests).\n    *   This container shall have distinct attributes for each log level (`debug`, `info`, `warning`, `error`, `exception`, `critical`).\n    *   Each of these level-specific attributes shall hold a list of the corresponding recorded log calls (as described in FR-ML-3), in the order they were received.",
                "test_traceability": [
                    {
                        "id": "tests/test_memory_logger.py::test_memory_logger_is_working",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/memory_logger.py::MemoryLogger",
                        "description": "initializes and uses `LoggerAccumulatedData`"
                    },
                    {
                        "id": "emptylog/accumulated_data.py::LoggerAccumulatedData",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ML-5",
                "requirement_description": "The `MemoryLogger` shall provide a mechanism to determine the total number of log calls recorded across all levels (e.g., via `len()` on its `data` attribute).",
                "test_traceability": [
                    {
                        "id": "tests/test_accumulated_data.py::test_fill_accumulated_data_and_check_size",
                        "description": "tests `LoggerAccumulatedData`, which is used by `MemoryLogger`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/accumulated_data.py::LoggerAccumulatedData::__len__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PL-1",
                "requirement_description": "The `PrintingLogger` shall implement all logging methods (`debug`, `info`, `warning`, `error`, `exception`, `critical`) as defined in the `LoggerProtocol` (IR-LP-1).",
                "test_traceability": [
                    {
                        "id": "tests/test_printing_logger.py::test_printing_logger_is_logger",
                        "description": ""
                    },
                    {
                        "id": "tests/test_printing_logger.py::test_check_simple_output",
                        "description": "verifies methods exist and produce output"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/printing_logger.py::PrintingLogger",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PL-2",
                "requirement_description": "When a logging method is called on a `PrintingLogger` instance, it shall generate a formatted string and output it.",
                "test_traceability": [
                    {
                        "id": "tests/test_printing_logger.py::test_check_simple_output",
                        "description": ""
                    },
                    {
                        "id": "tests/test_printing_logger.py::test_multiple_lines",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/printing_logger.py::PrintingLogger",
                        "description": "all logging methods call `self.callback(self.create_line(...))`"
                    }
                ]
            },
            {
                "requirement_id": "FR-PL-3",
                "requirement_description": "The default output format for the log string shall be: `\"{timestamp} {separator} {level} {separator} {message}\\n\"`.\n    *   `{timestamp}`: The current date and time of the log call. Must include year, month, day, hour, minute, second, and sub-second (microsecond) precision.\n    *   `{separator}`: A separator string, configurable at logger initialization (default is `|`).\n    *   `{level}`: The log level name (e.g., \"DEBUG\", \"INFO\"), left-justified and padded with spaces to a consistent width (9 characters).\n    *   `{message}`: The original log message string passed to the logging method. Positional (`*args`) and keyword (`**kwargs`) arguments are not used for message formatting.\n    *   The string must end with a newline character.",
                "test_traceability": [
                    {
                        "id": "tests/test_printing_logger.py::test_check_simple_output",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/printing_logger.py::PrintingLogger::create_line",
                        "description": ""
                    },
                    {
                        "id": "PrintingLogger::__init__",
                        "description": "for default template and separator"
                    }
                ]
            },
            {
                "requirement_id": "FR-PL-4",
                "requirement_description": "The `PrintingLogger` shall allow configuration of the separator string used in the output format during its initialization.",
                "test_traceability": [
                    {
                        "id": "tests/test_printing_logger.py::test_check_simple_output",
                        "description": "parameterized with different separators"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/printing_logger.py::PrintingLogger::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-PL-5",
                "requirement_description": "By default, the `PrintingLogger` shall output the formatted log string to the standard output (e.g., using `print()`).",
                "test_traceability": [
                    {
                        "id": "tests/test_printing_logger.py::test_check_simple_output",
                        "description": "captures stdout"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/printing_logger.py::PrintingLogger::__init__",
                        "description": "default `printing_callback` is `print`"
                    }
                ]
            },
            {
                "requirement_id": "FR-PL-6",
                "requirement_description": "The `PrintingLogger` shall allow a custom callback function to be provided during its initialization. If provided, this callback function shall be invoked with the formatted log string (including the trailing newline) instead of printing to standard output.",
                "test_traceability": [
                    {
                        "id": "tests/test_printing_logger.py::test_forward_output",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/printing_logger.py::PrintingLogger::__init__",
                        "description": ""
                    },
                    {
                        "id": "and all logging methods which use `self.callback`.",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-LG-1",
                "requirement_description": "A `LoggersGroup` shall implement all logging methods (`debug`, `info`, `warning`, `error`, `exception`, `critical`) as defined in the `LoggerProtocol` (IR-LP-1).",
                "test_traceability": [
                    {
                        "id": "tests/test_loggers_group.py::test_run_group_of_memory_loggers",
                        "description": "implicitly verifies methods exist and are callable"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/loggers_group.py::LoggersGroup",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-LG-2",
                "requirement_description": "A `LoggersGroup` can be instantiated by providing zero or more logger objects (which must conform to `LoggerProtocol`) as arguments.",
                "test_traceability": [
                    {
                        "id": "tests/test_loggers_group.py::test_len_of_group",
                        "description": "instantiates with varying numbers of loggers"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/loggers_group.py::LoggersGroup::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-LG-3",
                "requirement_description": "If any argument provided during `LoggersGroup` instantiation is not a `LoggerProtocol`-compliant object, the system shall raise a `TypeError`. The error message should indicate the problematic argument and its type.",
                "test_traceability": [
                    {
                        "id": "tests/test_loggers_group.py::test_create_group_with_not_loggers",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/loggers_group.py::LoggersGroup::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-LG-4",
                "requirement_description": "When a logging method is called on a `LoggersGroup` instance, the group shall call the same logging method on each of its contained logger objects, forwarding the original `message`, `*args`, and `**kwargs`.\n    *   The calls to contained loggers should occur in the order the loggers were provided during the group's instantiation or addition.",
                "test_traceability": [
                    {
                        "id": "tests/test_loggers_group.py::test_run_group_of_memory_loggers",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/loggers_group.py::LoggersGroup::run_loggers",
                        "description": ""
                    },
                    {
                        "id": "and all specific logging methods (`debug`",
                        "description": ""
                    },
                    {
                        "id": "info",
                        "description": ""
                    },
                    {
                        "id": "etc.).",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-LG-5",
                "requirement_description": "The system shall allow determination of the number of loggers contained within a `LoggersGroup` instance (e.g., via `len()`).",
                "test_traceability": [
                    {
                        "id": "tests/test_loggers_group.py::test_len_of_group",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/loggers_group.py::LoggersGroup::__len__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-LG-6",
                "requirement_description": "A `LoggersGroup` instance shall be iterable, yielding its contained logger objects in the order they were added/defined.",
                "test_traceability": [
                    {
                        "id": "tests/test_loggers_group.py::test_iteration_by_group",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/loggers_group.py::LoggersGroup::__iter__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-LC-1",
                "requirement_description": "The addition operator (`+`) shall be supported between two `LoggerProtocol`-compliant objects.\n    *   This includes addition between instances of `EmptyLogger`, `MemoryLogger`, `PrintingLogger`, `LoggersGroup`, and compatible external loggers.",
                "test_traceability": [
                    {
                        "id": "tests/test_abstract_logger.py::test_sum_of_inner_loggers",
                        "description": ""
                    },
                    {
                        "id": "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand",
                        "description": ""
                    },
                    {
                        "id": "tests/test_loggers_group.py::test_empty_group_plus_third_party_logger",
                        "description": ""
                    },
                    {
                        "id": "tests/test_loggers_group.py::test_third_party_logger_plus_empty_group",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/abstract_logger.py::AbstractLogger::__add__",
                        "description": ""
                    },
                    {
                        "id": "emptylog/abstract_logger.py::AbstractLogger::__radd__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-LC-2",
                "requirement_description": "The result of adding two logger objects shall be a new `LoggersGroup` instance.",
                "test_traceability": [
                    {
                        "id": "tests/test_abstract_logger.py::test_sum_of_inner_loggers",
                        "description": ""
                    },
                    {
                        "id": "tests/test_loggers_group.py::test_empty_group_plus_empty_group",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/abstract_logger.py::AbstractLogger::__add__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-LC-3",
                "requirement_description": "If `loggerA` is added to `loggerB` (`loggerA + loggerB`), the resulting `LoggersGroup` shall contain `loggerA` first, then `loggerB`.\n    *   If `loggerA` is itself a `LoggersGroup`, its contained loggers are added, followed by `loggerB` (or its contained loggers if `loggerB` is also a group). The resulting group should be \"flat\" (not nested `LoggersGroup` instances within the `loggers` collection of the outer group).",
                "test_traceability": [
                    {
                        "id": "tests/test_abstract_logger.py::test_sum_of_inner_loggers",
                        "description": ""
                    },
                    {
                        "id": "tests/test_abstract_logger.py::test_sum_of_three_loggers",
                        "description": ""
                    },
                    {
                        "id": "tests/test_loggers_group.py::test_not_empty_group_plus_empty_group",
                        "description": ""
                    },
                    {
                        "id": "tests/test_loggers_group.py::test_empty_group_plus_not_empty_group",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/abstract_logger.py::AbstractLogger::__add__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-LC-4",
                "requirement_description": "Adding multiple loggers sequentially (e.g., `logger1 + logger2 + logger3`) shall result in a single `LoggersGroup` containing all operand loggers in the order of addition, maintaining a flat structure.",
                "test_traceability": [
                    {
                        "id": "tests/test_abstract_logger.py::test_sum_of_three_loggers",
                        "description": ""
                    },
                    {
                        "id": "tests/test_loggers_group.py::test_len_of_group",
                        "description": "e.g. `MemoryLogger() + MemoryLogger() + MemoryLogger()`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/abstract_logger.py::AbstractLogger::__add__",
                        "description": "as it's called sequentially"
                    }
                ]
            },
            {
                "requirement_id": "FR-LC-5",
                "requirement_description": "Attempting to add a `LoggerProtocol`-compliant object with an object that does not conform to the `LoggerProtocol` (on either side of the `+` operator) shall result in a `NotImplementedError` (or a `TypeError` if the non-logger type doesn't implement reverse addition).",
                "test_traceability": [
                    {
                        "id": "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand",
                        "description": ""
                    },
                    {
                        "id": "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "emptylog/abstract_logger.py::AbstractLogger::__add__",
                        "description": ""
                    },
                    {
                        "id": "emptylog/abstract_logger.py::AbstractLogger::__radd__",
                        "description": ""
                    }
                ]
            }
        ],
        "commit_sha": "45bb45b6cd4e71977b1daddf3011cb35c3753a26",
        "full_code_skeleton": "--- File: emptylog/loggers_group.py ---\n```python\nclass LoggersGroup(AbstractLogger):\n    loggers: Tuple[LoggerProtocol, ...]\n\n    def __init__(self, *loggers: LoggerProtocol) -> None:\n        pass\n\n    def __repr__(self) -> str:\n        pass\n\n    def __len__(self) -> int:\n        pass\n\n    def __iter__(self) -> GroupIterator:  # type: ignore[type-arg, unused-ignore]\n        pass\n\n    def debug(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def info(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def warning(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def error(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def exception(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def critical(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def run_loggers(self, get_method: Callable[[LoggerProtocol], LoggerMethodProtocol], message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n```\n--- File: emptylog/abstract_logger.py ---\n```python\nclass AbstractLogger(LoggerProtocol, ABC):\n    def __repr__(self) -> str:\n        pass\n\n    def __add__(self, other: LoggerProtocol) -> 'LoggersGroup':  # type: ignore[name-defined] # noqa: F821\n        pass\n\n    def __radd__(self, other: LoggerProtocol) -> 'LoggersGroup':  # type: ignore[name-defined] # noqa: F821\n        pass\n```\n--- File: emptylog/protocols.py ---\n```python\n@runtime_checkable\nclass LoggerProtocol(Protocol):\n    def debug(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n    def info(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n    def warning(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n    def error(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n    def exception(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n    def critical(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n\nclass LoggerMethodProtocol(Protocol):\n    def __call__(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n```\n--- File: emptylog/memory_logger.py ---\n```python\nclass MemoryLogger(AbstractLogger):\n    def __init__(self) -> None:\n        pass\n\n    def debug(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n    def info(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n    def warning(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n    def error(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n    def exception(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n    def critical(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n```\n--- File: emptylog/printing_logger.py ---\n```python\nclass PrintingLogger(AbstractLogger):\n    def __init__(self, printing_callback: Callable[[Any], Any] = partial(print, end=''), separator: str = '|') -> None:\n        pass\n\n    def debug(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def info(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def warning(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def error(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def exception(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def critical(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def create_line(self, level: str, message: str) -> str:\n        pass\n```\n--- File: emptylog/accumulated_data.py ---\n```python\n@dataclass\nclass LoggerAccumulatedData:\n    debug: List[LoggerCallData] = field(default_factory=list)\n    info: List[LoggerCallData] = field(default_factory=list)\n    warning: List[LoggerCallData] = field(default_factory=list)\n    error: List[LoggerCallData] = field(default_factory=list)\n    exception: List[LoggerCallData] = field(default_factory=list)\n    critical: List[LoggerCallData] = field(default_factory=list)\n\n    def __len__(self) -> int:\n        pass\n```\n--- File: emptylog/call_data.py ---\n```python\n@dataclass\nclass LoggerCallData:\n    message: str\n    args: Tuple[Any, ...]\n    kwargs: Dict[str, Any]\n```\n--- File: emptylog/empty_logger.py ---\n```python\nclass EmptyLogger(AbstractLogger):\n    pass\n```",
        "full_code_skeleton_structured": [
            {
                "file_path": "emptylog/loggers_group.py",
                "code": "class LoggersGroup(AbstractLogger):\n    loggers: Tuple[LoggerProtocol, ...]\n\n    def __init__(self, *loggers: LoggerProtocol) -> None:\n        pass\n\n    def __repr__(self) -> str:\n        pass\n\n    def __len__(self) -> int:\n        pass\n\n    def __iter__(self) -> GroupIterator:  # type: ignore[type-arg, unused-ignore]\n        pass\n\n    def debug(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def info(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def warning(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def error(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def exception(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def critical(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def run_loggers(self, get_method: Callable[[LoggerProtocol], LoggerMethodProtocol], message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n"
            },
            {
                "file_path": "emptylog/abstract_logger.py",
                "code": "class AbstractLogger(LoggerProtocol, ABC):\n    def __repr__(self) -> str:\n        pass\n\n    def __add__(self, other: LoggerProtocol) -> 'LoggersGroup':  # type: ignore[name-defined] # noqa: F821\n        pass\n\n    def __radd__(self, other: LoggerProtocol) -> 'LoggersGroup':  # type: ignore[name-defined] # noqa: F821\n        pass\n"
            },
            {
                "file_path": "emptylog/protocols.py",
                "code": "@runtime_checkable\nclass LoggerProtocol(Protocol):\n    def debug(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n    def info(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n    def warning(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n    def error(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n    def exception(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n    def critical(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n\nclass LoggerMethodProtocol(Protocol):\n    def __call__(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n"
            },
            {
                "file_path": "emptylog/memory_logger.py",
                "code": "class MemoryLogger(AbstractLogger):\n    def __init__(self) -> None:\n        pass\n\n    def debug(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n    def info(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n    def warning(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n    def error(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n    def exception(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n    def critical(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n"
            },
            {
                "file_path": "emptylog/printing_logger.py",
                "code": "class PrintingLogger(AbstractLogger):\n    def __init__(self, printing_callback: Callable[[Any], Any] = partial(print, end=''), separator: str = '|') -> None:\n        pass\n\n    def debug(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def info(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def warning(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def error(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def exception(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def critical(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def create_line(self, level: str, message: str) -> str:\n        pass\n"
            },
            {
                "file_path": "emptylog/accumulated_data.py",
                "code": "@dataclass\nclass LoggerAccumulatedData:\n    debug: List[LoggerCallData] = field(default_factory=list)\n    info: List[LoggerCallData] = field(default_factory=list)\n    warning: List[LoggerCallData] = field(default_factory=list)\n    error: List[LoggerCallData] = field(default_factory=list)\n    exception: List[LoggerCallData] = field(default_factory=list)\n    critical: List[LoggerCallData] = field(default_factory=list)\n\n    def __len__(self) -> int:\n        pass\n"
            },
            {
                "file_path": "emptylog/call_data.py",
                "code": "@dataclass\nclass LoggerCallData:\n    message: str\n    args: Tuple[Any, ...]\n    kwargs: Dict[str, Any]\n"
            },
            {
                "file_path": "emptylog/empty_logger.py",
                "code": "class EmptyLogger(AbstractLogger):\n    pass\n"
            }
        ],
        "minimal_code_skeleton": "--- File: emptylog/abstract_logger.py ---\n```python\nfrom abc import ABC\n\nfrom emptylog.protocols import LoggerProtocol\n\n\nclass AbstractLogger(LoggerProtocol, ABC):\n    def __repr__(self) -> str:\n        pass\n\n    def __add__(self, other: LoggerProtocol) -> 'LoggersGroup':  # type: ignore[name-defined] # noqa: F821\n        pass\n\n    def __radd__(self, other: LoggerProtocol) -> 'LoggersGroup':  # type: ignore[name-defined] # noqa: F821\n        pass\n```\n--- File: emptylog/accumulated_data.py ---\n```python\nfrom dataclasses import dataclass, field\nfrom typing import List\n\nfrom emptylog.call_data import LoggerCallData\n\n\n@dataclass\nclass LoggerAccumulatedData:\n    debug: List[LoggerCallData] = field(default_factory=list)\n    info: List[LoggerCallData] = field(default_factory=list)\n    warning: List[LoggerCallData] = field(default_factory=list)\n    error: List[LoggerCallData] = field(default_factory=list)\n    exception: List[LoggerCallData] = field(default_factory=list)\n    critical: List[LoggerCallData] = field(default_factory=list)\n\n    def __len__(self) -> int:\n        pass\n```\n--- File: emptylog/call_data.py ---\n```python\nfrom dataclasses import dataclass\nfrom typing import Tuple, Dict, Any\n\n\n@dataclass\nclass LoggerCallData:\n    message: str\n    args: Tuple[Any, ...]\n    kwargs: Dict[str, Any]\n```\n--- File: emptylog/empty_logger.py ---\n```python\nfrom emptylog.abstract_logger import AbstractLogger\n\n\nclass EmptyLogger(AbstractLogger):\n    pass\n```\n--- File: emptylog/loggers_group.py ---\n```python\nimport sys\nfrom typing import Tuple, Callable, Any\nfrom collections.abc import Iterator\n\nfrom emptylog.protocols import LoggerProtocol, LoggerMethodProtocol\nfrom emptylog.abstract_logger import AbstractLogger\n\n\nif sys.version_info < (3, 9):\n    GroupIterator = Iterator  # pragma: no cover\nelse:\n    GroupIterator = Iterator[LoggerProtocol]  # pragma: no cover\n\nclass LoggersGroup(AbstractLogger):\n    loggers: Tuple[LoggerProtocol, ...]\n\n    def __init__(self, *loggers: LoggerProtocol) -> None:\n        pass\n\n    def __repr__(self) -> str:\n        pass\n\n    def __len__(self) -> int:\n        pass\n\n    def __iter__(self) -> GroupIterator:  # type: ignore[type-arg, unused-ignore]\n        pass\n\n    def debug(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def info(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def warning(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def error(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def exception(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def critical(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n```\n--- File: emptylog/memory_logger.py ---\n```python\nfrom typing import Any\n\nfrom emptylog.abstract_logger import AbstractLogger\nfrom emptylog.call_data import LoggerCallData\nfrom emptylog.accumulated_data import LoggerAccumulatedData\n\n\nclass MemoryLogger(AbstractLogger):\n    def __init__(self) -> None:\n        pass\n\n    def debug(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def info(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def warning(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def error(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def exception(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def critical(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n```\n--- File: emptylog/printing_logger.py ---\n```python\nfrom typing import Callable, Any\nfrom functools import partial\n\n\nfrom emptylog.abstract_logger import AbstractLogger\n\n\nclass PrintingLogger(AbstractLogger):\n    def __init__(self, printing_callback: Callable[[Any], Any] = partial(print, end=''), separator: str = '|') -> None:\n        pass\n\n    def debug(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def info(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def warning(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def error(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def exception(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def critical(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n```\n--- File: emptylog/protocols.py ---\n```python\nfrom typing import Any\n\ntry:\n    from typing import Protocol, runtime_checkable\nexcept ImportError:  # pragma: no cover\n    from typing_extensions import Protocol, runtime_checkable  # type: ignore[assignment]\n\n\n@runtime_checkable\nclass LoggerProtocol(Protocol):\n    def debug(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def info(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def warning(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def error(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def exception(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def critical(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n```",
        "minimal_code_skeleton_structured": [
            {
                "file_path": "emptylog/abstract_logger.py",
                "code": "from abc import ABC\n\nfrom emptylog.protocols import LoggerProtocol\n\n\nclass AbstractLogger(LoggerProtocol, ABC):\n    def __repr__(self) -> str:\n        pass\n\n    def __add__(self, other: LoggerProtocol) -> 'LoggersGroup':  # type: ignore[name-defined] # noqa: F821\n        pass\n\n    def __radd__(self, other: LoggerProtocol) -> 'LoggersGroup':  # type: ignore[name-defined] # noqa: F821\n        pass\n"
            },
            {
                "file_path": "emptylog/accumulated_data.py",
                "code": "from dataclasses import dataclass, field\nfrom typing import List\n\nfrom emptylog.call_data import LoggerCallData\n\n\n@dataclass\nclass LoggerAccumulatedData:\n    debug: List[LoggerCallData] = field(default_factory=list)\n    info: List[LoggerCallData] = field(default_factory=list)\n    warning: List[LoggerCallData] = field(default_factory=list)\n    error: List[LoggerCallData] = field(default_factory=list)\n    exception: List[LoggerCallData] = field(default_factory=list)\n    critical: List[LoggerCallData] = field(default_factory=list)\n\n    def __len__(self) -> int:\n        pass\n"
            },
            {
                "file_path": "emptylog/call_data.py",
                "code": "from dataclasses import dataclass\nfrom typing import Tuple, Dict, Any\n\n\n@dataclass\nclass LoggerCallData:\n    message: str\n    args: Tuple[Any, ...]\n    kwargs: Dict[str, Any]\n"
            },
            {
                "file_path": "emptylog/empty_logger.py",
                "code": "from emptylog.abstract_logger import AbstractLogger\n\n\nclass EmptyLogger(AbstractLogger):\n    pass\n"
            },
            {
                "file_path": "emptylog/loggers_group.py",
                "code": "import sys\nfrom typing import Tuple, Callable, Any\nfrom collections.abc import Iterator\n\nfrom emptylog.protocols import LoggerProtocol, LoggerMethodProtocol\nfrom emptylog.abstract_logger import AbstractLogger\n\n\nif sys.version_info < (3, 9):\n    GroupIterator = Iterator  # pragma: no cover\nelse:\n    GroupIterator = Iterator[LoggerProtocol]  # pragma: no cover\n\nclass LoggersGroup(AbstractLogger):\n    loggers: Tuple[LoggerProtocol, ...]\n\n    def __init__(self, *loggers: LoggerProtocol) -> None:\n        pass\n\n    def __repr__(self) -> str:\n        pass\n\n    def __len__(self) -> int:\n        pass\n\n    def __iter__(self) -> GroupIterator:  # type: ignore[type-arg, unused-ignore]\n        pass\n\n    def debug(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def info(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def warning(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def error(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def exception(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def critical(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n"
            },
            {
                "file_path": "emptylog/memory_logger.py",
                "code": "from typing import Any\n\nfrom emptylog.abstract_logger import AbstractLogger\nfrom emptylog.call_data import LoggerCallData\nfrom emptylog.accumulated_data import LoggerAccumulatedData\n\n\nclass MemoryLogger(AbstractLogger):\n    def __init__(self) -> None:\n        pass\n\n    def debug(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def info(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def warning(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def error(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def exception(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def critical(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n"
            },
            {
                "file_path": "emptylog/printing_logger.py",
                "code": "from typing import Callable, Any\nfrom functools import partial\n\n\nfrom emptylog.abstract_logger import AbstractLogger\n\n\nclass PrintingLogger(AbstractLogger):\n    def __init__(self, printing_callback: Callable[[Any], Any] = partial(print, end=''), separator: str = '|') -> None:\n        pass\n\n    def debug(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def info(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def warning(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def error(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def exception(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def critical(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n"
            },
            {
                "file_path": "emptylog/protocols.py",
                "code": "from typing import Any\n\ntry:\n    from typing import Protocol, runtime_checkable\nexcept ImportError:  # pragma: no cover\n    from typing_extensions import Protocol, runtime_checkable  # type: ignore[assignment]\n\n\n@runtime_checkable\nclass LoggerProtocol(Protocol):\n    def debug(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def info(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def warning(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def error(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def exception(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n\n    def critical(self, message: str, *args: Any, **kwargs: Any) -> None:\n        pass\n"
            }
        ],
        "minimal_test_cases": [
            {
                "test_id": "tests/test_empty_logger.py::test_search_callable_attributes",
                "covers": [
                    "emptylog.EmptyLogger.__init__ - basic instantiation",
                    "emptylog.EmptyLogger.debug - happy path",
                    "emptylog.EmptyLogger.info - happy path",
                    "emptylog.EmptyLogger.warning - happy path",
                    "emptylog.EmptyLogger.error - happy path",
                    "emptylog.EmptyLogger.exception - happy path",
                    "emptylog.EmptyLogger.critical - happy path"
                ]
            },
            {
                "test_id": "tests/test_empty_logger.py::test_repr_empty_logger",
                "covers": [
                    "emptylog.EmptyLogger.__repr__ - standard representation"
                ]
            },
            {
                "test_id": "tests/test_abstract_logger.py::test_sum_of_inner_loggers[second_logger0-first_logger0]",
                "covers": [
                    "emptylog.AbstractLogger.__add__ - happy path combining two AbstractLogger instances (e.g., EmptyLogger + EmptyLogger)"
                ]
            },
            {
                "test_id": "tests/test_abstract_logger.py::test_sum_with_another_loggers_as_first_operand[second_logger0-logging]",
                "covers": [
                    "emptylog.AbstractLogger.__radd__ - happy path combining external logger with an AbstractLogger instance (e.g., standard logging + EmptyLogger)"
                ]
            },
            {
                "test_id": "tests/test_memory_logger.py::test_memory_logger_is_working",
                "covers": [
                    "emptylog.MemoryLogger.__init__ - basic instantiation",
                    "emptylog.MemoryLogger.debug - happy path and data storage verification",
                    "emptylog.MemoryLogger.info - happy path and data storage verification",
                    "emptylog.MemoryLogger.warning - happy path and data storage verification",
                    "emptylog.MemoryLogger.error - happy path and data storage verification",
                    "emptylog.MemoryLogger.exception - happy path and data storage verification",
                    "emptylog.MemoryLogger.critical - happy path and data storage verification",
                    "emptylog.MemoryLogger.data - public attribute access and verification of stored log calls",
                    "emptylog.memory_logger.LoggerAccumulatedData - instantiation and attribute access as part of MemoryLogger.data",
                    "emptylog.memory_logger.LoggerCallData - instantiation and attribute access as part of MemoryLogger.data"
                ]
            },
            {
                "test_id": "tests/test_memory_logger.py::test_repr_memory_logger",
                "covers": [
                    "emptylog.MemoryLogger.__repr__ - standard representation"
                ]
            },
            {
                "test_id": "tests/test_printing_logger.py::test_check_simple_output[debug- | DEBUG     | kek]",
                "covers": [
                    "emptylog.PrintingLogger.__init__ - default constructor",
                    "emptylog.PrintingLogger.debug - happy path, default output format",
                    "emptylog.PrintingLogger.create_line - internal line formatting"
                ]
            },
            {
                "test_id": "tests/test_printing_logger.py::test_check_simple_output[info- | INFO      | kek]",
                "covers": [
                    "emptylog.PrintingLogger.info - happy path, default output format"
                ]
            },
            {
                "test_id": "tests/test_printing_logger.py::test_check_simple_output[warning- | WARNING   | kek]",
                "covers": [
                    "emptylog.PrintingLogger.warning - happy path, default output format"
                ]
            },
            {
                "test_id": "tests/test_printing_logger.py::test_check_simple_output[error- | ERROR     | kek]",
                "covers": [
                    "emptylog.PrintingLogger.error - happy path, default output format"
                ]
            },
            {
                "test_id": "tests/test_printing_logger.py::test_check_simple_output[exception- | EXCEPTION | kek]",
                "covers": [
                    "emptylog.PrintingLogger.exception - happy path, default output format"
                ]
            },
            {
                "test_id": "tests/test_printing_logger.py::test_check_simple_output[critical- | CRITICAL  | kek]",
                "covers": [
                    "emptylog.PrintingLogger.critical - happy path, default output format"
                ]
            },
            {
                "test_id": "tests/test_printing_logger.py::test_check_simple_output[debug- * DEBUG     * kek]",
                "covers": [
                    "emptylog.PrintingLogger.__init__ - constructor with custom separator"
                ]
            },
            {
                "test_id": "tests/test_printing_logger.py::test_forward_output[<lambda>- | DEBUG     | kek]",
                "covers": [
                    "emptylog.PrintingLogger.__init__ - constructor with custom printing_callback"
                ]
            },
            {
                "test_id": "tests/test_printing_logger.py::test_repr_printing_logger",
                "covers": [
                    "emptylog.PrintingLogger.__repr__ - standard representation"
                ]
            },
            {
                "test_id": "tests/test_loggers_group.py::test_create_group_with_not_loggers[1-A logger group can only be created from loggers. You passed 1 (int).]",
                "covers": [
                    "emptylog.LoggersGroup.__init__ - type error for non-logger arguments"
                ]
            },
            {
                "test_id": "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>0]",
                "covers": [
                    "emptylog.LoggersGroup.__init__ - constructor with multiple loggers",
                    "emptylog.LoggersGroup.debug - happy path, dispatch to member loggers"
                ]
            },
            {
                "test_id": "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>1]",
                "covers": [
                    "emptylog.LoggersGroup.info - happy path, dispatch to member loggers"
                ]
            },
            {
                "test_id": "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>2]",
                "covers": [
                    "emptylog.LoggersGroup.warning - happy path, dispatch to member loggers"
                ]
            },
            {
                "test_id": "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>3]",
                "covers": [
                    "emptylog.LoggersGroup.error - happy path, dispatch to member loggers"
                ]
            },
            {
                "test_id": "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>4]",
                "covers": [
                    "emptylog.LoggersGroup.exception - happy path, dispatch to member loggers"
                ]
            },
            {
                "test_id": "tests/test_loggers_group.py::test_run_group_of_memory_loggers[<lambda>5]",
                "covers": [
                    "emptylog.LoggersGroup.critical - happy path, dispatch to member loggers"
                ]
            },
            {
                "test_id": "tests/test_loggers_group.py::test_empty_group_plus_empty_group",
                "covers": [
                    "emptylog.LoggersGroup.__init__ - empty constructor",
                    "emptylog.LoggersGroup.__add__ - combining two LoggersGroup instances",
                    "emptylog.LoggersGroup.loggers - public attribute access for member loggers"
                ]
            },
            {
                "test_id": "tests/test_loggers_group.py::test_repr_loggers_group",
                "covers": [
                    "emptylog.LoggersGroup.__repr__ - standard representation"
                ]
            },
            {
                "test_id": "tests/test_loggers_group.py::test_len_of_group",
                "covers": [
                    "emptylog.LoggersGroup.__len__ - counting member loggers"
                ]
            },
            {
                "test_id": "tests/test_loggers_group.py::test_iteration_by_group[loggers1]",
                "covers": [
                    "emptylog.LoggersGroup.__iter__ - iteration over member loggers"
                ]
            },
            {
                "test_id": "tests/test_loggers_group.py::test_empty_group_plus_another_logger",
                "covers": [
                    "emptylog.LoggersGroup.__add__ - combining LoggersGroup with a concrete logger (e.g., MemoryLogger)"
                ]
            },
            {
                "test_id": "tests/test_loggers_group.py::test_third_party_logger_plus_empty_group[third_party_logger0]",
                "covers": [
                    "emptylog.LoggersGroup.__radd__ - combining external logger with LoggersGroup (via AbstractLogger.__radd__)"
                ]
            },
            {
                "test_id": "tests/test_protocols.py::test_positive_examples_of_runtime_check",
                "covers": [
                    "emptylog.LoggerProtocol - runtime type checking with isinstance for all provided logger types"
                ]
            },
            {
                "test_id": "tests/test_accumulated_data.py::test_fill_accumulated_data_and_check_size",
                "covers": [
                    "emptylog.memory_logger.LoggerAccumulatedData.__init__ - direct instantiation and initialization of log lists",
                    "emptylog.memory_logger.LoggerAccumulatedData.debug - direct list manipulation (as an example for all level attributes)",
                    "emptylog.memory_logger.LoggerAccumulatedData.info - direct list manipulation",
                    "emptylog.memory_logger.LoggerAccumulatedData.warning - direct list manipulation",
                    "emptylog.memory_logger.LoggerAccumulatedData.error - direct list manipulation",
                    "emptylog.memory_logger.LoggerAccumulatedData.exception - direct list manipulation",
                    "emptylog.memory_logger.LoggerAccumulatedData.critical - direct list manipulation",
                    "emptylog.memory_logger.LoggerAccumulatedData.__len__ - calculating total number of stored log calls"
                ]
            },
            {
                "test_id": "tests/test_abstract_logger.py::test_sum_with_wrong_second_operand[1-logger0]",
                "covers": [
                    "emptylog.AbstractLogger.__add__ - error handling for addition with a non-logger type"
                ]
            },
            {
                "test_id": "tests/test_abstract_logger.py::test_sum_with_wrong_first_operand[1-logger0]",
                "covers": [
                    "emptylog.AbstractLogger.__radd__ - error handling for reverse addition with a non-logger type"
                ]
            }
        ]
    },
    {
        "idx": 89923,
        "repo_name": "databrickslabs_pylint-plugin",
        "url": "https://github.com/databrickslabs/pylint-plugin",
        "description": "Databricks Plugin for PyLint",
        "stars": 20,
        "forks": 4,
        "language": "python",
        "size": 185,
        "created_at": "2024-01-23T16:32:36+00:00",
        "updated_at": "2025-04-24T06:25:35+00:00",
        "pypi_info": {
            "name": "databricks-labs-pylint",
            "version": "0.5.0",
            "url": "https://files.pythonhosted.org/packages/b4/be/2bff3b16e8e2918af28420180ecdd053c22aabd5d0e04c4151e24f6992a1/databricks_labs_pylint-0.5.0.tar.gz"
        },
        "judge_info": {
            "language": "python",
            "is_good_project": false,
            "reason": "",
            "python_file_num": 26,
            "comment_ratio": 0.1458198314970836,
            "pyfile_content_length": 55994,
            "pyfile_code_lines": 1543,
            "test_file_exist": true,
            "test_file_content_length": 11710,
            "pytest_framework": true,
            "test_case_num": 26,
            "metadata_path": [
                "pyproject.toml"
            ],
            "readme_content_length": 21427,
            "llm_reason": "Positive Aspects:\n- The project's core task (a PyLint plugin for static code analysis) is inherently self-contained. It analyzes code locally and does not require internet access, external APIs, or databases for its primary function or testing.\n- Dependencies (PyLint, astroid) are standard PyPI packages manageable via pip and do not violate the self-containment rules for their core operation.\n- The functionality is well-defined: the README clearly lists specific checks (e.g., `dbutils-fs-cp`, `spark-outside-function`) with their codes and rationales, providing a clear specification for replication.\n- The project includes a comprehensive test suite (`tests/`) using `pylint.testutils`, making the AI's output (the generated lint messages) programmatically verifiable against predefined code snippets.\n- It is a command-line tool/library, not a GUI application.\n- The complexity seems appropriate ('Medium'): building a PyLint plugin requires understanding AST traversal and the PyLint API, which is non-trivial but achievable, involving multiple interacting components (checkers). The scope (around 20 distinct checks) is manageable.\n- The problem domain (static analysis, linters) is well-understood, even if the specific rules are Databricks-focused.\n- The solution is predominantly code-based.\n\nNegative Aspects:\n- Requires understanding and using the PyLint/astroid API, making it dependent on a specific framework's structure and potentially its version stability.\n- The checks are specific to the Databricks ecosystem, although the README provides sufficient description for implementation without needing deep Databricks expertise or a live environment for the AI's rebuilt version.\n- Translating the check descriptions into correct AST node manipulations might require careful implementation by the AI.",
            "llm_project_type": "Linter Plugin / Static Code Analysis Tool",
            "llm_rating": 85,
            "llm_difficulty": "Medium"
        },
        "tests": {
            "repo_name": "databrickslabs_pylint-plugin",
            "finish_test": true,
            "test_case_result": {
                "tests/test_airflow.py::test_missing_data_security_mode_in_job_clusters": "passed",
                "tests/test_airflow.py::test_missing_data_security_mode_in_task_clusters": "passed",
                "tests/test_airflow.py::test_missing_data_security_mode_in_submit_run_clusters": "passed",
                "tests/test_dbutils.py::test_checks_cp": "passed",
                "tests/test_dbutils.py::test_checks_head": "passed",
                "tests/test_dbutils.py::test_checks_list": "passed",
                "tests/test_dbutils.py::test_checks_mount": "passed",
                "tests/test_dbutils.py::test_checks_credentials": "passed",
                "tests/test_dbutils.py::test_checks_notebook_run": "passed",
                "tests/test_dbutils.py::test_checks_secrets": "passed",
                "tests/test_dbutils.py::test_internal_api[import dbruntime.foo, bar]": "passed",
                "tests/test_dbutils.py::test_internal_api[from dbruntime.foo import bar, baz]": "passed",
                "tests/test_dbutils.py::test_internal_api[dbutils.notebook.entry_point.getDbutils()]": "passed",
                "tests/test_dbutils.py::test_internal_api[whatever['foo'].notebook.entry_point.getDbutils()]": "passed",
                "tests/test_dbutils.py::test_internal_api[dbutils.notebook.entry_point.getDbutils().notebook().getContext()]": "passed",
                "tests/test_dbutils.py::test_internal_api[blueberry.notebook().getContext().foo()]": "passed",
                "tests/test_dbutils.py::test_internal_api[banana.apiToken()]": "passed",
                "tests/test_legacy.py::test_legacy_cli[import databricks_cli.foo]": "passed",
                "tests/test_legacy.py::test_legacy_cli[from databricks_cli.foo import bar]": "passed",
                "tests/test_legacy.py::test_un_incompatible[spark.sql(\\n            'SELECT * FROM hive_metastore.default.foo' #@\\n        )]": "passed",
                "tests/test_legacy.py::test_un_incompatible[spark.read.format('delta').load(\\n            'dbfs:/foo/bar' #@\\n        )]": "passed",
                "tests/test_legacy.py::test_un_incompatible[{\\n            'kafka.sasl.client.callback.handler.class': 'foo', #@\\n        }]": "passed",
                "tests/test_legacy.py::test_un_incompatible[import pyspark.ml.foo]": "passed",
                "tests/test_legacy.py::test_un_incompatible[from pyspark.ml import bar]": "passed",
                "tests/test_legacy.py::test_un_incompatible[import graphframes]": "passed",
                "tests/test_legacy.py::test_un_incompatible[import boto3]": "passed",
                "tests/test_legacy.py::test_un_incompatible[import s3fs]": "passed",
                "tests/test_legacy.py::test_un_incompatible[spark.catalog.list()]": "passed",
                "tests/test_legacy.py::test_un_incompatible[spark._jsparkSession.catalog.listTables()]": "passed",
                "tests/test_legacy.py::test_un_incompatible[spark._jspark.anything()]": "passed",
                "tests/test_legacy.py::test_un_incompatible[spark._jvm.anything()]": "passed",
                "tests/test_legacy.py::test_un_incompatible[df._jdf.anything()]": "passed",
                "tests/test_legacy.py::test_un_incompatible[df['foo']._jcol.anything()]": "passed",
                "tests/test_legacy.py::test_un_incompatible[sc.setLocalProperty('foo', 'bar')]": "passed",
                "tests/test_mocking.py::test_obscure_mock": "passed",
                "tests/test_mocking.py::test_explicit_dependency_required": "passed",
                "tests/test_mocking.py::test_mock_in_function_arg": "passed",
                "tests/test_mocking.py::test_mock_not_assigned": "passed",
                "tests/test_mocking.py::test_mock_return_value_real": "passed",
                "tests/test_mocking.py::test_mock_is_asserted": "passed",
                "tests/test_readability.py::test_single_line_list_comprehensions_allowed": "passed",
                "tests/test_readability.py::test_multi_line_list_comprehensions_not_allowed": "passed",
                "tests/test_samples.py::test_samples[dead_code]": "passed",
                "tests/test_samples.py::test_samples[many_cells]": "passed",
                "tests/test_samples.py::test_samples[percent_run]": "passed",
                "tests/test_spark.py::test_spark_inside_function": "passed",
                "tests/test_spark.py::test_spark_outside_function": "passed",
                "tests/test_spark.py::test_spark_inside_of_function_but_not_in_args": "passed",
                "tests/test_spark.py::test_df_show": "passed"
            },
            "success_count": 49,
            "failed_count": 0,
            "error_count": 0,
            "skipped_count": 0,
            "unknown_count": 0,
            "total_count": 49,
            "success_rate": 1.0,
            "coverage_report": {
                "covered_lines": 286,
                "num_statements": 313,
                "percent_covered": 90.4051172707889,
                "percent_covered_display": "90",
                "missing_lines": 27,
                "excluded_lines": 0,
                "num_branches": 156,
                "num_partial_branches": 16,
                "covered_branches": 138,
                "missing_branches": 18
            },
            "coverage_result": {}
        },
        "codelines_count": 1543,
        "codefiles_count": 26,
        "code_length": 55994,
        "test_files_count": 7,
        "test_code_length": 11710,
        "class_diagram": "@startuml\nclass TestSupport {\n    __init__(klass, config): void\n    __lshift__(code): void\n}\nclass MockingChecker {\n    name: Unknown\n    msgs: Unknown\n    options: Unknown\n    open(): Unknown\n    visit_call(node): Unknown\n    _no_mock_usage(node): bool\n}\nclass SparkChecker {\n    name: Unknown\n    msgs: Unknown\n    visit_name(node): void\n    visit_attribute(node): void\n}\nclass LegacyChecker {\n    name: Unknown\n    msgs: Unknown\n    UC_INCOMPATIBLE_BRUTE_FORCE: Unknown\n    visit_import(node): void\n    visit_importfrom(node): void\n    visit_call(node): void\n    visit_const(node): void\n}\nclass AirflowChecker {\n    name: Unknown\n    msgs: Unknown\n    visit_call(node): void\n    _check_new_cluster(key, new_cluster, node): void\n    _is_supported(spark_version): void\n    _check_tasks(tasks, node): void\n    _check_job_clusters(job_clusters, node): void\n    _infer_kwargs(keywords): void\n    _infer_value(value): void\n    _infer_dict(in_dict): void\n    _infer_list(list_): void\n}\nclass DbutilsChecker {\n    name: Unknown\n    msgs: Unknown\n    visit_call(node): void\n    visit_const(node): void\n    visit_import(node): void\n    visit_importfrom(node): void\n}\nclass NotebookChecker {\n    __implements__: Unknown\n    name: Unknown\n    msgs: Unknown\n    options: Unknown\n    process_module(node): void\n}\nclass ReadabilityChecker {\n    name: Unknown\n    msgs: Unknown\n    visit_listcomp(node): Unknown\n}\nclass EradicateChecker {\n    name: Unknown\n    msgs: Unknown\n    open(): Unknown\n    process_module(node): void\n}\n@enduml",
        "structure": [
            {
                "file": "tests/test_readability.py",
                "functions": [
                    {
                        "name": "test_single_line_list_comprehensions_allowed",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with"
                        ]
                    },
                    {
                        "name": "test_multi_line_list_comprehensions_not_allowed",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_airflow.py",
                "functions": [
                    {
                        "name": "test_missing_data_security_mode_in_job_clusters",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with"
                        ]
                    },
                    {
                        "name": "test_missing_data_security_mode_in_task_clusters",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with"
                        ]
                    },
                    {
                        "name": "test_missing_data_security_mode_in_submit_run_clusters",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_samples.py",
                "functions": [
                    {
                        "name": "test_samples",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "sample"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/conftest.py",
                "functions": [
                    {
                        "name": "lint_with",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": [
                    {
                        "name": "TestSupport",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "klass",
                                    "config"
                                ]
                            },
                            {
                                "name": "__lshift__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "code"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/test_dbutils.py",
                "functions": [
                    {
                        "name": "test_checks_cp",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with"
                        ]
                    },
                    {
                        "name": "test_checks_head",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with"
                        ]
                    },
                    {
                        "name": "test_checks_list",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with"
                        ]
                    },
                    {
                        "name": "test_checks_mount",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with"
                        ]
                    },
                    {
                        "name": "test_checks_credentials",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with"
                        ]
                    },
                    {
                        "name": "test_checks_notebook_run",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with"
                        ]
                    },
                    {
                        "name": "test_checks_secrets",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with"
                        ]
                    },
                    {
                        "name": "test_internal_api",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with",
                            "code"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_legacy.py",
                "functions": [
                    {
                        "name": "test_legacy_cli",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with",
                            "code"
                        ]
                    },
                    {
                        "name": "test_un_incompatible",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with",
                            "code"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_spark.py",
                "functions": [
                    {
                        "name": "test_spark_inside_function",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with"
                        ]
                    },
                    {
                        "name": "test_spark_outside_function",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with"
                        ]
                    },
                    {
                        "name": "test_spark_inside_of_function_but_not_in_args",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with"
                        ]
                    },
                    {
                        "name": "test_df_show",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_mocking.py",
                "functions": [
                    {
                        "name": "test_obscure_mock",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with"
                        ]
                    },
                    {
                        "name": "test_explicit_dependency_required",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with"
                        ]
                    },
                    {
                        "name": "test_mock_in_function_arg",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with"
                        ]
                    },
                    {
                        "name": "test_mock_not_assigned",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with"
                        ]
                    },
                    {
                        "name": "test_mock_return_value_real",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with"
                        ]
                    },
                    {
                        "name": "test_mock_is_asserted",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "lint_with"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/samples/p/percent_run.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/samples/m/many_cells.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/samples/d/dead_code.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "src/databricks/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "src/databricks/labs/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "src/databricks/labs/pylint/__about__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "src/databricks/labs/pylint/mocking.py",
                "functions": [
                    {
                        "name": "register",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "linter"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "MockingChecker",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "open",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "visit_call",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "node"
                                ]
                            },
                            {
                                "name": "_no_mock_usage",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "node"
                                ]
                            }
                        ],
                        "attributes": [
                            "name",
                            "msgs",
                            "options"
                        ]
                    }
                ]
            },
            {
                "file": "src/databricks/labs/pylint/spark.py",
                "functions": [
                    {
                        "name": "register",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "linter"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "SparkChecker",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "visit_name",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "node"
                                ]
                            },
                            {
                                "name": "visit_attribute",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "node"
                                ]
                            }
                        ],
                        "attributes": [
                            "name",
                            "msgs"
                        ]
                    }
                ]
            },
            {
                "file": "src/databricks/labs/pylint/legacy.py",
                "functions": [
                    {
                        "name": "register",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "linter"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "LegacyChecker",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "visit_import",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "node"
                                ]
                            },
                            {
                                "name": "visit_importfrom",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "node"
                                ]
                            },
                            {
                                "name": "visit_call",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "node"
                                ]
                            },
                            {
                                "name": "visit_const",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "node"
                                ]
                            }
                        ],
                        "attributes": [
                            "name",
                            "msgs",
                            "UC_INCOMPATIBLE_BRUTE_FORCE"
                        ]
                    }
                ]
            },
            {
                "file": "src/databricks/labs/pylint/all.py",
                "functions": [
                    {
                        "name": "register",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "linter"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "src/databricks/labs/pylint/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "src/databricks/labs/pylint/airflow.py",
                "functions": [
                    {
                        "name": "register",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "linter"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "AirflowChecker",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "visit_call",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "node"
                                ]
                            },
                            {
                                "name": "_check_new_cluster",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "key",
                                    "new_cluster",
                                    "node"
                                ]
                            },
                            {
                                "name": "_is_supported",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "spark_version"
                                ]
                            },
                            {
                                "name": "_check_tasks",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "tasks",
                                    "node"
                                ]
                            },
                            {
                                "name": "_check_job_clusters",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "job_clusters",
                                    "node"
                                ]
                            },
                            {
                                "name": "_infer_kwargs",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "keywords"
                                ]
                            },
                            {
                                "name": "_infer_value",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            },
                            {
                                "name": "_infer_dict",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "in_dict"
                                ]
                            },
                            {
                                "name": "_infer_list",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "list_"
                                ]
                            }
                        ],
                        "attributes": [
                            "name",
                            "msgs"
                        ]
                    }
                ]
            },
            {
                "file": "src/databricks/labs/pylint/dbutils.py",
                "functions": [
                    {
                        "name": "register",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "linter"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "DbutilsChecker",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "visit_call",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "node"
                                ]
                            },
                            {
                                "name": "visit_const",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "node"
                                ]
                            },
                            {
                                "name": "visit_import",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "node"
                                ]
                            },
                            {
                                "name": "visit_importfrom",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "node"
                                ]
                            }
                        ],
                        "attributes": [
                            "name",
                            "msgs"
                        ]
                    }
                ]
            },
            {
                "file": "src/databricks/labs/pylint/notebooks.py",
                "functions": [
                    {
                        "name": "register",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "linter"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "NotebookChecker",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "process_module",
                                "docstring": "Read raw module. Need to do some tricks, as `ast` doesn't provide access for comments.\n\nAlternative libraries that can parse comments along with the code:\n- https://github.com/Instagram/LibCST/ (MIT + PSF)\n- https://github.com/python/cpython/tree/3.10/Lib/lib2to3 (PSF), removed in Python 3.12\n- https://github.com/t3rn0/ast-comments (MIT)\n- https://github.com/facebookincubator/bowler (MIT), abandoned\n- https://github.com/PyCQA/redbaron (LGPLv3)",
                                "comments": null,
                                "args": [
                                    "self",
                                    "node"
                                ]
                            }
                        ],
                        "attributes": [
                            "__implements__",
                            "name",
                            "msgs",
                            "options"
                        ]
                    }
                ]
            },
            {
                "file": "src/databricks/labs/pylint/readability.py",
                "functions": [
                    {
                        "name": "register",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "linter"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "ReadabilityChecker",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "visit_listcomp",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "node"
                                ]
                            }
                        ],
                        "attributes": [
                            "name",
                            "msgs"
                        ]
                    }
                ]
            },
            {
                "file": "src/databricks/labs/pylint/cli.py",
                "functions": [
                    {
                        "name": "check_python_notebook",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "info"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "src/databricks/labs/pylint/eradicate.py",
                "functions": [
                    {
                        "name": "register",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "linter"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "EradicateChecker",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "open",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "process_module",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "node"
                                ]
                            }
                        ],
                        "attributes": [
                            "name",
                            "msgs"
                        ]
                    }
                ]
            },
            {
                "file": "scripts/docs.py",
                "functions": [
                    {
                        "name": "do_something",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            }
        ],
        "test_cases": {
            "tests/test_airflow.py::test_missing_data_security_mode_in_job_clusters": {
                "testid": "tests/test_airflow.py::test_missing_data_security_mode_in_job_clusters",
                "result": "passed",
                "test_implementation": "def test_missing_data_security_mode_in_job_clusters(lint_with):\n    messages = (\n        lint_with(AirflowChecker)\n        << \"\"\"from airflow.providers.databricks.operators.databricks import DatabricksCreateJobsOperator\ntasks = [\n    {\n        \"task_key\": \"test\",\n        \"job_cluster_key\": \"job_cluster\",\n        \"notebook_task\": {\n            \"notebook_path\": \"/Shared/test\",\n        },\n    },\n]\njob_clusters = [\n    {\n        \"job_cluster_key\": \"banana\",\n        \"new_cluster\": {\n            \"spark_version\": \"7.3.x-scala2.12\",\n            \"node_type_id\": \"i3.xlarge\",\n            \"num_workers\": 2,\n        },\n    },\n]\nDatabricksCreateJobsOperator( #@\n    task_id=\"jobs_create_named\", \n    tasks=tasks, \n    job_clusters=job_clusters\n)\"\"\"\n    )\n    assert (\n        \"[missing-data-security-mode] banana cluster missing `data_security_mode` \"\n        \"required for Unity Catalog compatibility\"\n    ) in messages"
            },
            "tests/test_airflow.py::test_missing_data_security_mode_in_task_clusters": {
                "testid": "tests/test_airflow.py::test_missing_data_security_mode_in_task_clusters",
                "result": "passed",
                "test_implementation": "def test_missing_data_security_mode_in_task_clusters(lint_with):\n    messages = (\n        lint_with(AirflowChecker)\n        << \"\"\"from airflow.providers.databricks.operators.databricks import DatabricksCreateJobsOperator\ntasks = [\n    {\n        \"task_key\": \"banana\",\n        \"notebook_task\": {\n            \"notebook_path\": \"/Shared/test\",\n        },\n        'new_cluster': {\n            \"spark_version\": \"7.3.x-scala2.12\",\n            \"node_type_id\": \"i3.xlarge\",\n            \"num_workers\": 2,\n        },\n    },\n]\nDatabricksCreateJobsOperator( #@\n    task_id=\"jobs_create_named\", \n    tasks=tasks\n)\"\"\"\n    )\n    assert (\n        \"[missing-data-security-mode] banana cluster missing `data_security_mode` \"\n        \"required for Unity Catalog compatibility\"\n    ) in messages"
            },
            "tests/test_airflow.py::test_missing_data_security_mode_in_submit_run_clusters": {
                "testid": "tests/test_airflow.py::test_missing_data_security_mode_in_submit_run_clusters",
                "result": "passed",
                "test_implementation": "def test_missing_data_security_mode_in_submit_run_clusters(lint_with):\n    messages = (\n        lint_with(AirflowChecker)\n        << \"\"\"from airflow.providers.databricks.operators.databricks import DatabricksSubmitRunOperator\nnew_cluster = {\"spark_version\": \"10.1.x-scala2.12\", \"num_workers\": 2}\nnotebook_task = {\n    \"notebook_path\": \"/Users/airflow@example.com/PrepareData\",\n}\nDatabricksSubmitRunOperator( #@\n    task_id=\"notebook_run\", new_cluster=new_cluster, notebook_task=notebook_task\n)\"\"\"\n    )\n    assert \"[unsupported-runtime] ephemeral cluster has unsupported runtime: 10.1.x-scala2.12\" in messages\n    assert (\n        \"[missing-data-security-mode] ephemeral cluster missing `data_security_mode` \"\n        \"required for Unity Catalog compatibility\"\n    ) in messages"
            },
            "tests/test_dbutils.py::test_checks_cp": {
                "testid": "tests/test_dbutils.py::test_checks_cp",
                "result": "passed",
                "test_implementation": "def test_checks_cp(lint_with):\n    messages = lint_with(DbutilsChecker) << \"dbutils.fs.cp('foo', 'bar')\"\n    assert \"[dbutils-fs-cp] Use Databricks SDK instead: w.dbfs.copy('foo', 'bar')\" in messages"
            },
            "tests/test_dbutils.py::test_checks_head": {
                "testid": "tests/test_dbutils.py::test_checks_head",
                "result": "passed",
                "test_implementation": "def test_checks_head(lint_with):\n    messages = lint_with(DbutilsChecker) << \"\"\"dbutils.fs.head(\"/tmp/my_file.txt\", 25)\"\"\"\n    assert (\n        \"[dbutils-fs-head] Use Databricks SDK instead: with \"\n        \"w.dbfs.download('/tmp/my_file.txt') as f: f.read()\" in messages\n    )"
            },
            "tests/test_dbutils.py::test_checks_list": {
                "testid": "tests/test_dbutils.py::test_checks_list",
                "result": "passed",
                "test_implementation": "def test_checks_list(lint_with):\n    messages = lint_with(DbutilsChecker) << \"\"\"dbutils.fs.ls(\"/tmp\")\"\"\"\n    assert \"[dbutils-fs-ls] Use Databricks SDK instead: w.dbfs.list('/tmp')\" in messages"
            },
            "tests/test_dbutils.py::test_checks_mount": {
                "testid": "tests/test_dbutils.py::test_checks_mount",
                "result": "passed",
                "test_implementation": "def test_checks_mount(lint_with):\n    messages = (\n        lint_with(DbutilsChecker)\n        << \"\"\"aws_bucket_name = \"my-bucket\"\nmount_name = \"s3-my-bucket\"\ndbutils.fs.mount(\"s3a://%s\" % aws_bucket_name, \"/mnt/%s\" % mount_name)\"\"\"\n    )\n    assert (\n        \"[dbutils-fs-mount] Mounts are not supported with Unity Catalog, \"\n        \"switch to using Unity Catalog Volumes instead\"\n    ) in messages"
            },
            "tests/test_dbutils.py::test_checks_credentials": {
                "testid": "tests/test_dbutils.py::test_checks_credentials",
                "result": "passed",
                "test_implementation": "def test_checks_credentials(lint_with):\n    messages = lint_with(DbutilsChecker) << \"\"\"dbutils.credentials.assumeRole(\"arn:aws:iam::...:roles/my-role\")\"\"\"\n    assert \"[dbutils-credentials] Credentials utility is not supported with Unity Catalog\" in messages"
            },
            "tests/test_dbutils.py::test_checks_notebook_run": {
                "testid": "tests/test_dbutils.py::test_checks_notebook_run",
                "result": "passed",
                "test_implementation": "def test_checks_notebook_run(lint_with):\n    messages = lint_with(DbutilsChecker) << \"\"\"dbutils.notebook.run(\"my_notebook\", 5)\"\"\"\n    assert len(messages) == 1"
            },
            "tests/test_dbutils.py::test_checks_secrets": {
                "testid": "tests/test_dbutils.py::test_checks_secrets",
                "result": "passed",
                "test_implementation": "def test_checks_secrets(lint_with):\n    messages = (\n        lint_with(DbutilsChecker)\n        << \"\"\"do_something(\n        'dapi00000000', #@ \n        'other',\n    )\"\"\"\n    )\n    assert (\n        \"[pat-token-leaked] Use Databricks SDK instead: from databricks.sdk import \"\n        \"WorkspaceClient(); w = WorkspaceClient()\"\n    ) in messages"
            },
            "tests/test_dbutils.py::test_internal_api[import dbruntime.foo, bar]": {
                "testid": "tests/test_dbutils.py::test_internal_api[import dbruntime.foo, bar]",
                "result": "passed",
                "test_implementation": "def test_internal_api(lint_with, code):\n    messages = lint_with(DbutilsChecker) << code\n    assert f\"[internal-api] Do not use internal APIs, rewrite using Databricks SDK: {code}\" in messages"
            },
            "tests/test_dbutils.py::test_internal_api[from dbruntime.foo import bar, baz]": {
                "testid": "tests/test_dbutils.py::test_internal_api[from dbruntime.foo import bar, baz]",
                "result": "passed",
                "test_implementation": "def test_internal_api(lint_with, code):\n    messages = lint_with(DbutilsChecker) << code\n    assert f\"[internal-api] Do not use internal APIs, rewrite using Databricks SDK: {code}\" in messages"
            },
            "tests/test_dbutils.py::test_internal_api[dbutils.notebook.entry_point.getDbutils()]": {
                "testid": "tests/test_dbutils.py::test_internal_api[dbutils.notebook.entry_point.getDbutils()]",
                "result": "passed",
                "test_implementation": "def test_internal_api(lint_with, code):\n    messages = lint_with(DbutilsChecker) << code\n    assert f\"[internal-api] Do not use internal APIs, rewrite using Databricks SDK: {code}\" in messages"
            },
            "tests/test_dbutils.py::test_internal_api[whatever['foo'].notebook.entry_point.getDbutils()]": {
                "testid": "tests/test_dbutils.py::test_internal_api[whatever['foo'].notebook.entry_point.getDbutils()]",
                "result": "passed",
                "test_implementation": "def test_internal_api(lint_with, code):\n    messages = lint_with(DbutilsChecker) << code\n    assert f\"[internal-api] Do not use internal APIs, rewrite using Databricks SDK: {code}\" in messages"
            },
            "tests/test_dbutils.py::test_internal_api[dbutils.notebook.entry_point.getDbutils().notebook().getContext()]": {
                "testid": "tests/test_dbutils.py::test_internal_api[dbutils.notebook.entry_point.getDbutils().notebook().getContext()]",
                "result": "passed",
                "test_implementation": "def test_internal_api(lint_with, code):\n    messages = lint_with(DbutilsChecker) << code\n    assert f\"[internal-api] Do not use internal APIs, rewrite using Databricks SDK: {code}\" in messages"
            },
            "tests/test_dbutils.py::test_internal_api[blueberry.notebook().getContext().foo()]": {
                "testid": "tests/test_dbutils.py::test_internal_api[blueberry.notebook().getContext().foo()]",
                "result": "passed",
                "test_implementation": "def test_internal_api(lint_with, code):\n    messages = lint_with(DbutilsChecker) << code\n    assert f\"[internal-api] Do not use internal APIs, rewrite using Databricks SDK: {code}\" in messages"
            },
            "tests/test_dbutils.py::test_internal_api[banana.apiToken()]": {
                "testid": "tests/test_dbutils.py::test_internal_api[banana.apiToken()]",
                "result": "passed",
                "test_implementation": "def test_internal_api(lint_with, code):\n    messages = lint_with(DbutilsChecker) << code\n    assert f\"[internal-api] Do not use internal APIs, rewrite using Databricks SDK: {code}\" in messages"
            },
            "tests/test_legacy.py::test_legacy_cli[import databricks_cli.foo]": {
                "testid": "tests/test_legacy.py::test_legacy_cli[import databricks_cli.foo]",
                "result": "passed",
                "test_implementation": "def test_legacy_cli(lint_with, code):\n    messages = lint_with(LegacyChecker) << code\n    assert \"[legacy-cli] Don't use databricks_cli, use databricks.sdk instead: pip install databricks-sdk\" in messages"
            },
            "tests/test_legacy.py::test_legacy_cli[from databricks_cli.foo import bar]": {
                "testid": "tests/test_legacy.py::test_legacy_cli[from databricks_cli.foo import bar]",
                "result": "passed",
                "test_implementation": "def test_legacy_cli(lint_with, code):\n    messages = lint_with(LegacyChecker) << code\n    assert \"[legacy-cli] Don't use databricks_cli, use databricks.sdk instead: pip install databricks-sdk\" in messages"
            },
            "tests/test_legacy.py::test_un_incompatible[spark.sql(\\n            'SELECT * FROM hive_metastore.default.foo' #@\\n        )]": {
                "testid": "tests/test_legacy.py::test_un_incompatible[spark.sql(\\n            'SELECT * FROM hive_metastore.default.foo' #@\\n        )]",
                "result": "passed",
                "test_implementation": "def test_un_incompatible(lint_with, code):\n    messages = lint_with(LegacyChecker) << code\n    assert \"[incompatible-with-uc] Incompatible with Unity Catalog\" in messages.pop()"
            },
            "tests/test_legacy.py::test_un_incompatible[spark.read.format('delta').load(\\n            'dbfs:/foo/bar' #@\\n        )]": {
                "testid": "tests/test_legacy.py::test_un_incompatible[spark.read.format('delta').load(\\n            'dbfs:/foo/bar' #@\\n        )]",
                "result": "passed",
                "test_implementation": "def test_un_incompatible(lint_with, code):\n    messages = lint_with(LegacyChecker) << code\n    assert \"[incompatible-with-uc] Incompatible with Unity Catalog\" in messages.pop()"
            },
            "tests/test_legacy.py::test_un_incompatible[{\\n            'kafka.sasl.client.callback.handler.class': 'foo', #@\\n        }]": {
                "testid": "tests/test_legacy.py::test_un_incompatible[{\\n            'kafka.sasl.client.callback.handler.class': 'foo', #@\\n        }]",
                "result": "passed",
                "test_implementation": "def test_un_incompatible(lint_with, code):\n    messages = lint_with(LegacyChecker) << code\n    assert \"[incompatible-with-uc] Incompatible with Unity Catalog\" in messages.pop()"
            },
            "tests/test_legacy.py::test_un_incompatible[import pyspark.ml.foo]": {
                "testid": "tests/test_legacy.py::test_un_incompatible[import pyspark.ml.foo]",
                "result": "passed",
                "test_implementation": "def test_un_incompatible(lint_with, code):\n    messages = lint_with(LegacyChecker) << code\n    assert \"[incompatible-with-uc] Incompatible with Unity Catalog\" in messages.pop()"
            },
            "tests/test_legacy.py::test_un_incompatible[from pyspark.ml import bar]": {
                "testid": "tests/test_legacy.py::test_un_incompatible[from pyspark.ml import bar]",
                "result": "passed",
                "test_implementation": "def test_un_incompatible(lint_with, code):\n    messages = lint_with(LegacyChecker) << code\n    assert \"[incompatible-with-uc] Incompatible with Unity Catalog\" in messages.pop()"
            },
            "tests/test_legacy.py::test_un_incompatible[import graphframes]": {
                "testid": "tests/test_legacy.py::test_un_incompatible[import graphframes]",
                "result": "passed",
                "test_implementation": "def test_un_incompatible(lint_with, code):\n    messages = lint_with(LegacyChecker) << code\n    assert \"[incompatible-with-uc] Incompatible with Unity Catalog\" in messages.pop()"
            },
            "tests/test_legacy.py::test_un_incompatible[import boto3]": {
                "testid": "tests/test_legacy.py::test_un_incompatible[import boto3]",
                "result": "passed",
                "test_implementation": "def test_un_incompatible(lint_with, code):\n    messages = lint_with(LegacyChecker) << code\n    assert \"[incompatible-with-uc] Incompatible with Unity Catalog\" in messages.pop()"
            },
            "tests/test_legacy.py::test_un_incompatible[import s3fs]": {
                "testid": "tests/test_legacy.py::test_un_incompatible[import s3fs]",
                "result": "passed",
                "test_implementation": "def test_un_incompatible(lint_with, code):\n    messages = lint_with(LegacyChecker) << code\n    assert \"[incompatible-with-uc] Incompatible with Unity Catalog\" in messages.pop()"
            },
            "tests/test_legacy.py::test_un_incompatible[spark.catalog.list()]": {
                "testid": "tests/test_legacy.py::test_un_incompatible[spark.catalog.list()]",
                "result": "passed",
                "test_implementation": "def test_un_incompatible(lint_with, code):\n    messages = lint_with(LegacyChecker) << code\n    assert \"[incompatible-with-uc] Incompatible with Unity Catalog\" in messages.pop()"
            },
            "tests/test_legacy.py::test_un_incompatible[spark._jsparkSession.catalog.listTables()]": {
                "testid": "tests/test_legacy.py::test_un_incompatible[spark._jsparkSession.catalog.listTables()]",
                "result": "passed",
                "test_implementation": "def test_un_incompatible(lint_with, code):\n    messages = lint_with(LegacyChecker) << code\n    assert \"[incompatible-with-uc] Incompatible with Unity Catalog\" in messages.pop()"
            },
            "tests/test_legacy.py::test_un_incompatible[spark._jspark.anything()]": {
                "testid": "tests/test_legacy.py::test_un_incompatible[spark._jspark.anything()]",
                "result": "passed",
                "test_implementation": "def test_un_incompatible(lint_with, code):\n    messages = lint_with(LegacyChecker) << code\n    assert \"[incompatible-with-uc] Incompatible with Unity Catalog\" in messages.pop()"
            },
            "tests/test_legacy.py::test_un_incompatible[spark._jvm.anything()]": {
                "testid": "tests/test_legacy.py::test_un_incompatible[spark._jvm.anything()]",
                "result": "passed",
                "test_implementation": "def test_un_incompatible(lint_with, code):\n    messages = lint_with(LegacyChecker) << code\n    assert \"[incompatible-with-uc] Incompatible with Unity Catalog\" in messages.pop()"
            },
            "tests/test_legacy.py::test_un_incompatible[df._jdf.anything()]": {
                "testid": "tests/test_legacy.py::test_un_incompatible[df._jdf.anything()]",
                "result": "passed",
                "test_implementation": "def test_un_incompatible(lint_with, code):\n    messages = lint_with(LegacyChecker) << code\n    assert \"[incompatible-with-uc] Incompatible with Unity Catalog\" in messages.pop()"
            },
            "tests/test_legacy.py::test_un_incompatible[df['foo']._jcol.anything()]": {
                "testid": "tests/test_legacy.py::test_un_incompatible[df['foo']._jcol.anything()]",
                "result": "passed",
                "test_implementation": "def test_un_incompatible(lint_with, code):\n    messages = lint_with(LegacyChecker) << code\n    assert \"[incompatible-with-uc] Incompatible with Unity Catalog\" in messages.pop()"
            },
            "tests/test_legacy.py::test_un_incompatible[sc.setLocalProperty('foo', 'bar')]": {
                "testid": "tests/test_legacy.py::test_un_incompatible[sc.setLocalProperty('foo', 'bar')]",
                "result": "passed",
                "test_implementation": "def test_un_incompatible(lint_with, code):\n    messages = lint_with(LegacyChecker) << code\n    assert \"[incompatible-with-uc] Incompatible with Unity Catalog\" in messages.pop()"
            },
            "tests/test_mocking.py::test_obscure_mock": {
                "testid": "tests/test_mocking.py::test_obscure_mock",
                "result": "passed",
                "test_implementation": "def test_obscure_mock(lint_with):\n    messages = lint_with(MockingChecker) << \"MagicMock()\"\n    _ = \"[obscure-mock] Obscure implicit test dependency with MagicMock(). Rewrite with create_autospec(ConcreteType).\"\n    assert _ in messages"
            },
            "tests/test_mocking.py::test_explicit_dependency_required": {
                "testid": "tests/test_mocking.py::test_explicit_dependency_required",
                "result": "passed",
                "test_implementation": "def test_explicit_dependency_required(lint_with):\n    messages = lint_with(MockingChecker) << \"mocker.patch('databricks.sdk.foo')\"\n\n    _ = (\n        \"[explicit-dependency-required] Obscure implicit test dependency with mock.patch('databricks.sdk.foo'). \"\n        \"Rewrite to inject dependencies through constructor.\"\n    )\n    assert _ in messages"
            },
            "tests/test_mocking.py::test_mock_in_function_arg": {
                "testid": "tests/test_mocking.py::test_mock_in_function_arg",
                "result": "passed",
                "test_implementation": "def test_mock_in_function_arg(lint_with):\n    messages = (\n        lint_with(MockingChecker)\n        << \"\"\"some_fn(\n    some_arg,\n    create_autospec(ConcreteType), #@\n    True,\n)\"\"\"\n    )\n\n    assert \"[mock-no-assign] Mock not assigned to a variable: create_autospec(ConcreteType)\" in messages"
            },
            "tests/test_mocking.py::test_mock_not_assigned": {
                "testid": "tests/test_mocking.py::test_mock_not_assigned",
                "result": "passed",
                "test_implementation": "def test_mock_not_assigned(lint_with):\n    messages = (\n        lint_with(MockingChecker)\n        << \"\"\"_ = 1\ncreate_autospec(ConcreteType) #@\nsome_fn(some_arg, True)\n\"\"\"\n    )\n\n    assert \"[mock-no-assign] Mock not assigned to a variable: create_autospec(ConcreteType)\" in messages"
            },
            "tests/test_mocking.py::test_mock_return_value_real": {
                "testid": "tests/test_mocking.py::test_mock_return_value_real",
                "result": "passed",
                "test_implementation": "def test_mock_return_value_real(lint_with):\n    messages = (\n        lint_with(MockingChecker)\n        << \"\"\"with _lock:\n    installation = mock_installation()\n    if 'workspace_client' not in replace:\n        ws = (\n            create_autospec(WorkspaceClient) #@\n        )\n        ws.api_client.do.return_value = {}\n        ws.permissions.get.return_value = {}\n        replace['workspace_client'] = ws\n    if 'sql_backend' not in replace:\n        replace['sql_backend'] = MockBackend()\n\"\"\"\n    )\n\n    assert not messages"
            },
            "tests/test_mocking.py::test_mock_is_asserted": {
                "testid": "tests/test_mocking.py::test_mock_is_asserted",
                "result": "passed",
                "test_implementation": "def test_mock_is_asserted(lint_with):\n    messages = (\n        lint_with(MockingChecker)\n        << \"\"\"_ = 1\nmocked_thing = ( # wrapping in parentheses to fetch call node\n    create_autospec(ConcreteType) #@\n)\nmocked_thing.foo.bar.return_value = 42\nsome_fn(some_arg, mocked_thing, True)\nmocked_thing.foo.bar.assert_called_once()\n\"\"\"\n    )\n\n    assert not messages"
            },
            "tests/test_readability.py::test_single_line_list_comprehensions_allowed": {
                "testid": "tests/test_readability.py::test_single_line_list_comprehensions_allowed",
                "result": "passed",
                "test_implementation": "def test_single_line_list_comprehensions_allowed(lint_with):\n    messages = lint_with(ReadabilityChecker) << \"\"\"[x for x in range(10) if x % 2 == 0]\"\"\"\n    assert not messages"
            },
            "tests/test_readability.py::test_multi_line_list_comprehensions_not_allowed": {
                "testid": "tests/test_readability.py::test_multi_line_list_comprehensions_not_allowed",
                "result": "passed",
                "test_implementation": "def test_multi_line_list_comprehensions_not_allowed(lint_with):\n    messages = (\n        lint_with(ReadabilityChecker)\n        << \"\"\"[\n        x for x in range(10) if x % 2 == 0\n    ]\"\"\"\n    )\n    assert messages == {\"[rewrite-as-for-loop] List comprehension spans multiple lines, rewrite as for loop\"}"
            },
            "tests/test_samples.py::test_samples[dead_code]": {
                "testid": "tests/test_samples.py::test_samples[dead_code]",
                "result": "passed",
                "test_implementation": "def test_samples(sample: FunctionalTestFile) -> None:\n    thing = LintModuleTest(sample)\n    all.register(thing._linter)\n    thing.setUp()\n    thing.runTest()"
            },
            "tests/test_samples.py::test_samples[many_cells]": {
                "testid": "tests/test_samples.py::test_samples[many_cells]",
                "result": "passed",
                "test_implementation": "def test_samples(sample: FunctionalTestFile) -> None:\n    thing = LintModuleTest(sample)\n    all.register(thing._linter)\n    thing.setUp()\n    thing.runTest()"
            },
            "tests/test_samples.py::test_samples[percent_run]": {
                "testid": "tests/test_samples.py::test_samples[percent_run]",
                "result": "passed",
                "test_implementation": "def test_samples(sample: FunctionalTestFile) -> None:\n    thing = LintModuleTest(sample)\n    all.register(thing._linter)\n    thing.setUp()\n    thing.runTest()"
            },
            "tests/test_spark.py::test_spark_inside_function": {
                "testid": "tests/test_spark.py::test_spark_inside_function",
                "result": "passed",
                "test_implementation": "def test_spark_inside_function(lint_with):\n    messages = (\n        lint_with(SparkChecker)\n        << \"\"\"def do_something(spark, x):\n    for i in range(10):\n        if i > 3:\n            continue\n        spark #@\n\"\"\"\n    )\n    assert not messages"
            },
            "tests/test_spark.py::test_spark_outside_function": {
                "testid": "tests/test_spark.py::test_spark_outside_function",
                "result": "passed",
                "test_implementation": "def test_spark_outside_function(lint_with):\n    messages = (\n        lint_with(SparkChecker)\n        << \"\"\"for i in range(10):\n    if i > 3:\n        continue\n    spark #@\n\"\"\"\n    )\n    assert \"[spark-outside-function] Using spark outside the function is leading to untestable code\" in messages"
            },
            "tests/test_spark.py::test_spark_inside_of_function_but_not_in_args": {
                "testid": "tests/test_spark.py::test_spark_inside_of_function_but_not_in_args",
                "result": "passed",
                "test_implementation": "def test_spark_inside_of_function_but_not_in_args(lint_with):\n    messages = (\n        lint_with(SparkChecker)\n        << \"\"\"def do_something(x):\n    for i in range(10):\n        if i > 3:\n            continue\n        spark #@\n\"\"\"\n    )\n    assert \"[no-spark-argument-in-function] Function do_something is missing a 'spark' argument\" in messages"
            },
            "tests/test_spark.py::test_df_show": {
                "testid": "tests/test_spark.py::test_df_show",
                "result": "passed",
                "test_implementation": "def test_df_show(lint_with):\n    messages = lint_with(SparkChecker) << \"\"\"__(spark.read.csv('file.csv').show)()\"\"\"\n    assert (\n        \"[use-display-instead-of-show] Rewrite to display in a notebook: display(spark.read.csv('file.csv'))\"\n        in messages\n    )"
            }
        },
        "SRS_document": "**Software Requirements Specification: PyLint Plugin for Databricks**\n\n**1. Introduction**\n\n**1.1 Purpose**\nThis Software Requirements Specification (SRS) document provides a detailed description of the functional and non-functional requirements for the \"PyLint Plugin for Databricks.\" The primary purpose of this SRS is to serve as a definitive guide for software developers who will be tasked with implementing this system. Developers will use this SRS and a subset of public test cases to build the software. Their success will be measured by passing all original test cases, including private ones. Therefore, this document emphasizes clarity, comprehensiveness in functional capabilities, and an appropriate level of abstraction to allow for independent design and implementation choices while ensuring all specified functionalities are met.\n\n**1.2 Scope**\nThe software to be developed is a plugin for the PyLint static code analysis tool. This plugin extends PyLint's capabilities by adding checks specifically designed to identify common mistakes, potential issues, and deviations from best practices in Python code written for the Databricks environment. The plugin also includes a command-line interface (CLI) tool for linting Databricks notebooks.\n\nThe plugin will:\n*   Integrate with the PyLint framework.\n*   Provide a series of specific linting checks categorized by functionality (e.g., Airflow, dbutils, Spark usage, legacy code, notebook structure, mocking practices, readability, and dead code).\n*   Report violations with unique message IDs, symbols, and descriptive messages.\n*   Offer configurability for certain checks.\n*   Provide a CLI utility (`nbcheck`) for linting Python notebooks within a Databricks workspace.\n\nThis SRS defines *what* the plugin and its CLI tool must do, not *how* it should be implemented internally.\n\n**1.3 Definitions, Acronyms, and Abbreviations**\n*   **CLI:** Command-Line Interface\n*   **FR:** Functional Requirement\n*   **NFR:** Non-Functional Requirement\n*   **Pylint:** A static code analysis tool for Python.\n*   **SRS:** Software Requirements Specification\n*   **Databricks:** The data and AI company, and its associated platform.\n*   **SDK:** Software Development Kit\n*   **UC:** Unity Catalog\n*   **AST:** Abstract Syntax Tree\n*   **PAT:** Personal Access Token\n*   **ID:** Identifier\n\n**1.4 References**\n*   Original Project README: Provided as input.\n*   Original Source Code: Provided as input (for LLM contextual understanding only).\n*   Original Test Cases: Provided as input.\n\n**1.5 Overview**\nThe remainder of this document describes the overall system characteristics and specific requirements. Section 2 provides a general description of the software, its context, and user characteristics. Section 3 details the specific functional and non-functional requirements.\n\n**2. Overall Description**\n\n**2.1 Product Perspective**\nThe PyLint Plugin for Databricks is an extension to the Pylint static code analysis tool. It operates within the Pylint ecosystem and is loaded as a plugin. It enhances Pylint by providing specialized checks tailored for Python development on the Databricks platform. It also includes a standalone CLI component that leverages this plugin to analyze Databricks notebooks.\n\n**2.2 Product Functions**\nThe primary functions of the system are:\n*   **Static Code Analysis:** To analyze Python code and identify specific patterns, practices, or anti-patterns relevant to Databricks development.\n*   **Issue Reporting:** To report detected issues with clear messages, codes, and severity levels, consistent with Pylint's reporting mechanisms.\n*   **Configurability:** To allow users to configure certain checks via Pylint's standard configuration mechanisms.\n*   **Databricks Notebook Linting:** To provide a CLI tool capable of fetching Python notebooks from a Databricks workspace and linting them using the plugin's checks.\n\n**2.3 User Characteristics**\nThe primary users of this software are Python developers working within the Databricks ecosystem. They are expected to be familiar with Python, Pylint, and Databricks development practices.\n\n**2.4 Constraints**\n*   The system must be implementable as a Pylint plugin.\n*   The system must be able to parse and analyze Python code compatible with Python versions 3.8 through 3.12 (as indicated by CI in README).\n*   The CLI tool (`nbcheck`) requires interaction with a Databricks workspace.\n\n**2.5 Assumptions and Dependencies**\n*   Pylint is installed and available in the environment where the plugin is used.\n*   For the `nbcheck` CLI tool, appropriate Databricks SDK and credentials must be configured for workspace interaction.\n*   The structure of Databricks notebooks (e.g., `# Databricks notebook source`, `# COMMAND ----------`) is consistent with standard Databricks formats.\n\n**3. Specific Requirements**\n\n**3.1 Functional Requirements**\n\n**3.1.1 General Plugin Behavior**\n*   **FR-GP-001:** The system shall be loadable as a Pylint plugin using the entry point `databricks.labs.pylint.all`.\n\n**3.1.2 `databricks-airflow` Checker**\nThis checker focuses on configurations related to Databricks operators in Apache Airflow.\n\n*   **FR-DA-001:** The system shall detect when an Airflow `DatabricksCreateJobsOperator` or `DatabricksSubmitRunOperator` call defines a cluster (either via `new_cluster` in tasks, `job_clusters`, or directly as `new_cluster` argument) that is missing the `data_security_mode` attribute in its configuration.\n    *   Upon detection, the system shall issue a 'missing-data-security-mode' (W8901) warning.\n    *   The warning message shall be: \"`<cluster_identifier>` cluster missing `data_security_mode` required for Unity Catalog compatibility.\" where `<cluster_identifier>` is the job cluster key, task key, or \"ephemeral\" for clusters defined directly in `DatabricksSubmitRunOperator`.\n\n*   **FR-DA-002:** The system shall detect when an Airflow `DatabricksCreateJobsOperator` or `DatabricksSubmitRunOperator` call defines a cluster with a `spark_version` that is not supported for Unity Catalog (i.e., runtime version less than 11.3).\n    *   Upon detection, the system shall issue an 'unsupported-runtime' (W8902) warning.\n    *   The warning message shall be: \"`<cluster_identifier>` cluster has unsupported runtime: `<spark_version>`.\" where `<cluster_identifier>` is the job cluster key, task key, or \"ephemeral\", and `<spark_version>` is the detected runtime version.\n\n**3.1.3 `databricks-dbutils` Checker**\nThis checker focuses on the usage of `dbutils` utilities, often recommending Databricks SDK alternatives.\n\n*   **FR-DU-001:** The system shall detect calls to `dbutils.fs.cp(<arg1>, <arg2>)`.\n    *   Upon detection, the system shall issue a 'dbutils-fs-cp' (R8903) message.\n    *   The message shall be: \"Use Databricks SDK instead: w.dbfs.copy(`<arg1_val>`, `<arg2_val>`).\" where `<arg1_val>` and `<arg2_val>` are the string representations of the arguments passed to `dbutils.fs.cp`.\n\n*   **FR-DU-002:** The system shall detect calls to `dbutils.fs.head(<arg1>, ...)`.\n    *   Upon detection, the system shall issue a 'dbutils-fs-head' (R8904) message.\n    *   The message shall be: \"Use Databricks SDK instead: with w.dbfs.download(`<arg1_val>`) as f: f.read().\" where `<arg1_val>` is the string representation of the first argument to `dbutils.fs.head`.\n\n*   **FR-DU-003:** The system shall detect calls to `dbutils.fs.ls(<arg1>)`.\n    *   Upon detection, the system shall issue a 'dbutils-fs-ls' (R8905) message.\n    *   The message shall be: \"Use Databricks SDK instead: w.dbfs.list(`<arg1_val>`).\" where `<arg1_val>` is the string representation of the argument to `dbutils.fs.ls`.\n\n*   **FR-DU-004:** The system shall detect calls to `dbutils.fs.mount`, `dbutils.fs.mounts`, `dbutils.fs.unmount`, `dbutils.fs.updateMount`, or `dbutils.fs.refreshMounts`.\n    *   Upon detection, the system shall issue a 'dbutils-fs-mount' (R8906) message.\n    *   The message shall be: \"Mounts are not supported with Unity Catalog, switch to using Unity Catalog Volumes instead.\"\n\n*   **FR-DU-005:** The system shall detect calls to any function within the `dbutils.credentials` module (e.g., `dbutils.credentials.assumeRole(...)`).\n    *   Upon detection, the system shall issue a 'dbutils-credentials' (R8907) message.\n    *   The message shall be: \"Credentials utility is not supported with Unity Catalog.\"\n\n*   **FR-DU-006:** The system shall detect calls to `dbutils.notebook.run(<path_arg>, <timeout_arg>)`.\n    *   Upon detection, the system shall issue a 'dbutils-notebook-run' (R8908) message.\n    *   The message shall suggest using the Databricks SDK: \"Use Databricks SDK instead: w.jobs.submit(tasks=[jobs.SubmitTask(existing_cluster_id=..., notebook_task=jobs.NotebookTask(notebook_path=`<path_arg_val>`), task_key=...) ]).result(timeout=timedelta(minutes=`<timeout_arg_val>`)).\" where `<path_arg_val>` and `<timeout_arg_val>` are the string representations of the arguments.\n\n*   **FR-DU-007:** The system shall detect string constants that appear to be Databricks Personal Access Tokens (PATs), specifically strings starting with \"dapi\", \"dkea\", or \"dosa\" followed by what looks like a token.\n    *   Upon detection, the system shall issue a 'pat-token-leaked' (R8909) message.\n    *   The message shall be: \"Use Databricks SDK instead: from databricks.sdk import WorkspaceClient(); w = WorkspaceClient().\"\n\n*   **FR-DU-008:** The system shall detect usage of internal Databricks APIs. This includes:\n    *   Imports from `dbruntime` (e.g., `import dbruntime.foo`, `from dbruntime.foo import bar`).\n    *   Calls to functions ending with `getDbutils` (e.g., `dbutils.notebook.entry_point.getDbutils()`).\n    *   Calls containing `.notebook().getContext()` in the call chain (e.g., `blueberry.notebook().getContext().foo()`).\n    *   Calls containing `.notebook.entry_point` in the call chain.\n    *   Calls containing `.apiToken` in the call chain (e.g., `banana.apiToken()`).\n    *   Upon detection, the system shall issue an 'internal-api' (R8910) message.\n    *   The message shall be: \"Do not use internal APIs, rewrite using Databricks SDK: `<detected_code_snippet>`.\" where `<detected_code_snippet>` is the offending code.\n\n**3.1.4 `databricks-legacy` Checker**\nThis checker identifies usage of outdated or Unity Catalog-incompatible features.\n\n*   **FR-DL-001:** The system shall detect imports from the `databricks_cli` package (e.g., `import databricks_cli.foo`, `from databricks_cli.foo import bar`).\n    *   Upon detection, the system shall issue a 'legacy-cli' (R8911) message.\n    *   The message shall be: \"Don't use databricks_cli, use databricks.sdk instead: pip install databricks-sdk.\"\n\n*   **FR-DL-002:** The system shall detect various code patterns known to be incompatible with Unity Catalog. These include, but are not limited to:\n    *   Imports of `s3fs`, `boto3`, `graphframes`, `pyspark.ml`.\n    *   String literals containing `dbfs:`, `hive_metastore.`, or specific Kafka configuration keys like `kafka.sasl.client.callback.handler.class`.\n    *   Function/method calls like `spark.catalog.*`, `spark._jsparkSession.catalog.*`, `spark._jspark.*`, `spark._jvm.*`, `._jdf`, `._jcol`, `sc.setLocalProperty`, etc.\n    *   Upon detection, the system shall issue an 'incompatible-with-uc' (W8912) message.\n    *   The message shall be: \"Incompatible with Unity Catalog: `<detected_code_snippet>`.\" where `<detected_code_snippet>` is the offending code.\n\n**3.1.5 `databricks-notebooks` Checker**\nThis checker analyzes the structure and content of Databricks notebooks.\n\n*   **FR-DN-001:** The system shall check if a Databricks notebook (identified by starting with `# Databricks notebook source\\n`) exceeds a configurable maximum number of cells.\n    *   A cell is delimited by the comment `# COMMAND ----------\\n`.\n    *   The default maximum number of cells is 75. This should be configurable via the `max-cells` Pylint option for this checker.\n    *   If the number of cells exceeds the configured maximum, the system shall issue a 'notebooks-too-many-cells' (C8913) message.\n    *   The message shall be: \"Notebooks should not have more than 75 cells.\" (The message text might not reflect the configured value but the default; the check logic uses the configured value).\n\n*   **FR-DN-002:** The system shall detect the use of `%run` magic commands (e.g., `# MAGIC %run ./something`) in Databricks notebooks.\n    *   Upon detection, the system shall issue a 'notebooks-percent-run' (R8914) message.\n    *   The message shall be: \"Using %run is not allowed.\"\n\n**3.1.6 `spark` Checker**\nThis checker focuses on best practices for using Apache Spark.\n\n*   **FR-SP-001:** The system shall detect the usage of a SparkSession object (typically named `spark`) outside of a function definition at the module/global scope.\n    *   Upon detection, the system shall issue a 'spark-outside-function' (C8915) message.\n    *   The message shall be: \"Using spark outside the function is leading to untestable code.\"\n\n*   **FR-SP-002:** The system shall detect calls to `.show()` on a Spark DataFrame (e.g., `df.show()`).\n    *   Upon detection, the system shall issue a 'use-display-instead-of-show' (C8917) message.\n    *   The message shall be: \"Rewrite to display in a notebook: display(`<dataframe_expression>`).\" where `<dataframe_expression>` is the code producing the DataFrame on which `.show()` was called.\n\n*   **FR-SP-003:** The system shall detect when a function uses a SparkSession object (typically named `spark`) but does not include `spark` as one of its formal parameters.\n    *   Upon detection, the system shall issue a 'no-spark-argument-in-function' (W8916) message.\n    *   The message shall be: \"Function `<function_name>` is missing a 'spark' argument.\"\n\n**3.1.7 `readability` Checker**\nThis checker provides rules to improve code readability.\n\n*   **FR-RD-001:** The system shall detect list comprehensions that span multiple lines.\n    *   Upon detection, the system shall issue a 'rewrite-as-for-loop' (R8923) message.\n    *   The message shall be: \"List comprehension spans multiple lines, rewrite as for loop.\"\n\n**3.1.8 `mocking` Checker**\nThis checker focuses on best practices for using mocking libraries in tests.\n\n*   **FR-MK-001:** The system shall detect calls to `mocker.patch` or `patch` where the first argument (the target string) starts with a module name specified in the `require-explicit-dependency` Pylint option for this checker.\n    *   The default value for `require-explicit-dependency` is `databricks`. This should be configurable.\n    *   Upon detection, the system shall issue an 'explicit-dependency-required' (R8918) message.\n    *   The message shall be: \"Obscure implicit test dependency with mock.patch(`<target_string>`). Rewrite to inject dependencies through constructor.\"\n\n*   **FR-MK-002:** The system shall detect direct instantiation of `MagicMock()` (i.e., `MagicMock()` without arguments).\n    *   Upon detection, the system shall issue an 'obscure-mock' (R8919) message.\n    *   The message shall be: \"Obscure implicit test dependency with MagicMock(). Rewrite with create_autospec(ConcreteType).\"\n\n*   **FR-MK-003:** The system shall detect calls to `create_autospec(...)` that are not part of an assignment statement (e.g., the result is not assigned to a variable).\n    *   Upon detection, the system shall issue a 'mock-no-assign' (R8921) message.\n    *   The message shall be: \"Mock not assigned to a variable: `<create_autospec_call_string>`.\"\n\n*   **FR-MK-004:** The system shall detect when a mock object, created via `create_autospec(...)` and assigned to a variable, is not subsequently used for assertions (e.g., `mock_obj.method.assert_called_once()`) or to specify behavior (e.g., `mock_obj.method.return_value = ...`, `mock_obj.method.side_effect = ...`).\n    *   Upon detection, the system shall issue a 'mock-no-usage' (R8922) message.\n    *   The message shall be: \"Missing usage of mock for `<mocked_type_string>`.\" where `<mocked_type_string>` is the first argument to `create_autospec`.\n\n**3.1.9 `eradicate` Checker**\nThis checker identifies commented-out code.\n\n*   **FR-ER-001:** The system shall detect lines of Python code that have been commented out.\n    *   Upon detection, the system shall issue a 'dead-code' (C8920) message.\n    *   The message shall be: \"Remove commented out code: `<commented_code_line>`.\" where `<commented_code_line>` is the content of the commented-out line (stripped).\n\n**3.1.10 Databricks CLI Integration (`nbcheck`)**\nThis describes the functionality of the `databricks labs pylint-plugin nbcheck` command.\n\n*   **FR-CLI-001:** The system shall provide a mechanism to be installed as a Databricks CLI lab plugin, e.g., via `databricks labs install pylint-plugin`.\n\n*   **FR-CLI-002:** The `nbcheck` command, when run without a `--path` argument, shall attempt to lint all Python notebooks in the current user's home directory in the Databricks workspace.\n\n*   **FR-CLI-003:** The `nbcheck` command shall accept a `--path` flag (or equivalent configuration via JSON input, see FR-CLI-007) to specify a particular notebook file or a directory within the Databricks workspace to lint.\n    *   If a directory is specified, the system shall attempt to lint all Python notebooks within that directory.\n\n*   **FR-CLI-004:** The `nbcheck` command shall only process notebooks identified as Python notebooks by the Databricks workspace.\n\n*   **FR-CLI-005:** When linting notebooks via `nbcheck`, the system shall invoke Pylint with the `databricks.labs.pylint.all` plugin loaded, and with a specific, predefined set of checks enabled. This set includes: `missing-data-security-mode`, `unsupported-runtime`, `dbutils-fs-cp`, `dbutils-fs-head`, `dbutils-fs-ls`, `dbutils-fs-mount`, `dbutils-credentials`, `dbutils-notebook-run`, `pat-token-leaked`, `internal-api`, `legacy-cli`, `incompatible-with-uc`, `notebooks-too-many-cells`, `notebooks-percent-run`, `spark-outside-function`, `use-display-instead-of-show`, `no-spark-argument-in-function`. All other Pylint checks should be disabled by default for `nbcheck`.\n\n*   **FR-CLI-006:** The `nbcheck` command-line utility shall be invoked with a JSON payload string as its first system argument.\n\n*   **FR-CLI-007:** The JSON payload for `nbcheck` (see FR-CLI-006) shall contain a `flags` object. This `flags` object can include:\n    *   A `path` string: Specifies the Databricks workspace path to a notebook or directory for linting. If not provided, behavior is as per FR-CLI-002.\n    *   A `log_level` string (e.g., \"info\", \"debug\"): Controls the logging verbosity of the `nbcheck` tool, particularly for Databricks SDK interactions.\n\n**3.2 Non-Functional Requirements**\nThere are no specific non-functional requirements (e.g., performance, security hardening beyond functional checks, specific resource consumption limits) that can be directly verified by the provided original test cases. Therefore, no NFRs are formally specified in this document, adhering to the guideline that NFRs must have corresponding explicit original test cases.\n\n**4. Other Requirements**\n(Placeholder for sections like Interface Requirements, etc., if they were applicable and distinct from Functional Requirements. For this project, most interface aspects are covered by FRs, e.g., Pylint plugin interface, CLI arguments.)\n\n**Appendix A: Traceability Matrix (Summary)**\n(A full traceability matrix would be extensive. The Test Traceability and Source Code Traceability annotations directly within each requirement serve this purpose for this document.)",
        "structured_requirements": [
            {
                "requirement_id": "FR-GP-001",
                "requirement_description": "The system shall be loadable as a Pylint plugin using the entry point `databricks.labs.pylint.all`.",
                "test_traceability": [
                    {
                        "id": "tests/test_samples.py::test_samples",
                        "description": "Implicitly tested by all functional tests that load the plugin, e.g., ."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/all.py::register",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DA-001",
                "requirement_description": "The system shall detect when an Airflow `DatabricksCreateJobsOperator` or `DatabricksSubmitRunOperator` call defines a cluster (either via `new_cluster` in tasks, `job_clusters`, or directly as `new_cluster` argument) that is missing the `data_security_mode` attribute in its configuration.\n    *   Upon detection, the system shall issue a 'missing-data-security-mode' (W8901) warning.\n    *   The warning message shall be: \"`<cluster_identifier>` cluster missing `data_security_mode` required for Unity Catalog compatibility.\" where `<cluster_identifier>` is the job cluster key, task key, or \"ephemeral\" for clusters defined directly in `DatabricksSubmitRunOperator`.",
                "test_traceability": [
                    {
                        "id": "tests/test_airflow.py::test_missing_data_security_mode_in_job_clusters",
                        "description": ""
                    },
                    {
                        "id": "tests/test_airflow.py::test_missing_data_security_mode_in_task_clusters",
                        "description": ""
                    },
                    {
                        "id": "tests/test_airflow.py::test_missing_data_security_mode_in_submit_run_clusters",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/airflow.py::AirflowChecker::visit_call",
                        "description": ""
                    },
                    {
                        "id": "src/databricks/labs/pylint/airflow.py::AirflowChecker::_check_new_cluster",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DA-002",
                "requirement_description": "The system shall detect when an Airflow `DatabricksCreateJobsOperator` or `DatabricksSubmitRunOperator` call defines a cluster with a `spark_version` that is not supported for Unity Catalog (i.e., runtime version less than 11.3).\n    *   Upon detection, the system shall issue an 'unsupported-runtime' (W8902) warning.\n    *   The warning message shall be: \"`<cluster_identifier>` cluster has unsupported runtime: `<spark_version>`.\" where `<cluster_identifier>` is the job cluster key, task key, or \"ephemeral\", and `<spark_version>` is the detected runtime version.",
                "test_traceability": [
                    {
                        "id": "tests/test_airflow.py::test_missing_data_security_mode_in_submit_run_clusters",
                        "description": "(which also tests unsupported runtime)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/airflow.py::AirflowChecker::visit_call",
                        "description": ""
                    },
                    {
                        "id": "src/databricks/labs/pylint/airflow.py::AirflowChecker::_check_new_cluster",
                        "description": ""
                    },
                    {
                        "id": "src/databricks/labs/pylint/airflow.py::AirflowChecker::_is_supported",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DU-001",
                "requirement_description": "The system shall detect calls to `dbutils.fs.cp(<arg1>, <arg2>)`.\n    *   Upon detection, the system shall issue a 'dbutils-fs-cp' (R8903) message.\n    *   The message shall be: \"Use Databricks SDK instead: w.dbfs.copy(`<arg1_val>`, `<arg2_val>`).\" where `<arg1_val>` and `<arg2_val>` are the string representations of the arguments passed to `dbutils.fs.cp`.",
                "test_traceability": [
                    {
                        "id": "tests/test_dbutils.py::test_checks_cp",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/dbutils.py::DbutilsChecker::visit_call",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DU-002",
                "requirement_description": "The system shall detect calls to `dbutils.fs.head(<arg1>, ...)`.\n    *   Upon detection, the system shall issue a 'dbutils-fs-head' (R8904) message.\n    *   The message shall be: \"Use Databricks SDK instead: with w.dbfs.download(`<arg1_val>`) as f: f.read().\" where `<arg1_val>` is the string representation of the first argument to `dbutils.fs.head`.",
                "test_traceability": [
                    {
                        "id": "tests/test_dbutils.py::test_checks_head",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/dbutils.py::DbutilsChecker::visit_call",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DU-003",
                "requirement_description": "The system shall detect calls to `dbutils.fs.ls(<arg1>)`.\n    *   Upon detection, the system shall issue a 'dbutils-fs-ls' (R8905) message.\n    *   The message shall be: \"Use Databricks SDK instead: w.dbfs.list(`<arg1_val>`).\" where `<arg1_val>` is the string representation of the argument to `dbutils.fs.ls`.",
                "test_traceability": [
                    {
                        "id": "tests/test_dbutils.py::test_checks_list",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/dbutils.py::DbutilsChecker::visit_call",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DU-004",
                "requirement_description": "The system shall detect calls to `dbutils.fs.mount`, `dbutils.fs.mounts`, `dbutils.fs.unmount`, `dbutils.fs.updateMount`, or `dbutils.fs.refreshMounts`.\n    *   Upon detection, the system shall issue a 'dbutils-fs-mount' (R8906) message.\n    *   The message shall be: \"Mounts are not supported with Unity Catalog, switch to using Unity Catalog Volumes instead.\"",
                "test_traceability": [
                    {
                        "id": "tests/test_dbutils.py::test_checks_mount",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/dbutils.py::DbutilsChecker::visit_call",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DU-005",
                "requirement_description": "The system shall detect calls to any function within the `dbutils.credentials` module (e.g., `dbutils.credentials.assumeRole(...)`).\n    *   Upon detection, the system shall issue a 'dbutils-credentials' (R8907) message.\n    *   The message shall be: \"Credentials utility is not supported with Unity Catalog.\"",
                "test_traceability": [
                    {
                        "id": "tests/test_dbutils.py::test_checks_credentials",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/dbutils.py::DbutilsChecker::visit_call",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DU-006",
                "requirement_description": "The system shall detect calls to `dbutils.notebook.run(<path_arg>, <timeout_arg>)`.\n    *   Upon detection, the system shall issue a 'dbutils-notebook-run' (R8908) message.\n    *   The message shall suggest using the Databricks SDK: \"Use Databricks SDK instead: w.jobs.submit(tasks=[jobs.SubmitTask(existing_cluster_id=..., notebook_task=jobs.NotebookTask(notebook_path=`<path_arg_val>`), task_key=...) ]).result(timeout=timedelta(minutes=`<timeout_arg_val>`)).\" where `<path_arg_val>` and `<timeout_arg_val>` are the string representations of the arguments.",
                "test_traceability": [
                    {
                        "id": "tests/test_dbutils.py::test_checks_notebook_run",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/dbutils.py::DbutilsChecker::visit_call",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DU-007",
                "requirement_description": "The system shall detect string constants that appear to be Databricks Personal Access Tokens (PATs), specifically strings starting with \"dapi\", \"dkea\", or \"dosa\" followed by what looks like a token.\n    *   Upon detection, the system shall issue a 'pat-token-leaked' (R8909) message.\n    *   The message shall be: \"Use Databricks SDK instead: from databricks.sdk import WorkspaceClient(); w = WorkspaceClient().\"",
                "test_traceability": [
                    {
                        "id": "tests/test_dbutils.py::test_checks_secrets",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/dbutils.py::DbutilsChecker::visit_const",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DU-008",
                "requirement_description": "The system shall detect usage of internal Databricks APIs. This includes:\n    *   Imports from `dbruntime` (e.g., `import dbruntime.foo`, `from dbruntime.foo import bar`).\n    *   Calls to functions ending with `getDbutils` (e.g., `dbutils.notebook.entry_point.getDbutils()`).\n    *   Calls containing `.notebook().getContext()` in the call chain (e.g., `blueberry.notebook().getContext().foo()`).\n    *   Calls containing `.notebook.entry_point` in the call chain.\n    *   Calls containing `.apiToken` in the call chain (e.g., `banana.apiToken()`).\n    *   Upon detection, the system shall issue an 'internal-api' (R8910) message.\n    *   The message shall be: \"Do not use internal APIs, rewrite using Databricks SDK: `<detected_code_snippet>`.\" where `<detected_code_snippet>` is the offending code.",
                "test_traceability": [
                    {
                        "id": "tests/test_dbutils.py::test_internal_api",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/dbutils.py::DbutilsChecker::visit_call",
                        "description": ""
                    },
                    {
                        "id": "src/databricks/labs/pylint/dbutils.py::DbutilsChecker::visit_import",
                        "description": ""
                    },
                    {
                        "id": "src/databricks/labs/pylint/dbutils.py::DbutilsChecker::visit_importfrom",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DL-001",
                "requirement_description": "The system shall detect imports from the `databricks_cli` package (e.g., `import databricks_cli.foo`, `from databricks_cli.foo import bar`).\n    *   Upon detection, the system shall issue a 'legacy-cli' (R8911) message.\n    *   The message shall be: \"Don't use databricks_cli, use databricks.sdk instead: pip install databricks-sdk.\"",
                "test_traceability": [
                    {
                        "id": "tests/test_legacy.py::test_legacy_cli",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/legacy.py::LegacyChecker::visit_import",
                        "description": ""
                    },
                    {
                        "id": "src/databricks/labs/pylint/legacy.py::LegacyChecker::visit_importfrom",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DL-002",
                "requirement_description": "The system shall detect various code patterns known to be incompatible with Unity Catalog. These include, but are not limited to:\n    *   Imports of `s3fs`, `boto3`, `graphframes`, `pyspark.ml`.\n    *   String literals containing `dbfs:`, `hive_metastore.`, or specific Kafka configuration keys like `kafka.sasl.client.callback.handler.class`.\n    *   Function/method calls like `spark.catalog.*`, `spark._jsparkSession.catalog.*`, `spark._jspark.*`, `spark._jvm.*`, `._jdf`, `._jcol`, `sc.setLocalProperty`, etc.\n    *   Upon detection, the system shall issue an 'incompatible-with-uc' (W8912) message.\n    *   The message shall be: \"Incompatible with Unity Catalog: `<detected_code_snippet>`.\" where `<detected_code_snippet>` is the offending code.",
                "test_traceability": [
                    {
                        "id": "tests/test_legacy.py::test_un_incompatible",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/legacy.py::LegacyChecker::visit_import",
                        "description": ""
                    },
                    {
                        "id": "src/databricks/labs/pylint/legacy.py::LegacyChecker::visit_importfrom",
                        "description": ""
                    },
                    {
                        "id": "src/databricks/labs/pylint/legacy.py::LegacyChecker::visit_call",
                        "description": ""
                    },
                    {
                        "id": "src/databricks/labs/pylint/legacy.py::LegacyChecker::visit_const",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DN-001",
                "requirement_description": "The system shall check if a Databricks notebook (identified by starting with `# Databricks notebook source\\n`) exceeds a configurable maximum number of cells.\n    *   A cell is delimited by the comment `# COMMAND ----------\\n`.\n    *   The default maximum number of cells is 75. This should be configurable via the `max-cells` Pylint option for this checker.\n    *   If the number of cells exceeds the configured maximum, the system shall issue a 'notebooks-too-many-cells' (C8913) message.\n    *   The message shall be: \"Notebooks should not have more than 75 cells.\" (The message text might not reflect the configured value but the default; the check logic uses the configured value).",
                "test_traceability": [
                    {
                        "id": "tests/samples/m/many_cells.py",
                        "description": "(verified via `tests/test_samples.py`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/notebooks.py::NotebookChecker::process_module",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DN-002",
                "requirement_description": "The system shall detect the use of `%run` magic commands (e.g., `# MAGIC %run ./something`) in Databricks notebooks.\n    *   Upon detection, the system shall issue a 'notebooks-percent-run' (R8914) message.\n    *   The message shall be: \"Using %run is not allowed.\"",
                "test_traceability": [
                    {
                        "id": "tests/samples/p/percent_run.py",
                        "description": "(verified via `tests/test_samples.py`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/notebooks.py::NotebookChecker::process_module",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SP-001",
                "requirement_description": "The system shall detect the usage of a SparkSession object (typically named `spark`) outside of a function definition at the module/global scope.\n    *   Upon detection, the system shall issue a 'spark-outside-function' (C8915) message.\n    *   The message shall be: \"Using spark outside the function is leading to untestable code.\"",
                "test_traceability": [
                    {
                        "id": "tests/test_spark.py::test_spark_outside_function",
                        "description": ""
                    },
                    {
                        "id": "tests/samples/p/percent_run.py",
                        "description": "(verified via `tests/test_samples.py`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/spark.py::SparkChecker::visit_name",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SP-002",
                "requirement_description": "The system shall detect calls to `.show()` on a Spark DataFrame (e.g., `df.show()`).\n    *   Upon detection, the system shall issue a 'use-display-instead-of-show' (C8917) message.\n    *   The message shall be: \"Rewrite to display in a notebook: display(`<dataframe_expression>`).\" where `<dataframe_expression>` is the code producing the DataFrame on which `.show()` was called.",
                "test_traceability": [
                    {
                        "id": "tests/test_spark.py::test_df_show",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/spark.py::SparkChecker::visit_attribute",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SP-003",
                "requirement_description": "The system shall detect when a function uses a SparkSession object (typically named `spark`) but does not include `spark` as one of its formal parameters.\n    *   Upon detection, the system shall issue a 'no-spark-argument-in-function' (W8916) message.\n    *   The message shall be: \"Function `<function_name>` is missing a 'spark' argument.\"",
                "test_traceability": [
                    {
                        "id": "tests/test_spark.py::test_spark_inside_of_function_but_not_in_args",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/spark.py::SparkChecker::visit_name",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-RD-001",
                "requirement_description": "The system shall detect list comprehensions that span multiple lines.\n    *   Upon detection, the system shall issue a 'rewrite-as-for-loop' (R8923) message.\n    *   The message shall be: \"List comprehension spans multiple lines, rewrite as for loop.\"",
                "test_traceability": [
                    {
                        "id": "tests/test_readability.py::test_multi_line_list_comprehensions_not_allowed",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/readability.py::ReadabilityChecker::visit_listcomp",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MK-001",
                "requirement_description": "The system shall detect calls to `mocker.patch` or `patch` where the first argument (the target string) starts with a module name specified in the `require-explicit-dependency` Pylint option for this checker.\n    *   The default value for `require-explicit-dependency` is `databricks`. This should be configurable.\n    *   Upon detection, the system shall issue an 'explicit-dependency-required' (R8918) message.\n    *   The message shall be: \"Obscure implicit test dependency with mock.patch(`<target_string>`). Rewrite to inject dependencies through constructor.\"",
                "test_traceability": [
                    {
                        "id": "tests/test_mocking.py::test_explicit_dependency_required",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/mocking.py::MockingChecker::visit_call",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MK-002",
                "requirement_description": "The system shall detect direct instantiation of `MagicMock()` (i.e., `MagicMock()` without arguments).\n    *   Upon detection, the system shall issue an 'obscure-mock' (R8919) message.\n    *   The message shall be: \"Obscure implicit test dependency with MagicMock(). Rewrite with create_autospec(ConcreteType).\"",
                "test_traceability": [
                    {
                        "id": "tests/test_mocking.py::test_obscure_mock",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/mocking.py::MockingChecker::visit_call",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MK-003",
                "requirement_description": "The system shall detect calls to `create_autospec(...)` that are not part of an assignment statement (e.g., the result is not assigned to a variable).\n    *   Upon detection, the system shall issue a 'mock-no-assign' (R8921) message.\n    *   The message shall be: \"Mock not assigned to a variable: `<create_autospec_call_string>`.\"",
                "test_traceability": [
                    {
                        "id": "tests/test_mocking.py::test_mock_in_function_arg",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mocking.py::test_mock_not_assigned",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/mocking.py::MockingChecker::_no_mock_usage",
                        "description": "(indirectly via `visit_call`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-MK-004",
                "requirement_description": "The system shall detect when a mock object, created via `create_autospec(...)` and assigned to a variable, is not subsequently used for assertions (e.g., `mock_obj.method.assert_called_once()`) or to specify behavior (e.g., `mock_obj.method.return_value = ...`, `mock_obj.method.side_effect = ...`).\n    *   Upon detection, the system shall issue a 'mock-no-usage' (R8922) message.\n    *   The message shall be: \"Missing usage of mock for `<mocked_type_string>`.\" where `<mocked_type_string>` is the first argument to `create_autospec`.",
                "test_traceability": [
                    {
                        "id": "tests/test_mocking.py::test_mock_return_value_real",
                        "description": "This rule is implicitly tested by and which should *not* trigger the message. A positive test case for this rule would be one where `create_autospec` is assigned but no assertion/return_value/side_effect follows. (Assuming the intent from source and existing tests.)"
                    },
                    {
                        "id": "tests/test_mocking.py::test_mock_is_asserted",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/mocking.py::MockingChecker::_no_mock_usage",
                        "description": "(indirectly via `visit_call`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-ER-001",
                "requirement_description": "The system shall detect lines of Python code that have been commented out.\n    *   Upon detection, the system shall issue a 'dead-code' (C8920) message.\n    *   The message shall be: \"Remove commented out code: `<commented_code_line>`.\" where `<commented_code_line>` is the content of the commented-out line (stripped).",
                "test_traceability": [
                    {
                        "id": "tests/samples/d/dead_code.py",
                        "description": "(verified via `tests/test_samples.py`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/eradicate.py::EradicateChecker::process_module",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-001",
                "requirement_description": "The system shall provide a mechanism to be installed as a Databricks CLI lab plugin, e.g., via `databricks labs install pylint-plugin`.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/cli.py",
                        "description": "(as the entry point for the CLI command)"
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-002",
                "requirement_description": "The `nbcheck` command, when run without a `--path` argument, shall attempt to lint all Python notebooks in the current user's home directory in the Databricks workspace.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/cli.py",
                        "description": "(logic for default path)"
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-003",
                "requirement_description": "The `nbcheck` command shall accept a `--path` flag (or equivalent configuration via JSON input, see FR-CLI-007) to specify a particular notebook file or a directory within the Databricks workspace to lint.\n    *   If a directory is specified, the system shall attempt to lint all Python notebooks within that directory.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/cli.py",
                        "description": "(logic for path handling)"
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-004",
                "requirement_description": "The `nbcheck` command shall only process notebooks identified as Python notebooks by the Databricks workspace.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/cli.py::check_python_notebook",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-005",
                "requirement_description": "When linting notebooks via `nbcheck`, the system shall invoke Pylint with the `databricks.labs.pylint.all` plugin loaded, and with a specific, predefined set of checks enabled. This set includes: `missing-data-security-mode`, `unsupported-runtime`, `dbutils-fs-cp`, `dbutils-fs-head`, `dbutils-fs-ls`, `dbutils-fs-mount`, `dbutils-credentials`, `dbutils-notebook-run`, `pat-token-leaked`, `internal-api`, `legacy-cli`, `incompatible-with-uc`, `notebooks-too-many-cells`, `notebooks-percent-run`, `spark-outside-function`, `use-display-instead-of-show`, `no-spark-argument-in-function`. All other Pylint checks should be disabled by default for `nbcheck`.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/cli.py::check_python_notebook",
                        "description": "(specific Pylint command construction)"
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-006",
                "requirement_description": "The `nbcheck` command-line utility shall be invoked with a JSON payload string as its first system argument.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/cli.py",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CLI-007",
                "requirement_description": "The JSON payload for `nbcheck` (see FR-CLI-006) shall contain a `flags` object. This `flags` object can include:\n    *   A `path` string: Specifies the Databricks workspace path to a notebook or directory for linting. If not provided, behavior is as per FR-CLI-002.\n    *   A `log_level` string (e.g., \"info\", \"debug\"): Controls the logging verbosity of the `nbcheck` tool, particularly for Databricks SDK interactions.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "src/databricks/labs/pylint/cli.py",
                        "description": ""
                    }
                ]
            }
        ],
        "commit_sha": "b1be1a39703b8d3b693a0afd8a6ee61ff5078cb8",
        "full_code_skeleton": "--- File: src/databricks/__init__.py ---\n```python\npass\n```\n--- File: src/databricks/labs/__init__.py ---\n```python\npass\n```\n--- File: src/databricks/labs/pylint/__about__.py ---\n```python\npass\n```\n--- File: src/databricks/labs/pylint/mocking.py ---\n```python\nDOC_EXPLICIT_DEPENDENCY_REQUIRED = \"\"\"Using `patch` to mock dependencies in unit tests can introduce implicit \ndependencies within a class, making it unclear to other developers. Constructor arguments, on the other hand, \nexplicitly declare dependencies, enhancing code readability and maintainability. However, reliance on `patch` \nfor testing may lead to issues during refactoring, as updates to underlying implementations would necessitate \nchanges across multiple unrelated unit tests. Moreover, the use of hard-coded strings in `patch` can obscure \nwhich unit tests require modification, as they lack strongly typed references. This coupling of the class \nunder test to concrete classes signifies a code smell, and such code is not easily portable to statically typed \nlanguages where monkey patching isn't feasible without significant effort. In essence, extensive patching of \nexternal clients suggests a need for refactoring, with experienced engineers recognizing the potential for \ndependency inversion in such scenarios.\n\nTo address this issue, refactor the code to inject dependencies through the constructor. This approach\nexplicitly declares dependencies, enhancing code readability and maintainability. Moreover, it allows for\ndependency inversion, enabling the use of interfaces to decouple the class under test from concrete classes.\nThis decoupling facilitates unit testing, as it allows for the substitution of mock objects for concrete\nimplementations, ensuring that the class under test behaves as expected. By following this approach, you can\ncreate more robust and maintainable unit tests, improving the overall quality of your codebase.\n\nUse `require-explicit-dependency` option to specify the package names that contain code for your project.\"\"\"\nDOC_OBSCURE_MOCK = \"\"\"Using `MagicMock` to mock dependencies in unit tests can introduce implicit dependencies \nwithin a class, making it unclear to other developers. create_autospec(ConcreteType) is a better alternative, as it\nautomatically creates a mock object with the same attributes and methods as the concrete class. This\napproach ensures that the mock object behaves like the concrete class, allowing for more robust and\nmaintainable unit tests. Moreover, reliance on `MagicMock` for testing leads to issues during refactoring,\nas updates to underlying implementations would necessitate changes across multiple unrelated unit tests.\"\"\"\n\n\nclass MockingChecker(BaseChecker):\n    name = \"mocking\"\n    msgs = {\n        \"R8918\": (\n            \"Obscure implicit test dependency with mock.patch(%s). Rewrite to inject dependencies through constructor.\",\n            \"explicit-dependency-required\",\n            DOC_EXPLICIT_DEPENDENCY_REQUIRED,\n        ),\n        \"R8919\": (\n            \"Obscure implicit test dependency with MagicMock(). Rewrite with create_autospec(ConcreteType).\",\n            \"obscure-mock\",\n            DOC_OBSCURE_MOCK,\n        ),\n        \"R8921\": (\n            \"Mock not assigned to a variable: %s\",\n            \"mock-no-assign\",\n            \"Every mocked object should be assigned to a variable to allow for assertions.\",\n        ),\n        \"R8922\": (\n            \"Missing usage of mock for %s\",\n            \"mock-no-usage\",\n            \"Usually this check means a hidden bug, where object is mocked, but we don't check if it was used \"\n            \"correctly. Every mock should have at least one assertion, return value, or side effect specified.\",\n        ),\n    }\n    options = (\n        (\n            \"require-explicit-dependency\",\n            {\n                \"default\": (\"databricks\",),\n                \"type\": \"csv\",\n                \"metavar\": \"<modules>\",\n                \"help\": \"Package names that contain code for your project.\",\n            },\n        ),\n    )\n\n    def open(self) -> None:\n        pass\n\n    def visit_call(self, node: nodes.Call) -> None:\n        pass\n\n    def _no_mock_usage(self, node: nodes.Call) -> bool:\n        pass\n\n\ndef register(linter):\n    pass\n```\n--- File: src/databricks/labs/pylint/spark.py ---\n```python\nclass SparkChecker(BaseChecker):\n    name = \"spark\"\n    msgs = {\n        \"C8915\": (\n            \"Using spark outside the function is leading to untestable code\",\n            \"spark-outside-function\",\n            \"Do not use global spark object, pass it as an argument to the function instead, \"\n            \"so that the function becomes testable in a CI/CD pipelines.\",\n        ),\n        \"W8916\": (\n            \"Function %s is missing a 'spark' argument\",\n            \"no-spark-argument-in-function\",\n            \"Function refers to a global spark variable, which may not always be available. \"\n            \"Pass the spark object as an argument to the function instead, so that the function \"\n            \"becomes testable in a CI/CD pipelines.\",\n        ),\n        \"C8917\": (\n            \"Rewrite to display in a notebook: display(%s)\",\n            \"use-display-instead-of-show\",\n            \"Use display() instead of show() to visualize the data in a notebook.\",\n        ),\n    }\n\n    def visit_name(self, node: astroid.Name):\n        pass\n\n    def visit_attribute(self, node: astroid.Attribute):\n        pass\n\n\ndef register(linter):\n    pass\n```\n--- File: src/databricks/labs/pylint/legacy.py ---\n```python\nclass LegacyChecker(BaseChecker):\n    name = \"databricks-legacy\"\n    msgs = {\n        \"R8911\": (\n            \"Don't use databricks_cli, use databricks.sdk instead: pip install databricks-sdk\",\n            \"legacy-cli\",\n            \"Migrate all usage of Legacy CLI to Databricks SDK. See the more detailed documentation at \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/index.html\",\n        ),\n        \"W8912\": (\n            \"Incompatible with Unity Catalog: %s\",\n            \"incompatible-with-uc\",\n            \"Migrate all usage to Databricks Unity Catalog. Use https://github.com/databrickslabs/ucx for more details\",\n        ),\n    }\n    UC_INCOMPATIBLE_BRUTE_FORCE = {\n        \"s3fs\",\n        \"boto3\",\n        \"graphframes\",\n        \"pyspark.ml\",\n        \"dbfs:\",\n        \"hive_metastore.\",\n        \"kafka.sasl.client.callback.handler.class\",\n        \"kafka.sasl.login.callback.handler.class\",\n        \"kafka.sasl.login.class\",\n        \"kafka.partition.assignment.strategy\",\n        \"kafka.ssl.truststore.location\",\n        \"kafka.ssl.keystore.location\",\n        \"spark.catalog.\",\n        \"spark._jsparkSession.catalog\",\n        \"spark._jspark\",\n        \"spark._jvm\",\n        \"._jdf\",\n        \"._jcol\",\n        \"spark.udf.registerJavaFunction\",\n        \"applyInPandas\",\n        \"mapInPandas\",\n        \"_jvm\",\n        \"SQLContext\",\n        \"emptyRDD\",\n        \"pickleFile\",\n        \"textFile\",\n        \"newAPIHadoopFile\",\n        \"newAPIHadoopRDD\",\n        \"hadoopFile\",\n        \"hadoopRDD\",\n        \"saveAsHadoopFile\",\n        \"saveAsHadoopDataset\",\n        \"saveAsNewAPIHadoopFile\",\n        \"saveAsNewAPIHadoopDataset\",\n        \"setJobGroup\",\n        \"setLocalProperty\",\n        \"applyInPandasWithState\",\n    }\n\n    def visit_import(self, node: astroid.Import):\n        pass\n\n    def visit_importfrom(self, node: astroid.ImportFrom):\n        pass\n\n    def visit_call(self, node: astroid.Call):\n        pass\n\n    def visit_const(self, node: astroid.Const):\n        pass\n\n\ndef register(linter):\n    pass\n```\n--- File: src/databricks/labs/pylint/all.py ---\n```python\ndef register(linter):\n    pass\n```\n--- File: src/databricks/labs/pylint/__init__.py ---\n```python\npass\n```\n--- File: src/databricks/labs/pylint/airflow.py ---\n```python\nclass AirflowChecker(BaseChecker):\n    name = \"databricks-airflow\"\n    msgs = {\n        \"W8901\": (\n            \"%s cluster missing `data_security_mode` required for Unity Catalog compatibility\",\n            \"missing-data-security-mode\",\n            \"Before you enable Unity Catalog, you must set the `data_security_mode` to 'NONE',\"\n            \" so that your existing jobs would keep the same behavior. Failure to do so may cause \"\n            \"your jobs to fail with unexpected errors.\",\n        ),\n        \"W8902\": (\n            \"%s cluster has unsupported runtime: %s\",\n            \"unsupported-runtime\",\n            \"The runtime version is not supported by Unity Catalog. Please upgrade to a runtime greater \"\n            \"than or equal to 11.3.\",\n        ),\n    }\n\n    def visit_call(self, node: astroid.Call):\n        pass\n\n    def _check_new_cluster(self, key: str, new_cluster: Dict[str, Any], node: astroid.NodeNG):\n        pass\n\n    def _is_supported(spark_version: str):\n        pass\n\n    def _check_tasks(self, tasks: List[Dict[str, Any]], node: astroid.NodeNG):\n        pass\n\n    def _check_job_clusters(self, job_clusters: List[Dict[str, Any]], node: astroid.NodeNG):\n        pass\n\n    def _infer_kwargs(self, keywords: List[astroid.Keyword]):\n        pass\n\n    def _infer_value(self, value: astroid.NodeNG):\n        pass\n\n    def _infer_dict(self, in_dict: astroid.Dict):\n        pass\n\n    def _infer_list(self, list_: astroid.List):\n        pass\n\n\ndef register(linter):\n    pass\n```\n--- File: src/databricks/labs/pylint/dbutils.py ---\n```python\nclass DbutilsChecker(BaseChecker):\n    name = \"databricks-dbutils\"\n    msgs = {\n        \"R8903\": (\n            \"Use Databricks SDK instead: w.dbfs.copy(%s, %s)\",\n            \"dbutils-fs-cp\",\n            \"Migrate all usage of dbutils to Databricks SDK. See the more detailed documentation at \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/workspace/files/dbfs.html\",\n        ),\n        \"R8904\": (\n            \"Use Databricks SDK instead: with w.dbfs.download(%s) as f: f.read()\",\n            \"dbutils-fs-head\",\n            \"Migrate all usage of dbutils to Databricks SDK. See the more detailed documentation at \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/workspace/files/dbfs.html\",\n        ),\n        \"R8905\": (\n            \"Use Databricks SDK instead: w.dbfs.list(%s)\",\n            \"dbutils-fs-ls\",\n            \"Migrate all usage of dbutils to Databricks SDK. See the more detailed documentation at \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/workspace/files/dbfs.html\",\n        ),\n        \"R8906\": (\n            \"Mounts are not supported with Unity Catalog, switch to using Unity Catalog Volumes instead\",\n            \"dbutils-fs-mount\",\n            \"Migrate all usage to Unity Catalog\",\n        ),\n        \"R8907\": (\n            \"Credentials utility is not supported with Unity Catalog\",\n            \"dbutils-credentials\",\n            \"Migrate all usage to Unity Catalog\",\n        ),\n        \"R8908\": (\n            \"\"\"Use Databricks SDK instead: w.jobs.submit(\n                tasks=[jobs.SubmitTask(existing_cluster_id=...,\n                                       notebook_task=jobs.NotebookTask(notebook_path=%s),\n                                       task_key=...)\n                ]).result(timeout=timedelta(minutes=%s))\"\"\",\n            \"dbutils-notebook-run\",\n            \"Migrate all usage of dbutils to Databricks SDK. See the more detailed documentation at \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/workspace/jobs/jobs.html\",\n        ),\n        \"R8909\": (\n            \"Use Databricks SDK instead: from databricks.sdk import WorkspaceClient(); w = WorkspaceClient()\",\n            \"pat-token-leaked\",\n            \"Do not hardcode secrets in code, use Databricks SDK instead, which natively authenticates in Databricks \"\n            \"Notebooks. See more at https://databricks-sdk-py.readthedocs.io/en/latest/authentication.html\",\n        ),\n        \"R8910\": (\n            \"Do not use internal APIs, rewrite using Databricks SDK: %s\",\n            \"internal-api\",\n            \"Do not use internal APIs. Use Databricks SDK for Python: \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/index.html\",\n        ),\n    }\n\n    def visit_call(self, node: astroid.Call):\n        pass\n\n    def visit_const(self, node: astroid.Const):\n        pass\n\n    def visit_import(self, node: astroid.Import):\n        pass\n\n    def visit_importfrom(self, node: astroid.ImportFrom):\n        pass\n\n\ndef register(linter):\n    pass\n```\n--- File: src/databricks/labs/pylint/notebooks.py ---\n```python\nclass NotebookChecker(BaseRawFileChecker):\n    __implements__ = (BaseRawFileChecker,)\n    name = \"databricks-notebooks\"\n    msgs = {\n        \"C8913\": (\n            \"Notebooks should not have more than 75 cells\",\n            \"notebooks-too-many-cells\",\n            \"Otherwise, it's hard to maintain and understand the notebook for other people and the future you\",\n        ),\n        \"R8914\": (\n            \"Using %run is not allowed\",\n            \"notebooks-percent-run\",\n            \"Use functions instead of %run to avoid side effects and make the code more testable. \"\n            \"If you need to share code between notebooks, consider creating a library. \"\n            \"If still need to call another code as a separate job, use Databricks SDK for Python:\"\n            \" https://databricks-sdk-py.readthedocs.io/en/latest/index.html\",\n        ),\n    }\n    options = (\n        (\n            \"max-cells\",\n            {\n                \"default\": 75,\n                \"type\": \"int\",\n                \"metavar\": \"<int>\",\n                \"help\": \"Maximum number of cells in the notebook\",\n            },\n        ),\n    )\n\n    def process_module(self, node: astroid.Module):\n        \"\"\"Read raw module. Need to do some tricks, as `ast` doesn't provide access for comments.\n\n        Alternative libraries that can parse comments along with the code:\n        - https://github.com/Instagram/LibCST/ (MIT + PSF)\n        - https://github.com/python/cpython/tree/3.10/Lib/lib2to3 (PSF), removed in Python 3.12\n        - https://github.com/t3rn0/ast-comments (MIT)\n        - https://github.com/facebookincubator/bowler (MIT), abandoned\n        - https://github.com/PyCQA/redbaron (LGPLv3)\n        \"\"\"\n        pass\n\n\ndef register(linter):\n    pass\n```\n--- File: src/databricks/labs/pylint/readability.py ---\n```python\nclass ReadabilityChecker(BaseChecker):\n    name = \"readability\"\n    msgs = {\n        \"R8923\": (\n            \"List comprehension spans multiple lines, rewrite as for loop\",\n            \"rewrite-as-for-loop\",\n            \"\"\"List comprehensions in Python are typically used to create new lists by iterating over an existing\n            iterable in a concise, one-line syntax. However, when a list comprehension becomes too complex or spans \n            multiple lines, it may lose its readability and clarity, which are key advantages of Python's syntax.\"\"\",\n        ),\n    }\n\n    def visit_listcomp(self, node: nodes.ListComp) -> None:\n        pass\n\n\ndef register(linter):\n    pass\n```\n--- File: src/databricks/labs/pylint/cli.py ---\n```python\ndef check_python_notebook(info: ObjectInfo):\n    pass\n```\n--- File: src/databricks/labs/pylint/eradicate.py ---\n```python\nclass EradicateChecker(BaseRawFileChecker):\n    name = \"eradicate\"\n    msgs = {\n        \"C8920\": (\n            \"Remove commented out code: %s\",\n            \"dead-code\",\n            \"Version control helps with keeping track of code changes. There is no need to keep commented out code in \"\n            \"the codebase. Remove it to keep the codebase clean.\",\n        ),\n    }\n\n    def open(self) -> None:\n        pass\n\n    def process_module(self, node: astroid.Module):\n        pass\n\n\ndef register(linter):\n    pass\n```\n--- File: scripts/docs.py ---\n```python\ndef do_something():\n    pass\n```",
        "full_code_skeleton_structured": [
            {
                "file_path": "src/databricks/__init__.py",
                "code": "pass\n"
            },
            {
                "file_path": "src/databricks/labs/__init__.py",
                "code": "pass\n"
            },
            {
                "file_path": "src/databricks/labs/pylint/__about__.py",
                "code": "pass\n"
            },
            {
                "file_path": "src/databricks/labs/pylint/mocking.py",
                "code": "DOC_EXPLICIT_DEPENDENCY_REQUIRED = \"\"\"Using `patch` to mock dependencies in unit tests can introduce implicit \ndependencies within a class, making it unclear to other developers. Constructor arguments, on the other hand, \nexplicitly declare dependencies, enhancing code readability and maintainability. However, reliance on `patch` \nfor testing may lead to issues during refactoring, as updates to underlying implementations would necessitate \nchanges across multiple unrelated unit tests. Moreover, the use of hard-coded strings in `patch` can obscure \nwhich unit tests require modification, as they lack strongly typed references. This coupling of the class \nunder test to concrete classes signifies a code smell, and such code is not easily portable to statically typed \nlanguages where monkey patching isn't feasible without significant effort. In essence, extensive patching of \nexternal clients suggests a need for refactoring, with experienced engineers recognizing the potential for \ndependency inversion in such scenarios.\n\nTo address this issue, refactor the code to inject dependencies through the constructor. This approach\nexplicitly declares dependencies, enhancing code readability and maintainability. Moreover, it allows for\ndependency inversion, enabling the use of interfaces to decouple the class under test from concrete classes.\nThis decoupling facilitates unit testing, as it allows for the substitution of mock objects for concrete\nimplementations, ensuring that the class under test behaves as expected. By following this approach, you can\ncreate more robust and maintainable unit tests, improving the overall quality of your codebase.\n\nUse `require-explicit-dependency` option to specify the package names that contain code for your project.\"\"\"\nDOC_OBSCURE_MOCK = \"\"\"Using `MagicMock` to mock dependencies in unit tests can introduce implicit dependencies \nwithin a class, making it unclear to other developers. create_autospec(ConcreteType) is a better alternative, as it\nautomatically creates a mock object with the same attributes and methods as the concrete class. This\napproach ensures that the mock object behaves like the concrete class, allowing for more robust and\nmaintainable unit tests. Moreover, reliance on `MagicMock` for testing leads to issues during refactoring,\nas updates to underlying implementations would necessitate changes across multiple unrelated unit tests.\"\"\"\n\n\nclass MockingChecker(BaseChecker):\n    name = \"mocking\"\n    msgs = {\n        \"R8918\": (\n            \"Obscure implicit test dependency with mock.patch(%s). Rewrite to inject dependencies through constructor.\",\n            \"explicit-dependency-required\",\n            DOC_EXPLICIT_DEPENDENCY_REQUIRED,\n        ),\n        \"R8919\": (\n            \"Obscure implicit test dependency with MagicMock(). Rewrite with create_autospec(ConcreteType).\",\n            \"obscure-mock\",\n            DOC_OBSCURE_MOCK,\n        ),\n        \"R8921\": (\n            \"Mock not assigned to a variable: %s\",\n            \"mock-no-assign\",\n            \"Every mocked object should be assigned to a variable to allow for assertions.\",\n        ),\n        \"R8922\": (\n            \"Missing usage of mock for %s\",\n            \"mock-no-usage\",\n            \"Usually this check means a hidden bug, where object is mocked, but we don't check if it was used \"\n            \"correctly. Every mock should have at least one assertion, return value, or side effect specified.\",\n        ),\n    }\n    options = (\n        (\n            \"require-explicit-dependency\",\n            {\n                \"default\": (\"databricks\",),\n                \"type\": \"csv\",\n                \"metavar\": \"<modules>\",\n                \"help\": \"Package names that contain code for your project.\",\n            },\n        ),\n    )\n\n    def open(self) -> None:\n        pass\n\n    def visit_call(self, node: nodes.Call) -> None:\n        pass\n\n    def _no_mock_usage(self, node: nodes.Call) -> bool:\n        pass\n\n\ndef register(linter):\n    pass\n"
            },
            {
                "file_path": "src/databricks/labs/pylint/spark.py",
                "code": "class SparkChecker(BaseChecker):\n    name = \"spark\"\n    msgs = {\n        \"C8915\": (\n            \"Using spark outside the function is leading to untestable code\",\n            \"spark-outside-function\",\n            \"Do not use global spark object, pass it as an argument to the function instead, \"\n            \"so that the function becomes testable in a CI/CD pipelines.\",\n        ),\n        \"W8916\": (\n            \"Function %s is missing a 'spark' argument\",\n            \"no-spark-argument-in-function\",\n            \"Function refers to a global spark variable, which may not always be available. \"\n            \"Pass the spark object as an argument to the function instead, so that the function \"\n            \"becomes testable in a CI/CD pipelines.\",\n        ),\n        \"C8917\": (\n            \"Rewrite to display in a notebook: display(%s)\",\n            \"use-display-instead-of-show\",\n            \"Use display() instead of show() to visualize the data in a notebook.\",\n        ),\n    }\n\n    def visit_name(self, node: astroid.Name):\n        pass\n\n    def visit_attribute(self, node: astroid.Attribute):\n        pass\n\n\ndef register(linter):\n    pass\n"
            },
            {
                "file_path": "src/databricks/labs/pylint/legacy.py",
                "code": "class LegacyChecker(BaseChecker):\n    name = \"databricks-legacy\"\n    msgs = {\n        \"R8911\": (\n            \"Don't use databricks_cli, use databricks.sdk instead: pip install databricks-sdk\",\n            \"legacy-cli\",\n            \"Migrate all usage of Legacy CLI to Databricks SDK. See the more detailed documentation at \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/index.html\",\n        ),\n        \"W8912\": (\n            \"Incompatible with Unity Catalog: %s\",\n            \"incompatible-with-uc\",\n            \"Migrate all usage to Databricks Unity Catalog. Use https://github.com/databrickslabs/ucx for more details\",\n        ),\n    }\n    UC_INCOMPATIBLE_BRUTE_FORCE = {\n        \"s3fs\",\n        \"boto3\",\n        \"graphframes\",\n        \"pyspark.ml\",\n        \"dbfs:\",\n        \"hive_metastore.\",\n        \"kafka.sasl.client.callback.handler.class\",\n        \"kafka.sasl.login.callback.handler.class\",\n        \"kafka.sasl.login.class\",\n        \"kafka.partition.assignment.strategy\",\n        \"kafka.ssl.truststore.location\",\n        \"kafka.ssl.keystore.location\",\n        \"spark.catalog.\",\n        \"spark._jsparkSession.catalog\",\n        \"spark._jspark\",\n        \"spark._jvm\",\n        \"._jdf\",\n        \"._jcol\",\n        \"spark.udf.registerJavaFunction\",\n        \"applyInPandas\",\n        \"mapInPandas\",\n        \"_jvm\",\n        \"SQLContext\",\n        \"emptyRDD\",\n        \"pickleFile\",\n        \"textFile\",\n        \"newAPIHadoopFile\",\n        \"newAPIHadoopRDD\",\n        \"hadoopFile\",\n        \"hadoopRDD\",\n        \"saveAsHadoopFile\",\n        \"saveAsHadoopDataset\",\n        \"saveAsNewAPIHadoopFile\",\n        \"saveAsNewAPIHadoopDataset\",\n        \"setJobGroup\",\n        \"setLocalProperty\",\n        \"applyInPandasWithState\",\n    }\n\n    def visit_import(self, node: astroid.Import):\n        pass\n\n    def visit_importfrom(self, node: astroid.ImportFrom):\n        pass\n\n    def visit_call(self, node: astroid.Call):\n        pass\n\n    def visit_const(self, node: astroid.Const):\n        pass\n\n\ndef register(linter):\n    pass\n"
            },
            {
                "file_path": "src/databricks/labs/pylint/all.py",
                "code": "def register(linter):\n    pass\n"
            },
            {
                "file_path": "src/databricks/labs/pylint/__init__.py",
                "code": "pass\n"
            },
            {
                "file_path": "src/databricks/labs/pylint/airflow.py",
                "code": "class AirflowChecker(BaseChecker):\n    name = \"databricks-airflow\"\n    msgs = {\n        \"W8901\": (\n            \"%s cluster missing `data_security_mode` required for Unity Catalog compatibility\",\n            \"missing-data-security-mode\",\n            \"Before you enable Unity Catalog, you must set the `data_security_mode` to 'NONE',\"\n            \" so that your existing jobs would keep the same behavior. Failure to do so may cause \"\n            \"your jobs to fail with unexpected errors.\",\n        ),\n        \"W8902\": (\n            \"%s cluster has unsupported runtime: %s\",\n            \"unsupported-runtime\",\n            \"The runtime version is not supported by Unity Catalog. Please upgrade to a runtime greater \"\n            \"than or equal to 11.3.\",\n        ),\n    }\n\n    def visit_call(self, node: astroid.Call):\n        pass\n\n    def _check_new_cluster(self, key: str, new_cluster: Dict[str, Any], node: astroid.NodeNG):\n        pass\n\n    def _is_supported(spark_version: str):\n        pass\n\n    def _check_tasks(self, tasks: List[Dict[str, Any]], node: astroid.NodeNG):\n        pass\n\n    def _check_job_clusters(self, job_clusters: List[Dict[str, Any]], node: astroid.NodeNG):\n        pass\n\n    def _infer_kwargs(self, keywords: List[astroid.Keyword]):\n        pass\n\n    def _infer_value(self, value: astroid.NodeNG):\n        pass\n\n    def _infer_dict(self, in_dict: astroid.Dict):\n        pass\n\n    def _infer_list(self, list_: astroid.List):\n        pass\n\n\ndef register(linter):\n    pass\n"
            },
            {
                "file_path": "src/databricks/labs/pylint/dbutils.py",
                "code": "class DbutilsChecker(BaseChecker):\n    name = \"databricks-dbutils\"\n    msgs = {\n        \"R8903\": (\n            \"Use Databricks SDK instead: w.dbfs.copy(%s, %s)\",\n            \"dbutils-fs-cp\",\n            \"Migrate all usage of dbutils to Databricks SDK. See the more detailed documentation at \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/workspace/files/dbfs.html\",\n        ),\n        \"R8904\": (\n            \"Use Databricks SDK instead: with w.dbfs.download(%s) as f: f.read()\",\n            \"dbutils-fs-head\",\n            \"Migrate all usage of dbutils to Databricks SDK. See the more detailed documentation at \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/workspace/files/dbfs.html\",\n        ),\n        \"R8905\": (\n            \"Use Databricks SDK instead: w.dbfs.list(%s)\",\n            \"dbutils-fs-ls\",\n            \"Migrate all usage of dbutils to Databricks SDK. See the more detailed documentation at \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/workspace/files/dbfs.html\",\n        ),\n        \"R8906\": (\n            \"Mounts are not supported with Unity Catalog, switch to using Unity Catalog Volumes instead\",\n            \"dbutils-fs-mount\",\n            \"Migrate all usage to Unity Catalog\",\n        ),\n        \"R8907\": (\n            \"Credentials utility is not supported with Unity Catalog\",\n            \"dbutils-credentials\",\n            \"Migrate all usage to Unity Catalog\",\n        ),\n        \"R8908\": (\n            \"\"\"Use Databricks SDK instead: w.jobs.submit(\n                tasks=[jobs.SubmitTask(existing_cluster_id=...,\n                                       notebook_task=jobs.NotebookTask(notebook_path=%s),\n                                       task_key=...)\n                ]).result(timeout=timedelta(minutes=%s))\"\"\",\n            \"dbutils-notebook-run\",\n            \"Migrate all usage of dbutils to Databricks SDK. See the more detailed documentation at \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/workspace/jobs/jobs.html\",\n        ),\n        \"R8909\": (\n            \"Use Databricks SDK instead: from databricks.sdk import WorkspaceClient(); w = WorkspaceClient()\",\n            \"pat-token-leaked\",\n            \"Do not hardcode secrets in code, use Databricks SDK instead, which natively authenticates in Databricks \"\n            \"Notebooks. See more at https://databricks-sdk-py.readthedocs.io/en/latest/authentication.html\",\n        ),\n        \"R8910\": (\n            \"Do not use internal APIs, rewrite using Databricks SDK: %s\",\n            \"internal-api\",\n            \"Do not use internal APIs. Use Databricks SDK for Python: \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/index.html\",\n        ),\n    }\n\n    def visit_call(self, node: astroid.Call):\n        pass\n\n    def visit_const(self, node: astroid.Const):\n        pass\n\n    def visit_import(self, node: astroid.Import):\n        pass\n\n    def visit_importfrom(self, node: astroid.ImportFrom):\n        pass\n\n\ndef register(linter):\n    pass\n"
            },
            {
                "file_path": "src/databricks/labs/pylint/notebooks.py",
                "code": "class NotebookChecker(BaseRawFileChecker):\n    __implements__ = (BaseRawFileChecker,)\n    name = \"databricks-notebooks\"\n    msgs = {\n        \"C8913\": (\n            \"Notebooks should not have more than 75 cells\",\n            \"notebooks-too-many-cells\",\n            \"Otherwise, it's hard to maintain and understand the notebook for other people and the future you\",\n        ),\n        \"R8914\": (\n            \"Using %run is not allowed\",\n            \"notebooks-percent-run\",\n            \"Use functions instead of %run to avoid side effects and make the code more testable. \"\n            \"If you need to share code between notebooks, consider creating a library. \"\n            \"If still need to call another code as a separate job, use Databricks SDK for Python:\"\n            \" https://databricks-sdk-py.readthedocs.io/en/latest/index.html\",\n        ),\n    }\n    options = (\n        (\n            \"max-cells\",\n            {\n                \"default\": 75,\n                \"type\": \"int\",\n                \"metavar\": \"<int>\",\n                \"help\": \"Maximum number of cells in the notebook\",\n            },\n        ),\n    )\n\n    def process_module(self, node: astroid.Module):\n        \"\"\"Read raw module. Need to do some tricks, as `ast` doesn't provide access for comments.\n\n        Alternative libraries that can parse comments along with the code:\n        - https://github.com/Instagram/LibCST/ (MIT + PSF)\n        - https://github.com/python/cpython/tree/3.10/Lib/lib2to3 (PSF), removed in Python 3.12\n        - https://github.com/t3rn0/ast-comments (MIT)\n        - https://github.com/facebookincubator/bowler (MIT), abandoned\n        - https://github.com/PyCQA/redbaron (LGPLv3)\n        \"\"\"\n        pass\n\n\ndef register(linter):\n    pass\n"
            },
            {
                "file_path": "src/databricks/labs/pylint/readability.py",
                "code": "class ReadabilityChecker(BaseChecker):\n    name = \"readability\"\n    msgs = {\n        \"R8923\": (\n            \"List comprehension spans multiple lines, rewrite as for loop\",\n            \"rewrite-as-for-loop\",\n            \"\"\"List comprehensions in Python are typically used to create new lists by iterating over an existing\n            iterable in a concise, one-line syntax. However, when a list comprehension becomes too complex or spans \n            multiple lines, it may lose its readability and clarity, which are key advantages of Python's syntax.\"\"\",\n        ),\n    }\n\n    def visit_listcomp(self, node: nodes.ListComp) -> None:\n        pass\n\n\ndef register(linter):\n    pass\n"
            },
            {
                "file_path": "src/databricks/labs/pylint/cli.py",
                "code": "def check_python_notebook(info: ObjectInfo):\n    pass\n"
            },
            {
                "file_path": "src/databricks/labs/pylint/eradicate.py",
                "code": "class EradicateChecker(BaseRawFileChecker):\n    name = \"eradicate\"\n    msgs = {\n        \"C8920\": (\n            \"Remove commented out code: %s\",\n            \"dead-code\",\n            \"Version control helps with keeping track of code changes. There is no need to keep commented out code in \"\n            \"the codebase. Remove it to keep the codebase clean.\",\n        ),\n    }\n\n    def open(self) -> None:\n        pass\n\n    def process_module(self, node: astroid.Module):\n        pass\n\n\ndef register(linter):\n    pass\n"
            },
            {
                "file_path": "scripts/docs.py",
                "code": "def do_something():\n    pass\n"
            }
        ],
        "minimal_code_skeleton": "--- File: databricks/labs/pylint/airflow.py ---\n```python\nclass AirflowChecker(BaseChecker):\n    name = \"databricks-airflow\"\n    msgs = {\n        \"W8901\": (\n            \"%s cluster missing `data_security_mode` required for Unity Catalog compatibility\",\n            \"missing-data-security-mode\",\n            \"Before you enable Unity Catalog, you must set the `data_security_mode` to 'NONE',\"\n            \" so that your existing jobs would keep the same behavior. Failure to do so may cause \"\n            \"your jobs to fail with unexpected errors.\",\n        ),\n        \"W8902\": (\n            \"%s cluster has unsupported runtime: %s\",\n            \"unsupported-runtime\",\n            \"The runtime version is not supported by Unity Catalog. Please upgrade to a runtime greater \"\n            \"than or equal to 11.3.\",\n        ),\n    }\n\n    def visit_call(self, node: astroid.Call):\n        pass\n\n```\n--- File: databricks/labs/pylint/all.py ---\n```python\ndef register(linter):\n    pass\n\n```\n--- File: databricks/labs/pylint/dbutils.py ---\n```python\nclass DbutilsChecker(BaseChecker):\n    name = \"databricks-dbutils\"\n    msgs = {\n        \"R8903\": (\n            \"Use Databricks SDK instead: w.dbfs.copy(%s, %s)\",\n            \"dbutils-fs-cp\",\n            \"Migrate all usage of dbutils to Databricks SDK. See the more detailed documentation at \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/workspace/files/dbfs.html\",\n        ),\n        \"R8904\": (\n            \"Use Databricks SDK instead: with w.dbfs.download(%s) as f: f.read()\",\n            \"dbutils-fs-head\",\n            \"Migrate all usage of dbutils to Databricks SDK. See the more detailed documentation at \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/workspace/files/dbfs.html\",\n        ),\n        \"R8905\": (\n            \"Use Databricks SDK instead: w.dbfs.list(%s)\",\n            \"dbutils-fs-ls\",\n            \"Migrate all usage of dbutils to Databricks SDK. See the more detailed documentation at \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/workspace/files/dbfs.html\",\n        ),\n        \"R8906\": (\n            \"Mounts are not supported with Unity Catalog, switch to using Unity Catalog Volumes instead\",\n            \"dbutils-fs-mount\",\n            \"Migrate all usage to Unity Catalog\",\n        ),\n        \"R8907\": (\n            \"Credentials utility is not supported with Unity Catalog\",\n            \"dbutils-credentials\",\n            \"Migrate all usage to Unity Catalog\",\n        ),\n        \"R8908\": (\n            \"\"\"Use Databricks SDK instead: w.jobs.submit(\n                tasks=[jobs.SubmitTask(existing_cluster_id=...,\n                                       notebook_task=jobs.NotebookTask(notebook_path=%s),\n                                       task_key=...)\n                ]).result(timeout=timedelta(minutes=%s))\"\"\",\n            \"dbutils-notebook-run\",\n            \"Migrate all usage of dbutils to Databricks SDK. See the more detailed documentation at \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/workspace/jobs/jobs.html\",\n        ),\n        \"R8909\": (\n            \"Use Databricks SDK instead: from databricks.sdk import WorkspaceClient(); w = WorkspaceClient()\",\n            \"pat-token-leaked\",\n            \"Do not hardcode secrets in code, use Databricks SDK instead, which natively authenticates in Databricks \"\n            \"Notebooks. See more at https://databricks-sdk-py.readthedocs.io/en/latest/authentication.html\",\n        ),\n        \"R8910\": (\n            \"Do not use internal APIs, rewrite using Databricks SDK: %s\",\n            \"internal-api\",\n            \"Do not use internal APIs. Use Databricks SDK for Python: \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/index.html\",\n        ),\n    }\n\n    def visit_call(self, node: astroid.Call):\n        pass\n\n    def visit_const(self, node: astroid.Const):\n        pass\n\n    def visit_import(self, node: astroid.Import):\n        pass\n\n    def visit_importfrom(self, node: astroid.ImportFrom):\n        pass\n\n```\n--- File: databricks/labs/pylint/eradicate.py ---\n```python\nclass EradicateChecker(BaseRawFileChecker):\n    name = \"eradicate\"\n    msgs = {\n        \"C8920\": (\n            \"Remove commented out code: %s\",\n            \"dead-code\",\n            \"Version control helps with keeping track of code changes. There is no need to keep commented out code in \"\n            \"the codebase. Remove it to keep the codebase clean.\",\n        ),\n    }\n\n    def open(self) -> None:\n        pass\n\n    def process_module(self, node: astroid.Module):\n        pass\n\n```\n--- File: databricks/labs/pylint/legacy.py ---\n```python\nclass LegacyChecker(BaseChecker):\n    name = \"databricks-legacy\"\n    msgs = {\n        \"R8911\": (\n            \"Don't use databricks_cli, use databricks.sdk instead: pip install databricks-sdk\",\n            \"legacy-cli\",\n            \"Migrate all usage of Legacy CLI to Databricks SDK. See the more detailed documentation at \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/index.html\",\n        ),\n        \"W8912\": (\n            \"Incompatible with Unity Catalog: %s\",\n            \"incompatible-with-uc\",\n            \"Migrate all usage to Databricks Unity Catalog. Use https://github.com/databrickslabs/ucx for more details\",\n        ),\n    }\n    UC_INCOMPATIBLE_BRUTE_FORCE = {\n        \"s3fs\",\n        \"boto3\",\n        \"graphframes\",\n        \"pyspark.ml\",\n        # literals\n        \"dbfs:\",\n        \"hive_metastore.\",\n        \"kafka.sasl.client.callback.handler.class\",\n        \"kafka.sasl.login.callback.handler.class\",\n        \"kafka.sasl.login.class\",\n        \"kafka.partition.assignment.strategy\",\n        \"kafka.ssl.truststore.location\",\n        \"kafka.ssl.keystore.location\",\n        # calls\n        # \"sc.\", triggers false positives for \"misc.\"\n        \"spark.catalog.\",\n        \"spark._jsparkSession.catalog\",\n        \"spark._jspark\",\n        \"spark._jvm\",\n        \"._jdf\",\n        \"._jcol\",\n        \"spark.udf.registerJavaFunction\",\n        \"applyInPandas\",\n        \"mapInPandas\",\n        \"_jvm\",\n        \"SQLContext\",\n        \"emptyRDD\",\n        \"pickleFile\",\n        \"textFile\",\n        \"newAPIHadoopFile\",\n        \"newAPIHadoopRDD\",\n        \"hadoopFile\",\n        \"hadoopRDD\",\n        \"saveAsHadoopFile\",\n        \"saveAsHadoopDataset\",\n        \"saveAsNewAPIHadoopFile\",\n        \"saveAsNewAPIHadoopDataset\",\n        \"setJobGroup\",\n        \"setLocalProperty\",\n        \"applyInPandasWithState\",\n    }\n\n    def visit_import(self, node: astroid.Import):\n        pass\n\n    def visit_importfrom(self, node: astroid.ImportFrom):\n        pass\n\n    def visit_call(self, node: astroid.Call):\n        pass\n\n    def visit_const(self, node: astroid.Const):\n        pass\n\n```\n--- File: databricks/labs/pylint/mocking.py ---\n```python\nclass MockingChecker(BaseChecker):\n    name = \"mocking\"\n    msgs = {\n        \"R8918\": (\n            \"Obscure implicit test dependency with mock.patch(%s). Rewrite to inject dependencies through constructor.\",\n            \"explicit-dependency-required\",\n            DOC_EXPLICIT_DEPENDENCY_REQUIRED,\n        ),\n        \"R8919\": (\n            \"Obscure implicit test dependency with MagicMock(). Rewrite with create_autospec(ConcreteType).\",\n            \"obscure-mock\",\n            DOC_OBSCURE_MOCK,\n        ),\n        \"R8921\": (\n            \"Mock not assigned to a variable: %s\",\n            \"mock-no-assign\",\n            \"Every mocked object should be assigned to a variable to allow for assertions.\",\n        ),\n        \"R8922\": (\n            \"Missing usage of mock for %s\",\n            \"mock-no-usage\",\n            \"Usually this check means a hidden bug, where object is mocked, but we don't check if it was used \"\n            \"correctly. Every mock should have at least one assertion, return value, or side effect specified.\",\n        ),\n    }\n    options = (\n        (\n            \"require-explicit-dependency\",\n            {\n                \"default\": (\"databricks\",),\n                \"type\": \"csv\",\n                \"metavar\": \"<modules>\",\n                \"help\": \"Package names that contain code for your project.\",\n            },\n        ),\n    )\n\n    def open(self) -> None:\n        pass\n\n    def visit_call(self, node: nodes.Call) -> None:\n        pass\n\n```\n--- File: databricks/labs/pylint/notebooks.py ---\n```python\nclass NotebookChecker(BaseRawFileChecker):\n    __implements__ = (BaseRawFileChecker,)\n    name = \"databricks-notebooks\"\n    msgs = {\n        \"C8913\": (\n            \"Notebooks should not have more than 75 cells\",\n            \"notebooks-too-many-cells\",\n            \"Otherwise, it's hard to maintain and understand the notebook for other people and the future you\",\n        ),\n        \"R8914\": (\n            \"Using %run is not allowed\",\n            \"notebooks-percent-run\",\n            \"Use functions instead of %run to avoid side effects and make the code more testable. \"\n            \"If you need to share code between notebooks, consider creating a library. \"\n            \"If still need to call another code as a separate job, use Databricks SDK for Python:\"\n            \" https://databricks-sdk-py.readthedocs.io/en/latest/index.html\",\n        ),\n    }\n    options = (\n        (\n            \"max-cells\",\n            {\n                \"default\": 75,\n                \"type\": \"int\",\n                \"metavar\": \"<int>\",\n                \"help\": \"Maximum number of cells in the notebook\",\n            },\n        ),\n    )\n\n    def process_module(self, node: astroid.Module):\n        \"\"\"Read raw module. Need to do some tricks, as `ast` doesn't provide access for comments.\n\n        Alternative libraries that can parse comments along with the code:\n        - https://github.com/Instagram/LibCST/ (MIT + PSF)\n        - https://github.com/python/cpython/tree/3.10/Lib/lib2to3 (PSF), removed in Python 3.12\n        - https://github.com/t3rn0/ast-comments (MIT)\n        - https://github.com/facebookincubator/bowler (MIT), abandoned\n        - https://github.com/PyCQA/redbaron (LGPLv3)\n        \"\"\"\n        pass\n\n```\n--- File: databricks/labs/pylint/readability.py ---\n```python\nclass ReadabilityChecker(BaseChecker):\n    name = \"readability\"\n    msgs = {\n        \"R8923\": (\n            \"List comprehension spans multiple lines, rewrite as for loop\",\n            \"rewrite-as-for-loop\",\n            \"\"\"List comprehensions in Python are typically used to create new lists by iterating over an existing\n            iterable in a concise, one-line syntax. However, when a list comprehension becomes too complex or spans \n            multiple lines, it may lose its readability and clarity, which are key advantages of Python's syntax.\"\"\",\n        ),\n    }\n\n    def visit_listcomp(self, node: nodes.ListComp) -> None:\n        pass\n\n```\n--- File: databricks/labs/pylint/spark.py ---\n```python\nclass SparkChecker(BaseChecker):\n    name = \"spark\"\n    msgs = {\n        \"C8915\": (\n            \"Using spark outside the function is leading to untestable code\",\n            \"spark-outside-function\",\n            \"Do not use global spark object, pass it as an argument to the function instead, \"\n            \"so that the function becomes testable in a CI/CD pipelines.\",\n        ),\n        \"W8916\": (\n            \"Function %s is missing a 'spark' argument\",\n            \"no-spark-argument-in-function\",\n            \"Function refers to a global spark variable, which may not always be available. \"\n            \"Pass the spark object as an argument to the function instead, so that the function \"\n            \"becomes testable in a CI/CD pipelines.\",\n        ),\n        \"C8917\": (\n            \"Rewrite to display in a notebook: display(%s)\",\n            \"use-display-instead-of-show\",\n            \"Use display() instead of show() to visualize the data in a notebook.\",\n        ),\n    }\n\n    def visit_name(self, node: astroid.Name):\n        pass\n\n    def visit_attribute(self, node: astroid.Attribute):\n        pass\n\n```",
        "minimal_code_skeleton_structured": [
            {
                "file_path": "databricks/labs/pylint/airflow.py",
                "code": "class AirflowChecker(BaseChecker):\n    name = \"databricks-airflow\"\n    msgs = {\n        \"W8901\": (\n            \"%s cluster missing `data_security_mode` required for Unity Catalog compatibility\",\n            \"missing-data-security-mode\",\n            \"Before you enable Unity Catalog, you must set the `data_security_mode` to 'NONE',\"\n            \" so that your existing jobs would keep the same behavior. Failure to do so may cause \"\n            \"your jobs to fail with unexpected errors.\",\n        ),\n        \"W8902\": (\n            \"%s cluster has unsupported runtime: %s\",\n            \"unsupported-runtime\",\n            \"The runtime version is not supported by Unity Catalog. Please upgrade to a runtime greater \"\n            \"than or equal to 11.3.\",\n        ),\n    }\n\n    def visit_call(self, node: astroid.Call):\n        pass\n\n"
            },
            {
                "file_path": "databricks/labs/pylint/all.py",
                "code": "def register(linter):\n    pass\n\n"
            },
            {
                "file_path": "databricks/labs/pylint/dbutils.py",
                "code": "class DbutilsChecker(BaseChecker):\n    name = \"databricks-dbutils\"\n    msgs = {\n        \"R8903\": (\n            \"Use Databricks SDK instead: w.dbfs.copy(%s, %s)\",\n            \"dbutils-fs-cp\",\n            \"Migrate all usage of dbutils to Databricks SDK. See the more detailed documentation at \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/workspace/files/dbfs.html\",\n        ),\n        \"R8904\": (\n            \"Use Databricks SDK instead: with w.dbfs.download(%s) as f: f.read()\",\n            \"dbutils-fs-head\",\n            \"Migrate all usage of dbutils to Databricks SDK. See the more detailed documentation at \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/workspace/files/dbfs.html\",\n        ),\n        \"R8905\": (\n            \"Use Databricks SDK instead: w.dbfs.list(%s)\",\n            \"dbutils-fs-ls\",\n            \"Migrate all usage of dbutils to Databricks SDK. See the more detailed documentation at \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/workspace/files/dbfs.html\",\n        ),\n        \"R8906\": (\n            \"Mounts are not supported with Unity Catalog, switch to using Unity Catalog Volumes instead\",\n            \"dbutils-fs-mount\",\n            \"Migrate all usage to Unity Catalog\",\n        ),\n        \"R8907\": (\n            \"Credentials utility is not supported with Unity Catalog\",\n            \"dbutils-credentials\",\n            \"Migrate all usage to Unity Catalog\",\n        ),\n        \"R8908\": (\n            \"\"\"Use Databricks SDK instead: w.jobs.submit(\n                tasks=[jobs.SubmitTask(existing_cluster_id=...,\n                                       notebook_task=jobs.NotebookTask(notebook_path=%s),\n                                       task_key=...)\n                ]).result(timeout=timedelta(minutes=%s))\"\"\",\n            \"dbutils-notebook-run\",\n            \"Migrate all usage of dbutils to Databricks SDK. See the more detailed documentation at \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/workspace/jobs/jobs.html\",\n        ),\n        \"R8909\": (\n            \"Use Databricks SDK instead: from databricks.sdk import WorkspaceClient(); w = WorkspaceClient()\",\n            \"pat-token-leaked\",\n            \"Do not hardcode secrets in code, use Databricks SDK instead, which natively authenticates in Databricks \"\n            \"Notebooks. See more at https://databricks-sdk-py.readthedocs.io/en/latest/authentication.html\",\n        ),\n        \"R8910\": (\n            \"Do not use internal APIs, rewrite using Databricks SDK: %s\",\n            \"internal-api\",\n            \"Do not use internal APIs. Use Databricks SDK for Python: \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/index.html\",\n        ),\n    }\n\n    def visit_call(self, node: astroid.Call):\n        pass\n\n    def visit_const(self, node: astroid.Const):\n        pass\n\n    def visit_import(self, node: astroid.Import):\n        pass\n\n    def visit_importfrom(self, node: astroid.ImportFrom):\n        pass\n\n"
            },
            {
                "file_path": "databricks/labs/pylint/eradicate.py",
                "code": "class EradicateChecker(BaseRawFileChecker):\n    name = \"eradicate\"\n    msgs = {\n        \"C8920\": (\n            \"Remove commented out code: %s\",\n            \"dead-code\",\n            \"Version control helps with keeping track of code changes. There is no need to keep commented out code in \"\n            \"the codebase. Remove it to keep the codebase clean.\",\n        ),\n    }\n\n    def open(self) -> None:\n        pass\n\n    def process_module(self, node: astroid.Module):\n        pass\n\n"
            },
            {
                "file_path": "databricks/labs/pylint/legacy.py",
                "code": "class LegacyChecker(BaseChecker):\n    name = \"databricks-legacy\"\n    msgs = {\n        \"R8911\": (\n            \"Don't use databricks_cli, use databricks.sdk instead: pip install databricks-sdk\",\n            \"legacy-cli\",\n            \"Migrate all usage of Legacy CLI to Databricks SDK. See the more detailed documentation at \"\n            \"https://databricks-sdk-py.readthedocs.io/en/latest/index.html\",\n        ),\n        \"W8912\": (\n            \"Incompatible with Unity Catalog: %s\",\n            \"incompatible-with-uc\",\n            \"Migrate all usage to Databricks Unity Catalog. Use https://github.com/databrickslabs/ucx for more details\",\n        ),\n    }\n    UC_INCOMPATIBLE_BRUTE_FORCE = {\n        \"s3fs\",\n        \"boto3\",\n        \"graphframes\",\n        \"pyspark.ml\",\n        # literals\n        \"dbfs:\",\n        \"hive_metastore.\",\n        \"kafka.sasl.client.callback.handler.class\",\n        \"kafka.sasl.login.callback.handler.class\",\n        \"kafka.sasl.login.class\",\n        \"kafka.partition.assignment.strategy\",\n        \"kafka.ssl.truststore.location\",\n        \"kafka.ssl.keystore.location\",\n        # calls\n        # \"sc.\", triggers false positives for \"misc.\"\n        \"spark.catalog.\",\n        \"spark._jsparkSession.catalog\",\n        \"spark._jspark\",\n        \"spark._jvm\",\n        \"._jdf\",\n        \"._jcol\",\n        \"spark.udf.registerJavaFunction\",\n        \"applyInPandas\",\n        \"mapInPandas\",\n        \"_jvm\",\n        \"SQLContext\",\n        \"emptyRDD\",\n        \"pickleFile\",\n        \"textFile\",\n        \"newAPIHadoopFile\",\n        \"newAPIHadoopRDD\",\n        \"hadoopFile\",\n        \"hadoopRDD\",\n        \"saveAsHadoopFile\",\n        \"saveAsHadoopDataset\",\n        \"saveAsNewAPIHadoopFile\",\n        \"saveAsNewAPIHadoopDataset\",\n        \"setJobGroup\",\n        \"setLocalProperty\",\n        \"applyInPandasWithState\",\n    }\n\n    def visit_import(self, node: astroid.Import):\n        pass\n\n    def visit_importfrom(self, node: astroid.ImportFrom):\n        pass\n\n    def visit_call(self, node: astroid.Call):\n        pass\n\n    def visit_const(self, node: astroid.Const):\n        pass\n\n"
            },
            {
                "file_path": "databricks/labs/pylint/mocking.py",
                "code": "class MockingChecker(BaseChecker):\n    name = \"mocking\"\n    msgs = {\n        \"R8918\": (\n            \"Obscure implicit test dependency with mock.patch(%s). Rewrite to inject dependencies through constructor.\",\n            \"explicit-dependency-required\",\n            DOC_EXPLICIT_DEPENDENCY_REQUIRED,\n        ),\n        \"R8919\": (\n            \"Obscure implicit test dependency with MagicMock(). Rewrite with create_autospec(ConcreteType).\",\n            \"obscure-mock\",\n            DOC_OBSCURE_MOCK,\n        ),\n        \"R8921\": (\n            \"Mock not assigned to a variable: %s\",\n            \"mock-no-assign\",\n            \"Every mocked object should be assigned to a variable to allow for assertions.\",\n        ),\n        \"R8922\": (\n            \"Missing usage of mock for %s\",\n            \"mock-no-usage\",\n            \"Usually this check means a hidden bug, where object is mocked, but we don't check if it was used \"\n            \"correctly. Every mock should have at least one assertion, return value, or side effect specified.\",\n        ),\n    }\n    options = (\n        (\n            \"require-explicit-dependency\",\n            {\n                \"default\": (\"databricks\",),\n                \"type\": \"csv\",\n                \"metavar\": \"<modules>\",\n                \"help\": \"Package names that contain code for your project.\",\n            },\n        ),\n    )\n\n    def open(self) -> None:\n        pass\n\n    def visit_call(self, node: nodes.Call) -> None:\n        pass\n\n"
            },
            {
                "file_path": "databricks/labs/pylint/notebooks.py",
                "code": "class NotebookChecker(BaseRawFileChecker):\n    __implements__ = (BaseRawFileChecker,)\n    name = \"databricks-notebooks\"\n    msgs = {\n        \"C8913\": (\n            \"Notebooks should not have more than 75 cells\",\n            \"notebooks-too-many-cells\",\n            \"Otherwise, it's hard to maintain and understand the notebook for other people and the future you\",\n        ),\n        \"R8914\": (\n            \"Using %run is not allowed\",\n            \"notebooks-percent-run\",\n            \"Use functions instead of %run to avoid side effects and make the code more testable. \"\n            \"If you need to share code between notebooks, consider creating a library. \"\n            \"If still need to call another code as a separate job, use Databricks SDK for Python:\"\n            \" https://databricks-sdk-py.readthedocs.io/en/latest/index.html\",\n        ),\n    }\n    options = (\n        (\n            \"max-cells\",\n            {\n                \"default\": 75,\n                \"type\": \"int\",\n                \"metavar\": \"<int>\",\n                \"help\": \"Maximum number of cells in the notebook\",\n            },\n        ),\n    )\n\n    def process_module(self, node: astroid.Module):\n        \"\"\"Read raw module. Need to do some tricks, as `ast` doesn't provide access for comments.\n\n        Alternative libraries that can parse comments along with the code:\n        - https://github.com/Instagram/LibCST/ (MIT + PSF)\n        - https://github.com/python/cpython/tree/3.10/Lib/lib2to3 (PSF), removed in Python 3.12\n        - https://github.com/t3rn0/ast-comments (MIT)\n        - https://github.com/facebookincubator/bowler (MIT), abandoned\n        - https://github.com/PyCQA/redbaron (LGPLv3)\n        \"\"\"\n        pass\n\n"
            },
            {
                "file_path": "databricks/labs/pylint/readability.py",
                "code": "class ReadabilityChecker(BaseChecker):\n    name = \"readability\"\n    msgs = {\n        \"R8923\": (\n            \"List comprehension spans multiple lines, rewrite as for loop\",\n            \"rewrite-as-for-loop\",\n            \"\"\"List comprehensions in Python are typically used to create new lists by iterating over an existing\n            iterable in a concise, one-line syntax. However, when a list comprehension becomes too complex or spans \n            multiple lines, it may lose its readability and clarity, which are key advantages of Python's syntax.\"\"\",\n        ),\n    }\n\n    def visit_listcomp(self, node: nodes.ListComp) -> None:\n        pass\n\n"
            },
            {
                "file_path": "databricks/labs/pylint/spark.py",
                "code": "class SparkChecker(BaseChecker):\n    name = \"spark\"\n    msgs = {\n        \"C8915\": (\n            \"Using spark outside the function is leading to untestable code\",\n            \"spark-outside-function\",\n            \"Do not use global spark object, pass it as an argument to the function instead, \"\n            \"so that the function becomes testable in a CI/CD pipelines.\",\n        ),\n        \"W8916\": (\n            \"Function %s is missing a 'spark' argument\",\n            \"no-spark-argument-in-function\",\n            \"Function refers to a global spark variable, which may not always be available. \"\n            \"Pass the spark object as an argument to the function instead, so that the function \"\n            \"becomes testable in a CI/CD pipelines.\",\n        ),\n        \"C8917\": (\n            \"Rewrite to display in a notebook: display(%s)\",\n            \"use-display-instead-of-show\",\n            \"Use display() instead of show() to visualize the data in a notebook.\",\n        ),\n    }\n\n    def visit_name(self, node: astroid.Name):\n        pass\n\n    def visit_attribute(self, node: astroid.Attribute):\n        pass\n\n"
            }
        ],
        "minimal_test_cases": [
            {
                "test_id": "tests/test_samples.py::test_samples[dead_code]",
                "covers": [
                    "databricks.labs.pylint.all.register - utility for registering all checkers in sample tests",
                    "databricks.labs.pylint.eradicate.EradicateChecker.open - checker initialization",
                    "databricks.labs.pylint.eradicate.EradicateChecker.process_module - happy path for dead-code rule"
                ]
            },
            {
                "test_id": "tests/test_airflow.py::test_missing_data_security_mode_in_submit_run_clusters",
                "covers": [
                    "databricks.labs.pylint.airflow.AirflowChecker.visit_call - happy path for data-security-mode and runtime checks in DatabricksSubmitRunOperator"
                ]
            },
            {
                "test_id": "tests/test_dbutils.py::test_checks_cp",
                "covers": [
                    "databricks.labs.pylint.dbutils.DbutilsChecker.visit_call - happy path for dbutils-fs-cp rule"
                ]
            },
            {
                "test_id": "tests/test_dbutils.py::test_checks_secrets",
                "covers": [
                    "databricks.labs.pylint.dbutils.DbutilsChecker.visit_const - happy path for pat-token-leaked rule"
                ]
            },
            {
                "test_id": "tests/test_dbutils.py::test_internal_api[import dbruntime.foo, bar]",
                "covers": [
                    "databricks.labs.pylint.dbutils.DbutilsChecker.visit_import - happy path for internal-api rule (dbruntime import)"
                ]
            },
            {
                "test_id": "tests/test_dbutils.py::test_internal_api[from dbruntime.foo import bar, baz]",
                "covers": [
                    "databricks.labs.pylint.dbutils.DbutilsChecker.visit_importfrom - happy path for internal-api rule (dbruntime from-import)"
                ]
            },
            {
                "test_id": "tests/test_legacy.py::test_legacy_cli[import databricks_cli.foo]",
                "covers": [
                    "databricks.labs.pylint.legacy.LegacyChecker.visit_import - happy path for legacy-cli rule (import)"
                ]
            },
            {
                "test_id": "tests/test_legacy.py::test_legacy_cli[from databricks_cli.foo import bar]",
                "covers": [
                    "databricks.labs.pylint.legacy.LegacyChecker.visit_importfrom - happy path for legacy-cli rule (from-import)"
                ]
            },
            {
                "test_id": "tests/test_legacy.py::test_un_incompatible[spark.sql(\\n            'SELECT * FROM hive_metastore.default.foo' #@\\n        )]",
                "covers": [
                    "databricks.labs.pylint.legacy.LegacyChecker.visit_const - happy path for incompatible-with-uc rule (string constant)"
                ]
            },
            {
                "test_id": "tests/test_legacy.py::test_un_incompatible[spark.catalog.list()]",
                "covers": [
                    "databricks.labs.pylint.legacy.LegacyChecker.visit_call - happy path for incompatible-with-uc rule (function call)"
                ]
            },
            {
                "test_id": "tests/test_mocking.py::test_obscure_mock",
                "covers": [
                    "databricks.labs.pylint.mocking.MockingChecker.open - checker initialization",
                    "databricks.labs.pylint.mocking.MockingChecker.visit_call - happy path for obscure-mock rule (MagicMock)"
                ]
            },
            {
                "test_id": "tests/test_samples.py::test_samples[percent_run]",
                "covers": [
                    "databricks.labs.pylint.all.register - utility for registering all checkers in sample tests",
                    "databricks.labs.pylint.notebooks.NotebookChecker.process_module - happy path for notebooks-percent-run rule",
                    "databricks.labs.pylint.spark.SparkChecker.visit_name - happy path for spark-outside-function rule (via sample content)"
                ]
            },
            {
                "test_id": "tests/test_readability.py::test_multi_line_list_comprehensions_not_allowed",
                "covers": [
                    "databricks.labs.pylint.readability.ReadabilityChecker.visit_listcomp - happy path for rewrite-as-for-loop rule (multi-line list comprehension)"
                ]
            },
            {
                "test_id": "tests/test_spark.py::test_df_show",
                "covers": [
                    "databricks.labs.pylint.spark.SparkChecker.visit_attribute - happy path for use-display-instead-of-show rule (df.show())"
                ]
            }
        ]
    },
    {
        "idx": 104089,
        "repo_name": "6mini_holidayskr",
        "url": "https://github.com/6mini/holidayskr",
        "description": "   Python .    ,   ( ,  )     .      ,       .",
        "stars": 13,
        "forks": 2,
        "language": "python",
        "size": 27,
        "created_at": "2024-02-21T07:45:29+00:00",
        "updated_at": "2025-04-02T02:01:26+00:00",
        "pypi_info": {
            "name": "holidayskr",
            "version": "0.2.0",
            "url": "https://files.pythonhosted.org/packages/11/43/f56386a7cbd4cdde461a8b3e21b1c921202a41eff252ccff4da7b05bb478/holidayskr-0.2.0.tar.gz"
        },
        "judge_info": {
            "language": "python",
            "is_good_project": false,
            "reason": "",
            "python_file_num": 5,
            "comment_ratio": 0.16591928251121077,
            "pyfile_content_length": 8848,
            "pyfile_code_lines": 223,
            "test_file_exist": true,
            "test_file_content_length": 3678,
            "pytest_framework": true,
            "test_case_num": 10,
            "metadata_path": [
                "setup.py"
            ],
            "readme_content_length": 3200,
            "llm_reason": "Positive aspects: The project has a clear and well-defined goal (calculating South Korean holidays), making it suitable for specifying a replication task for an AI. It is a library, not a GUI application. The complexity is appropriate (Medium), involving date calculations, rule-based logic for different holiday types (solar, lunar, substitute, specific), which is non-trivial but manageable. Comprehensive test cases are provided, facilitating verification of the AI's output. Dependencies like `requests` and `korean_lunar_calendar` are standard PyPI packages.\nNegative aspects: The primary concern for using it *directly* as a self-contained benchmark is the `download_holiday_data` function in `core.py` which fetches holiday definitions from an external URL (GitHub). This violates the self-containment requirement (no internet dependency for core functionality/testing). To use this project as a benchmark, the task specification for the AI must address this, likely by requiring the AI to bundle the holiday data (e.g., from a provided local JSON file) within the package or read it from a local path, and tests might need mocking/adaptation. Assuming the AI is allowed to use the `korean_lunar_calendar` library for lunar conversions keeps the difficulty at Medium; requiring re-implementation would make it Hard/Very Hard.",
            "llm_project_type": "Date/Time Utility Library",
            "llm_rating": 75,
            "llm_difficulty": "Medium"
        },
        "tests": {
            "repo_name": "6mini_holidayskr",
            "finish_test": true,
            "test_case_result": {
                "tests/test_core.py::test_download_holiday_data": "passed",
                "tests/test_core.py::test_convert_lunar_to_solar[2024-1-1-2024-02-10]": "passed",
                "tests/test_core.py::test_convert_lunar_to_solar[2025-1-1-2025-01-29]": "passed",
                "tests/test_core.py::test_convert_lunar_to_solar[2026-1-1-2026-02-17]": "passed",
                "tests/test_core.py::test_is_holiday[2024-01-01-True]": "passed",
                "tests/test_core.py::test_is_holiday[2024-02-10-True]": "passed",
                "tests/test_core.py::test_is_holiday[2024-05-01-True]": "passed",
                "tests/test_core.py::test_is_holiday[2024-12-25-True]": "passed",
                "tests/test_core.py::test_is_holiday[2024-06-06-True]": "passed",
                "tests/test_core.py::test_is_holiday[2024-04-10-True]": "passed",
                "tests/test_core.py::test_is_holiday[2024-04-22-False]": "passed",
                "tests/test_core.py::test_year_holidays": "passed",
                "tests/test_core.py::test_today_is_holiday": "passed",
                "tests/test_core.py::test_year_specific_holidays[2024-2024-02-12-\\ub300\\uccb4 \\uacf5\\ud734\\uc77c(\\uc124\\ub0a0)]": "passed",
                "tests/test_core.py::test_year_specific_holidays[2024-2024-04-10-\\uc81c22\\ub300 \\uad6d\\ud68c\\uc758\\uc6d0 \\uc120\\uac70\\uc77c]": "passed",
                "tests/test_core.py::test_year_specific_holidays[2025-2025-03-03-\\ub300\\uccb4 \\uacf5\\ud734\\uc77c(3\\xb71\\uc808)]": "passed",
                "tests/test_core.py::test_year_specific_holidays[2026-2026-05-25-\\ub300\\uccb4 \\uacf5\\ud734\\uc77c(\\uc11d\\uac00\\ud0c4\\uc2e0\\uc77c)]": "passed",
                "tests/test_core.py::test_lunar_holidays_with_surrounding_days[2024-01-01-expected_dates0]": "passed",
                "tests/test_core.py::test_lunar_holidays_with_surrounding_days[2024-08-15-expected_dates1]": "passed",
                "tests/test_core.py::test_invalid_date_format": "passed",
                "tests/test_core.py::test_invalid_year_format": "passed",
                "tests/test_core.py::test_not_a_holiday[2024-01-02]": "passed",
                "tests/test_core.py::test_not_a_holiday[2024-07-01]": "passed"
            },
            "success_count": 23,
            "failed_count": 0,
            "error_count": 0,
            "skipped_count": 0,
            "unknown_count": 0,
            "total_count": 23,
            "success_rate": 1.0,
            "coverage_report": {
                "covered_lines": 48,
                "num_statements": 53,
                "percent_covered": 89.83050847457628,
                "percent_covered_display": "90",
                "missing_lines": 5,
                "excluded_lines": 0,
                "num_branches": 6,
                "num_partial_branches": 1,
                "covered_branches": 5,
                "missing_branches": 1
            },
            "coverage_result": {}
        },
        "codelines_count": 223,
        "codefiles_count": 5,
        "code_length": 8848,
        "test_files_count": 1,
        "test_code_length": 3678,
        "class_diagram": "@startuml\n@enduml",
        "structure": [
            {
                "file": "setup.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/test_core.py",
                "functions": [
                    {
                        "name": "test_download_holiday_data",
                        "docstring": null,
                        "comments": "1.    ",
                        "args": []
                    },
                    {
                        "name": "test_convert_lunar_to_solar",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "year",
                            "month",
                            "day",
                            "expected"
                        ]
                    },
                    {
                        "name": "test_is_holiday",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "date_str",
                            "expected"
                        ]
                    },
                    {
                        "name": "test_year_holidays",
                        "docstring": null,
                        "comments": "4.    ",
                        "args": []
                    },
                    {
                        "name": "test_today_is_holiday",
                        "docstring": null,
                        "comments": "5.     ",
                        "args": []
                    },
                    {
                        "name": "test_year_specific_holidays",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "year",
                            "date",
                            "expected_name"
                        ]
                    },
                    {
                        "name": "test_lunar_holidays_with_surrounding_days",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "year",
                            "lunar_date",
                            "expected_dates"
                        ]
                    },
                    {
                        "name": "test_invalid_date_format",
                        "docstring": null,
                        "comments": "8.      ",
                        "args": []
                    },
                    {
                        "name": "test_invalid_year_format",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_not_a_holiday",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "date_str"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "holidayskr/core.py",
                "functions": [
                    {
                        "name": "download_holiday_data",
                        "docstring": "GitHub   .   .",
                        "comments": null,
                        "args": [
                            "url",
                            "retries"
                        ]
                    },
                    {
                        "name": "convert_lunar_to_solar",
                        "docstring": "    .",
                        "comments": null,
                        "args": [
                            "year",
                            "month",
                            "day",
                            "adjust"
                        ]
                    },
                    {
                        "name": "get_holidays",
                        "docstring": "     ( ,  ,  ).",
                        "comments": null,
                        "args": [
                            "year"
                        ]
                    },
                    {
                        "name": "is_holiday",
                        "docstring": "   .",
                        "comments": null,
                        "args": [
                            "date_str"
                        ]
                    },
                    {
                        "name": "today_is_holiday",
                        "docstring": "   .",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "year_holidays",
                        "docstring": "    .",
                        "comments": null,
                        "args": [
                            "year_str"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "holidayskr/__init__.py",
                "functions": [],
                "classes": []
            }
        ],
        "test_cases": {
            "tests/test_core.py::test_download_holiday_data": {
                "testid": "tests/test_core.py::test_download_holiday_data",
                "result": "passed",
                "test_implementation": "def test_download_holiday_data():\n    url = \"https://raw.githubusercontent.com/6mini/holidayskr/main/holidayskr.json\"\n    data = download_holiday_data(url)\n    assert data is not None, \"   .\"\n    assert 'solar_holidays' in data, \"'solar_holidays'   .\"\n    assert 'lunar_holidays' in data, \"'lunar_holidays'   .\"\n    assert 'year_specific_holidays' in data, \"'year_specific_holidays'   .\""
            },
            "tests/test_core.py::test_convert_lunar_to_solar[2024-1-1-2024-02-10]": {
                "testid": "tests/test_core.py::test_convert_lunar_to_solar[2024-1-1-2024-02-10]",
                "result": "passed",
                "test_implementation": "def test_convert_lunar_to_solar(year, month, day, expected):\n    result = convert_lunar_to_solar(year, month, day)\n    assert result.strftime('%Y-%m-%d') == expected, f\"  : {expected},  : {result}\""
            },
            "tests/test_core.py::test_convert_lunar_to_solar[2025-1-1-2025-01-29]": {
                "testid": "tests/test_core.py::test_convert_lunar_to_solar[2025-1-1-2025-01-29]",
                "result": "passed",
                "test_implementation": "def test_convert_lunar_to_solar(year, month, day, expected):\n    result = convert_lunar_to_solar(year, month, day)\n    assert result.strftime('%Y-%m-%d') == expected, f\"  : {expected},  : {result}\""
            },
            "tests/test_core.py::test_convert_lunar_to_solar[2026-1-1-2026-02-17]": {
                "testid": "tests/test_core.py::test_convert_lunar_to_solar[2026-1-1-2026-02-17]",
                "result": "passed",
                "test_implementation": "def test_convert_lunar_to_solar(year, month, day, expected):\n    result = convert_lunar_to_solar(year, month, day)\n    assert result.strftime('%Y-%m-%d') == expected, f\"  : {expected},  : {result}\""
            },
            "tests/test_core.py::test_is_holiday[2024-01-01-True]": {
                "testid": "tests/test_core.py::test_is_holiday[2024-01-01-True]",
                "result": "passed",
                "test_implementation": "def test_is_holiday(date_str, expected):\n    assert is_holiday(date_str) == expected, f\"{date_str}    .\""
            },
            "tests/test_core.py::test_is_holiday[2024-02-10-True]": {
                "testid": "tests/test_core.py::test_is_holiday[2024-02-10-True]",
                "result": "passed",
                "test_implementation": "def test_is_holiday(date_str, expected):\n    assert is_holiday(date_str) == expected, f\"{date_str}    .\""
            },
            "tests/test_core.py::test_is_holiday[2024-05-01-True]": {
                "testid": "tests/test_core.py::test_is_holiday[2024-05-01-True]",
                "result": "passed",
                "test_implementation": "def test_is_holiday(date_str, expected):\n    assert is_holiday(date_str) == expected, f\"{date_str}    .\""
            },
            "tests/test_core.py::test_is_holiday[2024-12-25-True]": {
                "testid": "tests/test_core.py::test_is_holiday[2024-12-25-True]",
                "result": "passed",
                "test_implementation": "def test_is_holiday(date_str, expected):\n    assert is_holiday(date_str) == expected, f\"{date_str}    .\""
            },
            "tests/test_core.py::test_is_holiday[2024-06-06-True]": {
                "testid": "tests/test_core.py::test_is_holiday[2024-06-06-True]",
                "result": "passed",
                "test_implementation": "def test_is_holiday(date_str, expected):\n    assert is_holiday(date_str) == expected, f\"{date_str}    .\""
            },
            "tests/test_core.py::test_is_holiday[2024-04-10-True]": {
                "testid": "tests/test_core.py::test_is_holiday[2024-04-10-True]",
                "result": "passed",
                "test_implementation": "def test_is_holiday(date_str, expected):\n    assert is_holiday(date_str) == expected, f\"{date_str}    .\""
            },
            "tests/test_core.py::test_is_holiday[2024-04-22-False]": {
                "testid": "tests/test_core.py::test_is_holiday[2024-04-22-False]",
                "result": "passed",
                "test_implementation": "def test_is_holiday(date_str, expected):\n    assert is_holiday(date_str) == expected, f\"{date_str}    .\""
            },
            "tests/test_core.py::test_year_holidays": {
                "testid": "tests/test_core.py::test_year_holidays",
                "result": "passed",
                "test_implementation": "def test_year_holidays():\n    year = \"2024\"\n    holidays = year_holidays(year)\n    assert holidays is not None, \"   .\"\n    assert len(holidays) > 0, \"  .\""
            },
            "tests/test_core.py::test_today_is_holiday": {
                "testid": "tests/test_core.py::test_today_is_holiday",
                "result": "passed",
                "test_implementation": "def test_today_is_holiday():\n    #         ,      .\n    #  ,     ,        .\n    is_holiday = today_is_holiday()\n    assert isinstance(is_holiday, bool), \"  bool  .\""
            },
            "tests/test_core.py::test_year_specific_holidays[2024-2024-02-12-\\ub300\\uccb4 \\uacf5\\ud734\\uc77c(\\uc124\\ub0a0)]": {
                "testid": "tests/test_core.py::test_year_specific_holidays[2024-2024-02-12-\\ub300\\uccb4 \\uacf5\\ud734\\uc77c(\\uc124\\ub0a0)]",
                "result": "passed",
                "test_implementation": "def test_year_specific_holidays(year, date, expected_name):\n    holidays = year_holidays(str(year))\n    assert any(holiday for holiday in holidays if holiday[0].strftime('%Y-%m-%d') == date and holiday[1] == expected_name), \\\n        f\"{year} {date}({expected_name})   .\""
            },
            "tests/test_core.py::test_year_specific_holidays[2024-2024-04-10-\\uc81c22\\ub300 \\uad6d\\ud68c\\uc758\\uc6d0 \\uc120\\uac70\\uc77c]": {
                "testid": "tests/test_core.py::test_year_specific_holidays[2024-2024-04-10-\\uc81c22\\ub300 \\uad6d\\ud68c\\uc758\\uc6d0 \\uc120\\uac70\\uc77c]",
                "result": "passed",
                "test_implementation": "def test_year_specific_holidays(year, date, expected_name):\n    holidays = year_holidays(str(year))\n    assert any(holiday for holiday in holidays if holiday[0].strftime('%Y-%m-%d') == date and holiday[1] == expected_name), \\\n        f\"{year} {date}({expected_name})   .\""
            },
            "tests/test_core.py::test_year_specific_holidays[2025-2025-03-03-\\ub300\\uccb4 \\uacf5\\ud734\\uc77c(3\\xb71\\uc808)]": {
                "testid": "tests/test_core.py::test_year_specific_holidays[2025-2025-03-03-\\ub300\\uccb4 \\uacf5\\ud734\\uc77c(3\\xb71\\uc808)]",
                "result": "passed",
                "test_implementation": "def test_year_specific_holidays(year, date, expected_name):\n    holidays = year_holidays(str(year))\n    assert any(holiday for holiday in holidays if holiday[0].strftime('%Y-%m-%d') == date and holiday[1] == expected_name), \\\n        f\"{year} {date}({expected_name})   .\""
            },
            "tests/test_core.py::test_year_specific_holidays[2026-2026-05-25-\\ub300\\uccb4 \\uacf5\\ud734\\uc77c(\\uc11d\\uac00\\ud0c4\\uc2e0\\uc77c)]": {
                "testid": "tests/test_core.py::test_year_specific_holidays[2026-2026-05-25-\\ub300\\uccb4 \\uacf5\\ud734\\uc77c(\\uc11d\\uac00\\ud0c4\\uc2e0\\uc77c)]",
                "result": "passed",
                "test_implementation": "def test_year_specific_holidays(year, date, expected_name):\n    holidays = year_holidays(str(year))\n    assert any(holiday for holiday in holidays if holiday[0].strftime('%Y-%m-%d') == date and holiday[1] == expected_name), \\\n        f\"{year} {date}({expected_name})   .\""
            },
            "tests/test_core.py::test_lunar_holidays_with_surrounding_days[2024-01-01-expected_dates0]": {
                "testid": "tests/test_core.py::test_lunar_holidays_with_surrounding_days[2024-01-01-expected_dates0]",
                "result": "passed",
                "test_implementation": "def test_lunar_holidays_with_surrounding_days(year, lunar_date, expected_dates):\n    holidays = year_holidays(str(year))\n    for expected_date in expected_dates:\n        assert any(holiday for holiday in holidays if holiday[0].strftime('%Y-%m-%d') == expected_date), \\\n            f\"{year} {lunar_date}   {expected_date}   .\""
            },
            "tests/test_core.py::test_lunar_holidays_with_surrounding_days[2024-08-15-expected_dates1]": {
                "testid": "tests/test_core.py::test_lunar_holidays_with_surrounding_days[2024-08-15-expected_dates1]",
                "result": "passed",
                "test_implementation": "def test_lunar_holidays_with_surrounding_days(year, lunar_date, expected_dates):\n    holidays = year_holidays(str(year))\n    for expected_date in expected_dates:\n        assert any(holiday for holiday in holidays if holiday[0].strftime('%Y-%m-%d') == expected_date), \\\n            f\"{year} {lunar_date}   {expected_date}   .\""
            },
            "tests/test_core.py::test_invalid_date_format": {
                "testid": "tests/test_core.py::test_invalid_date_format",
                "result": "passed",
                "test_implementation": "def test_invalid_date_format():\n    with pytest.raises(ValueError):\n        is_holiday(\"2024-02-30\")  #   "
            },
            "tests/test_core.py::test_invalid_year_format": {
                "testid": "tests/test_core.py::test_invalid_year_format",
                "result": "passed",
                "test_implementation": "def test_invalid_year_format():\n    with pytest.raises(ValueError):\n        year_holidays(\"20XX\")  #   "
            },
            "tests/test_core.py::test_not_a_holiday[2024-01-02]": {
                "testid": "tests/test_core.py::test_not_a_holiday[2024-01-02]",
                "result": "passed",
                "test_implementation": "def test_not_a_holiday(date_str):\n    assert not is_holiday(date_str), f\"{date_str}  .\""
            },
            "tests/test_core.py::test_not_a_holiday[2024-07-01]": {
                "testid": "tests/test_core.py::test_not_a_holiday[2024-07-01]",
                "result": "passed",
                "test_implementation": "def test_not_a_holiday(date_str):\n    assert not is_holiday(date_str), f\"{date_str}  .\""
            }
        },
        "SRS_document": "**Software Requirements Specification: holidayskr**\n\n**Table of Contents**\n1.  Introduction\n    1.1 Purpose\n    1.2 Scope\n    1.3 Definitions, Acronyms, and Abbreviations\n    1.4 Overview\n2.  Overall Description\n    2.1 Product Perspective\n    2.2 Product Functions\n    2.3 User Characteristics\n    2.4 Constraints\n    2.5 Assumptions and Dependencies\n3.  Specific Requirements\n    3.1 Functional Requirements\n    3.2 External Interface Requirements\n        3.2.1 Software Interfaces (API)\n        3.2.2 Data Format Requirements (External JSON)\n    3.3 Non-Functional Requirements\n\n---\n\n**1. Introduction**\n\n**1.1 Purpose**\nThis Software Requirements Specification (SRS) document defines the functional and external interface requirements for the `holidayskr` Python package. The primary purpose of this SRS is to provide a clear, unambiguous, and comprehensive specification for software developers who will implement the `holidayskr` package. Their implementation will be assessed based on its adherence to these requirements, verified by a comprehensive set of test cases (public and private). This document focuses on *what* the system must do, abstracting away internal implementation details to allow for independent design choices.\n\n**1.2 Scope**\nThe `holidayskr` package is designed to determine and list public holidays in South Korea. The scope includes:\n*   Identifying whether a specific date is a public holiday.\n*   Identifying whether the current date (in KST) is a public holiday.\n*   Providing a list of all public holidays for a given year.\n*   Support for various types of holidays: fixed solar holidays, fixed lunar holidays (converted to solar), and year-specific holidays (e.g., election days, substitute holidays).\n*   Processing holiday data from a specified external JSON source.\n\nThe system is intended to be used as a Python library by other software applications. This SRS covers all externally observable behaviors and data processing rules necessary to achieve these functionalities.\n\n**1.3 Definitions, Acronyms, and Abbreviations**\n*   **SRS:** Software Requirements Specification\n*   **API:** Application Programming Interface\n*   **JSON:** JavaScript Object Notation\n*   **KST:** Korea Standard Time (UTC+9)\n*   **URL:** Uniform Resource Locator\n*   **Holiday Data Source:** An external JSON file containing definitions of holidays.\n*   **Solar Holiday:** A holiday that occurs on the same Gregorian calendar date each year.\n*   **Lunar Holiday:** A holiday based on the lunisolar calendar, whose Gregorian calendar date varies each year.\n*   **Substitute Holiday:** A public holiday granted when certain other public holidays fall on a weekend.\n*   **Year-Specific Holiday:** A holiday that is specific to a particular year, such as an election day or a specifically designated substitute holiday.\n\n**1.4 Overview**\nThis document is organized into three main sections:\n*   **Section 1 (Introduction):** Provides the purpose, scope, definitions, and overview of the SRS.\n*   **Section 2 (Overall Description):** Describes the product perspective, summarizes its functions, identifies user characteristics, and lists constraints, assumptions, and dependencies.\n*   **Section 3 (Specific Requirements):** Details the functional requirements, external interface requirements (including API and data formats), and non-functional requirements.\n\n---\n\n**2. Overall Description**\n\n**2.1 Product Perspective**\nThe `holidayskr` system is a self-contained Python library. It depends on an external data source (a JSON file accessible via a URL) for holiday definitions and requires a library capable of performing lunar to solar calendar conversions for Korean dates. It provides an API for other Python applications to query holiday information.\n\n**2.2 Product Functions**\nThe `holidayskr` package provides the following key functionalities:\n1.  **Holiday Check for Specific Date:** Determines if a user-provided date is a public holiday in South Korea.\n2.  **Holiday Check for Current Date:** Determines if the current date (KST) is a public holiday.\n3.  **Annual Holiday Listing:** Retrieves all public holidays for a user-specified year, including their dates and names.\n4.  **Holiday Data Processing:** Fetches and interprets holiday data from a structured external JSON source. This includes solar holidays, lunar holidays (requiring conversion to solar dates), and year-specific holidays.\n5.  **Special Lunar Holiday Handling:** Includes the day before and the day after Seollal (Lunar New Year) and Chuseok (Korean Thanksgiving) as public holidays.\n\n**2.3 User Characteristics**\nThe primary users of the `holidayskr` package are Python developers who need to incorporate South Korean holiday logic into their applications (e.g., scheduling systems, date utilities, business applications). Users are expected to have a working knowledge of Python and how to integrate third-party libraries.\n\n**2.4 Constraints**\n*   **C-1:** The system must be implemented in Python.\n*   **C-2:** The system must be compatible with Python versions 3.6 and higher. (Source: `setup.py::python_requires`)\n*   **C-3:** The system must fetch holiday data from the URL: `https://raw.githubusercontent.com/6mini/holidayskr/main/holidayskr.json`.\n*   **C-4:** The system relies on an external mechanism for converting Korean lunar calendar dates to solar (Gregorian) calendar dates. The accuracy of this conversion is crucial for lunar holiday calculations.\n\n**2.5 Assumptions and Dependencies**\n*   **A-1:** The external holiday data JSON file (specified in C-3) is available and accessible via HTTP GET request.\n*   **A-2:** The structure and content of the external holiday data JSON file conform to the format specified in Section 3.2.2.\n*   **A-3:** A reliable method/library for Korean lunar to solar date conversion is available and correctly implemented.\n\n---\n\n**3. Specific Requirements**\n\n**3.1 Functional Requirements**\n\n**FR-SYS-001:** The system shall provide a function to determine if a given date is a public holiday in South Korea.\n*   Input: A date string.\n*   Output: Boolean (True if the date is a holiday, False otherwise).\n\n**FR-SYS-002:** The system shall provide a function to determine if the current date is a public holiday in South Korea.\n*   The \"current date\" shall be interpreted in Korea Standard Time (KST, UTC+9).\n*   Output: Boolean (True if the current date is a holiday, False otherwise).\n\n**FR-SYS-003:** The system shall provide a function to retrieve all public holidays for a given calendar year.\n*   Input: A year string.\n*   Output: A list of holiday entries. Each entry shall represent a single holiday and include its solar date and descriptive name.\n\n**FR-DATA-001:** The system shall fetch holiday data from an external JSON data source located at a predefined URL.\n*   The predefined URL is `https://raw.githubusercontent.com/6mini/holidayskr/main/holidayskr.json`.\n\n**FR-DATA-002:** The system shall parse and utilize holiday information from the fetched JSON data, which includes solar holidays, lunar holidays, and year-specific holidays.\n*   The structure of the JSON data is defined in Section 3.2.2.\n\n**FR-CONV-001:** The system shall convert lunar holiday dates (month and day) specified in the external data source into their corresponding solar (Gregorian) calendar dates for the relevant year.\n\n**FR-HOL-SOLAR-001:** The system shall identify fixed solar holidays based on the month and day provided in the 'solar_holidays' section of the external data source.\n*   Example: New Year's Day (Jan 1st), Christmas Day (Dec 25th).\n\n**FR-HOL-LUNAR-001:** The system shall identify fixed lunar holidays (e.g., Seollal, Chuseok, Buddha's Birthday) by converting their specified lunar month and day to a solar date for the given year, based on the 'lunar_holidays' section of the external data source.\n\n**FR-HOL-LUNAR-EXT-001:** For holidays designated as \"\" (Seollal) and \"\" (Chuseok) in the 'lunar_holidays' data, the system shall also recognize:\n    1. The day immediately preceding the main lunar holiday date as a public holiday, named \"[Original Holiday Name] \".\n    2. The day immediately following the main lunar holiday date as a public holiday, named \"[Original Holiday Name] \".\n\n**FR-HOL-SPECIFIC-001:** The system shall identify year-specific holidays, such as election days and pre-defined substitute holidays, based on the 'year_specific_holidays' section of the external data source for the given year.\n\n**FR-OUTPUT-001:** The list of all holidays retrieved for a given year shall be sorted in chronological order by date.\n\n**FR-VALID-001:** The system shall expect date string inputs for holiday checks in the 'YYYY-MM-DD' format.\n*   If an invalid date format or an invalid date (e.g., \"2024-02-30\") is provided, the system shall raise a `ValueError`.\n\n**FR-VALID-002:** The system shall expect year string inputs for retrieving annual holidays in the 'YYYY' format.\n*   If an invalid year format (e.g., \"20XX\") is provided, the system shall raise a `ValueError`.\n\n**FR-LOGIC-001:** The system shall correctly identify dates that are not defined as public holidays (solar, lunar, or year-specific) as non-holidays.\n\n**3.2 External Interface Requirements**\n\n**3.2.1 Software Interfaces (API)**\nThe `holidayskr` package shall expose the following Python functions as its public API:\n\n**API-FUNC-001: `is_holiday(date_str: str) -> bool`**\n*   Description: Checks if the given date string represents a public holiday.\n*   Parameters:\n    *   `date_str`: A string representing the date to check, in 'YYYY-MM-DD' format.\n*   Returns: `True` if the date is a public holiday, `False` otherwise.\n*   Exceptions: Raises `ValueError` if `date_str` is not in the correct format or represents an invalid date.\n\n**API-FUNC-002: `today_is_holiday() -> bool`**\n*   Description: Checks if the current date (KST, UTC+9) is a public holiday.\n*   Parameters: None.\n*   Returns: `True` if the current date is a public holiday, `False` otherwise.\n\n**API-FUNC-003: `year_holidays(year_str: str) -> list[tuple[datetime.date, str]]`**\n*   Description: Retrieves all public holidays for the specified year.\n*   Parameters:\n    *   `year_str`: A string representing the year (e.g., \"2024\"), in 'YYYY' format.\n*   Returns: A list of tuples. Each tuple contains:\n    *   Element 1: A `datetime.date` object representing the solar date of the holiday.\n    *   Element 2: A string representing the name of the holiday.\n    The list is sorted chronologically by date.\n*   Exceptions: Raises `ValueError` if `year_str` is not in the correct format.\n\n**3.2.2 Data Format Requirements (External JSON)**\n\n**EIR-DATA-001:** The system shall consume holiday data from an external JSON file. The JSON file must adhere to the following structure:\n*   The root of the JSON must be an object.\n*   This root object must contain the following keys:\n    1.  `\"solar_holidays\"`:\n        *   Type: Array of objects.\n        *   Each object in the array represents a fixed solar holiday and must contain:\n            *   `\"date\"`: String, representing the month and day in \"MM-DD\" format (e.g., \"01-01\" for January 1st).\n            *   `\"name\"`: String, the official name of the holiday (e.g., \"\").\n    2.  `\"lunar_holidays\"`:\n        *   Type: Array of objects.\n        *   Each object in the array represents a fixed lunar holiday and must contain:\n            *   `\"date\"`: String, representing the lunar month and day in \"MM-DD\" format (e.g., \"01-01\" for Lunar January 1st).\n            *   `\"name\"`: String, the official name of the holiday (e.g., \"\").\n    3.  `\"year_specific_holidays\"`:\n        *   Type: Object.\n        *   Each key in this object is a string representing a year (e.g., \"2024\").\n        *   The value associated with each year key is an array of objects. Each object in this array represents a holiday specific to that year and must contain:\n            *   `\"date\"`: String, representing the month and day in \"MM-DD\" format (e.g., \"04-10\" for April 10th).\n            *   `\"name\"`: String, the official name of the year-specific holiday (e.g., \"22  \").\n\n**3.3 Non-Functional Requirements**\nBased on the provided test cases, no specific non-functional requirements (such as performance, security, or specific usability metrics) are explicitly tested and therefore are not specified in this document. The constraint C-2 (Python version compatibility) is a compatibility requirement handled under Constraints.\n\n---\n**End of Document**",
        "structured_requirements": [
            {
                "requirement_id": "C-1",
                "requirement_description": "The system must be implemented in Python.",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "C-2",
                "requirement_description": "The system must be compatible with Python versions 3.6 and higher. (Source: `setup.py::python_requires`)",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "C-3",
                "requirement_description": "The system must fetch holiday data from the URL: `https://raw.githubusercontent.com/6mini/holidayskr/main/holidayskr.json`.",
                "test_traceability": [
                    {
                        "id": "tests/test_core.py::test_download_holiday_data",
                        "description": "implicitly tests ability to fetch from this URL"
                    }
                ],
                "code_traceability": []
            },
            {
                "requirement_id": "C-4",
                "requirement_description": "The system relies on an external mechanism for converting Korean lunar calendar dates to solar (Gregorian) calendar dates. The accuracy of this conversion is crucial for lunar holiday calculations.",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "FR-SYS-001",
                "requirement_description": "The system shall provide a function to determine if a given date is a public holiday in South Korea.\n*   Input: A date string.\n*   Output: Boolean (True if the date is a holiday, False otherwise).",
                "test_traceability": [
                    {
                        "id": "tests/test_core.py::test_is_holiday",
                        "description": ""
                    },
                    {
                        "id": "tests/test_core.py::test_not_a_holiday",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "holidayskr/core.py::is_holiday",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SYS-002",
                "requirement_description": "The system shall provide a function to determine if the current date is a public holiday in South Korea.\n*   The \"current date\" shall be interpreted in Korea Standard Time (KST, UTC+9).\n*   Output: Boolean (True if the current date is a holiday, False otherwise).",
                "test_traceability": [
                    {
                        "id": "tests/test_core.py::test_today_is_holiday",
                        "description": "verifies return type"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "holidayskr/core.py::today_is_holiday",
                        "description": "contains KST logic"
                    }
                ]
            },
            {
                "requirement_id": "FR-SYS-003",
                "requirement_description": "The system shall provide a function to retrieve all public holidays for a given calendar year.\n*   Input: A year string.\n*   Output: A list of holiday entries. Each entry shall represent a single holiday and include its solar date and descriptive name.",
                "test_traceability": [
                    {
                        "id": "tests/test_core.py::test_year_holidays",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "holidayskr/core.py::year_holidays",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DATA-001",
                "requirement_description": "The system shall fetch holiday data from an external JSON data source located at a predefined URL.\n*   The predefined URL is `https://raw.githubusercontent.com/6mini/holidayskr/main/holidayskr.json`.",
                "test_traceability": [
                    {
                        "id": "tests/test_core.py::test_download_holiday_data",
                        "description": "verifies data can be fetched and has expected top-level keys"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "holidayskr/core.py::download_holiday_data",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DATA-002",
                "requirement_description": "The system shall parse and utilize holiday information from the fetched JSON data, which includes solar holidays, lunar holidays, and year-specific holidays.\n*   The structure of the JSON data is defined in Section 3.2.2.",
                "test_traceability": [
                    {
                        "id": "tests/test_core.py::test_download_holiday_data",
                        "description": "verifies presence of `solar_holidays`, `lunar_holidays`, `year_specific_holidays` keys"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "holidayskr/core.py::get_holidays",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CONV-001",
                "requirement_description": "The system shall convert lunar holiday dates (month and day) specified in the external data source into their corresponding solar (Gregorian) calendar dates for the relevant year.",
                "test_traceability": [
                    {
                        "id": "tests/test_core.py::test_convert_lunar_to_solar",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "holidayskr/core.py::convert_lunar_to_solar",
                        "description": ""
                    },
                    {
                        "id": "holidayskr/core.py::get_holidays",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-HOL-SOLAR-001",
                "requirement_description": "The system shall identify fixed solar holidays based on the month and day provided in the 'solar_holidays' section of the external data source.\n*   Example: New Year's Day (Jan 1st), Christmas Day (Dec 25th).",
                "test_traceability": [
                    {
                        "id": "tests/test_core.py::test_is_holiday",
                        "description": "e.g., \"2024-01-01\", \"2024-12-25\""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "holidayskr/core.py::get_holidays",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-HOL-LUNAR-001",
                "requirement_description": "The system shall identify fixed lunar holidays (e.g., Seollal, Chuseok, Buddha's Birthday) by converting their specified lunar month and day to a solar date for the given year, based on the 'lunar_holidays' section of the external data source.",
                "test_traceability": [
                    {
                        "id": "tests/test_core.py::test_is_holiday",
                        "description": "e.g., \"2024-02-10\" for Seollal"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "holidayskr/core.py::get_holidays",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-HOL-LUNAR-EXT-001",
                "requirement_description": "For holidays designated as \"\" (Seollal) and \"\" (Chuseok) in the 'lunar_holidays' data, the system shall also recognize:\n    1. The day immediately preceding the main lunar holiday date as a public holiday, named \"[Original Holiday Name] \".\n    2. The day immediately following the main lunar holiday date as a public holiday, named \"[Original Holiday Name] \".",
                "test_traceability": [
                    {
                        "id": "tests/test_core.py::test_lunar_holidays_with_surrounding_days",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "holidayskr/core.py::get_holidays",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-HOL-SPECIFIC-001",
                "requirement_description": "The system shall identify year-specific holidays, such as election days and pre-defined substitute holidays, based on the 'year_specific_holidays' section of the external data source for the given year.",
                "test_traceability": [
                    {
                        "id": "tests/test_core.py::test_year_specific_holidays",
                        "description": ""
                    },
                    {
                        "id": "tests/test_core.py::test_is_holiday",
                        "description": "e.g., \"2024-04-10\" election day"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "holidayskr/core.py::get_holidays",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-OUTPUT-001",
                "requirement_description": "The list of all holidays retrieved for a given year shall be sorted in chronological order by date.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis and README example. No direct corresponding original test case explicitly validating the sort order of the full list.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "holidayskr/core.py::get_holidays",
                        "description": "uses `sorted()`"
                    }
                ]
            },
            {
                "requirement_id": "FR-VALID-001",
                "requirement_description": "The system shall expect date string inputs for holiday checks in the 'YYYY-MM-DD' format.\n*   If an invalid date format or an invalid date (e.g., \"2024-02-30\") is provided, the system shall raise a `ValueError`.",
                "test_traceability": [
                    {
                        "id": "tests/test_core.py::test_invalid_date_format",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "holidayskr/core.py::is_holiday",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-VALID-002",
                "requirement_description": "The system shall expect year string inputs for retrieving annual holidays in the 'YYYY' format.\n*   If an invalid year format (e.g., \"20XX\") is provided, the system shall raise a `ValueError`.",
                "test_traceability": [
                    {
                        "id": "tests/test_core.py::test_invalid_year_format",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "holidayskr/core.py::year_holidays",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-LOGIC-001",
                "requirement_description": "The system shall correctly identify dates that are not defined as public holidays (solar, lunar, or year-specific) as non-holidays.",
                "test_traceability": [
                    {
                        "id": "tests/test_core.py::test_not_a_holiday",
                        "description": ""
                    },
                    {
                        "id": "tests/test_core.py::test_is_holiday",
                        "description": "e.g., test case \"2024-04-22\", False"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "holidayskr/core.py::is_holiday",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "API-FUNC-001",
                "requirement_description": "`is_holiday(date_str: str) -> bool`\n*   Description: Checks if the given date string represents a public holiday.\n*   Parameters:\n    *   `date_str`: A string representing the date to check, in 'YYYY-MM-DD' format.\n*   Returns: `True` if the date is a public holiday, `False` otherwise.\n*   Exceptions: Raises `ValueError` if `date_str` is not in the correct format or represents an invalid date.",
                "test_traceability": [
                    {
                        "id": "tests/test_core.py::test_is_holiday",
                        "description": ""
                    },
                    {
                        "id": "tests/test_core.py::test_invalid_date_format",
                        "description": ""
                    },
                    {
                        "id": "tests/test_core.py::test_not_a_holiday",
                        "description": ""
                    }
                ],
                "code_traceability": []
            },
            {
                "requirement_id": "API-FUNC-002",
                "requirement_description": "`today_is_holiday() -> bool`\n*   Description: Checks if the current date (KST, UTC+9) is a public holiday.\n*   Parameters: None.\n*   Returns: `True` if the current date is a public holiday, `False` otherwise.",
                "test_traceability": [
                    {
                        "id": "tests/test_core.py::test_today_is_holiday",
                        "description": ""
                    }
                ],
                "code_traceability": []
            },
            {
                "requirement_id": "API-FUNC-003",
                "requirement_description": "`year_holidays(year_str: str) -> list[tuple[datetime.date, str]]`\n*   Description: Retrieves all public holidays for the specified year.\n*   Parameters:\n    *   `year_str`: A string representing the year (e.g., \"2024\"), in 'YYYY' format.\n*   Returns: A list of tuples. Each tuple contains:\n    *   Element 1: A `datetime.date` object representing the solar date of the holiday.\n    *   Element 2: A string representing the name of the holiday.\n    The list is sorted chronologically by date.\n*   Exceptions: Raises `ValueError` if `year_str` is not in the correct format.",
                "test_traceability": [
                    {
                        "id": "tests/test_core.py::test_year_holidays",
                        "description": ""
                    },
                    {
                        "id": "tests/test_core.py::test_invalid_year_format",
                        "description": ""
                    },
                    {
                        "id": "tests/test_core.py::test_year_specific_holidays",
                        "description": ""
                    },
                    {
                        "id": "tests/test_core.py::test_lunar_holidays_with_surrounding_days",
                        "description": ""
                    }
                ],
                "code_traceability": []
            },
            {
                "requirement_id": "EIR-DATA-001",
                "requirement_description": "The system shall consume holiday data from an external JSON file. The JSON file must adhere to the following structure:\n*   The root of the JSON must be an object.\n*   This root object must contain the following keys:\n    1.  `\"solar_holidays\"`:\n        *   Type: Array of objects.\n        *   Each object in the array represents a fixed solar holiday and must contain:\n            *   `\"date\"`: String, representing the month and day in \"MM-DD\" format (e.g., \"01-01\" for January 1st).\n            *   `\"name\"`: String, the official name of the holiday (e.g., \"\").\n    2.  `\"lunar_holidays\"`:\n        *   Type: Array of objects.\n        *   Each object in the array represents a fixed lunar holiday and must contain:\n            *   `\"date\"`: String, representing the lunar month and day in \"MM-DD\" format (e.g., \"01-01\" for Lunar January 1st).\n            *   `\"name\"`: String, the official name of the holiday (e.g., \"\").\n    3.  `\"year_specific_holidays\"`:\n        *   Type: Object.\n        *   Each key in this object is a string representing a year (e.g., \"2024\").\n        *   The value associated with each year key is an array of objects. Each object in this array represents a holiday specific to that year and must contain:\n            *   `\"date\"`: String, representing the month and day in \"MM-DD\" format (e.g., \"04-10\" for April 10th).\n            *   `\"name\"`: String, the official name of the year-specific holiday (e.g., \"22  \").",
                "test_traceability": [
                    {
                        "id": "tests/test_core.py::test_download_holiday_data",
                        "description": "verifies the presence of these top-level keys: `solar_holidays`, `lunar_holidays`, `year_specific_holidays`"
                    }
                ],
                "code_traceability": []
            }
        ],
        "commit_sha": "91eaed1fc7be761c084ef7392ae978480eac6068",
        "full_code_skeleton": "--- File: holidayskr/core.py ---\n```python\ndef download_holiday_data(url, retries=50):\n    \"\"\"Downloads holiday data from GitHub. Retries on failure.\"\"\"\n    pass\n\ndef convert_lunar_to_solar(year, month, day, adjust=0):\n    \"\"\"Converts a lunar date to a solar date.\"\"\"\n    pass\n\ndef get_holidays(year):\n    \"\"\"Retrieves all holidays for the specified year (fixed solar, fixed lunar, year-specific).\"\"\"\n    pass\n\ndef is_holiday(date_str):\n    \"\"\"Checks if the specified date is a holiday.\"\"\"\n    pass\n\ndef today_is_holiday():\n    \"\"\"Checks if the current date is a holiday.\"\"\"\n    pass\n\ndef year_holidays(year_str):\n    \"\"\"Returns all holidays for the specified year.\"\"\"\n    pass\n```\n--- File: holidayskr/__init__.py ---\n```python\n```",
        "full_code_skeleton_structured": [
            {
                "file_path": "holidayskr/core.py",
                "code": "def download_holiday_data(url, retries=50):\n    \"\"\"Downloads holiday data from GitHub. Retries on failure.\"\"\"\n    pass\n\ndef convert_lunar_to_solar(year, month, day, adjust=0):\n    \"\"\"Converts a lunar date to a solar date.\"\"\"\n    pass\n\ndef get_holidays(year):\n    \"\"\"Retrieves all holidays for the specified year (fixed solar, fixed lunar, year-specific).\"\"\"\n    pass\n\ndef is_holiday(date_str):\n    \"\"\"Checks if the specified date is a holiday.\"\"\"\n    pass\n\ndef today_is_holiday():\n    \"\"\"Checks if the current date is a holiday.\"\"\"\n    pass\n\ndef year_holidays(year_str):\n    \"\"\"Returns all holidays for the specified year.\"\"\"\n    pass\n"
            },
            {
                "file_path": "holidayskr/__init__.py",
                "code": ""
            }
        ],
        "minimal_code_skeleton": "--- File: holidayskr/core.py ---\n```python\ndef download_holiday_data(url, retries=50):\n    \"\"\"Downloads holiday data from GitHub. Retries on failure.\"\"\"\n    pass\n\ndef convert_lunar_to_solar(year, month, day, adjust=0):\n    \"\"\"Converts a lunar date to a solar date.\"\"\"\n    pass\n\ndef is_holiday(date_str):\n    \"\"\"Checks if the specified date is a holiday.\"\"\"\n    pass\n\ndef today_is_holiday():\n    \"\"\"Checks if the current date is a holiday.\"\"\"\n    pass\n\ndef year_holidays(year_str):\n    \"\"\"Returns all holidays for the specified year.\"\"\"\n    pass\n```",
        "minimal_code_skeleton_structured": [
            {
                "file_path": "holidayskr/core.py",
                "code": "def download_holiday_data(url, retries=50):\n    \"\"\"Downloads holiday data from GitHub. Retries on failure.\"\"\"\n    pass\n\ndef convert_lunar_to_solar(year, month, day, adjust=0):\n    \"\"\"Converts a lunar date to a solar date.\"\"\"\n    pass\n\ndef is_holiday(date_str):\n    \"\"\"Checks if the specified date is a holiday.\"\"\"\n    pass\n\ndef today_is_holiday():\n    \"\"\"Checks if the current date is a holiday.\"\"\"\n    pass\n\ndef year_holidays(year_str):\n    \"\"\"Returns all holidays for the specified year.\"\"\"\n    pass\n"
            }
        ],
        "minimal_test_cases": [
            {
                "test_id": "tests/test_core.py::test_download_holiday_data",
                "covers": [
                    "holidayskr.core.download_holiday_data - happy path, data download"
                ]
            },
            {
                "test_id": "tests/test_core.py::test_convert_lunar_to_solar[2024-1-1-2024-02-10]",
                "covers": [
                    "holidayskr.core.convert_lunar_to_solar - happy path, lunar to solar conversion"
                ]
            },
            {
                "test_id": "tests/test_core.py::test_is_holiday[2024-01-01-True]",
                "covers": [
                    "holidayskr.is_holiday - happy path, checking a known holiday"
                ]
            },
            {
                "test_id": "tests/test_core.py::test_year_holidays",
                "covers": [
                    "holidayskr.year_holidays - happy path, retrieving annual holidays"
                ]
            },
            {
                "test_id": "tests/test_core.py::test_today_is_holiday",
                "covers": [
                    "holidayskr.today_is_holiday - happy path, checking current date"
                ]
            }
        ]
    },
    {
        "idx": 82016,
        "repo_name": "DanielAvdar_pandas-pyarrow",
        "url": "https://github.com/DanielAvdar/pandas-pyarrow",
        "description": "Seamlessly switch Pandas DataFrame backend to PyArrow.",
        "stars": 8,
        "forks": 2,
        "language": "python",
        "size": 1104,
        "created_at": "2024-03-04T10:54:36+00:00",
        "updated_at": "2025-04-25T16:30:34+00:00",
        "pypi_info": {
            "name": "schemarrow",
            "version": "0.1.1a0",
            "url": "https://files.pythonhosted.org/packages/a2/98/7394e35fe176ac96affb4da49cc52a0f2b9c6a8ed14bd947a848c3959902/schemarrow-0.1.1a0.tar.gz"
        },
        "judge_info": {
            "language": "python",
            "is_good_project": false,
            "reason": "",
            "python_file_num": 31,
            "comment_ratio": 0.06521739130434782,
            "pyfile_content_length": 43652,
            "pyfile_code_lines": 1058,
            "test_file_exist": true,
            "test_file_content_length": 25202,
            "pytest_framework": true,
            "test_case_num": 26,
            "metadata_path": [
                "pyproject.toml"
            ],
            "readme_content_length": 6934,
            "llm_reason": "Positive Aspects:\n*   **Clear Functionality:** The project has a well-defined goal: converting pandas DataFrame dtypes to pyarrow dtypes, including handling various standard, nullable, and potentially db-specific types, with customization options. This is clearly explained in the README.\n*   **Self-Contained Core:** The core functionality of mapping and converting dtypes between pandas and pyarrow for locally created DataFrames does not require internet access, external APIs, or complex external services. Dependencies (pandas, pyarrow) are standard PyPI packages.\n*   **Highly Testable:** The project includes a comprehensive test suite (unit, integration-like using local data, property-based) using pytest, parametrization, and hypothesis. This makes the AI's output highly verifiable, potentially by reusing or adapting these tests.\n*   **No GUI:** The project is a library, suitable for programmatic use and testing.\n*   **Manageable Scope:** The codebase is focused on the conversion task and appears relatively small and modular.\n*   **Appropriate Complexity:** Replicating the dtype mapping logic, handling different type representations (e.g., `int64` vs `Int64`, timezones), and implementing the converter class structure presents a meaningful challenge (Medium difficulty) without being excessively complex or requiring novel algorithms.\n\nNegative Aspects:\n*   **External Dependency Example:** The README includes an example demonstrating integration with `pandas-gbq` to read from BigQuery. This part requires internet access and depends on an external service (Google Cloud). For the project to be suitable as a *direct* benchmark, the specification given to the AI **must explicitly exclude** this BigQuery integration functionality and focus solely on the core, local DataFrame dtype conversion logic and tests.\n*   **Domain Knowledge:** Requires specific knowledge of pandas and pyarrow dtype systems and their nuances, which might be slightly specialized but is standard within the Python data ecosystem.\n\nOverall Assessment:\nThe project is a good candidate (75/100) for a 'build from scratch' benchmark *if* the scope is carefully defined to exclude the external BigQuery dependency shown in the README example. The core task is well-defined, self-contained, highly testable, and represents a realistic, medium-complexity library development task.",
            "llm_project_type": "Data type conversion utility library for pandas/pyarrow",
            "llm_rating": 75,
            "llm_difficulty": "Medium"
        },
        "tests": {
            "repo_name": "DanielAvdar_pandas-pyarrow",
            "finish_test": true,
            "test_case_result": {
                "tests/docs/test_docs.py::test_doc_examples[/testbed/docs/source/usage.rst-110-example0]": "passed",
                "tests/docs/test_docs.py::test_doc_examples[/testbed/docs/source/usage.rst-628-example1]": "passed",
                "tests/intg/test_db_date_dtypes.py::test_db_date_dtypes[dbdate case]": "passed",
                "tests/intg/test_db_date_dtypes.py::test_db_date_dtypes[dbtime case]": "passed",
                "tests/intg/test_db_general_dtypes.py::test_db_general_dtypes[DB Int64 case]": "passed",
                "tests/intg/test_db_general_dtypes.py::test_db_general_dtypes[DB Int32 case]": "passed",
                "tests/intg/test_db_general_dtypes.py::test_db_general_dtypes[DB Float64 case]": "passed",
                "tests/intg/test_db_general_dtypes.py::test_db_general_dtypes[DB Float32 case]": "passed",
                "tests/unit/date_time/test_dt_types.py::test_dt_types[Test Case: Datetime]": "passed",
                "tests/unit/date_time/test_dt_types.py::test_dt_types[Test Case: Datetime Milliseconds]": "passed",
                "tests/unit/date_time/test_dt_types.py::test_dt_types[Test Case: Datetime seconds]": "passed",
                "tests/unit/date_time/test_dt_tz_types.py::test_dt_tz_types[Test Case: Datetime with Timezone US/Eastern]": "passed",
                "tests/unit/date_time/test_dt_tz_types.py::test_dt_tz_types[Test Case: Datetime with Timezone Africa/Abidjan]": "passed",
                "tests/unit/date_time/test_dt_tz_types.py::test_dt_tz_types[Test Case: Datetime with UTC Timezone]": "passed",
                "tests/unit/date_time/test_dt_tz_types.py::test_dt_tz_types[Test Case: Datetime with UTC Timezone Seconds]": "passed",
                "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types[Test Case: Timedelta]": "passed",
                "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types[Test Case: Timedelta in Hours]": "passed",
                "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types[Test Case: Timedelta in Minutes]": "passed",
                "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types[Test Case: Timedelta Minutes in Milliseconds]": "passed",
                "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types[Test Case: Timedelta Minutes with Timezone]": "passed",
                "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types[Test Case: Timedelta Minutes in Microseconds]": "passed",
                "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types[Test Case: Timedelta Minutes in Seconds]": "passed",
                "tests/unit/property_based/test_dt.py::test_datetime_pb_ns": "passed",
                "tests/unit/property_based/test_general.py::test_uncommon_dtypes_hp": "passed",
                "tests/unit/property_based/test_general.py::test_common_dtypes_hp": "passed",
                "tests/unit/property_based/test_general.py::test_convert_to_numpy": "passed",
                "tests/unit/property_based/test_numeric.py::test_float_numpy_api_hp": "passed",
                "tests/unit/property_based/test_numeric.py::test_float_array_api_hp": "passed",
                "tests/unit/property_based/test_numeric.py::test_int_numpy_api_hp": "passed",
                "tests/unit/property_based/test_numeric.py::test_int_array_api_hp": "passed",
                "tests/unit/test_add_dtypes_mapper_types.py::test_add_dtypes_types[test simple type mapping override with additional_mapper_dicts ns]": "passed",
                "tests/unit/test_add_dtypes_mapper_types.py::test_add_dtypes_types[test simple type mapping override with additional_mapper_dicts ms0]": "passed",
                "tests/unit/test_add_dtypes_mapper_types.py::test_add_dtypes_types[test simple type mapping override with additional_mapper_dicts ms1]": "passed",
                "tests/unit/test_add_dtypes_mapper_types.py::test_add_dtypes_types[test simple type mapping override with additional_mapper_dicts ms2]": "passed",
                "tests/unit/test_dtype_exists.py::test_str_dtypes[str_types0]": "passed",
                "tests/unit/test_dtype_exists.py::test_str_dtypes[str_types1]": "passed",
                "tests/unit/test_dtype_exists.py::test_str_dtypes[str_types2]": "passed",
                "tests/unit/test_dtype_exists.py::test_str_dtypes[str_types3]": "passed",
                "tests/unit/test_dtype_exists.py::test_str_dtypes_numpy[str_types0]": "passed",
                "tests/unit/test_dtype_exists.py::test_str_dtypes_numpy[str_types1]": "passed",
                "tests/unit/test_dtype_exists.py::test_str_dtypes_pyarrow": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting int8 to int8[pyarrow]]": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting int16 to int16[pyarrow]]": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting int32 to int32[pyarrow]]": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting int64 to int64[pyarrow]]": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting Int8 to int8[pyarrow]]": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting Int16 to int16[pyarrow]]": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting Int32 to int32[pyarrow]]": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting Int64 to int64[pyarrow]]": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting uint8 to uint8[pyarrow]]": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting uint16 to uint16[pyarrow]]": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting uint32 to uint32[pyarrow]]": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting uint64 to uint64[pyarrow]]": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting UInt8 to uint8[pyarrow]]": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting UInt16 to uint16[pyarrow]]": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting UInt32 to uint32[pyarrow]]": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting UInt64 to uint64[pyarrow]]": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting float16 to float16[pyarrow]]": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting float32 to float32[pyarrow]]": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting float64 to float64[pyarrow]]": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting Float32 to float32[pyarrow]]": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting Float64 to float64[pyarrow]]": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting complex64 to string[pyarrow]]": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting float32[pyarrow] to float32[pyarrow]]": "passed",
                "tests/unit/test_numeric_types.py::test_numeric_types[test casting float64[pyarrow] to float64[pyarrow]]": "passed",
                "tests/unit/test_object_types.py::test_numeric_types[test casting object to string[pyarrow]]": "passed",
                "tests/unit/test_object_types.py::test_numeric_types[test casting O to string[pyarrow]]": "passed",
                "tests/unit/test_object_types.py::test_numeric_types[test casting <class 'str'> to string[pyarrow]0]": "passed",
                "tests/unit/test_object_types.py::test_numeric_types[test casting bytes to string[pyarrow]]": "passed",
                "tests/unit/test_object_types.py::test_numeric_types[test casting <class 'str'> to string[pyarrow]1]": "passed",
                "tests/unit/test_object_types.py::test_numeric_types[test casting bool to bool[pyarrow]0]": "passed",
                "tests/unit/test_object_types.py::test_numeric_types[test casting boolean to bool[pyarrow]0]": "passed",
                "tests/unit/test_object_types.py::test_numeric_types[test casting bool to bool[pyarrow]1]": "passed",
                "tests/unit/test_object_types.py::test_numeric_types[test casting bool[pyarrow] to bool[pyarrow]]": "passed",
                "tests/unit/test_object_types.py::test_numeric_types[test casting boolean to bool[pyarrow]1]": "passed",
                "tests/unit/test_object_types.py::test_numeric_types[test casting boolean to bool[pyarrow]2]": "passed",
                "tests/unit/test_object_types.py::test_numeric_types[test casting str to string[pyarrow]]": "passed",
                "tests/unit/test_object_types.py::test_numeric_types[test casting <U1 to string[pyarrow]]": "passed",
                "tests/unit/test_object_types.py::test_numeric_types[test casting string to string[pyarrow]]": "passed",
                "tests/unit/test_object_types.py::test_numeric_types[test casting category to string[pyarrow]]": "passed",
                "tests/unit/test_object_types.py::test_numeric_types[test casting string[python] to string[pyarrow]]": "passed",
                "tests/unit/test_object_types.py::test_numeric_types[test casting string[pyarrow] to string[pyarrow]]": "passed",
                "tests/unit/test_reverse_converter.py::test_convert_timestamp": "passed",
                "tests/unit/test_reverse_converter.py::test_convert_halffloat": "passed",
                "tests/unit/test_reverse_converter.py::test_convert_duration": "passed",
                "tests/unit/test_reverse_converter.py::test_convert_string": "passed",
                "tests/unit/test_reverse_mapper.py::test_reverse_to_all_pyarrow_types": "passed",
                "tests/unit/test_reverse_mapper.py::test_all_numpy_types": "passed"
            },
            "success_count": 88,
            "failed_count": 0,
            "error_count": 0,
            "skipped_count": 0,
            "unknown_count": 0,
            "total_count": 88,
            "success_rate": 1.0,
            "coverage_report": {
                "covered_lines": 101,
                "num_statements": 101,
                "percent_covered": 100.0,
                "percent_covered_display": "100",
                "missing_lines": 0,
                "excluded_lines": 0,
                "num_branches": 6,
                "num_partial_branches": 0,
                "covered_branches": 6,
                "missing_branches": 0
            },
            "coverage_result": {}
        },
        "codelines_count": 1058,
        "codefiles_count": 31,
        "code_length": 43652,
        "test_files_count": 15,
        "test_code_length": 25202,
        "class_diagram": "@startuml\nclass PandasArrowConverter {\n    __init__(custom_mapper, default_target_type): void\n    __call__(df): pd.DataFrame\n    _target_dtype_name(dtype_name): str\n    _map_dtype_names(dtype_names): List[str]\n}\nclass ReversePandasArrowConverter {\n    __init__(custom_mapper, default_target_type): void\n    __call__(df): pd.DataFrame\n    _target_dtype_name(dtype_name): str\n    _map_dtype_names(dtype_names): List[str]\n}\n@enduml",
        "structure": [
            {
                "file": "tests/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/docs/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/docs/test_docs.py",
                "functions": [
                    {
                        "name": "collect_examples",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_doc_examples",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "file_path",
                            "line",
                            "example"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/intg/test_db_general_dtypes.py",
                "functions": [
                    {
                        "name": "test_db_general_dtypes",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "df_data",
                            "expected_dtype"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/intg/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/intg/test_db_date_dtypes.py",
                "functions": [
                    {
                        "name": "test_db_date_dtypes",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "df_data",
                            "expected_dtype"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/unit/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/unit/test_dtype_exists.py",
                "functions": [
                    {
                        "name": "test_str_dtypes",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "str_types"
                        ]
                    },
                    {
                        "name": "test_str_dtypes_numpy",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "str_types"
                        ]
                    },
                    {
                        "name": "test_str_dtypes_pyarrow",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/unit/test_object_types.py",
                "functions": [
                    {
                        "name": "create_test_case",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "source_dtype",
                            "target_dtype",
                            "values"
                        ]
                    },
                    {
                        "name": "test_numeric_types",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "df_data",
                            "expected_dtype"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/unit/test_reverse_mapper.py",
                "functions": [
                    {
                        "name": "test_reverse_to_all_pyarrow_types",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_all_numpy_types",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/unit/test_add_dtypes_mapper_types.py",
                "functions": [
                    {
                        "name": "create_df",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "column_values",
                            "data_type"
                        ]
                    },
                    {
                        "name": "test_add_dtypes_types",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "df_data",
                            "expected_dtype",
                            "additional_mapper_dicts"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/unit/test_numeric_types.py",
                "functions": [
                    {
                        "name": "create_test_case",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "source_dtype",
                            "target_dtype",
                            "values"
                        ]
                    },
                    {
                        "name": "test_numeric_types",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "df_data",
                            "expected_dtype"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/unit/test_reverse_converter.py",
                "functions": [
                    {
                        "name": "test_convert_timestamp",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_convert_halffloat",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_convert_duration",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_convert_string",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/unit/property_based/test_numeric.py",
                "functions": [
                    {
                        "name": "test_float_numpy_api_hp",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "pair"
                        ]
                    },
                    {
                        "name": "test_float_array_api_hp",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "pair"
                        ]
                    },
                    {
                        "name": "test_int_numpy_api_hp",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "pair"
                        ]
                    },
                    {
                        "name": "test_int_array_api_hp",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "pair"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/unit/property_based/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/unit/property_based/test_general.py",
                "functions": [
                    {
                        "name": "test_uncommon_dtypes_hp",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "df"
                        ]
                    },
                    {
                        "name": "test_common_dtypes_hp",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "df"
                        ]
                    },
                    {
                        "name": "test_convert_to_numpy",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "df"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/unit/property_based/test_dt.py",
                "functions": [
                    {
                        "name": "test_datetime_pb_ns",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "pair"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/unit/property_based/pb_sts.py",
                "functions": [
                    {
                        "name": "create_dataframe",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "draw",
                            "gen_type"
                        ]
                    },
                    {
                        "name": "df_st",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "draw",
                            "dtypes"
                        ]
                    },
                    {
                        "name": "single_column_df_st",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "draw",
                            "pair_mapping",
                            "gen_type"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/unit/date_time/test_dt_tz_types.py",
                "functions": [
                    {
                        "name": "test_dt_tz_types",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "data",
                            "expected_dtype"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/unit/date_time/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/unit/date_time/test_dt_types.py",
                "functions": [
                    {
                        "name": "test_dt_types",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "df_data",
                            "expected_dtype"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/unit/date_time/test_timedelta_types.py",
                "functions": [
                    {
                        "name": "test_timedelta_types",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "df_data",
                            "expected_dtype"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "docs/source/conf.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "pandas_pyarrow/pda_converter.py",
                "functions": [],
                "classes": [
                    {
                        "name": "PandasArrowConverter",
                        "docstring": "PandasArrowConverter manages the conversion of Pandas DataFrame data types to Arrow data types.\n:param custom_mapper: dictionary with key as the source data type and value as the target data type.\nWill override default mapping\n:param default_target_type: Optional string specifying the default data type to use if no mapping is found for a\nspecific data type. Default is \"string[pyarrow]\".",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "custom_mapper",
                                    "default_target_type"
                                ]
                            },
                            {
                                "name": "__call__",
                                "docstring": "Apply a transformation to the dtypes of a Pandas DataFrame based on a mapping.\n\nThe function adjusts the data types of the columns in the provided DataFrame.\nIt uses the current dtypes of the DataFrame columns, processes them through\na mapping function to get the corresponding target dtypes, and applies the\nmapping to create a new DataFrame with updated dtypes.\n\n:param df: A Pandas DataFrame whose column dtypes will be transformed.\n:type df: pd.DataFrame\n:return: A new Pandas DataFrame with transformed column dtypes.\n:rtype: pd.DataFrame",
                                "comments": null,
                                "args": [
                                    "self",
                                    "df"
                                ]
                            },
                            {
                                "name": "_target_dtype_name",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "dtype_name"
                                ]
                            },
                            {
                                "name": "_map_dtype_names",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "dtype_names"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "pandas_pyarrow/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "pandas_pyarrow/reverse_converter.py",
                "functions": [],
                "classes": [
                    {
                        "name": "ReversePandasArrowConverter",
                        "docstring": "ReversePandasArrowConverter manages the conversion of pyarrow-backed Pandas DataFrame dtypes\nback to their Numpy/Pandas equivalents.\n\n:param custom_mapper: Dictionary with key as the string-representation of the\n    Arrow-backed dtype, and value as the desired target dtype (e.g. \"object\", \"int64\", etc.).\n    This overrides default mapping returned by reverse_create_mapper().\n:param default_target_type: Optional string specifying the default dtype to use\n    if no mapping is found for a specific dtype. Default is \"object\".",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "custom_mapper",
                                    "default_target_type"
                                ]
                            },
                            {
                                "name": "__call__",
                                "docstring": "Maps the data types of a given pandas DataFrame to the target data types\nspecified by the object's internal mapping logic. This method processes\nthe DataFrame by replacing its column data types according to the mapped\ntarget types and returns a new DataFrame with these updated data types.\nAny `NaN` values are handled accordingly during the process.\n\n:param df: A pandas DataFrame that is to be processed.\n:type df: pd.DataFrame\n:return: A new pandas DataFrame with updated column data types as per\n         the mapping.\n:rtype: pd.DataFrame",
                                "comments": null,
                                "args": [
                                    "self",
                                    "df"
                                ]
                            },
                            {
                                "name": "_target_dtype_name",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "dtype_name"
                                ]
                            },
                            {
                                "name": "_map_dtype_names",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "dtype_names"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "pandas_pyarrow/mappers/numeric_mapper.py",
                "functions": [
                    {
                        "name": "create_type_variations",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "source_types",
                            "filter_func",
                            "variations"
                        ]
                    },
                    {
                        "name": "numeric_mapper",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "source_types",
                            "variations"
                        ]
                    },
                    {
                        "name": "reverse_create_type_variations",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "source_types",
                            "filter_func",
                            "variations"
                        ]
                    },
                    {
                        "name": "reverse_numeric_mapper",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "source_types",
                            "variations"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "pandas_pyarrow/mappers/dtype_mapper.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "pandas_pyarrow/mappers/db_types.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "pandas_pyarrow/mappers/__init__.py",
                "functions": [
                    {
                        "name": "create_mapper",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "reverse_create_mapper",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "adapter"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "pandas_pyarrow/mappers/datetime_mapper.py",
                "functions": [
                    {
                        "name": "datetime_mapper",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "from_type",
                            "to_type"
                        ]
                    },
                    {
                        "name": "reverse_datetime_mapper",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "from_type",
                            "to_type",
                            "adapter"
                        ]
                    }
                ],
                "classes": []
            }
        ],
        "test_cases": {
            "tests/docs/test_docs.py::test_doc_examples[/testbed/docs/source/usage.rst-110-example0]": {
                "testid": "tests/docs/test_docs.py::test_doc_examples[/testbed/docs/source/usage.rst-110-example0]",
                "result": "passed",
                "test_implementation": "def test_doc_examples(file_path, line, example):\n    example.evaluate()"
            },
            "tests/docs/test_docs.py::test_doc_examples[/testbed/docs/source/usage.rst-628-example1]": {
                "testid": "tests/docs/test_docs.py::test_doc_examples[/testbed/docs/source/usage.rst-628-example1]",
                "result": "passed",
                "test_implementation": "def test_doc_examples(file_path, line, example):\n    example.evaluate()"
            },
            "tests/intg/test_db_date_dtypes.py::test_db_date_dtypes[dbdate case]": {
                "testid": "tests/intg/test_db_date_dtypes.py::test_db_date_dtypes[dbdate case]",
                "result": "passed",
                "test_implementation": "def test_db_date_dtypes(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype"
            },
            "tests/intg/test_db_date_dtypes.py::test_db_date_dtypes[dbtime case]": {
                "testid": "tests/intg/test_db_date_dtypes.py::test_db_date_dtypes[dbtime case]",
                "result": "passed",
                "test_implementation": "def test_db_date_dtypes(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype"
            },
            "tests/intg/test_db_general_dtypes.py::test_db_general_dtypes[DB Int64 case]": {
                "testid": "tests/intg/test_db_general_dtypes.py::test_db_general_dtypes[DB Int64 case]",
                "result": "passed",
                "test_implementation": "def test_db_general_dtypes(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype"
            },
            "tests/intg/test_db_general_dtypes.py::test_db_general_dtypes[DB Int32 case]": {
                "testid": "tests/intg/test_db_general_dtypes.py::test_db_general_dtypes[DB Int32 case]",
                "result": "passed",
                "test_implementation": "def test_db_general_dtypes(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype"
            },
            "tests/intg/test_db_general_dtypes.py::test_db_general_dtypes[DB Float64 case]": {
                "testid": "tests/intg/test_db_general_dtypes.py::test_db_general_dtypes[DB Float64 case]",
                "result": "passed",
                "test_implementation": "def test_db_general_dtypes(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype"
            },
            "tests/intg/test_db_general_dtypes.py::test_db_general_dtypes[DB Float32 case]": {
                "testid": "tests/intg/test_db_general_dtypes.py::test_db_general_dtypes[DB Float32 case]",
                "result": "passed",
                "test_implementation": "def test_db_general_dtypes(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype"
            },
            "tests/unit/date_time/test_dt_types.py::test_dt_types[Test Case: Datetime]": {
                "testid": "tests/unit/date_time/test_dt_types.py::test_dt_types[Test Case: Datetime]",
                "result": "passed",
                "test_implementation": "def test_dt_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/date_time/test_dt_types.py::test_dt_types[Test Case: Datetime Milliseconds]": {
                "testid": "tests/unit/date_time/test_dt_types.py::test_dt_types[Test Case: Datetime Milliseconds]",
                "result": "passed",
                "test_implementation": "def test_dt_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/date_time/test_dt_types.py::test_dt_types[Test Case: Datetime seconds]": {
                "testid": "tests/unit/date_time/test_dt_types.py::test_dt_types[Test Case: Datetime seconds]",
                "result": "passed",
                "test_implementation": "def test_dt_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/date_time/test_dt_tz_types.py::test_dt_tz_types[Test Case: Datetime with Timezone US/Eastern]": {
                "testid": "tests/unit/date_time/test_dt_tz_types.py::test_dt_tz_types[Test Case: Datetime with Timezone US/Eastern]",
                "result": "passed",
                "test_implementation": "def test_dt_tz_types(data, expected_dtype):\n    df_data = pd.DataFrame(**data)\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert rdf.compare(df_data).empty\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/date_time/test_dt_tz_types.py::test_dt_tz_types[Test Case: Datetime with Timezone Africa/Abidjan]": {
                "testid": "tests/unit/date_time/test_dt_tz_types.py::test_dt_tz_types[Test Case: Datetime with Timezone Africa/Abidjan]",
                "result": "passed",
                "test_implementation": "def test_dt_tz_types(data, expected_dtype):\n    df_data = pd.DataFrame(**data)\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert rdf.compare(df_data).empty\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/date_time/test_dt_tz_types.py::test_dt_tz_types[Test Case: Datetime with UTC Timezone]": {
                "testid": "tests/unit/date_time/test_dt_tz_types.py::test_dt_tz_types[Test Case: Datetime with UTC Timezone]",
                "result": "passed",
                "test_implementation": "def test_dt_tz_types(data, expected_dtype):\n    df_data = pd.DataFrame(**data)\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert rdf.compare(df_data).empty\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/date_time/test_dt_tz_types.py::test_dt_tz_types[Test Case: Datetime with UTC Timezone Seconds]": {
                "testid": "tests/unit/date_time/test_dt_tz_types.py::test_dt_tz_types[Test Case: Datetime with UTC Timezone Seconds]",
                "result": "passed",
                "test_implementation": "def test_dt_tz_types(data, expected_dtype):\n    df_data = pd.DataFrame(**data)\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert rdf.compare(df_data).empty\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types[Test Case: Timedelta]": {
                "testid": "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types[Test Case: Timedelta]",
                "result": "passed",
                "test_implementation": "def test_timedelta_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert rdf.compare(df_data).empty\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types[Test Case: Timedelta in Hours]": {
                "testid": "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types[Test Case: Timedelta in Hours]",
                "result": "passed",
                "test_implementation": "def test_timedelta_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert rdf.compare(df_data).empty\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types[Test Case: Timedelta in Minutes]": {
                "testid": "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types[Test Case: Timedelta in Minutes]",
                "result": "passed",
                "test_implementation": "def test_timedelta_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert rdf.compare(df_data).empty\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types[Test Case: Timedelta Minutes in Milliseconds]": {
                "testid": "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types[Test Case: Timedelta Minutes in Milliseconds]",
                "result": "passed",
                "test_implementation": "def test_timedelta_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert rdf.compare(df_data).empty\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types[Test Case: Timedelta Minutes with Timezone]": {
                "testid": "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types[Test Case: Timedelta Minutes with Timezone]",
                "result": "passed",
                "test_implementation": "def test_timedelta_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert rdf.compare(df_data).empty\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types[Test Case: Timedelta Minutes in Microseconds]": {
                "testid": "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types[Test Case: Timedelta Minutes in Microseconds]",
                "result": "passed",
                "test_implementation": "def test_timedelta_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert rdf.compare(df_data).empty\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types[Test Case: Timedelta Minutes in Seconds]": {
                "testid": "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types[Test Case: Timedelta Minutes in Seconds]",
                "result": "passed",
                "test_implementation": "def test_timedelta_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert rdf.compare(df_data).empty\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/property_based/test_dt.py::test_datetime_pb_ns": {
                "testid": "tests/unit/property_based/test_dt.py::test_datetime_pb_ns",
                "result": "passed",
                "test_implementation": "def test_datetime_pb_ns(pair: Tuple[pd.DataFrame, str]):\n    df, target_dtype = pair\n    adf = convert_to_pyarrow(df)\n    assert list(adf.dtypes)[0] == target_dtype"
            },
            "tests/unit/property_based/test_general.py::test_uncommon_dtypes_hp": {
                "testid": "tests/unit/property_based/test_general.py::test_uncommon_dtypes_hp",
                "result": "passed",
                "test_implementation": "def test_uncommon_dtypes_hp(df):\n    df_copy = df.copy()\n    adf = convert_to_pyarrow(df)\n\n    new_dtypes_names = [repr(i) for i in adf.dtypes.tolist()]\n    is_arrows = [\"[pyarrow]\" in dtype for dtype in new_dtypes_names]\n    assert all(is_arrows), \"Some dtypes are not converted\"\n    assert not df.equals(adf), \"The original df has been modified\"\n    assert df.equals(df_copy), \"The original df has been modified\"\n    assert adf.equals(convert_to_pyarrow(adf)), \"The conversion is not idempotent\""
            },
            "tests/unit/property_based/test_general.py::test_common_dtypes_hp": {
                "testid": "tests/unit/property_based/test_general.py::test_common_dtypes_hp",
                "result": "passed",
                "test_implementation": "def test_common_dtypes_hp(df):\n    adf_pd_api = df.convert_dtypes(dtype_backend=\"pyarrow\")\n    adf = convert_to_pyarrow(df)\n    assert adf_pd_api.compare(adf).empty, \"The conversion is not consistent with pandas api\""
            },
            "tests/unit/property_based/test_general.py::test_convert_to_numpy": {
                "testid": "tests/unit/property_based/test_general.py::test_convert_to_numpy",
                "result": "passed",
                "test_implementation": "def test_convert_to_numpy(df):\n    adf = convert_to_pyarrow(df)\n    df_copy = adf.copy()\n    rdf = convert_to_numpy(adf)\n    new_numpy_dtypes = [repr(i) for i in rdf.dtypes.tolist()]\n    is_numpy = [\"[pyarrow]\" not in dtype for dtype in new_numpy_dtypes]\n    assert all(is_numpy), \"Some dtypes are not converted to numpy\"\n    assert rdf.equals(convert_to_numpy(rdf)), \"The conversion is not idempotent\"\n    assert df_copy.equals(adf), \"The original df has been modified\""
            },
            "tests/unit/property_based/test_numeric.py::test_float_numpy_api_hp": {
                "testid": "tests/unit/property_based/test_numeric.py::test_float_numpy_api_hp",
                "result": "passed",
                "test_implementation": "def test_float_numpy_api_hp(pair: Tuple[pd.DataFrame, str]):\n    df, target_dtype = pair\n    adf = convert_to_pyarrow(df)\n\n    assert list(adf.dtypes)[0] == target_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert df.equals(rdf)"
            },
            "tests/unit/property_based/test_numeric.py::test_float_array_api_hp": {
                "testid": "tests/unit/property_based/test_numeric.py::test_float_array_api_hp",
                "result": "passed",
                "test_implementation": "def test_float_array_api_hp(pair: Tuple[pd.DataFrame, str]):\n    df, target_dtype = pair\n    adf = convert_to_pyarrow(df)\n\n    assert list(adf.dtypes)[0] == target_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])"
            },
            "tests/unit/property_based/test_numeric.py::test_int_numpy_api_hp": {
                "testid": "tests/unit/property_based/test_numeric.py::test_int_numpy_api_hp",
                "result": "passed",
                "test_implementation": "def test_int_numpy_api_hp(pair: Tuple[pd.DataFrame, str]):\n    df, target_dtype = pair\n    adf = convert_to_pyarrow(df)\n\n    assert list(adf.dtypes)[0] == target_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert df.equals(rdf)"
            },
            "tests/unit/property_based/test_numeric.py::test_int_array_api_hp": {
                "testid": "tests/unit/property_based/test_numeric.py::test_int_array_api_hp",
                "result": "passed",
                "test_implementation": "def test_int_array_api_hp(pair: Tuple[pd.DataFrame, str]):\n    df, target_dtype = pair\n    adf = convert_to_pyarrow(df)\n\n    assert list(adf.dtypes)[0] == target_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])"
            },
            "tests/unit/test_add_dtypes_mapper_types.py::test_add_dtypes_types[test simple type mapping override with additional_mapper_dicts ns]": {
                "testid": "tests/unit/test_add_dtypes_mapper_types.py::test_add_dtypes_types[test simple type mapping override with additional_mapper_dicts ns]",
                "result": "passed",
                "test_implementation": "def test_add_dtypes_types(df_data, expected_dtype, additional_mapper_dicts):\n    sa = PandasArrowConverter(custom_mapper=additional_mapper_dicts)\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert list(rdf.dtypes)[0] != expected_dtype\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/test_add_dtypes_mapper_types.py::test_add_dtypes_types[test simple type mapping override with additional_mapper_dicts ms0]": {
                "testid": "tests/unit/test_add_dtypes_mapper_types.py::test_add_dtypes_types[test simple type mapping override with additional_mapper_dicts ms0]",
                "result": "passed",
                "test_implementation": "def test_add_dtypes_types(df_data, expected_dtype, additional_mapper_dicts):\n    sa = PandasArrowConverter(custom_mapper=additional_mapper_dicts)\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert list(rdf.dtypes)[0] != expected_dtype\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/test_add_dtypes_mapper_types.py::test_add_dtypes_types[test simple type mapping override with additional_mapper_dicts ms1]": {
                "testid": "tests/unit/test_add_dtypes_mapper_types.py::test_add_dtypes_types[test simple type mapping override with additional_mapper_dicts ms1]",
                "result": "passed",
                "test_implementation": "def test_add_dtypes_types(df_data, expected_dtype, additional_mapper_dicts):\n    sa = PandasArrowConverter(custom_mapper=additional_mapper_dicts)\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert list(rdf.dtypes)[0] != expected_dtype\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/test_add_dtypes_mapper_types.py::test_add_dtypes_types[test simple type mapping override with additional_mapper_dicts ms2]": {
                "testid": "tests/unit/test_add_dtypes_mapper_types.py::test_add_dtypes_types[test simple type mapping override with additional_mapper_dicts ms2]",
                "result": "passed",
                "test_implementation": "def test_add_dtypes_types(df_data, expected_dtype, additional_mapper_dicts):\n    sa = PandasArrowConverter(custom_mapper=additional_mapper_dicts)\n    adf = sa(df_data)\n\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert list(rdf.dtypes)[0] != expected_dtype\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/test_dtype_exists.py::test_str_dtypes[str_types0]": {
                "testid": "tests/unit/test_dtype_exists.py::test_str_dtypes[str_types0]",
                "result": "passed",
                "test_implementation": "def test_str_dtypes(str_types):\n    for t in str_types:\n        pd_dtype = pd.api.types.pandas_dtype(t)\n        if \"pyarrow\" not in t:\n            assert str(pd_dtype) in str_types"
            },
            "tests/unit/test_dtype_exists.py::test_str_dtypes[str_types1]": {
                "testid": "tests/unit/test_dtype_exists.py::test_str_dtypes[str_types1]",
                "result": "passed",
                "test_implementation": "def test_str_dtypes(str_types):\n    for t in str_types:\n        pd_dtype = pd.api.types.pandas_dtype(t)\n        if \"pyarrow\" not in t:\n            assert str(pd_dtype) in str_types"
            },
            "tests/unit/test_dtype_exists.py::test_str_dtypes[str_types2]": {
                "testid": "tests/unit/test_dtype_exists.py::test_str_dtypes[str_types2]",
                "result": "passed",
                "test_implementation": "def test_str_dtypes(str_types):\n    for t in str_types:\n        pd_dtype = pd.api.types.pandas_dtype(t)\n        if \"pyarrow\" not in t:\n            assert str(pd_dtype) in str_types"
            },
            "tests/unit/test_dtype_exists.py::test_str_dtypes[str_types3]": {
                "testid": "tests/unit/test_dtype_exists.py::test_str_dtypes[str_types3]",
                "result": "passed",
                "test_implementation": "def test_str_dtypes(str_types):\n    for t in str_types:\n        pd_dtype = pd.api.types.pandas_dtype(t)\n        if \"pyarrow\" not in t:\n            assert str(pd_dtype) in str_types"
            },
            "tests/unit/test_dtype_exists.py::test_str_dtypes_numpy[str_types0]": {
                "testid": "tests/unit/test_dtype_exists.py::test_str_dtypes_numpy[str_types0]",
                "result": "passed",
                "test_implementation": "def test_str_dtypes_numpy(str_types):\n    for t in str_types:\n        pd_dtype = pd.api.types.pandas_dtype(t)\n        assert str(pd_dtype) in str_types"
            },
            "tests/unit/test_dtype_exists.py::test_str_dtypes_numpy[str_types1]": {
                "testid": "tests/unit/test_dtype_exists.py::test_str_dtypes_numpy[str_types1]",
                "result": "passed",
                "test_implementation": "def test_str_dtypes_numpy(str_types):\n    for t in str_types:\n        pd_dtype = pd.api.types.pandas_dtype(t)\n        assert str(pd_dtype) in str_types"
            },
            "tests/unit/test_dtype_exists.py::test_str_dtypes_pyarrow": {
                "testid": "tests/unit/test_dtype_exists.py::test_str_dtypes_pyarrow",
                "result": "passed",
                "test_implementation": "def test_str_dtypes_pyarrow():\n    mapper_from_numpy = create_mapper()\n    mapper_from_pyarrow = reverse_create_mapper(adapter=\"tz=\")\n    str_types = set(mapper_from_numpy.values()).union(set(mapper_from_pyarrow.keys()))\n    for t in str_types:\n        pd_dtype = pd.api.types.pandas_dtype(t)\n        pd_dtype_repr = repr(pd_dtype)\n        assert pd_dtype_repr in str_types"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting int8 to int8[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting int8 to int8[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting int16 to int16[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting int16 to int16[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting int32 to int32[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting int32 to int32[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting int64 to int64[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting int64 to int64[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting Int8 to int8[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting Int8 to int8[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting Int16 to int16[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting Int16 to int16[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting Int32 to int32[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting Int32 to int32[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting Int64 to int64[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting Int64 to int64[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting uint8 to uint8[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting uint8 to uint8[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting uint16 to uint16[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting uint16 to uint16[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting uint32 to uint32[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting uint32 to uint32[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting uint64 to uint64[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting uint64 to uint64[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting UInt8 to uint8[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting UInt8 to uint8[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting UInt16 to uint16[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting UInt16 to uint16[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting UInt32 to uint32[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting UInt32 to uint32[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting UInt64 to uint64[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting UInt64 to uint64[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting float16 to float16[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting float16 to float16[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting float32 to float32[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting float32 to float32[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting float64 to float64[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting float64 to float64[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting Float32 to float32[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting Float32 to float32[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting Float64 to float64[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting Float64 to float64[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting complex64 to string[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting complex64 to string[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting float32[pyarrow] to float32[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting float32[pyarrow] to float32[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_numeric_types.py::test_numeric_types[test casting float64[pyarrow] to float64[pyarrow]]": {
                "testid": "tests/unit/test_numeric_types.py::test_numeric_types[test casting float64[pyarrow] to float64[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1\n    is_lowercase_dtype = str(df_data.dtypes[0]).lower() == str(df_data.dtypes[0])\n    is_not_complex = \"complex\" not in str(df_data.dtypes[0])\n    is_not_pyarrow = \"pyarrow\" not in str(df_data.dtypes[0])\n    if is_lowercase_dtype and is_not_complex and is_not_pyarrow:\n        assert df_data.equals(rdf)"
            },
            "tests/unit/test_object_types.py::test_numeric_types[test casting object to string[pyarrow]]": {
                "testid": "tests/unit/test_object_types.py::test_numeric_types[test casting object to string[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/test_object_types.py::test_numeric_types[test casting O to string[pyarrow]]": {
                "testid": "tests/unit/test_object_types.py::test_numeric_types[test casting O to string[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/test_object_types.py::test_numeric_types[test casting <class 'str'> to string[pyarrow]0]": {
                "testid": "tests/unit/test_object_types.py::test_numeric_types[test casting <class 'str'> to string[pyarrow]0]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/test_object_types.py::test_numeric_types[test casting bytes to string[pyarrow]]": {
                "testid": "tests/unit/test_object_types.py::test_numeric_types[test casting bytes to string[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/test_object_types.py::test_numeric_types[test casting <class 'str'> to string[pyarrow]1]": {
                "testid": "tests/unit/test_object_types.py::test_numeric_types[test casting <class 'str'> to string[pyarrow]1]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/test_object_types.py::test_numeric_types[test casting bool to bool[pyarrow]0]": {
                "testid": "tests/unit/test_object_types.py::test_numeric_types[test casting bool to bool[pyarrow]0]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/test_object_types.py::test_numeric_types[test casting boolean to bool[pyarrow]0]": {
                "testid": "tests/unit/test_object_types.py::test_numeric_types[test casting boolean to bool[pyarrow]0]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/test_object_types.py::test_numeric_types[test casting bool to bool[pyarrow]1]": {
                "testid": "tests/unit/test_object_types.py::test_numeric_types[test casting bool to bool[pyarrow]1]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/test_object_types.py::test_numeric_types[test casting bool[pyarrow] to bool[pyarrow]]": {
                "testid": "tests/unit/test_object_types.py::test_numeric_types[test casting bool[pyarrow] to bool[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/test_object_types.py::test_numeric_types[test casting boolean to bool[pyarrow]1]": {
                "testid": "tests/unit/test_object_types.py::test_numeric_types[test casting boolean to bool[pyarrow]1]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/test_object_types.py::test_numeric_types[test casting boolean to bool[pyarrow]2]": {
                "testid": "tests/unit/test_object_types.py::test_numeric_types[test casting boolean to bool[pyarrow]2]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/test_object_types.py::test_numeric_types[test casting str to string[pyarrow]]": {
                "testid": "tests/unit/test_object_types.py::test_numeric_types[test casting str to string[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/test_object_types.py::test_numeric_types[test casting <U1 to string[pyarrow]]": {
                "testid": "tests/unit/test_object_types.py::test_numeric_types[test casting <U1 to string[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/test_object_types.py::test_numeric_types[test casting string to string[pyarrow]]": {
                "testid": "tests/unit/test_object_types.py::test_numeric_types[test casting string to string[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/test_object_types.py::test_numeric_types[test casting category to string[pyarrow]]": {
                "testid": "tests/unit/test_object_types.py::test_numeric_types[test casting category to string[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/test_object_types.py::test_numeric_types[test casting string[python] to string[pyarrow]]": {
                "testid": "tests/unit/test_object_types.py::test_numeric_types[test casting string[python] to string[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/test_object_types.py::test_numeric_types[test casting string[pyarrow] to string[pyarrow]]": {
                "testid": "tests/unit/test_object_types.py::test_numeric_types[test casting string[pyarrow] to string[pyarrow]]",
                "result": "passed",
                "test_implementation": "def test_numeric_types(df_data, expected_dtype):\n    sa = PandasArrowConverter()\n    adf = sa(df_data)\n    assert list(adf.dtypes)[0] == expected_dtype\n    rdf = convert_to_numpy(adf)\n    assert \"Float\" not in str(rdf.dtypes[0])\n    assert \"Int\" not in str(rdf.dtypes[0])\n    assert \"pyarrow\" not in repr(rdf.dtypes[0])\n    assert \"pyarrow\" not in str(rdf.dtypes[0])\n    assert len(set(rdf.dtypes).union(set(adf.dtypes))) > 1"
            },
            "tests/unit/test_reverse_converter.py::test_convert_timestamp": {
                "testid": "tests/unit/test_reverse_converter.py::test_convert_timestamp",
                "result": "passed",
                "test_implementation": "def test_convert_timestamp():\n    data = {\n        \"timestamp_col\": pd.Series(\n            pd.date_range(\"2000\", periods=100, freq=\"D\"),\n        )\n    }\n    df = pd.DataFrame(data)\n    adf = convert_to_pyarrow(df)\n    rdf = convert_to_numpy(adf)\n    r_dtype = rdf[\"timestamp_col\"].dtype\n    assert \"pyarrow\" not in repr(r_dtype)\n    rdf = convert_to_numpy(adf)\n    assert df.equals(rdf)"
            },
            "tests/unit/test_reverse_converter.py::test_convert_halffloat": {
                "testid": "tests/unit/test_reverse_converter.py::test_convert_halffloat",
                "result": "passed",
                "test_implementation": "def test_convert_halffloat():\n    data = {\"halffloat_col\": pd.Series(np.random.rand(100), dtype=\"float16\")}\n    df = pd.DataFrame(data)\n    adf = convert_to_pyarrow(df)\n    rdf = convert_to_numpy(adf)\n    r_dtype = rdf[\"halffloat_col\"].dtype\n    assert \"pyarrow\" not in repr(r_dtype)\n    rdf = convert_to_numpy(adf)\n    assert df.equals(rdf)"
            },
            "tests/unit/test_reverse_converter.py::test_convert_duration": {
                "testid": "tests/unit/test_reverse_converter.py::test_convert_duration",
                "result": "passed",
                "test_implementation": "def test_convert_duration():\n    data = {\"duration_col\": pd.Series(pd.to_timedelta(np.arange(100), \"D\"), dtype=\"timedelta64[ns]\")}\n    df = pd.DataFrame(data)\n    adf = convert_to_pyarrow(df)\n    rdf = convert_to_numpy(adf)\n    r_dtype = rdf[\"duration_col\"].dtype\n    assert r_dtype == \"timedelta64[ns]\"\n    rdf = convert_to_numpy(adf)\n    assert df.equals(rdf)"
            },
            "tests/unit/test_reverse_converter.py::test_convert_string": {
                "testid": "tests/unit/test_reverse_converter.py::test_convert_string",
                "result": "passed",
                "test_implementation": "def test_convert_string():\n    data = {\"string_col\": pd.Series([\"abc\", \"def\", \"ghi\"], dtype=\"object\")}\n    df = pd.DataFrame(data)\n    adf = convert_to_pyarrow(df)\n    rdf = convert_to_numpy(adf)\n    r_dtype = rdf[\"string_col\"].dtype\n    assert repr(r_dtype) != \"string[pyarrow]\"\n    assert \"pyarrow\" not in repr(r_dtype)\n    assert \"pyarrow\" not in str(r_dtype)"
            },
            "tests/unit/test_reverse_mapper.py::test_reverse_to_all_pyarrow_types": {
                "testid": "tests/unit/test_reverse_mapper.py::test_reverse_to_all_pyarrow_types",
                "result": "passed",
                "test_implementation": "def test_reverse_to_all_pyarrow_types():\n    pyarrow_mapper = create_mapper()\n    reverse_mapper = reverse_create_mapper(adapter=\"\")\n    all_pyarrow_types = set(pyarrow_mapper.values())\n    all_reverse_types = set(reverse_mapper.keys())\n    difference = all_pyarrow_types.difference(all_reverse_types)\n    assert len(difference) == 0"
            },
            "tests/unit/test_reverse_mapper.py::test_all_numpy_types": {
                "testid": "tests/unit/test_reverse_mapper.py::test_all_numpy_types",
                "result": "passed",
                "test_implementation": "def test_all_numpy_types():\n    pyarrow_mapper = create_mapper()\n    reverse_mapper = reverse_create_mapper(adapter=\"\")\n    all_source_numpy = set(pyarrow_mapper.keys())\n    all_target_numpy = set(reverse_mapper.values())\n    assert all_target_numpy.issubset(all_source_numpy)\n    source_dtypes = {pd.api.types.pandas_dtype(t) for t in all_source_numpy if t not in {\"dbtime\", \"dbdate\"}}\n    target_dtypes = {pd.api.types.pandas_dtype(t) for t in all_target_numpy}\n    assert target_dtypes.issubset(source_dtypes)"
            }
        },
        "SRS_document": "**Software Requirements Specification**\n\n**pandas-pyarrow Conversion Library**\n\n**Primary Goal of this SRS Document:**\nThis Software Requirements Specification (SRS) document will serve a critical role in assessing software developers. Developers will be provided with this SRS document and a designated subset of the original test cases (public tests). Their objective is to develop a complete, functional software project based solely on this SRS. Their final success will be rigorously measured by whether their implementation passes all original test cases, including a comprehensive set of private tests not initially provided to them.\n\n**Table of Contents**\n1. Introduction\n    1.1 Purpose\n    1.2 Scope\n    1.3 Definitions, Acronyms, and Abbreviations\n    1.4 References\n    1.5 Overview\n2. Overall Description\n    2.1 Product Perspective\n    2.2 Product Functions\n    2.3 User Characteristics\n    2.4 Constraints\n    2.5 Assumptions and Dependencies\n3. Specific Requirements\n    3.1 Functional Requirements\n        3.1.1 General System Interface\n        3.1.2 Pandas to PyArrow DataFrame Conversion (P2A)\n        3.1.3 PyArrow to Pandas/Numpy DataFrame Conversion (A2P)\n        3.1.4 DataFrame Integrity and Consistency\n    3.2 Non-Functional Requirements\n    3.3 External Interface Requirements\n    3.4 Other Requirements\n\n---\n\n**1. Introduction**\n\n**1.1 Purpose**\nThis Software Requirements Specification (SRS) document defines the functional and non-functional requirements for the `pandas-pyarrow` library. The primary purpose of this library is to facilitate the conversion of pandas DataFrame data types between standard pandas/Numpy backends and PyArrow-backed backends. This SRS is intended to be used by software developers to understand the system's capabilities and to guide the development and testing of a software project that fulfills these requirements.\n\n**1.2 Scope**\nThe software described in this document provides functionalities to:\n*   Convert pandas DataFrames using various standard and extension dtypes (including numeric, string, boolean, datetime, timedelta, and database-specific types) to DataFrames where columns are backed by PyArrow arrays.\n*   Allow users to customize these conversion mappings.\n*   Convert pandas DataFrames with PyArrow-backed dtypes back to DataFrames using standard pandas/Numpy dtypes.\n*   Handle special cases, such as `float16` conversion, more robustly than standard pandas mechanisms.\n\nThe system is a Python library intended for use by data scientists, data engineers, and developers working with pandas and PyArrow in Python environments.\n\n**1.3 Definitions, Acronyms, and Abbreviations**\n*   **A2P:** Arrow to Pandas/Numpy conversion.\n*   **API:** Application Programming Interface.\n*   **DataFrame:** A two-dimensional, size-mutable, potentially heterogeneous tabular data structure with labeled axes (rows and columns), as provided by the pandas library.\n*   **db-dtypes:** Pandas extension dtypes often used with database connectors (e.g., by `pandas-gbq`), such as `dbdate` and `dbtime`.\n*   **dtype:** Data type. Specifies the type of data held in a pandas Series or DataFrame column.\n*   **NaN:** Not a Number. A special floating-point value representing an undefined or unrepresentable value.\n*   **NFR:** Non-Functional Requirement.\n*   **Numpy:** NumPy, a fundamental package for numerical computation in Python.\n*   **P2A:** Pandas to PyArrow conversion.\n*   **Pandas:** Python Data Analysis Library.\n*   **PyArrow:** Apache Arrow Python bindings. A cross-language development platform for in-memory data.\n*   **[pyarrow]:** A suffix used in pandas dtype string representations to indicate that the data type is backed by a PyArrow array (e.g., `int64[pyarrow]`).\n*   **SRS:** Software Requirements Specification.\n*   **TZ:** Timezone.\n*   **UTC:** Coordinated Universal Time.\n\n**1.4 References**\n*   Original `pandas-pyarrow` README: Provided as input.\n*   Original `pandas-pyarrow` source code: Provided as input for LLM contextual understanding.\n*   Original `pandas-pyarrow` test cases: Provided as input for deriving requirements and for LLM contextual understanding.\n\n**1.5 Overview**\nThis SRS document is organized into three main sections:\n*   **Section 1 (Introduction):** Provides a general overview of the SRS, including its purpose, scope, definitions, and references.\n*   **Section 2 (Overall Description):** Describes the product, its capabilities, intended users, and operational environment at a high level.\n*   **Section 3 (Specific Requirements):** Details all functional and non-functional requirements of the software. Functional requirements specify what the system must do, while non-functional requirements specify quality attributes.\n\n---\n\n**2. Overall Description**\n\n**2.1 Product Perspective**\nThe `pandas-pyarrow` library is a Python utility designed to enhance interoperability between pandas DataFrames and the PyArrow data format. It acts as an extension to pandas, offering more comprehensive and customizable dtype conversion capabilities to and from PyArrow-backed types than those natively available in pandas alone, particularly for certain dtypes.\n\n**2.2 Product Functions**\nThe key functions of the `pandas-pyarrow` library include:\n1.  **Pandas to PyArrow Conversion:** Conversion of pandas DataFrame columns from various standard (Numpy-based) and extension dtypes to their PyArrow-backed equivalents.\n2.  **PyArrow to Pandas/Numpy Conversion:** Conversion of pandas DataFrame columns from PyArrow-backed dtypes back to standard Numpy-based or pandas object dtypes.\n3.  **Customizable Mappings:** Ability for users to define or override the default dtype conversion rules for both forward (Pandas to PyArrow) and reverse (PyArrow to Pandas) conversions.\n4.  **Handling of Special Dtypes:** Improved handling for dtypes that may present challenges with standard pandas conversion mechanisms, such as `float16` and database-specific dtypes.\n\n**2.3 User Characteristics**\nThe intended users of this library are Python developers, data scientists, and data engineers who:\n*   Work extensively with pandas DataFrames.\n*   Utilize or intend to utilize PyArrow for performance benefits or interoperability.\n*   Require fine-grained control over dtype conversions between pandas and PyArrow.\n*   Interact with systems or libraries that produce or consume data with specific dtypes (e.g., Google BigQuery via `pandas-gbq`).\n\nUsers are expected to have a working knowledge of Python and the pandas library. Familiarity with PyArrow concepts and data types is beneficial but not strictly required for basic usage.\n\n**2.4 Constraints**\n*   The system shall be implemented as a Python library.\n*   The system shall be compatible with versions of pandas and PyArrow that support PyArrow-backed dtypes. (Specific version compatibility is outside the scope of this SRS but implied by the context of the original project).\n\n**2.5 Assumptions and Dependencies**\n*   The system assumes that users will provide valid pandas DataFrames as input.\n*   The system depends on the pandas and PyArrow libraries being installed in the Python environment.\n*   The `pytz` library is a dependency for handling timezone information in datetime conversions.\n*   For `db-dtypes` conversion, the `db_dtypes` library is an implicit dependency if those types are used.\n\n---\n\n**3. Specific Requirements**\n\n**3.1 Functional Requirements**\n\n**3.1.1 General System Interface**\n\n*   **FR-GEN-IF-001:** The system shall provide a primary functional interface to initiate the conversion of a pandas DataFrame's dtypes to PyArrow-backed dtypes.\n    *   This includes a direct callable function for convenience.\n*   **FR-GEN-IF-002:** The system shall allow instantiation of a converter object that can be used to perform Pandas to PyArrow dtype conversions.\n    *   This converter object shall be configurable.\n*   **FR-GEN-IF-003:** The system shall provide a primary functional interface to initiate the conversion of a PyArrow-backed pandas DataFrame's dtypes to standard Pandas/Numpy dtypes.\n    *   This includes a direct callable function for convenience.\n*   **FR-GEN-IF-004:** The system shall allow instantiation of a converter object that can be used to perform PyArrow to Pandas/Numpy dtype conversions.\n    *   This converter object shall be configurable.\n**3.1.2 Pandas to PyArrow DataFrame Conversion (P2A)**\n\n    **3.1.2.1 Core P2A Functionality**\n*   **FR-P2A-CORE-001:** The system shall convert the data types of columns in an input pandas DataFrame to PyArrow-backed data types based on a set of mapping rules.\n    *   The conversion shall result in a new DataFrame with the updated dtypes.\n*   **FR-P2A-CORE-002:** If a column's data type in the input DataFrame is already PyArrow-backed, the system shall retain its existing PyArrow data type during the P2A conversion process.\n    **3.1.2.2 Standard Numeric Type Conversions (P2A)**\n*   **FR-P2A-NUMS-001:** The system shall convert pandas integer dtypes ('int8', 'int16', 'int32', 'int64') to their corresponding PyArrow-backed integer dtypes (e.g., 'int8[pyarrow]', 'int64[pyarrow]').\n*   **FR-P2A-NUMS-002:** The system shall convert pandas unsigned integer dtypes ('uint8', 'uint16', 'uint32', 'uint64') to their corresponding PyArrow-backed unsigned integer dtypes (e.g., 'uint8[pyarrow]', 'uint64[pyarrow]').\n*   **FR-P2A-NUMS-003:** The system shall convert pandas floating-point dtypes ('float32', 'float64') to their corresponding PyArrow-backed floating-point dtypes (e.g., 'float32[pyarrow]', 'float64[pyarrow]').\n    *   Note: 'float64' pandas dtype maps to 'double[pyarrow]' which is an alias for 'float64[pyarrow]'. 'float32' maps to 'float[pyarrow]' which is an alias for 'float32[pyarrow]'.\n    **3.1.2.3 Pandas Nullable Numeric Type Conversions (P2A)**\n*   **FR-P2A-NUMN-001:** The system shall convert pandas nullable integer dtypes ('Int8', 'Int16', 'Int32', 'Int64') to their corresponding PyArrow-backed integer dtypes (e.g., 'int8[pyarrow]', 'int64[pyarrow]').\n*   **FR-P2A-NUMN-002:** The system shall convert pandas nullable unsigned integer dtypes ('UInt8', 'UInt16', 'UInt32', 'UInt64') to their corresponding PyArrow-backed unsigned integer dtypes (e.g., 'uint8[pyarrow]', 'uint64[pyarrow]').\n*   **FR-P2A-NUMN-003:** The system shall convert pandas nullable floating-point dtypes ('Float32', 'Float64') to their corresponding PyArrow-backed floating-point dtypes (e.g., 'float32[pyarrow]', 'float64[pyarrow]').\n    **3.1.2.4 Boolean Type Conversions (P2A)**\n*   **FR-P2A-BOOL-001:** The system shall convert pandas boolean dtypes ('bool', 'boolean', `pd.BooleanDtype()`) to 'bool[pyarrow]'.\n    **3.1.2.5 String, Object, and Category Type Conversions (P2A)**\n*   **FR-P2A-STR-001:** The system shall convert pandas object dtypes ('object', 'O'), string dtypes ('string', 'str', 'string[python]', '<U1'), and category dtype ('category') to 'string[pyarrow]'.\n*   **FR-P2A-BYTES-001:** The system shall convert pandas 'bytes' dtype to 'string[pyarrow]'.\n    **3.1.2.6 Datetime Type Conversions (P2A)**\n*   **FR-P2A-DT-001:** The system shall convert pandas naive datetime dtypes with various precisions ('datetime64[ns]', 'datetime64[ms]', 'datetime64[s]') to their corresponding PyArrow-backed timestamp dtypes ('timestamp[ns][pyarrow]', 'timestamp[ms][pyarrow]', 'timestamp[s][pyarrow]').\n*   **FR-P2A-DT-002:** The system shall convert pandas timezone-aware datetime dtypes with various precisions and timezones (e.g., 'datetime64[ns, UTC]', 'datetime64[s, US/Eastern]') to their corresponding PyArrow-backed timezone-aware timestamp dtypes (e.g., 'timestamp[ns, tz=UTC][pyarrow]', 'timestamp[s, tz=US/Eastern][pyarrow]').\n    *   The system must support all timezones available via `pytz.all_timezones`.\n    **3.1.2.7 Timedelta Type Conversions (P2A)**\n*   **FR-P2A-TD-001:** The system shall convert pandas timedelta dtypes with various precisions ('timedelta64[ns]', 'timedelta64[ms]', 'timedelta64[us]', 'timedelta64[s]') to their corresponding PyArrow-backed duration dtypes (e.g., 'duration[ns][pyarrow]', 'duration[ms][pyarrow]', 'duration[us][pyarrow]', 'duration[s][pyarrow]').\n    *   The 'timedelta64' dtype (without explicit precision) shall be converted to 'duration[us][pyarrow]'.\n    **3.1.2.8 Special Numeric Type Conversions (P2A)**\n*   **FR-P2A-SPEC-001:** The system shall convert pandas 'float16' dtype to 'float16[pyarrow]' (also known as 'halffloat[pyarrow]').\n*   **FR-P2A-SPEC-002:** The system shall convert pandas complex number dtypes (e.g., 'complex64') to 'string[pyarrow]'.\n    **3.1.2.9 Database-Specific Type Conversions (P2A)**\n*   **FR-P2A-DB-001:** The system shall convert 'dbdate' (from `db_dtypes` library) to 'date32[pyarrow]'.\n*   **FR-P2A-DB-002:** The system shall convert 'dbtime' (from `db_dtypes` library) to 'time64[us][pyarrow]'.\n    **3.1.2.10 Custom Type Mapping Configuration (P2A)**\n*   **FR-P2A-CUST-001:** The system shall allow users to provide a custom mapping dictionary to the P2A converter.\n    *   These custom mappings shall override the default conversion rules for the specified input dtypes.\n    *   Keys in the custom mapping are string representations of pandas dtypes, and values are string representations of target PyArrow dtypes.\n    **3.1.2.11 Default Fallback for Unmapped Types (P2A)**\n*   **FR-P2A-DEF-001:** For input pandas dtypes not covered by default or custom mappings, and not already PyArrow-backed, the system shall convert them to a configurable default PyArrow dtype.\n    *   If not otherwise specified, this default target type shall be 'string[pyarrow]'.\n**3.1.3 PyArrow to Pandas/Numpy DataFrame Conversion (A2P)**\n\n    **3.1.3.1 Core A2P Functionality**\n*   **FR-A2P-CORE-001:** The system shall convert the data types of columns in an input PyArrow-backed pandas DataFrame to standard Pandas/Numpy data types based on a set of mapping rules.\n    *   The conversion shall result in a new DataFrame with the updated dtypes.\n*   **FR-A2P-CORE-002:** If a column's data type in the input DataFrame is not PyArrow-backed, the system shall retain its existing data type during the A2P conversion process.\n    **3.1.3.2 PyArrow Numeric to Numpy Numeric Type Conversions (A2P)**\n*   **FR-A2P-NUM-001:** The system shall convert PyArrow-backed integer dtypes (e.g., 'int8[pyarrow]', 'int64[pyarrow]') to their corresponding standard Numpy integer dtypes (e.g., 'int8', 'int64').\n*   **FR-A2P-NUM-002:** The system shall convert PyArrow-backed unsigned integer dtypes (e.g., 'uint8[pyarrow]', 'uint64[pyarrow]') to their corresponding standard Numpy unsigned integer dtypes (e.g., 'uint8', 'uint64').\n*   **FR-A2P-NUM-003:** The system shall convert PyArrow-backed floating-point dtypes (e.g., 'float16[pyarrow]'/'halffloat[pyarrow]', 'float32[pyarrow]'/'float[pyarrow]', 'float64[pyarrow]'/'double[pyarrow]') to their corresponding standard Numpy floating-point dtypes (e.g., 'float16', 'float32', 'float64').\n    **3.1.3.3 PyArrow Boolean to Numpy Boolean Type Conversion (A2P)**\n*   **FR-A2P-BOOL-001:** The system shall convert 'bool[pyarrow]' dtype to the standard Numpy 'bool' dtype.\n    **3.1.3.4 PyArrow String to Pandas Object/String Type Conversion (A2P)**\n*   **FR-A2P-STR-001:** The system shall convert 'string[pyarrow]' dtype to pandas 'string' extension dtype (which may be represented as 'object' dtype by older pandas or in certain contexts if it contains non-string objects, but aims for 'string' or 'object' suitable for strings).\n    *   The `ReversePandasArrowConverter` maps `string[pyarrow]` to `string`. Pandas then may store this as object or string extension type.\n    **3.1.3.5 PyArrow Timestamp to Pandas Datetime Type Conversion (A2P)**\n*   **FR-A2P-TS-001:** The system shall convert PyArrow-backed timestamp dtypes (e.g., 'timestamp[ns][pyarrow]', 'timestamp[ms][pyarrow]', 'timestamp[us][pyarrow]', 'timestamp[s][pyarrow]') to their corresponding pandas 'datetime64' dtypes with appropriate precision (e.g., 'datetime64[ns]', 'datetime64[ms]', etc.).\n*   **FR-A2P-TS-002:** The system shall convert PyArrow-backed timezone-aware timestamp dtypes (e.g., 'timestamp[ns, tz=UTC][pyarrow]') to their corresponding pandas timezone-aware 'datetime64' dtypes with appropriate precision and timezone (e.g., 'datetime64[ns, UTC]').\n    *   The system must support all timezones available via `pytz.all_timezones`.\n*   **FR-A2P-DATE-001:** The system shall convert PyArrow 'date32[pyarrow]' (or 'date32[day][pyarrow]') to 'datetime64[ns]' pandas dtype.\n*   **FR-A2P-TIME-001:** The system shall convert PyArrow 'time64[us][pyarrow]' and 'time64[ns][pyarrow]' to 'datetime64[us]' and 'datetime64[ns]' pandas dtypes respectively.\n    **3.1.3.6 PyArrow Duration to Pandas Timedelta Type Conversion (A2P)**\n*   **FR-A2P-DUR-001:** The system shall convert PyArrow-backed duration dtypes (e.g., 'duration[ns][pyarrow]', 'duration[ms][pyarrow]') to their corresponding pandas 'timedelta64' dtypes with appropriate precision (e.g., 'timedelta64[ns]', 'timedelta64[ms]').\n    **3.1.3.7 Custom Reverse Type Mapping Configuration (A2P)**\n*   **FR-A2P-CUST-001:** The system shall allow users to provide a custom mapping dictionary to the A2P converter.\n    *   These custom mappings shall override the default reverse conversion rules for the specified input PyArrow-backed dtypes.\n    *   Keys in the custom mapping are string representations of PyArrow-backed dtypes, and values are string representations of target Pandas/Numpy dtypes.\n    **3.1.3.8 Default Fallback for Unmapped PyArrow Types (A2P)**\n*   **FR-A2P-DEF-001:** For input PyArrow-backed dtypes not covered by default or custom mappings, the system shall convert them to a configurable default Pandas/Numpy dtype.\n    *   If not otherwise specified, this default target type shall be 'object'.\n    **3.1.3.9 Handling of Null/NaN Values (A2P)**\n*   **FR-A2P-NULL-001:** During the A2P conversion, if the source PyArrow data contains nulls, the system shall represent these as appropriate null markers in the target Pandas/Numpy dtype (e.g., `np.nan` for float types, `pd.NaT` for datetime types, None or `np.nan` for object types).\n    *   The `fillna(np.nan)` step in the implementation suggests a specific handling before final `astype`.\n**3.1.4 DataFrame Integrity and Consistency**\n\n*   **FR-DF-IDEM-P2A-001:** Applying the P2A conversion to a DataFrame whose columns are already exclusively PyArrow-backed dtypes (as per the system's conversion rules) shall result in a DataFrame that is equivalent to the input DataFrame.\n*   **FR-DF-IDEM-A2P-001:** Applying the A2P conversion to a DataFrame whose columns are already exclusively standard Pandas/Numpy dtypes (as per the system's reverse conversion rules) shall result in a DataFrame that is equivalent to the input DataFrame.\n*   **FR-DF-IMMUTE-001:** The P2A conversion process shall not modify the input DataFrame. It must return a new DataFrame with the converted dtypes.\n*   **FR-DF-IMMUTE-002:** The A2P conversion process shall not modify the input PyArrow-backed DataFrame. It must return a new DataFrame with the converted dtypes.\n*   **FR-DF-PRESERVE-001:** For certain P2A followed by A2P round-trip conversions, the data values in the final DataFrame shall be equivalent to the original DataFrame. This applies specifically to:\n    *   Standard non-complex numeric types (e.g., 'int64', 'float32', 'uint8') if the original type was already a base Numpy type (not a Pandas nullable extension type like 'Int64').\n    *   Timestamp ('datetime64[ns]') and halffloat ('float16') types.\n    *   Timedelta ('timedelta64[ns]') types.\n    *   Datetime types with timezones.\n*   **FR-DF-CONSIST-PD-001:** For pandas dtypes commonly supported by pandas' native `convert_dtypes(dtype_backend='pyarrow')` method, the system's P2A conversion shall produce results consistent with the native pandas method.\n    *   Commonly supported dtypes include bool, string, integer, datetime64[ns], timedelta64[ns].\n**3.2 Non-Functional Requirements**\nNo non-functional requirements are specified as there are no explicit original test cases that directly validate NFRs such as performance, security, or specific usability metrics beyond functional correctness of documented examples.\n\n**3.3 External Interface Requirements**\n*   **EIR-001:** The system shall accept a pandas DataFrame object as primary input for conversions.\n*   **EIR-002:** The system shall return a pandas DataFrame object as primary output from conversions.\n**3.4 Other Requirements**\nNone.",
        "structured_requirements": [
            {
                "requirement_id": "FR-GEN-IF-001",
                "requirement_description": "The system shall provide a primary functional interface to initiate the conversion of a pandas DataFrame's dtypes to PyArrow-backed dtypes.\n    *   This includes a direct callable function for convenience.",
                "test_traceability": [
                    {
                        "id": "tests/docs/test_docs.py::test_doc_examples",
                        "description": "usage of `convert_to_pyarrow`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/__init__.py::convert_to_pyarrow",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-IF-002",
                "requirement_description": "The system shall allow instantiation of a converter object that can be used to perform Pandas to PyArrow dtype conversions.\n    *   This converter object shall be configurable.",
                "test_traceability": [
                    {
                        "id": "tests/docs/test_docs.py::test_doc_examples",
                        "description": "usage of `PandasArrowConverter`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-IF-003",
                "requirement_description": "The system shall provide a primary functional interface to initiate the conversion of a PyArrow-backed pandas DataFrame's dtypes to standard Pandas/Numpy dtypes.\n    *   This includes a direct callable function for convenience.",
                "test_traceability": [
                    {
                        "id": "tests/unit/test_numeric_types.py::test_numeric_types",
                        "description": "usage of `convert_to_numpy`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/__init__.py::convert_to_numpy",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-IF-004",
                "requirement_description": "The system shall allow instantiation of a converter object that can be used to perform PyArrow to Pandas/Numpy dtype conversions.\n    *   This converter object shall be configurable.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/reverse_converter.py::ReversePandasArrowConverter",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P2A-CORE-001",
                "requirement_description": "The system shall convert the data types of columns in an input pandas DataFrame to PyArrow-backed data types based on a set of mapping rules.\n    *   The conversion shall result in a new DataFrame with the updated dtypes.",
                "test_traceability": [
                    {
                        "id": "tests/docs/test_docs.py::test_doc_examples",
                        "description": "basic conversion example"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P2A-CORE-002",
                "requirement_description": "If a column's data type in the input DataFrame is already PyArrow-backed, the system shall retain its existing PyArrow data type during the P2A conversion process.",
                "test_traceability": [
                    {
                        "id": "tests/unit/test_numeric_types.py::test_numeric_types[test casting float32[pyarrow] to float32[pyarrow]]",
                        "description": ""
                    },
                    {
                        "id": "tests/unit/test_object_types.py::test_numeric_types[test casting bool[pyarrow] to bool[pyarrow]]",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::_target_dtype_name",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P2A-NUMS-001",
                "requirement_description": "The system shall convert pandas integer dtypes ('int8', 'int16', 'int32', 'int64') to their corresponding PyArrow-backed integer dtypes (e.g., 'int8[pyarrow]', 'int64[pyarrow]').",
                "test_traceability": [
                    {
                        "id": "tests/unit/test_numeric_types.py::test_numeric_types",
                        "description": "parameters for int types"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P2A-NUMS-002",
                "requirement_description": "The system shall convert pandas unsigned integer dtypes ('uint8', 'uint16', 'uint32', 'uint64') to their corresponding PyArrow-backed unsigned integer dtypes (e.g., 'uint8[pyarrow]', 'uint64[pyarrow]').",
                "test_traceability": [
                    {
                        "id": "tests/unit/test_numeric_types.py::test_numeric_types",
                        "description": "parameters for uint types"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P2A-NUMS-003",
                "requirement_description": "The system shall convert pandas floating-point dtypes ('float32', 'float64') to their corresponding PyArrow-backed floating-point dtypes (e.g., 'float32[pyarrow]', 'float64[pyarrow]').\n    *   Note: 'float64' pandas dtype maps to 'double[pyarrow]' which is an alias for 'float64[pyarrow]'. 'float32' maps to 'float[pyarrow]' which is an alias for 'float32[pyarrow]'.",
                "test_traceability": [
                    {
                        "id": "tests/unit/test_numeric_types.py::test_numeric_types",
                        "description": "parameters for float types"
                    },
                    {
                        "id": "tests/docs/test_docs.py::test_doc_examples",
                        "description": "DataFrame with float column"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P2A-NUMN-001",
                "requirement_description": "The system shall convert pandas nullable integer dtypes ('Int8', 'Int16', 'Int32', 'Int64') to their corresponding PyArrow-backed integer dtypes (e.g., 'int8[pyarrow]', 'int64[pyarrow]').",
                "test_traceability": [
                    {
                        "id": "tests/unit/test_numeric_types.py::test_numeric_types",
                        "description": "parameters for Int types"
                    },
                    {
                        "id": "tests/intg/test_db_general_dtypes.py::test_db_general_dtypes",
                        "description": "parameters for Int32, Int64"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P2A-NUMN-002",
                "requirement_description": "The system shall convert pandas nullable unsigned integer dtypes ('UInt8', 'UInt16', 'UInt32', 'UInt64') to their corresponding PyArrow-backed unsigned integer dtypes (e.g., 'uint8[pyarrow]', 'uint64[pyarrow]').",
                "test_traceability": [
                    {
                        "id": "tests/unit/test_numeric_types.py::test_numeric_types",
                        "description": "parameters for UInt types"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P2A-NUMN-003",
                "requirement_description": "The system shall convert pandas nullable floating-point dtypes ('Float32', 'Float64') to their corresponding PyArrow-backed floating-point dtypes (e.g., 'float32[pyarrow]', 'float64[pyarrow]').",
                "test_traceability": [
                    {
                        "id": "tests/unit/test_numeric_types.py::test_numeric_types",
                        "description": "parameters for Float types"
                    },
                    {
                        "id": "tests/intg/test_db_general_dtypes.py::test_db_general_dtypes",
                        "description": "parameters for Float32, Float64"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P2A-BOOL-001",
                "requirement_description": "The system shall convert pandas boolean dtypes ('bool', 'boolean', `pd.BooleanDtype()`) to 'bool[pyarrow]'.",
                "test_traceability": [
                    {
                        "id": "tests/unit/test_object_types.py::test_numeric_types",
                        "description": "parameters for bool, boolean, pd.BooleanDtype()"
                    },
                    {
                        "id": "tests/docs/test_docs.py::test_doc_examples",
                        "description": "DataFrame with boolean column"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P2A-STR-001",
                "requirement_description": "The system shall convert pandas object dtypes ('object', 'O'), string dtypes ('string', 'str', 'string[python]', '<U1'), and category dtype ('category') to 'string[pyarrow]'.",
                "test_traceability": [
                    {
                        "id": "tests/unit/test_object_types.py::test_numeric_types",
                        "description": "parameters for object, O, str, <U1, string, category, string[python]"
                    },
                    {
                        "id": "tests/docs/test_docs.py::test_doc_examples",
                        "description": "DataFrame with string column"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P2A-BYTES-001",
                "requirement_description": "The system shall convert pandas 'bytes' dtype to 'string[pyarrow]'.",
                "test_traceability": [
                    {
                        "id": "tests/unit/test_object_types.py::test_numeric_types[test casting bytes to string[pyarrow]]",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P2A-DT-001",
                "requirement_description": "The system shall convert pandas naive datetime dtypes with various precisions ('datetime64[ns]', 'datetime64[ms]', 'datetime64[s]') to their corresponding PyArrow-backed timestamp dtypes ('timestamp[ns][pyarrow]', 'timestamp[ms][pyarrow]', 'timestamp[s][pyarrow]').",
                "test_traceability": [
                    {
                        "id": "tests/unit/date_time/test_dt_types.py::test_dt_types",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P2A-DT-002",
                "requirement_description": "The system shall convert pandas timezone-aware datetime dtypes with various precisions and timezones (e.g., 'datetime64[ns, UTC]', 'datetime64[s, US/Eastern]') to their corresponding PyArrow-backed timezone-aware timestamp dtypes (e.g., 'timestamp[ns, tz=UTC][pyarrow]', 'timestamp[s, tz=US/Eastern][pyarrow]').\n    *   The system must support all timezones available via `pytz.all_timezones`.",
                "test_traceability": [
                    {
                        "id": "tests/unit/date_time/test_dt_tz_types.py::test_dt_tz_types",
                        "description": ""
                    },
                    {
                        "id": "tests/unit/property_based/test_dt.py::test_datetime_pb_ns",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P2A-TD-001",
                "requirement_description": "The system shall convert pandas timedelta dtypes with various precisions ('timedelta64[ns]', 'timedelta64[ms]', 'timedelta64[us]', 'timedelta64[s]') to their corresponding PyArrow-backed duration dtypes (e.g., 'duration[ns][pyarrow]', 'duration[ms][pyarrow]', 'duration[us][pyarrow]', 'duration[s][pyarrow]').\n    *   The 'timedelta64' dtype (without explicit precision) shall be converted to 'duration[us][pyarrow]'.",
                "test_traceability": [
                    {
                        "id": "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P2A-SPEC-001",
                "requirement_description": "The system shall convert pandas 'float16' dtype to 'float16[pyarrow]' (also known as 'halffloat[pyarrow]').",
                "test_traceability": [
                    {
                        "id": "tests/unit/test_numeric_types.py::test_numeric_types[test casting float16 to float16[pyarrow]]",
                        "description": ""
                    },
                    {
                        "id": "tests/docs/test_docs.py::test_doc_examples",
                        "description": "float16 example"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P2A-SPEC-002",
                "requirement_description": "The system shall convert pandas complex number dtypes (e.g., 'complex64') to 'string[pyarrow]'.",
                "test_traceability": [
                    {
                        "id": "tests/unit/test_numeric_types.py::test_numeric_types[test casting complex64 to string[pyarrow]]",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P2A-DB-001",
                "requirement_description": "The system shall convert 'dbdate' (from `db_dtypes` library) to 'date32[pyarrow]'.",
                "test_traceability": [
                    {
                        "id": "tests/intg/test_db_date_dtypes.py::test_db_date_dtypes",
                        "description": "dbdate case"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P2A-DB-002",
                "requirement_description": "The system shall convert 'dbtime' (from `db_dtypes` library) to 'time64[us][pyarrow]'.",
                "test_traceability": [
                    {
                        "id": "tests/intg/test_db_date_dtypes.py::test_db_date_dtypes",
                        "description": "dbtime case"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P2A-CUST-001",
                "requirement_description": "The system shall allow users to provide a custom mapping dictionary to the P2A converter.\n    *   These custom mappings shall override the default conversion rules for the specified input dtypes.\n    *   Keys in the custom mapping are string representations of pandas dtypes, and values are string representations of target PyArrow dtypes.",
                "test_traceability": [
                    {
                        "id": "tests/unit/test_add_dtypes_mapper_types.py::test_add_dtypes_types",
                        "description": ""
                    },
                    {
                        "id": "tests/docs/test_docs.py::test_doc_examples",
                        "description": "custom mapper example"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__init__",
                        "description": ""
                    },
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::_target_dtype_name",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-P2A-DEF-001",
                "requirement_description": "For input pandas dtypes not covered by default or custom mappings, and not already PyArrow-backed, the system shall convert them to a configurable default PyArrow dtype.\n    *   If not otherwise specified, this default target type shall be 'string[pyarrow]'.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__init__",
                        "description": ""
                    },
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::_target_dtype_name",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-A2P-CORE-001",
                "requirement_description": "The system shall convert the data types of columns in an input PyArrow-backed pandas DataFrame to standard Pandas/Numpy data types based on a set of mapping rules.\n    *   The conversion shall result in a new DataFrame with the updated dtypes.",
                "test_traceability": [
                    {
                        "id": "tests/unit/test_numeric_types.py::test_numeric_types",
                        "description": "general reverse conversion part of test"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/reverse_converter.py::ReversePandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-A2P-CORE-002",
                "requirement_description": "If a column's data type in the input DataFrame is not PyArrow-backed, the system shall retain its existing data type during the A2P conversion process.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/reverse_converter.py::ReversePandasArrowConverter::_target_dtype_name",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-A2P-NUM-001",
                "requirement_description": "The system shall convert PyArrow-backed integer dtypes (e.g., 'int8[pyarrow]', 'int64[pyarrow]') to their corresponding standard Numpy integer dtypes (e.g., 'int8', 'int64').",
                "test_traceability": [
                    {
                        "id": "tests/unit/test_numeric_types.py::test_numeric_types",
                        "description": "assertion `assert \"Int\" not in str(rdf.dtypes[0])`"
                    },
                    {
                        "id": "tests/unit/property_based/test_numeric.py::test_int_numpy_api_hp",
                        "description": ""
                    },
                    {
                        "id": "tests/unit/property_based/test_numeric.py::test_int_array_api_hp",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/reverse_converter.py::ReversePandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-A2P-NUM-002",
                "requirement_description": "The system shall convert PyArrow-backed unsigned integer dtypes (e.g., 'uint8[pyarrow]', 'uint64[pyarrow]') to their corresponding standard Numpy unsigned integer dtypes (e.g., 'uint8', 'uint64').",
                "test_traceability": [
                    {
                        "id": "tests/unit/test_numeric_types.py::test_numeric_types",
                        "description": "assertion `assert \"Int\" not in str(rdf.dtypes[0])`"
                    },
                    {
                        "id": "tests/unit/property_based/test_numeric.py::test_int_numpy_api_hp",
                        "description": ""
                    },
                    {
                        "id": "tests/unit/property_based/test_numeric.py::test_int_array_api_hp",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/reverse_converter.py::ReversePandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-A2P-NUM-003",
                "requirement_description": "The system shall convert PyArrow-backed floating-point dtypes (e.g., 'float16[pyarrow]'/'halffloat[pyarrow]', 'float32[pyarrow]'/'float[pyarrow]', 'float64[pyarrow]'/'double[pyarrow]') to their corresponding standard Numpy floating-point dtypes (e.g., 'float16', 'float32', 'float64').",
                "test_traceability": [
                    {
                        "id": "tests/unit/test_numeric_types.py::test_numeric_types",
                        "description": "assertion `assert \"Float\" not in str(rdf.dtypes[0])`"
                    },
                    {
                        "id": "tests/unit/test_reverse_converter.py::test_convert_halffloat",
                        "description": ""
                    },
                    {
                        "id": "tests/unit/property_based/test_numeric.py::test_float_numpy_api_hp",
                        "description": ""
                    },
                    {
                        "id": "tests/unit/property_based/test_numeric.py::test_float_array_api_hp",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/reverse_converter.py::ReversePandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-A2P-BOOL-001",
                "requirement_description": "The system shall convert 'bool[pyarrow]' dtype to the standard Numpy 'bool' dtype.",
                "test_traceability": [
                    {
                        "id": "tests/unit/test_object_types.py::test_numeric_types",
                        "description": "relevant assertions for boolean types after reverse conversion"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/reverse_converter.py::ReversePandasArrowConverter::_target_dtype_name",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-A2P-STR-001",
                "requirement_description": "The system shall convert 'string[pyarrow]' dtype to pandas 'string' extension dtype (which may be represented as 'object' dtype by older pandas or in certain contexts if it contains non-string objects, but aims for 'string' or 'object' suitable for strings).\n    *   The `ReversePandasArrowConverter` maps `string[pyarrow]` to `string`. Pandas then may store this as object or string extension type.",
                "test_traceability": [
                    {
                        "id": "tests/unit/test_reverse_converter.py::test_convert_string",
                        "description": "asserts dtype is not pyarrow"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/reverse_converter.py::ReversePandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-A2P-TS-001",
                "requirement_description": "The system shall convert PyArrow-backed timestamp dtypes (e.g., 'timestamp[ns][pyarrow]', 'timestamp[ms][pyarrow]', 'timestamp[us][pyarrow]', 'timestamp[s][pyarrow]') to their corresponding pandas 'datetime64' dtypes with appropriate precision (e.g., 'datetime64[ns]', 'datetime64[ms]', etc.).",
                "test_traceability": [
                    {
                        "id": "tests/unit/date_time/test_dt_types.py::test_dt_types",
                        "description": "implicit in reverse conversion check"
                    },
                    {
                        "id": "tests/unit/test_reverse_converter.py::test_convert_timestamp",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/reverse_converter.py::ReversePandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-A2P-TS-002",
                "requirement_description": "The system shall convert PyArrow-backed timezone-aware timestamp dtypes (e.g., 'timestamp[ns, tz=UTC][pyarrow]') to their corresponding pandas timezone-aware 'datetime64' dtypes with appropriate precision and timezone (e.g., 'datetime64[ns, UTC]').\n    *   The system must support all timezones available via `pytz.all_timezones`.",
                "test_traceability": [
                    {
                        "id": "tests/unit/date_time/test_dt_tz_types.py::test_dt_tz_types",
                        "description": "implicit in reverse conversion check and `rdf.compare(df_data).empty`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/reverse_converter.py::ReversePandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-A2P-DATE-001",
                "requirement_description": "The system shall convert PyArrow 'date32[pyarrow]' (or 'date32[day][pyarrow]') to 'datetime64[ns]' pandas dtype.",
                "test_traceability": [
                    {
                        "id": "tests/intg/test_db_date_dtypes.py::test_db_date_dtypes",
                        "description": "reverse part, though not explicitly asserted, it's part of the standard test pattern"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/reverse_converter.py::ReversePandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-A2P-TIME-001",
                "requirement_description": "The system shall convert PyArrow 'time64[us][pyarrow]' and 'time64[ns][pyarrow]' to 'datetime64[us]' and 'datetime64[ns]' pandas dtypes respectively.",
                "test_traceability": [
                    {
                        "id": "tests/intg/test_db_date_dtypes.py::test_db_date_dtypes",
                        "description": "reverse part for `time64[us][pyarrow]`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/reverse_converter.py::ReversePandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-A2P-DUR-001",
                "requirement_description": "The system shall convert PyArrow-backed duration dtypes (e.g., 'duration[ns][pyarrow]', 'duration[ms][pyarrow]') to their corresponding pandas 'timedelta64' dtypes with appropriate precision (e.g., 'timedelta64[ns]', 'timedelta64[ms]').",
                "test_traceability": [
                    {
                        "id": "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types",
                        "description": "implicit in reverse conversion check and `rdf.compare(df_data).empty`"
                    },
                    {
                        "id": "tests/unit/test_reverse_converter.py::test_convert_duration",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/reverse_converter.py::ReversePandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-A2P-CUST-001",
                "requirement_description": "The system shall allow users to provide a custom mapping dictionary to the A2P converter.\n    *   These custom mappings shall override the default reverse conversion rules for the specified input PyArrow-backed dtypes.\n    *   Keys in the custom mapping are string representations of PyArrow-backed dtypes, and values are string representations of target Pandas/Numpy dtypes.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/reverse_converter.py::ReversePandasArrowConverter::__init__",
                        "description": ""
                    },
                    {
                        "id": "pandas_pyarrow/reverse_converter.py::ReversePandasArrowConverter::_target_dtype_name",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-A2P-DEF-001",
                "requirement_description": "For input PyArrow-backed dtypes not covered by default or custom mappings, the system shall convert them to a configurable default Pandas/Numpy dtype.\n    *   If not otherwise specified, this default target type shall be 'object'.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/reverse_converter.py::ReversePandasArrowConverter::__init__",
                        "description": ""
                    },
                    {
                        "id": "pandas_pyarrow/reverse_converter.py::ReversePandasArrowConverter::_target_dtype_name",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-A2P-NULL-001",
                "requirement_description": "During the A2P conversion, if the source PyArrow data contains nulls, the system shall represent these as appropriate null markers in the target Pandas/Numpy dtype (e.g., `np.nan` for float types, `pd.NaT` for datetime types, None or `np.nan` for object types).\n    *   The `fillna(np.nan)` step in the implementation suggests a specific handling before final `astype`.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/reverse_converter.py::ReversePandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DF-IDEM-P2A-001",
                "requirement_description": "Applying the P2A conversion to a DataFrame whose columns are already exclusively PyArrow-backed dtypes (as per the system's conversion rules) shall result in a DataFrame that is equivalent to the input DataFrame.",
                "test_traceability": [
                    {
                        "id": "tests/unit/property_based/test_general.py::test_uncommon_dtypes_hp",
                        "description": "assertion `adf.equals(convert_to_pyarrow(adf))`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DF-IDEM-A2P-001",
                "requirement_description": "Applying the A2P conversion to a DataFrame whose columns are already exclusively standard Pandas/Numpy dtypes (as per the system's reverse conversion rules) shall result in a DataFrame that is equivalent to the input DataFrame.",
                "test_traceability": [
                    {
                        "id": "tests/unit/property_based/test_general.py::test_convert_to_numpy",
                        "description": "assertion `rdf.equals(convert_to_numpy(rdf))`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/reverse_converter.py::ReversePandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DF-IMMUTE-001",
                "requirement_description": "The P2A conversion process shall not modify the input DataFrame. It must return a new DataFrame with the converted dtypes.",
                "test_traceability": [
                    {
                        "id": "tests/unit/property_based/test_general.py::test_uncommon_dtypes_hp",
                        "description": "assertions `assert not df.equals(adf)` and `assert df.equals(df_copy)`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DF-IMMUTE-002",
                "requirement_description": "The A2P conversion process shall not modify the input PyArrow-backed DataFrame. It must return a new DataFrame with the converted dtypes.",
                "test_traceability": [
                    {
                        "id": "tests/unit/property_based/test_general.py::test_convert_to_numpy",
                        "description": "assertion `assert df_copy.equals(adf)`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/reverse_converter.py::ReversePandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DF-PRESERVE-001",
                "requirement_description": "For certain P2A followed by A2P round-trip conversions, the data values in the final DataFrame shall be equivalent to the original DataFrame. This applies specifically to:\n    *   Standard non-complex numeric types (e.g., 'int64', 'float32', 'uint8') if the original type was already a base Numpy type (not a Pandas nullable extension type like 'Int64').\n    *   Timestamp ('datetime64[ns]') and halffloat ('float16') types.\n    *   Timedelta ('timedelta64[ns]') types.\n    *   Datetime types with timezones.",
                "test_traceability": [
                    {
                        "id": "tests/unit/test_numeric_types.py::test_numeric_types",
                        "description": "assertion `df.equals(rdf)` under specific conditions"
                    },
                    {
                        "id": "tests/unit/test_reverse_converter.py::test_convert_timestamp",
                        "description": ""
                    },
                    {
                        "id": "tests/unit/test_reverse_converter.py::test_convert_halffloat",
                        "description": ""
                    },
                    {
                        "id": "tests/unit/test_reverse_converter.py::test_convert_duration",
                        "description": ""
                    },
                    {
                        "id": "tests/unit/date_time/test_dt_tz_types.py::test_dt_tz_types",
                        "description": "assertion `rdf.compare(df_data).empty`"
                    },
                    {
                        "id": "tests/unit/date_time/test_timedelta_types.py::test_timedelta_types",
                        "description": "assertion `rdf.compare(df_data).empty`"
                    },
                    {
                        "id": "tests/unit/property_based/test_numeric.py::test_float_numpy_api_hp",
                        "description": ""
                    },
                    {
                        "id": "tests/unit/property_based/test_numeric.py::test_int_numpy_api_hp",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__call__",
                        "description": ""
                    },
                    {
                        "id": "pandas_pyarrow/reverse_converter.py::ReversePandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DF-CONSIST-PD-001",
                "requirement_description": "For pandas dtypes commonly supported by pandas' native `convert_dtypes(dtype_backend='pyarrow')` method, the system's P2A conversion shall produce results consistent with the native pandas method.\n    *   Commonly supported dtypes include bool, string, integer, datetime64[ns], timedelta64[ns].",
                "test_traceability": [
                    {
                        "id": "tests/unit/property_based/test_general.py::test_common_dtypes_hp",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-001",
                "requirement_description": "The system shall accept a pandas DataFrame object as primary input for conversions.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__call__",
                        "description": ""
                    },
                    {
                        "id": "pandas_pyarrow/reverse_converter.py::ReversePandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-002",
                "requirement_description": "The system shall return a pandas DataFrame object as primary output from conversions.",
                "test_traceability": [],
                "code_traceability": [
                    {
                        "id": "pandas_pyarrow/pda_converter.py::PandasArrowConverter::__call__",
                        "description": ""
                    },
                    {
                        "id": "pandas_pyarrow/reverse_converter.py::ReversePandasArrowConverter::__call__",
                        "description": ""
                    }
                ]
            }
        ],
        "commit_sha": "2f2115eb097b8806736dddfe7b92f96026f2c7fa",
        "full_code_skeleton": "--- File: pandas_pyarrow/pda_converter.py ---\n```python\nclass PandasArrowConverter:\n    \"\"\"PandasArrowConverter manages the conversion of Pandas DataFrame data types to Arrow data types.\n    :param custom_mapper: dictionary with key as the source data type and value as the target data type.\n    Will override default mapping\n    :param default_target_type: Optional string specifying the default data type to use if no mapping is found for a\n    specific data type. Default is \"string[pyarrow]\".\n\n    \"\"\"\n\n    def __init__(\n        self,\n        custom_mapper: Optional[Dict[str, str]] = None,\n        default_target_type: Optional[str] = \"string[pyarrow]\",\n    ):\n        pass\n\n    def __call__(self, df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Apply a transformation to the dtypes of a Pandas DataFrame based on a mapping.\n\n        The function adjusts the data types of the columns in the provided DataFrame.\n        It uses the current dtypes of the DataFrame columns, processes them through\n        a mapping function to get the corresponding target dtypes, and applies the\n        mapping to create a new DataFrame with updated dtypes.\n\n        :param df: A Pandas DataFrame whose column dtypes will be transformed.\n        :type df: pd.DataFrame\n        :return: A new Pandas DataFrame with transformed column dtypes.\n        :rtype: pd.DataFrame\n        \"\"\"\n        pass\n\n    def _target_dtype_name(self, dtype_name: str) -> str:\n        pass\n\n    def _map_dtype_names(self, dtype_names: List[str]) -> List[str]:\n        pass\n```\n--- File: pandas_pyarrow/reverse_converter.py ---\n```python\nclass ReversePandasArrowConverter:\n    \"\"\"\n    ReversePandasArrowConverter manages the conversion of pyarrow-backed Pandas DataFrame dtypes\n    back to their Numpy/Pandas equivalents.\n\n    :param custom_mapper: Dictionary with key as the string-representation of the\n        Arrow-backed dtype, and value as the desired target dtype (e.g. \"object\", \"int64\", etc.).\n        This overrides default mapping returned by reverse_create_mapper().\n    :param default_target_type: Optional string specifying the default dtype to use\n        if no mapping is found for a specific dtype. Default is \"object\".\n\n    \"\"\"\n\n    def __init__(\n        self,\n        custom_mapper: Optional[Dict[str, str]] = None,\n        default_target_type: Optional[str] = \"object\",\n    ):\n        pass\n\n    def __call__(self, df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Maps the data types of a given pandas DataFrame to the target data types\n        specified by the object's internal mapping logic. This method processes\n        the DataFrame by replacing its column data types according to the mapped\n        target types and returns a new DataFrame with these updated data types.\n        Any `NaN` values are handled accordingly during the process.\n\n        :param df: A pandas DataFrame that is to be processed.\n        :type df: pd.DataFrame\n        :return: A new pandas DataFrame with updated column data types as per\n                 the mapping.\n        :rtype: pd.DataFrame\n        \"\"\"\n        pass\n\n    def _target_dtype_name(self, dtype_name: str) -> str:\n        pass\n\n    def _map_dtype_names(self, dtype_names: List[str]) -> List[str]:\n        pass\n```\n--- File: pandas_pyarrow/mappers/numeric_mapper.py ---\n```python\ndef create_type_variations(\n    source_types: List[str], filter_func: Callable[[str], bool], variations: List[str]\n) -> Dict[str, str]:\n    pass\n\ndef numeric_mapper(source_types: List[str], variations: List[str]) -> Dict[str, str]:\n    pass\n\ndef reverse_create_type_variations(\n    source_types: List[str], filter_func: Callable[[str], bool], variations: List[str]\n) -> Dict[str, str]:\n    pass\n\ndef reverse_numeric_mapper(source_types: List[str], variations: List[str]) -> Dict[str, str]:\n    pass\n```\n--- File: pandas_pyarrow/mappers/__init__.py ---\n```python\ndef create_mapper() -> Dict[str, str]:\n    pass\n\ndef reverse_create_mapper(\n    adapter: str = \"tz=\",\n) -> Dict[str, str]:\n    pass\n```\n--- File: pandas_pyarrow/mappers/datetime_mapper.py ---\n```python\ndef datetime_mapper(from_type: str = \"datetime64\", to_type: str = \"timestamp\") -> Dict[str, str]:\n    pass\n\ndef reverse_datetime_mapper(\n    from_type: str = \"timestamp\",\n    to_type: str = \"datetime64\",\n    adapter: str = \"tz=\",\n) -> Dict[str, str]:\n    pass\n```",
        "full_code_skeleton_structured": [
            {
                "file_path": "pandas_pyarrow/pda_converter.py",
                "code": "class PandasArrowConverter:\n    \"\"\"PandasArrowConverter manages the conversion of Pandas DataFrame data types to Arrow data types.\n    :param custom_mapper: dictionary with key as the source data type and value as the target data type.\n    Will override default mapping\n    :param default_target_type: Optional string specifying the default data type to use if no mapping is found for a\n    specific data type. Default is \"string[pyarrow]\".\n\n    \"\"\"\n\n    def __init__(\n        self,\n        custom_mapper: Optional[Dict[str, str]] = None,\n        default_target_type: Optional[str] = \"string[pyarrow]\",\n    ):\n        pass\n\n    def __call__(self, df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Apply a transformation to the dtypes of a Pandas DataFrame based on a mapping.\n\n        The function adjusts the data types of the columns in the provided DataFrame.\n        It uses the current dtypes of the DataFrame columns, processes them through\n        a mapping function to get the corresponding target dtypes, and applies the\n        mapping to create a new DataFrame with updated dtypes.\n\n        :param df: A Pandas DataFrame whose column dtypes will be transformed.\n        :type df: pd.DataFrame\n        :return: A new Pandas DataFrame with transformed column dtypes.\n        :rtype: pd.DataFrame\n        \"\"\"\n        pass\n\n    def _target_dtype_name(self, dtype_name: str) -> str:\n        pass\n\n    def _map_dtype_names(self, dtype_names: List[str]) -> List[str]:\n        pass\n"
            },
            {
                "file_path": "pandas_pyarrow/reverse_converter.py",
                "code": "class ReversePandasArrowConverter:\n    \"\"\"\n    ReversePandasArrowConverter manages the conversion of pyarrow-backed Pandas DataFrame dtypes\n    back to their Numpy/Pandas equivalents.\n\n    :param custom_mapper: Dictionary with key as the string-representation of the\n        Arrow-backed dtype, and value as the desired target dtype (e.g. \"object\", \"int64\", etc.).\n        This overrides default mapping returned by reverse_create_mapper().\n    :param default_target_type: Optional string specifying the default dtype to use\n        if no mapping is found for a specific dtype. Default is \"object\".\n\n    \"\"\"\n\n    def __init__(\n        self,\n        custom_mapper: Optional[Dict[str, str]] = None,\n        default_target_type: Optional[str] = \"object\",\n    ):\n        pass\n\n    def __call__(self, df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Maps the data types of a given pandas DataFrame to the target data types\n        specified by the object's internal mapping logic. This method processes\n        the DataFrame by replacing its column data types according to the mapped\n        target types and returns a new DataFrame with these updated data types.\n        Any `NaN` values are handled accordingly during the process.\n\n        :param df: A pandas DataFrame that is to be processed.\n        :type df: pd.DataFrame\n        :return: A new pandas DataFrame with updated column data types as per\n                 the mapping.\n        :rtype: pd.DataFrame\n        \"\"\"\n        pass\n\n    def _target_dtype_name(self, dtype_name: str) -> str:\n        pass\n\n    def _map_dtype_names(self, dtype_names: List[str]) -> List[str]:\n        pass\n"
            },
            {
                "file_path": "pandas_pyarrow/mappers/numeric_mapper.py",
                "code": "def create_type_variations(\n    source_types: List[str], filter_func: Callable[[str], bool], variations: List[str]\n) -> Dict[str, str]:\n    pass\n\ndef numeric_mapper(source_types: List[str], variations: List[str]) -> Dict[str, str]:\n    pass\n\ndef reverse_create_type_variations(\n    source_types: List[str], filter_func: Callable[[str], bool], variations: List[str]\n) -> Dict[str, str]:\n    pass\n\ndef reverse_numeric_mapper(source_types: List[str], variations: List[str]) -> Dict[str, str]:\n    pass\n"
            },
            {
                "file_path": "pandas_pyarrow/mappers/__init__.py",
                "code": "def create_mapper() -> Dict[str, str]:\n    pass\n\ndef reverse_create_mapper(\n    adapter: str = \"tz=\",\n) -> Dict[str, str]:\n    pass\n"
            },
            {
                "file_path": "pandas_pyarrow/mappers/datetime_mapper.py",
                "code": "def datetime_mapper(from_type: str = \"datetime64\", to_type: str = \"timestamp\") -> Dict[str, str]:\n    pass\n\ndef reverse_datetime_mapper(\n    from_type: str = \"timestamp\",\n    to_type: str = \"datetime64\",\n    adapter: str = \"tz=\",\n) -> Dict[str, str]:\n    pass\n"
            }
        ],
        "minimal_code_skeleton": "--- File: pandas_pyarrow/__init__.py ---\n```python\nfrom typing import Dict, List, Optional\n\nimport pandas as pd\n\ndef convert_to_pyarrow(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Dynamically assigned in the original __init__.py by PandasArrowConverter().__call__.\n    This skeleton provides a function signature for implementation.\n    \"\"\"\n    pass\n\ndef convert_to_numpy(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Dynamically assigned in the original __init__.py by ReversePandasArrowConverter().__call__.\n    This skeleton provides a function signature for implementation.\n    \"\"\"\n    pass\n\nclass PandasArrowConverter:\n    \"\"\"PandasArrowConverter manages the conversion of Pandas DataFrame data types to Arrow data types.\n    :param custom_mapper: dictionary with key as the source data type and value as the target data type.\n    Will override default mapping\n    :param default_target_type: Optional string specifying the default data type to use if no mapping is found for a\n    specific data type. Default is \"string[pyarrow]\".\n\n    \"\"\"\n    def __init__(self, custom_mapper: Optional[Dict[str, str]] = None, default_target_type: Optional[str] = \"string[pyarrow]\"):\n        pass\n\n    def __call__(self, df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Apply a transformation to the dtypes of a Pandas DataFrame based on a mapping.\n\n        The function adjusts the data types of the columns in the provided DataFrame.\n        It uses the current dtypes of the DataFrame columns, processes them through\n        a mapping function to get the corresponding target dtypes, and applies the\n        mapping to create a new DataFrame with updated dtypes.\n\n        :param df: A Pandas DataFrame whose column dtypes will be transformed.\n        :type df: pd.DataFrame\n        :return: A new Pandas DataFrame with transformed column dtypes.\n        :rtype: pd.DataFrame\n        \"\"\"\n        pass\n```\n--- File: pandas_pyarrow/mappers/__init__.py ---\n```python\nfrom typing import Dict, List\n\ndef create_mapper() -> Dict[str, str]:\n    pass\n\ndef reverse_create_mapper(adapter: str = \"tz=\") -> Dict[str, str]:\n    pass\n\ndef numeric_mapper(source_types: List[str], variations: List[str]) -> Dict[str, str]:\n    pass\n\ndef datetime_mapper(from_type: str = \"datetime64\", to_type: str = \"timestamp\") -> Dict[str, str]:\n    pass\n\nmapper_db_types: Dict[str, str] = {\n    \"dbdate\": \"date32[pyarrow]\",\n    \"dbtime\": \"time64[us][pyarrow]\",\n}\n```\n--- File: pandas_pyarrow/pda_converter.py ---\n```python\nfrom typing import Dict, List, Optional\n\nimport pandas as pd\n\nclass PandasArrowConverter:\n    \"\"\"PandasArrowConverter manages the conversion of Pandas DataFrame data types to Arrow data types.\n    :param custom_mapper: dictionary with key as the source data type and value as the target data type.\n    Will override default mapping\n    :param default_target_type: Optional string specifying the default data type to use if no mapping is found for a\n    specific data type. Default is \"string[pyarrow]\".\n\n    \"\"\"\n    def __init__(self, custom_mapper: Optional[Dict[str, str]] = None, default_target_type: Optional[str] = \"string[pyarrow]\"):\n        pass\n\n    def __call__(self, df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Apply a transformation to the dtypes of a Pandas DataFrame based on a mapping.\n\n        The function adjusts the data types of the columns in the provided DataFrame.\n        It uses the current dtypes of the DataFrame columns, processes them through\n        a mapping function to get the corresponding target dtypes, and applies the\n        mapping to create a new DataFrame with updated dtypes.\n\n        :param df: A Pandas DataFrame whose column dtypes will be transformed.\n        :type df: pd.DataFrame\n        :return: A new Pandas DataFrame with transformed column dtypes.\n        :rtype: pd.DataFrame\n        \"\"\"\n        pass\n```",
        "minimal_code_skeleton_structured": [
            {
                "file_path": "pandas_pyarrow/__init__.py",
                "code": "from typing import Dict, List, Optional\n\nimport pandas as pd\n\ndef convert_to_pyarrow(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Dynamically assigned in the original __init__.py by PandasArrowConverter().__call__.\n    This skeleton provides a function signature for implementation.\n    \"\"\"\n    pass\n\ndef convert_to_numpy(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Dynamically assigned in the original __init__.py by ReversePandasArrowConverter().__call__.\n    This skeleton provides a function signature for implementation.\n    \"\"\"\n    pass\n\nclass PandasArrowConverter:\n    \"\"\"PandasArrowConverter manages the conversion of Pandas DataFrame data types to Arrow data types.\n    :param custom_mapper: dictionary with key as the source data type and value as the target data type.\n    Will override default mapping\n    :param default_target_type: Optional string specifying the default data type to use if no mapping is found for a\n    specific data type. Default is \"string[pyarrow]\".\n\n    \"\"\"\n    def __init__(self, custom_mapper: Optional[Dict[str, str]] = None, default_target_type: Optional[str] = \"string[pyarrow]\"):\n        pass\n\n    def __call__(self, df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Apply a transformation to the dtypes of a Pandas DataFrame based on a mapping.\n\n        The function adjusts the data types of the columns in the provided DataFrame.\n        It uses the current dtypes of the DataFrame columns, processes them through\n        a mapping function to get the corresponding target dtypes, and applies the\n        mapping to create a new DataFrame with updated dtypes.\n\n        :param df: A Pandas DataFrame whose column dtypes will be transformed.\n        :type df: pd.DataFrame\n        :return: A new Pandas DataFrame with transformed column dtypes.\n        :rtype: pd.DataFrame\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "pandas_pyarrow/mappers/__init__.py",
                "code": "from typing import Dict, List\n\ndef create_mapper() -> Dict[str, str]:\n    pass\n\ndef reverse_create_mapper(adapter: str = \"tz=\") -> Dict[str, str]:\n    pass\n\ndef numeric_mapper(source_types: List[str], variations: List[str]) -> Dict[str, str]:\n    pass\n\ndef datetime_mapper(from_type: str = \"datetime64\", to_type: str = \"timestamp\") -> Dict[str, str]:\n    pass\n\nmapper_db_types: Dict[str, str] = {\n    \"dbdate\": \"date32[pyarrow]\",\n    \"dbtime\": \"time64[us][pyarrow]\",\n}\n"
            },
            {
                "file_path": "pandas_pyarrow/pda_converter.py",
                "code": "from typing import Dict, List, Optional\n\nimport pandas as pd\n\nclass PandasArrowConverter:\n    \"\"\"PandasArrowConverter manages the conversion of Pandas DataFrame data types to Arrow data types.\n    :param custom_mapper: dictionary with key as the source data type and value as the target data type.\n    Will override default mapping\n    :param default_target_type: Optional string specifying the default data type to use if no mapping is found for a\n    specific data type. Default is \"string[pyarrow]\".\n\n    \"\"\"\n    def __init__(self, custom_mapper: Optional[Dict[str, str]] = None, default_target_type: Optional[str] = \"string[pyarrow]\"):\n        pass\n\n    def __call__(self, df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Apply a transformation to the dtypes of a Pandas DataFrame based on a mapping.\n\n        The function adjusts the data types of the columns in the provided DataFrame.\n        It uses the current dtypes of the DataFrame columns, processes them through\n        a mapping function to get the corresponding target dtypes, and applies the\n        mapping to create a new DataFrame with updated dtypes.\n\n        :param df: A Pandas DataFrame whose column dtypes will be transformed.\n        :type df: pd.DataFrame\n        :return: A new Pandas DataFrame with transformed column dtypes.\n        :rtype: pd.DataFrame\n        \"\"\"\n        pass\n"
            }
        ],
        "minimal_test_cases": [
            {
                "test_id": "tests/docs/test_docs.py::test_doc_examples[/testbed/docs/source/usage.rst-110-example0]",
                "covers": [
                    "pandas_pyarrow.PandasArrowConverter.__init__ - default arguments, happy path",
                    "pandas_pyarrow.PandasArrowConverter.__call__ - basic conversion following instantiation, happy path",
                    "pandas_pyarrow.ReversePandasArrowConverter.__init__ - default arguments, happy path",
                    "pandas_pyarrow.ReversePandasArrowConverter.__call__ - basic reverse conversion following instantiation, happy path"
                ]
            },
            {
                "test_id": "tests/unit/test_add_dtypes_mapper_types.py::test_add_dtypes_types[test simple type mapping override with additional_mapper_dicts ns]",
                "covers": [
                    "pandas_pyarrow.PandasArrowConverter.__init__ - with custom_mapper argument, happy path",
                    "pandas_pyarrow.PandasArrowConverter.__call__ - conversion following instantiation with custom_mapper, happy path"
                ]
            },
            {
                "test_id": "tests/docs/test_docs.py::test_doc_examples[/testbed/docs/source/usage.rst-628-example1]",
                "covers": [
                    "pandas_pyarrow.convert_to_pyarrow - functional API for conversion, happy path",
                    "pandas_pyarrow.convert_to_numpy - functional API for reverse conversion, happy path"
                ]
            },
            {
                "test_id": "tests/unit/test_dtype_exists.py::test_str_dtypes_pyarrow",
                "covers": [
                    "pandas_pyarrow.mappers.create_mapper - basic usage for map creation, happy path",
                    "pandas_pyarrow.mappers.reverse_create_mapper - usage with default adapter for reverse map creation, happy path"
                ]
            },
            {
                "test_id": "tests/unit/property_based/test_dt.py::test_datetime_pb_ns",
                "covers": [
                    "pandas_pyarrow.mappers.datetime_mapper - default arguments usage for test data generation"
                ]
            },
            {
                "test_id": "tests/unit/property_based/test_numeric.py::test_float_numpy_api_hp",
                "covers": [
                    "pandas_pyarrow.mappers.numeric_mapper - usage with specific arguments for test data generation"
                ]
            }
        ]
    },
    {
        "idx": 92551,
        "repo_name": "yezz123_pgqb",
        "url": "https://github.com/yezz123/pgqb",
        "description": "Typed Python PostgreSQL query builder ",
        "stars": 7,
        "forks": 0,
        "language": "python",
        "size": 205,
        "created_at": "2024-03-05T22:45:34+00:00",
        "updated_at": "2024-12-30T22:29:18+00:00",
        "pypi_info": {
            "name": "pgqb",
            "version": "0.1.0",
            "url": "https://files.pythonhosted.org/packages/c9/aa/6866a4702ff0436f182d0406ca43dbf682867ad104ddd6a0254af98adaac/pgqb-0.1.0.tar.gz"
        },
        "judge_info": {
            "language": "python",
            "is_good_project": false,
            "reason": "",
            "python_file_num": 8,
            "comment_ratio": 0.34641407307171856,
            "pyfile_content_length": 62517,
            "pyfile_code_lines": 2217,
            "test_file_exist": true,
            "test_file_content_length": 15356,
            "pytest_framework": true,
            "test_case_num": 19,
            "metadata_path": [
                "pyproject.toml"
            ],
            "readme_content_length": 3514,
            "llm_reason": "The project, pgqb, is a Python library for building PostgreSQL SQL queries. It is a strong candidate for an AI 'Build from Scratch' benchmark.\n\nPositive Aspects:\n*   **Self-Contained & Independent:** The core functionality of building SQL query strings does not require internet access, external APIs, or a running database. The AI-rebuilt solution would generate strings, which can be tested independently.\n*   **Clear & Well-Defined Functionality:** The goal is to create a Pythonic API that generates SQL queries. The README and existing code provide a clear specification of this API and its behavior.\n*   **Testable & Verifiable Output:** The project includes a comprehensive test suite (`test_builder.py`, `test_types.py`, `test_snake.py`) that primarily asserts the correctness of generated SQL strings and parameters. These tests can be directly used to verify the AI's output.\n*   **No Graphical User Interface (GUI):** It is a library, and interactions are through Python code (imports and method calls).\n*   **Well-Understood Problem Domain:** SQL query building is a common and well-understood problem in software development.\n*   **Predominantly Code-Based Solution:** The task is entirely about generating Python code for the library.\n*   **Manageable Dependencies:** The core library appears to have no external runtime dependencies beyond the Python standard library for its query-building logic.\n\nNegative Aspects or Concerns:\n*   **Moderate Complexity:** While not excessively complex, replicating the entire query builder involves a significant number of interacting classes and methods (e.g., for SELECT, INSERT, UPDATE, DELETE, JOINs, WHERE clauses, expressions, table/column definitions, and PostgreSQL-specific types). The `builder.py` file, in particular, has a rich object model. This makes the task a solid 'Medium' difficulty, requiring the AI to manage relationships between these components correctly.\n*   **Specificity to PostgreSQL:** The library targets PostgreSQL, so the AI would need to generate SQL syntax specific to it (e.g., data types, quoting). This adds a layer of detail.\n*   **Scope:** Replicating all features, including the extensive list of PostgreSQL types in `types.py` and all query construction capabilities shown in tests, constitutes a moderately sized project for an AI to generate from scratch.\n\nOverall, the project's clear scope, excellent testability, and self-contained nature make it a very good candidate. The 'Medium' difficulty is appropriate for a challenging yet achievable benchmark task.",
            "llm_project_type": "SQL Query Builder Library",
            "llm_rating": 80,
            "llm_difficulty": "Medium"
        },
        "tests": {
            "repo_name": "yezz123_pgqb",
            "finish_test": true,
            "test_case_result": {
                "tests/test_builder.py::test_select": "passed",
                "tests/test_builder.py::test_select_columns": "passed",
                "tests/test_builder.py::test_insert": "passed",
                "tests/test_builder.py::test_insert_str_columns": "passed",
                "tests/test_builder.py::test_expressions": "passed",
                "tests/test_builder.py::test_operators": "passed",
                "tests/test_builder.py::test_operators_chained": "xfailed",
                "tests/test_builder.py::test_update": "passed",
                "tests/test_builder.py::test_update_str_columns": "passed",
                "tests/test_builder.py::test_delete": "passed",
                "tests/test_snake.py::test_get_words[PotatoHumanAlien-expected_output0]": "passed",
                "tests/test_snake.py::test_get_words[Potato.Human.Alien-expected_output1]": "passed",
                "tests/test_snake.py::test_get_words[Potato-Human-Alien-expected_output2]": "passed",
                "tests/test_snake.py::test_get_words[Potato/Human/Alien-expected_output3]": "passed",
                "tests/test_snake.py::test_get_words[Potato_Human_Alien-expected_output4]": "passed",
                "tests/test_snake.py::test_get_words[Potato Human Alien-expected_output5]": "passed",
                "tests/test_snake.py::test_get_words[Honey-expected_output6]": "passed",
                "tests/test_snake.py::test_get_words[DING-expected_output7]": "passed",
                "tests/test_snake.py::test_get_words[-expected_output8]": "passed",
                "tests/test_snake.py::test_get_words[orange beer-PotatoAlien_food.yummy/honey-expected_output9]": "passed",
                "tests/test_snake.py::test_get_words[HumanNAMEDJason-expected_output10]": "passed",
                "tests/test_snake.py::test_to_snake[PotatoHumanAlien-potato_human_alien]": "passed",
                "tests/test_snake.py::test_to_snake[Potato.Human.Alien-potato_human_alien]": "passed",
                "tests/test_snake.py::test_to_snake[Potato-Human-Alien-potato_human_alien]": "passed",
                "tests/test_snake.py::test_to_snake[Potato/Human/Alien-potato_human_alien]": "passed",
                "tests/test_snake.py::test_to_snake[Potato_Human_Alien-potato_human_alien]": "passed",
                "tests/test_snake.py::test_to_snake[Potato Human Alien-potato_human_alien]": "passed",
                "tests/test_snake.py::test_to_snake[Honey-honey]": "passed",
                "tests/test_snake.py::test_to_snake[DING-ding]": "passed",
                "tests/test_snake.py::test_to_snake[-]": "passed",
                "tests/test_snake.py::test_to_snake[orange beer-PotatoAlien_food.yummy/honey-orange_beer_potato_alien_food_yummy_honey]": "passed",
                "tests/test_snake.py::test_to_snake[HumanNAMEDJason-human_named_jason]": "passed",
                "tests/test_snake.py::test_split_words_on_regex_happy_path[words0-\\\\s-expected0]": "passed",
                "tests/test_snake.py::test_split_words_on_regex_happy_path[words1---expected1]": "passed",
                "tests/test_snake.py::test_split_words_on_regex_happy_path[words2-,-expected2]": "passed",
                "tests/test_snake.py::test_split_words_on_regex_happy_path[words3-\\\\|-expected3]": "passed",
                "tests/test_snake.py::test_split_words_on_regex_edge_cases[words0-\\\\s-expected0]": "passed",
                "tests/test_snake.py::test_split_words_on_regex_edge_cases[words1-\\\\s-expected1]": "passed",
                "tests/test_snake.py::test_split_words_on_regex_error_cases[words0-None-TypeError]": "passed",
                "tests/test_snake.py::test_split_words_on_regex_error_cases[words1-123-TypeError]": "passed",
                "tests/test_types.py::test_create_table": "passed",
                "tests/test_types.py::test_type_options": "passed",
                "tests/test_types.py::test_column_options": "passed",
                "tests/test_types.py::test_enum": "passed"
            },
            "success_count": 44,
            "failed_count": 0,
            "error_count": 0,
            "skipped_count": 0,
            "unknown_count": 0,
            "total_count": 44,
            "success_rate": 1.0,
            "coverage_report": {
                "covered_lines": 507,
                "num_statements": 513,
                "percent_covered": 98.34710743801652,
                "percent_covered_display": "98",
                "missing_lines": 6,
                "excluded_lines": 4,
                "num_branches": 92,
                "num_partial_branches": 4,
                "covered_branches": 88,
                "missing_branches": 4
            },
            "coverage_result": {}
        },
        "codelines_count": 2217,
        "codefiles_count": 8,
        "code_length": 62517,
        "test_files_count": 3,
        "test_code_length": 15356,
        "class_diagram": "@startuml\nclass MyEnum {\n    OPTION: Unknown\n}\nclass User {\n    id: Column\n    bigint: Column\n    bigserial: Column\n    bit: Column\n    varbit: Column\n    boolean: Column\n    box: Column\n    bytea: Column\n    char: Column\n    varchar: Column\n    cidr: Column\n    circle: Column\n    date: Column\n    double: Column\n    inet: Column\n    integer: Column\n    interval: Column\n    json: Column\n    jsonb: Column\n    line: Column\n    lseg: Column\n    macaddr: Column\n    macaddr8: Column\n    money: Column\n    numeric: Column\n    path: Column\n    pg_lsn: Column\n    pg_snapshot: Column\n    point: Column\n    polygon: Column\n    real: Column\n    smallint: Column\n    smallserial: Column\n    serial: Column\n    text: Column\n    time: Column\n    timestamp: Column\n    tsquery: Column\n    tsvector: Column\n    uuid: Column\n    xml: Column\n}\nclass Task {\n    id: Column\n    user_id: Column\n    value: Column\n}\nclass TypeOptionsTable {\n    char: Column\n    varchar: Column\n    interval: Column\n    numeric: Column\n    numeric_two: Column\n    time: Column\n    timestamp: Column\n}\nclass ColumnOptionsTable {\n    integer: Column\n    fk: Column\n    fk2: Column\n}\nclass PGEnum {\n    pg_enum_name(cls): str\n    pg_enum_get_create(cls): str\n}\nclass SQLType {\n    __str__(): str\n}\nclass BIGINT {\n}\nclass BIGSERIAL {\n}\nclass BIT {\n}\nclass VARBIT {\n}\nclass BOOLEAN {\n}\nclass BOX {\n}\nclass BYTEA {\n}\nclass CHAR {\n    __init__(fixed_length): Unknown\n    __str__(): str\n}\nclass VARCHAR {\n    __init__(variable_length): Unknown\n    __str__(): str\n}\nclass CIDR {\n}\nclass CIRCLE {\n}\nclass DATE {\n}\nclass DOUBLE {\n    __str__(): str\n}\nclass INET {\n}\nclass INTEGER {\n}\nclass INTERVAL {\n    __init__(fields, precision): Unknown\n    __str__(): str\n}\nclass JSON {\n}\nclass JSONB {\n}\nclass LINE {\n}\nclass LSEG {\n}\nclass MACADDR {\n}\nclass MACADDR8 {\n}\nclass MONEY {\n}\nclass NUMERIC {\n    __init__(precision, scale): Unknown\n    __str__(): str\n}\nclass PATH {\n}\nclass PG_LSN {\n}\nclass PG_SNAPSHOT {\n}\nclass POINT {\n}\nclass POLYGON {\n}\nclass REAL {\n}\nclass SMALLINT {\n}\nclass SMALLSERIAL {\n}\nclass SERIAL {\n}\nclass TEXT {\n}\nclass TIME {\n    __init__(precision): Unknown\n    __str__(): str\n}\nclass TIMESTAMP {\n    __init__(precision): Unknown\n    __str__(): str\n}\nclass TSQUERY {\n}\nclass TSVECTOR {\n}\nclass UUID {\n}\nclass XML {\n}\nclass QueryBuilder {\n    prepare(): tuple[str, list[Any]]\n}\nclass _OperatorMixin {\n    __gt__(other): Expression\n    __ge__(other): Expression\n    __lt__(other): Expression\n    __le__(other): Expression\n    __eq__(other): Expression\n    __ne__(other): Expression\n    __add__(other): Expression\n    __sub__(other): Expression\n    __mul__(other): Expression\n    __truediv__(other): Expression\n    __mod__(other): Expression\n    is_(other): Expression\n    is_not(other): Expression\n}\nclass As {\n    __init__(sub_query, alias): Unknown\n    prepare(): tuple[str, list[Any]]\n}\nclass Column {\n    __init__(sql_type): Unknown\n    __str__(): str\n    __hash__(): int\n    _create(): str\n    prepare(): tuple[str, list[Any]]\n    as_(alias): As\n    asc(): Column\n    desc(): Column\n    asc_or_desc(asc): Column\n}\nclass Table {\n    __table_name__: Unknown\n    __table_columns__: dict[str, Column]\n    __init_subclass__(cls): Unknown\n    create_table(cls): str\n}\nclass _LimitMixin {\n    limit(limit): Limit\n}\nclass _OffsetMixin {\n    offset(offset): Offset\n}\nclass _PaginateMixin {\n}\nclass _OrderByMixin {\n    order_by(): OrderBy\n}\nclass _WhereMixin {\n    where(evaluation): Where\n}\nclass BooleanOperator {\n    AND: Unknown\n    AND_NOT: Unknown\n    OR: Unknown\n    OR_NOT: Unknown\n    IS: Unknown\n    IS_NOT: Unknown\n    IN: Unknown\n    NOT_IN: Unknown\n}\nclass LogicGate {\n    __init__(boolean_operator, evaluation): Unknown\n    prepare(): tuple[str, list[Any]]\n}\nclass Expression {\n    __init__(left_operand, operator, right_operand): Unknown\n    as_(alias): As\n    prepare(): tuple[str, list[Any]]\n}\nclass Join {\n    __init__(table): Unknown\n    prepare(): tuple[str, list[Any]]\n    on(): Self\n}\nclass LeftJoin {\n    __init__(table): Unknown\n}\nclass RightJoin {\n    __init__(table): Unknown\n}\nclass Limit {\n    __init__(subquery, limit): Unknown\n    prepare(): tuple[str, list[Any]]\n}\nclass Offset {\n    __init__(subquery, offset): Unknown\n    prepare(): tuple[str, list[Any]]\n}\nclass On {\n    __init__(): Unknown\n    prepare(): tuple[str, list[Any]]\n}\nclass From {\n    __init__(select, table): Unknown\n    prepare(): tuple[str, list[Any]]\n}\nclass OrderBy {\n    __init__(subquery): Unknown\n    prepare(): tuple[str, list[Any]]\n}\nclass Values {\n    __init__(subquery, values): Unknown\n    prepare(): tuple[str, list[Any]]\n}\nclass Where {\n    __init__(subquery): Unknown\n    prepare(): tuple[str, list[Any]]\n}\nclass Set {\n    __init__(subquery, values): Unknown\n    prepare(): tuple[str, list[Any]]\n}\nclass InsertInto {\n    __init__(table): Unknown\n    prepare(): tuple[str, list[Any]]\n    values(values): Values\n}\nclass Delete {\n    __init__(table): Unknown\n    prepare(): tuple[str, list[Any]]\n}\nclass Select {\n    __init__(): Unknown\n    prepare(): tuple[str, list[Any]]\n    from_(table): From\n}\nclass Update {\n    __init__(table): Unknown\n    set(values): Set\n    prepare(): tuple[str, list[Any]]\n}\n_PaginateMixin <|-- OrderBy\n_WhereMixin <|-- From\nUser --> Column\nSQLType <|-- TSQUERY\nSQLType <|-- BIGSERIAL\nJoin --> On\nSQLType <|-- DOUBLE\n_OffsetMixin --> Offset\nQueryBuilder <|-- LogicGate\n_WhereMixin <|-- Set\nSQLType <|-- BOX\nQueryBuilder <|-- As\nSQLType <|-- CIRCLE\nColumn --> As\nSQLType <|-- TIME\nQueryBuilder <|-- _LimitMixin\nTable <|-- ColumnOptionsTable\nExpression --> As\nSQLType <|-- BIT\nSQLType <|-- UUID\nSQLType <|-- VARCHAR\nQueryBuilder <|-- InsertInto\nSQLType <|-- INTEGER\nQueryBuilder <|-- _OrderByMixin\nSQLType <|-- XML\nSQLType <|-- BYTEA\nQueryBuilder <|-- Update\nQueryBuilder <|-- _WhereMixin\nQueryBuilder <|-- _OffsetMixin\n_OperatorMixin <|-- Column\nTable <|-- TypeOptionsTable\nTable <|-- User\nSQLType <|-- LINE\nInsertInto --> Values\nValues --> InsertInto\nLimit --> QueryBuilder\n_OffsetMixin <|-- _PaginateMixin\nSQLType <|-- POLYGON\n_PaginateMixin <|-- Where\n_PaginateMixin <|-- On\nSQLType <|-- NUMERIC\nSQLType <|-- MONEY\nSQLType <|-- INET\nSQLType <|-- JSON\nQueryBuilder <|-- Values\n_OffsetMixin <|-- Limit\nQueryBuilder <|-- Offset\nTask --> Column\nTypeOptionsTable --> Column\nQueryBuilder <|-- Join\nSQLType <|-- PG_LSN\nQueryBuilder <|-- Select\nSQLType <|-- JSONB\nSQLType <|-- TIMESTAMP\nSQLType <|-- POINT\n_LimitMixin --> Limit\n_OperatorMixin <|-- Expression\nSQLType <|-- MACADDR\nSQLType <|-- REAL\nSQLType <|-- BIGINT\nSQLType <|-- PG_SNAPSHOT\nSQLType <|-- MACADDR8\n_WhereMixin --> Expression\nJoin <|-- RightJoin\nSQLType <|-- LSEG\nSQLType <|-- SMALLINT\n_PaginateMixin <|-- From\n_OrderByMixin --> OrderBy\nTable <|-- Task\n_OperatorMixin --> Expression\nOffset --> QueryBuilder\nColumn --> Column\nSQLType <|-- TEXT\nSQLType <|-- VARBIT\nQueryBuilder <|-- _OperatorMixin\n_WhereMixin --> Where\nSQLType <|-- PATH\nLogicGate --> BooleanOperator\nSQLType <|-- BOOLEAN\nSQLType <|-- CHAR\nSQLType <|-- INTERVAL\nSet --> Update\nColumnOptionsTable --> Column\nFrom --> Select\nSQLType <|-- DATE\n_OrderByMixin <|-- Where\nSQLType <|-- CIDR\nSelect --> From\nLogicGate --> Expression\n_WhereMixin <|-- Delete\nSQLType <|-- TSVECTOR\n_LimitMixin <|-- _PaginateMixin\nUpdate --> Set\nSQLType <|-- SERIAL\nSQLType <|-- SMALLSERIAL\nJoin <|-- LeftJoin\nLimit ..> QueryBuilder\nInsertInto ..> Values\nColumn ..> As\n_OffsetMixin ..> Offset\nSet ..> Update\nExpression ..> As\nLogicGate ..> Expression\nTypeOptionsTable ..> Column\nJoin ..> On\nLogicGate ..> BooleanOperator\n_OrderByMixin ..> OrderBy\n_OperatorMixin ..> Expression\nValues ..> InsertInto\nUpdate ..> Set\nTask ..> Column\nFrom ..> Select\nOffset ..> QueryBuilder\n_WhereMixin ..> Expression\n_WhereMixin ..> Where\n_LimitMixin ..> Limit\nColumnOptionsTable ..> Column\nSelect ..> From\nUser ..> Column\nColumn ..> Column\n@enduml",
        "structure": [
            {
                "file": "tests/test_builder.py",
                "functions": [
                    {
                        "name": "test_select",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_select_columns",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_insert",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_insert_str_columns",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_expressions",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_operators",
                        "docstring": null,
                        "comments": "noinspection PyComparisonWithNone",
                        "args": []
                    },
                    {
                        "name": "test_operators_chained",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_update",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_update_str_columns",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_delete",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": [
                    {
                        "name": "MyEnum",
                        "docstring": "Test enum.",
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "OPTION"
                        ]
                    },
                    {
                        "name": "User",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "id",
                            "first",
                            "last"
                        ]
                    },
                    {
                        "name": "Task",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "id",
                            "user_id",
                            "value"
                        ]
                    }
                ]
            },
            {
                "file": "tests/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/test_snake.py",
                "functions": [
                    {
                        "name": "test_get_words",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "input_str",
                            "expected_output"
                        ]
                    },
                    {
                        "name": "test_to_snake",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "input_str",
                            "expected_output"
                        ]
                    },
                    {
                        "name": "test_split_words_on_regex_happy_path",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "words",
                            "regex",
                            "expected"
                        ]
                    },
                    {
                        "name": "test_split_words_on_regex_edge_cases",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "words",
                            "regex",
                            "expected"
                        ]
                    },
                    {
                        "name": "test_split_words_on_regex_error_cases",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "words",
                            "regex",
                            "expected_exception"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_types.py",
                "functions": [
                    {
                        "name": "test_create_table",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_type_options",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_column_options",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_enum",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": [
                    {
                        "name": "User",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "id",
                            "bigint",
                            "bigserial",
                            "bit",
                            "varbit",
                            "boolean",
                            "box",
                            "bytea",
                            "char",
                            "varchar",
                            "cidr",
                            "circle",
                            "date",
                            "double",
                            "inet",
                            "integer",
                            "interval",
                            "json",
                            "jsonb",
                            "line",
                            "lseg",
                            "macaddr",
                            "macaddr8",
                            "money",
                            "numeric",
                            "path",
                            "pg_lsn",
                            "pg_snapshot",
                            "point",
                            "polygon",
                            "real",
                            "smallint",
                            "smallserial",
                            "serial",
                            "text",
                            "time",
                            "timestamp",
                            "tsquery",
                            "tsvector",
                            "uuid",
                            "xml"
                        ]
                    },
                    {
                        "name": "TypeOptionsTable",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "char",
                            "varchar",
                            "interval",
                            "numeric",
                            "numeric_two",
                            "time",
                            "timestamp"
                        ]
                    },
                    {
                        "name": "ColumnOptionsTable",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "integer",
                            "fk",
                            "fk2"
                        ]
                    },
                    {
                        "name": "MyE",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "A",
                            "B"
                        ]
                    },
                    {
                        "name": "UsesEnum",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "col"
                        ]
                    }
                ]
            },
            {
                "file": "pgqb/__init__.py",
                "functions": [
                    {
                        "name": "insert_into",
                        "docstring": "Build an insert query.",
                        "comments": null,
                        "args": [
                            "table"
                        ]
                    },
                    {
                        "name": "delete_from",
                        "docstring": "Build a delete query.",
                        "comments": null,
                        "args": [
                            "table"
                        ]
                    },
                    {
                        "name": "select",
                        "docstring": "Build a select query.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "update",
                        "docstring": "Build an update query.",
                        "comments": null,
                        "args": [
                            "table"
                        ]
                    },
                    {
                        "name": "join",
                        "docstring": "Build a join query.",
                        "comments": null,
                        "args": [
                            "table"
                        ]
                    },
                    {
                        "name": "left_join",
                        "docstring": "Build a left join query.",
                        "comments": null,
                        "args": [
                            "table"
                        ]
                    },
                    {
                        "name": "right_join",
                        "docstring": "Build a right join query.",
                        "comments": null,
                        "args": [
                            "table"
                        ]
                    },
                    {
                        "name": "on",
                        "docstring": "Build an \"on\" query for a join.",
                        "comments": null,
                        "args": [
                            "evaluation"
                        ]
                    },
                    {
                        "name": "and_",
                        "docstring": "Build an \"and\" expression for a part of a query.",
                        "comments": null,
                        "args": [
                            "evaluation"
                        ]
                    },
                    {
                        "name": "and_not",
                        "docstring": "Build an \"and not\" expression for a part of a query.",
                        "comments": null,
                        "args": [
                            "evaluation"
                        ]
                    },
                    {
                        "name": "or_",
                        "docstring": "Build an \"or\" expression for a part of a query.",
                        "comments": null,
                        "args": [
                            "evaluation"
                        ]
                    },
                    {
                        "name": "or_not",
                        "docstring": "Build an \"or not\" expression for a part of a query.",
                        "comments": null,
                        "args": [
                            "evaluation"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "pgqb/_snake.py",
                "functions": [
                    {
                        "name": "to_snake",
                        "docstring": "Return a version of the string in `snake_case` format.\n\nArgs:\n    string: The string to convert to snake_case.\n\nReturns:\n    The string in snake_case format.",
                        "comments": null,
                        "args": [
                            "string"
                        ]
                    },
                    {
                        "name": "get_words",
                        "docstring": "Get a list of the words in a string in the order they appear.\n\nArgs:\n    string: The string to get the words from.\n\nReturns:\n    A list of the words in the string.",
                        "comments": null,
                        "args": [
                            "string"
                        ]
                    },
                    {
                        "name": "_split_words_on_regex",
                        "docstring": "Split words on a regex.\n\nArgs:\n    words (list[str]): The list of words to split.\n    regex (Union[Pattern, str]): The regex to split on.\n\nReturns:\n    list[str]: The list of words with the split words inserted.",
                        "comments": null,
                        "args": [
                            "words",
                            "regex"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "pgqb/types.py",
                "functions": [],
                "classes": [
                    {
                        "name": "PGEnum",
                        "docstring": "Enum type class.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "pg_enum_name",
                                "docstring": "Get the SQL name for this custom enum.\n\nArgs:\n    cls: The class to get the SQL name for.\n\nReturns:\n    str: The SQL name for this custom enum.",
                                "comments": null,
                                "args": [
                                    "cls"
                                ]
                            },
                            {
                                "name": "pg_enum_get_create",
                                "docstring": "Get create enum SQL.\n\nArgs:\n    cls: The class to get the create enum SQL for.\n\nReturns:\n    str: The create enum SQL.",
                                "comments": null,
                                "args": [
                                    "cls"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "SQLType",
                        "docstring": "Base SQL type class.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__str__",
                                "docstring": "Get the string representation of this column.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "BIGINT",
                        "docstring": "Signed eight-byte integer.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "BIGSERIAL",
                        "docstring": "Auto-incrementing eight-byte integer.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "BIT",
                        "docstring": "Fixed-length bit string.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "VARBIT",
                        "docstring": "Variable-length bit string.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "BOOLEAN",
                        "docstring": "Logical Boolean (true/false).",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "BOX",
                        "docstring": "Rectangular box on a plane.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "BYTEA",
                        "docstring": "Binary data (byte array).",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "CHAR",
                        "docstring": "Fixed-length character string.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Fixed-length character string.\n\nArgs:\n    fixed_length: The fixed length of the string.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "fixed_length"
                                ]
                            },
                            {
                                "name": "__str__",
                                "docstring": "Get the string representation of this column.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "VARCHAR",
                        "docstring": "Variable-length character string.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Variable-length character string.\n\nArgs:\n    variable_length: The variable length of the string.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "variable_length"
                                ]
                            },
                            {
                                "name": "__str__",
                                "docstring": "Get the string representation of this column.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "CIDR",
                        "docstring": "IPv4 or IPv6 network address.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "CIRCLE",
                        "docstring": "Circle on a plane.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "DATE",
                        "docstring": "Calendar date (year, month, day).",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "DOUBLE",
                        "docstring": "Double precision floating-point number (8 bytes).",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__str__",
                                "docstring": "Get the string representation of this column.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "INET",
                        "docstring": "IPv4 or IPv6 host address.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "INTEGER",
                        "docstring": "Signed four-byte integer.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "INTERVAL",
                        "docstring": "Time span.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Time span.\n\nArgs:\n    fields: The fields of the interval.\n    precision: The precision of the interval.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "fields",
                                    "precision"
                                ]
                            },
                            {
                                "name": "__str__",
                                "docstring": "Get the string representation of this column.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "JSON",
                        "docstring": "Textual JSON data.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "JSONB",
                        "docstring": "Binary JSON data, decomposed.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "LINE",
                        "docstring": "Infinite line on a plane.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "LSEG",
                        "docstring": "Line segment on a plane.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "MACADDR",
                        "docstring": "MAC (Media Access Control) address.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "MACADDR8",
                        "docstring": "MAC (Media Access Control) address (EUI-64 format).",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "MONEY",
                        "docstring": "Currency amount.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "NUMERIC",
                        "docstring": "Exact numeric of selectable precision.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Exact numeric of selectable precision.\n\nArgs:\n    precision: The precision of the numeric.\n    scale: The scale of the numeric.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "precision",
                                    "scale"
                                ]
                            },
                            {
                                "name": "__str__",
                                "docstring": "Get the string representation of this column.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "PATH",
                        "docstring": "Geometric path on a plane.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "PG_LSN",
                        "docstring": "PostgreSQL Log Sequence Number.",
                        "comments": "noinspection PyPep8Naming",
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "PG_SNAPSHOT",
                        "docstring": "User-level transaction ID snapshot.",
                        "comments": "noinspection PyPep8Naming",
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "POINT",
                        "docstring": "Geometric point on a plane.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "POLYGON",
                        "docstring": "Closed geometric path on a plane.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "REAL",
                        "docstring": "Single precision floating-point number (4 bytes).",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "SMALLINT",
                        "docstring": "Signed two-byte integer.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "SMALLSERIAL",
                        "docstring": "Auto-incrementing two-byte integer.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "SERIAL",
                        "docstring": "Auto-incrementing four-byte integer.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "TEXT",
                        "docstring": "Variable-length character string.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "TIME",
                        "docstring": "Time of day.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Time of day.\n\nArgs:\n    precision: The precision of the time.\n    with_time_zone: Whether to include the time zone.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "precision"
                                ]
                            },
                            {
                                "name": "__str__",
                                "docstring": "Get the string representation of this column.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TIMESTAMP",
                        "docstring": "Date and time.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Date and time.\n\nArgs:\n    precision: The precision of the timestamp.\n    with_time_zone: Whether to include the time zone.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "precision"
                                ]
                            },
                            {
                                "name": "__str__",
                                "docstring": "Get the string representation of this column.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TSQUERY",
                        "docstring": "Text search query.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "TSVECTOR",
                        "docstring": "Text search document.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "UUID",
                        "docstring": "Universally unique identifier.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "XML",
                        "docstring": "XML data.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "pgqb/builder.py",
                "functions": [
                    {
                        "name": "_prepare_expressions",
                        "docstring": "Prepare multiple expressions for use in a SQL query.\n\nThis function is used internally to combine multiple expressions or logic gates\ninto a single SQL string with associated parameters.\n\nArgs:\n    *expressions: The expressions or logic gates to prepare.\n\nReturns:\n    A tuple containing the combined SQL string and a list of all parameters.",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": [
                    {
                        "name": "QueryBuilder",
                        "docstring": "Base class for all query builders.\n\nThis abstract class defines the interface for all query builders in the system.\nAll specific query builder classes should inherit from this base class.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "prepare",
                                "docstring": "Get all params and the SQL string.\n\nReturns:\n    A tuple containing the SQL string and a list of parameters.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "_OperatorMixin",
                        "docstring": "Mixin class providing common SQL comparison and arithmetic operators.\n\nThis mixin adds methods for common SQL operators like >, <, =, !=, +, -, *, /, %.\nIt also includes IS and IS NOT operators.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__gt__",
                                "docstring": "Greater than operator.\n\nArgs:\n    other: The value to compare against.\n\nReturns:\n    An Expression representing the \"greater than\" comparison.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "__ge__",
                                "docstring": "Greater than or equal to operator.\n\nArgs:\n    other: The value to compare against.\n\nReturns:\n    An Expression representing the \"greater than or equal to\" comparison.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "__lt__",
                                "docstring": "Less than operator.\n\nArgs:\n    other: The value to compare against.\n\nReturns:\n    An Expression representing the \"less than\" comparison.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "__le__",
                                "docstring": "Less than or equal to operator.\n\nArgs:\n    other: The value to compare against.\n\nReturns:\n    An Expression representing the \"less than or equal to\" comparison.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "__eq__",
                                "docstring": "Equality operator.\n\nFor None, True, or False, uses IS operator instead of =.\n\nArgs:\n    other: The value to compare against.\n\nReturns:\n    An Expression representing the equality comparison.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "__ne__",
                                "docstring": "Inequality operator.\n\nFor None, True, or False, uses IS NOT operator instead of !=.\n\nArgs:\n    other: The value to compare against.\n\nReturns:\n    An Expression representing the inequality comparison.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "__add__",
                                "docstring": "Addition operator.\n\nArgs:\n    other: The value to add.\n\nReturns:\n    An Expression representing the addition operation.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "__sub__",
                                "docstring": "Subtraction operator.\n\nArgs:\n    other: The value to subtract.\n\nReturns:\n    An Expression representing the subtraction operation.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "__mul__",
                                "docstring": "Multiplication operator.\n\nArgs:\n    other: The value to multiply by.\n\nReturns:\n    An Expression representing the multiplication operation.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "__truediv__",
                                "docstring": "Division operator.\n\nArgs:\n    other: The value to divide by.\n\nReturns:\n    An Expression representing the division operation.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "__mod__",
                                "docstring": "Modulo operator.\n\nArgs:\n    other: The value to mod by.\n\nReturns:\n    An Expression representing the modulo operation.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "is_",
                                "docstring": "Equality operator using IS.\n\nArgs:\n    other: The value to compare against.\n\nReturns:\n    An Expression representing the IS comparison.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "is_not",
                                "docstring": "Inequality operator using IS NOT.\n\nArgs:\n    other: The value to compare against.\n\nReturns:\n    An Expression representing the IS NOT comparison.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "As",
                        "docstring": "Represents an SQL AS clause for aliasing.\n\nThis class is used to create aliases for columns or expressions in SQL queries.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize an As instance.\n\nArgs:\n    sub_query: The Column or Expression to be aliased.\n    alias: The alias name.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "sub_query",
                                    "alias"
                                ]
                            },
                            {
                                "name": "prepare",
                                "docstring": "Prepare the AS clause.\n\nReturns:\n    A tuple containing the SQL string for the AS clause and any parameters.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "Column",
                        "docstring": "Represents a column in a SQL table.\n\nThis class encapsulates the properties and behaviors of a database column,\nincluding its data type, constraints, and other attributes.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize a Column instance.\n\nArgs:\n    sql_type: The SQL type for this column.\n    check: The check constraint for this column.\n    default: The default value for this column.\n    foreign_key: The foreign key for this column.\n    index: Whether to create an index for this column.\n    null: Whether this column is nullable.\n    primary: Whether this column is a primary key.\n    unique: Whether this column is unique.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "sql_type"
                                ]
                            },
                            {
                                "name": "__str__",
                                "docstring": "Get the string representation of this column.\n\nReturns:\n    A string in the format \"table.column\".",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__hash__",
                                "docstring": "Get the hash of this column.\n\nReturns:\n    An integer hash value based on the string representation of the column.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "_create",
                                "docstring": "Get column create SQL.\n\nReturns:\n    A string containing the SQL definition for creating this column.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "prepare",
                                "docstring": "Get column as SQL.\n\nReturns:\n    A tuple containing the SQL string for this column and an empty list of parameters.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "as_",
                                "docstring": "Create an alias for this column.\n\nArgs:\n    alias: The alias name for the column.\n\nReturns:\n    An As instance representing the aliased column.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "alias"
                                ]
                            },
                            {
                                "name": "asc",
                                "docstring": "Set this column to be sorted in ascending order.\n\nReturns:\n    A new Column instance with ascending sort order.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "desc",
                                "docstring": "Set this column to be sorted in descending order.\n\nReturns:\n    A new Column instance with descending sort order.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "asc_or_desc",
                                "docstring": "Set this column to be sorted in ascending or descending order.\n\nArgs:\n    asc: True for ascending order, False for descending order.\n\nReturns:\n    A new Column instance with the specified sort order.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "asc"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "Table",
                        "docstring": "Metaclass for representing SQL tables.\n\nThis metaclass automatically processes class attributes to set up\ntable names and columns based on the class definition.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init_subclass__",
                                "docstring": "Initialize a subclass of Table.\n\nThis method is called when a new subclass of Table is created. It sets up\nthe table name and processes the class attributes to identify columns.\n\nArgs:\n    **kwargs: Additional keyword arguments.",
                                "comments": null,
                                "args": [
                                    "cls"
                                ]
                            },
                            {
                                "name": "create_table",
                                "docstring": "Generate SQL to create the table.\n\nReturns:\n    A string containing the SQL CREATE TABLE statement for this table.",
                                "comments": null,
                                "args": [
                                    "cls"
                                ]
                            }
                        ],
                        "attributes": [
                            "__table_name__"
                        ]
                    },
                    {
                        "name": "_LimitMixin",
                        "docstring": "Mixin class for adding LIMIT clause functionality.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "limit",
                                "docstring": "Add a LIMIT clause to the query.\n\nArgs:\n    limit: The maximum number of rows to return.\n\nReturns:\n    A Limit instance representing the LIMIT clause.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "limit"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "_OffsetMixin",
                        "docstring": "Mixin class for adding OFFSET clause functionality.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "offset",
                                "docstring": "Add an OFFSET clause to the query.\n\nArgs:\n    offset: The number of rows to skip.\n\nReturns:\n    An Offset instance representing the OFFSET clause.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "offset"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "_PaginateMixin",
                        "docstring": "Mixin class combining LIMIT and OFFSET functionality for pagination.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "_OrderByMixin",
                        "docstring": "Mixin class for adding ORDER BY clause functionality.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "order_by",
                                "docstring": "Add an ORDER BY clause to the query.\n\nArgs:\n    *columns: The columns to order by.\n\nReturns:\n    An OrderBy instance representing the ORDER BY clause.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "_WhereMixin",
                        "docstring": "Mixin class for adding WHERE clause functionality.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "where",
                                "docstring": "Add a WHERE clause to the query.\n\nArgs:\n    evaluation: The primary condition for the WHERE clause.\n    *evaluations: Additional conditions to be combined with AND.\n\nReturns:\n    A Where instance representing the WHERE clause.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "evaluation"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "BooleanOperator",
                        "docstring": "Enumeration of boolean operators used in SQL queries.\n\nThis enum defines the various boolean operators that can be used\nin constructing complex SQL conditions.",
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "AND",
                            "AND_NOT",
                            "OR",
                            "OR_NOT",
                            "IS",
                            "IS_NOT",
                            "IN",
                            "NOT_IN"
                        ]
                    },
                    {
                        "name": "LogicGate",
                        "docstring": "Represents a logical operation in SQL queries.\n\nThis class is used to construct complex logical conditions by combining\nmultiple expressions with boolean operators.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize a LogicGate instance.\n\nArgs:\n    boolean_operator: The boolean operator to use.\n    evaluation: The primary expression to evaluate.\n    *evaluations: Additional expressions to combine with the primary expression.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "boolean_operator",
                                    "evaluation"
                                ]
                            },
                            {
                                "name": "prepare",
                                "docstring": "Prepare the logical operation for use in a SQL query.\n\nReturns:\n    A tuple containing the SQL string for this logical operation and a list of parameters.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "Expression",
                        "docstring": "Represents a SQL expression or condition.\n\nThis class is used to construct SQL expressions involving comparisons,\narithmetic operations, or function calls.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize an Expression instance.\n\nArgs:\n    left_operand: The left side of the expression.\n    operator: The operator to use in the expression.\n    right_operand: The right side of the expression.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "left_operand",
                                    "operator",
                                    "right_operand"
                                ]
                            },
                            {
                                "name": "as_",
                                "docstring": "Create an alias for this expression.\n\nArgs:\n    alias: The alias name for the expression.\n\nReturns:\n    An As instance representing the aliased expression.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "alias"
                                ]
                            },
                            {
                                "name": "prepare",
                                "docstring": "Prepare the expression for use in a SQL query.\n\nReturns:\n    A tuple containing the SQL string for this expression and a list of parameters.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "Join",
                        "docstring": "Represents a JOIN operation in a SQL query.\n\nThis class is used to construct various types of JOIN clauses.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize a Join instance.\n\nArgs:\n    table: The table to join with.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "table"
                                ]
                            },
                            {
                                "name": "prepare",
                                "docstring": "Prepare the JOIN clause for use in a SQL query.\n\nReturns:\n    A tuple containing the SQL string for this JOIN clause and a list of parameters.\n\nRaises:\n    ValueError: If no ON condition has been set for the join.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "on",
                                "docstring": "Set the ON condition for the JOIN.\n\nArgs:\n    *expressions: The conditions to use in the ON clause.\n\nReturns:\n    The Join instance itself, allowing for method chaining.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "LeftJoin",
                        "docstring": "Represents a LEFT JOIN operation in a SQL query.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize a LeftJoin instance.\n\nArgs:\n    table: The table to left join with.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "table"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "RightJoin",
                        "docstring": "Represents a RIGHT JOIN operation in a SQL query.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize a RightJoin instance.\n\nArgs:\n    table: The table to right join with.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "table"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "Limit",
                        "docstring": "Represents a LIMIT clause in a SQL query.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize a Limit instance.\n\nArgs:\n    subquery: The query to apply the LIMIT to.\n    limit: The maximum number of rows to return.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "subquery",
                                    "limit"
                                ]
                            },
                            {
                                "name": "prepare",
                                "docstring": "Prepare the LIMIT clause for use in a SQL query.\n\nReturns:\n    A tuple containing the SQL string with the LIMIT clause and a list of parameters.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "Offset",
                        "docstring": "Represents an OFFSET clause in a SQL query.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize an Offset instance.\n\nArgs:\n    subquery: The query to apply the OFFSET to.\n    offset: The number of rows to skip.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "subquery",
                                    "offset"
                                ]
                            },
                            {
                                "name": "prepare",
                                "docstring": "Prepare the OFFSET clause for use in a SQL query.\n\nReturns:\n    A tuple containing the SQL string with the OFFSET clause and a list of parameters.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "On",
                        "docstring": "Represents an ON clause in a JOIN operation.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize an On instance.\n\nArgs:\n    *expressions: The conditions to use in the ON clause.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "prepare",
                                "docstring": "Prepare the ON clause for use in a SQL query.\n\nReturns:\n    A tuple containing the SQL string for the ON clause and a list of parameters.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "From",
                        "docstring": "Represents a FROM clause in a SQL query.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize a From instance.\n\nArgs:\n    select: The SELECT clause of the query.\n    table: The main table to select from.\n    *joins: Any JOIN clauses to include.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "select",
                                    "table"
                                ]
                            },
                            {
                                "name": "prepare",
                                "docstring": "Prepare the FROM clause for use in a SQL query.\n\nReturns:\n    A tuple containing the SQL string for the FROM clause (including any JOINs) and a list of parameters.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "OrderBy",
                        "docstring": "Represents an ORDER BY clause in a SQL query.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize an OrderBy instance.\n\nArgs:\n    subquery: The query to apply the ORDER BY to.\n    *columns: The columns to order by.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "subquery"
                                ]
                            },
                            {
                                "name": "prepare",
                                "docstring": "Prepare the ORDER BY clause for use in a SQL query.\n\nReturns:\n    A tuple containing the SQL string with the ORDER BY clause and a list of parameters.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "Values",
                        "docstring": "Represents a VALUES clause in an INSERT statement.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize a Values instance.\n\nArgs:\n    subquery: The INSERT INTO clause.\n    values: A dictionary mapping columns to their values.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "subquery",
                                    "values"
                                ]
                            },
                            {
                                "name": "prepare",
                                "docstring": "Prepare the VALUES clause for use in a SQL query.\n\nReturns:\n    A tuple containing the SQL string with the VALUES clause and a list of parameter values.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "Where",
                        "docstring": "Represents a WHERE clause in a SQL query.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize a Where instance.\n\nArgs:\n    subquery: The query to apply the WHERE clause to.\n    *expressions: The conditions to use in the WHERE clause.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "subquery"
                                ]
                            },
                            {
                                "name": "prepare",
                                "docstring": "Prepare the WHERE clause for use in a SQL query.\n\nReturns:\n    A tuple containing the SQL string with the WHERE clause and a list of parameters.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "Set",
                        "docstring": "Represents a SET clause in an UPDATE statement.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize a Set instance.\n\nArgs:\n    subquery: The UPDATE clause.\n    values: A dictionary mapping columns to their new values.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "subquery",
                                    "values"
                                ]
                            },
                            {
                                "name": "prepare",
                                "docstring": "Prepare the SET clause for use in a SQL query.\n\nReturns:\n    A tuple containing the SQL string with the SET clause and a list of parameter values.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "InsertInto",
                        "docstring": "Represents an INSERT INTO statement in SQL.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize an InsertInto instance.\n\nArgs:\n    table: The table to insert into.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "table"
                                ]
                            },
                            {
                                "name": "prepare",
                                "docstring": "Prepare the INSERT INTO clause for use in a SQL query.\n\nReturns:\n    A tuple containing the SQL string for the INSERT INTO clause and an empty list of parameters.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "values",
                                "docstring": "Add a VALUES clause to the INSERT statement.\n\nArgs:\n    values: A dictionary mapping columns to their values. If None, an empty dict is used.\n\nReturns:\n    A Values instance representing the VALUES clause.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "values"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "Delete",
                        "docstring": "Represents a DELETE statement in SQL.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize a Delete instance.\n\nArgs:\n    table: The table to delete from.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "table"
                                ]
                            },
                            {
                                "name": "prepare",
                                "docstring": "Prepare the DELETE statement for use in a SQL query.\n\nReturns:\n    A tuple containing the SQL string for the DELETE statement and an empty list of parameters.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "Select",
                        "docstring": "Represents a SELECT statement in SQL.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize a Select instance.\n\nArgs:\n    *args: The columns, tables, or aliases to select from.\n\nRaises:\n    ValueError: If an argument is not a Column, Table, or As instance.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "prepare",
                                "docstring": "Prepare the SELECT statement for use in a SQL query.\n\nReturns:\n    A tuple containing the SQL string for the SELECT statement and a list of parameters.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "from_",
                                "docstring": "Add a FROM clause to the SELECT statement.\n\nArgs:\n    table: The main table to select from.\n    *args: Any JOIN clauses to include.\n\nReturns:\n    A From instance representing the FROM clause.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "table"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "Update",
                        "docstring": "Represents an UPDATE statement in SQL.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize an Update instance.\n\nArgs:\n    table: The table to update.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "table"
                                ]
                            },
                            {
                                "name": "set",
                                "docstring": "Add a SET clause to the UPDATE statement.\n\nArgs:\n    values: A dictionary mapping columns to their new values.\n\nReturns:\n    A Set instance representing the SET clause.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "values"
                                ]
                            },
                            {
                                "name": "prepare",
                                "docstring": "Prepare the UPDATE statement for use in a SQL query.\n\nReturns:\n    A tuple containing the SQL string for the UPDATE statement and an empty list of parameters.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            }
        ],
        "test_cases": {
            "tests/test_builder.py::test_select": {
                "testid": "tests/test_builder.py::test_select",
                "result": "passed",
                "test_implementation": "def test_select() -> None:\n    query, params = (\n        select(\n            User,\n        )\n        .from_(\n            User,\n            join(Task).on(Task.user_id == User.id and Task.user_id == User.id),\n            left_join(Task).on(Task.value == 1),\n            right_join(Task).on(Task.value >= 2),\n            join(Task).on(Task.value <= MyEnum.OPTION),\n        )\n        .where(\n            Task.value > \"a string\",\n        )\n        .order_by(\n            Task.value.asc(),\n            Task.value.desc(),\n        )\n    ).prepare()\n    assert params == [1, 2, \"option\", \"a string\"]\n    expected = \" \".join(\n        [\n            'SELECT \"user\".id, \"user\".first, \"user\".last',\n            'FROM \"user\" JOIN \"task\" ON \"task\".user_id = \"user\".id',\n            'LEFT JOIN \"task\" ON \"task\".value = ?',\n            'RIGHT JOIN \"task\" ON \"task\".value >= ?',\n            'JOIN \"task\" ON \"task\".value <= ?',\n            'WHERE \"task\".value > ?',\n            'ORDER BY \"task\".value ASC,',\n            '\"task\".value DESC',\n        ]\n    )\n    assert query == expected"
            },
            "tests/test_builder.py::test_select_columns": {
                "testid": "tests/test_builder.py::test_select_columns",
                "result": "passed",
                "test_implementation": "def test_select_columns() -> None:\n    sql, params = (\n        select(\n            User.id,\n            User.first.as_(\"name\"),\n            Task.id,\n        )\n        .from_(\n            User,\n            left_join(Task).on(Task.user_id == User.id),\n        )\n        .limit(20)\n        .offset(20)\n        .prepare()\n    )\n    assert params == []\n    assert sql == \" \".join(\n        [\n            'SELECT \"user\".id, \"user\".first AS name, \"task\".id',\n            'FROM \"user\" LEFT JOIN \"task\" ON \"task\".user_id = \"user\".id',\n            \"LIMIT 20 OFFSET 20\",\n        ]\n    )"
            },
            "tests/test_builder.py::test_insert": {
                "testid": "tests/test_builder.py::test_insert",
                "result": "passed",
                "test_implementation": "def test_insert() -> None:\n    id = uuid.uuid4()\n    query, params = (insert_into(User).values({User.id: id})).prepare()\n    assert params == [id]\n    assert query == 'INSERT INTO \"user\" (\"id\") VALUES (?)'"
            },
            "tests/test_builder.py::test_insert_str_columns": {
                "testid": "tests/test_builder.py::test_insert_str_columns",
                "result": "passed",
                "test_implementation": "def test_insert_str_columns() -> None:\n    id = uuid.uuid4()\n    query, params = (insert_into(User).values({\"id\": id})).prepare()\n    assert params == [id]\n    assert query == 'INSERT INTO \"user\" (\"id\") VALUES (?)'"
            },
            "tests/test_builder.py::test_expressions": {
                "testid": "tests/test_builder.py::test_expressions",
                "result": "passed",
                "test_implementation": "def test_expressions() -> None:\n    query = (\n        select(User)\n        .from_(User)\n        .where(\n            User.id > 1,\n            and_(User.id < User.id),\n            and_not(User.id >= User.id),\n            or_(User.id <= User.id),\n            or_not(\n                User.id != User.id,\n                and_(User.id != User.id),\n            ),\n        )\n    )\n    sql, params = query.prepare()\n    assert params == [1]\n    assert sql == \" \".join(\n        [\n            'SELECT \"user\".id, \"user\".first, \"user\".last',\n            'FROM \"user\" WHERE \"user\".id > ?',\n            'AND \"user\".id < \"user\".id',\n            'AND NOT \"user\".id >= \"user\".id',\n            'OR \"user\".id <= \"user\".id',\n            'OR NOT (\"user\".id != \"user\".id AND \"user\".id != \"user\".id)',\n        ]\n    )"
            },
            "tests/test_builder.py::test_operators": {
                "testid": "tests/test_builder.py::test_operators",
                "result": "passed",
                "test_implementation": "def test_operators() -> None:\n    false: Any = False\n    query = (\n        select(\n            User,\n            (User.id == 3).as_(\"mocha\"),\n        )\n        .from_(User)\n        .where(\n            User.id > 1,\n            and_(User.last.is_(None), or_(User.first.is_not(True))),\n            and_(User.last.is_(1), or_(User.first.is_not(1))),\n            and_((User.last == false), or_(User.first != false)),\n        )\n    )\n    sql, params = query.prepare()\n    assert params == [3, 1, 1, 1]\n    assert sql == \" \".join(\n        [\n            'SELECT \"user\".id, \"user\".first, \"user\".last, \"user\".id = ? AS mocha',\n            'FROM \"user\"',\n            'WHERE \"user\".id > ?',\n            'AND (\"user\".last IS NULL OR \"user\".first IS NOT TRUE)',\n            'AND (\"user\".last = ? OR \"user\".first != ?)',\n            'AND (\"user\".last IS FALSE OR \"user\".first IS NOT FALSE)',\n        ]\n    )"
            },
            "tests/test_builder.py::test_operators_chained": {
                "testid": "tests/test_builder.py::test_operators_chained",
                "result": "xfailed",
                "test_implementation": "def test_operators_chained() -> None:\n    query = (\n        select(User)\n        .from_(User)\n        .where(\n            User.id + 1 > Task.id - 2,\n            and_(User.id > 12, or_(User.id * 5 % 6 > 7)),\n        )\n    )\n    sql, params = query.prepare()\n    assert params == [1, 2, 3, 4, 5, 6, 7]\n    assert sql == \" \".join(\n        [\n            'SELECT \"user\".id, \"user\".first, \"user\".last',\n            'FROM \"user\"',\n            'WHERE \"user\".id + ? > \"task\".id - ? AND (\"user\".id / ? > ?',\n            'OR \"user\".id * ? % ? > ?)',\n        ]\n    )"
            },
            "tests/test_builder.py::test_update": {
                "testid": "tests/test_builder.py::test_update",
                "result": "passed",
                "test_implementation": "def test_update() -> None:\n    sql, params = (\n        update(User)\n        .set(\n            {\n                User.first: \"Potato\",\n                User.last: \"Wedge\",\n                User.id: select(Task.id).from_(Task).where(Task.id == 1),\n            }\n        )\n        .where(User.id == 2)\n    ).prepare()\n    assert params == [\"Potato\", \"Wedge\", 1, 2]\n    assert sql == \" \".join(\n        [\n            'UPDATE \"user\"',\n            'SET \"first\" = ?, \"last\" = ?,',\n            '\"id\" = (SELECT \"task\".id FROM \"task\" WHERE \"task\".id = ?)',\n            'WHERE \"user\".id = ?',\n        ]\n    )"
            },
            "tests/test_builder.py::test_update_str_columns": {
                "testid": "tests/test_builder.py::test_update_str_columns",
                "result": "passed",
                "test_implementation": "def test_update_str_columns() -> None:\n    sql, params = (\n        update(User)\n        .set(\n            {\n                \"first\": \"Potato\",\n                \"last\": \"Wedge\",\n                \"id\": select(Task.id).from_(Task).where(Task.id == 1),\n            }\n        )\n        .where(User.id == 2)\n    ).prepare()\n    assert params == [\"Potato\", \"Wedge\", 1, 2]\n    assert sql == \" \".join(\n        [\n            'UPDATE \"user\"',\n            'SET \"first\" = ?, \"last\" = ?,',\n            '\"id\" = (SELECT \"task\".id FROM \"task\" WHERE \"task\".id = ?)',\n            'WHERE \"user\".id = ?',\n        ]\n    )"
            },
            "tests/test_builder.py::test_delete": {
                "testid": "tests/test_builder.py::test_delete",
                "result": "passed",
                "test_implementation": "def test_delete() -> None:\n    sql, params = delete_from(User).where(User.first == \"Potato\").prepare()\n    assert params == [\"Potato\"]\n    assert sql == 'DELETE FROM \"user\" WHERE \"user\".first = ?'"
            },
            "tests/test_snake.py::test_get_words[PotatoHumanAlien-expected_output0]": {
                "testid": "tests/test_snake.py::test_get_words[PotatoHumanAlien-expected_output0]",
                "result": "passed",
                "test_implementation": "def test_get_words(input_str, expected_output):\n    assert snake.get_words(input_str) == expected_output"
            },
            "tests/test_snake.py::test_get_words[Potato.Human.Alien-expected_output1]": {
                "testid": "tests/test_snake.py::test_get_words[Potato.Human.Alien-expected_output1]",
                "result": "passed",
                "test_implementation": "def test_get_words(input_str, expected_output):\n    assert snake.get_words(input_str) == expected_output"
            },
            "tests/test_snake.py::test_get_words[Potato-Human-Alien-expected_output2]": {
                "testid": "tests/test_snake.py::test_get_words[Potato-Human-Alien-expected_output2]",
                "result": "passed",
                "test_implementation": "def test_get_words(input_str, expected_output):\n    assert snake.get_words(input_str) == expected_output"
            },
            "tests/test_snake.py::test_get_words[Potato/Human/Alien-expected_output3]": {
                "testid": "tests/test_snake.py::test_get_words[Potato/Human/Alien-expected_output3]",
                "result": "passed",
                "test_implementation": "def test_get_words(input_str, expected_output):\n    assert snake.get_words(input_str) == expected_output"
            },
            "tests/test_snake.py::test_get_words[Potato_Human_Alien-expected_output4]": {
                "testid": "tests/test_snake.py::test_get_words[Potato_Human_Alien-expected_output4]",
                "result": "passed",
                "test_implementation": "def test_get_words(input_str, expected_output):\n    assert snake.get_words(input_str) == expected_output"
            },
            "tests/test_snake.py::test_get_words[Potato Human Alien-expected_output5]": {
                "testid": "tests/test_snake.py::test_get_words[Potato Human Alien-expected_output5]",
                "result": "passed",
                "test_implementation": "def test_get_words(input_str, expected_output):\n    assert snake.get_words(input_str) == expected_output"
            },
            "tests/test_snake.py::test_get_words[Honey-expected_output6]": {
                "testid": "tests/test_snake.py::test_get_words[Honey-expected_output6]",
                "result": "passed",
                "test_implementation": "def test_get_words(input_str, expected_output):\n    assert snake.get_words(input_str) == expected_output"
            },
            "tests/test_snake.py::test_get_words[DING-expected_output7]": {
                "testid": "tests/test_snake.py::test_get_words[DING-expected_output7]",
                "result": "passed",
                "test_implementation": "def test_get_words(input_str, expected_output):\n    assert snake.get_words(input_str) == expected_output"
            },
            "tests/test_snake.py::test_get_words[-expected_output8]": {
                "testid": "tests/test_snake.py::test_get_words[-expected_output8]",
                "result": "passed",
                "test_implementation": "def test_get_words(input_str, expected_output):\n    assert snake.get_words(input_str) == expected_output"
            },
            "tests/test_snake.py::test_get_words[orange beer-PotatoAlien_food.yummy/honey-expected_output9]": {
                "testid": "tests/test_snake.py::test_get_words[orange beer-PotatoAlien_food.yummy/honey-expected_output9]",
                "result": "passed",
                "test_implementation": "def test_get_words(input_str, expected_output):\n    assert snake.get_words(input_str) == expected_output"
            },
            "tests/test_snake.py::test_get_words[HumanNAMEDJason-expected_output10]": {
                "testid": "tests/test_snake.py::test_get_words[HumanNAMEDJason-expected_output10]",
                "result": "passed",
                "test_implementation": "def test_get_words(input_str, expected_output):\n    assert snake.get_words(input_str) == expected_output"
            },
            "tests/test_snake.py::test_to_snake[PotatoHumanAlien-potato_human_alien]": {
                "testid": "tests/test_snake.py::test_to_snake[PotatoHumanAlien-potato_human_alien]",
                "result": "passed",
                "test_implementation": "def test_to_snake(input_str, expected_output):\n    assert snake.to_snake(input_str) == expected_output"
            },
            "tests/test_snake.py::test_to_snake[Potato.Human.Alien-potato_human_alien]": {
                "testid": "tests/test_snake.py::test_to_snake[Potato.Human.Alien-potato_human_alien]",
                "result": "passed",
                "test_implementation": "def test_to_snake(input_str, expected_output):\n    assert snake.to_snake(input_str) == expected_output"
            },
            "tests/test_snake.py::test_to_snake[Potato-Human-Alien-potato_human_alien]": {
                "testid": "tests/test_snake.py::test_to_snake[Potato-Human-Alien-potato_human_alien]",
                "result": "passed",
                "test_implementation": "def test_to_snake(input_str, expected_output):\n    assert snake.to_snake(input_str) == expected_output"
            },
            "tests/test_snake.py::test_to_snake[Potato/Human/Alien-potato_human_alien]": {
                "testid": "tests/test_snake.py::test_to_snake[Potato/Human/Alien-potato_human_alien]",
                "result": "passed",
                "test_implementation": "def test_to_snake(input_str, expected_output):\n    assert snake.to_snake(input_str) == expected_output"
            },
            "tests/test_snake.py::test_to_snake[Potato_Human_Alien-potato_human_alien]": {
                "testid": "tests/test_snake.py::test_to_snake[Potato_Human_Alien-potato_human_alien]",
                "result": "passed",
                "test_implementation": "def test_to_snake(input_str, expected_output):\n    assert snake.to_snake(input_str) == expected_output"
            },
            "tests/test_snake.py::test_to_snake[Potato Human Alien-potato_human_alien]": {
                "testid": "tests/test_snake.py::test_to_snake[Potato Human Alien-potato_human_alien]",
                "result": "passed",
                "test_implementation": "def test_to_snake(input_str, expected_output):\n    assert snake.to_snake(input_str) == expected_output"
            },
            "tests/test_snake.py::test_to_snake[Honey-honey]": {
                "testid": "tests/test_snake.py::test_to_snake[Honey-honey]",
                "result": "passed",
                "test_implementation": "def test_to_snake(input_str, expected_output):\n    assert snake.to_snake(input_str) == expected_output"
            },
            "tests/test_snake.py::test_to_snake[DING-ding]": {
                "testid": "tests/test_snake.py::test_to_snake[DING-ding]",
                "result": "passed",
                "test_implementation": "def test_to_snake(input_str, expected_output):\n    assert snake.to_snake(input_str) == expected_output"
            },
            "tests/test_snake.py::test_to_snake[-]": {
                "testid": "tests/test_snake.py::test_to_snake[-]",
                "result": "passed",
                "test_implementation": "def test_to_snake(input_str, expected_output):\n    assert snake.to_snake(input_str) == expected_output"
            },
            "tests/test_snake.py::test_to_snake[orange beer-PotatoAlien_food.yummy/honey-orange_beer_potato_alien_food_yummy_honey]": {
                "testid": "tests/test_snake.py::test_to_snake[orange beer-PotatoAlien_food.yummy/honey-orange_beer_potato_alien_food_yummy_honey]",
                "result": "passed",
                "test_implementation": "def test_to_snake(input_str, expected_output):\n    assert snake.to_snake(input_str) == expected_output"
            },
            "tests/test_snake.py::test_to_snake[HumanNAMEDJason-human_named_jason]": {
                "testid": "tests/test_snake.py::test_to_snake[HumanNAMEDJason-human_named_jason]",
                "result": "passed",
                "test_implementation": "def test_to_snake(input_str, expected_output):\n    assert snake.to_snake(input_str) == expected_output"
            },
            "tests/test_snake.py::test_split_words_on_regex_happy_path[words0-\\\\s-expected0]": {
                "testid": "tests/test_snake.py::test_split_words_on_regex_happy_path[words0-\\\\s-expected0]",
                "result": "passed",
                "test_implementation": "def test_split_words_on_regex_happy_path(words, regex, expected):\n    result = snake._split_words_on_regex(words, regex)\n    assert result == expected, f\"Expected {expected} but got {result}\""
            },
            "tests/test_snake.py::test_split_words_on_regex_happy_path[words1---expected1]": {
                "testid": "tests/test_snake.py::test_split_words_on_regex_happy_path[words1---expected1]",
                "result": "passed",
                "test_implementation": "def test_split_words_on_regex_happy_path(words, regex, expected):\n    result = snake._split_words_on_regex(words, regex)\n    assert result == expected, f\"Expected {expected} but got {result}\""
            },
            "tests/test_snake.py::test_split_words_on_regex_happy_path[words2-,-expected2]": {
                "testid": "tests/test_snake.py::test_split_words_on_regex_happy_path[words2-,-expected2]",
                "result": "passed",
                "test_implementation": "def test_split_words_on_regex_happy_path(words, regex, expected):\n    result = snake._split_words_on_regex(words, regex)\n    assert result == expected, f\"Expected {expected} but got {result}\""
            },
            "tests/test_snake.py::test_split_words_on_regex_happy_path[words3-\\\\|-expected3]": {
                "testid": "tests/test_snake.py::test_split_words_on_regex_happy_path[words3-\\\\|-expected3]",
                "result": "passed",
                "test_implementation": "def test_split_words_on_regex_happy_path(words, regex, expected):\n    result = snake._split_words_on_regex(words, regex)\n    assert result == expected, f\"Expected {expected} but got {result}\""
            },
            "tests/test_snake.py::test_split_words_on_regex_edge_cases[words0-\\\\s-expected0]": {
                "testid": "tests/test_snake.py::test_split_words_on_regex_edge_cases[words0-\\\\s-expected0]",
                "result": "passed",
                "test_implementation": "def test_split_words_on_regex_edge_cases(words, regex, expected):\n    result = snake._split_words_on_regex(words, regex)\n    assert result == expected, f\"Expected {expected} but got {result}\""
            },
            "tests/test_snake.py::test_split_words_on_regex_edge_cases[words1-\\\\s-expected1]": {
                "testid": "tests/test_snake.py::test_split_words_on_regex_edge_cases[words1-\\\\s-expected1]",
                "result": "passed",
                "test_implementation": "def test_split_words_on_regex_edge_cases(words, regex, expected):\n    result = snake._split_words_on_regex(words, regex)\n    assert result == expected, f\"Expected {expected} but got {result}\""
            },
            "tests/test_snake.py::test_split_words_on_regex_error_cases[words0-None-TypeError]": {
                "testid": "tests/test_snake.py::test_split_words_on_regex_error_cases[words0-None-TypeError]",
                "result": "passed",
                "test_implementation": "def test_split_words_on_regex_error_cases(words, regex, expected_exception):\n    with pytest.raises(expected_exception):\n        snake._split_words_on_regex(words, regex)"
            },
            "tests/test_snake.py::test_split_words_on_regex_error_cases[words1-123-TypeError]": {
                "testid": "tests/test_snake.py::test_split_words_on_regex_error_cases[words1-123-TypeError]",
                "result": "passed",
                "test_implementation": "def test_split_words_on_regex_error_cases(words, regex, expected_exception):\n    with pytest.raises(expected_exception):\n        snake._split_words_on_regex(words, regex)"
            },
            "tests/test_types.py::test_create_table": {
                "testid": "tests/test_types.py::test_create_table",
                "result": "passed",
                "test_implementation": "def test_create_table() -> None:\n    sql = User.create_table()\n    assert sql == inspect.cleandoc(\n        \"\"\"\n        CREATE TABLE IF NOT EXISTS \"user\" (\n          \"id\" UUID,\n          \"bigint\" BIGINT,\n          \"bigserial\" BIGSERIAL NOT NULL,\n          \"bit\" BIT NOT NULL,\n          \"varbit\" VARBIT NOT NULL,\n          \"boolean\" BOOLEAN NOT NULL,\n          \"box\" BOX NOT NULL,\n          \"bytea\" BYTEA NOT NULL,\n          \"char\" CHAR NOT NULL,\n          \"varchar\" VARCHAR NOT NULL,\n          \"cidr\" CIDR NOT NULL,\n          \"circle\" CIRCLE NOT NULL,\n          \"date\" DATE NOT NULL,\n          \"double\" DOUBLE PRECISION NOT NULL,\n          \"inet\" INET NOT NULL,\n          \"integer\" INTEGER NOT NULL,\n          \"interval\" INTERVAL NOT NULL,\n          \"json\" JSON NOT NULL,\n          \"jsonb\" JSONB NOT NULL,\n          \"line\" LINE NOT NULL,\n          \"lseg\" LSEG NOT NULL,\n          \"macaddr\" MACADDR NOT NULL,\n          \"macaddr8\" MACADDR8 NOT NULL,\n          \"money\" MONEY NOT NULL,\n          \"numeric\" NUMERIC NOT NULL,\n          \"path\" PATH NOT NULL,\n          \"pg_lsn\" PG_LSN NOT NULL,\n          \"pg_snapshot\" PG_SNAPSHOT NOT NULL,\n          \"point\" POINT NOT NULL,\n          \"polygon\" POLYGON NOT NULL,\n          \"real\" REAL NOT NULL,\n          \"smallint\" SMALLINT NOT NULL,\n          \"smallserial\" SMALLSERIAL NOT NULL,\n          \"serial\" SERIAL NOT NULL,\n          \"text\" TEXT NOT NULL,\n          \"time\" TIME NOT NULL,\n          \"timestamp\" TIMESTAMP NOT NULL,\n          \"tsquery\" TSQUERY NOT NULL,\n          \"tsvector\" TSVECTOR NOT NULL,\n          \"uuid\" UUID NOT NULL,\n          \"xml\" XML NOT NULL,\n          PRIMARY KEY (id, bigint)\n        );\n        \"\"\"\n    )"
            },
            "tests/test_types.py::test_type_options": {
                "testid": "tests/test_types.py::test_type_options",
                "result": "passed",
                "test_implementation": "def test_type_options() -> None:\n    sql = TypeOptionsTable.create_table()\n    assert sql == inspect.cleandoc(\n        \"\"\"\n        CREATE TABLE IF NOT EXISTS \"type_options_table\" (\n          \"char\" CHAR(1),\n          \"varchar\" VARCHAR(1) DEFAULT '',\n          \"interval\" INTERVAL DAY TO SECOND(1),\n          \"numeric\" NUMERIC(10, 2),\n          \"numeric_two\" NUMERIC(10),\n          \"time\" TIME(1) WITH TIME ZONE,\n          \"timestamp\" TIMESTAMP(1) WITH TIME ZONE\n        );\n        \"\"\"\n    )\n\n    with pytest.raises(ValueError):\n        Column(NUMERIC(scale=1))._create()"
            },
            "tests/test_types.py::test_column_options": {
                "testid": "tests/test_types.py::test_column_options",
                "result": "passed",
                "test_implementation": "def test_column_options() -> None:\n    sql = ColumnOptionsTable.create_table()\n    assert sql == inspect.cleandoc(\n        \"\"\"\n        CREATE TABLE IF NOT EXISTS \"column_options_table\" (\n          \"integer\" INTEGER DEFAULT 1 UNIQUE CHECK (integer > 0),\n          \"fk\" UUID NOT NULL,\n          \"fk2\" BIGINT NOT NULL,\n          FOREIGN KEY (fk, fk2) REFERENCES \"user\" (id, bigint)\n        );\n        CREATE INDEX ON \"column_options_table\" (integer);\n        \"\"\"\n    )"
            },
            "tests/test_types.py::test_enum": {
                "testid": "tests/test_types.py::test_enum",
                "result": "passed",
                "test_implementation": "def test_enum() -> None:\n    class MyE(PGEnum):\n        A = \"apple\"\n        B = \"bee\"\n\n    assert MyE.pg_enum_get_create() == \"CREATE TYPE MY_E AS ENUM ('apple', 'bee');\"\n\n    class UsesEnum(Table):\n        col = Column(MyE, null=True)\n\n    assert UsesEnum.create_table() == inspect.cleandoc(\n        \"\"\"\n        CREATE TABLE IF NOT EXISTS \"uses_enum\" (\n          \"col\" MY_E\n        );\n        \"\"\"\n    )"
            }
        },
        "SRS_document": "**Software Requirements Specification**\n\n**pgqb: Python PostgreSQL Query Builder**\n\n**1. Introduction**\n\n**1.1 Purpose**\nThis Software Requirements Specification (SRS) document defines the functional and external interface requirements for `pgqb`, a Python library designed for programmatically constructing PostgreSQL SQL queries. This document is intended to provide a clear, unambiguous, and comprehensive basis for software developers to implement the `pgqb` library. The resulting implementation will be assessed based on its adherence to these specifications and its ability to pass a comprehensive suite of test cases (public and private).\n\n**1.2 Scope**\nThe `pgqb` library shall enable Python developers to:\n*   Define database table structures, including columns, data types, and constraints, and generate corresponding `CREATE TABLE` and `CREATE INDEX` statements.\n*   Define custom PostgreSQL ENUM types and generate `CREATE TYPE` statements.\n*   Construct SQL `SELECT` queries, incorporating features such as column selection, aliasing, table joins (INNER, LEFT, RIGHT), filtering (`WHERE`), ordering (`ORDER BY`), and pagination (`LIMIT`, `OFFSET`).\n*   Construct SQL `INSERT INTO` queries with specified column values.\n*   Construct SQL `UPDATE` queries with `SET` clauses for modifying data and `WHERE` clauses for targeting rows.\n*   Construct SQL `DELETE FROM` queries with `WHERE` clauses for specifying rows to be deleted.\n*   Generate parameterized SQL query strings and corresponding parameter lists to promote safe database interaction and prevent SQL injection vulnerabilities.\n\nThe library is specifically for PostgreSQL. The internal implementation details are not within the scope of this SRS, except where they directly influence externally observable behavior or interfaces.\n\n**1.3 Definitions, Acronyms, and Abbreviations**\n*   **SQL:** Structured Query Language\n*   **PG:** PostgreSQL\n*   **SRS:** Software Requirements Specification\n*   **API:** Application Programming Interface\n*   **IDEF:** Identifier (e.g., table name, column name)\n*   **FR:** Functional Requirement\n*   **NFR:** Non-Functional Requirement\n*   **EIR:** External Interface Requirement\n*   **DD:** Data Dictionary\n\n**1.4 References**\n*   PostgreSQL Documentation (for general SQL syntax and data type understanding): [https://www.postgresql.org/docs/current/](https://www.postgresql.org/docs/current/)\n\n**1.5 Overview**\nThis SRS is organized into three main sections. Section 1 provides an introduction. Section 2 gives an overall description of the software, its intended users, and general constraints. Section 3 details the specific requirements, including functional requirements, non-functional requirements (if any meeting criteria), external interface requirements, and a data dictionary of supported types.\n\n**2. Overall Description**\n\n**2.1 Product Perspective**\n`pgqb` is a Python library, intended to be integrated into other Python applications that require interaction with a PostgreSQL database. It is not a standalone application. It provides an API to build SQL queries programmatically.\n\n**2.2 Product Functions**\nThe primary functions of the `pgqb` library are:\n*   **Schema Definition:** Allow programmatic definition of PostgreSQL table structures, including columns, data types, primary keys, foreign keys, unique constraints, check constraints, default values, and indexes. Generation of DDL statements (`CREATE TABLE`, `CREATE INDEX`, `CREATE TYPE`).\n*   **SELECT Query Construction:** Facilitate building complex `SELECT` queries with support for various clauses like `FROM`, `JOIN`, `WHERE`, `ORDER BY`, `LIMIT`, and `OFFSET`.\n*   **INSERT Query Construction:** Facilitate building `INSERT INTO` queries to add new data to tables.\n*   **UPDATE Query Construction:** Facilitate building `UPDATE` queries to modify existing data in tables.\n*   **DELETE Query Construction:** Facilitate building `DELETE FROM` queries to remove data from tables.\n*   **Parameterized Query Generation:** Ensure all constructed queries produce a SQL string with placeholders for values and a corresponding list of parameters, suitable for safe execution by a database driver.\n\n**2.3 User Characteristics**\nThe intended users of `pgqb` are Python developers who are building applications that interface with PostgreSQL databases. Users are expected to have a working knowledge of Python and SQL concepts.\n\n**2.4 Constraints**\n*   The generated SQL must be compatible with PostgreSQL.\n*   Parameter placeholders in generated SQL strings must be represented by '?' (question mark).\n*   Table and column identifiers in generated SQL must be enclosed in double quotes (e.g., `\"user\"`, `\"user\".\"id\"`).\n*   The library is intended for use with Python 3.9 or higher (as per development environment setup in README, although no explicit NFR test case exists for this).\n\n**2.5 Assumptions and Dependencies**\n*   Users will have a Python environment (3.9+ recommended).\n*   Users will use a separate database connector library (e.g., `psycopg2`, `asyncpg`) to execute the generated SQL queries. `pgqb` is solely a query builder.\n\n**3. Specific Requirements**\n\n**3.1 Functional Requirements**\n\n**3.1.1 Schema Definition (FR-SDEF)**\n\n*   **FR-SDEF-001:** Table Definition: The system shall allow users to define database tables programmatically.\n    *   **FR-SDEF-001.1:** Table Naming Convention: SQL table names shall be automatically derived from the user-defined table class name, converted to snake_case, and enclosed in double quotes (e.g., Python class `UserData` results in SQL table name `\"user_data\"`).\n\n*   **FR-SDEF-002:** Column Definition: The system shall allow users to define columns within tables, associating them with Python class attributes.\n    *   **FR-SDEF-002.1:** Column Naming Convention: SQL column names shall be automatically derived from the attribute name in the table class definition and enclosed in double quotes (e.g., attribute `first_name` results in SQL column name `\"first_name\"`).\n\n*   **FR-SDEF-003:** Data Type Specification: The system shall support associating PostgreSQL data types with columns. A comprehensive list of supported types is in Section 3.4 (Data Dictionary).\n\n*   **FR-SDEF-004:** Parameterized Data Types: The system shall allow specification of parameters for data types that support them.\n    *   Examples include: `CHAR(length)`, `VARCHAR(length)`, `INTERVAL(fields, precision)`, `NUMERIC(precision, scale)`, `TIME(precision, with_time_zone)`, `TIMESTAMP(precision, with_time_zone)`.\n\n*   **FR-SDEF-005:** Column Nullability: The system shall allow columns to be defined as nullable or non-nullable. By default, columns are non-nullable unless specified otherwise or if they are primary keys (which are implicitly NOT NULL).\n\n*   **FR-SDEF-006:** Primary Key Constraint: The system shall allow one or more columns to be designated as a primary key for a table. This includes support for composite primary keys.\n\n*   **FR-SDEF-007:** Unique Constraint: The system shall allow a unique constraint to be defined on a column.\n\n*   **FR-SDEF-008:** Default Value: The system shall allow a default value to be specified for a column.\n\n*   **FR-SDEF-009:** Check Constraint: The system shall allow a custom check constraint string to be defined for a column.\n\n*   **FR-SDEF-010:** Foreign Key Constraint: The system shall allow a foreign key constraint to be defined on a column or set of columns, referencing columns in another table. This includes support for composite foreign keys.\n\n*   **FR-SDEF-011:** Column Indexing: The system shall allow an index to be automatically created for a specified column.\n\n*   **FR-SDEF-012:** `CREATE TABLE` Statement Generation: The system shall generate a `CREATE TABLE IF NOT EXISTS` SQL statement accurately reflecting the defined table, columns, types, and constraints.\n\n*   **FR-SDEF-013:** `CREATE INDEX` Statement Generation: For columns marked for indexing, the system shall generate corresponding `CREATE INDEX` SQL statements separate from the `CREATE TABLE` statement.\n\n*   **FR-SDEF-014:** Custom ENUM Type Definition: The system shall allow users to define custom PostgreSQL ENUM types with a specified set of string values.\n    *   **FR-SDEF-014.1:** ENUM Type Naming Convention: SQL ENUM type names shall be automatically derived from the user-defined ENUM class name, converted to snake_case, and capitalized (e.g., Python class `MyStatus` results in SQL ENUM type `MY_STATUS`).\n\n*   **FR-SDEF-015:** `CREATE TYPE AS ENUM` Statement Generation: The system shall generate a `CREATE TYPE <enum_name> AS ENUM ('value1', 'value2', ...);` SQL statement for defined custom ENUM types.\n\n*   **FR-SDEF-016:** Custom ENUM Usage: The system shall allow defined custom ENUM types to be used as data types for table columns.\n\n**3.1.2 Query Generation - General (FR-QGEN)**\n\n*   **FR-QGEN-001:** Query Preparation: The system shall provide a mechanism (e.g., a `.prepare()` method) to finalize any constructed query definition. This mechanism must return two distinct outputs:\n    1.  A SQL query string, formatted for PostgreSQL, with parameter placeholders.\n    2.  An ordered list of parameter values corresponding to the placeholders in the SQL string.\n\n**3.1.3 SELECT Query Construction (FR-SEL)**\n\n*   **FR-SEL-001:** Select All Columns: The system shall allow selecting all defined columns from a table by specifying the table itself in the selection list.\n\n*   **FR-SEL-002:** Select Specific Columns: The system shall allow selecting specific columns by providing `Column` objects.\n\n*   **FR-SEL-003:** Column Aliasing: The system shall allow aliasing of selected columns using an `AS` keyword equivalent.\n\n*   **FR-SEL-004:** Expression Aliasing: The system shall allow aliasing of expressions in the select list using an `AS` keyword equivalent.\n\n*   **FR-SEL-005:** `FROM` Clause: The system shall generate a `FROM` clause specifying the primary table for the select query.\n\n*   **FR-SEL-006:** `JOIN` Clause: The system shall support joining tables.\n    *   **FR-SEL-006.1:** `INNER JOIN`: Support for `INNER JOIN` (or `JOIN`) clauses.\n    *   **FR-SEL-006.2:** `LEFT JOIN`: Support for `LEFT JOIN` clauses.\n    *   **FR-SEL-006.3:** `RIGHT JOIN`: Support for `RIGHT JOIN` clauses.\n    *   **FR-SEL-006.4:** `ON` Condition: `JOIN` clauses must be accompanied by an `ON` condition specifying the join predicate. `ON` conditions can involve comparisons between columns of different tables or columns and literal values.\n    *   **FR-SEL-006.5:** Multiple `ON` Conditions: `ON` conditions can consist of multiple expressions combined using logical `AND`.\n\n*   **FR-SEL-007:** `WHERE` Clause: The system shall support a `WHERE` clause for filtering results based on specified conditions. For details on condition expressions, see Section 3.1.7 (Expressions and Conditions).\n\n*   **FR-SEL-008:** `ORDER BY` Clause: The system shall support an `ORDER BY` clause for sorting results.\n    *   **FR-SEL-008.1:** Multiple Columns: Ordering can be specified by one or more columns.\n    *   **FR-SEL-008.2:** Sort Direction: For each ordering column, `ASC` (ascending) or `DESC` (descending) sort direction can be specified.\n\n*   **FR-SEL-009:** `LIMIT` Clause: The system shall support a `LIMIT` clause to restrict the number of rows returned.\n\n*   **FR-SEL-010:** `OFFSET` Clause: The system shall support an `OFFSET` clause to skip a specified number of rows before returning results.\n\n**3.1.4 INSERT Query Construction (FR-INS)**\n\n*   **FR-INS-001:** `INSERT INTO` Table: The system shall allow construction of `INSERT INTO` queries targeting a specified table.\n\n*   **FR-INS-002:** Values Specification: The system shall allow specifying columns and their corresponding values for insertion using a dictionary-like structure.\n    *   **FR-INS-002.1:** Values are Parameterized: All provided values shall be parameterized in the final query.\n    *   **FR-INS-002.2:** Column Identification: Columns in the values dictionary can be identified either by `Column` objects or by string names corresponding to column attributes in the table definition.\n\n**3.1.5 UPDATE Query Construction (FR-UPD)**\n\n*   **FR-UPD-001:** `UPDATE` Table: The system shall allow construction of `UPDATE` queries targeting a specified table.\n\n*   **FR-UPD-002:** `SET` Clause: The system shall support a `SET` clause for specifying columns and their new values using a dictionary-like structure.\n    *   **FR-UPD-002.1:** Values are Parameterized: Literal values provided in the `SET` clause shall be parameterized.\n    *   **FR-UPD-002.2:** Subquery in SET: Values in the `SET` clause can be derived from a sub-select query. The subquery's SQL and parameters shall be integrated into the main `UPDATE` query.\n    *   **FR-UPD-002.3:** Column Identification: Columns in the `SET` dictionary can be identified either by `Column` objects or by string names corresponding to column attributes in the table definition.\n\n*   **FR-UPD-003:** `WHERE` Clause for UPDATE: The system shall support a `WHERE` clause to specify which rows to update, with the same capabilities as `WHERE` clauses in `SELECT` queries (see Section 3.1.7).\n\n**3.1.6 DELETE Query Construction (FR-DEL)**\n\n*   **FR-DEL-001:** `DELETE FROM` Table: The system shall allow construction of `DELETE FROM` queries targeting a specified table.\n\n*   **FR-DEL-002:** `WHERE` Clause for DELETE: The system shall support a `WHERE` clause to specify which rows to delete, with the same capabilities as `WHERE` clauses in `SELECT` queries (see Section 3.1.7).\n\n**3.1.7 Expressions and Conditions (FR-EXPR)**\n\n*   **FR-EXPR-001:** Comparison Operators: The system shall support the following comparison operators between columns, expressions, and literal values:\n    *   `>` (greater than)\n    *   `<` (less than)\n    *   `>=` (greater than or equal to)\n    *   `<=` (less than or equal to)\n    *   `=` (equal to)\n    *   `!=` (not equal to)\n    *   Literal values used in comparisons shall be parameterized. Enum values should be converted to their underlying value for parameterization.\n\n*   **FR-EXPR-002:** `IS` Operators: The system shall support SQL `IS` operators for comparisons with `NULL`, `TRUE`, and `FALSE`.\n    *   `IS NULL` (implicitly generated for `col == None`)\n    *   `IS NOT NULL` (implicitly generated for `col != None`)\n    *   `IS TRUE` (implicitly generated for `col == True`)\n    *   `IS NOT TRUE` (implicitly generated for `col != True`)\n    *   `IS FALSE` (implicitly generated for `col == False`)\n    *   `IS NOT FALSE` (implicitly generated for `col != False`)\n    *   The system shall also provide explicit `is_()` and `is_not()` methods for these comparisons.\n\n*   **FR-EXPR-003:** Logical Operators: The system shall support logical operators to combine multiple conditions:\n    *   `AND`\n    *   `OR`\n    *   `AND NOT`\n    *   `OR NOT`\n    *   `OR NOT` applied to multiple sub-conditions should group them in parentheses in the generated SQL (e.g., `OR NOT (condition1 AND condition2)`).\n\n*   **FR-EXPR-004:** Arithmetic Operators: The system shall support arithmetic operations (`+`, `-`, `*`, `/`, `%`) in expressions, applicable between columns, or columns and literal values. Literal values shall be parameterized.\n\n**3.1.8 Error Handling (FR-ERR)**\n\n*   **FR-ERR-001:** Invalid `NUMERIC` Definition: The system shall raise an error if a `NUMERIC` data type is defined with a `scale` parameter but without a corresponding `precision` parameter during schema generation preparations.\n\n*   **FR-ERR-002:** Missing `ON` Condition for `JOIN`: The system shall raise an error if an attempt is made to prepare a query containing a `JOIN` clause for which no `ON` condition has been specified.\n\n*   **FR-ERR-003:** Unsupported Argument in `SELECT`: The system shall raise an error during `SELECT` clause construction if an argument of an unsupported type (i.e., not a `Column`, `Table`, or `As` instance) is provided for the items to be selected.\n\n**3.2 Non-Functional Requirements**\nThere are no non-functional requirements explicitly validated by dedicated test cases in the provided materials.\n\n**3.3 External Interface Requirements**\n\n*   **EIR-001:** PostgreSQL Compatibility: The system shall generate SQL query strings that are syntactically valid for PostgreSQL.\n\n*   **EIR-002:** Parameter Placeholder: Parameterized values in the generated SQL query strings must be represented by the '?' (question mark) placeholder.\n\n*   **EIR-003:** Identifier Quoting: All SQL identifiers (table names, column names, generated ENUM type names) in the generated query strings shall be enclosed in double quotes (e.g., `\"user\"`, `\"user\".\"id\"`, `\"MY_ENUM_TYPE\"`).\n\n**3.4 Other Requirements**\n\n**3.4.1 Data Dictionary: Supported PostgreSQL Data Types (DD-TYPES)**\nThe system shall provide representations for and support the use of the following PostgreSQL data types in column definitions. This includes generating the correct SQL type name in `CREATE TABLE` statements.\n\n*   `BIGINT`\n*   `BIGSERIAL`\n*   `BIT` (without parameters)\n*   `VARBIT` (without parameters)\n*   `BOOLEAN`\n*   `BOX`\n*   `BYTEA`\n*   `CHAR` (optionally with length, e.g., `CHAR(10)`)\n*   `VARCHAR` (optionally with length, e.g., `VARCHAR(255)`)\n*   `CIDR`\n*   `CIRCLE`\n*   `DATE`\n*   `DOUBLE PRECISION` (represented in the library as `DOUBLE`)\n*   `INET`\n*   `INTEGER`\n*   `INTERVAL` (optionally with fields string like \"DAY TO SECOND\" and/or precision, e.g., `INTERVAL DAY TO SECOND(3)`)\n*   `JSON`\n*   `JSONB`\n*   `LINE`\n*   `LSEG`\n*   `MACADDR`\n*   `MACADDR8`\n*   `MONEY`\n*   `NUMERIC` (optionally with precision only, e.g., `NUMERIC(10)`, or precision and scale, e.g., `NUMERIC(10, 2)`)\n*   `PATH`\n*   `PG_LSN`\n*   `PG_SNAPSHOT`\n*   `POINT`\n*   `POLYGON`\n*   `REAL`\n*   `SMALLINT`\n*   `SMALLSERIAL`\n*   `SERIAL`\n*   `TEXT`\n*   `TIME` (optionally with precision and/or `WITH TIME ZONE`, e.g., `TIME(3) WITH TIME ZONE`)\n*   `TIMESTAMP` (optionally with precision and/or `WITH TIME ZONE`, e.g., `TIMESTAMP(6) WITH TIME ZONE`)\n*   `TSQUERY`\n*   `TSVECTOR`\n*   `UUID`\n*   `XML`\n*   Custom ENUM types defined via `PGEnum` (see FR-SDEF-014, FR-SDEF-016).\n\n**3.4.2 String Case Conversion Utility (DD-UTIL)**\nWhile an internal utility, its effect on observable table and ENUM type naming is a requirement.\n*   **DD-UTIL-001:** Snake Case Conversion: The system must internally possess a utility to convert various string casings (CamelCase, PascalCase, dot.case, kebab-case, space separated, underscore_separated) into a standardized snake_case format (e.g., \"MyTable\" -> \"my_table\", \"ColumnONE\" -> \"column_one\"). This is used for FR-SDEF-001.1 and FR-SDEF-014.1.",
        "structured_requirements": [
            {
                "requirement_id": "FR-SDEF-001",
                "requirement_description": "Table Definition: The system shall allow users to define database tables programmatically.",
                "test_traceability": [
                    {
                        "id": "tests/test_types.py::test_create_table",
                        "description": ""
                    },
                    {
                        "id": "tests/test_types.py::TypeOptionsTable::TypeOptionsTable",
                        "description": ""
                    },
                    {
                        "id": "tests/test_types.py::ColumnOptionsTable::ColumnOptionsTable",
                        "description": ""
                    },
                    {
                        "id": "tests/test_types.py::test_enum",
                        "description": "for `UsesEnum` table"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Table::__init_subclass__",
                        "description": "utilizes `pgqb/_snake.py`"
                    }
                ]
            },
            {
                "requirement_id": "FR-SDEF-001.1",
                "requirement_description": "Table Naming Convention: SQL table names shall be automatically derived from the user-defined table class name, converted to snake_case, and enclosed in double quotes (e.g., Python class `UserData` results in SQL table name `\"user_data\"`).",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "FR-SDEF-002",
                "requirement_description": "Column Definition: The system shall allow users to define columns within tables, associating them with Python class attributes.",
                "test_traceability": [
                    {
                        "id": "tests/test_types.py::test_create_table",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Table::__init_subclass__",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Column",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SDEF-002.1",
                "requirement_description": "Column Naming Convention: SQL column names shall be automatically derived from the attribute name in the table class definition and enclosed in double quotes (e.g., attribute `first_name` results in SQL column name `\"first_name\"`).",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "FR-SDEF-003",
                "requirement_description": "Data Type Specification: The system shall support associating PostgreSQL data types with columns. A comprehensive list of supported types is in Section 3.4 (Data Dictionary).",
                "test_traceability": [
                    {
                        "id": "tests/test_types.py::test_create_table",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/types.py",
                        "description": "various type classes"
                    },
                    {
                        "id": "pgqb/builder.py::Column",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SDEF-004",
                "requirement_description": "Parameterized Data Types: The system shall allow specification of parameters for data types that support them.\nExamples include: `CHAR(length)`, `VARCHAR(length)`, `INTERVAL(fields, precision)`, `NUMERIC(precision, scale)`, `TIME(precision, with_time_zone)`, `TIMESTAMP(precision, with_time_zone)`.",
                "test_traceability": [
                    {
                        "id": "tests/test_types.py::test_type_options",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/types.py::CHAR",
                        "description": ""
                    },
                    {
                        "id": "VARCHAR",
                        "description": ""
                    },
                    {
                        "id": "INTERVAL",
                        "description": ""
                    },
                    {
                        "id": "NUMERIC",
                        "description": ""
                    },
                    {
                        "id": "TIME",
                        "description": ""
                    },
                    {
                        "id": "TIMESTAMP",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SDEF-005",
                "requirement_description": "Column Nullability: The system shall allow columns to be defined as nullable or non-nullable. By default, columns are non-nullable unless specified otherwise or if they are primary keys (which are implicitly NOT NULL).",
                "test_traceability": [
                    {
                        "id": "tests/test_types.py::test_create_table",
                        "description": "implicit NOT NULL for most"
                    },
                    {
                        "id": "tests/test_types.py::test_type_options",
                        "description": "explicit `null=True`"
                    },
                    {
                        "id": "tests/test_types.py::test_column_options",
                        "description": "explicit `null=True`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Column::__init__",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Column::_create",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SDEF-006",
                "requirement_description": "Primary Key Constraint: The system shall allow one or more columns to be designated as a primary key for a table. This includes support for composite primary keys.",
                "test_traceability": [
                    {
                        "id": "tests/test_types.py::test_create_table",
                        "description": "composite PK `id, bigint`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Column::__init__",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Table::create_table",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SDEF-007",
                "requirement_description": "Unique Constraint: The system shall allow a unique constraint to be defined on a column.",
                "test_traceability": [
                    {
                        "id": "tests/test_types.py::test_column_options",
                        "description": "on `integer` column"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Column::__init__",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Column::_create",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SDEF-008",
                "requirement_description": "Default Value: The system shall allow a default value to be specified for a column.",
                "test_traceability": [
                    {
                        "id": "tests/test_types.py::test_type_options",
                        "description": "default for `varchar`"
                    },
                    {
                        "id": "tests/test_types.py::test_column_options",
                        "description": "default for `integer`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Column::__init__",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Column::_create",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SDEF-009",
                "requirement_description": "Check Constraint: The system shall allow a custom check constraint string to be defined for a column.",
                "test_traceability": [
                    {
                        "id": "tests/test_types.py::test_column_options",
                        "description": "check on `integer` column"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Column::__init__",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Column::_create",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SDEF-010",
                "requirement_description": "Foreign Key Constraint: The system shall allow a foreign key constraint to be defined on a column or set of columns, referencing columns in another table. This includes support for composite foreign keys.",
                "test_traceability": [
                    {
                        "id": "tests/test_types.py::test_column_options",
                        "description": "fk to `User.id`, fk2 to `User.bigint`, forming a composite FK"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Column::__init__",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Table::create_table",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SDEF-011",
                "requirement_description": "Column Indexing: The system shall allow an index to be automatically created for a specified column.",
                "test_traceability": [
                    {
                        "id": "tests/test_types.py::test_column_options",
                        "description": "index on `integer` column"
                    },
                    {
                        "id": "README example",
                        "description": "`email` column"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Column::__init__",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Table::create_table",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SDEF-012",
                "requirement_description": "`CREATE TABLE` Statement Generation: The system shall generate a `CREATE TABLE IF NOT EXISTS` SQL statement accurately reflecting the defined table, columns, types, and constraints.",
                "test_traceability": [
                    {
                        "id": "tests/test_types.py::test_create_table",
                        "description": ""
                    },
                    {
                        "id": "tests/test_types.py::test_type_options",
                        "description": ""
                    },
                    {
                        "id": "tests/test_types.py::test_column_options",
                        "description": ""
                    },
                    {
                        "id": "tests/test_types.py::test_enum",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Table::create_table",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SDEF-013",
                "requirement_description": "`CREATE INDEX` Statement Generation: For columns marked for indexing, the system shall generate corresponding `CREATE INDEX` SQL statements separate from the `CREATE TABLE` statement.",
                "test_traceability": [
                    {
                        "id": "tests/test_types.py::test_column_options",
                        "description": ""
                    },
                    {
                        "id": "README example",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Table::create_table",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SDEF-014",
                "requirement_description": "Custom ENUM Type Definition: The system shall allow users to define custom PostgreSQL ENUM types with a specified set of string values.",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "FR-SDEF-014.1",
                "requirement_description": "ENUM Type Naming Convention: SQL ENUM type names shall be automatically derived from the user-defined ENUM class name, converted to snake_case, and capitalized (e.g., Python class `MyStatus` results in SQL ENUM type `MY_STATUS`).",
                "test_traceability": [
                    {
                        "id": "tests/test_types.py::test_enum",
                        "description": "`MyE` enum"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/types.py::PGEnum",
                        "description": ""
                    },
                    {
                        "id": "pgqb/types.py::PGEnum::pg_enum_name",
                        "description": "utilizes `pgqb/_snake.py`"
                    }
                ]
            },
            {
                "requirement_id": "FR-SDEF-015",
                "requirement_description": "`CREATE TYPE AS ENUM` Statement Generation: The system shall generate a `CREATE TYPE <enum_name> AS ENUM ('value1', 'value2', ...);` SQL statement for defined custom ENUM types.",
                "test_traceability": [
                    {
                        "id": "tests/test_types.py::test_enum",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/types.py::PGEnum::pg_enum_get_create",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SDEF-016",
                "requirement_description": "Custom ENUM Usage: The system shall allow defined custom ENUM types to be used as data types for table columns.",
                "test_traceability": [
                    {
                        "id": "tests/test_types.py::test_enum",
                        "description": "`UsesEnum` table with `col` of type `MyE`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Column::_create",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-QGEN-001",
                "requirement_description": "Query Preparation: The system shall provide a mechanism (e.g., a `.prepare()` method) to finalize any constructed query definition. This mechanism must return two distinct outputs:\n1.  A SQL query string, formatted for PostgreSQL, with parameter placeholders.\n2.  An ordered list of parameter values corresponding to the placeholders in the SQL string.",
                "test_traceability": [
                    {
                        "id": "Applies to all tests in `tests/test_builder.py` that call `.prepare()`",
                        "description": "e.g., `test_select`, `test_insert`, `test_update`, `test_delete`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::QueryBuilder::prepare",
                        "description": "and its concrete implementations"
                    }
                ]
            },
            {
                "requirement_id": "FR-SEL-001",
                "requirement_description": "Select All Columns: The system shall allow selecting all defined columns from a table by specifying the table itself in the selection list.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_select",
                        "description": "e.g., `select(User)`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Select::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SEL-002",
                "requirement_description": "Select Specific Columns: The system shall allow selecting specific columns by providing `Column` objects.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_select_columns",
                        "description": "e.g., `select(User.id, Task.id)`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Select::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SEL-003",
                "requirement_description": "Column Aliasing: The system shall allow aliasing of selected columns using an `AS` keyword equivalent.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_select_columns",
                        "description": "e.g., `User.first.as_(\"name\")`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Column::as_",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::As",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SEL-004",
                "requirement_description": "Expression Aliasing: The system shall allow aliasing of expressions in the select list using an `AS` keyword equivalent.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_operators",
                        "description": "e.g., `(User.id == 3).as_(\"mocha\")`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Expression::as_",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::As",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SEL-005",
                "requirement_description": "`FROM` Clause: The system shall generate a `FROM` clause specifying the primary table for the select query.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_select",
                        "description": ""
                    },
                    {
                        "id": "tests/test_builder.py::test_select_columns",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Select::from_",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::From",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SEL-006",
                "requirement_description": "`JOIN` Clause: The system shall support joining tables.",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "FR-SEL-006.1",
                "requirement_description": "`INNER JOIN`: Support for `INNER JOIN` (or `JOIN`) clauses.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_select",
                        "description": "e.g., `join(Task).on(...)`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/__init__.py::join",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Join",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SEL-006.2",
                "requirement_description": "`LEFT JOIN`: Support for `LEFT JOIN` clauses.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_select",
                        "description": ""
                    },
                    {
                        "id": "tests/test_builder.py::test_select_columns",
                        "description": "e.g., `left_join(Task).on(...)`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/__init__.py::left_join",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::LeftJoin",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SEL-006.3",
                "requirement_description": "`RIGHT JOIN`: Support for `RIGHT JOIN` clauses.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_select",
                        "description": "e.g., `right_join(Task).on(...)`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/__init__.py::right_join",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::RightJoin",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SEL-006.4",
                "requirement_description": "`ON` Condition: `JOIN` clauses must be accompanied by an `ON` condition specifying the join predicate. `ON` conditions can involve comparisons between columns of different tables or columns and literal values.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_select",
                        "description": ""
                    },
                    {
                        "id": "tests/test_builder.py::test_select_columns",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/__init__.py::on",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Join::on",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::On",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SEL-006.5",
                "requirement_description": "Multiple `ON` Conditions: `ON` conditions can consist of multiple expressions combined using logical `AND`.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_select",
                        "description": "e.g., `Task.user_id == User.id and Task.user_id == User.id`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::On",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::_prepare_expressions",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SEL-007",
                "requirement_description": "`WHERE` Clause: The system shall support a `WHERE` clause for filtering results based on specified conditions. For details on condition expressions, see Section 3.1.7 (Expressions and Conditions).",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_select",
                        "description": ""
                    },
                    {
                        "id": "tests/test_builder.py::test_expressions",
                        "description": ""
                    },
                    {
                        "id": "tests/test_builder.py::test_operators",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::_WhereMixin::where",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Where",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SEL-008",
                "requirement_description": "`ORDER BY` Clause: The system shall support an `ORDER BY` clause for sorting results.",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "FR-SEL-008.1",
                "requirement_description": "Multiple Columns: Ordering can be specified by one or more columns.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_select",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::_OrderByMixin::order_by",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::OrderBy",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SEL-008.2",
                "requirement_description": "Sort Direction: For each ordering column, `ASC` (ascending) or `DESC` (descending) sort direction can be specified.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_select",
                        "description": "e.g., `Task.value.asc()`, `Task.value.desc()`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Column::asc",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Column::desc",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::OrderBy",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SEL-009",
                "requirement_description": "`LIMIT` Clause: The system shall support a `LIMIT` clause to restrict the number of rows returned.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_select_columns",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::_LimitMixin::limit",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Limit",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SEL-010",
                "requirement_description": "`OFFSET` Clause: The system shall support an `OFFSET` clause to skip a specified number of rows before returning results.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_select_columns",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::_OffsetMixin::offset",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Offset",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-INS-001",
                "requirement_description": "`INSERT INTO` Table: The system shall allow construction of `INSERT INTO` queries targeting a specified table.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_insert",
                        "description": ""
                    },
                    {
                        "id": "tests/test_builder.py::test_insert_str_columns",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/__init__.py::insert_into",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::InsertInto",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-INS-002",
                "requirement_description": "Values Specification: The system shall allow specifying columns and their corresponding values for insertion using a dictionary-like structure.",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "FR-INS-002.1",
                "requirement_description": "Values are Parameterized: All provided values shall be parameterized in the final query.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_insert",
                        "description": ""
                    },
                    {
                        "id": "tests/test_builder.py::test_insert_str_columns",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::InsertInto::values",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Values",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-INS-002.2",
                "requirement_description": "Column Identification: Columns in the values dictionary can be identified either by `Column` objects or by string names corresponding to column attributes in the table definition.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_insert",
                        "description": "Column object"
                    },
                    {
                        "id": "tests/test_builder.py::test_insert_str_columns",
                        "description": "string name"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Values::prepare",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-UPD-001",
                "requirement_description": "`UPDATE` Table: The system shall allow construction of `UPDATE` queries targeting a specified table.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_update",
                        "description": ""
                    },
                    {
                        "id": "tests/test_builder.py::test_update_str_columns",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/__init__.py::update",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Update",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-UPD-002",
                "requirement_description": "`SET` Clause: The system shall support a `SET` clause for specifying columns and their new values using a dictionary-like structure.",
                "test_traceability": [],
                "code_traceability": []
            },
            {
                "requirement_id": "FR-UPD-002.1",
                "requirement_description": "Values are Parameterized: Literal values provided in the `SET` clause shall be parameterized.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_update",
                        "description": ""
                    },
                    {
                        "id": "tests/test_builder.py::test_update_str_columns",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Update::set",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Set",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-UPD-002.2",
                "requirement_description": "Subquery in SET: Values in the `SET` clause can be derived from a sub-select query. The subquery's SQL and parameters shall be integrated into the main `UPDATE` query.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_update",
                        "description": "setting `User.id` to a select query"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Set::prepare",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-UPD-002.3",
                "requirement_description": "Column Identification: Columns in the `SET` dictionary can be identified either by `Column` objects or by string names corresponding to column attributes in the table definition.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_update",
                        "description": "Column object"
                    },
                    {
                        "id": "tests/test_builder.py::test_update_str_columns",
                        "description": "string name"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Set::prepare",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-UPD-003",
                "requirement_description": "`WHERE` Clause for UPDATE: The system shall support a `WHERE` clause to specify which rows to update, with the same capabilities as `WHERE` clauses in `SELECT` queries (see Section 3.1.7).",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_update",
                        "description": ""
                    },
                    {
                        "id": "tests/test_builder.py::test_update_str_columns",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Set",
                        "description": "inherits `_WhereMixin`"
                    },
                    {
                        "id": "pgqb/builder.py::Where",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEL-001",
                "requirement_description": "`DELETE FROM` Table: The system shall allow construction of `DELETE FROM` queries targeting a specified table.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_delete",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/__init__.py::delete_from",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Delete",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEL-002",
                "requirement_description": "`WHERE` Clause for DELETE: The system shall support a `WHERE` clause to specify which rows to delete, with the same capabilities as `WHERE` clauses in `SELECT` queries (see Section 3.1.7).",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_delete",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Delete",
                        "description": "inherits `_WhereMixin`"
                    },
                    {
                        "id": "pgqb/builder.py::Where",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXPR-001",
                "requirement_description": "Comparison Operators: The system shall support the following comparison operators between columns, expressions, and literal values:\n`>` (greater than)\n`<` (less than)\n`>=` (greater than or equal to)\n`<=` (less than or equal to)\n`=` (equal to)\n`!=` (not equal to)\nLiteral values used in comparisons shall be parameterized. Enum values should be converted to their underlying value for parameterization.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_select",
                        "description": "e.g., `Task.value <= MyEnum.OPTION`"
                    },
                    {
                        "id": "tests/test_builder.py::test_expressions",
                        "description": ""
                    },
                    {
                        "id": "tests/test_builder.py::test_operators",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::_OperatorMixin",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Expression",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXPR-002",
                "requirement_description": "`IS` Operators: The system shall support SQL `IS` operators for comparisons with `NULL`, `TRUE`, and `FALSE`.\n`IS NULL` (implicitly generated for `col == None`)\n`IS NOT NULL` (implicitly generated for `col != None`)\n`IS TRUE` (implicitly generated for `col == True`)\n`IS NOT TRUE` (implicitly generated for `col != True`)\n`IS FALSE` (implicitly generated for `col == False`)\n`IS NOT FALSE` (implicitly generated for `col != False`)\nThe system shall also provide explicit `is_()` and `is_not()` methods for these comparisons.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_operators",
                        "description": "e.g., `User.last.is_(None)`, `User.first.is_not(True)`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::_OperatorMixin::__eq__",
                        "description": ""
                    },
                    {
                        "id": "__ne__",
                        "description": ""
                    },
                    {
                        "id": "is_",
                        "description": ""
                    },
                    {
                        "id": "is_not",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Expression",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXPR-003",
                "requirement_description": "Logical Operators: The system shall support logical operators to combine multiple conditions:\n`AND`\n`OR`\n`AND NOT`\n`OR NOT`\n`OR NOT` applied to multiple sub-conditions should group them in parentheses in the generated SQL (e.g., `OR NOT (condition1 AND condition2)`).",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_expressions",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/__init__.py::and_",
                        "description": ""
                    },
                    {
                        "id": "or_",
                        "description": ""
                    },
                    {
                        "id": "and_not",
                        "description": ""
                    },
                    {
                        "id": "or_not",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::LogicGate",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXPR-004",
                "requirement_description": "Arithmetic Operators: The system shall support arithmetic operations (`+`, `-`, `*`, `/`, `%`) in expressions, applicable between columns, or columns and literal values. Literal values shall be parameterized.",
                "test_traceability": [
                    {
                        "id": "tests/test_builder.py::test_operators_chained",
                        "description": "Note: This test is marked xfail in the original suite; the requirement is for the developer to implement this correctly to pass the test"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::_OperatorMixin",
                        "description": "arithmetic methods"
                    },
                    {
                        "id": "pgqb/builder.py::Expression",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ERR-001",
                "requirement_description": "Invalid `NUMERIC` Definition: The system shall raise an error if a `NUMERIC` data type is defined with a `scale` parameter but without a corresponding `precision` parameter during schema generation preparations.",
                "test_traceability": [
                    {
                        "id": "tests/test_types.py::test_type_options",
                        "description": "specifically `with pytest.raises(ValueError): Column(NUMERIC(scale=1))._create()`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/types.py::NUMERIC::__str__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ERR-002",
                "requirement_description": "Missing `ON` Condition for `JOIN`: The system shall raise an error if an attempt is made to prepare a query containing a `JOIN` clause for which no `ON` condition has been specified.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis.",
                        "description": "No direct corresponding original test case."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Join::prepare",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ERR-003",
                "requirement_description": "Unsupported Argument in `SELECT`: The system shall raise an error during `SELECT` clause construction if an argument of an unsupported type (i.e., not a `Column`, `Table`, or `As` instance) is provided for the items to be selected.",
                "test_traceability": [
                    {
                        "id": "Derived from source code analysis.",
                        "description": "No direct corresponding original test case."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Select::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-001",
                "requirement_description": "PostgreSQL Compatibility: The system shall generate SQL query strings that are syntactically valid for PostgreSQL.",
                "test_traceability": [
                    {
                        "id": "All tests in `tests/test_builder.py` and `tests/test_types.py` that assert generated SQL strings.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "System-wide",
                        "description": "System-wide; encompasses all query and DDL generation logic."
                    }
                ]
            },
            {
                "requirement_id": "EIR-002",
                "requirement_description": "Parameter Placeholder: Parameterized values in the generated SQL query strings must be represented by the '?' (question mark) placeholder.",
                "test_traceability": [
                    {
                        "id": "All tests in `tests/test_builder.py` that verify SQL strings and associated parameter lists",
                        "description": "e.g., `test_select`, `test_insert`, `test_update`, `test_delete`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Expression",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Values",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Set",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-003",
                "requirement_description": "Identifier Quoting: All SQL identifiers (table names, column names, generated ENUM type names) in the generated query strings shall be enclosed in double quotes (e.g., `\"user\"`, `\"user\".\"id\"`, `\"MY_ENUM_TYPE\"`).",
                "test_traceability": [
                    {
                        "id": "All tests in `tests/test_builder.py` and `tests/test_types.py` that assert generated SQL strings.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/builder.py::Table::__init_subclass__",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Column::__str__",
                        "description": ""
                    },
                    {
                        "id": "pgqb/types.py::PGEnum::pg_enum_name",
                        "description": ""
                    },
                    {
                        "id": "pgqb/builder.py::Column::_create",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "DD-TYPES",
                "requirement_description": "The system shall provide representations for and support the use of the following PostgreSQL data types in column definitions. This includes generating the correct SQL type name in `CREATE TABLE` statements.\n`BIGINT`\n`BIGSERIAL`\n`BIT` (without parameters)\n`VARBIT` (without parameters)\n`BOOLEAN`\n`BOX`\n`BYTEA`\n`CHAR` (optionally with length, e.g., `CHAR(10)`)\n`VARCHAR` (optionally with length, e.g., `VARCHAR(255)`)\n`CIDR`\n`CIRCLE`\n`DATE`\n`DOUBLE PRECISION` (represented in the library as `DOUBLE`)\n`INET`\n`INTEGER`\n`INTERVAL` (optionally with fields string like \"DAY TO SECOND\" and/or precision, e.g., `INTERVAL DAY TO SECOND(3)`)\n`JSON`\n`JSONB`\n`LINE`\n`LSEG`\n`MACADDR`\n`MACADDR8`\n`MONEY`\n`NUMERIC` (optionally with precision only, e.g., `NUMERIC(10)`, or precision and scale, e.g., `NUMERIC(10, 2)`)\n`PATH`\n`PG_LSN`\n`PG_SNAPSHOT`\n`POINT`\n`POLYGON`\n`REAL`\n`SMALLINT`\n`SMALLSERIAL`\n`SERIAL`\n`TEXT`\n`TIME` (optionally with precision and/or `WITH TIME ZONE`, e.g., `TIME(3) WITH TIME ZONE`)\n`TIMESTAMP` (optionally with precision and/or `WITH TIME ZONE`, e.g., `TIMESTAMP(6) WITH TIME ZONE`)\n`TSQUERY`\n`TSVECTOR`\n`UUID`\n`XML`\nCustom ENUM types defined via `PGEnum` (see FR-SDEF-014, FR-SDEF-016).",
                "test_traceability": [
                    {
                        "id": "tests/test_types.py::test_create_table",
                        "description": ""
                    },
                    {
                        "id": "tests/test_types.py::test_type_options",
                        "description": ""
                    },
                    {
                        "id": "tests/test_types.py::test_enum",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "All classes defined in `pgqb/types.py` that inherit from `SQLType`",
                        "description": "and `pgqb/types.py::PGEnum`"
                    }
                ]
            },
            {
                "requirement_id": "DD-UTIL-001",
                "requirement_description": "Snake Case Conversion: The system must internally possess a utility to convert various string casings (CamelCase, PascalCase, dot.case, kebab-case, space separated, underscore_separated) into a standardized snake_case format (e.g., \"MyTable\" -> \"my_table\", \"ColumnONE\" -> \"column_one\"). This is used for FR-SDEF-001.1 and FR-SDEF-014.1.",
                "test_traceability": [
                    {
                        "id": "tests/test_snake.py::test_to_snake",
                        "description": ""
                    },
                    {
                        "id": "tests/test_snake.py::test_get_words",
                        "description": "as `get_words` is a component of `to_snake`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "pgqb/_snake.py::to_snake",
                        "description": ""
                    },
                    {
                        "id": "pgqb/_snake.py::get_words",
                        "description": ""
                    },
                    {
                        "id": "pgqb/_snake.py::_split_words_on_regex",
                        "description": ""
                    }
                ]
            }
        ],
        "commit_sha": "d2754ef7ef773c0d0f436a06a4e0afdd65d1a820",
        "full_code_skeleton": "--- File: pgqb/__init__.py ---\n```python\n\"\"\"A simple SQL query builder for PostgreSQL.\"\"\"\nfrom typing import Type\n\n\ndef insert_into(table: Type[Table]) -> InsertInto:\n    \"\"\"Build an insert query.\"\"\"\n    pass\n\n\ndef delete_from(table: Type[Table]) -> Delete:\n    \"\"\"Build a delete query.\"\"\"\n    pass\n\n\ndef select(*args: Column | Type[Table] | As) -> Select:\n    \"\"\"Build a select query.\"\"\"\n    pass\n\n\ndef update(table: Type[Table]) -> Update:\n    \"\"\"Build an update query.\"\"\"\n    pass\n\n\ndef join(table: Type[Table]) -> Join:\n    \"\"\"Build a join query.\"\"\"\n    pass\n\n\ndef left_join(table: Type[Table]) -> Join:\n    \"\"\"Build a left join query.\"\"\"\n    pass\n\n\ndef right_join(table: Type[Table]) -> Join:\n    \"\"\"Build a right join query.\"\"\"\n    pass\n\n\ndef on(evaluation: Expression, *evaluations: Expression | LogicGate) -> On:\n    \"\"\"Build an \"on\" query for a join.\"\"\"\n    pass\n\n\ndef and_(evaluation: Expression, *evaluations: Expression | LogicGate) -> LogicGate:\n    \"\"\"Build an \"and\" expression for a part of a query.\"\"\"\n    pass\n\n\ndef and_not(evaluation: Expression, *evaluations: Expression | LogicGate) -> LogicGate:\n    \"\"\"Build an \"and not\" expression for a part of a query.\"\"\"\n    pass\n\n\ndef or_(evaluation: Expression, *evaluations: Expression | LogicGate) -> LogicGate:\n    \"\"\"Build an \"or\" expression for a part of a query.\"\"\"\n    pass\n\n\ndef or_not(evaluation: Expression, *evaluations: Expression | LogicGate) -> LogicGate:\n    \"\"\"Build an \"or not\" expression for a part of a query.\"\"\"\n    pass\n```\n--- File: pgqb/_snake.py ---\n```python\nfrom typing import Union\n\n\ndef to_snake(string: str) -> str:\n    \"\"\"\n    Return a version of the string in `snake_case` format.\n\n    Args:\n        string: The string to convert to snake_case.\n\n    Returns:\n        The string in snake_case format.\n    \"\"\"\n    pass\n\n\ndef get_words(string: str) -> list[str]:\n    \"\"\"\n    Get a list of the words in a string in the order they appear.\n\n    Args:\n        string: The string to get the words from.\n\n    Returns:\n        A list of the words in the string.\n    \"\"\"\n    pass\n\n\ndef _split_words_on_regex(words: list[str], regex: Union[re.Pattern, str]) -> list[str]:  # type: ignore\n    \"\"\"\n    Split words on a regex.\n\n    Args:\n        words (list[str]): The list of words to split.\n        regex (Union[Pattern, str]): The regex to split on.\n\n    Returns:\n        list[str]: The list of words with the split words inserted.\n    \"\"\"\n    pass\n```\n--- File: pgqb/types.py ---\n```python\n\"\"\"PostgreSQL types for pgqb query builder library.\n\nThis module contains classes for PostgreSQL data types. The classes are\nused to specify the type of a column in a table. The classes are used to\ngenerate the SQL for creating a table.\n\nFrom the docs: https://www.postgresql.org/docs/current/datatype.html\n\"\"\"\n\nimport enum\n\n\nclass PGEnum(enum.Enum):\n    \"\"\"Enum type class.\"\"\"\n\n    @classmethod\n    def pg_enum_name(cls) -> str:\n        \"\"\"Get the SQL name for this custom enum.\n\n        Args:\n            cls: The class to get the SQL name for.\n\n        Returns:\n            str: The SQL name for this custom enum.\n        \"\"\"\n        pass\n\n    @classmethod\n    def pg_enum_get_create(cls) -> str:\n        \"\"\"Get create enum SQL.\n\n        Args:\n            cls: The class to get the create enum SQL for.\n\n        Returns:\n            str: The create enum SQL.\n        \"\"\"\n        pass\n\n\nclass SQLType:\n    \"\"\"Base SQL type class.\"\"\"\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\n\nclass BIGINT(SQLType):\n    \"\"\"Signed eight-byte integer.\"\"\"\n    pass\n\n\nclass BIGSERIAL(SQLType):\n    \"\"\"Auto-incrementing eight-byte integer.\"\"\"\n    pass\n\n\nclass BIT(SQLType):\n    \"\"\"Fixed-length bit string.\"\"\"\n    pass\n\n\nclass VARBIT(SQLType):\n    \"\"\"Variable-length bit string.\"\"\"\n    pass\n\n\nclass BOOLEAN(SQLType):\n    \"\"\"Logical Boolean (true/false).\"\"\"\n    pass\n\n\nclass BOX(SQLType):\n    \"\"\"Rectangular box on a plane.\"\"\"\n    pass\n\n\nclass BYTEA(SQLType):\n    \"\"\"Binary data (byte array).\"\"\"\n    pass\n\n\nclass CHAR(SQLType):\n    \"\"\"Fixed-length character string.\"\"\"\n\n    def __init__(self, fixed_length: int | None = None) -> None:\n        \"\"\"Fixed-length character string.\n\n        Args:\n            fixed_length: The fixed length of the string.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\n\nclass VARCHAR(SQLType):\n    \"\"\"Variable-length character string.\"\"\"\n\n    def __init__(self, variable_length: int | None = None) -> None:\n        \"\"\"Variable-length character string.\n\n        Args:\n            variable_length: The variable length of the string.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\n\nclass CIDR(SQLType):\n    \"\"\"IPv4 or IPv6 network address.\"\"\"\n    pass\n\n\nclass CIRCLE(SQLType):\n    \"\"\"Circle on a plane.\"\"\"\n    pass\n\n\nclass DATE(SQLType):\n    \"\"\"Calendar date (year, month, day).\"\"\"\n    pass\n\n\nclass DOUBLE(SQLType):\n    \"\"\"Double precision floating-point number (8 bytes).\"\"\"\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\n\nclass INET(SQLType):\n    \"\"\"IPv4 or IPv6 host address.\"\"\"\n    pass\n\n\nclass INTEGER(SQLType):\n    \"\"\"Signed four-byte integer.\"\"\"\n    pass\n\n\nclass INTERVAL(SQLType):\n    \"\"\"Time span.\"\"\"\n\n    def __init__(self, fields: str | None = None, precision: int | None = None) -> None:\n        \"\"\"Time span.\n\n        Args:\n            fields: The fields of the interval.\n            precision: The precision of the interval.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\n\nclass JSON(SQLType):\n    \"\"\"Textual JSON data.\"\"\"\n    pass\n\n\nclass JSONB(SQLType):\n    \"\"\"Binary JSON data, decomposed.\"\"\"\n    pass\n\n\nclass LINE(SQLType):\n    \"\"\"Infinite line on a plane.\"\"\"\n    pass\n\n\nclass LSEG(SQLType):\n    \"\"\"Line segment on a plane.\"\"\"\n    pass\n\n\nclass MACADDR(SQLType):\n    \"\"\"MAC (Media Access Control) address.\"\"\"\n    pass\n\n\nclass MACADDR8(SQLType):\n    \"\"\"MAC (Media Access Control) address (EUI-64 format).\"\"\"\n    pass\n\n\nclass MONEY(SQLType):\n    \"\"\"Currency amount.\"\"\"\n    pass\n\n\nclass NUMERIC(SQLType):\n    \"\"\"Exact numeric of selectable precision.\"\"\"\n\n    def __init__(self, precision: int | None = None, scale: int | None = None) -> None:\n        \"\"\"Exact numeric of selectable precision.\n\n        Args:\n            precision: The precision of the numeric.\n            scale: The scale of the numeric.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\n\nclass PATH(SQLType):\n    \"\"\"Geometric path on a plane.\"\"\"\n    pass\n\n\nclass PG_LSN(SQLType):  # noqa: N801\n    \"\"\"PostgreSQL Log Sequence Number.\"\"\"\n    pass\n\n\nclass PG_SNAPSHOT(SQLType):  # noqa: N801\n    \"\"\"User-level transaction ID snapshot.\"\"\"\n    pass\n\n\nclass POINT(SQLType):\n    \"\"\"Geometric point on a plane.\"\"\"\n    pass\n\n\nclass POLYGON(SQLType):\n    \"\"\"Closed geometric path on a plane.\"\"\"\n    pass\n\n\nclass REAL(SQLType):\n    \"\"\"Single precision floating-point number (4 bytes).\"\"\"\n    pass\n\n\nclass SMALLINT(SQLType):\n    \"\"\"Signed two-byte integer.\"\"\"\n    pass\n\n\nclass SMALLSERIAL(SQLType):\n    \"\"\"Auto-incrementing two-byte integer.\"\"\"\n    pass\n\n\nclass SERIAL(SQLType):\n    \"\"\"Auto-incrementing four-byte integer.\"\"\"\n    pass\n\n\nclass TEXT(SQLType):\n    \"\"\"Variable-length character string.\"\"\"\n    pass\n\n\nclass TIME(SQLType):\n    \"\"\"Time of day.\"\"\"\n\n    def __init__(\n        self, precision: int | None = None, *, with_time_zone: bool = False\n    ) -> None:\n        \"\"\"Time of day.\n\n        Args:\n            precision: The precision of the time.\n            with_time_zone: Whether to include the time zone.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\n\nclass TIMESTAMP(SQLType):\n    \"\"\"Date and time.\"\"\"\n\n    def __init__(\n        self, precision: int | None = None, *, with_time_zone: bool = False\n    ) -> None:\n        \"\"\"Date and time.\n\n        Args:\n            precision: The precision of the timestamp.\n            with_time_zone: Whether to include the time zone.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\n\nclass TSQUERY(SQLType):\n    \"\"\"Text search query.\"\"\"\n    pass\n\n\nclass TSVECTOR(SQLType):\n    \"\"\"Text search document.\"\"\"\n    pass\n\n\nclass UUID(SQLType):\n    \"\"\"Universally unique identifier.\"\"\"\n    pass\n\n\nclass XML(SQLType):\n    \"\"\"XML data.\"\"\"\n    pass\n```\n--- File: pgqb/builder.py ---\n```python\n\"\"\"Query building functions for pgqb.\n\nThis module provides a set of classes and functions for building SQL queries\nin a Pythonic way. It includes support for various SQL operations such as\nSELECT, INSERT, UPDATE, DELETE, JOIN, WHERE, ORDER BY, LIMIT, and OFFSET.\n\"\"\"\n\nimport abc\nimport enum\nimport typing\nfrom abc import ABC\nfrom typing import Any, Type\n\n\nclass QueryBuilder(abc.ABC):\n    \"\"\"Base class for all query builders.\n\n    This abstract class defines the interface for all query builders in the system.\n    All specific query builder classes should inherit from this base class.\n    \"\"\"\n\n    @abc.abstractmethod\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Get all params and the SQL string.\n\n        Returns:\n            A tuple containing the SQL string and a list of parameters.\n        \"\"\"\n        pass\n\n\nclass _OperatorMixin(QueryBuilder, abc.ABC):  # noqa: PLW1641\n    \"\"\"Mixin class providing common SQL comparison and arithmetic operators.\n\n    This mixin adds methods for common SQL operators like >, <, =, !=, +, -, *, /, %.\n    It also includes IS and IS NOT operators.\n    \"\"\"\n\n    def __gt__(self, other: Any) -> Expression:\n        \"\"\"Greater than operator.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the \"greater than\" comparison.\n        \"\"\"\n        pass\n\n    def __ge__(self, other: Any) -> Expression:\n        \"\"\"Greater than or equal to operator.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the \"greater than or equal to\" comparison.\n        \"\"\"\n        pass\n\n    def __lt__(self, other: Any) -> Expression:\n        \"\"\"Less than operator.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the \"less than\" comparison.\n        \"\"\"\n        pass\n\n    def __le__(self, other: Any) -> Expression:\n        \"\"\"Less than or equal to operator.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the \"less than or equal to\" comparison.\n        \"\"\"\n        pass\n\n    def __eq__(self, other: object) -> Expression:  # type: ignore\n        \"\"\"Equality operator.\n\n        For None, True, or False, uses IS operator instead of =.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the equality comparison.\n        \"\"\"\n        pass\n\n    def __ne__(self, other: object) -> Expression:  # type: ignore\n        \"\"\"Inequality operator.\n\n        For None, True, or False, uses IS NOT operator instead of !=.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the inequality comparison.\n        \"\"\"\n        pass\n\n    def __add__(self, other: Any) -> Expression:\n        \"\"\"Addition operator.\n\n        Args:\n            other: The value to add.\n\n        Returns:\n            An Expression representing the addition operation.\n        \"\"\"\n        pass\n\n    def __sub__(self, other: Any) -> Expression:\n        \"\"\"Subtraction operator.\n\n        Args:\n            other: The value to subtract.\n\n        Returns:\n            An Expression representing the subtraction operation.\n        \"\"\"\n        pass\n\n    def __mul__(self, other: Any) -> Expression:\n        \"\"\"Multiplication operator.\n\n        Args:\n            other: The value to multiply by.\n\n        Returns:\n            An Expression representing the multiplication operation.\n        \"\"\"\n        pass\n\n    def __truediv__(self, other: Any) -> Expression:\n        \"\"\"Division operator.\n\n        Args:\n            other: The value to divide by.\n\n        Returns:\n            An Expression representing the division operation.\n        \"\"\"\n        pass\n\n    def __mod__(self, other: Any) -> Expression:\n        \"\"\"Modulo operator.\n\n        Args:\n            other: The value to mod by.\n\n        Returns:\n            An Expression representing the modulo operation.\n        \"\"\"\n        pass\n\n    def is_(self, other: Any) -> Expression:\n        \"\"\"Equality operator using IS.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the IS comparison.\n        \"\"\"\n        pass\n\n    def is_not(self, other: Any) -> Expression:\n        \"\"\"Inequality operator using IS NOT.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the IS NOT comparison.\n        \"\"\"\n        pass\n\n\nclass As(QueryBuilder):\n    \"\"\"Represents an SQL AS clause for aliasing.\n\n    This class is used to create aliases for columns or expressions in SQL queries.\n    \"\"\"\n\n    def __init__(self, sub_query: Column | Expression, alias: str) -> None:\n        \"\"\"Initialize an As instance.\n\n        Args:\n            sub_query: The Column or Expression to be aliased.\n            alias: The alias name.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the AS clause.\n\n        Returns:\n            A tuple containing the SQL string for the AS clause and any parameters.\n        \"\"\"\n        pass\n\n\nclass Column(_OperatorMixin):\n    \"\"\"Represents a column in a SQL table.\n\n    This class encapsulates the properties and behaviors of a database column,\n    including its data type, constraints, and other attributes.\n    \"\"\"\n\n    def __init__(  # noqa: PLR0913\n        self,\n        sql_type: SQLType | Type[PGEnum] | None = None,\n        *,\n        check: str | None = None,\n        default: Any | None = None,\n        foreign_key: Column | None = None,\n        index: bool = False,\n        null: bool = False,\n        primary: bool = False,\n        unique: bool = False,\n    ) -> None:\n        \"\"\"Initialize a Column instance.\n\n        Args:\n            sql_type: The SQL type for this column.\n            check: The check constraint for this column.\n            default: The default value for this column.\n            foreign_key: The foreign key for this column.\n            index: Whether to create an index for this column.\n            null: Whether this column is nullable.\n            primary: Whether this column is a primary key.\n            unique: Whether this column is unique.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\n\n        Returns:\n            A string in the format \"table.column\".\n        \"\"\"\n        pass\n\n    def __hash__(self) -> int:\n        \"\"\"Get the hash of this column.\n\n        Returns:\n            An integer hash value based on the string representation of the column.\n        \"\"\"\n        pass\n\n    def _create(self) -> str:\n        \"\"\"Get column create SQL.\n\n        Returns:\n            A string containing the SQL definition for creating this column.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Get column as SQL.\n\n        Returns:\n            A tuple containing the SQL string for this column and an empty list of parameters.\n        \"\"\"\n        pass\n\n    def as_(self, alias: str) -> As:\n        \"\"\"Create an alias for this column.\n\n        Args:\n            alias: The alias name for the column.\n\n        Returns:\n            An As instance representing the aliased column.\n        \"\"\"\n        pass\n\n    def asc(self) -> Column:\n        \"\"\"Set this column to be sorted in ascending order.\n\n        Returns:\n            A new Column instance with ascending sort order.\n        \"\"\"\n        pass\n\n    def desc(self) -> Column:\n        \"\"\"Set this column to be sorted in descending order.\n\n        Returns:\n            A new Column instance with descending sort order.\n        \"\"\"\n        pass\n\n    def asc_or_desc(self, asc: bool) -> Column:\n        \"\"\"Set this column to be sorted in ascending or descending order.\n\n        Args:\n            asc: True for ascending order, False for descending order.\n\n        Returns:\n            A new Column instance with the specified sort order.\n        \"\"\"\n        pass\n\n\nclass Table(type):\n    \"\"\"Metaclass for representing SQL tables.\n\n    This metaclass automatically processes class attributes to set up\n    table names and columns based on the class definition.\n    \"\"\"\n\n    __table_name__: str = \"\"\n    __table_columns__: dict[str, Column] = {}\n\n    def __init_subclass__(cls, **kwargs: Any) -> None:\n        \"\"\"Initialize a subclass of Table.\n\n        This method is called when a new subclass of Table is created. It sets up\n        the table name and processes the class attributes to identify columns.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        pass\n\n    @classmethod\n    def create_table(cls) -> str:\n        \"\"\"Generate SQL to create the table.\n\n        Returns:\n            A string containing the SQL CREATE TABLE statement for this table.\n        \"\"\"\n        pass\n\n\nclass _LimitMixin(QueryBuilder, abc.ABC):\n    \"\"\"Mixin class for adding LIMIT clause functionality.\"\"\"\n\n    def limit(self, limit: int) -> Limit:\n        \"\"\"Add a LIMIT clause to the query.\n\n        Args:\n            limit: The maximum number of rows to return.\n\n        Returns:\n            A Limit instance representing the LIMIT clause.\n        \"\"\"\n        pass\n\n\nclass _OffsetMixin(QueryBuilder, abc.ABC):\n    \"\"\"Mixin class for adding OFFSET clause functionality.\"\"\"\n\n    def offset(self, offset: int) -> Offset:\n        \"\"\"Add an OFFSET clause to the query.\n\n        Args:\n            offset: The number of rows to skip.\n\n        Returns:\n            An Offset instance representing the OFFSET clause.\n        \"\"\"\n        pass\n\n\nclass _PaginateMixin(_OffsetMixin, _LimitMixin, ABC):\n    \"\"\"Mixin class combining LIMIT and OFFSET functionality for pagination.\"\"\"\n\n    pass\n\n\nclass _OrderByMixin(QueryBuilder, abc.ABC):\n    \"\"\"Mixin class for adding ORDER BY clause functionality.\"\"\"\n\n    def order_by(self, *columns: Column) -> OrderBy:\n        \"\"\"Add an ORDER BY clause to the query.\n\n        Args:\n            *columns: The columns to order by.\n\n        Returns:\n            An OrderBy instance representing the ORDER BY clause.\n        \"\"\"\n        pass\n\n\nclass _WhereMixin(QueryBuilder, abc.ABC):\n    \"\"\"Mixin class for adding WHERE clause functionality.\"\"\"\n\n    def where(\n        self, evaluation: Expression, *evaluations: Expression | LogicGate\n    ) -> Where:\n        \"\"\"Add a WHERE clause to the query.\n\n        Args:\n            evaluation: The primary condition for the WHERE clause.\n            *evaluations: Additional conditions to be combined with AND.\n\n        Returns:\n            A Where instance representing the WHERE clause.\n        \"\"\"\n        pass\n\n\nclass BooleanOperator(enum.Enum):\n    \"\"\"Enumeration of boolean operators used in SQL queries.\n\n    This enum defines the various boolean operators that can be used\n    in constructing complex SQL conditions.\n    \"\"\"\n\n    AND = \"AND\"\n    AND_NOT = \"AND NOT\"\n    OR = \"OR\"\n    OR_NOT = \"OR NOT\"\n    IS = \"IS\"\n    IS_NOT = \"IS NOT\"\n    IN = \"IN\"\n    NOT_IN = \"NOT IN\"\n\n\nclass LogicGate(QueryBuilder):\n    \"\"\"Represents a logical operation in SQL queries.\n\n    This class is used to construct complex logical conditions by combining\n    multiple expressions with boolean operators.\n    \"\"\"\n\n    def __init__(\n        self,\n        boolean_operator: BooleanOperator,\n        evaluation: Expression,\n        *evaluations: Expression | LogicGate,\n    ) -> None:\n        \"\"\"Initialize a LogicGate instance.\n\n        Args:\n            boolean_operator: The boolean operator to use.\n            evaluation: The primary expression to evaluate.\n            *evaluations: Additional expressions to combine with the primary expression.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the logical operation for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for this logical operation and a list of parameters.\n        \"\"\"\n        pass\n\n\nclass Expression(_OperatorMixin):\n    \"\"\"Represents a SQL expression or condition.\n\n    This class is used to construct SQL expressions involving comparisons,\n    arithmetic operations, or function calls.\n    \"\"\"\n\n    def __init__(\n        self,\n        left_operand: Column | Expression | _OperatorMixin,\n        operator: str,\n        right_operand: Any,\n    ) -> None:\n        \"\"\"Initialize an Expression instance.\n\n        Args:\n            left_operand: The left side of the expression.\n            operator: The operator to use in the expression.\n            right_operand: The right side of the expression.\n        \"\"\"\n        pass\n\n    def as_(self, alias: str) -> As:\n        \"\"\"Create an alias for this expression.\n\n        Args:\n            alias: The alias name for the expression.\n\n        Returns:\n            An As instance representing the aliased expression.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the expression for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for this expression and a list of parameters.\n        \"\"\"\n        pass\n\n\nclass Join(QueryBuilder):\n    \"\"\"Represents a JOIN operation in a SQL query.\n\n    This class is used to construct various types of JOIN clauses.\n    \"\"\"\n\n    def __init__(self, table: Type[Table]) -> None:\n        \"\"\"Initialize a Join instance.\n\n        Args:\n            table: The table to join with.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the JOIN clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for this JOIN clause and a list of parameters.\n\n        Raises:\n            ValueError: If no ON condition has been set for the join.\n        \"\"\"\n        pass\n\n    def on(self, *expressions: Expression | LogicGate) -> Self:\n        \"\"\"Set the ON condition for the JOIN.\n\n        Args:\n            *expressions: The conditions to use in the ON clause.\n\n        Returns:\n            The Join instance itself, allowing for method chaining.\n        \"\"\"\n        pass\n\n\nclass LeftJoin(Join):\n    \"\"\"Represents a LEFT JOIN operation in a SQL query.\"\"\"\n\n    def __init__(self, table: Type[Table]) -> None:\n        \"\"\"Initialize a LeftJoin instance.\n\n        Args:\n            table: The table to left join with.\n        \"\"\"\n        pass\n\n\nclass RightJoin(Join):\n    \"\"\"Represents a RIGHT JOIN operation in a SQL query.\"\"\"\n\n    def __init__(self, table: Type[Table]) -> None:\n        \"\"\"Initialize a RightJoin instance.\n\n        Args:\n            table: The table to right join with.\n        \"\"\"\n        pass\n\n\nclass Limit(_OffsetMixin):\n    \"\"\"Represents a LIMIT clause in a SQL query.\"\"\"\n\n    def __init__(self, subquery: QueryBuilder, limit: int) -> None:\n        \"\"\"Initialize a Limit instance.\n\n        Args:\n            subquery: The query to apply the LIMIT to.\n            limit: The maximum number of rows to return.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the LIMIT clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the LIMIT clause and a list of parameters.\n        \"\"\"\n        pass\n\n\nclass Offset(QueryBuilder):\n    \"\"\"Represents an OFFSET clause in a SQL query.\"\"\"\n\n    def __init__(self, subquery: QueryBuilder, offset: int) -> None:\n        \"\"\"Initialize an Offset instance.\n\n        Args:\n            subquery: The query to apply the OFFSET to.\n            offset: The number of rows to skip.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the OFFSET clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the OFFSET clause and a list of parameters.\n        \"\"\"\n        pass\n\n\nclass On(_PaginateMixin):\n    \"\"\"Represents an ON clause in a JOIN operation.\"\"\"\n\n    def __init__(self, *expressions: Expression | LogicGate) -> None:\n        \"\"\"Initialize an On instance.\n\n        Args:\n            *expressions: The conditions to use in the ON clause.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the ON clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the ON clause and a list of parameters.\n        \"\"\"\n        pass\n\n\nclass From(_WhereMixin, _PaginateMixin):\n    \"\"\"Represents a FROM clause in a SQL query.\"\"\"\n\n    def __init__(self, select: Select, table: Type[Table], *joins: Join) -> None:\n        \"\"\"Initialize a From instance.\n\n        Args:\n            select: The SELECT clause of the query.\n            table: The main table to select from.\n            *joins: Any JOIN clauses to include.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the FROM clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the FROM clause (including any JOINs) and a list of parameters.\n        \"\"\"\n        pass\n\n\nclass OrderBy(_PaginateMixin):\n    \"\"\"Represents an ORDER BY clause in a SQL query.\"\"\"\n\n    def __init__(\n        self, subquery: Select | From | On | _OrderByMixin, *columns: Column\n    ) -> None:\n        \"\"\"Initialize an OrderBy instance.\n\n        Args:\n            subquery: The query to apply the ORDER BY to.\n            *columns: The columns to order by.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the ORDER BY clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the ORDER BY clause and a list of parameters.\n        \"\"\"\n        pass\n\n\nclass Values(QueryBuilder):\n    \"\"\"Represents a VALUES clause in an INSERT statement.\"\"\"\n\n    def __init__(self, subquery: InsertInto, values: dict[Column | str, Any]) -> None:\n        \"\"\"Initialize a Values instance.\n\n        Args:\n            subquery: The INSERT INTO clause.\n            values: A dictionary mapping columns to their values.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the VALUES clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the VALUES clause and a list of parameter values.\n        \"\"\"\n        pass\n\n\nclass Where(_OrderByMixin, _PaginateMixin):\n    \"\"\"Represents a WHERE clause in a SQL query.\"\"\"\n\n    def __init__(\n        self,\n        subquery: Select | From | _WhereMixin,\n        *expressions: Expression | LogicGate,\n    ) -> None:\n        \"\"\"Initialize a Where instance.\n\n        Args:\n            subquery: The query to apply the WHERE clause to.\n            *expressions: The conditions to use in the WHERE clause.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the WHERE clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the WHERE clause and a list of parameters.\n        \"\"\"\n        pass\n\n\nclass Set(_WhereMixin):\n    \"\"\"Represents a SET clause in an UPDATE statement.\"\"\"\n\n    def __init__(self, subquery: Update, values: dict[Column | str, Any]) -> None:\n        \"\"\"Initialize a Set instance.\n\n        Args:\n            subquery: The UPDATE clause.\n            values: A dictionary mapping columns to their new values.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the SET clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the SET clause and a list of parameter values.\n        \"\"\"\n        pass\n\n\nclass InsertInto(QueryBuilder):\n    \"\"\"Represents an INSERT INTO statement in SQL.\"\"\"\n\n    def __init__(self, table: Type[Table]) -> None:\n        \"\"\"Initialize an InsertInto instance.\n\n        Args:\n            table: The table to insert into.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the INSERT INTO clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the INSERT INTO clause and an empty list of parameters.\n        \"\"\"\n        pass\n\n    def values(self, values: dict[Column | str, Any] | None = None) -> Values:\n        \"\"\"Add a VALUES clause to the INSERT statement.\n\n        Args:\n            values: A dictionary mapping columns to their values. If None, an empty dict is used.\n\n        Returns:\n            A Values instance representing the VALUES clause.\n        \"\"\"\n        pass\n\n\nclass Delete(_WhereMixin):\n    \"\"\"Represents a DELETE statement in SQL.\"\"\"\n\n    def __init__(self, table: Type[Table]) -> None:\n        \"\"\"Initialize a Delete instance.\n\n        Args:\n            table: The table to delete from.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the DELETE statement for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the DELETE statement and an empty list of parameters.\n        \"\"\"\n        pass\n\n\nclass Select(QueryBuilder):\n    \"\"\"Represents a SELECT statement in SQL.\"\"\"\n\n    def __init__(self, *args: Column | Type[Table] | As) -> None:\n        \"\"\"Initialize a Select instance.\n\n        Args:\n            *args: The columns, tables, or aliases to select from.\n\n        Raises:\n            ValueError: If an argument is not a Column, Table, or As instance.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the SELECT statement for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the SELECT statement and a list of parameters.\n        \"\"\"\n        pass\n\n    def from_(self, table: Type[Table], *args: Join) -> From:\n        \"\"\"Add a FROM clause to the SELECT statement.\n\n        Args:\n            table: The main table to select from.\n            *args: Any JOIN clauses to include.\n\n        Returns:\n            A From instance representing the FROM clause.\n        \"\"\"\n        pass\n\n\nclass Update(QueryBuilder):\n    \"\"\"Represents an UPDATE statement in SQL.\"\"\"\n\n    def __init__(self, table: Type[Table]) -> None:\n        \"\"\"Initialize an Update instance.\n\n        Args:\n            table: The table to update.\n        \"\"\"\n        pass\n\n    def set(self, values: dict[Column | str, Any]) -> Set:\n        \"\"\"Add a SET clause to the UPDATE statement.\n\n        Args:\n            values: A dictionary mapping columns to their new values.\n\n        Returns:\n            A Set instance representing the SET clause.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the UPDATE statement for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the UPDATE statement and an empty list of parameters.\n        \"\"\"\n        pass\n\n\ndef _prepare_expressions(*expressions: Expression | LogicGate) -> tuple[str, list[Any]]:\n    \"\"\"Prepare multiple expressions for use in a SQL query.\n\n    This function is used internally to combine multiple expressions or logic gates\n    into a single SQL string with associated parameters.\n\n    Args:\n        *expressions: The expressions or logic gates to prepare.\n\n    Returns:\n        A tuple containing the combined SQL string and a list of all parameters.\n    \"\"\"\n    pass\n```",
        "full_code_skeleton_structured": [
            {
                "file_path": "pgqb/__init__.py",
                "code": "\"\"\"A simple SQL query builder for PostgreSQL.\"\"\"\nfrom typing import Type\n\n\ndef insert_into(table: Type[Table]) -> InsertInto:\n    \"\"\"Build an insert query.\"\"\"\n    pass\n\n\ndef delete_from(table: Type[Table]) -> Delete:\n    \"\"\"Build a delete query.\"\"\"\n    pass\n\n\ndef select(*args: Column | Type[Table] | As) -> Select:\n    \"\"\"Build a select query.\"\"\"\n    pass\n\n\ndef update(table: Type[Table]) -> Update:\n    \"\"\"Build an update query.\"\"\"\n    pass\n\n\ndef join(table: Type[Table]) -> Join:\n    \"\"\"Build a join query.\"\"\"\n    pass\n\n\ndef left_join(table: Type[Table]) -> Join:\n    \"\"\"Build a left join query.\"\"\"\n    pass\n\n\ndef right_join(table: Type[Table]) -> Join:\n    \"\"\"Build a right join query.\"\"\"\n    pass\n\n\ndef on(evaluation: Expression, *evaluations: Expression | LogicGate) -> On:\n    \"\"\"Build an \"on\" query for a join.\"\"\"\n    pass\n\n\ndef and_(evaluation: Expression, *evaluations: Expression | LogicGate) -> LogicGate:\n    \"\"\"Build an \"and\" expression for a part of a query.\"\"\"\n    pass\n\n\ndef and_not(evaluation: Expression, *evaluations: Expression | LogicGate) -> LogicGate:\n    \"\"\"Build an \"and not\" expression for a part of a query.\"\"\"\n    pass\n\n\ndef or_(evaluation: Expression, *evaluations: Expression | LogicGate) -> LogicGate:\n    \"\"\"Build an \"or\" expression for a part of a query.\"\"\"\n    pass\n\n\ndef or_not(evaluation: Expression, *evaluations: Expression | LogicGate) -> LogicGate:\n    \"\"\"Build an \"or not\" expression for a part of a query.\"\"\"\n    pass\n"
            },
            {
                "file_path": "pgqb/_snake.py",
                "code": "from typing import Union\n\n\ndef to_snake(string: str) -> str:\n    \"\"\"\n    Return a version of the string in `snake_case` format.\n\n    Args:\n        string: The string to convert to snake_case.\n\n    Returns:\n        The string in snake_case format.\n    \"\"\"\n    pass\n\n\ndef get_words(string: str) -> list[str]:\n    \"\"\"\n    Get a list of the words in a string in the order they appear.\n\n    Args:\n        string: The string to get the words from.\n\n    Returns:\n        A list of the words in the string.\n    \"\"\"\n    pass\n\n\ndef _split_words_on_regex(words: list[str], regex: Union[re.Pattern, str]) -> list[str]:  # type: ignore\n    \"\"\"\n    Split words on a regex.\n\n    Args:\n        words (list[str]): The list of words to split.\n        regex (Union[Pattern, str]): The regex to split on.\n\n    Returns:\n        list[str]: The list of words with the split words inserted.\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "pgqb/types.py",
                "code": "\"\"\"PostgreSQL types for pgqb query builder library.\n\nThis module contains classes for PostgreSQL data types. The classes are\nused to specify the type of a column in a table. The classes are used to\ngenerate the SQL for creating a table.\n\nFrom the docs: https://www.postgresql.org/docs/current/datatype.html\n\"\"\"\n\nimport enum\n\n\nclass PGEnum(enum.Enum):\n    \"\"\"Enum type class.\"\"\"\n\n    @classmethod\n    def pg_enum_name(cls) -> str:\n        \"\"\"Get the SQL name for this custom enum.\n\n        Args:\n            cls: The class to get the SQL name for.\n\n        Returns:\n            str: The SQL name for this custom enum.\n        \"\"\"\n        pass\n\n    @classmethod\n    def pg_enum_get_create(cls) -> str:\n        \"\"\"Get create enum SQL.\n\n        Args:\n            cls: The class to get the create enum SQL for.\n\n        Returns:\n            str: The create enum SQL.\n        \"\"\"\n        pass\n\n\nclass SQLType:\n    \"\"\"Base SQL type class.\"\"\"\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\n\nclass BIGINT(SQLType):\n    \"\"\"Signed eight-byte integer.\"\"\"\n    pass\n\n\nclass BIGSERIAL(SQLType):\n    \"\"\"Auto-incrementing eight-byte integer.\"\"\"\n    pass\n\n\nclass BIT(SQLType):\n    \"\"\"Fixed-length bit string.\"\"\"\n    pass\n\n\nclass VARBIT(SQLType):\n    \"\"\"Variable-length bit string.\"\"\"\n    pass\n\n\nclass BOOLEAN(SQLType):\n    \"\"\"Logical Boolean (true/false).\"\"\"\n    pass\n\n\nclass BOX(SQLType):\n    \"\"\"Rectangular box on a plane.\"\"\"\n    pass\n\n\nclass BYTEA(SQLType):\n    \"\"\"Binary data (byte array).\"\"\"\n    pass\n\n\nclass CHAR(SQLType):\n    \"\"\"Fixed-length character string.\"\"\"\n\n    def __init__(self, fixed_length: int | None = None) -> None:\n        \"\"\"Fixed-length character string.\n\n        Args:\n            fixed_length: The fixed length of the string.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\n\nclass VARCHAR(SQLType):\n    \"\"\"Variable-length character string.\"\"\"\n\n    def __init__(self, variable_length: int | None = None) -> None:\n        \"\"\"Variable-length character string.\n\n        Args:\n            variable_length: The variable length of the string.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\n\nclass CIDR(SQLType):\n    \"\"\"IPv4 or IPv6 network address.\"\"\"\n    pass\n\n\nclass CIRCLE(SQLType):\n    \"\"\"Circle on a plane.\"\"\"\n    pass\n\n\nclass DATE(SQLType):\n    \"\"\"Calendar date (year, month, day).\"\"\"\n    pass\n\n\nclass DOUBLE(SQLType):\n    \"\"\"Double precision floating-point number (8 bytes).\"\"\"\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\n\nclass INET(SQLType):\n    \"\"\"IPv4 or IPv6 host address.\"\"\"\n    pass\n\n\nclass INTEGER(SQLType):\n    \"\"\"Signed four-byte integer.\"\"\"\n    pass\n\n\nclass INTERVAL(SQLType):\n    \"\"\"Time span.\"\"\"\n\n    def __init__(self, fields: str | None = None, precision: int | None = None) -> None:\n        \"\"\"Time span.\n\n        Args:\n            fields: The fields of the interval.\n            precision: The precision of the interval.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\n\nclass JSON(SQLType):\n    \"\"\"Textual JSON data.\"\"\"\n    pass\n\n\nclass JSONB(SQLType):\n    \"\"\"Binary JSON data, decomposed.\"\"\"\n    pass\n\n\nclass LINE(SQLType):\n    \"\"\"Infinite line on a plane.\"\"\"\n    pass\n\n\nclass LSEG(SQLType):\n    \"\"\"Line segment on a plane.\"\"\"\n    pass\n\n\nclass MACADDR(SQLType):\n    \"\"\"MAC (Media Access Control) address.\"\"\"\n    pass\n\n\nclass MACADDR8(SQLType):\n    \"\"\"MAC (Media Access Control) address (EUI-64 format).\"\"\"\n    pass\n\n\nclass MONEY(SQLType):\n    \"\"\"Currency amount.\"\"\"\n    pass\n\n\nclass NUMERIC(SQLType):\n    \"\"\"Exact numeric of selectable precision.\"\"\"\n\n    def __init__(self, precision: int | None = None, scale: int | None = None) -> None:\n        \"\"\"Exact numeric of selectable precision.\n\n        Args:\n            precision: The precision of the numeric.\n            scale: The scale of the numeric.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\n\nclass PATH(SQLType):\n    \"\"\"Geometric path on a plane.\"\"\"\n    pass\n\n\nclass PG_LSN(SQLType):  # noqa: N801\n    \"\"\"PostgreSQL Log Sequence Number.\"\"\"\n    pass\n\n\nclass PG_SNAPSHOT(SQLType):  # noqa: N801\n    \"\"\"User-level transaction ID snapshot.\"\"\"\n    pass\n\n\nclass POINT(SQLType):\n    \"\"\"Geometric point on a plane.\"\"\"\n    pass\n\n\nclass POLYGON(SQLType):\n    \"\"\"Closed geometric path on a plane.\"\"\"\n    pass\n\n\nclass REAL(SQLType):\n    \"\"\"Single precision floating-point number (4 bytes).\"\"\"\n    pass\n\n\nclass SMALLINT(SQLType):\n    \"\"\"Signed two-byte integer.\"\"\"\n    pass\n\n\nclass SMALLSERIAL(SQLType):\n    \"\"\"Auto-incrementing two-byte integer.\"\"\"\n    pass\n\n\nclass SERIAL(SQLType):\n    \"\"\"Auto-incrementing four-byte integer.\"\"\"\n    pass\n\n\nclass TEXT(SQLType):\n    \"\"\"Variable-length character string.\"\"\"\n    pass\n\n\nclass TIME(SQLType):\n    \"\"\"Time of day.\"\"\"\n\n    def __init__(\n        self, precision: int | None = None, *, with_time_zone: bool = False\n    ) -> None:\n        \"\"\"Time of day.\n\n        Args:\n            precision: The precision of the time.\n            with_time_zone: Whether to include the time zone.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\n\nclass TIMESTAMP(SQLType):\n    \"\"\"Date and time.\"\"\"\n\n    def __init__(\n        self, precision: int | None = None, *, with_time_zone: bool = False\n    ) -> None:\n        \"\"\"Date and time.\n\n        Args:\n            precision: The precision of the timestamp.\n            with_time_zone: Whether to include the time zone.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\n\nclass TSQUERY(SQLType):\n    \"\"\"Text search query.\"\"\"\n    pass\n\n\nclass TSVECTOR(SQLType):\n    \"\"\"Text search document.\"\"\"\n    pass\n\n\nclass UUID(SQLType):\n    \"\"\"Universally unique identifier.\"\"\"\n    pass\n\n\nclass XML(SQLType):\n    \"\"\"XML data.\"\"\"\n    pass\n"
            },
            {
                "file_path": "pgqb/builder.py",
                "code": "\"\"\"Query building functions for pgqb.\n\nThis module provides a set of classes and functions for building SQL queries\nin a Pythonic way. It includes support for various SQL operations such as\nSELECT, INSERT, UPDATE, DELETE, JOIN, WHERE, ORDER BY, LIMIT, and OFFSET.\n\"\"\"\n\nimport abc\nimport enum\nimport typing\nfrom abc import ABC\nfrom typing import Any, Type\n\n\nclass QueryBuilder(abc.ABC):\n    \"\"\"Base class for all query builders.\n\n    This abstract class defines the interface for all query builders in the system.\n    All specific query builder classes should inherit from this base class.\n    \"\"\"\n\n    @abc.abstractmethod\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Get all params and the SQL string.\n\n        Returns:\n            A tuple containing the SQL string and a list of parameters.\n        \"\"\"\n        pass\n\n\nclass _OperatorMixin(QueryBuilder, abc.ABC):  # noqa: PLW1641\n    \"\"\"Mixin class providing common SQL comparison and arithmetic operators.\n\n    This mixin adds methods for common SQL operators like >, <, =, !=, +, -, *, /, %.\n    It also includes IS and IS NOT operators.\n    \"\"\"\n\n    def __gt__(self, other: Any) -> Expression:\n        \"\"\"Greater than operator.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the \"greater than\" comparison.\n        \"\"\"\n        pass\n\n    def __ge__(self, other: Any) -> Expression:\n        \"\"\"Greater than or equal to operator.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the \"greater than or equal to\" comparison.\n        \"\"\"\n        pass\n\n    def __lt__(self, other: Any) -> Expression:\n        \"\"\"Less than operator.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the \"less than\" comparison.\n        \"\"\"\n        pass\n\n    def __le__(self, other: Any) -> Expression:\n        \"\"\"Less than or equal to operator.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the \"less than or equal to\" comparison.\n        \"\"\"\n        pass\n\n    def __eq__(self, other: object) -> Expression:  # type: ignore\n        \"\"\"Equality operator.\n\n        For None, True, or False, uses IS operator instead of =.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the equality comparison.\n        \"\"\"\n        pass\n\n    def __ne__(self, other: object) -> Expression:  # type: ignore\n        \"\"\"Inequality operator.\n\n        For None, True, or False, uses IS NOT operator instead of !=.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the inequality comparison.\n        \"\"\"\n        pass\n\n    def __add__(self, other: Any) -> Expression:\n        \"\"\"Addition operator.\n\n        Args:\n            other: The value to add.\n\n        Returns:\n            An Expression representing the addition operation.\n        \"\"\"\n        pass\n\n    def __sub__(self, other: Any) -> Expression:\n        \"\"\"Subtraction operator.\n\n        Args:\n            other: The value to subtract.\n\n        Returns:\n            An Expression representing the subtraction operation.\n        \"\"\"\n        pass\n\n    def __mul__(self, other: Any) -> Expression:\n        \"\"\"Multiplication operator.\n\n        Args:\n            other: The value to multiply by.\n\n        Returns:\n            An Expression representing the multiplication operation.\n        \"\"\"\n        pass\n\n    def __truediv__(self, other: Any) -> Expression:\n        \"\"\"Division operator.\n\n        Args:\n            other: The value to divide by.\n\n        Returns:\n            An Expression representing the division operation.\n        \"\"\"\n        pass\n\n    def __mod__(self, other: Any) -> Expression:\n        \"\"\"Modulo operator.\n\n        Args:\n            other: The value to mod by.\n\n        Returns:\n            An Expression representing the modulo operation.\n        \"\"\"\n        pass\n\n    def is_(self, other: Any) -> Expression:\n        \"\"\"Equality operator using IS.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the IS comparison.\n        \"\"\"\n        pass\n\n    def is_not(self, other: Any) -> Expression:\n        \"\"\"Inequality operator using IS NOT.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the IS NOT comparison.\n        \"\"\"\n        pass\n\n\nclass As(QueryBuilder):\n    \"\"\"Represents an SQL AS clause for aliasing.\n\n    This class is used to create aliases for columns or expressions in SQL queries.\n    \"\"\"\n\n    def __init__(self, sub_query: Column | Expression, alias: str) -> None:\n        \"\"\"Initialize an As instance.\n\n        Args:\n            sub_query: The Column or Expression to be aliased.\n            alias: The alias name.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the AS clause.\n\n        Returns:\n            A tuple containing the SQL string for the AS clause and any parameters.\n        \"\"\"\n        pass\n\n\nclass Column(_OperatorMixin):\n    \"\"\"Represents a column in a SQL table.\n\n    This class encapsulates the properties and behaviors of a database column,\n    including its data type, constraints, and other attributes.\n    \"\"\"\n\n    def __init__(  # noqa: PLR0913\n        self,\n        sql_type: SQLType | Type[PGEnum] | None = None,\n        *,\n        check: str | None = None,\n        default: Any | None = None,\n        foreign_key: Column | None = None,\n        index: bool = False,\n        null: bool = False,\n        primary: bool = False,\n        unique: bool = False,\n    ) -> None:\n        \"\"\"Initialize a Column instance.\n\n        Args:\n            sql_type: The SQL type for this column.\n            check: The check constraint for this column.\n            default: The default value for this column.\n            foreign_key: The foreign key for this column.\n            index: Whether to create an index for this column.\n            null: Whether this column is nullable.\n            primary: Whether this column is a primary key.\n            unique: Whether this column is unique.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\n\n        Returns:\n            A string in the format \"table.column\".\n        \"\"\"\n        pass\n\n    def __hash__(self) -> int:\n        \"\"\"Get the hash of this column.\n\n        Returns:\n            An integer hash value based on the string representation of the column.\n        \"\"\"\n        pass\n\n    def _create(self) -> str:\n        \"\"\"Get column create SQL.\n\n        Returns:\n            A string containing the SQL definition for creating this column.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Get column as SQL.\n\n        Returns:\n            A tuple containing the SQL string for this column and an empty list of parameters.\n        \"\"\"\n        pass\n\n    def as_(self, alias: str) -> As:\n        \"\"\"Create an alias for this column.\n\n        Args:\n            alias: The alias name for the column.\n\n        Returns:\n            An As instance representing the aliased column.\n        \"\"\"\n        pass\n\n    def asc(self) -> Column:\n        \"\"\"Set this column to be sorted in ascending order.\n\n        Returns:\n            A new Column instance with ascending sort order.\n        \"\"\"\n        pass\n\n    def desc(self) -> Column:\n        \"\"\"Set this column to be sorted in descending order.\n\n        Returns:\n            A new Column instance with descending sort order.\n        \"\"\"\n        pass\n\n    def asc_or_desc(self, asc: bool) -> Column:\n        \"\"\"Set this column to be sorted in ascending or descending order.\n\n        Args:\n            asc: True for ascending order, False for descending order.\n\n        Returns:\n            A new Column instance with the specified sort order.\n        \"\"\"\n        pass\n\n\nclass Table(type):\n    \"\"\"Metaclass for representing SQL tables.\n\n    This metaclass automatically processes class attributes to set up\n    table names and columns based on the class definition.\n    \"\"\"\n\n    __table_name__: str = \"\"\n    __table_columns__: dict[str, Column] = {}\n\n    def __init_subclass__(cls, **kwargs: Any) -> None:\n        \"\"\"Initialize a subclass of Table.\n\n        This method is called when a new subclass of Table is created. It sets up\n        the table name and processes the class attributes to identify columns.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        pass\n\n    @classmethod\n    def create_table(cls) -> str:\n        \"\"\"Generate SQL to create the table.\n\n        Returns:\n            A string containing the SQL CREATE TABLE statement for this table.\n        \"\"\"\n        pass\n\n\nclass _LimitMixin(QueryBuilder, abc.ABC):\n    \"\"\"Mixin class for adding LIMIT clause functionality.\"\"\"\n\n    def limit(self, limit: int) -> Limit:\n        \"\"\"Add a LIMIT clause to the query.\n\n        Args:\n            limit: The maximum number of rows to return.\n\n        Returns:\n            A Limit instance representing the LIMIT clause.\n        \"\"\"\n        pass\n\n\nclass _OffsetMixin(QueryBuilder, abc.ABC):\n    \"\"\"Mixin class for adding OFFSET clause functionality.\"\"\"\n\n    def offset(self, offset: int) -> Offset:\n        \"\"\"Add an OFFSET clause to the query.\n\n        Args:\n            offset: The number of rows to skip.\n\n        Returns:\n            An Offset instance representing the OFFSET clause.\n        \"\"\"\n        pass\n\n\nclass _PaginateMixin(_OffsetMixin, _LimitMixin, ABC):\n    \"\"\"Mixin class combining LIMIT and OFFSET functionality for pagination.\"\"\"\n\n    pass\n\n\nclass _OrderByMixin(QueryBuilder, abc.ABC):\n    \"\"\"Mixin class for adding ORDER BY clause functionality.\"\"\"\n\n    def order_by(self, *columns: Column) -> OrderBy:\n        \"\"\"Add an ORDER BY clause to the query.\n\n        Args:\n            *columns: The columns to order by.\n\n        Returns:\n            An OrderBy instance representing the ORDER BY clause.\n        \"\"\"\n        pass\n\n\nclass _WhereMixin(QueryBuilder, abc.ABC):\n    \"\"\"Mixin class for adding WHERE clause functionality.\"\"\"\n\n    def where(\n        self, evaluation: Expression, *evaluations: Expression | LogicGate\n    ) -> Where:\n        \"\"\"Add a WHERE clause to the query.\n\n        Args:\n            evaluation: The primary condition for the WHERE clause.\n            *evaluations: Additional conditions to be combined with AND.\n\n        Returns:\n            A Where instance representing the WHERE clause.\n        \"\"\"\n        pass\n\n\nclass BooleanOperator(enum.Enum):\n    \"\"\"Enumeration of boolean operators used in SQL queries.\n\n    This enum defines the various boolean operators that can be used\n    in constructing complex SQL conditions.\n    \"\"\"\n\n    AND = \"AND\"\n    AND_NOT = \"AND NOT\"\n    OR = \"OR\"\n    OR_NOT = \"OR NOT\"\n    IS = \"IS\"\n    IS_NOT = \"IS NOT\"\n    IN = \"IN\"\n    NOT_IN = \"NOT IN\"\n\n\nclass LogicGate(QueryBuilder):\n    \"\"\"Represents a logical operation in SQL queries.\n\n    This class is used to construct complex logical conditions by combining\n    multiple expressions with boolean operators.\n    \"\"\"\n\n    def __init__(\n        self,\n        boolean_operator: BooleanOperator,\n        evaluation: Expression,\n        *evaluations: Expression | LogicGate,\n    ) -> None:\n        \"\"\"Initialize a LogicGate instance.\n\n        Args:\n            boolean_operator: The boolean operator to use.\n            evaluation: The primary expression to evaluate.\n            *evaluations: Additional expressions to combine with the primary expression.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the logical operation for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for this logical operation and a list of parameters.\n        \"\"\"\n        pass\n\n\nclass Expression(_OperatorMixin):\n    \"\"\"Represents a SQL expression or condition.\n\n    This class is used to construct SQL expressions involving comparisons,\n    arithmetic operations, or function calls.\n    \"\"\"\n\n    def __init__(\n        self,\n        left_operand: Column | Expression | _OperatorMixin,\n        operator: str,\n        right_operand: Any,\n    ) -> None:\n        \"\"\"Initialize an Expression instance.\n\n        Args:\n            left_operand: The left side of the expression.\n            operator: The operator to use in the expression.\n            right_operand: The right side of the expression.\n        \"\"\"\n        pass\n\n    def as_(self, alias: str) -> As:\n        \"\"\"Create an alias for this expression.\n\n        Args:\n            alias: The alias name for the expression.\n\n        Returns:\n            An As instance representing the aliased expression.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the expression for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for this expression and a list of parameters.\n        \"\"\"\n        pass\n\n\nclass Join(QueryBuilder):\n    \"\"\"Represents a JOIN operation in a SQL query.\n\n    This class is used to construct various types of JOIN clauses.\n    \"\"\"\n\n    def __init__(self, table: Type[Table]) -> None:\n        \"\"\"Initialize a Join instance.\n\n        Args:\n            table: The table to join with.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the JOIN clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for this JOIN clause and a list of parameters.\n\n        Raises:\n            ValueError: If no ON condition has been set for the join.\n        \"\"\"\n        pass\n\n    def on(self, *expressions: Expression | LogicGate) -> Self:\n        \"\"\"Set the ON condition for the JOIN.\n\n        Args:\n            *expressions: The conditions to use in the ON clause.\n\n        Returns:\n            The Join instance itself, allowing for method chaining.\n        \"\"\"\n        pass\n\n\nclass LeftJoin(Join):\n    \"\"\"Represents a LEFT JOIN operation in a SQL query.\"\"\"\n\n    def __init__(self, table: Type[Table]) -> None:\n        \"\"\"Initialize a LeftJoin instance.\n\n        Args:\n            table: The table to left join with.\n        \"\"\"\n        pass\n\n\nclass RightJoin(Join):\n    \"\"\"Represents a RIGHT JOIN operation in a SQL query.\"\"\"\n\n    def __init__(self, table: Type[Table]) -> None:\n        \"\"\"Initialize a RightJoin instance.\n\n        Args:\n            table: The table to right join with.\n        \"\"\"\n        pass\n\n\nclass Limit(_OffsetMixin):\n    \"\"\"Represents a LIMIT clause in a SQL query.\"\"\"\n\n    def __init__(self, subquery: QueryBuilder, limit: int) -> None:\n        \"\"\"Initialize a Limit instance.\n\n        Args:\n            subquery: The query to apply the LIMIT to.\n            limit: The maximum number of rows to return.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the LIMIT clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the LIMIT clause and a list of parameters.\n        \"\"\"\n        pass\n\n\nclass Offset(QueryBuilder):\n    \"\"\"Represents an OFFSET clause in a SQL query.\"\"\"\n\n    def __init__(self, subquery: QueryBuilder, offset: int) -> None:\n        \"\"\"Initialize an Offset instance.\n\n        Args:\n            subquery: The query to apply the OFFSET to.\n            offset: The number of rows to skip.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the OFFSET clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the OFFSET clause and a list of parameters.\n        \"\"\"\n        pass\n\n\nclass On(_PaginateMixin):\n    \"\"\"Represents an ON clause in a JOIN operation.\"\"\"\n\n    def __init__(self, *expressions: Expression | LogicGate) -> None:\n        \"\"\"Initialize an On instance.\n\n        Args:\n            *expressions: The conditions to use in the ON clause.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the ON clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the ON clause and a list of parameters.\n        \"\"\"\n        pass\n\n\nclass From(_WhereMixin, _PaginateMixin):\n    \"\"\"Represents a FROM clause in a SQL query.\"\"\"\n\n    def __init__(self, select: Select, table: Type[Table], *joins: Join) -> None:\n        \"\"\"Initialize a From instance.\n\n        Args:\n            select: The SELECT clause of the query.\n            table: The main table to select from.\n            *joins: Any JOIN clauses to include.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the FROM clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the FROM clause (including any JOINs) and a list of parameters.\n        \"\"\"\n        pass\n\n\nclass OrderBy(_PaginateMixin):\n    \"\"\"Represents an ORDER BY clause in a SQL query.\"\"\"\n\n    def __init__(\n        self, subquery: Select | From | On | _OrderByMixin, *columns: Column\n    ) -> None:\n        \"\"\"Initialize an OrderBy instance.\n\n        Args:\n            subquery: The query to apply the ORDER BY to.\n            *columns: The columns to order by.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the ORDER BY clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the ORDER BY clause and a list of parameters.\n        \"\"\"\n        pass\n\n\nclass Values(QueryBuilder):\n    \"\"\"Represents a VALUES clause in an INSERT statement.\"\"\"\n\n    def __init__(self, subquery: InsertInto, values: dict[Column | str, Any]) -> None:\n        \"\"\"Initialize a Values instance.\n\n        Args:\n            subquery: The INSERT INTO clause.\n            values: A dictionary mapping columns to their values.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the VALUES clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the VALUES clause and a list of parameter values.\n        \"\"\"\n        pass\n\n\nclass Where(_OrderByMixin, _PaginateMixin):\n    \"\"\"Represents a WHERE clause in a SQL query.\"\"\"\n\n    def __init__(\n        self,\n        subquery: Select | From | _WhereMixin,\n        *expressions: Expression | LogicGate,\n    ) -> None:\n        \"\"\"Initialize a Where instance.\n\n        Args:\n            subquery: The query to apply the WHERE clause to.\n            *expressions: The conditions to use in the WHERE clause.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the WHERE clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the WHERE clause and a list of parameters.\n        \"\"\"\n        pass\n\n\nclass Set(_WhereMixin):\n    \"\"\"Represents a SET clause in an UPDATE statement.\"\"\"\n\n    def __init__(self, subquery: Update, values: dict[Column | str, Any]) -> None:\n        \"\"\"Initialize a Set instance.\n\n        Args:\n            subquery: The UPDATE clause.\n            values: A dictionary mapping columns to their new values.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the SET clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the SET clause and a list of parameter values.\n        \"\"\"\n        pass\n\n\nclass InsertInto(QueryBuilder):\n    \"\"\"Represents an INSERT INTO statement in SQL.\"\"\"\n\n    def __init__(self, table: Type[Table]) -> None:\n        \"\"\"Initialize an InsertInto instance.\n\n        Args:\n            table: The table to insert into.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the INSERT INTO clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the INSERT INTO clause and an empty list of parameters.\n        \"\"\"\n        pass\n\n    def values(self, values: dict[Column | str, Any] | None = None) -> Values:\n        \"\"\"Add a VALUES clause to the INSERT statement.\n\n        Args:\n            values: A dictionary mapping columns to their values. If None, an empty dict is used.\n\n        Returns:\n            A Values instance representing the VALUES clause.\n        \"\"\"\n        pass\n\n\nclass Delete(_WhereMixin):\n    \"\"\"Represents a DELETE statement in SQL.\"\"\"\n\n    def __init__(self, table: Type[Table]) -> None:\n        \"\"\"Initialize a Delete instance.\n\n        Args:\n            table: The table to delete from.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the DELETE statement for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the DELETE statement and an empty list of parameters.\n        \"\"\"\n        pass\n\n\nclass Select(QueryBuilder):\n    \"\"\"Represents a SELECT statement in SQL.\"\"\"\n\n    def __init__(self, *args: Column | Type[Table] | As) -> None:\n        \"\"\"Initialize a Select instance.\n\n        Args:\n            *args: The columns, tables, or aliases to select from.\n\n        Raises:\n            ValueError: If an argument is not a Column, Table, or As instance.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the SELECT statement for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the SELECT statement and a list of parameters.\n        \"\"\"\n        pass\n\n    def from_(self, table: Type[Table], *args: Join) -> From:\n        \"\"\"Add a FROM clause to the SELECT statement.\n\n        Args:\n            table: The main table to select from.\n            *args: Any JOIN clauses to include.\n\n        Returns:\n            A From instance representing the FROM clause.\n        \"\"\"\n        pass\n\n\nclass Update(QueryBuilder):\n    \"\"\"Represents an UPDATE statement in SQL.\"\"\"\n\n    def __init__(self, table: Type[Table]) -> None:\n        \"\"\"Initialize an Update instance.\n\n        Args:\n            table: The table to update.\n        \"\"\"\n        pass\n\n    def set(self, values: dict[Column | str, Any]) -> Set:\n        \"\"\"Add a SET clause to the UPDATE statement.\n\n        Args:\n            values: A dictionary mapping columns to their new values.\n\n        Returns:\n            A Set instance representing the SET clause.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the UPDATE statement for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the UPDATE statement and an empty list of parameters.\n        \"\"\"\n        pass\n\n\ndef _prepare_expressions(*expressions: Expression | LogicGate) -> tuple[str, list[Any]]:\n    \"\"\"Prepare multiple expressions for use in a SQL query.\n\n    This function is used internally to combine multiple expressions or logic gates\n    into a single SQL string with associated parameters.\n\n    Args:\n        *expressions: The expressions or logic gates to prepare.\n\n    Returns:\n        A tuple containing the combined SQL string and a list of all parameters.\n    \"\"\"\n    pass\n"
            }
        ],
        "minimal_code_skeleton": "--- File: pgqb/__init__.py ---\n```python\nfrom typing import Type, Any\n\n# Forward declarations for type hints within this file, actual definitions are in builder.py / types.py\n# These are not part of the skeleton itself but help understand the facade function signatures.\n# For the skeleton, we only need the facade functions.\n# class Table: pass\n# class Column: pass\n# class As: pass\n# class InsertInto: pass\n# class Delete: pass\n# class Select: pass\n# class Update: pass\n# class Join: pass\n# class Expression: pass\n# class LogicGate: pass\n# class On: pass # Not used directly by tests via pgqb.on, but pgqb.builder.On is used by Join.on\n# enum BooleanOperator: AND = \"AND\"; AND_NOT = \"AND NOT\"; OR = \"OR\"; OR_NOT = \"OR NOT\" # From builder.py\n\ndef insert_into(table: Type[\"Table\"]) -> \"InsertInto\":\n    \"\"\"Build an insert query.\"\"\"\n    pass\n\ndef delete_from(table: Type[\"Table\"]) -> \"Delete\":\n    \"\"\"Build a delete query.\"\"\"\n    pass\n\ndef select(*args: \"Column\" | Type[\"Table\"] | \"As\") -> \"Select\":\n    \"\"\"Build a select query.\"\"\"\n    pass\n\ndef update(table: Type[\"Table\"]) -> \"Update\":\n    \"\"\"Build an update query.\"\"\"\n    pass\n\ndef join(table: Type[\"Table\"]) -> \"Join\":\n    \"\"\"Build a join query.\"\"\"\n    pass\n\ndef left_join(table: Type[\"Table\"]) -> \"Join\":\n    \"\"\"Build a left join query.\"\"\"\n    pass\n\ndef right_join(table: Type[\"Table\"]) -> \"Join\":\n    \"\"\"Build a right join query.\"\"\"\n    pass\n\ndef and_(evaluation: \"Expression\", *evaluations: \"Expression\" | \"LogicGate\") -> \"LogicGate\":\n    \"\"\"Build an \"and\" expression for a part of a query.\"\"\"\n    pass\n\ndef and_not(evaluation: \"Expression\", *evaluations: \"Expression\" | \"LogicGate\") -> \"LogicGate\":\n    \"\"\"Build an \"and not\" expression for a part of a query.\"\"\"\n    pass\n\ndef or_(evaluation: \"Expression\", *evaluations: \"Expression\" | \"LogicGate\") -> \"LogicGate\":\n    \"\"\"Build an \"or\" expression for a part of a query.\"\"\"\n    pass\n\ndef or_not(evaluation: \"Expression\", *evaluations: \"Expression\" | \"LogicGate\") -> \"LogicGate\":\n    \"\"\"Build an \"or not\" expression for a part of a query.\"\"\"\n    pass\n```\n--- File: pgqb/_snake.py ---\n```python\nimport re\nfrom typing import Union\n\ndef to_snake(string: str) -> str:\n    \"\"\"\n    Return a version of the string in `snake_case` format.\n\n    Args:\n        string: The string to convert to snake_case.\n\n    Returns:\n        The string in snake_case format.\n    \"\"\"\n    pass\n\ndef get_words(string: str) -> list[str]:\n    \"\"\"\n    Get a list of the words in a string in the order they appear.\n\n    Args:\n        string: The string to get the words from.\n\n    Returns:\n        A list of the words in the string.\n    \"\"\"\n    pass\n\ndef _split_words_on_regex(words: list[str], regex: Union[re.Pattern, str]) -> list[str]:  # type: ignore\n    \"\"\"\n    Split words on a regex.\n\n    Args:\n        words (list[str]): The list of words to split.\n        regex (Union[Pattern, str]): The regex to split on.\n\n    Returns:\n        list[str]: The list of words with the split words inserted.\n    \"\"\"\n    pass\n```\n--- File: pgqb/types.py ---\n```python\nfrom __future__ import annotations\nimport enum\nfrom typing import Type\n\nclass PGEnum(enum.Enum):\n    \"\"\"Enum type class.\"\"\"\n\n    @classmethod\n    def pg_enum_name(cls) -> str:\n        \"\"\"Get the SQL name for this custom enum.\n\n        Args:\n            cls: The class to get the SQL name for.\n\n        Returns:\n            str: The SQL name for this custom enum.\n        \"\"\"\n        pass\n\n    @classmethod\n    def pg_enum_get_create(cls) -> str:\n        \"\"\"Get create enum SQL.\n\n        Args:\n            cls: The class to get the create enum SQL for.\n\n        Returns:\n            str: The create enum SQL.\n        \"\"\"\n        pass\n\nclass SQLType:\n    \"\"\"Base SQL type class.\"\"\"\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\nclass BIGINT(SQLType):\n    \"\"\"Signed eight-byte integer.\"\"\"\n    pass\n\nclass BIGSERIAL(SQLType):\n    \"\"\"Auto-incrementing eight-byte integer.\"\"\"\n    pass\n\nclass BIT(SQLType):\n    \"\"\"Fixed-length bit string.\"\"\"\n    pass\n\nclass VARBIT(SQLType):\n    \"\"\"Variable-length bit string.\"\"\"\n    pass\n\nclass BOOLEAN(SQLType):\n    \"\"\"Logical Boolean (true/false).\"\"\"\n    pass\n\nclass BOX(SQLType):\n    \"\"\"Rectangular box on a plane.\"\"\"\n    pass\n\nclass BYTEA(SQLType):\n    \"\"\"Binary data (byte array).\"\"\"\n    pass\n\nclass CHAR(SQLType):\n    \"\"\"Fixed-length character string.\"\"\"\n\n    def __init__(self, fixed_length: int | None = None) -> None:\n        \"\"\"Fixed-length character string.\n\n        Args:\n            fixed_length: The fixed length of the string.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\nclass VARCHAR(SQLType):\n    \"\"\"Variable-length character string.\"\"\"\n\n    def __init__(self, variable_length: int | None = None) -> None:\n        \"\"\"Variable-length character string.\n\n        Args:\n            variable_length: The variable length of the string.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\nclass CIDR(SQLType):\n    \"\"\"IPv4 or IPv6 network address.\"\"\"\n    pass\n\nclass CIRCLE(SQLType):\n    \"\"\"Circle on a plane.\"\"\"\n    pass\n\nclass DATE(SQLType):\n    \"\"\"Calendar date (year, month, day).\"\"\"\n    pass\n\nclass DOUBLE(SQLType):\n    \"\"\"Double precision floating-point number (8 bytes).\"\"\"\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\nclass INET(SQLType):\n    \"\"\"IPv4 or IPv6 host address.\"\"\"\n    pass\n\nclass INTEGER(SQLType):\n    \"\"\"Signed four-byte integer.\"\"\"\n    pass\n\nclass INTERVAL(SQLType):\n    \"\"\"Time span.\"\"\"\n\n    def __init__(self, fields: str | None = None, precision: int | None = None) -> None:\n        \"\"\"Time span.\n\n        Args:\n            fields: The fields of the interval.\n            precision: The precision of the interval.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\nclass JSON(SQLType):\n    \"\"\"Textual JSON data.\"\"\"\n    pass\n\nclass JSONB(SQLType):\n    \"\"\"Binary JSON data, decomposed.\"\"\"\n    pass\n\nclass LINE(SQLType):\n    \"\"\"Infinite line on a plane.\"\"\"\n    pass\n\nclass LSEG(SQLType):\n    \"\"\"Line segment on a plane.\"\"\"\n    pass\n\nclass MACADDR(SQLType):\n    \"\"\"MAC (Media Access Control) address.\"\"\"\n    pass\n\nclass MACADDR8(SQLType):\n    \"\"\"MAC (Media Access Control) address (EUI-64 format).\"\"\"\n    pass\n\nclass MONEY(SQLType):\n    \"\"\"Currency amount.\"\"\"\n    pass\n\nclass NUMERIC(SQLType):\n    \"\"\"Exact numeric of selectable precision.\"\"\"\n\n    def __init__(self, precision: int | None = None, scale: int | None = None) -> None:\n        \"\"\"Exact numeric of selectable precision.\n\n        Args:\n            precision: The precision of the numeric.\n            scale: The scale of the numeric.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\nclass PATH(SQLType):\n    \"\"\"Geometric path on a plane.\"\"\"\n    pass\n\nclass PG_LSN(SQLType):  # noqa: N801\n    \"\"\"PostgreSQL Log Sequence Number.\"\"\"\n    pass\n\nclass PG_SNAPSHOT(SQLType):  # noqa: N801\n    \"\"\"User-level transaction ID snapshot.\"\"\"\n    pass\n\nclass POINT(SQLType):\n    \"\"\"Geometric point on a plane.\"\"\"\n    pass\n\nclass POLYGON(SQLType):\n    \"\"\"Closed geometric path on a plane.\"\"\"\n    pass\n\nclass REAL(SQLType):\n    \"\"\"Single precision floating-point number (4 bytes).\"\"\"\n    pass\n\nclass SMALLINT(SQLType):\n    \"\"\"Signed two-byte integer.\"\"\"\n    pass\n\nclass SMALLSERIAL(SQLType):\n    \"\"\"Auto-incrementing two-byte integer.\"\"\"\n    pass\n\nclass SERIAL(SQLType):\n    \"\"\"Auto-incrementing four-byte integer.\"\"\"\n    pass\n\nclass TEXT(SQLType):\n    \"\"\"Variable-length character string.\"\"\"\n    pass\n\nclass TIME(SQLType):\n    \"\"\"Time of day.\"\"\"\n\n    def __init__(\n        self, precision: int | None = None, *, with_time_zone: bool = False\n    ) -> None:\n        \"\"\"Time of day.\n\n        Args:\n            precision: The precision of the time.\n            with_time_zone: Whether to include the time zone.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\nclass TIMESTAMP(SQLType):\n    \"\"\"Date and time.\"\"\"\n\n    def __init__(\n        self, precision: int | None = None, *, with_time_zone: bool = False\n    ) -> None:\n        \"\"\"Date and time.\n\n        Args:\n            precision: The precision of the timestamp.\n            with_time_zone: Whether to include the time zone.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\nclass TSQUERY(SQLType):\n    \"\"\"Text search query.\"\"\"\n    pass\n\nclass TSVECTOR(SQLType):\n    \"\"\"Text search document.\"\"\"\n    pass\n\nclass UUID(SQLType):\n    \"\"\"Universally unique identifier.\"\"\"\n    pass\n\nclass XML(SQLType):\n    \"\"\"XML data.\"\"\"\n    pass\n```\n--- File: pgqb/builder.py ---\n```python\nfrom __future__ import annotations\nimport abc\nimport enum\nfrom typing import Any, Type\nfrom typing_extensions import Self # Assuming Python <3.11 for Self, or use typing.Self for >=3.11\n\n# Forward declarations for type hints within this file\n# class SQLType: pass (from types)\n# class PGEnum: pass (from types)\nfrom pgqb.types import SQLType, PGEnum\n\n\nclass QueryBuilder(abc.ABC):\n    \"\"\"Base class for all query builders.\n\n    This abstract class defines the interface for all query builders in the system.\n    All specific query builder classes should inherit from this base class.\n    \"\"\"\n\n    @abc.abstractmethod\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Get all params and the SQL string.\n\n        Returns:\n            A tuple containing the SQL string and a list of parameters.\n        \"\"\"\n        pass\n\nclass _OperatorMixin(QueryBuilder, abc.ABC):  # noqa: PLW1641\n    \"\"\"Mixin class providing common SQL comparison and arithmetic operators.\n\n    This mixin adds methods for common SQL operators like >, <, =, !=, +, -, *, /, %.\n    It also includes IS and IS NOT operators.\n    \"\"\"\n\n    def __gt__(self, other: Any) -> \"Expression\":\n        \"\"\"Greater than operator.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the \"greater than\" comparison.\n        \"\"\"\n        pass\n\n    def __ge__(self, other: Any) -> \"Expression\":\n        \"\"\"Greater than or equal to operator.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the \"greater than or equal to\" comparison.\n        \"\"\"\n        pass\n\n    def __lt__(self, other: Any) -> \"Expression\":\n        \"\"\"Less than operator.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the \"less than\" comparison.\n        \"\"\"\n        pass\n\n    def __le__(self, other: Any) -> \"Expression\":\n        \"\"\"Less than or equal to operator.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the \"less than or equal to\" comparison.\n        \"\"\"\n        pass\n\n    def __eq__(self, other: object) -> \"Expression\":  # type: ignore\n        \"\"\"Equality operator.\n\n        For None, True, or False, uses IS operator instead of =.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the equality comparison.\n        \"\"\"\n        pass\n\n    def __ne__(self, other: object) -> \"Expression\":  # type: ignore\n        \"\"\"Inequality operator.\n\n        For None, True, or False, uses IS NOT operator instead of !=.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the inequality comparison.\n        \"\"\"\n        pass\n\n    def __add__(self, other: Any) -> \"Expression\":\n        \"\"\"Addition operator.\n\n        Args:\n            other: The value to add.\n\n        Returns:\n            An Expression representing the addition operation.\n        \"\"\"\n        pass\n\n    def __sub__(self, other: Any) -> \"Expression\":\n        \"\"\"Subtraction operator.\n\n        Args:\n            other: The value to subtract.\n\n        Returns:\n            An Expression representing the subtraction operation.\n        \"\"\"\n        pass\n\n    def __mul__(self, other: Any) -> \"Expression\":\n        \"\"\"Multiplication operator.\n\n        Args:\n            other: The value to multiply by.\n\n        Returns:\n            An Expression representing the multiplication operation.\n        \"\"\"\n        pass\n\n    def __truediv__(self, other: Any) -> \"Expression\":\n        \"\"\"Division operator.\n\n        Args:\n            other: The value to divide by.\n\n        Returns:\n            An Expression representing the division operation.\n        \"\"\"\n        pass\n\n    def __mod__(self, other: Any) -> \"Expression\":\n        \"\"\"Modulo operator.\n\n        Args:\n            other: The value to mod by.\n\n        Returns:\n            An Expression representing the modulo operation.\n        \"\"\"\n        pass\n\n    def is_(self, other: Any) -> \"Expression\":\n        \"\"\"Equality operator using IS.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the IS comparison.\n        \"\"\"\n        pass\n\n    def is_not(self, other: Any) -> \"Expression\":\n        \"\"\"Inequality operator using IS NOT.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the IS NOT comparison.\n        \"\"\"\n        pass\n\nclass As(QueryBuilder):\n    \"\"\"Represents an SQL AS clause for aliasing.\n\n    This class is used to create aliases for columns or expressions in SQL queries.\n    \"\"\"\n\n    def __init__(self, sub_query: \"Column\" | \"Expression\", alias: str) -> None:\n        \"\"\"Initialize an As instance.\n\n        Args:\n            sub_query: The Column or Expression to be aliased.\n            alias: The alias name.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the AS clause.\n\n        Returns:\n            A tuple containing the SQL string for the AS clause and any parameters.\n        \"\"\"\n        pass\n\nclass Column(_OperatorMixin):\n    \"\"\"Represents a column in a SQL table.\n\n    This class encapsulates the properties and behaviors of a database column,\n    including its data type, constraints, and other attributes.\n    \"\"\"\n\n    def __init__(  # noqa: PLR0913\n        self,\n        sql_type: SQLType | Type[PGEnum] | None = None,\n        *,\n        check: str | None = None,\n        default: Any | None = None,\n        foreign_key: \"Column\" | None = None,\n        index: bool = False,\n        null: bool = False,\n        primary: bool = False,\n        unique: bool = False,\n    ) -> None:\n        \"\"\"Initialize a Column instance.\n\n        Args:\n            sql_type: The SQL type for this column.\n            check: The check constraint for this column.\n            default: The default value for this column.\n            foreign_key: The foreign key for this column.\n            index: Whether to create an index for this column.\n            null: Whether this column is nullable.\n            primary: Whether this column is a primary key.\n            unique: Whether this column is unique.\n        \"\"\"\n        pass\n\n    def __hash__(self) -> int:\n        \"\"\"Get the hash of this column.\n\n        Returns:\n            An integer hash value based on the string representation of the column.\n        \"\"\"\n        pass\n\n    def _create(self) -> str:\n        \"\"\"Get column create SQL.\n\n        Returns:\n            A string containing the SQL definition for creating this column.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Get column as SQL.\n\n        Returns:\n            A tuple containing the SQL string for this column and an empty list of parameters.\n        \"\"\"\n        pass\n\n    def as_(self, alias: str) -> \"As\":\n        \"\"\"Create an alias for this column.\n\n        Args:\n            alias: The alias name for the column.\n\n        Returns:\n            An As instance representing the aliased column.\n        \"\"\"\n        pass\n\n    def asc(self) -> \"Column\":\n        \"\"\"Set this column to be sorted in ascending order.\n\n        Returns:\n            A new Column instance with ascending sort order.\n        \"\"\"\n        pass\n\n    def desc(self) -> \"Column\":\n        \"\"\"Set this column to be sorted in descending order.\n\n        Returns:\n            A new Column instance with descending sort order.\n        \"\"\"\n        pass\n\nclass Table(type):\n    \"\"\"Metaclass for representing SQL tables.\n\n    This metaclass automatically processes class attributes to set up\n    table names and columns based on the class definition.\n    \"\"\"\n\n    __table_name__: str = \"\"\n    __table_columns__: dict[str, \"Column\"] = {}\n\n    def __init_subclass__(cls, **kwargs: Any) -> None:\n        \"\"\"Initialize a subclass of Table.\n\n        This method is called when a new subclass of Table is created. It sets up\n        the table name and processes the class attributes to identify columns.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        pass\n\n    @classmethod\n    def create_table(cls) -> str:\n        \"\"\"Generate SQL to create the table.\n\n        Returns:\n            A string containing the SQL CREATE TABLE statement for this table.\n        \"\"\"\n        pass\n\nclass _LimitMixin(QueryBuilder, abc.ABC):\n    \"\"\"Mixin class for adding LIMIT clause functionality.\"\"\"\n\n    def limit(self, limit: int) -> \"Limit\":\n        \"\"\"Add a LIMIT clause to the query.\n\n        Args:\n            limit: The maximum number of rows to return.\n\n        Returns:\n            A Limit instance representing the LIMIT clause.\n        \"\"\"\n        pass\n\nclass _OffsetMixin(QueryBuilder, abc.ABC):\n    \"\"\"Mixin class for adding OFFSET clause functionality.\"\"\"\n\n    def offset(self, offset: int) -> \"Offset\":\n        \"\"\"Add an OFFSET clause to the query.\n\n        Args:\n            offset: The number of rows to skip.\n\n        Returns:\n            An Offset instance representing the OFFSET clause.\n        \"\"\"\n        pass\n\nclass _PaginateMixin(_OffsetMixin, _LimitMixin, abc.ABC):\n    \"\"\"Mixin class combining LIMIT and OFFSET functionality for pagination.\"\"\"\n    pass\n\nclass _OrderByMixin(QueryBuilder, abc.ABC):\n    \"\"\"Mixin class for adding ORDER BY clause functionality.\"\"\"\n\n    def order_by(self, *columns: \"Column\") -> \"OrderBy\":\n        \"\"\"Add an ORDER BY clause to the query.\n\n        Args:\n            *columns: The columns to order by.\n\n        Returns:\n            An OrderBy instance representing the ORDER BY clause.\n        \"\"\"\n        pass\n\nclass _WhereMixin(QueryBuilder, abc.ABC):\n    \"\"\"Mixin class for adding WHERE clause functionality.\"\"\"\n\n    def where(\n        self, evaluation: \"Expression\", *evaluations: \"Expression\" | \"LogicGate\"\n    ) -> \"Where\":\n        \"\"\"Add a WHERE clause to the query.\n\n        Args:\n            evaluation: The primary condition for the WHERE clause.\n            *evaluations: Additional conditions to be combined with AND.\n\n        Returns:\n            A Where instance representing the WHERE clause.\n        \"\"\"\n        pass\n\nclass BooleanOperator(enum.Enum):\n    \"\"\"Enumeration of boolean operators used in SQL queries.\n\n    This enum defines the various boolean operators that can be used\n    in constructing complex SQL conditions.\n    \"\"\"\n\n    AND = \"AND\"\n    AND_NOT = \"AND NOT\"\n    OR = \"OR\"\n    OR_NOT = \"OR NOT\"\n    IS = \"IS\"\n    IS_NOT = \"IS NOT\"\n    IN = \"IN\"\n    NOT_IN = \"NOT IN\"\n\nclass LogicGate(QueryBuilder):\n    \"\"\"Represents a logical operation in SQL queries.\n\n    This class is used to construct complex logical conditions by combining\n    multiple expressions with boolean operators.\n    \"\"\"\n\n    def __init__(\n        self,\n        boolean_operator: \"BooleanOperator\",\n        evaluation: \"Expression\",\n        *evaluations: \"Expression\" | \"LogicGate\",\n    ) -> None:\n        \"\"\"Initialize a LogicGate instance.\n\n        Args:\n            boolean_operator: The boolean operator to use.\n            evaluation: The primary expression to evaluate.\n            *evaluations: Additional expressions to combine with the primary expression.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the logical operation for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for this logical operation and a list of parameters.\n        \"\"\"\n        pass\n\nclass Expression(_OperatorMixin):\n    \"\"\"Represents a SQL expression or condition.\n\n    This class is used to construct SQL expressions involving comparisons,\n    arithmetic operations, or function calls.\n    \"\"\"\n\n    def __init__(\n        self,\n        left_operand: \"Column\" | \"Expression\" | _OperatorMixin,\n        operator: str,\n        right_operand: Any,\n    ) -> None:\n        \"\"\"Initialize an Expression instance.\n\n        Args:\n            left_operand: The left side of the expression.\n            operator: The operator to use in the expression.\n            right_operand: The right side of the expression.\n        \"\"\"\n        pass\n\n    def as_(self, alias: str) -> \"As\":\n        \"\"\"Create an alias for this expression.\n\n        Args:\n            alias: The alias name for the expression.\n\n        Returns:\n            An As instance representing the aliased expression.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the expression for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for this expression and a list of parameters.\n        \"\"\"\n        pass\n\nclass Join(QueryBuilder):\n    \"\"\"Represents a JOIN operation in a SQL query.\n\n    This class is used to construct various types of JOIN clauses.\n    \"\"\"\n\n    def __init__(self, table: Type[\"Table\"]) -> None:\n        \"\"\"Initialize a Join instance.\n\n        Args:\n            table: The table to join with.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the JOIN clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for this JOIN clause and a list of parameters.\n\n        Raises:\n            ValueError: If no ON condition has been set for the join.\n        \"\"\"\n        pass\n\n    def on(self, *expressions: \"Expression\" | \"LogicGate\") -> Self:\n        \"\"\"Set the ON condition for the JOIN.\n\n        Args:\n            *expressions: The conditions to use in the ON clause.\n\n        Returns:\n            The Join instance itself, allowing for method chaining.\n        \"\"\"\n        pass\n\nclass LeftJoin(Join):\n    \"\"\"Represents a LEFT JOIN operation in a SQL query.\"\"\"\n\n    def __init__(self, table: Type[\"Table\"]) -> None:\n        \"\"\"Initialize a LeftJoin instance.\n\n        Args:\n            table: The table to left join with.\n        \"\"\"\n        pass\n\nclass RightJoin(Join):\n    \"\"\"Represents a RIGHT JOIN operation in a SQL query.\"\"\"\n\n    def __init__(self, table: Type[\"Table\"]) -> None:\n        \"\"\"Initialize a RightJoin instance.\n\n        Args:\n            table: The table to right join with.\n        \"\"\"\n        pass\n\nclass Limit(_OffsetMixin):\n    \"\"\"Represents a LIMIT clause in a SQL query.\"\"\"\n\n    def __init__(self, subquery: \"QueryBuilder\", limit: int) -> None:\n        \"\"\"Initialize a Limit instance.\n\n        Args:\n            subquery: The query to apply the LIMIT to.\n            limit: The maximum number of rows to return.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the LIMIT clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the LIMIT clause and a list of parameters.\n        \"\"\"\n        pass\n\nclass Offset(QueryBuilder):\n    \"\"\"Represents an OFFSET clause in a SQL query.\"\"\"\n\n    def __init__(self, subquery: \"QueryBuilder\", offset: int) -> None:\n        \"\"\"Initialize an Offset instance.\n\n        Args:\n            subquery: The query to apply the OFFSET to.\n            offset: The number of rows to skip.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the OFFSET clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the OFFSET clause and a list of parameters.\n        \"\"\"\n        pass\n\nclass On(_PaginateMixin):\n    \"\"\"Represents an ON clause in a JOIN operation.\"\"\"\n\n    def __init__(self, *expressions: \"Expression\" | \"LogicGate\") -> None:\n        \"\"\"Initialize an On instance.\n\n        Args:\n            *expressions: The conditions to use in the ON clause.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the ON clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the ON clause and a list of parameters.\n        \"\"\"\n        pass\n\nclass From(_WhereMixin, _PaginateMixin):\n    \"\"\"Represents a FROM clause in a SQL query.\"\"\"\n\n    def __init__(self, select: \"Select\", table: Type[\"Table\"], *joins: \"Join\") -> None:\n        \"\"\"Initialize a From instance.\n\n        Args:\n            select: The SELECT clause of the query.\n            table: The main table to select from.\n            *joins: Any JOIN clauses to include.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the FROM clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the FROM clause (including any JOINs) and a list of parameters.\n        \"\"\"\n        pass\n\nclass OrderBy(_PaginateMixin):\n    \"\"\"Represents an ORDER BY clause in a SQL query.\"\"\"\n\n    def __init__(\n        self, subquery: \"Select\" | \"From\" | \"On\" | _OrderByMixin, *columns: \"Column\"\n    ) -> None:\n        \"\"\"Initialize an OrderBy instance.\n\n        Args:\n            subquery: The query to apply the ORDER BY to.\n            *columns: The columns to order by.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the ORDER BY clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the ORDER BY clause and a list of parameters.\n        \"\"\"\n        pass\n\nclass Values(QueryBuilder):\n    \"\"\"Represents a VALUES clause in an INSERT statement.\"\"\"\n\n    def __init__(self, subquery: \"InsertInto\", values: dict[\"Column\" | str, Any]) -> None:\n        \"\"\"Initialize a Values instance.\n\n        Args:\n            subquery: The INSERT INTO clause.\n            values: A dictionary mapping columns to their values.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the VALUES clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the VALUES clause and a list of parameter values.\n        \"\"\"\n        pass\n\nclass Where(_OrderByMixin, _PaginateMixin):\n    \"\"\"Represents a WHERE clause in a SQL query.\"\"\"\n\n    def __init__(\n        self,\n        subquery: \"Select\" | \"From\" | _WhereMixin,\n        *expressions: \"Expression\" | \"LogicGate\",\n    ) -> None:\n        \"\"\"Initialize a Where instance.\n\n        Args:\n            subquery: The query to apply the WHERE clause to.\n            *expressions: The conditions to use in the WHERE clause.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the WHERE clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the WHERE clause and a list of parameters.\n        \"\"\"\n        pass\n\nclass Set(_WhereMixin):\n    \"\"\"Represents a SET clause in an UPDATE statement.\"\"\"\n\n    def __init__(self, subquery: \"Update\", values: dict[\"Column\" | str, Any]) -> None:\n        \"\"\"Initialize a Set instance.\n\n        Args:\n            subquery: The UPDATE clause.\n            values: A dictionary mapping columns to their new values.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the SET clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the SET clause and a list of parameter values.\n        \"\"\"\n        pass\n\nclass InsertInto(QueryBuilder):\n    \"\"\"Represents an INSERT INTO statement in SQL.\"\"\"\n\n    def __init__(self, table: Type[\"Table\"]) -> None:\n        \"\"\"Initialize an InsertInto instance.\n\n        Args:\n            table: The table to insert into.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the INSERT INTO clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the INSERT INTO clause and an empty list of parameters.\n        \"\"\"\n        pass\n\n    def values(self, values: dict[\"Column\" | str, Any] | None = None) -> \"Values\":\n        \"\"\"Add a VALUES clause to the INSERT statement.\n\n        Args:\n            values: A dictionary mapping columns to their values. If None, an empty dict is used.\n\n        Returns:\n            A Values instance representing the VALUES clause.\n        \"\"\"\n        pass\n\nclass Delete(_WhereMixin):\n    \"\"\"Represents a DELETE statement in SQL.\"\"\"\n\n    def __init__(self, table: Type[\"Table\"]) -> None:\n        \"\"\"Initialize a Delete instance.\n\n        Args:\n            table: The table to delete from.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the DELETE statement for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the DELETE statement and an empty list of parameters.\n        \"\"\"\n        pass\n\nclass Select(QueryBuilder):\n    \"\"\"Represents a SELECT statement in SQL.\"\"\"\n\n    def __init__(self, *args: \"Column\" | Type[\"Table\"] | \"As\") -> None:\n        \"\"\"Initialize a Select instance.\n\n        Args:\n            *args: The columns, tables, or aliases to select from.\n\n        Raises:\n            ValueError: If an argument is not a Column, Table, or As instance.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the SELECT statement for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the SELECT statement and a list of parameters.\n        \"\"\"\n        pass\n\n    def from_(self, table: Type[\"Table\"], *args: \"Join\") -> \"From\":\n        \"\"\"Add a FROM clause to the SELECT statement.\n\n        Args:\n            table: The main table to select from.\n            *args: Any JOIN clauses to include.\n\n        Returns:\n            A From instance representing the FROM clause.\n        \"\"\"\n        pass\n\nclass Update(QueryBuilder):\n    \"\"\"Represents an UPDATE statement in SQL.\"\"\"\n\n    def __init__(self, table: Type[\"Table\"]) -> None:\n        \"\"\"Initialize an Update instance.\n\n        Args:\n            table: The table to update.\n        \"\"\"\n        pass\n\n    def set(self, values: dict[\"Column\" | str, Any]) -> \"Set\":\n        \"\"\"Add a SET clause to the UPDATE statement.\n\n        Args:\n            values: A dictionary mapping columns to their new values.\n\n        Returns:\n            A Set instance representing the SET clause.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the UPDATE statement for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the UPDATE statement and an empty list of parameters.\n        \"\"\"\n        pass\n```",
        "minimal_code_skeleton_structured": [
            {
                "file_path": "pgqb/__init__.py",
                "code": "from typing import Type, Any\n\n# Forward declarations for type hints within this file, actual definitions are in builder.py / types.py\n# These are not part of the skeleton itself but help understand the facade function signatures.\n# For the skeleton, we only need the facade functions.\n# class Table: pass\n# class Column: pass\n# class As: pass\n# class InsertInto: pass\n# class Delete: pass\n# class Select: pass\n# class Update: pass\n# class Join: pass\n# class Expression: pass\n# class LogicGate: pass\n# class On: pass # Not used directly by tests via pgqb.on, but pgqb.builder.On is used by Join.on\n# enum BooleanOperator: AND = \"AND\"; AND_NOT = \"AND NOT\"; OR = \"OR\"; OR_NOT = \"OR NOT\" # From builder.py\n\ndef insert_into(table: Type[\"Table\"]) -> \"InsertInto\":\n    \"\"\"Build an insert query.\"\"\"\n    pass\n\ndef delete_from(table: Type[\"Table\"]) -> \"Delete\":\n    \"\"\"Build a delete query.\"\"\"\n    pass\n\ndef select(*args: \"Column\" | Type[\"Table\"] | \"As\") -> \"Select\":\n    \"\"\"Build a select query.\"\"\"\n    pass\n\ndef update(table: Type[\"Table\"]) -> \"Update\":\n    \"\"\"Build an update query.\"\"\"\n    pass\n\ndef join(table: Type[\"Table\"]) -> \"Join\":\n    \"\"\"Build a join query.\"\"\"\n    pass\n\ndef left_join(table: Type[\"Table\"]) -> \"Join\":\n    \"\"\"Build a left join query.\"\"\"\n    pass\n\ndef right_join(table: Type[\"Table\"]) -> \"Join\":\n    \"\"\"Build a right join query.\"\"\"\n    pass\n\ndef and_(evaluation: \"Expression\", *evaluations: \"Expression\" | \"LogicGate\") -> \"LogicGate\":\n    \"\"\"Build an \"and\" expression for a part of a query.\"\"\"\n    pass\n\ndef and_not(evaluation: \"Expression\", *evaluations: \"Expression\" | \"LogicGate\") -> \"LogicGate\":\n    \"\"\"Build an \"and not\" expression for a part of a query.\"\"\"\n    pass\n\ndef or_(evaluation: \"Expression\", *evaluations: \"Expression\" | \"LogicGate\") -> \"LogicGate\":\n    \"\"\"Build an \"or\" expression for a part of a query.\"\"\"\n    pass\n\ndef or_not(evaluation: \"Expression\", *evaluations: \"Expression\" | \"LogicGate\") -> \"LogicGate\":\n    \"\"\"Build an \"or not\" expression for a part of a query.\"\"\"\n    pass\n"
            },
            {
                "file_path": "pgqb/_snake.py",
                "code": "import re\nfrom typing import Union\n\ndef to_snake(string: str) -> str:\n    \"\"\"\n    Return a version of the string in `snake_case` format.\n\n    Args:\n        string: The string to convert to snake_case.\n\n    Returns:\n        The string in snake_case format.\n    \"\"\"\n    pass\n\ndef get_words(string: str) -> list[str]:\n    \"\"\"\n    Get a list of the words in a string in the order they appear.\n\n    Args:\n        string: The string to get the words from.\n\n    Returns:\n        A list of the words in the string.\n    \"\"\"\n    pass\n\ndef _split_words_on_regex(words: list[str], regex: Union[re.Pattern, str]) -> list[str]:  # type: ignore\n    \"\"\"\n    Split words on a regex.\n\n    Args:\n        words (list[str]): The list of words to split.\n        regex (Union[Pattern, str]): The regex to split on.\n\n    Returns:\n        list[str]: The list of words with the split words inserted.\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "pgqb/types.py",
                "code": "from __future__ import annotations\nimport enum\nfrom typing import Type\n\nclass PGEnum(enum.Enum):\n    \"\"\"Enum type class.\"\"\"\n\n    @classmethod\n    def pg_enum_name(cls) -> str:\n        \"\"\"Get the SQL name for this custom enum.\n\n        Args:\n            cls: The class to get the SQL name for.\n\n        Returns:\n            str: The SQL name for this custom enum.\n        \"\"\"\n        pass\n\n    @classmethod\n    def pg_enum_get_create(cls) -> str:\n        \"\"\"Get create enum SQL.\n\n        Args:\n            cls: The class to get the create enum SQL for.\n\n        Returns:\n            str: The create enum SQL.\n        \"\"\"\n        pass\n\nclass SQLType:\n    \"\"\"Base SQL type class.\"\"\"\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\nclass BIGINT(SQLType):\n    \"\"\"Signed eight-byte integer.\"\"\"\n    pass\n\nclass BIGSERIAL(SQLType):\n    \"\"\"Auto-incrementing eight-byte integer.\"\"\"\n    pass\n\nclass BIT(SQLType):\n    \"\"\"Fixed-length bit string.\"\"\"\n    pass\n\nclass VARBIT(SQLType):\n    \"\"\"Variable-length bit string.\"\"\"\n    pass\n\nclass BOOLEAN(SQLType):\n    \"\"\"Logical Boolean (true/false).\"\"\"\n    pass\n\nclass BOX(SQLType):\n    \"\"\"Rectangular box on a plane.\"\"\"\n    pass\n\nclass BYTEA(SQLType):\n    \"\"\"Binary data (byte array).\"\"\"\n    pass\n\nclass CHAR(SQLType):\n    \"\"\"Fixed-length character string.\"\"\"\n\n    def __init__(self, fixed_length: int | None = None) -> None:\n        \"\"\"Fixed-length character string.\n\n        Args:\n            fixed_length: The fixed length of the string.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\nclass VARCHAR(SQLType):\n    \"\"\"Variable-length character string.\"\"\"\n\n    def __init__(self, variable_length: int | None = None) -> None:\n        \"\"\"Variable-length character string.\n\n        Args:\n            variable_length: The variable length of the string.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\nclass CIDR(SQLType):\n    \"\"\"IPv4 or IPv6 network address.\"\"\"\n    pass\n\nclass CIRCLE(SQLType):\n    \"\"\"Circle on a plane.\"\"\"\n    pass\n\nclass DATE(SQLType):\n    \"\"\"Calendar date (year, month, day).\"\"\"\n    pass\n\nclass DOUBLE(SQLType):\n    \"\"\"Double precision floating-point number (8 bytes).\"\"\"\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\nclass INET(SQLType):\n    \"\"\"IPv4 or IPv6 host address.\"\"\"\n    pass\n\nclass INTEGER(SQLType):\n    \"\"\"Signed four-byte integer.\"\"\"\n    pass\n\nclass INTERVAL(SQLType):\n    \"\"\"Time span.\"\"\"\n\n    def __init__(self, fields: str | None = None, precision: int | None = None) -> None:\n        \"\"\"Time span.\n\n        Args:\n            fields: The fields of the interval.\n            precision: The precision of the interval.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\nclass JSON(SQLType):\n    \"\"\"Textual JSON data.\"\"\"\n    pass\n\nclass JSONB(SQLType):\n    \"\"\"Binary JSON data, decomposed.\"\"\"\n    pass\n\nclass LINE(SQLType):\n    \"\"\"Infinite line on a plane.\"\"\"\n    pass\n\nclass LSEG(SQLType):\n    \"\"\"Line segment on a plane.\"\"\"\n    pass\n\nclass MACADDR(SQLType):\n    \"\"\"MAC (Media Access Control) address.\"\"\"\n    pass\n\nclass MACADDR8(SQLType):\n    \"\"\"MAC (Media Access Control) address (EUI-64 format).\"\"\"\n    pass\n\nclass MONEY(SQLType):\n    \"\"\"Currency amount.\"\"\"\n    pass\n\nclass NUMERIC(SQLType):\n    \"\"\"Exact numeric of selectable precision.\"\"\"\n\n    def __init__(self, precision: int | None = None, scale: int | None = None) -> None:\n        \"\"\"Exact numeric of selectable precision.\n\n        Args:\n            precision: The precision of the numeric.\n            scale: The scale of the numeric.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\nclass PATH(SQLType):\n    \"\"\"Geometric path on a plane.\"\"\"\n    pass\n\nclass PG_LSN(SQLType):  # noqa: N801\n    \"\"\"PostgreSQL Log Sequence Number.\"\"\"\n    pass\n\nclass PG_SNAPSHOT(SQLType):  # noqa: N801\n    \"\"\"User-level transaction ID snapshot.\"\"\"\n    pass\n\nclass POINT(SQLType):\n    \"\"\"Geometric point on a plane.\"\"\"\n    pass\n\nclass POLYGON(SQLType):\n    \"\"\"Closed geometric path on a plane.\"\"\"\n    pass\n\nclass REAL(SQLType):\n    \"\"\"Single precision floating-point number (4 bytes).\"\"\"\n    pass\n\nclass SMALLINT(SQLType):\n    \"\"\"Signed two-byte integer.\"\"\"\n    pass\n\nclass SMALLSERIAL(SQLType):\n    \"\"\"Auto-incrementing two-byte integer.\"\"\"\n    pass\n\nclass SERIAL(SQLType):\n    \"\"\"Auto-incrementing four-byte integer.\"\"\"\n    pass\n\nclass TEXT(SQLType):\n    \"\"\"Variable-length character string.\"\"\"\n    pass\n\nclass TIME(SQLType):\n    \"\"\"Time of day.\"\"\"\n\n    def __init__(\n        self, precision: int | None = None, *, with_time_zone: bool = False\n    ) -> None:\n        \"\"\"Time of day.\n\n        Args:\n            precision: The precision of the time.\n            with_time_zone: Whether to include the time zone.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\nclass TIMESTAMP(SQLType):\n    \"\"\"Date and time.\"\"\"\n\n    def __init__(\n        self, precision: int | None = None, *, with_time_zone: bool = False\n    ) -> None:\n        \"\"\"Date and time.\n\n        Args:\n            precision: The precision of the timestamp.\n            with_time_zone: Whether to include the time zone.\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"Get the string representation of this column.\"\"\"\n        pass\n\nclass TSQUERY(SQLType):\n    \"\"\"Text search query.\"\"\"\n    pass\n\nclass TSVECTOR(SQLType):\n    \"\"\"Text search document.\"\"\"\n    pass\n\nclass UUID(SQLType):\n    \"\"\"Universally unique identifier.\"\"\"\n    pass\n\nclass XML(SQLType):\n    \"\"\"XML data.\"\"\"\n    pass\n"
            },
            {
                "file_path": "pgqb/builder.py",
                "code": "from __future__ import annotations\nimport abc\nimport enum\nfrom typing import Any, Type\nfrom typing_extensions import Self # Assuming Python <3.11 for Self, or use typing.Self for >=3.11\n\n# Forward declarations for type hints within this file\n# class SQLType: pass (from types)\n# class PGEnum: pass (from types)\nfrom pgqb.types import SQLType, PGEnum\n\n\nclass QueryBuilder(abc.ABC):\n    \"\"\"Base class for all query builders.\n\n    This abstract class defines the interface for all query builders in the system.\n    All specific query builder classes should inherit from this base class.\n    \"\"\"\n\n    @abc.abstractmethod\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Get all params and the SQL string.\n\n        Returns:\n            A tuple containing the SQL string and a list of parameters.\n        \"\"\"\n        pass\n\nclass _OperatorMixin(QueryBuilder, abc.ABC):  # noqa: PLW1641\n    \"\"\"Mixin class providing common SQL comparison and arithmetic operators.\n\n    This mixin adds methods for common SQL operators like >, <, =, !=, +, -, *, /, %.\n    It also includes IS and IS NOT operators.\n    \"\"\"\n\n    def __gt__(self, other: Any) -> \"Expression\":\n        \"\"\"Greater than operator.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the \"greater than\" comparison.\n        \"\"\"\n        pass\n\n    def __ge__(self, other: Any) -> \"Expression\":\n        \"\"\"Greater than or equal to operator.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the \"greater than or equal to\" comparison.\n        \"\"\"\n        pass\n\n    def __lt__(self, other: Any) -> \"Expression\":\n        \"\"\"Less than operator.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the \"less than\" comparison.\n        \"\"\"\n        pass\n\n    def __le__(self, other: Any) -> \"Expression\":\n        \"\"\"Less than or equal to operator.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the \"less than or equal to\" comparison.\n        \"\"\"\n        pass\n\n    def __eq__(self, other: object) -> \"Expression\":  # type: ignore\n        \"\"\"Equality operator.\n\n        For None, True, or False, uses IS operator instead of =.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the equality comparison.\n        \"\"\"\n        pass\n\n    def __ne__(self, other: object) -> \"Expression\":  # type: ignore\n        \"\"\"Inequality operator.\n\n        For None, True, or False, uses IS NOT operator instead of !=.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the inequality comparison.\n        \"\"\"\n        pass\n\n    def __add__(self, other: Any) -> \"Expression\":\n        \"\"\"Addition operator.\n\n        Args:\n            other: The value to add.\n\n        Returns:\n            An Expression representing the addition operation.\n        \"\"\"\n        pass\n\n    def __sub__(self, other: Any) -> \"Expression\":\n        \"\"\"Subtraction operator.\n\n        Args:\n            other: The value to subtract.\n\n        Returns:\n            An Expression representing the subtraction operation.\n        \"\"\"\n        pass\n\n    def __mul__(self, other: Any) -> \"Expression\":\n        \"\"\"Multiplication operator.\n\n        Args:\n            other: The value to multiply by.\n\n        Returns:\n            An Expression representing the multiplication operation.\n        \"\"\"\n        pass\n\n    def __truediv__(self, other: Any) -> \"Expression\":\n        \"\"\"Division operator.\n\n        Args:\n            other: The value to divide by.\n\n        Returns:\n            An Expression representing the division operation.\n        \"\"\"\n        pass\n\n    def __mod__(self, other: Any) -> \"Expression\":\n        \"\"\"Modulo operator.\n\n        Args:\n            other: The value to mod by.\n\n        Returns:\n            An Expression representing the modulo operation.\n        \"\"\"\n        pass\n\n    def is_(self, other: Any) -> \"Expression\":\n        \"\"\"Equality operator using IS.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the IS comparison.\n        \"\"\"\n        pass\n\n    def is_not(self, other: Any) -> \"Expression\":\n        \"\"\"Inequality operator using IS NOT.\n\n        Args:\n            other: The value to compare against.\n\n        Returns:\n            An Expression representing the IS NOT comparison.\n        \"\"\"\n        pass\n\nclass As(QueryBuilder):\n    \"\"\"Represents an SQL AS clause for aliasing.\n\n    This class is used to create aliases for columns or expressions in SQL queries.\n    \"\"\"\n\n    def __init__(self, sub_query: \"Column\" | \"Expression\", alias: str) -> None:\n        \"\"\"Initialize an As instance.\n\n        Args:\n            sub_query: The Column or Expression to be aliased.\n            alias: The alias name.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the AS clause.\n\n        Returns:\n            A tuple containing the SQL string for the AS clause and any parameters.\n        \"\"\"\n        pass\n\nclass Column(_OperatorMixin):\n    \"\"\"Represents a column in a SQL table.\n\n    This class encapsulates the properties and behaviors of a database column,\n    including its data type, constraints, and other attributes.\n    \"\"\"\n\n    def __init__(  # noqa: PLR0913\n        self,\n        sql_type: SQLType | Type[PGEnum] | None = None,\n        *,\n        check: str | None = None,\n        default: Any | None = None,\n        foreign_key: \"Column\" | None = None,\n        index: bool = False,\n        null: bool = False,\n        primary: bool = False,\n        unique: bool = False,\n    ) -> None:\n        \"\"\"Initialize a Column instance.\n\n        Args:\n            sql_type: The SQL type for this column.\n            check: The check constraint for this column.\n            default: The default value for this column.\n            foreign_key: The foreign key for this column.\n            index: Whether to create an index for this column.\n            null: Whether this column is nullable.\n            primary: Whether this column is a primary key.\n            unique: Whether this column is unique.\n        \"\"\"\n        pass\n\n    def __hash__(self) -> int:\n        \"\"\"Get the hash of this column.\n\n        Returns:\n            An integer hash value based on the string representation of the column.\n        \"\"\"\n        pass\n\n    def _create(self) -> str:\n        \"\"\"Get column create SQL.\n\n        Returns:\n            A string containing the SQL definition for creating this column.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Get column as SQL.\n\n        Returns:\n            A tuple containing the SQL string for this column and an empty list of parameters.\n        \"\"\"\n        pass\n\n    def as_(self, alias: str) -> \"As\":\n        \"\"\"Create an alias for this column.\n\n        Args:\n            alias: The alias name for the column.\n\n        Returns:\n            An As instance representing the aliased column.\n        \"\"\"\n        pass\n\n    def asc(self) -> \"Column\":\n        \"\"\"Set this column to be sorted in ascending order.\n\n        Returns:\n            A new Column instance with ascending sort order.\n        \"\"\"\n        pass\n\n    def desc(self) -> \"Column\":\n        \"\"\"Set this column to be sorted in descending order.\n\n        Returns:\n            A new Column instance with descending sort order.\n        \"\"\"\n        pass\n\nclass Table(type):\n    \"\"\"Metaclass for representing SQL tables.\n\n    This metaclass automatically processes class attributes to set up\n    table names and columns based on the class definition.\n    \"\"\"\n\n    __table_name__: str = \"\"\n    __table_columns__: dict[str, \"Column\"] = {}\n\n    def __init_subclass__(cls, **kwargs: Any) -> None:\n        \"\"\"Initialize a subclass of Table.\n\n        This method is called when a new subclass of Table is created. It sets up\n        the table name and processes the class attributes to identify columns.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        pass\n\n    @classmethod\n    def create_table(cls) -> str:\n        \"\"\"Generate SQL to create the table.\n\n        Returns:\n            A string containing the SQL CREATE TABLE statement for this table.\n        \"\"\"\n        pass\n\nclass _LimitMixin(QueryBuilder, abc.ABC):\n    \"\"\"Mixin class for adding LIMIT clause functionality.\"\"\"\n\n    def limit(self, limit: int) -> \"Limit\":\n        \"\"\"Add a LIMIT clause to the query.\n\n        Args:\n            limit: The maximum number of rows to return.\n\n        Returns:\n            A Limit instance representing the LIMIT clause.\n        \"\"\"\n        pass\n\nclass _OffsetMixin(QueryBuilder, abc.ABC):\n    \"\"\"Mixin class for adding OFFSET clause functionality.\"\"\"\n\n    def offset(self, offset: int) -> \"Offset\":\n        \"\"\"Add an OFFSET clause to the query.\n\n        Args:\n            offset: The number of rows to skip.\n\n        Returns:\n            An Offset instance representing the OFFSET clause.\n        \"\"\"\n        pass\n\nclass _PaginateMixin(_OffsetMixin, _LimitMixin, abc.ABC):\n    \"\"\"Mixin class combining LIMIT and OFFSET functionality for pagination.\"\"\"\n    pass\n\nclass _OrderByMixin(QueryBuilder, abc.ABC):\n    \"\"\"Mixin class for adding ORDER BY clause functionality.\"\"\"\n\n    def order_by(self, *columns: \"Column\") -> \"OrderBy\":\n        \"\"\"Add an ORDER BY clause to the query.\n\n        Args:\n            *columns: The columns to order by.\n\n        Returns:\n            An OrderBy instance representing the ORDER BY clause.\n        \"\"\"\n        pass\n\nclass _WhereMixin(QueryBuilder, abc.ABC):\n    \"\"\"Mixin class for adding WHERE clause functionality.\"\"\"\n\n    def where(\n        self, evaluation: \"Expression\", *evaluations: \"Expression\" | \"LogicGate\"\n    ) -> \"Where\":\n        \"\"\"Add a WHERE clause to the query.\n\n        Args:\n            evaluation: The primary condition for the WHERE clause.\n            *evaluations: Additional conditions to be combined with AND.\n\n        Returns:\n            A Where instance representing the WHERE clause.\n        \"\"\"\n        pass\n\nclass BooleanOperator(enum.Enum):\n    \"\"\"Enumeration of boolean operators used in SQL queries.\n\n    This enum defines the various boolean operators that can be used\n    in constructing complex SQL conditions.\n    \"\"\"\n\n    AND = \"AND\"\n    AND_NOT = \"AND NOT\"\n    OR = \"OR\"\n    OR_NOT = \"OR NOT\"\n    IS = \"IS\"\n    IS_NOT = \"IS NOT\"\n    IN = \"IN\"\n    NOT_IN = \"NOT IN\"\n\nclass LogicGate(QueryBuilder):\n    \"\"\"Represents a logical operation in SQL queries.\n\n    This class is used to construct complex logical conditions by combining\n    multiple expressions with boolean operators.\n    \"\"\"\n\n    def __init__(\n        self,\n        boolean_operator: \"BooleanOperator\",\n        evaluation: \"Expression\",\n        *evaluations: \"Expression\" | \"LogicGate\",\n    ) -> None:\n        \"\"\"Initialize a LogicGate instance.\n\n        Args:\n            boolean_operator: The boolean operator to use.\n            evaluation: The primary expression to evaluate.\n            *evaluations: Additional expressions to combine with the primary expression.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the logical operation for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for this logical operation and a list of parameters.\n        \"\"\"\n        pass\n\nclass Expression(_OperatorMixin):\n    \"\"\"Represents a SQL expression or condition.\n\n    This class is used to construct SQL expressions involving comparisons,\n    arithmetic operations, or function calls.\n    \"\"\"\n\n    def __init__(\n        self,\n        left_operand: \"Column\" | \"Expression\" | _OperatorMixin,\n        operator: str,\n        right_operand: Any,\n    ) -> None:\n        \"\"\"Initialize an Expression instance.\n\n        Args:\n            left_operand: The left side of the expression.\n            operator: The operator to use in the expression.\n            right_operand: The right side of the expression.\n        \"\"\"\n        pass\n\n    def as_(self, alias: str) -> \"As\":\n        \"\"\"Create an alias for this expression.\n\n        Args:\n            alias: The alias name for the expression.\n\n        Returns:\n            An As instance representing the aliased expression.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the expression for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for this expression and a list of parameters.\n        \"\"\"\n        pass\n\nclass Join(QueryBuilder):\n    \"\"\"Represents a JOIN operation in a SQL query.\n\n    This class is used to construct various types of JOIN clauses.\n    \"\"\"\n\n    def __init__(self, table: Type[\"Table\"]) -> None:\n        \"\"\"Initialize a Join instance.\n\n        Args:\n            table: The table to join with.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the JOIN clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for this JOIN clause and a list of parameters.\n\n        Raises:\n            ValueError: If no ON condition has been set for the join.\n        \"\"\"\n        pass\n\n    def on(self, *expressions: \"Expression\" | \"LogicGate\") -> Self:\n        \"\"\"Set the ON condition for the JOIN.\n\n        Args:\n            *expressions: The conditions to use in the ON clause.\n\n        Returns:\n            The Join instance itself, allowing for method chaining.\n        \"\"\"\n        pass\n\nclass LeftJoin(Join):\n    \"\"\"Represents a LEFT JOIN operation in a SQL query.\"\"\"\n\n    def __init__(self, table: Type[\"Table\"]) -> None:\n        \"\"\"Initialize a LeftJoin instance.\n\n        Args:\n            table: The table to left join with.\n        \"\"\"\n        pass\n\nclass RightJoin(Join):\n    \"\"\"Represents a RIGHT JOIN operation in a SQL query.\"\"\"\n\n    def __init__(self, table: Type[\"Table\"]) -> None:\n        \"\"\"Initialize a RightJoin instance.\n\n        Args:\n            table: The table to right join with.\n        \"\"\"\n        pass\n\nclass Limit(_OffsetMixin):\n    \"\"\"Represents a LIMIT clause in a SQL query.\"\"\"\n\n    def __init__(self, subquery: \"QueryBuilder\", limit: int) -> None:\n        \"\"\"Initialize a Limit instance.\n\n        Args:\n            subquery: The query to apply the LIMIT to.\n            limit: The maximum number of rows to return.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the LIMIT clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the LIMIT clause and a list of parameters.\n        \"\"\"\n        pass\n\nclass Offset(QueryBuilder):\n    \"\"\"Represents an OFFSET clause in a SQL query.\"\"\"\n\n    def __init__(self, subquery: \"QueryBuilder\", offset: int) -> None:\n        \"\"\"Initialize an Offset instance.\n\n        Args:\n            subquery: The query to apply the OFFSET to.\n            offset: The number of rows to skip.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the OFFSET clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the OFFSET clause and a list of parameters.\n        \"\"\"\n        pass\n\nclass On(_PaginateMixin):\n    \"\"\"Represents an ON clause in a JOIN operation.\"\"\"\n\n    def __init__(self, *expressions: \"Expression\" | \"LogicGate\") -> None:\n        \"\"\"Initialize an On instance.\n\n        Args:\n            *expressions: The conditions to use in the ON clause.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the ON clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the ON clause and a list of parameters.\n        \"\"\"\n        pass\n\nclass From(_WhereMixin, _PaginateMixin):\n    \"\"\"Represents a FROM clause in a SQL query.\"\"\"\n\n    def __init__(self, select: \"Select\", table: Type[\"Table\"], *joins: \"Join\") -> None:\n        \"\"\"Initialize a From instance.\n\n        Args:\n            select: The SELECT clause of the query.\n            table: The main table to select from.\n            *joins: Any JOIN clauses to include.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the FROM clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the FROM clause (including any JOINs) and a list of parameters.\n        \"\"\"\n        pass\n\nclass OrderBy(_PaginateMixin):\n    \"\"\"Represents an ORDER BY clause in a SQL query.\"\"\"\n\n    def __init__(\n        self, subquery: \"Select\" | \"From\" | \"On\" | _OrderByMixin, *columns: \"Column\"\n    ) -> None:\n        \"\"\"Initialize an OrderBy instance.\n\n        Args:\n            subquery: The query to apply the ORDER BY to.\n            *columns: The columns to order by.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the ORDER BY clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the ORDER BY clause and a list of parameters.\n        \"\"\"\n        pass\n\nclass Values(QueryBuilder):\n    \"\"\"Represents a VALUES clause in an INSERT statement.\"\"\"\n\n    def __init__(self, subquery: \"InsertInto\", values: dict[\"Column\" | str, Any]) -> None:\n        \"\"\"Initialize a Values instance.\n\n        Args:\n            subquery: The INSERT INTO clause.\n            values: A dictionary mapping columns to their values.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the VALUES clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the VALUES clause and a list of parameter values.\n        \"\"\"\n        pass\n\nclass Where(_OrderByMixin, _PaginateMixin):\n    \"\"\"Represents a WHERE clause in a SQL query.\"\"\"\n\n    def __init__(\n        self,\n        subquery: \"Select\" | \"From\" | _WhereMixin,\n        *expressions: \"Expression\" | \"LogicGate\",\n    ) -> None:\n        \"\"\"Initialize a Where instance.\n\n        Args:\n            subquery: The query to apply the WHERE clause to.\n            *expressions: The conditions to use in the WHERE clause.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the WHERE clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the WHERE clause and a list of parameters.\n        \"\"\"\n        pass\n\nclass Set(_WhereMixin):\n    \"\"\"Represents a SET clause in an UPDATE statement.\"\"\"\n\n    def __init__(self, subquery: \"Update\", values: dict[\"Column\" | str, Any]) -> None:\n        \"\"\"Initialize a Set instance.\n\n        Args:\n            subquery: The UPDATE clause.\n            values: A dictionary mapping columns to their new values.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the SET clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string with the SET clause and a list of parameter values.\n        \"\"\"\n        pass\n\nclass InsertInto(QueryBuilder):\n    \"\"\"Represents an INSERT INTO statement in SQL.\"\"\"\n\n    def __init__(self, table: Type[\"Table\"]) -> None:\n        \"\"\"Initialize an InsertInto instance.\n\n        Args:\n            table: The table to insert into.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the INSERT INTO clause for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the INSERT INTO clause and an empty list of parameters.\n        \"\"\"\n        pass\n\n    def values(self, values: dict[\"Column\" | str, Any] | None = None) -> \"Values\":\n        \"\"\"Add a VALUES clause to the INSERT statement.\n\n        Args:\n            values: A dictionary mapping columns to their values. If None, an empty dict is used.\n\n        Returns:\n            A Values instance representing the VALUES clause.\n        \"\"\"\n        pass\n\nclass Delete(_WhereMixin):\n    \"\"\"Represents a DELETE statement in SQL.\"\"\"\n\n    def __init__(self, table: Type[\"Table\"]) -> None:\n        \"\"\"Initialize a Delete instance.\n\n        Args:\n            table: The table to delete from.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the DELETE statement for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the DELETE statement and an empty list of parameters.\n        \"\"\"\n        pass\n\nclass Select(QueryBuilder):\n    \"\"\"Represents a SELECT statement in SQL.\"\"\"\n\n    def __init__(self, *args: \"Column\" | Type[\"Table\"] | \"As\") -> None:\n        \"\"\"Initialize a Select instance.\n\n        Args:\n            *args: The columns, tables, or aliases to select from.\n\n        Raises:\n            ValueError: If an argument is not a Column, Table, or As instance.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the SELECT statement for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the SELECT statement and a list of parameters.\n        \"\"\"\n        pass\n\n    def from_(self, table: Type[\"Table\"], *args: \"Join\") -> \"From\":\n        \"\"\"Add a FROM clause to the SELECT statement.\n\n        Args:\n            table: The main table to select from.\n            *args: Any JOIN clauses to include.\n\n        Returns:\n            A From instance representing the FROM clause.\n        \"\"\"\n        pass\n\nclass Update(QueryBuilder):\n    \"\"\"Represents an UPDATE statement in SQL.\"\"\"\n\n    def __init__(self, table: Type[\"Table\"]) -> None:\n        \"\"\"Initialize an Update instance.\n\n        Args:\n            table: The table to update.\n        \"\"\"\n        pass\n\n    def set(self, values: dict[\"Column\" | str, Any]) -> \"Set\":\n        \"\"\"Add a SET clause to the UPDATE statement.\n\n        Args:\n            values: A dictionary mapping columns to their new values.\n\n        Returns:\n            A Set instance representing the SET clause.\n        \"\"\"\n        pass\n\n    def prepare(self) -> tuple[str, list[Any]]:\n        \"\"\"Prepare the UPDATE statement for use in a SQL query.\n\n        Returns:\n            A tuple containing the SQL string for the UPDATE statement and an empty list of parameters.\n        \"\"\"\n        pass\n"
            }
        ],
        "minimal_test_cases": [
            {
                "test_id": "tests/test_builder.py::test_select",
                "covers": [
                    "pgqb.select - complex select with multiple joins, where, and order by",
                    "pgqb.join - standard SQL JOIN",
                    "pgqb.left_join - SQL LEFT JOIN",
                    "pgqb.right_join - SQL RIGHT JOIN",
                    "pgqb.builder.Select.from_ - basic FROM clause chaining",
                    "pgqb.builder.From.where - basic WHERE clause chaining",
                    "pgqb.builder.Where.order_by - basic ORDER BY clause chaining",
                    "pgqb.builder.Join.on - specifying join conditions",
                    "pgqb.builder.Column.asc - ordering ASC",
                    "pgqb.builder.Column.desc - ordering DESC",
                    "pgqb.builder.Column operators (==, >=, <=, >) - usage in conditions",
                    "pgqb.builder.QueryBuilder.prepare - general query preparation"
                ]
            },
            {
                "test_id": "tests/test_builder.py::test_select_columns",
                "covers": [
                    "pgqb.select - selecting specific columns and using aliases",
                    "pgqb.builder.Column.as_ - aliasing columns",
                    "pgqb.builder.From.limit - LIMIT clause usage",
                    "pgqb.builder.From.offset - OFFSET clause chaining after FROM",
                    "pgqb.builder.Limit.offset - OFFSET clause chaining after LIMIT"
                ]
            },
            {
                "test_id": "tests/test_builder.py::test_insert",
                "covers": [
                    "pgqb.insert_into - happy path for INSERT statement",
                    "pgqb.builder.InsertInto.values - specifying values with Column objects as keys"
                ]
            },
            {
                "test_id": "tests/test_builder.py::test_update",
                "covers": [
                    "pgqb.update - happy path for UPDATE statement",
                    "pgqb.builder.Update.set - specifying SET clause with Column objects as keys and subquery value",
                    "pgqb.builder.Set.where - WHERE clause for UPDATE statement"
                ]
            },
            {
                "test_id": "tests/test_builder.py::test_delete",
                "covers": [
                    "pgqb.delete_from - happy path for DELETE statement",
                    "pgqb.builder.Delete.where - WHERE clause for DELETE statement"
                ]
            },
            {
                "test_id": "tests/test_builder.py::test_expressions",
                "covers": [
                    "pgqb.and_ - logical AND in WHERE clause",
                    "pgqb.and_not - logical AND NOT in WHERE clause",
                    "pgqb.or_ - logical OR in WHERE clause",
                    "pgqb.or_not - logical OR NOT in WHERE clause",
                    "pgqb.builder.Column operators (>, <, >=, <=, !=) - comprehensive comparison usage"
                ]
            },
            {
                "test_id": "tests/test_builder.py::test_operators",
                "covers": [
                    "pgqb.builder.Column.is_ - SQL IS operator",
                    "pgqb.builder.Column.is_not - SQL IS NOT operator",
                    "pgqb.builder.Column operators (==, != for None/bool) - SQL IS NULL / IS TRUE / IS FALSE usage",
                    "pgqb.builder.Expression.as_ - aliasing complex expressions"
                ]
            },
            {
                "test_id": "tests/test_builder.py::test_operators_chained",
                "covers": [
                    "pgqb.builder.Column arithmetic operators (+, -, *, /, %) - arithmetic operations in expressions (xfail, but exercises API)"
                ]
            },
            {
                "test_id": "tests/test_types.py::test_create_table",
                "covers": [
                    "pgqb.builder.Table.create_table - fundamental table creation with common data types",
                    "pgqb.builder.Column.__init__ - defining columns with basic data types and primary keys",
                    "pgqb.types (various simple SQL types) - usage of standard SQL types"
                ]
            },
            {
                "test_id": "tests/test_types.py::test_type_options",
                "covers": [
                    "pgqb.builder.Table.create_table - table creation demonstrating data type parameters (length, precision, scale)",
                    "pgqb.builder.Column.__init__ - defining columns with parameterized data types",
                    "pgqb.types.CHAR.__init__ - specific test for CHAR(n)",
                    "pgqb.types.VARCHAR.__init__ - specific test for VARCHAR(n)",
                    "pgqb.types.INTERVAL.__init__ - specific test for INTERVAL with options",
                    "pgqb.types.NUMERIC.__init__ - specific test for NUMERIC(p,s) and validation",
                    "pgqb.types.TIME.__init__ - specific test for TIME with options",
                    "pgqb.types.TIMESTAMP.__init__ - specific test for TIMESTAMP with options"
                ]
            },
            {
                "test_id": "tests/test_types.py::test_column_options",
                "covers": [
                    "pgqb.builder.Table.create_table - table creation demonstrating various column constraints",
                    "pgqb.builder.Column.__init__ - defining columns with CHECK, DEFAULT, INDEX, NULL, UNIQUE, FOREIGN KEY constraints"
                ]
            },
            {
                "test_id": "tests/test_types.py::test_enum",
                "covers": [
                    "pgqb.types.PGEnum.pg_enum_get_create - DDL generation for custom PostgreSQL ENUM types",
                    "pgqb.types.PGEnum.pg_enum_name - Naming convention for ENUM types (implicit)",
                    "pgqb.builder.Table.create_table - table creation using custom PGEnum typed columns",
                    "pgqb.builder.Column.__init__ - defining columns of custom PGEnum type"
                ]
            },
            {
                "test_id": "tests/test_snake.py::test_get_words[PotatoHumanAlien-expected_output0]",
                "covers": [
                    "pgqb._snake.get_words - happy path for splitting string into words"
                ]
            },
            {
                "test_id": "tests/test_snake.py::test_to_snake[PotatoHumanAlien-potato_human_alien]",
                "covers": [
                    "pgqb._snake.to_snake - happy path for converting string to snake_case"
                ]
            }
        ]
    },
    {
        "idx": 37907,
        "repo_name": "ul-mds_gecko",
        "url": "https://github.com/ul-mds/gecko",
        "description": "Python library for the generation and mutation of realistic personal identification data at scale",
        "stars": 6,
        "forks": 1,
        "language": "python",
        "size": 5779,
        "created_at": "2024-03-12T12:12:25+00:00",
        "updated_at": "2025-03-28T12:22:49+00:00",
        "pypi_info": {
            "name": "gecko-syndata",
            "version": "0.6.4",
            "url": "https://files.pythonhosted.org/packages/11/1e/32a530ba32eb6934c6b46a52446aade36c59f8c52bdb9e16eeeca729da29/gecko_syndata-0.6.4.tar.gz"
        },
        "judge_info": {
            "language": "python",
            "is_good_project": false,
            "reason": "",
            "python_file_num": 13,
            "comment_ratio": 0.17084233261339093,
            "pyfile_content_length": 163754,
            "pyfile_code_lines": 4630,
            "test_file_exist": true,
            "test_file_content_length": 65742,
            "pytest_framework": true,
            "test_case_num": 133,
            "metadata_path": [
                "pyproject.toml"
            ],
            "readme_content_length": 5258,
            "llm_reason": "Positive Aspects:\n*   **Self-Contained Core Logic:** The core functionality of generating data from local frequency tables (CSVs) and applying various mutations does not inherently require internet access or external APIs/services. It relies on standard libraries like NumPy and Pandas.\n*   **Clear Functionality:** The project aims to generate and mutate datasets based on statistical information and defined rules (typos, phonetic changes, regex, etc.), which is a well-defined task.\n*   **Testable:** The project includes a comprehensive test suite (`tests` directory with `pytest` files), indicating that the output (Pandas DataFrames) is programmatically verifiable. These tests could be adapted to check the AI's output.\n*   **No GUI:** The project is a library, intended for programmatic use (scripting/import), not a GUI application.\n*   **Appropriate Complexity:** It's more complex than a trivial example, involving data generation strategies, various mutation algorithms (CLDR keymaps, phonetic rules, regex replacements), and effective use of Pandas/NumPy. Replicating this presents a meaningful challenge.\n*   **Well-Understood Domain:** Synthetic data generation and mutation is a relatively common problem in data science.\n*   **Code-Based:** The task is primarily Python code generation.\n\nNegative Aspects:\n*   **Requires Input Data:** The benchmark specification would need to explicitly provide the necessary input data files (e.g., frequency tables, CLDR keymap files, rule tables) that the original project uses (like those mentioned from the `gecko-data` repository) for the AI to replicate the functionality accurately. This data dependency needs careful handling in the benchmark setup.\n*   **Moderate Code Size/Features:** The library implements a significant number of distinct generator and mutator functions, increasing the scope and complexity for a 'from scratch' build compared to a smaller utility.\n*   **Potential Optimization Complexity:** Modules like `_dfbitlookup.py` suggest potential low-level optimizations that might add difficulty to replicate precisely without specific guidance.",
            "llm_project_type": "Data Generation/Mutation Library",
            "llm_rating": 75,
            "llm_difficulty": "Medium"
        },
        "tests": {
            "repo_name": "ul-mds_gecko",
            "finish_test": true,
            "test_case_result": {
                "tests/test_cldr.py::test_uppercase_char_to_index": "passed",
                "tests/test_cldr.py::test_decode_iso_kb_pos": "passed",
                "tests/test_cldr.py::test_unescape_kb_char": "passed",
                "tests/test_cldr.py::test_get_neighbor_kb_pos_for[trbl-noshift]": "passed",
                "tests/test_cldr.py::test_get_neighbor_kb_pos_for[trbl-shift]": "passed",
                "tests/test_cldr.py::test_get_neighbor_kb_pos_for[trb-noshift]": "passed",
                "tests/test_cldr.py::test_get_neighbor_kb_pos_for[rbl-noshift]": "passed",
                "tests/test_cldr.py::test_get_neighbor_kb_pos_for[blt-noshift]": "passed",
                "tests/test_cldr.py::test_get_neighbor_kb_pos_for[ltb-noshift]": "passed",
                "tests/test_dfbitlookup.py::test_with_capacity[1-1-1]": "passed",
                "tests/test_dfbitlookup.py::test_with_capacity[10-32-1]": "passed",
                "tests/test_dfbitlookup.py::test_with_capacity[10-64-1]": "passed",
                "tests/test_dfbitlookup.py::test_with_capacity[100-65-2]": "passed",
                "tests/test_dfbitlookup.py::test_with_capacity[100-128-2]": "passed",
                "tests/test_dfbitlookup.py::test_with_capacity[100-129-3]": "passed",
                "tests/test_dfbitlookup.py::test_with_capacity_raise_rows_too_low": "passed",
                "tests/test_dfbitlookup.py::test_with_capacity_raise_capacity_too_low": "passed",
                "tests/test_dfbitlookup.py::test_set_test_index[100-64-mask0-63]": "passed",
                "tests/test_dfbitlookup.py::test_set_test_index[100-128-mask1-64]": "passed",
                "tests/test_dfbitlookup.py::test_count_bits_per_row": "passed",
                "tests/test_dfbitlookup.py::test_count_bits_per_index": "passed",
                "tests/test_dfbitlookup.py::test_count_bits_per_index_infer_capacity": "passed",
                "tests/test_dfbitlookup.py::test_count_bits_per_index_raise_capacity_too_low": "passed",
                "tests/test_dfbitlookup.py::test_count_bits_per_index_raise_capacity_too_high": "passed",
                "tests/test_dfbitlookup.py::test_no_raise_on_test_int_idx_63[py-int-63]": "passed",
                "tests/test_dfbitlookup.py::test_no_raise_on_test_int_idx_63[np-int64-63]": "passed",
                "tests/test_dfbitlookup.py::test_no_raise_on_test_int_idx_63[np-uint64-63]": "passed",
                "tests/test_dfbitlookup.py::test_no_raise_on_test_int_idx_63[py-int-127]": "passed",
                "tests/test_dfbitlookup.py::test_no_raise_on_test_int_idx_63[np-int64-127]": "passed",
                "tests/test_dfbitlookup.py::test_no_raise_on_test_int_idx_63[np-uint64-127]": "passed",
                "tests/test_dfbitlookup.py::test_no_raise_on_set_int_idx_63[py-int-63]": "passed",
                "tests/test_dfbitlookup.py::test_no_raise_on_set_int_idx_63[np-int64-63]": "passed",
                "tests/test_dfbitlookup.py::test_no_raise_on_set_int_idx_63[np-uint64-63]": "passed",
                "tests/test_dfbitlookup.py::test_no_raise_on_set_int_idx_63[py-int-127]": "passed",
                "tests/test_dfbitlookup.py::test_no_raise_on_set_int_idx_63[np-int64-127]": "passed",
                "tests/test_dfbitlookup.py::test_no_raise_on_set_int_idx_63[np-uint64-127]": "passed",
                "tests/test_dfbitlookup.py::test_no_raise_on_count_int_idx_63[py-int-63]": "passed",
                "tests/test_dfbitlookup.py::test_no_raise_on_count_int_idx_63[np-int64-63]": "passed",
                "tests/test_dfbitlookup.py::test_no_raise_on_count_int_idx_63[np-uint64-63]": "passed",
                "tests/test_dfbitlookup.py::test_no_raise_on_count_int_idx_63[py-int-127]": "passed",
                "tests/test_dfbitlookup.py::test_no_raise_on_count_int_idx_63[np-int64-127]": "passed",
                "tests/test_dfbitlookup.py::test_no_raise_on_count_int_idx_63[np-uint64-127]": "passed",
                "tests/test_generator.py::test_from_function": "passed",
                "tests/test_generator.py::test_from_uniform_distribution": "passed",
                "tests/test_generator.py::test_from_normal_distribution": "passed",
                "tests/test_generator.py::test_from_frequency_table_no_header": "passed",
                "tests/test_generator.py::test_from_frequency_table_with_header": "passed",
                "tests/test_generator.py::test_from_frequency_table_tsv": "passed",
                "tests/test_generator.py::test_from_frequency_table": "passed",
                "tests/test_generator.py::test_from_multicolumn_frequency_table": "passed",
                "tests/test_generator.py::test_from_datetime_range": "passed",
                "tests/test_generator.py::test_from_datetime_range_invalid_start_datetime": "passed",
                "tests/test_generator.py::test_from_datetime_range_invalid_end_datetime": "passed",
                "tests/test_generator.py::test_from_datetime_range_all_units[d]": "passed",
                "tests/test_generator.py::test_from_datetime_range_all_units[days]": "passed",
                "tests/test_generator.py::test_from_datetime_range_all_units[h]": "passed",
                "tests/test_generator.py::test_from_datetime_range_all_units[hours]": "passed",
                "tests/test_generator.py::test_from_datetime_range_all_units[m]": "passed",
                "tests/test_generator.py::test_from_datetime_range_all_units[minutes]": "passed",
                "tests/test_generator.py::test_from_datetime_range_all_units[s]": "passed",
                "tests/test_generator.py::test_from_datetime_range_all_units[seconds]": "passed",
                "tests/test_generator.py::test_from_datetime_range_end_before_start": "passed",
                "tests/test_generator.py::test_to_dataframe_error_empty_list": "passed",
                "tests/test_generator.py::test_to_dataframe_error_count_not_positive": "passed",
                "tests/test_generator.py::test_to_dataframe": "passed",
                "tests/test_generator.py::test_from_frequency_table_nan": "passed",
                "tests/test_generator.py::test_from_frequency_table_df": "passed",
                "tests/test_generator.py::test_from_multicolumn_frequency_table_nan": "passed",
                "tests/test_generator.py::test_from_multicolumn_frequency_table_df": "passed",
                "tests/test_generator.py::test_from_group_single_column_same_weight": "passed",
                "tests/test_generator.py::test_from_group_single_column_different_weight": "passed",
                "tests/test_generator.py::test_from_group_multiple_column_same_weight": "passed",
                "tests/test_generator.py::test_from_group_multiple_column_different_weight": "passed",
                "tests/test_generator.py::test_from_group_raise_different_column_counts": "passed",
                "tests/test_generator.py::test_from_group_raise_p_sum_not_1": "passed",
                "tests/test_generator.py::test_from_group_raise_row_count": "passed",
                "tests/test_generator.py::test_from_group_rounding_adjustment_positive": "passed",
                "tests/test_generator.py::test_from_group_weight_sanity_check": "passed",
                "tests/test_generator.py::test_from_group_rounding_adjustment_negative": "passed",
                "tests/test_generator.py::test_from_group_raise_rounding_adjustment_not_high_enough": "passed",
                "tests/test_mutator.py::test_with_cldr_keymap_file": "passed",
                "tests/test_mutator.py::test_with_cldr_keymap_file_partial": "passed",
                "tests/test_mutator.py::test_with_cldr_keymap_file_multiple_options": "passed",
                "tests/test_mutator.py::test_with_cldr_keymap_file_warn_low_p": "passed",
                "tests/test_mutator.py::test_with_missing_value": "passed",
                "tests/test_mutator.py::test_with_missing_value_partial": "passed",
                "tests/test_mutator.py::test_with_missing_value_existing": "passed",
                "tests/test_mutator.py::test_with_replacement_table": "passed",
                "tests/test_mutator.py::test_with_replacement_table_random_values": "passed",
                "tests/test_mutator.py::test_with_replacement_table_favor_rare_replacements": "passed",
                "tests/test_mutator.py::test_with_replacement_table_partial": "passed",
                "tests/test_mutator.py::test_with_replacement_table_reverse": "passed",
                "tests/test_mutator.py::test_with_replacement_table_inline": "passed",
                "tests/test_mutator.py::test_with_replacement_table_warn_p": "passed",
                "tests/test_mutator.py::test_with_replacement_table_csv": "passed",
                "tests/test_mutator.py::test_with_delete": "passed",
                "tests/test_mutator.py::test_with_delete_partial": "passed",
                "tests/test_mutator.py::test_with_delete_warn_p": "passed",
                "tests/test_mutator.py::test_with_insert": "passed",
                "tests/test_mutator.py::test_with_insert_partial": "passed",
                "tests/test_mutator.py::test_with_insert_charset": "passed",
                "tests/test_mutator.py::test_with_transpose": "passed",
                "tests/test_mutator.py::test_with_transpose_partial": "passed",
                "tests/test_mutator.py::test_with_transpose_warn_p": "passed",
                "tests/test_mutator.py::test_with_substitute": "passed",
                "tests/test_mutator.py::test_with_substitute_partial": "passed",
                "tests/test_mutator.py::test_with_substitute_charset": "passed",
                "tests/test_mutator.py::test_with_substitute_warn_p": "passed",
                "tests/test_mutator.py::test_with_uppercase": "passed",
                "tests/test_mutator.py::test_with_uppercase_partial": "passed",
                "tests/test_mutator.py::test_with_uppercase_warn_p": "passed",
                "tests/test_mutator.py::test_with_lowercase": "passed",
                "tests/test_mutator.py::test_with_lowercase_partial": "passed",
                "tests/test_mutator.py::test_with_lowercase_warn_p": "passed",
                "tests/test_mutator.py::test_with_function": "passed",
                "tests/test_mutator.py::test_with_function_partial": "passed",
                "tests/test_mutator.py::test_with_repeat": "passed",
                "tests/test_mutator.py::test_with_repeat_partial": "passed",
                "tests/test_mutator.py::test_with_repeat_join_character": "passed",
                "tests/test_mutator.py::test_with_permute": "passed",
                "tests/test_mutator.py::test_with_permute_multicolumn": "passed",
                "tests/test_mutator.py::test_with_permute_partial": "passed",
                "tests/test_mutator.py::test_with_generator_replace": "passed",
                "tests/test_mutator.py::test_with_generator_partial": "passed",
                "tests/test_mutator.py::test_with_generator_prepend": "passed",
                "tests/test_mutator.py::test_with_generator_append": "passed",
                "tests/test_mutator.py::test_with_generator_prepend_join_char": "passed",
                "tests/test_mutator.py::test_with_generator_append_join_char": "passed",
                "tests/test_mutator.py::test_with_generator_prepend_join_char_insert": "passed",
                "tests/test_mutator.py::test_with_generator_append_join_char_insert": "passed",
                "tests/test_mutator.py::test_with_generator_multi_column": "passed",
                "tests/test_mutator.py::test_with_generator_raise_mismatched_columns": "passed",
                "tests/test_mutator.py::test_with_group": "passed",
                "tests/test_mutator.py::test_with_group_partial": "passed",
                "tests/test_mutator.py::test_with_group_weighted": "passed",
                "tests/test_mutator.py::test_with_group_padded": "passed",
                "tests/test_mutator.py::test_with_group_raise_p_sum_too_high": "passed",
                "tests/test_mutator.py::test_with_group_raise_p_sum_too_low": "passed",
                "tests/test_mutator.py::test_with_categorical_values": "passed",
                "tests/test_mutator.py::test_with_categorical_values_partial": "passed",
                "tests/test_mutator.py::test_with_categorical_values_warn_p": "passed",
                "tests/test_mutator.py::test_with_categorical_values_raise_too_few_values": "passed",
                "tests/test_mutator.py::test_with_categorical_values_csv": "passed",
                "tests/test_mutator.py::test_with_datetime_offset[d]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset[days]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset[h]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset[hours]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset[m]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset[minutes]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset[s]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset[seconds]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset_partial[d]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset_partial[days]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset_partial[h]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset_partial[hours]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset_partial[m]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset_partial[minutes]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset_partial[s]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset_partial[seconds]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[d]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[days]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[h]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[hours]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[m]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[minutes]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[s]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[seconds]": "passed",
                "tests/test_mutator.py::test_with_datetime_offset_custom_format": "passed",
                "tests/test_mutator.py::test_with_datetime_offset_raise_invalid_delta": "passed",
                "tests/test_mutator.py::test_with_phonetic_replacement_table": "passed",
                "tests/test_mutator.py::test_with_phonetic_replacement_table_random_values": "passed",
                "tests/test_mutator.py::test_with_phonetic_replacement_table_partial": "passed",
                "tests/test_mutator.py::test_with_phonetic_replacement_table_no_flags": "passed",
                "tests/test_mutator.py::test_with_phonetic_replacement_table_csv": "passed",
                "tests/test_mutator.py::test_with_phonetic_replacement_table_warn_p": "passed",
                "tests/test_mutator.py::test_with_phonetic_replacement_table_raise_no_rules": "passed",
                "tests/test_mutator.py::test_with_regex_replacement_table_unnamed_capture_group": "passed",
                "tests/test_mutator.py::test_with_regex_replacement_table_favor_rare_regexes": "passed",
                "tests/test_mutator.py::test_with_regex_replacement_table_unnamed_capture_group_partial": "passed",
                "tests/test_mutator.py::test_with_regex_replacement_table_named_capture_group": "passed",
                "tests/test_mutator.py::test_with_regex_replacement_table_flags": "passed",
                "tests/test_mutator.py::test_with_regex_replacement_table_warn_p": "passed",
                "tests/test_mutator.py::test_with_regex_replacement_table_raise_no_rules": "passed",
                "tests/test_mutator.py::test_with_regex_replacement_table_csv": "passed",
                "tests/test_mutator.py::test_with_regex_replacement_table_partial[pattern0]": "passed",
                "tests/test_mutator.py::test_with_regex_replacement_table_partial[pattern1]": "passed",
                "tests/test_mutator.py::test_with_regex_replacement_table_random_values": "passed",
                "tests/test_mutator.py::test_mutate_data_frame": "passed"
            },
            "success_count": 188,
            "failed_count": 0,
            "error_count": 0,
            "skipped_count": 0,
            "unknown_count": 0,
            "total_count": 188,
            "success_rate": 1.0,
            "coverage_report": {
                "covered_lines": 908,
                "num_statements": 984,
                "percent_covered": 88.83357041251779,
                "percent_covered_display": "89",
                "missing_lines": 76,
                "excluded_lines": 0,
                "num_branches": 422,
                "num_partial_branches": 81,
                "covered_branches": 341,
                "missing_branches": 81
            },
            "coverage_result": {}
        },
        "codelines_count": 4630,
        "codefiles_count": 13,
        "code_length": 163754,
        "test_files_count": 4,
        "test_code_length": 65742,
        "class_diagram": "@startuml\nclass GeckoWarning {\n}\nclass _PhoneticReplacementRule {\n    pattern: str\n    replacement: str\n    flag: str\n}\nclass KeyMutation {\n    row: list[str]\n    col: list[str]\n}\n@enduml",
        "structure": [
            {
                "file": "tests/test_dfbitlookup.py",
                "functions": [
                    {
                        "name": "test_with_capacity",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rows",
                            "capacity",
                            "expected_columns"
                        ]
                    },
                    {
                        "name": "test_with_capacity_raise_rows_too_low",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_with_capacity_raise_capacity_too_low",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_set_test_index",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rows",
                            "capacity",
                            "mask",
                            "index"
                        ]
                    },
                    {
                        "name": "test_count_bits_per_row",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_count_bits_per_index",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_count_bits_per_index_infer_capacity",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_count_bits_per_index_raise_capacity_too_low",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_count_bits_per_index_raise_capacity_too_high",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_no_raise_on_test_int_idx_63",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "index"
                        ]
                    },
                    {
                        "name": "test_no_raise_on_set_int_idx_63",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "index"
                        ]
                    },
                    {
                        "name": "test_no_raise_on_count_int_idx_63",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "index"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/conftest.py",
                "functions": [
                    {
                        "name": "rng_factory",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "rng",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng_factory"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_generator.py",
                "functions": [
                    {
                        "name": "test_from_function",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_from_uniform_distribution",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_normal_distribution",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_frequency_table_no_header",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_frequency_table_with_header",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_frequency_table_tsv",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_frequency_table",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_multicolumn_frequency_table",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_datetime_range",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_datetime_range_invalid_start_datetime",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_datetime_range_invalid_end_datetime",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_datetime_range_all_units",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng",
                            "unit"
                        ]
                    },
                    {
                        "name": "test_from_datetime_range_end_before_start",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_to_dataframe_error_empty_list",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_to_dataframe_error_count_not_positive",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_to_dataframe",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_frequency_table_nan",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "tmp_path",
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_frequency_table_df",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_multicolumn_frequency_table_nan",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "tmp_path",
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_multicolumn_frequency_table_df",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_group_single_column_same_weight",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_group_single_column_different_weight",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_group_multiple_column_same_weight",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_group_multiple_column_different_weight",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_group_raise_different_column_counts",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_group_raise_p_sum_not_1",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_group_raise_row_count",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_group_rounding_adjustment_positive",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_group_weight_sanity_check",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_group_rounding_adjustment_negative",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_from_group_raise_rounding_adjustment_not_high_enough",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_mutator.py",
                "functions": [
                    {
                        "name": "test_with_cldr_keymap_file",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_cldr_keymap_file_partial",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_cldr_keymap_file_multiple_options",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_cldr_keymap_file_warn_low_p",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_missing_value",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_missing_value_partial",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_missing_value_existing",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_replacement_table",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_replacement_table_random_values",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_replacement_table_favor_rare_replacements",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_replacement_table_partial",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_replacement_table_reverse",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_replacement_table_inline",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_replacement_table_warn_p",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_replacement_table_csv",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng",
                            "tmp_path"
                        ]
                    },
                    {
                        "name": "test_with_delete",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_delete_partial",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_delete_warn_p",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_insert",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_insert_partial",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_insert_charset",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_transpose",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_transpose_partial",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_transpose_warn_p",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_substitute",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_substitute_partial",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_substitute_charset",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_substitute_warn_p",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_uppercase",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_uppercase_partial",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_uppercase_warn_p",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_lowercase",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_lowercase_partial",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_lowercase_warn_p",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_function",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_function_partial",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_repeat",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_repeat_partial",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_repeat_join_character",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_permute",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_permute_multicolumn",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_permute_partial",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "_from_scalar_value",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "column_values"
                        ]
                    },
                    {
                        "name": "test_with_generator_replace",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_generator_partial",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_generator_prepend",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_generator_append",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_generator_prepend_join_char",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_generator_append_join_char",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_generator_prepend_join_char_insert",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_generator_append_join_char_insert",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_generator_multi_column",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_generator_raise_mismatched_columns",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_group",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_group_partial",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_group_weighted",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_group_padded",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_group_raise_p_sum_too_high",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_group_raise_p_sum_too_low",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_categorical_values",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_categorical_values_partial",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_categorical_values_warn_p",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_categorical_values_raise_too_few_values",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_categorical_values_csv",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng",
                            "tmp_path"
                        ]
                    },
                    {
                        "name": "test_with_datetime_offset",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng",
                            "unit"
                        ]
                    },
                    {
                        "name": "test_with_datetime_offset_partial",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng",
                            "unit"
                        ]
                    },
                    {
                        "name": "test_with_datetime_offset_prevent_wraparound",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng",
                            "unit"
                        ]
                    },
                    {
                        "name": "test_with_datetime_offset_custom_format",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_datetime_offset_raise_invalid_delta",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_phonetic_replacement_table",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_phonetic_replacement_table_random_values",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_phonetic_replacement_table_partial",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_phonetic_replacement_table_no_flags",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_phonetic_replacement_table_csv",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng",
                            "tmp_path"
                        ]
                    },
                    {
                        "name": "test_with_phonetic_replacement_table_warn_p",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_phonetic_replacement_table_raise_no_rules",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_regex_replacement_table_unnamed_capture_group",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_regex_replacement_table_favor_rare_regexes",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_regex_replacement_table_unnamed_capture_group_partial",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_regex_replacement_table_named_capture_group",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_regex_replacement_table_flags",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_regex_replacement_table_warn_p",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_regex_replacement_table_raise_no_rules",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_with_regex_replacement_table_csv",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng",
                            "tmp_path"
                        ]
                    },
                    {
                        "name": "test_with_regex_replacement_table_partial",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng",
                            "pattern"
                        ]
                    },
                    {
                        "name": "test_with_regex_replacement_table_random_values",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "test_mutate_data_frame",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_cldr.py",
                "functions": [
                    {
                        "name": "test_uppercase_char_to_index",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_decode_iso_kb_pos",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_unescape_kb_char",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_get_neighbor_kb_pos_for",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "kb_pos",
                            "max_row",
                            "max_col",
                            "expected_kb_pos_list"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/helpers.py",
                "functions": [
                    {
                        "name": "get_asset_path",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "file_name"
                        ]
                    },
                    {
                        "name": "write_temporary_csv_file",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "dir_path",
                            "header",
                            "rows",
                            "delimiter",
                            "encoding"
                        ]
                    },
                    {
                        "name": "random_strings",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "n_strings",
                            "str_len",
                            "charset",
                            "unique",
                            "rng"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "gecko/generator.py",
                "functions": [
                    {
                        "name": "from_function",
                        "docstring": "Generate data from an arbitrary function that returns a single value at a time.\n\nNotes:\n    This function should be used sparingly since it is not vectorized.\n    Only use it for testing purposes or if performance is not important.\n\nArgs:\n    func: function to invoke to generate data from\n    *args: positional arguments to pass to `func`\n    **kwargs: keyword arguments to pass to `func`\n\nReturns:\n    function returning list with strings generated from custom function",
                        "comments": null,
                        "args": [
                            "func"
                        ]
                    },
                    {
                        "name": "from_uniform_distribution",
                        "docstring": "Generate data from a uniform distribution.\n\nArgs:\n    low: lower limit of uniform distribution (inclusive)\n    high: upper limit of uniform distribution (exclusive)\n    precision: decimal precision of the numbers generated from the uniform distribution\n    rng: random number generator to use\n\nReturns:\n    function returning list with numbers drawn from a uniform distribution formatted as strings",
                        "comments": null,
                        "args": [
                            "low",
                            "high",
                            "precision",
                            "rng"
                        ]
                    },
                    {
                        "name": "from_normal_distribution",
                        "docstring": "Generate data from a normal distribution.\n\nArgs:\n    mean: mean of the normal distribution\n    sd: standard deviation of the normal distribution\n    precision: decimal precision of the numbers generated from the normal distribution\n    rng: random number generator to use\n\nReturns:\n    function returning list with numbers drawn from a normal distribution formatted as strings",
                        "comments": null,
                        "args": [
                            "mean",
                            "sd",
                            "precision",
                            "rng"
                        ]
                    },
                    {
                        "name": "from_frequency_table",
                        "docstring": "Generate data from a frequency table.\nThe frequency table must be provided in CSV format and contain at least two columns: one containing values to\ngenerate and one containing their assigned absolute frequencies.\nValues generated by this function will have a distribution similar to the frequencies listed in the input file.\nIf the value and frequency column are provided as strings, then it is automatically assumed that the CSV file\nhas a header row.\n\nArgs:\n    data_source: path to CSV file or data frame to use as frequency table\n    value_column: name or index of the value column\n    freq_column: name or index of the frequency column\n    encoding: character encoding of the CSV file\n    delimiter: column delimiter of the CSV file\n    rng: random number generator to use\n\nReturns:\n    function returning list with single series containing values generated from the input file",
                        "comments": null,
                        "args": [
                            "data_source",
                            "value_column",
                            "freq_column",
                            "encoding",
                            "delimiter",
                            "rng"
                        ]
                    },
                    {
                        "name": "from_multicolumn_frequency_table",
                        "docstring": "Generate data from a frequency table with multiple interdependent columns..\nThe frequency table must be provided in CSV format and contain at least two columns: one containing values to\ngenerate and one containing their assigned absolute frequencies.\nValues generated by this function will have a distribution similar to the frequencies listed in the input file.\nIf the values and frequency column are provided as strings, then it is automatically assumed that the CSV file\nhas a header row.\n\nArgs:\n    data_source: path to CSV file or data frame to use as frequency table\n    value_columns: names or indices of the value columns\n    freq_column: name or index of the frequency column\n    encoding: character encoding of the CSV file\n    delimiter: column delimiter of the CSV file\n    rng: random number generator to use\n\nReturns:\n    function returning list with as many series as there are value columns specified containing values generated from the input file",
                        "comments": null,
                        "args": [
                            "data_source",
                            "value_columns",
                            "freq_column",
                            "encoding",
                            "delimiter",
                            "rng"
                        ]
                    },
                    {
                        "name": "from_datetime_range",
                        "docstring": "Generate data from a range of dates and times.\nThe start and end datetime must be provided either as a ISO 8601 datetime string or a NumPy datetime object.\nThe output format must include the same format codes as specified in the `datetime` Python module for the\n`strftime` function.\nThe unit specifies the smallest unit of time that may change when generating random dates and times.\nFor example if `D` is specified, generated dates will only differ in their days, months and years, leaving hours,\nminutes and seconds unaffected.\nThe same applies for `h`, `m` and `s` for hours, minutes and seconds respectively.\n\nArgs:\n    start_dt: datetime string or object for start of range\n    end_dt: datetime string or object for end of range\n    dt_format: output format for generated datetimes\n    unit: smallest unit of time that may change when generating random dates and times\n    rng: random number generator to use\n\nReturns:\n    function returning list of random datetime strings within the specified range",
                        "comments": null,
                        "args": [
                            "start_dt",
                            "end_dt",
                            "dt_format",
                            "unit",
                            "rng"
                        ]
                    },
                    {
                        "name": "_is_weighted_generator",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "x"
                        ]
                    },
                    {
                        "name": "from_group",
                        "docstring": "Generate data from multiple generators.\nUnless explicitly specified, all generators will generate data with equal probability.\nAlternatively generators can be assigned fixed probabilities.\nThe output of each generator is then shuffled.\nIf all generators generate multiple series, then all series are shuffled the same.\nDue to rounding errors, it may occur that the computed amount of rows to generate for each generator does\nnot exactly sum up to the desired amount of rows.\nTo compensate, this generator allows the specification of a maximum amount of rows that may be added or removed\nto random generators to match the target amount of rows.\n\nArgs:\n    generator_lst: list of (weighted) generators\n    max_rounding_adjustment: maximum amount of rows to add or remove if the computed amount of total rows does not match the desired amount of rows\n    rng: random number generator to use\n\nReturns:\n    function returning list of random data generated using supplied generators",
                        "comments": null,
                        "args": [
                            "generator_lst",
                            "max_rounding_adjustment",
                            "rng"
                        ]
                    },
                    {
                        "name": "to_data_frame",
                        "docstring": "Generate data frame by using multiple generators at once.\nColumn names must be mapped to their respective generators.\nA generator can be assigned to one or multiple column names, but it must always match the amount of series\nthat the generator returns.\n\nArgs:\n    generator_lst: list of column names to generators\n    count: amount of records to generate\n\nReturns:\n    data frame with columns and rows generated as specified",
                        "comments": null,
                        "args": [
                            "generator_lst",
                            "count"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "gecko/_typedefs.py",
                "functions": [
                    {
                        "name": "convert_gecko_date_time_unit_to_pandas",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "unit"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "GeckoWarning",
                        "docstring": "Generic class that represents all warnings emitted by Gecko.",
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "gecko/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "gecko/mutator.py",
                "functions": [
                    {
                        "name": "_check_probability_in_bounds",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "p"
                        ]
                    },
                    {
                        "name": "_warn_p",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "fn_name",
                            "p_expected",
                            "p_actual"
                        ]
                    },
                    {
                        "name": "with_function",
                        "docstring": "Mutate series using an arbitrary function that mutates a single value at a time.\n\nNotes:\n    This function should be used sparingly since it is not vectorized.\n    Only use it for testing purposes or if performance is not important.\n\nArgs:\n    func: function to mutate values with\n    rng: random number generator to use\n    *args: positional arguments to pass to `func`\n    **kwargs: keyword arguments to pass to `func`\n\nReturns:\n    function that mutates series using the custom function",
                        "comments": null,
                        "args": [
                            "func",
                            "rng"
                        ]
                    },
                    {
                        "name": "with_cldr_keymap_file",
                        "docstring": "Mutate series by randomly introducing typos.\nPotential typos are sourced from a Common Locale Data Repository (CLDR) keymap.\nAny character may be replaced with one of its horizontal or vertical neighbors on a keyboard.\nThey may also be replaced with its upper- or lowercase variant.\nIt is possible for a string to not be modified if a selected character has no possible replacements.\nIf the `charset` parameter is `None`, then any character present on the keymap may be mutated.\n\nArgs:\n    cldr_path: path to CLDR keymap file\n    charset: character string or list of characters that may be mutated\n    rng: random number generator to use\n\nReturns:\n    function that mutates series using a keymap",
                        "comments": null,
                        "args": [
                            "cldr_path",
                            "charset",
                            "rng"
                        ]
                    },
                    {
                        "name": "with_phonetic_replacement_table",
                        "docstring": "Mutate series by randomly replacing character sequences with others that sound similar.\nThe rules for similar-sounding character sequences are sourced from a table.\nThis table must have at least three columns: a source, target and a flag column.\nA source pattern is mapped to its target under the rules imposed by the provided flags.\nThese flags determine where such a replacement can take place within a string.\nIf no flags are defined, it is implied that this replacement can take place anywhere in a string.\nConversely, if `^`, `$`, `_`, or any combination of the three are set, it implies that a replacement\ncan only occur at the start, end or in the middle of a string.\nIf the source, target and flags column are provided as strings, and if a path to a CSV file is\nprovided to this function, then it is automatically assumed that the CSV file has a header row.\n\nArgs:\n    data_source: path to CSV file or data frame containing phonetic replacement rules\n    source_column: name or index of source column\n    target_column: name or index of target column\n    flags_column: name or index of flag column\n    encoding: character encoding of the CSV file\n    delimiter: column delimiter of the CSV file\n    rng: random number generator to use\n\nReturns:\n   function that mutates series using phonetic rules sourced from a table",
                        "comments": null,
                        "args": [
                            "data_source",
                            "source_column",
                            "target_column",
                            "flags_column",
                            "encoding",
                            "delimiter",
                            "rng"
                        ]
                    },
                    {
                        "name": "with_replacement_table",
                        "docstring": "Mutate series by randomly substituting character sequences from a replacement table.\nThe table must have at least two columns: a source and a target value column.\nA source value may have multiple target values that it can map to.\nStrings that do not contain any possible source values are not mutated.\nIt is possible for a string to not be modified if no target value could be picked for its assigned source value.\nThis can only happen if a source value is mapped to multiple target values.\nIn this case, each target value will be independently selected or not.\nIf the source and target column are provided as strings, and a path to a CSV file is provided\nto this function, then it is automatically assumed that the CSV file has a header row.\nThe mutator will favor less common replacements over more common ones.\n\nArgs:\n    data_source: path to CSV file or data frame containing replacement table\n    source_column: name or index of the source column\n    target_column: name or index of the target column\n    inline: whether to perform replacements inline\n    reverse: whether to allow replacements from target to source column\n    encoding: character encoding of the CSV file\n    delimiter: column delimiter of the CSV file\n    rng: random number generator to use\n\nReturns:\n    function that mutates series according to a replacement table",
                        "comments": null,
                        "args": [
                            "data_source",
                            "source_column",
                            "target_column",
                            "inline",
                            "reverse",
                            "encoding",
                            "delimiter",
                            "rng"
                        ]
                    },
                    {
                        "name": "with_missing_value",
                        "docstring": "Mutate series by replacing its values with a representative \"missing\" value.\n\nArgs:\n    value: \"missing\" value to replace select entries with\n    rng: random number generator to use\n\nReturns:\n    function that mutates series by overwriting it with a \"missing\" value",
                        "comments": null,
                        "args": [
                            "value",
                            "rng"
                        ]
                    },
                    {
                        "name": "with_insert",
                        "docstring": "Mutate series by inserting random characters.\nThe characters are drawn from the provided charset.\n\nArgs:\n    charset: character string or list of characters to sample from\n    rng: random number generator to use\n\nReturns:\n    function that mutates series by injecting random characters",
                        "comments": null,
                        "args": [
                            "charset",
                            "rng"
                        ]
                    },
                    {
                        "name": "with_delete",
                        "docstring": "Mutate series by randomly deleting characters.\n\nArgs:\n    rng: random number generator to use\n\nReturns:\n    function that mutates series by deleting random characters",
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "with_transpose",
                        "docstring": "Mutate series by randomly swapping neighboring characters.\n\nNotes:\n    It is possible for the same two neighboring characters to be swapped.\n\nArgs:\n    rng: random number generator to use\n\nReturns:\n    function that mutates series by swapping adjacent characters",
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "with_substitute",
                        "docstring": "Mutate data by replacing single characters with a new one.\nThe characters are drawn from the provided charset.\n\nNotes:\n    It is possible for a character to be replaced by itself.\n\nArgs:\n    charset: character string or list of characters to sample from\n    rng: random number generator to use\n\nReturns:\n    function that mutates series by substituting random characters",
                        "comments": null,
                        "args": [
                            "charset",
                            "rng"
                        ]
                    },
                    {
                        "name": "with_noop",
                        "docstring": "Mutate series by not mutating it at all.\nThis mutator returns the input series as-is.\nYou might use it to leave a certain percentage of records in a series untouched.\n\nReturns:\n    function that does not mutate series",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "with_categorical_values",
                        "docstring": "Mutate series by replacing values with another from a list of categorical values.\nThis mutator reads all unique values from a singular column.\nAll values within a series will be replaced with a different random value from this column.\nIf the value column is provided as a string, and a path to a CSV file is provided to this\nfunction, then it is automatically assumed that the CSV file has a header row.\n\nArgs:\n    data_source: path to CSV file or data frame containing values\n    value_column: name or index of value column\n    encoding: character encoding of the CSV file\n    delimiter: column delimiter of the CSV file\n    rng: random number generator to use\n\nReturns:\n    function that mutates series by replacing values with a different one from a limited set of permitted values",
                        "comments": null,
                        "args": [
                            "data_source",
                            "value_column",
                            "encoding",
                            "delimiter",
                            "rng"
                        ]
                    },
                    {
                        "name": "with_permute",
                        "docstring": "Mutate series by permuting their contents.\nThis function ensures that rows are permuted in such a way that no value remains in the series\nit originated from.\n\nArgs:\n    rng: random number generator to use\n\nReturns:\n    function that mutates series by permuting their contents",
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "with_lowercase",
                        "docstring": "Mutate series by converting its contents to lowercase.\n\nArgs:\n    rng: random number generator to use\n\nReturns:\n    function that mutates series by converting its contents to lowercase",
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "with_uppercase",
                        "docstring": "Mutate series by converting its contents to uppercase.\n\nArgs:\n    rng: random number generator to use\n\nReturns:\n    function that mutates series by converting its contents to uppercase",
                        "comments": null,
                        "args": [
                            "rng"
                        ]
                    },
                    {
                        "name": "with_datetime_offset",
                        "docstring": "Mutate series by treating their contents it as datetime information and offsetting it by random amounts.\nThe delta and the unit specify which datetime field should be affected, where possible values are\n`d` and `days`, `h` and `hours`, `m` and `minutes`, `s` and `seconds`.\nThe datetime format must include the same format codes as specified in the `datetime` Python module for the\n`strftime` function.\nBy setting `prevent_wraparound` to `True`, this mutator will not apply a mutation if it will cause an\nunrelated field to change its value, e.g. when subtracting a day from July 1st, 2001.\n\nArgs:\n    max_delta: maximum amount of units to change by\n    unit: affected datetime field\n    dt_format: input and output datetime format\n    prevent_wraparound: `True` if unrelated fields should not be modified, `False` otherwise\n    rng: random number generator to use\n\nReturns:\n    function that mutates series by applying random date and time offsets to them",
                        "comments": null,
                        "args": [
                            "max_delta",
                            "unit",
                            "dt_format",
                            "prevent_wraparound",
                            "rng"
                        ]
                    },
                    {
                        "name": "with_generator",
                        "docstring": "Mutate series by replacing its content by appending, prepending or replacing it with data from another generator.\nA string to join generated data with when appending or prepending can be provided.\nUsing `{}` in the `join_with` parameter will cause it to be replaced by generated values.\nOnly the first occurrence of `{}` will be replaced.\n\nArgs:\n    generator: generator to source data from\n    mode: either append, prepend or replace\n    join_with: string to join present and generated data with\n    rng: random number generator to use\n\nReturns:\n    function that mutates series using another generator",
                        "comments": null,
                        "args": [
                            "generator",
                            "mode",
                            "join_with",
                            "rng"
                        ]
                    },
                    {
                        "name": "_new_regex_replacement_fn",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "srs"
                        ]
                    },
                    {
                        "name": "_parse_regex_flags",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "regex_flags_val"
                        ]
                    },
                    {
                        "name": "with_regex_replacement_table",
                        "docstring": "Mutate series by performing regex-based substitutions sourced from a table.\nThis table must contain a column with the regex patterns to look for and columns for each capture group to look up\nsubstitutions.\nWhen using regular capture groups, the columns must be numbered starting with 1.\nWhen using named capture groups, the columns must be named after the capture groups they are supposed to substitute.\n\nArgs:\n    data_source: path to CSV file or data frame containing regex-based substitutions\n    pattern_column: name of regex pattern column\n    flags_column: name of regex flag column\n    encoding: character encoding of the CSV file\n    delimiter: column delimiter of the CSV file\n    rng: random number generator to use\n\nReturns:\n    function that mutates series by performing regex-based substitutions",
                        "comments": null,
                        "args": [
                            "data_source",
                            "pattern_column",
                            "flags_column",
                            "encoding",
                            "delimiter",
                            "rng"
                        ]
                    },
                    {
                        "name": "with_repeat",
                        "docstring": "Mutate series by repeating its contents.\nBy default, selected entries will be duplicated and separated by a whitespace.\n\nArgs:\n    join_with: joining character to use, space by default\n    rng: random number generator to use\n\nReturns:\n    function that mutates series by repeating its contents",
                        "comments": null,
                        "args": [
                            "join_with",
                            "rng"
                        ]
                    },
                    {
                        "name": "_is_weighted_mutator_tuple",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "x"
                        ]
                    },
                    {
                        "name": "_is_weighted_mutator_tuple_list",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "x"
                        ]
                    },
                    {
                        "name": "with_group",
                        "docstring": "Mutate series by applying multiple mutators on it.\nThe mutators are applied in the order that they are provided in to this function.\nWhen providing a list of mutators, each row will be affected by each mutator with an equal probability.\nWhen providing a list of weighted mutators, each row will be affected by each mutator with the\nspecified probabilities.\nIf the probabilities do not sum up to 1, an additional mutator is added which does not modify input data.\n\nArgs:\n    mutator_lst: list of mutators or weighted mutators\n    rng: random number generator to use\n\nReturns:\n    function that mutates series using multiple mutually exclusive mutators at once",
                        "comments": null,
                        "args": [
                            "mutator_lst",
                            "rng"
                        ]
                    },
                    {
                        "name": "mutate_data_frame",
                        "docstring": "Mutate a data frame by applying several mutators on select columns.\nThis function takes a list which contains columns and mutators that are assigned to them.\nA column may be assigned a single mutator, a mutator with a probability, a list of mutators where each is applied\nwith the same probability, and a list of weighted mutators where each is applied with its assigned probability.\n\nArgs:\n    df_in: data frame to mutate\n    mutator_lst: list of columns with their mutator assignments\n\nReturns:\n    data frame with columns mutated as specified",
                        "comments": null,
                        "args": [
                            "df_in",
                            "mutator_lst"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "_PhoneticReplacementRule",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "KeyMutation",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "gecko/_dfbitlookup.py",
                "functions": [
                    {
                        "name": "with_capacity",
                        "docstring": "Construct a new data frame that is capable of storing the desired capacity of bits for the desired\nnumber of rows.\nAn index object can be supplied to align the data frame returned by this function with another\nPandas object.\n\nArgs:\n    rows: amount of rows\n    capacity: maximum amount of bits\n    index: index to align to\n\nReturns:\n    Data frame to set and test bits on across all of its rows",
                        "comments": null,
                        "args": [
                            "rows",
                            "capacity",
                            "index"
                        ]
                    },
                    {
                        "name": "_divmod",
                        "docstring": "Alternative for the built-in divmod function which returns ints instead of floats.\n\nArgs:\n    num: dividend\n    div: divisor\n\nReturns:\n    quotient and remainder as integers",
                        "comments": null,
                        "args": [
                            "num",
                            "div"
                        ]
                    },
                    {
                        "name": "set_index",
                        "docstring": "Set a bit on all selected rows at the specified index.\n\nArgs:\n    df: data frame to perform operation on\n    mask: series or list of booleans to select rows to set bit in with\n    idx: index of the bit to set",
                        "comments": null,
                        "args": [
                            "df",
                            "mask",
                            "idx"
                        ]
                    },
                    {
                        "name": "test_index",
                        "docstring": "Test a bit on all rows at the specified index.\n\nArgs:\n    df: data frame to perform operation on\n    idx: index of the bit to test\n\nReturns:\n    series of booleans representing rows where the selected bit is set",
                        "comments": null,
                        "args": [
                            "df",
                            "idx"
                        ]
                    },
                    {
                        "name": "any_set",
                        "docstring": "Test whether any bits are set for each row.\n\nArgs:\n    df: data frame to perform operation on\n\nReturns:\n    series of booleans representing rows where any bit is set",
                        "comments": null,
                        "args": [
                            "df"
                        ]
                    },
                    {
                        "name": "count_bits_per_index",
                        "docstring": "Count the bits set for each index across all rows.\nIf provided, this function will use the capacity argument as the upper bound for indices to count.\nIf not provided, it will be inferred from the number of columns in the data frame.\n\nArgs:\n    df: data frame to perform operation on\n    capacity: maximum amount of bits to test\n\nReturns:\n    list of tuples where the first int representing the index and the second int representing the number of set bits",
                        "comments": null,
                        "args": [
                            "df",
                            "capacity"
                        ]
                    },
                    {
                        "name": "count_bits_per_row",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "df",
                            "capacity"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "gecko/_cldr.py",
                "functions": [
                    {
                        "name": "uppercase_char_to_index",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "char"
                        ]
                    },
                    {
                        "name": "unescape_kb_char",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "char"
                        ]
                    },
                    {
                        "name": "decode_iso_kb_pos",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "iso_kb_pos_str"
                        ]
                    },
                    {
                        "name": "get_neighbor_kb_pos_for",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "kb_pos",
                            "max_row",
                            "max_col"
                        ]
                    }
                ],
                "classes": []
            }
        ],
        "test_cases": {
            "tests/test_cldr.py::test_uppercase_char_to_index": {
                "testid": "tests/test_cldr.py::test_uppercase_char_to_index",
                "result": "passed",
                "test_implementation": "def test_uppercase_char_to_index():\n    assert _cldr.uppercase_char_to_index(\"A\") == 0\n    assert _cldr.uppercase_char_to_index(\"B\") == 1  # and so on ...\n    assert _cldr.uppercase_char_to_index(\"Z\") == 25"
            },
            "tests/test_cldr.py::test_decode_iso_kb_pos": {
                "testid": "tests/test_cldr.py::test_decode_iso_kb_pos",
                "result": "passed",
                "test_implementation": "def test_decode_iso_kb_pos():\n    assert _cldr.decode_iso_kb_pos(\"A00\") == (0, 0)\n    assert _cldr.decode_iso_kb_pos(\"B00\") == (1, 0)\n    assert _cldr.decode_iso_kb_pos(\"A01\") == (0, 1)\n    assert _cldr.decode_iso_kb_pos(\"B15\") == (1, 15)"
            },
            "tests/test_cldr.py::test_unescape_kb_char": {
                "testid": "tests/test_cldr.py::test_unescape_kb_char",
                "result": "passed",
                "test_implementation": "def test_unescape_kb_char():\n    assert _cldr.unescape_kb_char(\"A\") == \"A\"  # stays the same\n    assert _cldr.unescape_kb_char(\"&amp;\") == \"&\"  # html entities should be decoded\n    assert _cldr.unescape_kb_char(\"\\\\u{22}\") == '\"'  # unicode entities should be decoded\n    # this case caused the char.startswith(\"\\\\u\") check because there's some funny\n    # stuff that happens when you run special chars through many encodings\n    assert _cldr.unescape_kb_char(\"\") == \"\""
            },
            "tests/test_cldr.py::test_get_neighbor_kb_pos_for[trbl-noshift]": {
                "testid": "tests/test_cldr.py::test_get_neighbor_kb_pos_for[trbl-noshift]",
                "result": "passed",
                "test_implementation": "def test_get_neighbor_kb_pos_for(kb_pos, max_row, max_col, expected_kb_pos_list):\n    actual_kb_pos_list = _cldr.get_neighbor_kb_pos_for(kb_pos, max_row, max_col)\n\n    assert len(actual_kb_pos_list) == len(expected_kb_pos_list)\n\n    for expected_kb_pos in expected_kb_pos_list:\n        assert expected_kb_pos in actual_kb_pos_list"
            },
            "tests/test_cldr.py::test_get_neighbor_kb_pos_for[trbl-shift]": {
                "testid": "tests/test_cldr.py::test_get_neighbor_kb_pos_for[trbl-shift]",
                "result": "passed",
                "test_implementation": "def test_get_neighbor_kb_pos_for(kb_pos, max_row, max_col, expected_kb_pos_list):\n    actual_kb_pos_list = _cldr.get_neighbor_kb_pos_for(kb_pos, max_row, max_col)\n\n    assert len(actual_kb_pos_list) == len(expected_kb_pos_list)\n\n    for expected_kb_pos in expected_kb_pos_list:\n        assert expected_kb_pos in actual_kb_pos_list"
            },
            "tests/test_cldr.py::test_get_neighbor_kb_pos_for[trb-noshift]": {
                "testid": "tests/test_cldr.py::test_get_neighbor_kb_pos_for[trb-noshift]",
                "result": "passed",
                "test_implementation": "def test_get_neighbor_kb_pos_for(kb_pos, max_row, max_col, expected_kb_pos_list):\n    actual_kb_pos_list = _cldr.get_neighbor_kb_pos_for(kb_pos, max_row, max_col)\n\n    assert len(actual_kb_pos_list) == len(expected_kb_pos_list)\n\n    for expected_kb_pos in expected_kb_pos_list:\n        assert expected_kb_pos in actual_kb_pos_list"
            },
            "tests/test_cldr.py::test_get_neighbor_kb_pos_for[rbl-noshift]": {
                "testid": "tests/test_cldr.py::test_get_neighbor_kb_pos_for[rbl-noshift]",
                "result": "passed",
                "test_implementation": "def test_get_neighbor_kb_pos_for(kb_pos, max_row, max_col, expected_kb_pos_list):\n    actual_kb_pos_list = _cldr.get_neighbor_kb_pos_for(kb_pos, max_row, max_col)\n\n    assert len(actual_kb_pos_list) == len(expected_kb_pos_list)\n\n    for expected_kb_pos in expected_kb_pos_list:\n        assert expected_kb_pos in actual_kb_pos_list"
            },
            "tests/test_cldr.py::test_get_neighbor_kb_pos_for[blt-noshift]": {
                "testid": "tests/test_cldr.py::test_get_neighbor_kb_pos_for[blt-noshift]",
                "result": "passed",
                "test_implementation": "def test_get_neighbor_kb_pos_for(kb_pos, max_row, max_col, expected_kb_pos_list):\n    actual_kb_pos_list = _cldr.get_neighbor_kb_pos_for(kb_pos, max_row, max_col)\n\n    assert len(actual_kb_pos_list) == len(expected_kb_pos_list)\n\n    for expected_kb_pos in expected_kb_pos_list:\n        assert expected_kb_pos in actual_kb_pos_list"
            },
            "tests/test_cldr.py::test_get_neighbor_kb_pos_for[ltb-noshift]": {
                "testid": "tests/test_cldr.py::test_get_neighbor_kb_pos_for[ltb-noshift]",
                "result": "passed",
                "test_implementation": "def test_get_neighbor_kb_pos_for(kb_pos, max_row, max_col, expected_kb_pos_list):\n    actual_kb_pos_list = _cldr.get_neighbor_kb_pos_for(kb_pos, max_row, max_col)\n\n    assert len(actual_kb_pos_list) == len(expected_kb_pos_list)\n\n    for expected_kb_pos in expected_kb_pos_list:\n        assert expected_kb_pos in actual_kb_pos_list"
            },
            "tests/test_dfbitlookup.py::test_with_capacity[1-1-1]": {
                "testid": "tests/test_dfbitlookup.py::test_with_capacity[1-1-1]",
                "result": "passed",
                "test_implementation": "def test_with_capacity(rows: int, capacity: int, expected_columns: int):\n    df = _dfbitlookup.with_capacity(rows, capacity)\n\n    assert len(df) == rows\n    assert len(df.columns) == expected_columns\n    assert (df == 0).all().all()  # double all() to cover all axes"
            },
            "tests/test_dfbitlookup.py::test_with_capacity[10-32-1]": {
                "testid": "tests/test_dfbitlookup.py::test_with_capacity[10-32-1]",
                "result": "passed",
                "test_implementation": "def test_with_capacity(rows: int, capacity: int, expected_columns: int):\n    df = _dfbitlookup.with_capacity(rows, capacity)\n\n    assert len(df) == rows\n    assert len(df.columns) == expected_columns\n    assert (df == 0).all().all()  # double all() to cover all axes"
            },
            "tests/test_dfbitlookup.py::test_with_capacity[10-64-1]": {
                "testid": "tests/test_dfbitlookup.py::test_with_capacity[10-64-1]",
                "result": "passed",
                "test_implementation": "def test_with_capacity(rows: int, capacity: int, expected_columns: int):\n    df = _dfbitlookup.with_capacity(rows, capacity)\n\n    assert len(df) == rows\n    assert len(df.columns) == expected_columns\n    assert (df == 0).all().all()  # double all() to cover all axes"
            },
            "tests/test_dfbitlookup.py::test_with_capacity[100-65-2]": {
                "testid": "tests/test_dfbitlookup.py::test_with_capacity[100-65-2]",
                "result": "passed",
                "test_implementation": "def test_with_capacity(rows: int, capacity: int, expected_columns: int):\n    df = _dfbitlookup.with_capacity(rows, capacity)\n\n    assert len(df) == rows\n    assert len(df.columns) == expected_columns\n    assert (df == 0).all().all()  # double all() to cover all axes"
            },
            "tests/test_dfbitlookup.py::test_with_capacity[100-128-2]": {
                "testid": "tests/test_dfbitlookup.py::test_with_capacity[100-128-2]",
                "result": "passed",
                "test_implementation": "def test_with_capacity(rows: int, capacity: int, expected_columns: int):\n    df = _dfbitlookup.with_capacity(rows, capacity)\n\n    assert len(df) == rows\n    assert len(df.columns) == expected_columns\n    assert (df == 0).all().all()  # double all() to cover all axes"
            },
            "tests/test_dfbitlookup.py::test_with_capacity[100-129-3]": {
                "testid": "tests/test_dfbitlookup.py::test_with_capacity[100-129-3]",
                "result": "passed",
                "test_implementation": "def test_with_capacity(rows: int, capacity: int, expected_columns: int):\n    df = _dfbitlookup.with_capacity(rows, capacity)\n\n    assert len(df) == rows\n    assert len(df.columns) == expected_columns\n    assert (df == 0).all().all()  # double all() to cover all axes"
            },
            "tests/test_dfbitlookup.py::test_with_capacity_raise_rows_too_low": {
                "testid": "tests/test_dfbitlookup.py::test_with_capacity_raise_rows_too_low",
                "result": "passed",
                "test_implementation": "def test_with_capacity_raise_rows_too_low():\n    with pytest.raises(ValueError) as e:\n        _dfbitlookup.with_capacity(0, 1)\n\n    assert str(e.value) == \"number of rows must be positive, is 0\""
            },
            "tests/test_dfbitlookup.py::test_with_capacity_raise_capacity_too_low": {
                "testid": "tests/test_dfbitlookup.py::test_with_capacity_raise_capacity_too_low",
                "result": "passed",
                "test_implementation": "def test_with_capacity_raise_capacity_too_low():\n    with pytest.raises(ValueError) as e:\n        _dfbitlookup.with_capacity(1, 0)\n\n    assert str(e.value) == \"capacity must be positive, is 0\""
            },
            "tests/test_dfbitlookup.py::test_set_test_index[100-64-mask0-63]": {
                "testid": "tests/test_dfbitlookup.py::test_set_test_index[100-64-mask0-63]",
                "result": "passed",
                "test_implementation": "def test_set_test_index(rows: int, capacity: int, mask: pd.Series, index: int):\n    df = _dfbitlookup.with_capacity(rows, capacity)\n    _dfbitlookup.set_index(df, mask, index)\n\n    assert (_dfbitlookup.test_index(df, index) == mask).all()"
            },
            "tests/test_dfbitlookup.py::test_set_test_index[100-128-mask1-64]": {
                "testid": "tests/test_dfbitlookup.py::test_set_test_index[100-128-mask1-64]",
                "result": "passed",
                "test_implementation": "def test_set_test_index(rows: int, capacity: int, mask: pd.Series, index: int):\n    df = _dfbitlookup.with_capacity(rows, capacity)\n    _dfbitlookup.set_index(df, mask, index)\n\n    assert (_dfbitlookup.test_index(df, index) == mask).all()"
            },
            "tests/test_dfbitlookup.py::test_count_bits_per_row": {
                "testid": "tests/test_dfbitlookup.py::test_count_bits_per_row",
                "result": "passed",
                "test_implementation": "def test_count_bits_per_row():\n    df = pd.DataFrame([0b1001, 0b0101, 0, 0b1101], dtype=np.uint64)\n\n    # [0] =>  1  0  0  1  => 2\n    # [1] =>  1  0  1  0  => 2\n    # [2] =>  0  0  0  0  => 0\n    # [3] =>  1  0  1  1  => 3\n\n    expected = [2, 2, 0, 3]\n    assert (_dfbitlookup.count_bits_per_row(df) == expected).all()"
            },
            "tests/test_dfbitlookup.py::test_count_bits_per_index": {
                "testid": "tests/test_dfbitlookup.py::test_count_bits_per_index",
                "result": "passed",
                "test_implementation": "def test_count_bits_per_index():\n    df = pd.DataFrame([0b1001, 0b0101, 0b1101], dtype=np.uint64)\n\n    # [0] =>  1  0  0  1\n    # [1] =>  1  0  1  0\n    # [2] =>  1  0  1  1\n    #        [a][b][c][d]  =>  [a] = 3, [b] = 0, [c] = 2, [d] = 2\n\n    expected = [(0, 3), (1, 0), (2, 2), (3, 2)]\n    assert _dfbitlookup.count_bits_per_index(df, 4) == expected"
            },
            "tests/test_dfbitlookup.py::test_count_bits_per_index_infer_capacity": {
                "testid": "tests/test_dfbitlookup.py::test_count_bits_per_index_infer_capacity",
                "result": "passed",
                "test_implementation": "def test_count_bits_per_index_infer_capacity():\n    df = pd.DataFrame([0b1001, 0b0101, 0b1101], dtype=np.uint64)\n\n    # indices 4-63 should be zero\n    expected = [(0, 3), (1, 0), (2, 2), (3, 2)] + [(idx, 0) for idx in range(4, 64)]\n    assert _dfbitlookup.count_bits_per_index(df) == expected"
            },
            "tests/test_dfbitlookup.py::test_count_bits_per_index_raise_capacity_too_low": {
                "testid": "tests/test_dfbitlookup.py::test_count_bits_per_index_raise_capacity_too_low",
                "result": "passed",
                "test_implementation": "def test_count_bits_per_index_raise_capacity_too_low():\n    df = pd.DataFrame([0b1001, 0b0101, 0b1101], dtype=np.uint64)\n\n    with pytest.raises(ValueError) as e:\n        _ = _dfbitlookup.count_bits_per_index(df, 0)\n\n    assert str(e.value) == \"capacity must be positive, is 0\""
            },
            "tests/test_dfbitlookup.py::test_count_bits_per_index_raise_capacity_too_high": {
                "testid": "tests/test_dfbitlookup.py::test_count_bits_per_index_raise_capacity_too_high",
                "result": "passed",
                "test_implementation": "def test_count_bits_per_index_raise_capacity_too_high():\n    df = pd.DataFrame([0b1001, 0b0101, 0b1101], dtype=np.uint64)\n\n    with pytest.raises(ValueError) as e:\n        _ = _dfbitlookup.count_bits_per_index(df, 65)\n\n    assert str(e.value) == \"capacity must not be higher than 64, is 65\""
            },
            "tests/test_dfbitlookup.py::test_no_raise_on_test_int_idx_63[py-int-63]": {
                "testid": "tests/test_dfbitlookup.py::test_no_raise_on_test_int_idx_63[py-int-63]",
                "result": "passed",
                "test_implementation": "def test_no_raise_on_test_int_idx_63(index):\n    df = _dfbitlookup.with_capacity(1, 128)\n    df.loc[:, :] |= 1 << 63\n    _ = _dfbitlookup.test_index(df, index)"
            },
            "tests/test_dfbitlookup.py::test_no_raise_on_test_int_idx_63[np-int64-63]": {
                "testid": "tests/test_dfbitlookup.py::test_no_raise_on_test_int_idx_63[np-int64-63]",
                "result": "passed",
                "test_implementation": "def test_no_raise_on_test_int_idx_63(index):\n    df = _dfbitlookup.with_capacity(1, 128)\n    df.loc[:, :] |= 1 << 63\n    _ = _dfbitlookup.test_index(df, index)"
            },
            "tests/test_dfbitlookup.py::test_no_raise_on_test_int_idx_63[np-uint64-63]": {
                "testid": "tests/test_dfbitlookup.py::test_no_raise_on_test_int_idx_63[np-uint64-63]",
                "result": "passed",
                "test_implementation": "def test_no_raise_on_test_int_idx_63(index):\n    df = _dfbitlookup.with_capacity(1, 128)\n    df.loc[:, :] |= 1 << 63\n    _ = _dfbitlookup.test_index(df, index)"
            },
            "tests/test_dfbitlookup.py::test_no_raise_on_test_int_idx_63[py-int-127]": {
                "testid": "tests/test_dfbitlookup.py::test_no_raise_on_test_int_idx_63[py-int-127]",
                "result": "passed",
                "test_implementation": "def test_no_raise_on_test_int_idx_63(index):\n    df = _dfbitlookup.with_capacity(1, 128)\n    df.loc[:, :] |= 1 << 63\n    _ = _dfbitlookup.test_index(df, index)"
            },
            "tests/test_dfbitlookup.py::test_no_raise_on_test_int_idx_63[np-int64-127]": {
                "testid": "tests/test_dfbitlookup.py::test_no_raise_on_test_int_idx_63[np-int64-127]",
                "result": "passed",
                "test_implementation": "def test_no_raise_on_test_int_idx_63(index):\n    df = _dfbitlookup.with_capacity(1, 128)\n    df.loc[:, :] |= 1 << 63\n    _ = _dfbitlookup.test_index(df, index)"
            },
            "tests/test_dfbitlookup.py::test_no_raise_on_test_int_idx_63[np-uint64-127]": {
                "testid": "tests/test_dfbitlookup.py::test_no_raise_on_test_int_idx_63[np-uint64-127]",
                "result": "passed",
                "test_implementation": "def test_no_raise_on_test_int_idx_63(index):\n    df = _dfbitlookup.with_capacity(1, 128)\n    df.loc[:, :] |= 1 << 63\n    _ = _dfbitlookup.test_index(df, index)"
            },
            "tests/test_dfbitlookup.py::test_no_raise_on_set_int_idx_63[py-int-63]": {
                "testid": "tests/test_dfbitlookup.py::test_no_raise_on_set_int_idx_63[py-int-63]",
                "result": "passed",
                "test_implementation": "def test_no_raise_on_set_int_idx_63(index):\n    df = _dfbitlookup.with_capacity(1, 128)\n    _ = _dfbitlookup.set_index(df, [True], index)"
            },
            "tests/test_dfbitlookup.py::test_no_raise_on_set_int_idx_63[np-int64-63]": {
                "testid": "tests/test_dfbitlookup.py::test_no_raise_on_set_int_idx_63[np-int64-63]",
                "result": "passed",
                "test_implementation": "def test_no_raise_on_set_int_idx_63(index):\n    df = _dfbitlookup.with_capacity(1, 128)\n    _ = _dfbitlookup.set_index(df, [True], index)"
            },
            "tests/test_dfbitlookup.py::test_no_raise_on_set_int_idx_63[np-uint64-63]": {
                "testid": "tests/test_dfbitlookup.py::test_no_raise_on_set_int_idx_63[np-uint64-63]",
                "result": "passed",
                "test_implementation": "def test_no_raise_on_set_int_idx_63(index):\n    df = _dfbitlookup.with_capacity(1, 128)\n    _ = _dfbitlookup.set_index(df, [True], index)"
            },
            "tests/test_dfbitlookup.py::test_no_raise_on_set_int_idx_63[py-int-127]": {
                "testid": "tests/test_dfbitlookup.py::test_no_raise_on_set_int_idx_63[py-int-127]",
                "result": "passed",
                "test_implementation": "def test_no_raise_on_set_int_idx_63(index):\n    df = _dfbitlookup.with_capacity(1, 128)\n    _ = _dfbitlookup.set_index(df, [True], index)"
            },
            "tests/test_dfbitlookup.py::test_no_raise_on_set_int_idx_63[np-int64-127]": {
                "testid": "tests/test_dfbitlookup.py::test_no_raise_on_set_int_idx_63[np-int64-127]",
                "result": "passed",
                "test_implementation": "def test_no_raise_on_set_int_idx_63(index):\n    df = _dfbitlookup.with_capacity(1, 128)\n    _ = _dfbitlookup.set_index(df, [True], index)"
            },
            "tests/test_dfbitlookup.py::test_no_raise_on_set_int_idx_63[np-uint64-127]": {
                "testid": "tests/test_dfbitlookup.py::test_no_raise_on_set_int_idx_63[np-uint64-127]",
                "result": "passed",
                "test_implementation": "def test_no_raise_on_set_int_idx_63(index):\n    df = _dfbitlookup.with_capacity(1, 128)\n    _ = _dfbitlookup.set_index(df, [True], index)"
            },
            "tests/test_dfbitlookup.py::test_no_raise_on_count_int_idx_63[py-int-63]": {
                "testid": "tests/test_dfbitlookup.py::test_no_raise_on_count_int_idx_63[py-int-63]",
                "result": "passed",
                "test_implementation": "def test_no_raise_on_count_int_idx_63(index):\n    df = _dfbitlookup.with_capacity(1, 128)\n    _ = _dfbitlookup.count_bits_per_index(df, index + 1)"
            },
            "tests/test_dfbitlookup.py::test_no_raise_on_count_int_idx_63[np-int64-63]": {
                "testid": "tests/test_dfbitlookup.py::test_no_raise_on_count_int_idx_63[np-int64-63]",
                "result": "passed",
                "test_implementation": "def test_no_raise_on_count_int_idx_63(index):\n    df = _dfbitlookup.with_capacity(1, 128)\n    _ = _dfbitlookup.count_bits_per_index(df, index + 1)"
            },
            "tests/test_dfbitlookup.py::test_no_raise_on_count_int_idx_63[np-uint64-63]": {
                "testid": "tests/test_dfbitlookup.py::test_no_raise_on_count_int_idx_63[np-uint64-63]",
                "result": "passed",
                "test_implementation": "def test_no_raise_on_count_int_idx_63(index):\n    df = _dfbitlookup.with_capacity(1, 128)\n    _ = _dfbitlookup.count_bits_per_index(df, index + 1)"
            },
            "tests/test_dfbitlookup.py::test_no_raise_on_count_int_idx_63[py-int-127]": {
                "testid": "tests/test_dfbitlookup.py::test_no_raise_on_count_int_idx_63[py-int-127]",
                "result": "passed",
                "test_implementation": "def test_no_raise_on_count_int_idx_63(index):\n    df = _dfbitlookup.with_capacity(1, 128)\n    _ = _dfbitlookup.count_bits_per_index(df, index + 1)"
            },
            "tests/test_dfbitlookup.py::test_no_raise_on_count_int_idx_63[np-int64-127]": {
                "testid": "tests/test_dfbitlookup.py::test_no_raise_on_count_int_idx_63[np-int64-127]",
                "result": "passed",
                "test_implementation": "def test_no_raise_on_count_int_idx_63(index):\n    df = _dfbitlookup.with_capacity(1, 128)\n    _ = _dfbitlookup.count_bits_per_index(df, index + 1)"
            },
            "tests/test_dfbitlookup.py::test_no_raise_on_count_int_idx_63[np-uint64-127]": {
                "testid": "tests/test_dfbitlookup.py::test_no_raise_on_count_int_idx_63[np-uint64-127]",
                "result": "passed",
                "test_implementation": "def test_no_raise_on_count_int_idx_63(index):\n    df = _dfbitlookup.with_capacity(1, 128)\n    _ = _dfbitlookup.count_bits_per_index(df, index + 1)"
            },
            "tests/test_generator.py::test_from_function": {
                "testid": "tests/test_generator.py::test_from_function",
                "result": "passed",
                "test_implementation": "def test_from_function():\n    flag = False\n\n    def _generator() -> str:\n        nonlocal flag\n        flag = not flag\n\n        return \"foo\" if flag else \"bar\"\n\n    generate_foobar = generator.from_function(_generator)\n    foobar_list = generate_foobar(4)\n\n    assert len(foobar_list) == 1\n    assert foobar_list[0].equals(pd.Series([\"foo\", \"bar\", \"foo\", \"bar\"]))"
            },
            "tests/test_generator.py::test_from_uniform_distribution": {
                "testid": "tests/test_generator.py::test_from_uniform_distribution",
                "result": "passed",
                "test_implementation": "def test_from_uniform_distribution(rng):\n    generate_uniform = generator.from_uniform_distribution(1, 10, rng=rng)\n    number_list = generate_uniform(1000)\n\n    assert len(number_list) == 1\n    assert len(number_list[0]) == 1000\n\n    numbers_as_floats = np.array([float(n) for n in number_list[0]], dtype=float)\n\n    assert (numbers_as_floats >= 1).all()\n    assert (numbers_as_floats <= 10).all()"
            },
            "tests/test_generator.py::test_from_normal_distribution": {
                "testid": "tests/test_generator.py::test_from_normal_distribution",
                "result": "passed",
                "test_implementation": "def test_from_normal_distribution(rng):\n    generate_normal = generator.from_normal_distribution(0, 1, rng=rng)\n    number_list = generate_normal(1000)\n\n    # bound checks don't really make sense here ...\n    assert len(number_list) == 1\n    assert len(number_list[0]) == 1000"
            },
            "tests/test_generator.py::test_from_frequency_table_no_header": {
                "testid": "tests/test_generator.py::test_from_frequency_table_no_header",
                "result": "passed",
                "test_implementation": "def test_from_frequency_table_no_header(rng):\n    generate_tab = generator.from_frequency_table(\n        get_asset_path(\"freq_table_no_header.csv\"),\n        rng=rng,\n    )\n\n    srs = generate_tab(100)[0]\n\n    assert (srs == \"foo\").any()\n    assert (srs == \"bar\").any()"
            },
            "tests/test_generator.py::test_from_frequency_table_with_header": {
                "testid": "tests/test_generator.py::test_from_frequency_table_with_header",
                "result": "passed",
                "test_implementation": "def test_from_frequency_table_with_header(rng):\n    generate_tab = generator.from_frequency_table(\n        get_asset_path(\"freq_table_header.csv\"),\n        rng=rng,\n        value_column=\"value\",\n        freq_column=\"freq\",\n    )\n\n    srs = generate_tab(100)[0]\n\n    assert (srs == \"foo\").any()\n    assert (srs == \"bar\").any()"
            },
            "tests/test_generator.py::test_from_frequency_table_tsv": {
                "testid": "tests/test_generator.py::test_from_frequency_table_tsv",
                "result": "passed",
                "test_implementation": "def test_from_frequency_table_tsv(rng):\n    generate_tab = generator.from_frequency_table(get_asset_path(\"freq_table_no_header.tsv\"), rng=rng, delimiter=\"\\t\")\n\n    srs = generate_tab(100)[0]\n\n    assert (srs == \"foo\").any()\n    assert (srs == \"bar\").any()"
            },
            "tests/test_generator.py::test_from_frequency_table": {
                "testid": "tests/test_generator.py::test_from_frequency_table",
                "result": "passed",
                "test_implementation": "def test_from_frequency_table(rng):\n    gen_fruits = generator.from_frequency_table(\n        get_asset_path(\"freq-fruits.csv\"),\n        value_column=\"fruit\",\n        freq_column=\"count\",\n        rng=rng,\n    )\n\n    list_of_srs = gen_fruits(100)\n    assert len(list_of_srs) == 1\n\n    srs = list_of_srs[0]\n    assert len(srs) == 100\n    assert sorted(srs.unique()) == [\"apple\", \"banana\", \"orange\"]"
            },
            "tests/test_generator.py::test_from_multicolumn_frequency_table": {
                "testid": "tests/test_generator.py::test_from_multicolumn_frequency_table",
                "result": "passed",
                "test_implementation": "def test_from_multicolumn_frequency_table(rng):\n    gen_fruit_types = generator.from_multicolumn_frequency_table(\n        get_asset_path(\"freq-fruits-types.csv\"),\n        value_columns=[\"fruit\", \"type\"],\n        freq_column=\"count\",\n        rng=rng,\n    )\n\n    list_of_srs = gen_fruit_types(100)\n    assert len(list_of_srs) == 2\n\n    srs_fruit, srs_type = list_of_srs\n    assert len(srs_fruit) == 100\n    assert len(srs_type) == 100\n\n    for i in range(100):\n        fruit = srs_fruit.iloc[i]\n        fruit_type = srs_type.iloc[i]\n\n        if fruit == \"apple\":\n            assert fruit_type in (\"braeburn\", \"elstar\")\n        elif fruit == \"banana\":\n            assert fruit_type in (\"cavendish\", \"plantain\")\n        elif fruit == \"orange\":\n            assert fruit_type in (\"clementine\", \"mandarin\")\n        else:\n            raise AssertionError(f\"unknown fruit: `{fruit}`\")"
            },
            "tests/test_generator.py::test_from_datetime_range": {
                "testid": "tests/test_generator.py::test_from_datetime_range",
                "result": "passed",
                "test_implementation": "def test_from_datetime_range(rng):\n    gen_datetime = generator.from_datetime_range(\"1920-01-01\", \"2020-01-01\", \"%d.%m.%Y\", \"days\", rng=rng)\n\n    (dt_srs,) = gen_datetime(100)\n    assert dt_srs.str.fullmatch(r\"\\d{2}\\.\\d{2}\\.\\d{4}\").all()"
            },
            "tests/test_generator.py::test_from_datetime_range_invalid_start_datetime": {
                "testid": "tests/test_generator.py::test_from_datetime_range_invalid_start_datetime",
                "result": "passed",
                "test_implementation": "def test_from_datetime_range_invalid_start_datetime(rng):\n    with pytest.raises(ValueError) as e:\n        generator.from_datetime_range(\"foobar\", \"2020-01-01\", \"%d.%m.%Y\", \"days\")\n\n    assert str(e.value).startswith(\"Error parsing datetime string\")"
            },
            "tests/test_generator.py::test_from_datetime_range_invalid_end_datetime": {
                "testid": "tests/test_generator.py::test_from_datetime_range_invalid_end_datetime",
                "result": "passed",
                "test_implementation": "def test_from_datetime_range_invalid_end_datetime(rng):\n    with pytest.raises(ValueError) as e:\n        generator.from_datetime_range(\"1920-01-01\", \"foobar\", \"%d.%m.%Y\", \"days\")\n\n    assert str(e.value).startswith(\"Error parsing datetime string\")"
            },
            "tests/test_generator.py::test_from_datetime_range_all_units[d]": {
                "testid": "tests/test_generator.py::test_from_datetime_range_all_units[d]",
                "result": "passed",
                "test_implementation": "def test_from_datetime_range_all_units(rng, unit):\n    gen_datetime = generator.from_datetime_range(\"1920-01-01\", \"2020-01-01\", \"%d.%m.%Y %H:%M:%S\", unit, rng=rng)\n\n    (dt_srs,) = gen_datetime(100)\n\n    df_matches = dt_srs.str.extract(r\"(?P<date>\\d{2}.\\d{2}.\\d{4}) (?P<hour>\\d{2}):(?P<minute>\\d{2}):(?P<second>\\d{2})\")\n\n    assert df_matches[\"date\"].notna().all()\n\n    hour_not_all_zero = unit in (\"h\", \"hours\", \"m\", \"minutes\", \"s\", \"seconds\")\n    minute_not_all_zero = unit in (\"m\", \"minutes\", \"s\", \"seconds\")\n    second_not_all_zero = unit in (\"s\", \"seconds\")\n\n    assert (not (df_matches[\"hour\"] == \"00\").all()) == hour_not_all_zero\n    assert (not (df_matches[\"minute\"] == \"00\").all()) == minute_not_all_zero\n    assert (not (df_matches[\"second\"] == \"00\").all()) == second_not_all_zero"
            },
            "tests/test_generator.py::test_from_datetime_range_all_units[days]": {
                "testid": "tests/test_generator.py::test_from_datetime_range_all_units[days]",
                "result": "passed",
                "test_implementation": "def test_from_datetime_range_all_units(rng, unit):\n    gen_datetime = generator.from_datetime_range(\"1920-01-01\", \"2020-01-01\", \"%d.%m.%Y %H:%M:%S\", unit, rng=rng)\n\n    (dt_srs,) = gen_datetime(100)\n\n    df_matches = dt_srs.str.extract(r\"(?P<date>\\d{2}.\\d{2}.\\d{4}) (?P<hour>\\d{2}):(?P<minute>\\d{2}):(?P<second>\\d{2})\")\n\n    assert df_matches[\"date\"].notna().all()\n\n    hour_not_all_zero = unit in (\"h\", \"hours\", \"m\", \"minutes\", \"s\", \"seconds\")\n    minute_not_all_zero = unit in (\"m\", \"minutes\", \"s\", \"seconds\")\n    second_not_all_zero = unit in (\"s\", \"seconds\")\n\n    assert (not (df_matches[\"hour\"] == \"00\").all()) == hour_not_all_zero\n    assert (not (df_matches[\"minute\"] == \"00\").all()) == minute_not_all_zero\n    assert (not (df_matches[\"second\"] == \"00\").all()) == second_not_all_zero"
            },
            "tests/test_generator.py::test_from_datetime_range_all_units[h]": {
                "testid": "tests/test_generator.py::test_from_datetime_range_all_units[h]",
                "result": "passed",
                "test_implementation": "def test_from_datetime_range_all_units(rng, unit):\n    gen_datetime = generator.from_datetime_range(\"1920-01-01\", \"2020-01-01\", \"%d.%m.%Y %H:%M:%S\", unit, rng=rng)\n\n    (dt_srs,) = gen_datetime(100)\n\n    df_matches = dt_srs.str.extract(r\"(?P<date>\\d{2}.\\d{2}.\\d{4}) (?P<hour>\\d{2}):(?P<minute>\\d{2}):(?P<second>\\d{2})\")\n\n    assert df_matches[\"date\"].notna().all()\n\n    hour_not_all_zero = unit in (\"h\", \"hours\", \"m\", \"minutes\", \"s\", \"seconds\")\n    minute_not_all_zero = unit in (\"m\", \"minutes\", \"s\", \"seconds\")\n    second_not_all_zero = unit in (\"s\", \"seconds\")\n\n    assert (not (df_matches[\"hour\"] == \"00\").all()) == hour_not_all_zero\n    assert (not (df_matches[\"minute\"] == \"00\").all()) == minute_not_all_zero\n    assert (not (df_matches[\"second\"] == \"00\").all()) == second_not_all_zero"
            },
            "tests/test_generator.py::test_from_datetime_range_all_units[hours]": {
                "testid": "tests/test_generator.py::test_from_datetime_range_all_units[hours]",
                "result": "passed",
                "test_implementation": "def test_from_datetime_range_all_units(rng, unit):\n    gen_datetime = generator.from_datetime_range(\"1920-01-01\", \"2020-01-01\", \"%d.%m.%Y %H:%M:%S\", unit, rng=rng)\n\n    (dt_srs,) = gen_datetime(100)\n\n    df_matches = dt_srs.str.extract(r\"(?P<date>\\d{2}.\\d{2}.\\d{4}) (?P<hour>\\d{2}):(?P<minute>\\d{2}):(?P<second>\\d{2})\")\n\n    assert df_matches[\"date\"].notna().all()\n\n    hour_not_all_zero = unit in (\"h\", \"hours\", \"m\", \"minutes\", \"s\", \"seconds\")\n    minute_not_all_zero = unit in (\"m\", \"minutes\", \"s\", \"seconds\")\n    second_not_all_zero = unit in (\"s\", \"seconds\")\n\n    assert (not (df_matches[\"hour\"] == \"00\").all()) == hour_not_all_zero\n    assert (not (df_matches[\"minute\"] == \"00\").all()) == minute_not_all_zero\n    assert (not (df_matches[\"second\"] == \"00\").all()) == second_not_all_zero"
            },
            "tests/test_generator.py::test_from_datetime_range_all_units[m]": {
                "testid": "tests/test_generator.py::test_from_datetime_range_all_units[m]",
                "result": "passed",
                "test_implementation": "def test_from_datetime_range_all_units(rng, unit):\n    gen_datetime = generator.from_datetime_range(\"1920-01-01\", \"2020-01-01\", \"%d.%m.%Y %H:%M:%S\", unit, rng=rng)\n\n    (dt_srs,) = gen_datetime(100)\n\n    df_matches = dt_srs.str.extract(r\"(?P<date>\\d{2}.\\d{2}.\\d{4}) (?P<hour>\\d{2}):(?P<minute>\\d{2}):(?P<second>\\d{2})\")\n\n    assert df_matches[\"date\"].notna().all()\n\n    hour_not_all_zero = unit in (\"h\", \"hours\", \"m\", \"minutes\", \"s\", \"seconds\")\n    minute_not_all_zero = unit in (\"m\", \"minutes\", \"s\", \"seconds\")\n    second_not_all_zero = unit in (\"s\", \"seconds\")\n\n    assert (not (df_matches[\"hour\"] == \"00\").all()) == hour_not_all_zero\n    assert (not (df_matches[\"minute\"] == \"00\").all()) == minute_not_all_zero\n    assert (not (df_matches[\"second\"] == \"00\").all()) == second_not_all_zero"
            },
            "tests/test_generator.py::test_from_datetime_range_all_units[minutes]": {
                "testid": "tests/test_generator.py::test_from_datetime_range_all_units[minutes]",
                "result": "passed",
                "test_implementation": "def test_from_datetime_range_all_units(rng, unit):\n    gen_datetime = generator.from_datetime_range(\"1920-01-01\", \"2020-01-01\", \"%d.%m.%Y %H:%M:%S\", unit, rng=rng)\n\n    (dt_srs,) = gen_datetime(100)\n\n    df_matches = dt_srs.str.extract(r\"(?P<date>\\d{2}.\\d{2}.\\d{4}) (?P<hour>\\d{2}):(?P<minute>\\d{2}):(?P<second>\\d{2})\")\n\n    assert df_matches[\"date\"].notna().all()\n\n    hour_not_all_zero = unit in (\"h\", \"hours\", \"m\", \"minutes\", \"s\", \"seconds\")\n    minute_not_all_zero = unit in (\"m\", \"minutes\", \"s\", \"seconds\")\n    second_not_all_zero = unit in (\"s\", \"seconds\")\n\n    assert (not (df_matches[\"hour\"] == \"00\").all()) == hour_not_all_zero\n    assert (not (df_matches[\"minute\"] == \"00\").all()) == minute_not_all_zero\n    assert (not (df_matches[\"second\"] == \"00\").all()) == second_not_all_zero"
            },
            "tests/test_generator.py::test_from_datetime_range_all_units[s]": {
                "testid": "tests/test_generator.py::test_from_datetime_range_all_units[s]",
                "result": "passed",
                "test_implementation": "def test_from_datetime_range_all_units(rng, unit):\n    gen_datetime = generator.from_datetime_range(\"1920-01-01\", \"2020-01-01\", \"%d.%m.%Y %H:%M:%S\", unit, rng=rng)\n\n    (dt_srs,) = gen_datetime(100)\n\n    df_matches = dt_srs.str.extract(r\"(?P<date>\\d{2}.\\d{2}.\\d{4}) (?P<hour>\\d{2}):(?P<minute>\\d{2}):(?P<second>\\d{2})\")\n\n    assert df_matches[\"date\"].notna().all()\n\n    hour_not_all_zero = unit in (\"h\", \"hours\", \"m\", \"minutes\", \"s\", \"seconds\")\n    minute_not_all_zero = unit in (\"m\", \"minutes\", \"s\", \"seconds\")\n    second_not_all_zero = unit in (\"s\", \"seconds\")\n\n    assert (not (df_matches[\"hour\"] == \"00\").all()) == hour_not_all_zero\n    assert (not (df_matches[\"minute\"] == \"00\").all()) == minute_not_all_zero\n    assert (not (df_matches[\"second\"] == \"00\").all()) == second_not_all_zero"
            },
            "tests/test_generator.py::test_from_datetime_range_all_units[seconds]": {
                "testid": "tests/test_generator.py::test_from_datetime_range_all_units[seconds]",
                "result": "passed",
                "test_implementation": "def test_from_datetime_range_all_units(rng, unit):\n    gen_datetime = generator.from_datetime_range(\"1920-01-01\", \"2020-01-01\", \"%d.%m.%Y %H:%M:%S\", unit, rng=rng)\n\n    (dt_srs,) = gen_datetime(100)\n\n    df_matches = dt_srs.str.extract(r\"(?P<date>\\d{2}.\\d{2}.\\d{4}) (?P<hour>\\d{2}):(?P<minute>\\d{2}):(?P<second>\\d{2})\")\n\n    assert df_matches[\"date\"].notna().all()\n\n    hour_not_all_zero = unit in (\"h\", \"hours\", \"m\", \"minutes\", \"s\", \"seconds\")\n    minute_not_all_zero = unit in (\"m\", \"minutes\", \"s\", \"seconds\")\n    second_not_all_zero = unit in (\"s\", \"seconds\")\n\n    assert (not (df_matches[\"hour\"] == \"00\").all()) == hour_not_all_zero\n    assert (not (df_matches[\"minute\"] == \"00\").all()) == minute_not_all_zero\n    assert (not (df_matches[\"second\"] == \"00\").all()) == second_not_all_zero"
            },
            "tests/test_generator.py::test_from_datetime_range_end_before_start": {
                "testid": "tests/test_generator.py::test_from_datetime_range_end_before_start",
                "result": "passed",
                "test_implementation": "def test_from_datetime_range_end_before_start(rng):\n    with pytest.raises(ValueError) as e:\n        generator.from_datetime_range(\"2020-01-01\", \"1920-01-01\", \"%d.%m.%Y\", \"days\", rng=rng)\n\n    assert str(e.value) == \"start datetime `2020-01-01` is greater than end datetime `1920-01-01`\""
            },
            "tests/test_generator.py::test_to_dataframe_error_empty_list": {
                "testid": "tests/test_generator.py::test_to_dataframe_error_empty_list",
                "result": "passed",
                "test_implementation": "def test_to_dataframe_error_empty_list():\n    with pytest.raises(ValueError) as e:\n        generator.to_data_frame([], 1000)\n\n    assert str(e.value) == \"generator list may not be empty\""
            },
            "tests/test_generator.py::test_to_dataframe_error_count_not_positive": {
                "testid": "tests/test_generator.py::test_to_dataframe_error_count_not_positive",
                "result": "passed",
                "test_implementation": "def test_to_dataframe_error_count_not_positive():\n    with pytest.raises(ValueError) as e:\n        generator.to_data_frame(\n            [(\"foo\", generator.from_uniform_distribution())],\n            0,\n        )\n\n    assert str(e.value) == \"amount of rows must be positive, is 0\""
            },
            "tests/test_generator.py::test_to_dataframe": {
                "testid": "tests/test_generator.py::test_to_dataframe",
                "result": "passed",
                "test_implementation": "def test_to_dataframe(rng):\n    gen_fruit_types = generator.from_multicolumn_frequency_table(\n        get_asset_path(\"freq-fruits-types.csv\"),\n        value_columns=[\"fruit\", \"type\"],\n        freq_column=\"count\",\n        rng=rng,\n    )\n\n    gen_numbers = generator.from_uniform_distribution(\n        rng=rng,\n    )\n\n    df_row_count = 1000\n    df = generator.to_data_frame(\n        [\n            ((\"fruit\", \"type\"), gen_fruit_types),\n            (\"num\", gen_numbers),\n        ],\n        df_row_count,\n    )\n\n    assert len(df) == df_row_count\n\n    for col in [\"fruit\", \"type\", \"num\"]:\n        assert col in df.columns"
            },
            "tests/test_generator.py::test_from_frequency_table_nan": {
                "testid": "tests/test_generator.py::test_from_frequency_table_nan",
                "result": "passed",
                "test_implementation": "def test_from_frequency_table_nan(tmp_path, rng):\n    freq_file_path = tmp_path / \"freq.csv\"\n    freq_file_path.write_text('value,freq\\n\"\",1\\n\"foobar\",1\\n')\n\n    gen_freq_table = generator.from_frequency_table(\n        freq_file_path,\n        value_column=\"value\",\n        freq_column=\"freq\",\n        rng=rng,\n    )\n\n    (srs,) = gen_freq_table(100)\n\n    assert pd.notna(srs).all()"
            },
            "tests/test_generator.py::test_from_frequency_table_df": {
                "testid": "tests/test_generator.py::test_from_frequency_table_df",
                "result": "passed",
                "test_implementation": "def test_from_frequency_table_df(rng):\n    df = pd.DataFrame.from_dict({\"freq\": [10, 5], \"value\": [\"foo\", \"bar\"]})\n\n    gen_freq_table = generator.from_frequency_table(df, value_column=\"value\", freq_column=\"freq\", rng=rng)\n\n    (srs,) = gen_freq_table(100)\n    assert pd.notna(srs).all()\n\n    value_counts = srs.value_counts()\n    assert value_counts[\"bar\"] < value_counts[\"foo\"]"
            },
            "tests/test_generator.py::test_from_multicolumn_frequency_table_nan": {
                "testid": "tests/test_generator.py::test_from_multicolumn_frequency_table_nan",
                "result": "passed",
                "test_implementation": "def test_from_multicolumn_frequency_table_nan(tmp_path, rng):\n    freq_file_path = tmp_path / \"freq.csv\"\n    freq_file_path.write_text('value1,value2,freq\\n\"\",\"bar\",1\\n\"foo\",\"baz\",1\\n')\n\n    gen_freq_table = generator.from_multicolumn_frequency_table(\n        freq_file_path,\n        value_columns=[\"value1\", \"value2\"],\n        freq_column=\"freq\",\n        rng=rng,\n    )\n\n    (srs1, srs2) = gen_freq_table(100)\n\n    assert pd.notna(srs1).all()\n    assert pd.notna(srs2).all()"
            },
            "tests/test_generator.py::test_from_multicolumn_frequency_table_df": {
                "testid": "tests/test_generator.py::test_from_multicolumn_frequency_table_df",
                "result": "passed",
                "test_implementation": "def test_from_multicolumn_frequency_table_df(rng):\n    df = pd.DataFrame.from_dict(\n        {\n            \"freq\": [10, 5, 20, 10],\n            \"value1\": [\"foo\", \"foo\", \"bar\", \"bar\"],\n            \"value2\": [\"baz\", \"bat\", \"baz\", \"bat\"],\n        }\n    )\n\n    gen_freq_table = generator.from_multicolumn_frequency_table(\n        df,\n        value_columns=[\"value1\", \"value2\"],\n        freq_column=\"freq\",\n        rng=rng,\n    )\n\n    (srs_1, srs_2) = gen_freq_table(100)\n    assert pd.notna(srs_1).all()\n    assert pd.notna(srs_2).all()\n\n    counts_1 = srs_1.value_counts()\n    assert counts_1[\"bar\"] > counts_1[\"foo\"]\n\n    counts_2 = srs_2.value_counts()\n    assert counts_2[\"baz\"] > counts_2[\"bat\"]"
            },
            "tests/test_generator.py::test_from_group_single_column_same_weight": {
                "testid": "tests/test_generator.py::test_from_group_single_column_same_weight",
                "result": "passed",
                "test_implementation": "def test_from_group_single_column_same_weight(rng):\n    gen_a = generator.from_function(lambda: \"a\")\n    gen_b = generator.from_function(lambda: \"b\")\n\n    gen_group = generator.from_group([gen_a, gen_b], rng=rng)\n    count = 100_000\n\n    (srs,) = gen_group(count)\n    assert len(srs) == count\n\n    # check that the generated values are roughly equally distributed (<0.01%)\n    df_value_counts = srs.value_counts()\n    assert abs(df_value_counts[\"a\"] - df_value_counts[\"b\"]) / count < 0.0001"
            },
            "tests/test_generator.py::test_from_group_single_column_different_weight": {
                "testid": "tests/test_generator.py::test_from_group_single_column_different_weight",
                "result": "passed",
                "test_implementation": "def test_from_group_single_column_different_weight(rng):\n    gen_a = generator.from_function(lambda: \"a\")\n    gen_b = generator.from_function(lambda: \"b\")\n\n    count = 100_000\n    gen_group = generator.from_group(\n        [\n            (0.25, gen_a),\n            (0.75, gen_b),\n        ],\n        rng=rng,\n    )\n\n    (srs,) = gen_group(count)\n    assert len(srs) == count\n\n    # check that the difference in relative frequency (50%) is present\n    df_value_counts = srs.value_counts()\n    assert abs(0.5 - abs((df_value_counts[\"a\"] - df_value_counts[\"b\"]) / count)) < 0.0001"
            },
            "tests/test_generator.py::test_from_group_multiple_column_same_weight": {
                "testid": "tests/test_generator.py::test_from_group_multiple_column_same_weight",
                "result": "passed",
                "test_implementation": "def test_from_group_multiple_column_same_weight(rng):\n    gen_a = lambda c: [pd.Series([\"a1\"] * c), pd.Series([\"a2\"] * c)]\n    gen_b = lambda c: [pd.Series([\"b1\"] * c), pd.Series([\"b2\"] * c)]\n\n    count = 100_000\n    gen_group = generator.from_group([gen_a, gen_b], rng=rng)\n\n    (srs_1, srs_2) = gen_group(count)\n    assert len(srs_1) == len(srs_2) == count\n\n    df_value_counts_1 = srs_1.value_counts()\n    assert abs(df_value_counts_1[\"a1\"] - df_value_counts_1[\"b1\"]) / count < 0.0001\n\n    df_value_counts_2 = srs_2.value_counts()\n    assert abs(df_value_counts_2[\"a2\"] - df_value_counts_2[\"b2\"]) / count < 0.0001"
            },
            "tests/test_generator.py::test_from_group_multiple_column_different_weight": {
                "testid": "tests/test_generator.py::test_from_group_multiple_column_different_weight",
                "result": "passed",
                "test_implementation": "def test_from_group_multiple_column_different_weight(rng):\n    gen_a = lambda c: [pd.Series([\"a1\"] * c), pd.Series([\"a2\"] * c)]\n    gen_b = lambda c: [pd.Series([\"b1\"] * c), pd.Series([\"b2\"] * c)]\n\n    count = 100_000\n    gen_group = generator.from_group(\n        [\n            (0.25, gen_a),\n            (0.75, gen_b),\n        ],\n        rng=rng,\n    )\n\n    (srs_1, srs_2) = gen_group(count)\n    assert len(srs_1) == len(srs_2) == count\n\n    # check that the difference in relative frequency (50%) is present\n    df_value_counts_1 = srs_1.value_counts()\n    assert abs(0.5 - abs((df_value_counts_1[\"a1\"] - df_value_counts_1[\"b1\"]) / count)) < 0.0001\n\n    df_value_counts_2 = srs_2.value_counts()\n    assert abs(0.5 - abs((df_value_counts_2[\"a2\"] - df_value_counts_2[\"b2\"]) / count)) < 0.0001"
            },
            "tests/test_generator.py::test_from_group_raise_different_column_counts": {
                "testid": "tests/test_generator.py::test_from_group_raise_different_column_counts",
                "result": "passed",
                "test_implementation": "def test_from_group_raise_different_column_counts(rng):\n    gen_a = generator.from_function(lambda: \"a\")\n    gen_b = lambda c: [pd.Series([\"b1\"] * c), pd.Series([\"b2\"] * c)]\n\n    with pytest.raises(ValueError) as e:\n        gen = generator.from_group([gen_a, gen_b], rng=rng)\n        gen(100_000)\n\n    assert str(e.value) == \"generators returned different amounts of columns: got 1, 2\""
            },
            "tests/test_generator.py::test_from_group_raise_p_sum_not_1": {
                "testid": "tests/test_generator.py::test_from_group_raise_p_sum_not_1",
                "result": "passed",
                "test_implementation": "def test_from_group_raise_p_sum_not_1(rng):\n    gen_a = generator.from_function(lambda: \"a\")\n    gen_b = generator.from_function(lambda: \"b\")\n\n    with pytest.raises(ValueError) as e:\n        generator.from_group([(0.2, gen_a), (0.3, gen_b)], rng=rng)\n\n    assert str(e.value) == \"sum of weights must be 1, is 0.5\""
            },
            "tests/test_generator.py::test_from_group_raise_row_count": {
                "testid": "tests/test_generator.py::test_from_group_raise_row_count",
                "result": "passed",
                "test_implementation": "def test_from_group_raise_row_count(rng):\n    gen_a = generator.from_function(lambda: \"a\")\n    gen_b = generator.from_function(lambda: \"b\")\n    gen_c = generator.from_function(lambda: \"c\")\n\n    with pytest.raises(ValueError) as e:\n        gen = generator.from_group([gen_a, gen_b, gen_c], rng=rng)\n        gen(100_000)\n\n    assert str(e.value) == (\n        \"sum of values per generator does not equal amount of desired rows: expected 100000, is 99999 - \"\n        \"this is likely due to rounding errors and can be compensated for by adjusting \"\n        \"`max_rounding_adjustment`\"\n    )"
            },
            "tests/test_generator.py::test_from_group_rounding_adjustment_positive": {
                "testid": "tests/test_generator.py::test_from_group_rounding_adjustment_positive",
                "result": "passed",
                "test_implementation": "def test_from_group_rounding_adjustment_positive(rng):\n    gen_a = generator.from_function(lambda: \"a\")\n    gen_b = generator.from_function(lambda: \"b\")\n    gen_c = generator.from_function(lambda: \"c\")\n\n    # this would otherwise generate 99999 rows but with the rounding adjustment,\n    # all series should now have 100000\n    gen = generator.from_group([gen_a, gen_b, gen_c], rng=rng, max_rounding_adjustment=1)\n\n    # this should work without error\n    count = 100_000\n    srs_lst = gen(count)\n\n    assert all(len(srs) == count for srs in srs_lst)"
            },
            "tests/test_generator.py::test_from_group_weight_sanity_check": {
                "testid": "tests/test_generator.py::test_from_group_weight_sanity_check",
                "result": "passed",
                "test_implementation": "def test_from_group_weight_sanity_check(rng):\n    # having generators with p=1/7 for example will not exactly sum up to 1. this is where a\n    # sum(p_vals) == 1 check will fail, but numpy should account for that.\n    _ = generator.from_group(\n        [generator.from_function(lambda: \"a\")] * 7,\n        rng=rng,\n        max_rounding_adjustment=2,  # will generate 100002 values otherwise\n    )"
            },
            "tests/test_generator.py::test_from_group_rounding_adjustment_negative": {
                "testid": "tests/test_generator.py::test_from_group_rounding_adjustment_negative",
                "result": "passed",
                "test_implementation": "def test_from_group_rounding_adjustment_negative(rng):\n    # 7 generators with equal p will result in 100002 rows\n    gen = generator.from_group(\n        [generator.from_function(lambda: \"a\")] * 7,\n        rng=rng,\n        max_rounding_adjustment=2,\n    )\n\n    count = 100_000\n    srs_lst = gen(count)\n\n    assert all(len(srs) == count for srs in srs_lst)"
            },
            "tests/test_generator.py::test_from_group_raise_rounding_adjustment_not_high_enough": {
                "testid": "tests/test_generator.py::test_from_group_raise_rounding_adjustment_not_high_enough",
                "result": "passed",
                "test_implementation": "def test_from_group_raise_rounding_adjustment_not_high_enough(rng):\n    # similar tests as above but this time the rounding adjustment is set too low\n    gen = generator.from_group(\n        [generator.from_function(lambda: \"a\")] * 7,\n        rng=rng,\n        max_rounding_adjustment=1,\n    )\n\n    count = 100_000\n\n    with pytest.raises(ValueError) as e:\n        _ = gen(count)\n\n    assert str(e.value) == (\n        \"sum of values per generator does not equal amount of desired rows: expected 100000, \"\n        \"is 100002 - this is likely due to rounding errors, but `max_rounding_adjustment` \"\n        \"is set so it cannot account for this difference\"\n    )"
            },
            "tests/test_mutator.py::test_with_cldr_keymap_file": {
                "testid": "tests/test_mutator.py::test_with_cldr_keymap_file",
                "result": "passed",
                "test_implementation": "def test_with_cldr_keymap_file(rng):\n    srs = pd.Series(list(string.ascii_lowercase))\n    mutate_cldr = mutator.with_cldr_keymap_file(get_asset_path(\"de-t-k0-windows.xml\"), rng=rng)\n    (srs_mutated,) = mutate_cldr([srs], 1.0)\n\n    assert len(srs) == len(srs_mutated)\n    assert (srs.str.len() == srs_mutated.str.len()).all()\n    assert (srs != srs_mutated).all()"
            },
            "tests/test_mutator.py::test_with_cldr_keymap_file_partial": {
                "testid": "tests/test_mutator.py::test_with_cldr_keymap_file_partial",
                "result": "passed",
                "test_implementation": "def test_with_cldr_keymap_file_partial(rng):\n    srs = pd.Series(list(string.ascii_lowercase))\n    mutate_cldr = mutator.with_cldr_keymap_file(get_asset_path(\"de-t-k0-windows.xml\"), rng=rng)\n    (srs_mutated,) = mutate_cldr([srs], 0.5)\n\n    assert len(srs) == len(srs_mutated)\n    assert (srs == srs_mutated).any()\n    assert (srs != srs_mutated).any()"
            },
            "tests/test_mutator.py::test_with_cldr_keymap_file_multiple_options": {
                "testid": "tests/test_mutator.py::test_with_cldr_keymap_file_multiple_options",
                "result": "passed",
                "test_implementation": "def test_with_cldr_keymap_file_multiple_options(rng):\n    srs = pd.Series([\"foobar\"] * 100)\n    mutate_cldr = mutator.with_cldr_keymap_file(get_asset_path(\"de-t-k0-windows.xml\"), rng=rng)\n    (srs_mutated,) = mutate_cldr([srs], 1.0)\n\n    assert len(srs) == len(srs_mutated)\n    assert (srs.str.len() == srs_mutated.str.len()).all()\n    assert len(srs_mutated.unique()) > 1"
            },
            "tests/test_mutator.py::test_with_cldr_keymap_file_warn_low_p": {
                "testid": "tests/test_mutator.py::test_with_cldr_keymap_file_warn_low_p",
                "result": "passed",
                "test_implementation": "def test_with_cldr_keymap_file_warn_low_p(rng):\n    # restrain mutator to digits only. if p=0.5 then this should put out a warning.\n    srs = pd.Series([\"123\"] * 20 + [\"foobar\"] * 80)\n    mutate_cldr = mutator.with_cldr_keymap_file(get_asset_path(\"de-t-k0-windows.xml\"), charset=string.digits, rng=rng)\n\n    with pytest.warns(GeckoWarning) as record:\n        (srs_mutated,) = mutate_cldr([srs], 0.5)\n\n    assert len(record) == 1\n    assert record[0].message.args[0].startswith(\"with_cldr_keymap_file: desired probability of 0.5 cannot be met\")\n\n    srs_digits, srs_foobar = srs.iloc[:20], srs.iloc[20:]\n    srs_mutated_digits, srs_mutated_foobar = (\n        srs_mutated.iloc[:20],\n        srs_mutated.iloc[20:],\n    )\n\n    assert (srs_digits != srs_mutated_digits).all()\n    assert (srs_foobar == srs_mutated_foobar).all()"
            },
            "tests/test_mutator.py::test_with_missing_value": {
                "testid": "tests/test_mutator.py::test_with_missing_value",
                "result": "passed",
                "test_implementation": "def test_with_missing_value(rng):\n    srs = pd.Series(range(1_000), dtype=str)\n    mut_missing = mutator.with_missing_value(value=\"\", rng=rng)\n    (srs_mut,) = mut_missing([srs], 1.0)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert (srs_mut == \"\").all()"
            },
            "tests/test_mutator.py::test_with_missing_value_partial": {
                "testid": "tests/test_mutator.py::test_with_missing_value_partial",
                "result": "passed",
                "test_implementation": "def test_with_missing_value_partial(rng):\n    srs = pd.Series(range(1_000), dtype=str)\n    mut_missing = mutator.with_missing_value(value=\"\", rng=rng)\n    (srs_mut,) = mut_missing([srs], 0.5)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs == srs_mut).any()\n    assert (srs != srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_missing_value_existing": {
                "testid": "tests/test_mutator.py::test_with_missing_value_existing",
                "result": "passed",
                "test_implementation": "def test_with_missing_value_existing(rng):\n    srs = pd.Series([\"foo\"] * 20 + [\"\"] * 80)\n    mut_missing = mutator.with_missing_value(value=\"\", rng=rng)\n\n    with pytest.warns(GeckoWarning) as record:\n        (srs_mut,) = mut_missing([srs], 0.5)\n\n    assert len(record) == 1\n    assert record[0].message.args[0].startswith(\"with_missing_value: desired probability of 0.5 cannot be met\")\n\n    assert len(srs) == len(srs_mut)\n    assert (srs_mut == \"\").all()"
            },
            "tests/test_mutator.py::test_with_replacement_table": {
                "testid": "tests/test_mutator.py::test_with_replacement_table",
                "result": "passed",
                "test_implementation": "def test_with_replacement_table(rng):\n    srs = pd.Series(list(string.ascii_lowercase))\n\n    # replacement table that maps lowercase chars to uppercase\n    df = pd.DataFrame(\n        list(zip(string.ascii_lowercase, string.ascii_uppercase)),\n        columns=[\"source\", \"target\"],\n    )\n\n    mut_replacement_table = mutator.with_replacement_table(df, source_column=\"source\", target_column=\"target\", rng=rng)\n\n    (srs_mut,) = mut_replacement_table([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert (srs.str.len() == srs_mut.str.len()).all()"
            },
            "tests/test_mutator.py::test_with_replacement_table_random_values": {
                "testid": "tests/test_mutator.py::test_with_replacement_table_random_values",
                "result": "passed",
                "test_implementation": "def test_with_replacement_table_random_values(rng):\n    srs = pd.Series([\"aaa\"] * 1_000)\n    df_replacement_table = pd.DataFrame.from_dict({\"source\": [\"a\", \"a\", \"a\"], \"target\": [\"0\", \"1\", \"2\"]})\n\n    mut_replacement_table = mutator.with_replacement_table(\n        df_replacement_table,\n        source_column=\"source\",\n        target_column=\"target\",\n        inline=True,\n        rng=rng,\n    )\n\n    (srs_mut,) = mut_replacement_table([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert len(srs_mut.unique()) > 1"
            },
            "tests/test_mutator.py::test_with_replacement_table_favor_rare_replacements": {
                "testid": "tests/test_mutator.py::test_with_replacement_table_favor_rare_replacements",
                "result": "passed",
                "test_implementation": "def test_with_replacement_table_favor_rare_replacements(rng):\n    srs = pd.Series([\"foobar\"] * 100 + [\"foobaz\"] * 50)\n\n    df = pd.DataFrame.from_dict({\"source\": [\"foobar\", \"foobaz\"], \"target\": [\"0\", \"1\"]})\n\n    mut_replacement_table = mutator.with_replacement_table(df, source_column=\"source\", target_column=\"target\", rng=rng)\n\n    (srs_mutated,) = mut_replacement_table([srs], 1)\n\n    assert len(srs) == len(srs_mutated)\n    assert (srs != srs_mutated).all()\n    assert (srs_mutated == [\"0\"] * 100 + [\"1\"] * 50).all()"
            },
            "tests/test_mutator.py::test_with_replacement_table_partial": {
                "testid": "tests/test_mutator.py::test_with_replacement_table_partial",
                "result": "passed",
                "test_implementation": "def test_with_replacement_table_partial(rng):\n    srs = pd.Series(list(string.ascii_lowercase))\n\n    # replacement table that maps lowercase chars to uppercase\n    df = pd.DataFrame(\n        list(zip(string.ascii_lowercase, string.ascii_uppercase)),\n        columns=[\"source\", \"target\"],\n    )\n\n    mut_replacement_table = mutator.with_replacement_table(df, source_column=\"source\", target_column=\"target\", rng=rng)\n\n    (srs_mut,) = mut_replacement_table([srs], 0.5)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs == srs_mut).any()\n    assert (srs != srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_replacement_table_reverse": {
                "testid": "tests/test_mutator.py::test_with_replacement_table_reverse",
                "result": "passed",
                "test_implementation": "def test_with_replacement_table_reverse(rng):\n    # lowercase AND uppercase will be converted to the opposite case\n    srs = pd.Series(list(string.ascii_lowercase + string.ascii_uppercase))\n\n    df = pd.DataFrame(\n        list(zip(string.ascii_lowercase, string.ascii_uppercase)),\n        columns=[\"source\", \"target\"],\n    )\n\n    # this mutator should ensure that uppercase -> lowercase should take place\n    mut_replacement_table = mutator.with_replacement_table(\n        df, source_column=\"source\", target_column=\"target\", reverse=True, rng=rng\n    )\n\n    (srs_mut,) = mut_replacement_table([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert (srs.str.len() == srs_mut.str.len()).all()"
            },
            "tests/test_mutator.py::test_with_replacement_table_inline": {
                "testid": "tests/test_mutator.py::test_with_replacement_table_inline",
                "result": "passed",
                "test_implementation": "def test_with_replacement_table_inline(rng):\n    # generate random lowercase strings\n    srs = pd.Series(random_strings(str_len=10, charset=string.ascii_lowercase, rng=rng))\n\n    df = pd.DataFrame(\n        list(zip(string.ascii_lowercase, string.ascii_uppercase)),\n        columns=[\"source\", \"target\"],\n    )\n\n    # this mutator should ensure that replacements occur inline\n    mut_replacement_table = mutator.with_replacement_table(\n        df, source_column=\"source\", target_column=\"target\", inline=True, rng=rng\n    )\n\n    (srs_mut,) = mut_replacement_table([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert (srs.str.len() == srs_mut.str.len()).all()"
            },
            "tests/test_mutator.py::test_with_replacement_table_warn_p": {
                "testid": "tests/test_mutator.py::test_with_replacement_table_warn_p",
                "result": "passed",
                "test_implementation": "def test_with_replacement_table_warn_p(rng):\n    srs = pd.Series([\"a\"] * 50 + [\"b\"] * 50)\n\n    # no mapping for \"b\"\n    df = pd.DataFrame.from_dict({\"source\": [\"a\"], \"target\": [\"A\"]})\n\n    mut_replacement_table = mutator.with_replacement_table(df, source_column=\"source\", target_column=\"target\", rng=rng)\n\n    with pytest.warns(GeckoWarning) as record:\n        (srs_mut,) = mut_replacement_table([srs], 0.8)\n\n    assert len(record) == 1\n    assert record[0].message.args[0].startswith(\"with_replacement_table: desired probability of 0.8 cannot be met\")\n\n    assert len(srs) == len(srs_mut)\n    assert (srs.iloc[:50] != srs_mut.iloc[:50]).all()\n    assert (srs.iloc[50:] == srs_mut.iloc[50:]).all()\n    assert (srs.str.len() == srs_mut.str.len()).all()"
            },
            "tests/test_mutator.py::test_with_replacement_table_csv": {
                "testid": "tests/test_mutator.py::test_with_replacement_table_csv",
                "result": "passed",
                "test_implementation": "def test_with_replacement_table_csv(rng, tmp_path):\n    srs = pd.Series(list(string.ascii_lowercase))\n    csv_file_path = write_temporary_csv_file(\n        tmp_path,\n        header=[\"source\", \"target\"],\n        rows=list(zip(string.ascii_lowercase, string.ascii_uppercase)),\n    )\n\n    mut_replacement_table = mutator.with_replacement_table(\n        csv_file_path, source_column=\"source\", target_column=\"target\", rng=rng\n    )\n\n    (srs_mut,) = mut_replacement_table([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert (srs.str.len() == srs_mut.str.len()).all()"
            },
            "tests/test_mutator.py::test_with_delete": {
                "testid": "tests/test_mutator.py::test_with_delete",
                "result": "passed",
                "test_implementation": "def test_with_delete(rng):\n    srs = pd.Series(random_strings(rng=rng))\n    mut_delete = mutator.with_delete(rng=rng)\n\n    (srs_mut,) = mut_delete([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert (srs.str.len() - 1 == srs_mut.str.len()).all()"
            },
            "tests/test_mutator.py::test_with_delete_partial": {
                "testid": "tests/test_mutator.py::test_with_delete_partial",
                "result": "passed",
                "test_implementation": "def test_with_delete_partial(rng):\n    srs = pd.Series(random_strings(rng=rng))\n    mut_delete = mutator.with_delete(rng=rng)\n\n    (srs_mut,) = mut_delete([srs], 0.5)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs == srs_mut).any()\n    assert (srs != srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_delete_warn_p": {
                "testid": "tests/test_mutator.py::test_with_delete_warn_p",
                "result": "passed",
                "test_implementation": "def test_with_delete_warn_p(rng):\n    srs = pd.Series(random_strings(n_strings=50, rng=rng) + [\"\"] * 50)\n    mut_delete = mutator.with_delete(rng=rng)\n\n    with pytest.warns(GeckoWarning) as record:\n        (srs_mut,) = mut_delete([srs], 0.8)\n\n    assert len(record) == 1\n    assert record[0].message.args[0].startswith(\"with_delete: desired probability of 0.8 cannot be met\")\n\n    assert len(srs) == len(srs_mut)\n\n    assert (srs.iloc[:50] != srs_mut.iloc[:50]).all()\n    assert (srs.iloc[:50].str.len() - 1 == srs_mut.iloc[:50].str.len()).all()\n    assert (srs.iloc[50:] == srs_mut.iloc[50:]).all()"
            },
            "tests/test_mutator.py::test_with_insert": {
                "testid": "tests/test_mutator.py::test_with_insert",
                "result": "passed",
                "test_implementation": "def test_with_insert(rng):\n    srs = pd.Series(random_strings(rng=rng))\n    mut_insert = mutator.with_insert(rng=rng)\n\n    (srs_mut,) = mut_insert([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert (srs.str.len() + 1 == srs_mut.str.len()).all()"
            },
            "tests/test_mutator.py::test_with_insert_partial": {
                "testid": "tests/test_mutator.py::test_with_insert_partial",
                "result": "passed",
                "test_implementation": "def test_with_insert_partial(rng):\n    srs = pd.Series(random_strings(rng=rng))\n    mut_insert = mutator.with_insert(rng=rng)\n\n    (srs_mut,) = mut_insert([srs], 0.5)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs == srs_mut).any()\n    assert (srs != srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_insert_charset": {
                "testid": "tests/test_mutator.py::test_with_insert_charset",
                "result": "passed",
                "test_implementation": "def test_with_insert_charset(rng):\n    # test by inserting uppercase characters into lowercase strings\n    srs = pd.Series(random_strings(rng=rng, charset=string.ascii_lowercase))\n    mut_insert = mutator.with_insert(charset=string.ascii_uppercase, rng=rng)\n\n    (srs_mut,) = mut_insert([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert (srs.str.len() + 1 == srs_mut.str.len()).all()\n\n    # test that all rows are no longer only lowercase\n    assert srs_mut.str.lower().all()\n    assert (~srs_mut.str.islower()).all()"
            },
            "tests/test_mutator.py::test_with_transpose": {
                "testid": "tests/test_mutator.py::test_with_transpose",
                "result": "passed",
                "test_implementation": "def test_with_transpose(rng):\n    # create unique strings, otherwise the same characters might be swapped\n    srs = pd.Series(random_strings(unique=True, rng=rng))\n    mut_transpose = mutator.with_transpose(rng=rng)\n\n    (srs_mut,) = mut_transpose([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert (srs.str.len() == srs_mut.str.len()).all()"
            },
            "tests/test_mutator.py::test_with_transpose_partial": {
                "testid": "tests/test_mutator.py::test_with_transpose_partial",
                "result": "passed",
                "test_implementation": "def test_with_transpose_partial(rng):\n    # create unique strings, otherwise the same characters might be swapped\n    srs = pd.Series(random_strings(unique=True, rng=rng))\n    mut_transpose = mutator.with_transpose(rng=rng)\n\n    (srs_mut,) = mut_transpose([srs], 0.5)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs == srs_mut).any()\n    assert (srs != srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_transpose_warn_p": {
                "testid": "tests/test_mutator.py::test_with_transpose_warn_p",
                "result": "passed",
                "test_implementation": "def test_with_transpose_warn_p(rng):\n    srs = pd.Series(random_strings(n_strings=50, unique=True, rng=rng) + [\"a\"] * 50)\n    mut_transpose = mutator.with_transpose(rng=rng)\n\n    with pytest.warns(GeckoWarning) as record:\n        (srs_mut,) = mut_transpose([srs], 0.8)\n\n    assert len(record) == 1\n    assert record[0].message.args[0].startswith(\"with_transpose: desired probability of 0.8 cannot be met\")\n\n    assert len(srs) == len(srs_mut)\n    assert (srs.str.len() == srs_mut.str.len()).all()\n    assert (srs.iloc[:50] != srs_mut.iloc[:50]).all()\n    assert (srs.iloc[50:] == srs_mut.iloc[50:]).all()"
            },
            "tests/test_mutator.py::test_with_substitute": {
                "testid": "tests/test_mutator.py::test_with_substitute",
                "result": "passed",
                "test_implementation": "def test_with_substitute(rng):\n    # by default, with_substitute inserts characters, so use digits to avoid replacement of same characters\n    srs = pd.Series(random_strings(charset=string.digits, rng=rng))\n    mut_substitute = mutator.with_substitute(rng=rng)\n\n    (srs_mut,) = mut_substitute([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert (srs.str.len() == srs_mut.str.len()).all()\n\n    # check that the correct characters have been inserted\n    assert srs.str.isdigit().all()\n    assert not srs_mut.str.isdigit().all()"
            },
            "tests/test_mutator.py::test_with_substitute_partial": {
                "testid": "tests/test_mutator.py::test_with_substitute_partial",
                "result": "passed",
                "test_implementation": "def test_with_substitute_partial(rng):\n    srs = pd.Series(random_strings(charset=string.digits, rng=rng))\n    mut_substitute = mutator.with_substitute(rng=rng)\n\n    (srs_mut,) = mut_substitute([srs], 0.5)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs == srs_mut).any()\n    assert (srs != srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_substitute_charset": {
                "testid": "tests/test_mutator.py::test_with_substitute_charset",
                "result": "passed",
                "test_implementation": "def test_with_substitute_charset(rng):\n    # same as above, this time using a custom charset param\n    srs = pd.Series(random_strings(charset=string.ascii_lowercase, rng=rng))\n    mut_substitute = mutator.with_substitute(charset=string.digits, rng=rng)\n\n    (srs_mut,) = mut_substitute([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert (srs.str.len() == srs_mut.str.len()).all()\n\n    # same check as above, this time checking if digits have been inserted\n    assert srs.str.isalpha().all()\n    assert not srs_mut.str.isalpha().all()\n    assert srs_mut.str.isalnum().all()  # should be alphanumeric now!"
            },
            "tests/test_mutator.py::test_with_substitute_warn_p": {
                "testid": "tests/test_mutator.py::test_with_substitute_warn_p",
                "result": "passed",
                "test_implementation": "def test_with_substitute_warn_p(rng):\n    srs = pd.Series(random_strings(n_strings=50, charset=string.digits, rng=rng) + [\"\"] * 50)\n    mut_substitute = mutator.with_substitute(rng=rng)\n\n    with pytest.warns(GeckoWarning) as record:\n        (srs_mut,) = mut_substitute([srs], 0.8)\n\n    assert len(record) == 1\n    assert record[0].message.args[0].startswith(\"with_substitute: desired probability of 0.8 cannot be met\")\n\n    assert len(srs) == len(srs_mut)\n    assert (srs.str.len() == srs_mut.str.len()).all()\n    assert (srs.iloc[:50] != srs_mut.iloc[:50]).all()\n    assert (srs.iloc[50:] == srs_mut.iloc[50:]).all()"
            },
            "tests/test_mutator.py::test_with_uppercase": {
                "testid": "tests/test_mutator.py::test_with_uppercase",
                "result": "passed",
                "test_implementation": "def test_with_uppercase(rng):\n    srs = pd.Series(random_strings(charset=string.ascii_lowercase, rng=rng))\n    mut_uppercase = mutator.with_uppercase(rng=rng)\n\n    (srs_mut,) = mut_uppercase([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert (srs.str.upper() == srs_mut).all()"
            },
            "tests/test_mutator.py::test_with_uppercase_partial": {
                "testid": "tests/test_mutator.py::test_with_uppercase_partial",
                "result": "passed",
                "test_implementation": "def test_with_uppercase_partial(rng):\n    srs = pd.Series(random_strings(charset=string.ascii_lowercase, rng=rng))\n    mut_uppercase = mutator.with_uppercase(rng=rng)\n\n    (srs_mut,) = mut_uppercase([srs], 0.5)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs == srs_mut).any()\n    assert (srs != srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_uppercase_warn_p": {
                "testid": "tests/test_mutator.py::test_with_uppercase_warn_p",
                "result": "passed",
                "test_implementation": "def test_with_uppercase_warn_p(rng):\n    srs = pd.Series(\n        random_strings(n_strings=50, charset=string.ascii_lowercase, rng=rng)\n        + random_strings(n_strings=50, charset=string.ascii_uppercase, rng=rng)\n    )\n    mut_uppercase = mutator.with_uppercase(rng=rng)\n\n    with pytest.warns(GeckoWarning) as record:\n        (srs_mut,) = mut_uppercase([srs], 0.8)\n\n    assert len(record) == 1\n    assert record[0].message.args[0].startswith(\"with_uppercase: desired probability of 0.8 cannot be met\")\n\n    assert len(srs) == len(srs_mut)\n    assert (srs.iloc[:50] != srs_mut.iloc[:50]).all()\n    assert (srs.iloc[:50].str.upper() == srs_mut.iloc[:50]).all()\n    assert (srs.iloc[50:] == srs_mut.iloc[50:]).all()"
            },
            "tests/test_mutator.py::test_with_lowercase": {
                "testid": "tests/test_mutator.py::test_with_lowercase",
                "result": "passed",
                "test_implementation": "def test_with_lowercase(rng):\n    srs = pd.Series(random_strings(charset=string.ascii_uppercase, rng=rng))\n    mut_lowercase = mutator.with_lowercase(rng=rng)\n\n    (srs_mut,) = mut_lowercase([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert (srs.str.lower() == srs_mut).all()"
            },
            "tests/test_mutator.py::test_with_lowercase_partial": {
                "testid": "tests/test_mutator.py::test_with_lowercase_partial",
                "result": "passed",
                "test_implementation": "def test_with_lowercase_partial(rng):\n    srs = pd.Series(random_strings(charset=string.ascii_uppercase, rng=rng))\n    mut_lowercase = mutator.with_lowercase(rng=rng)\n\n    (srs_mut,) = mut_lowercase([srs], 0.5)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs == srs_mut).any()\n    assert (srs != srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_lowercase_warn_p": {
                "testid": "tests/test_mutator.py::test_with_lowercase_warn_p",
                "result": "passed",
                "test_implementation": "def test_with_lowercase_warn_p(rng):\n    srs = pd.Series(\n        random_strings(n_strings=50, charset=string.ascii_uppercase, rng=rng)\n        + random_strings(n_strings=50, charset=string.ascii_lowercase, rng=rng)\n    )\n    mut_lowercase = mutator.with_lowercase(rng=rng)\n\n    with pytest.warns(GeckoWarning) as record:\n        (srs_mut,) = mut_lowercase([srs], 0.8)\n\n    assert len(record) == 1\n    assert record[0].message.args[0].startswith(\"with_lowercase: desired probability of 0.8 cannot be met\")\n\n    assert len(srs) == len(srs_mut)\n    assert (srs.iloc[:50] != srs_mut.iloc[:50]).all()\n    assert (srs.iloc[:50].str.lower() == srs_mut.iloc[:50]).all()\n    assert (srs.iloc[50:] == srs_mut.iloc[50:]).all()"
            },
            "tests/test_mutator.py::test_with_function": {
                "testid": "tests/test_mutator.py::test_with_function",
                "result": "passed",
                "test_implementation": "def test_with_function(rng):\n    import numpy as np\n\n    def _my_func(value: str, my_rng: np.random.Generator) -> str:\n        return f\"{value}{my_rng.integers(0, 10)}\"\n\n    srs = pd.Series(random_strings(charset=string.ascii_letters, rng=rng))\n    mut_fn = mutator.with_function(_my_func, rng=rng, my_rng=rng)\n\n    (srs_mut,) = mut_fn([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert (srs.str.len() + 1 == srs_mut.str.len()).all()\n    assert (srs == srs_mut.str[:-1]).all()\n    assert srs_mut.str[-1].str.isdigit().all()"
            },
            "tests/test_mutator.py::test_with_function_partial": {
                "testid": "tests/test_mutator.py::test_with_function_partial",
                "result": "passed",
                "test_implementation": "def test_with_function_partial(rng):\n    import numpy as np\n\n    def _my_func(value: str, my_rng: np.random.Generator) -> str:\n        return f\"{value}{my_rng.integers(0, 10)}\"\n\n    srs = pd.Series(random_strings(charset=string.ascii_letters, rng=rng))\n    mut_fn = mutator.with_function(_my_func, rng=rng, my_rng=rng)\n\n    (srs_mut,) = mut_fn([srs], 0.5)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs == srs_mut).any()\n    assert (srs != srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_repeat": {
                "testid": "tests/test_mutator.py::test_with_repeat",
                "result": "passed",
                "test_implementation": "def test_with_repeat(rng):\n    srs = pd.Series(random_strings(charset=string.ascii_letters, rng=rng))\n    mut_repeat = mutator.with_repeat(rng=rng)\n\n    (srs_mut,) = mut_repeat([srs], 1.0)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert (srs + \" \" + srs == srs_mut).all()"
            },
            "tests/test_mutator.py::test_with_repeat_partial": {
                "testid": "tests/test_mutator.py::test_with_repeat_partial",
                "result": "passed",
                "test_implementation": "def test_with_repeat_partial(rng):\n    srs = pd.Series(random_strings(charset=string.ascii_letters, rng=rng))\n    mut_repeat = mutator.with_repeat(rng=rng)\n\n    (srs_mut,) = mut_repeat([srs], 0.5)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs == srs_mut).any()\n    assert (srs != srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_repeat_join_character": {
                "testid": "tests/test_mutator.py::test_with_repeat_join_character",
                "result": "passed",
                "test_implementation": "def test_with_repeat_join_character(rng):\n    srs = pd.Series(random_strings(charset=string.ascii_letters, rng=rng))\n    mut_repeat = mutator.with_repeat(join_with=\":\", rng=rng)\n\n    (srs_mut,) = mut_repeat([srs], 1.0)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs + \":\" + srs == srs_mut).all()"
            },
            "tests/test_mutator.py::test_with_permute": {
                "testid": "tests/test_mutator.py::test_with_permute",
                "result": "passed",
                "test_implementation": "def test_with_permute(rng):\n    srs_a = pd.Series(random_strings(charset=string.ascii_lowercase, rng=rng))\n    srs_b = pd.Series(random_strings(charset=string.ascii_uppercase, rng=rng))\n    mut_permute = mutator.with_permute(rng=rng)\n\n    (srs_a_mut, srs_b_mut) = mut_permute([srs_a, srs_b], 1.0)\n\n    assert len(srs_a) == len(srs_b) == len(srs_a_mut) == len(srs_b_mut)\n    assert (srs_a == srs_b_mut).all()\n    assert (srs_b == srs_a_mut).all()"
            },
            "tests/test_mutator.py::test_with_permute_multicolumn": {
                "testid": "tests/test_mutator.py::test_with_permute_multicolumn",
                "result": "passed",
                "test_implementation": "def test_with_permute_multicolumn(rng):\n    srs_a = pd.Series(random_strings(charset=string.ascii_lowercase, rng=rng))\n    srs_b = pd.Series(random_strings(charset=string.ascii_uppercase, rng=rng))\n    srs_c = pd.Series(random_strings(charset=string.digits, rng=rng))\n    mut_permute = mutator.with_permute(rng=rng)\n\n    (srs_a_mut, srs_b_mut, srs_c_mut) = mut_permute([srs_a, srs_b, srs_c], 1.0)\n\n    assert len(srs_a) == len(srs_b) == len(srs_c) == len(srs_a_mut) == len(srs_b_mut) == len(srs_c_mut)\n    assert (~srs_a_mut.str.islower()).all()\n    assert (~srs_b_mut.str.isupper()).all()\n    assert (~srs_c_mut.str.isdigit()).all()"
            },
            "tests/test_mutator.py::test_with_permute_partial": {
                "testid": "tests/test_mutator.py::test_with_permute_partial",
                "result": "passed",
                "test_implementation": "def test_with_permute_partial(rng):\n    srs_a = pd.Series(random_strings(charset=string.ascii_lowercase, rng=rng))\n    srs_b = pd.Series(random_strings(charset=string.ascii_uppercase, rng=rng))\n    mut_permute = mutator.with_permute(rng=rng)\n\n    # most entries should be flipped\n    (srs_a_mut, srs_b_mut) = mut_permute([srs_a, srs_b], 0.8)\n\n    assert len(srs_a) == len(srs_b) == len(srs_a_mut) == len(srs_b_mut)\n\n    srs_a_flipped = srs_a_mut.str.isupper()\n    srs_b_flipped = srs_b_mut.str.islower()\n\n    assert not srs_a_flipped.all()\n    assert not srs_b_flipped.all()\n\n    assert srs_a_flipped.sum() > (~srs_a_flipped).sum()\n    assert srs_b_flipped.sum() > (~srs_b_flipped).sum()"
            },
            "tests/test_mutator.py::test_with_generator_replace": {
                "testid": "tests/test_mutator.py::test_with_generator_replace",
                "result": "passed",
                "test_implementation": "def test_with_generator_replace(rng):\n    srs = pd.Series(random_strings(charset=string.ascii_letters, rng=rng))\n    mut_generator = mutator.with_generator(_from_scalar_value(\"foobar\"), mode=\"replace\", rng=rng)\n    (srs_mut,) = mut_generator([srs], 1.0)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert (srs_mut == \"foobar\").all()"
            },
            "tests/test_mutator.py::test_with_generator_partial": {
                "testid": "tests/test_mutator.py::test_with_generator_partial",
                "result": "passed",
                "test_implementation": "def test_with_generator_partial(rng):\n    srs = pd.Series(random_strings(charset=string.ascii_letters, rng=rng))\n    mut_generator = mutator.with_generator(_from_scalar_value(\"foobar\"), mode=\"replace\", rng=rng)\n    (srs_mut,) = mut_generator([srs], 0.8)\n\n    assert len(srs) == len(srs_mut)\n\n    srs_value_mutated = srs_mut == \"foobar\"\n\n    assert not srs_value_mutated.all()\n    assert srs_value_mutated.sum() > (~srs_value_mutated).sum()"
            },
            "tests/test_mutator.py::test_with_generator_prepend": {
                "testid": "tests/test_mutator.py::test_with_generator_prepend",
                "result": "passed",
                "test_implementation": "def test_with_generator_prepend(rng):\n    srs = pd.Series(random_strings(charset=string.digits, rng=rng))\n    mut_generator = mutator.with_generator(_from_scalar_value(\"foobar\"), mode=\"prepend\", rng=rng)\n    (srs_mut,) = mut_generator([srs], 1.0)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert srs_mut.str.match(r\"foobar \\d+\").all()"
            },
            "tests/test_mutator.py::test_with_generator_append": {
                "testid": "tests/test_mutator.py::test_with_generator_append",
                "result": "passed",
                "test_implementation": "def test_with_generator_append(rng):\n    srs = pd.Series(random_strings(charset=string.digits, rng=rng))\n    mut_generator = mutator.with_generator(_from_scalar_value(\"foobar\"), mode=\"append\", rng=rng)\n    (srs_mut,) = mut_generator([srs], 1.0)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert srs_mut.str.match(r\"\\d+ foobar\").all()"
            },
            "tests/test_mutator.py::test_with_generator_prepend_join_char": {
                "testid": "tests/test_mutator.py::test_with_generator_prepend_join_char",
                "result": "passed",
                "test_implementation": "def test_with_generator_prepend_join_char(rng):\n    srs = pd.Series(random_strings(charset=string.digits, rng=rng))\n    mut_generator = mutator.with_generator(_from_scalar_value(\"foobar\"), mode=\"prepend\", join_with=\"-\", rng=rng)\n    (srs_mut,) = mut_generator([srs], 1.0)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert srs_mut.str.match(r\"foobar-\\d+\").all()"
            },
            "tests/test_mutator.py::test_with_generator_append_join_char": {
                "testid": "tests/test_mutator.py::test_with_generator_append_join_char",
                "result": "passed",
                "test_implementation": "def test_with_generator_append_join_char(rng):\n    srs = pd.Series(random_strings(charset=string.digits, rng=rng))\n    mut_generator = mutator.with_generator(_from_scalar_value(\"foobar\"), mode=\"append\", join_with=\"-\", rng=rng)\n    (srs_mut,) = mut_generator([srs], 1.0)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert srs_mut.str.match(r\"\\d+-foobar\").all()"
            },
            "tests/test_mutator.py::test_with_generator_prepend_join_char_insert": {
                "testid": "tests/test_mutator.py::test_with_generator_prepend_join_char_insert",
                "result": "passed",
                "test_implementation": "def test_with_generator_prepend_join_char_insert(rng):\n    srs = pd.Series(random_strings(charset=string.digits, rng=rng))\n    mut_generator = mutator.with_generator(_from_scalar_value(\"foobar\"), mode=\"prepend\", join_with=\" ({}) \", rng=rng)\n    (srs_mut,) = mut_generator([srs], 1.0)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert srs_mut.str.match(r\" \\(foobar\\) \\d+\").all()"
            },
            "tests/test_mutator.py::test_with_generator_append_join_char_insert": {
                "testid": "tests/test_mutator.py::test_with_generator_append_join_char_insert",
                "result": "passed",
                "test_implementation": "def test_with_generator_append_join_char_insert(rng):\n    srs = pd.Series(random_strings(charset=string.digits, rng=rng))\n    mut_generator = mutator.with_generator(_from_scalar_value(\"foobar\"), mode=\"append\", join_with=\" ({}) \", rng=rng)\n    (srs_mut,) = mut_generator([srs], 1.0)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert srs_mut.str.match(r\"\\d+ \\(foobar\\) \").all()"
            },
            "tests/test_mutator.py::test_with_generator_multi_column": {
                "testid": "tests/test_mutator.py::test_with_generator_multi_column",
                "result": "passed",
                "test_implementation": "def test_with_generator_multi_column(rng):\n    srs_a = pd.Series(random_strings(charset=string.ascii_letters, rng=rng))\n    srs_b = pd.Series(random_strings(charset=string.ascii_letters, rng=rng))\n\n    mut_generator = mutator.with_generator(_from_scalar_value((\"foobar\", \"foobaz\")), mode=\"replace\", rng=rng)\n    (srs_a_mut, srs_b_mut) = mut_generator([srs_a, srs_b], 1.0)\n\n    assert len(srs_a) == len(srs_b) == len(srs_a_mut) == len(srs_b_mut)\n\n    assert (srs_a != srs_a_mut).all()\n    assert (srs_b != srs_b_mut).all()\n    assert (srs_a_mut == \"foobar\").all()\n    assert (srs_b_mut == \"foobaz\").all()"
            },
            "tests/test_mutator.py::test_with_generator_raise_mismatched_columns": {
                "testid": "tests/test_mutator.py::test_with_generator_raise_mismatched_columns",
                "result": "passed",
                "test_implementation": "def test_with_generator_raise_mismatched_columns(rng):\n    srs = pd.Series(random_strings(charset=string.ascii_letters, rng=rng))\n    mut_generator = mutator.with_generator(_from_scalar_value((\"foobar\", \"foobaz\")), mode=\"replace\", rng=rng)\n\n    with pytest.raises(ValueError) as e:\n        _ = mut_generator([srs], 1.0)\n\n    assert str(e.value) == (\"generator must generate as many series as provided to the mutator: \" \"got 2, expected 1\")"
            },
            "tests/test_mutator.py::test_with_group": {
                "testid": "tests/test_mutator.py::test_with_group",
                "result": "passed",
                "test_implementation": "def test_with_group(rng):\n    srs = pd.Series(random_strings(charset=string.ascii_letters, str_len=20, rng=rng))\n    mut_group = mutator.with_group(\n        [\n            mutator.with_insert(charset=string.digits, rng=rng),\n            mutator.with_delete(rng=rng),\n        ],\n        rng=rng,\n    )\n\n    (srs_mut,) = mut_group([srs], 1.0)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert (srs.str.len() != srs_mut.str.len()).all()\n    assert set(srs_mut.str.len().unique()) == {19, 21}"
            },
            "tests/test_mutator.py::test_with_group_partial": {
                "testid": "tests/test_mutator.py::test_with_group_partial",
                "result": "passed",
                "test_implementation": "def test_with_group_partial(rng):\n    srs = pd.Series(random_strings(charset=string.ascii_letters, str_len=20, rng=rng))\n    mut_group = mutator.with_group(\n        [\n            mutator.with_insert(charset=string.digits, rng=rng),\n            mutator.with_delete(rng=rng),\n        ],\n        rng=rng,\n    )\n\n    (srs_mut,) = mut_group([srs], 0.5)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs == srs_mut).any()\n    assert (srs != srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_group_weighted": {
                "testid": "tests/test_mutator.py::test_with_group_weighted",
                "result": "passed",
                "test_implementation": "def test_with_group_weighted(rng):\n    srs = pd.Series(random_strings(charset=string.ascii_letters, str_len=20, rng=rng))\n    mut_group = mutator.with_group(\n        [\n            (0.2, mutator.with_insert(charset=string.digits, rng=rng)),\n            (0.8, mutator.with_delete(rng=rng)),\n        ],\n        rng=rng,\n    )\n\n    (srs_mut,) = mut_group([srs], 1.0)\n\n    assert len(srs) == len(srs_mut)\n\n    srs_mut_str_len_counts = srs_mut.str.len().value_counts()\n    assert srs_mut_str_len_counts[19] > srs_mut_str_len_counts[21]"
            },
            "tests/test_mutator.py::test_with_group_padded": {
                "testid": "tests/test_mutator.py::test_with_group_padded",
                "result": "passed",
                "test_implementation": "def test_with_group_padded(rng):\n    srs = pd.Series(random_strings(charset=string.ascii_letters, rng=rng))\n    mut_group = mutator.with_group(\n        [\n            (0.2, mutator.with_insert(charset=string.digits, rng=rng)),\n        ],\n        rng=rng,\n    )\n\n    (srs_mut,) = mut_group([srs], 1.0)\n\n    assert len(srs) == len(srs_mut)\n\n    srs_mut_str_len_counts = srs_mut.str.len().value_counts()\n    assert srs_mut_str_len_counts[20] > srs_mut_str_len_counts[21]"
            },
            "tests/test_mutator.py::test_with_group_raise_p_sum_too_high": {
                "testid": "tests/test_mutator.py::test_with_group_raise_p_sum_too_high",
                "result": "passed",
                "test_implementation": "def test_with_group_raise_p_sum_too_high(rng):\n    with pytest.raises(ValueError) as e:\n        _ = mutator.with_group(\n            [\n                (0.6, mutator.with_delete(rng=rng)),\n                (0.41, mutator.with_insert(rng=rng)),\n            ],\n            rng=rng,\n        )\n\n    assert str(e.value) == f\"sum of weights must not be higher than 1, is {.6 + .41}\""
            },
            "tests/test_mutator.py::test_with_group_raise_p_sum_too_low": {
                "testid": "tests/test_mutator.py::test_with_group_raise_p_sum_too_low",
                "result": "passed",
                "test_implementation": "def test_with_group_raise_p_sum_too_low(rng):\n    with pytest.raises(ValueError) as e:\n        _ = mutator.with_group(\n            [\n                (0, mutator.with_delete(rng=rng)),\n                (0, mutator.with_insert(rng=rng)),\n            ],\n            rng=rng,\n        )\n\n    assert str(e.value) == \"sum of weights must be higher than 0, is 0\""
            },
            "tests/test_mutator.py::test_with_categorical_values": {
                "testid": "tests/test_mutator.py::test_with_categorical_values",
                "result": "passed",
                "test_implementation": "def test_with_categorical_values(rng):\n    values = {\"a\", \"b\", \"c\", \"d\"}\n    srs = pd.Series(list(sorted(values)) * 1_000)\n\n    df_cat = pd.DataFrame.from_dict({\"values\": list(\"abcd\")})\n\n    mut_categorical = mutator.with_categorical_values(df_cat, value_column=\"values\", rng=rng)\n\n    (srs_mut,) = mut_categorical([srs], 1.0)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n\n    # check that each other categorical value appears at least once\n    for value in values:\n        this_val = srs == value\n\n        for other_value in values - {value}:\n            assert (srs_mut[this_val] == other_value).any()"
            },
            "tests/test_mutator.py::test_with_categorical_values_partial": {
                "testid": "tests/test_mutator.py::test_with_categorical_values_partial",
                "result": "passed",
                "test_implementation": "def test_with_categorical_values_partial(rng):\n    values = {\"a\", \"b\", \"c\", \"d\"}\n    srs = pd.Series(list(sorted(values)) * 1_000)\n\n    df_cat = pd.DataFrame.from_dict({\"values\": list(\"abcd\")})\n\n    mut_categorical = mutator.with_categorical_values(df_cat, value_column=\"values\", rng=rng)\n\n    (srs_mut,) = mut_categorical([srs], 0.5)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs == srs_mut).any()\n    assert (srs != srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_categorical_values_warn_p": {
                "testid": "tests/test_mutator.py::test_with_categorical_values_warn_p",
                "result": "passed",
                "test_implementation": "def test_with_categorical_values_warn_p(rng):\n    srs = pd.Series(list(\"abcd\") * 1_000)\n\n    # only two values from the series can be mutated, so p should be approx. 50%\n    df_cat = pd.DataFrame.from_dict({\"values\": list(\"ab\")})\n\n    mut_categorical = mutator.with_categorical_values(df_cat, value_column=\"values\", rng=rng)\n\n    with pytest.warns(GeckoWarning) as record:\n        (srs_mut,) = mut_categorical([srs], 0.8)\n\n    assert len(record) == 1\n    assert record[0].message.args[0].startswith(\"with_categorical_values: desired probability of 0.8 cannot be met\")\n\n    srs_mutated_rows = (srs == \"a\") | (srs == \"b\")\n\n    assert (srs.loc[srs_mutated_rows] != srs_mut.loc[srs_mutated_rows]).all()\n    assert (srs.loc[~srs_mutated_rows] == srs_mut.loc[~srs_mutated_rows]).all()"
            },
            "tests/test_mutator.py::test_with_categorical_values_raise_too_few_values": {
                "testid": "tests/test_mutator.py::test_with_categorical_values_raise_too_few_values",
                "result": "passed",
                "test_implementation": "def test_with_categorical_values_raise_too_few_values(rng):\n    df_cat = pd.DataFrame.from_dict({\"values\": list(\"a\")})\n\n    with pytest.raises(ValueError) as e:\n        _ = mutator.with_categorical_values(df_cat, value_column=\"values\", rng=rng)\n\n    assert str(e.value) == \"column must contain at least two unique values, has 1\""
            },
            "tests/test_mutator.py::test_with_categorical_values_csv": {
                "testid": "tests/test_mutator.py::test_with_categorical_values_csv",
                "result": "passed",
                "test_implementation": "def test_with_categorical_values_csv(rng, tmp_path):\n    srs = pd.Series(list(string.ascii_letters))\n    csv_file_path = write_temporary_csv_file(\n        tmp_path,\n        header=[\"values\"],\n        rows=list(string.ascii_letters),\n    )\n\n    mut_categorical = mutator.with_categorical_values(csv_file_path, value_column=\"values\", rng=rng)\n\n    (srs_mut,) = mut_categorical([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()"
            },
            "tests/test_mutator.py::test_with_datetime_offset[d]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset[d]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset(rng, unit):\n    srs = pd.Series(pd.date_range(\"2020-01-01\", \"2021-01-01\", freq=\"h\", inclusive=\"left\"))\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", rng=rng)\n    (srs_mut,) = mut_datetime_offset([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()"
            },
            "tests/test_mutator.py::test_with_datetime_offset[days]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset[days]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset(rng, unit):\n    srs = pd.Series(pd.date_range(\"2020-01-01\", \"2021-01-01\", freq=\"h\", inclusive=\"left\"))\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", rng=rng)\n    (srs_mut,) = mut_datetime_offset([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()"
            },
            "tests/test_mutator.py::test_with_datetime_offset[h]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset[h]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset(rng, unit):\n    srs = pd.Series(pd.date_range(\"2020-01-01\", \"2021-01-01\", freq=\"h\", inclusive=\"left\"))\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", rng=rng)\n    (srs_mut,) = mut_datetime_offset([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()"
            },
            "tests/test_mutator.py::test_with_datetime_offset[hours]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset[hours]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset(rng, unit):\n    srs = pd.Series(pd.date_range(\"2020-01-01\", \"2021-01-01\", freq=\"h\", inclusive=\"left\"))\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", rng=rng)\n    (srs_mut,) = mut_datetime_offset([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()"
            },
            "tests/test_mutator.py::test_with_datetime_offset[m]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset[m]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset(rng, unit):\n    srs = pd.Series(pd.date_range(\"2020-01-01\", \"2021-01-01\", freq=\"h\", inclusive=\"left\"))\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", rng=rng)\n    (srs_mut,) = mut_datetime_offset([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()"
            },
            "tests/test_mutator.py::test_with_datetime_offset[minutes]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset[minutes]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset(rng, unit):\n    srs = pd.Series(pd.date_range(\"2020-01-01\", \"2021-01-01\", freq=\"h\", inclusive=\"left\"))\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", rng=rng)\n    (srs_mut,) = mut_datetime_offset([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()"
            },
            "tests/test_mutator.py::test_with_datetime_offset[s]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset[s]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset(rng, unit):\n    srs = pd.Series(pd.date_range(\"2020-01-01\", \"2021-01-01\", freq=\"h\", inclusive=\"left\"))\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", rng=rng)\n    (srs_mut,) = mut_datetime_offset([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()"
            },
            "tests/test_mutator.py::test_with_datetime_offset[seconds]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset[seconds]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset(rng, unit):\n    srs = pd.Series(pd.date_range(\"2020-01-01\", \"2021-01-01\", freq=\"h\", inclusive=\"left\"))\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", rng=rng)\n    (srs_mut,) = mut_datetime_offset([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()"
            },
            "tests/test_mutator.py::test_with_datetime_offset_partial[d]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset_partial[d]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset_partial(rng, unit):\n    srs = pd.Series(pd.date_range(\"2020-01-01\", \"2021-01-01\", freq=\"h\", inclusive=\"left\"))\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", rng=rng)\n    (srs_mut,) = mut_datetime_offset([srs], 0.5)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs == srs_mut).any()\n    assert (srs != srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_datetime_offset_partial[days]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset_partial[days]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset_partial(rng, unit):\n    srs = pd.Series(pd.date_range(\"2020-01-01\", \"2021-01-01\", freq=\"h\", inclusive=\"left\"))\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", rng=rng)\n    (srs_mut,) = mut_datetime_offset([srs], 0.5)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs == srs_mut).any()\n    assert (srs != srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_datetime_offset_partial[h]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset_partial[h]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset_partial(rng, unit):\n    srs = pd.Series(pd.date_range(\"2020-01-01\", \"2021-01-01\", freq=\"h\", inclusive=\"left\"))\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", rng=rng)\n    (srs_mut,) = mut_datetime_offset([srs], 0.5)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs == srs_mut).any()\n    assert (srs != srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_datetime_offset_partial[hours]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset_partial[hours]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset_partial(rng, unit):\n    srs = pd.Series(pd.date_range(\"2020-01-01\", \"2021-01-01\", freq=\"h\", inclusive=\"left\"))\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", rng=rng)\n    (srs_mut,) = mut_datetime_offset([srs], 0.5)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs == srs_mut).any()\n    assert (srs != srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_datetime_offset_partial[m]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset_partial[m]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset_partial(rng, unit):\n    srs = pd.Series(pd.date_range(\"2020-01-01\", \"2021-01-01\", freq=\"h\", inclusive=\"left\"))\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", rng=rng)\n    (srs_mut,) = mut_datetime_offset([srs], 0.5)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs == srs_mut).any()\n    assert (srs != srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_datetime_offset_partial[minutes]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset_partial[minutes]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset_partial(rng, unit):\n    srs = pd.Series(pd.date_range(\"2020-01-01\", \"2021-01-01\", freq=\"h\", inclusive=\"left\"))\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", rng=rng)\n    (srs_mut,) = mut_datetime_offset([srs], 0.5)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs == srs_mut).any()\n    assert (srs != srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_datetime_offset_partial[s]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset_partial[s]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset_partial(rng, unit):\n    srs = pd.Series(pd.date_range(\"2020-01-01\", \"2021-01-01\", freq=\"h\", inclusive=\"left\"))\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", rng=rng)\n    (srs_mut,) = mut_datetime_offset([srs], 0.5)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs == srs_mut).any()\n    assert (srs != srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_datetime_offset_partial[seconds]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset_partial[seconds]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset_partial(rng, unit):\n    srs = pd.Series(pd.date_range(\"2020-01-01\", \"2021-01-01\", freq=\"h\", inclusive=\"left\"))\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", rng=rng)\n    (srs_mut,) = mut_datetime_offset([srs], 0.5)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs == srs_mut).any()\n    assert (srs != srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[d]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[d]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset_prevent_wraparound(rng, unit):\n    srs = pd.Series([\"2020-01-01 00:00:00\"] * 1_000)\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", prevent_wraparound=True, rng=rng)\n\n    with pytest.warns(GeckoWarning) as record:\n        (srs_mut,) = mut_datetime_offset([srs], 1)\n\n    assert len(record) == 1\n    assert record[0].message.args[0].startswith(\"with_datetime_offset: desired probability of 1 cannot be met\")\n\n    assert len(srs) == len(srs_mut)\n    assert not (srs != srs_mut).all()\n    assert (srs == srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[days]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[days]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset_prevent_wraparound(rng, unit):\n    srs = pd.Series([\"2020-01-01 00:00:00\"] * 1_000)\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", prevent_wraparound=True, rng=rng)\n\n    with pytest.warns(GeckoWarning) as record:\n        (srs_mut,) = mut_datetime_offset([srs], 1)\n\n    assert len(record) == 1\n    assert record[0].message.args[0].startswith(\"with_datetime_offset: desired probability of 1 cannot be met\")\n\n    assert len(srs) == len(srs_mut)\n    assert not (srs != srs_mut).all()\n    assert (srs == srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[h]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[h]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset_prevent_wraparound(rng, unit):\n    srs = pd.Series([\"2020-01-01 00:00:00\"] * 1_000)\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", prevent_wraparound=True, rng=rng)\n\n    with pytest.warns(GeckoWarning) as record:\n        (srs_mut,) = mut_datetime_offset([srs], 1)\n\n    assert len(record) == 1\n    assert record[0].message.args[0].startswith(\"with_datetime_offset: desired probability of 1 cannot be met\")\n\n    assert len(srs) == len(srs_mut)\n    assert not (srs != srs_mut).all()\n    assert (srs == srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[hours]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[hours]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset_prevent_wraparound(rng, unit):\n    srs = pd.Series([\"2020-01-01 00:00:00\"] * 1_000)\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", prevent_wraparound=True, rng=rng)\n\n    with pytest.warns(GeckoWarning) as record:\n        (srs_mut,) = mut_datetime_offset([srs], 1)\n\n    assert len(record) == 1\n    assert record[0].message.args[0].startswith(\"with_datetime_offset: desired probability of 1 cannot be met\")\n\n    assert len(srs) == len(srs_mut)\n    assert not (srs != srs_mut).all()\n    assert (srs == srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[m]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[m]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset_prevent_wraparound(rng, unit):\n    srs = pd.Series([\"2020-01-01 00:00:00\"] * 1_000)\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", prevent_wraparound=True, rng=rng)\n\n    with pytest.warns(GeckoWarning) as record:\n        (srs_mut,) = mut_datetime_offset([srs], 1)\n\n    assert len(record) == 1\n    assert record[0].message.args[0].startswith(\"with_datetime_offset: desired probability of 1 cannot be met\")\n\n    assert len(srs) == len(srs_mut)\n    assert not (srs != srs_mut).all()\n    assert (srs == srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[minutes]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[minutes]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset_prevent_wraparound(rng, unit):\n    srs = pd.Series([\"2020-01-01 00:00:00\"] * 1_000)\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", prevent_wraparound=True, rng=rng)\n\n    with pytest.warns(GeckoWarning) as record:\n        (srs_mut,) = mut_datetime_offset([srs], 1)\n\n    assert len(record) == 1\n    assert record[0].message.args[0].startswith(\"with_datetime_offset: desired probability of 1 cannot be met\")\n\n    assert len(srs) == len(srs_mut)\n    assert not (srs != srs_mut).all()\n    assert (srs == srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[s]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[s]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset_prevent_wraparound(rng, unit):\n    srs = pd.Series([\"2020-01-01 00:00:00\"] * 1_000)\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", prevent_wraparound=True, rng=rng)\n\n    with pytest.warns(GeckoWarning) as record:\n        (srs_mut,) = mut_datetime_offset([srs], 1)\n\n    assert len(record) == 1\n    assert record[0].message.args[0].startswith(\"with_datetime_offset: desired probability of 1 cannot be met\")\n\n    assert len(srs) == len(srs_mut)\n    assert not (srs != srs_mut).all()\n    assert (srs == srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[seconds]": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound[seconds]",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset_prevent_wraparound(rng, unit):\n    srs = pd.Series([\"2020-01-01 00:00:00\"] * 1_000)\n    mut_datetime_offset = mutator.with_datetime_offset(5, unit, \"%Y-%m-%d %H:%M:%S\", prevent_wraparound=True, rng=rng)\n\n    with pytest.warns(GeckoWarning) as record:\n        (srs_mut,) = mut_datetime_offset([srs], 1)\n\n    assert len(record) == 1\n    assert record[0].message.args[0].startswith(\"with_datetime_offset: desired probability of 1 cannot be met\")\n\n    assert len(srs) == len(srs_mut)\n    assert not (srs != srs_mut).all()\n    assert (srs == srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_datetime_offset_custom_format": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset_custom_format",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset_custom_format(rng):\n    srs = pd.Series(pd.date_range(\"2020-01-01\", periods=28, freq=\"D\")).dt.strftime(\"%d.%m.%Y\")\n    mut_datetime_offset = mutator.with_datetime_offset(5, \"d\", \"%d.%m.%Y\", rng=rng)\n    (srs_mut,) = mut_datetime_offset([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert srs_mut.str.fullmatch(r\"\\d{2}.\\d{2}.\\d{4}\").all()"
            },
            "tests/test_mutator.py::test_with_datetime_offset_raise_invalid_delta": {
                "testid": "tests/test_mutator.py::test_with_datetime_offset_raise_invalid_delta",
                "result": "passed",
                "test_implementation": "def test_with_datetime_offset_raise_invalid_delta(rng):\n    with pytest.raises(ValueError) as e:\n        _ = mutator.with_datetime_offset(0, \"d\", \"%Y-%m-%d\", rng=rng)\n\n    assert str(e.value) == \"delta must be positive, is 0\""
            },
            "tests/test_mutator.py::test_with_phonetic_replacement_table": {
                "testid": "tests/test_mutator.py::test_with_phonetic_replacement_table",
                "result": "passed",
                "test_implementation": "def test_with_phonetic_replacement_table(rng):\n    srs = pd.Series([\"\".join(tpl) for tpl in itertools.permutations(\"abc\")])\n    df_phon = pd.DataFrame.from_dict({\"source\": list(\"abcbcca\"), \"target\": list(\"0123456\"), \"flags\": list(\"^^^$$__\")})\n\n    mut_phonetic = mutator.with_phonetic_replacement_table(\n        df_phon,\n        source_column=\"source\",\n        target_column=\"target\",\n        flags_column=\"flags\",\n        rng=rng,\n    )\n\n    (srs_mut,) = mut_phonetic([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert not srs_mut.str.isalpha().all()"
            },
            "tests/test_mutator.py::test_with_phonetic_replacement_table_random_values": {
                "testid": "tests/test_mutator.py::test_with_phonetic_replacement_table_random_values",
                "result": "passed",
                "test_implementation": "def test_with_phonetic_replacement_table_random_values(rng):\n    srs = pd.Series([\"aaa\"] * 1_000)\n    df_phon = pd.DataFrame.from_dict({\"source\": [\"a\", \"a\", \"a\"], \"target\": [\"0\", \"1\", \"2\"], \"flags\": [\"^\", \"_\", \"$\"]})\n\n    mut_phonetic = mutator.with_phonetic_replacement_table(\n        df_phon,\n        source_column=\"source\",\n        target_column=\"target\",\n        flags_column=\"flags\",\n        rng=rng,\n    )\n\n    (srs_mut,) = mut_phonetic([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert len(srs_mut.unique()) == 3"
            },
            "tests/test_mutator.py::test_with_phonetic_replacement_table_partial": {
                "testid": "tests/test_mutator.py::test_with_phonetic_replacement_table_partial",
                "result": "passed",
                "test_implementation": "def test_with_phonetic_replacement_table_partial(rng):\n    srs = pd.Series([\"\".join(tpl) for tpl in itertools.permutations(\"abc\")])\n    df_phon = pd.DataFrame.from_dict({\"source\": list(\"abcbcca\"), \"target\": list(\"0123456\"), \"flags\": list(\"^^^$$__\")})\n\n    mut_phonetic = mutator.with_phonetic_replacement_table(\n        df_phon,\n        source_column=\"source\",\n        target_column=\"target\",\n        flags_column=\"flags\",\n        rng=rng,\n    )\n\n    (srs_mut,) = mut_phonetic([srs], 0.5)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs == srs_mut).any()\n    assert (srs != srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_phonetic_replacement_table_no_flags": {
                "testid": "tests/test_mutator.py::test_with_phonetic_replacement_table_no_flags",
                "result": "passed",
                "test_implementation": "def test_with_phonetic_replacement_table_no_flags(rng):\n    # no flag defaults to all flags enabled. generate a list of strings where all characters a-z\n    # are shuffled.\n    srs = pd.Series(\n        random_strings(\n            charset=string.ascii_lowercase,\n            str_len=len(string.ascii_lowercase),\n            unique=True,\n            rng=rng,\n        )\n    )\n\n    df_phon = pd.DataFrame.from_dict({\"source\": [\"a\"], \"target\": [\"0\"], \"flags\": [\"\"]})\n\n    mut_phonetic = mutator.with_phonetic_replacement_table(\n        df_phon,\n        source_column=\"source\",\n        target_column=\"target\",\n        flags_column=\"flags\",\n        rng=rng,\n    )\n\n    (srs_mut,) = mut_phonetic([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert not srs_mut.str.isalpha().all()"
            },
            "tests/test_mutator.py::test_with_phonetic_replacement_table_csv": {
                "testid": "tests/test_mutator.py::test_with_phonetic_replacement_table_csv",
                "result": "passed",
                "test_implementation": "def test_with_phonetic_replacement_table_csv(rng, tmp_path):\n    # same as regular test except this one is based on a csv file\n    srs = pd.Series([\"\".join(tpl) for tpl in itertools.permutations(\"abc\")])\n    csv_file_path = write_temporary_csv_file(\n        tmp_path,\n        header=[\"source\", \"target\", \"flags\"],\n        rows=list(zip(\"abcbcca\", \"0123456\", \"^^^$$__\")),\n    )\n\n    mut_phonetic = mutator.with_phonetic_replacement_table(\n        csv_file_path,\n        source_column=\"source\",\n        target_column=\"target\",\n        flags_column=\"flags\",\n        rng=rng,\n    )\n\n    (srs_mut,) = mut_phonetic([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert not srs_mut.str.isalpha().all()"
            },
            "tests/test_mutator.py::test_with_phonetic_replacement_table_warn_p": {
                "testid": "tests/test_mutator.py::test_with_phonetic_replacement_table_warn_p",
                "result": "passed",
                "test_implementation": "def test_with_phonetic_replacement_table_warn_p(rng):\n    srs = pd.Series([\"abc\", \"def\"] * 100)\n    df_phon = pd.DataFrame.from_dict({\"source\": [\"a\"], \"target\": [\"0\"], \"flags\": [\"^\"]})\n\n    mut_phonetic = mutator.with_phonetic_replacement_table(\n        df_phon,\n        source_column=\"source\",\n        target_column=\"target\",\n        flags_column=\"flags\",\n        rng=rng,\n    )\n\n    with pytest.warns(GeckoWarning) as record:\n        (srs_mut,) = mut_phonetic([srs], 0.8)\n\n    assert len(record) == 1\n    assert (\n        record[0]\n        .message.args[0]\n        .startswith(\"with_phonetic_replacement_table: desired probability of 0.8 cannot be met\")\n    )\n\n    srs_mutated_rows = srs.str.startswith(\"a\")\n\n    assert (srs.loc[srs_mutated_rows] != srs_mut.loc[srs_mutated_rows]).all()\n    assert (srs.loc[~srs_mutated_rows] == srs_mut.loc[~srs_mutated_rows]).all()"
            },
            "tests/test_mutator.py::test_with_phonetic_replacement_table_raise_no_rules": {
                "testid": "tests/test_mutator.py::test_with_phonetic_replacement_table_raise_no_rules",
                "result": "passed",
                "test_implementation": "def test_with_phonetic_replacement_table_raise_no_rules(rng):\n    with pytest.raises(ValueError) as e:\n        _ = mutator.with_phonetic_replacement_table(\n            pd.DataFrame.from_dict(\n                {\n                    \"source\": [],\n                    \"target\": [],\n                    \"flags\": [],\n                }\n            ),\n            source_column=\"source\",\n            target_column=\"target\",\n            flags_column=\"flags\",\n        )\n\n    assert str(e.value) == \"must provide at least one phonetic replacement rule\""
            },
            "tests/test_mutator.py::test_with_regex_replacement_table_unnamed_capture_group": {
                "testid": "tests/test_mutator.py::test_with_regex_replacement_table_unnamed_capture_group",
                "result": "passed",
                "test_implementation": "def test_with_regex_replacement_table_unnamed_capture_group(rng):\n    srs = pd.Series([\"abc\", \"def\"] * 100)\n    df_table = pd.DataFrame.from_dict({\"pattern\": [\"a(bc)\", \"d(ef)\"], \"1\": [\"1\", \"2\"]})\n    mut_regex = mutator.with_regex_replacement_table(df_table, pattern_column=\"pattern\", rng=rng)\n\n    (srs_mut,) = mut_regex([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert not srs_mut.str.isalpha().all()"
            },
            "tests/test_mutator.py::test_with_regex_replacement_table_favor_rare_regexes": {
                "testid": "tests/test_mutator.py::test_with_regex_replacement_table_favor_rare_regexes",
                "result": "passed",
                "test_implementation": "def test_with_regex_replacement_table_favor_rare_regexes(rng):\n    srs = pd.Series([\"abc\"] * 100 + [\"def\"] * 50)\n    df_table = pd.DataFrame.from_dict({\"pattern\": [\"a(bc)\", \"d(ef)\"], \"1\": [\"1\", \"2\"]})\n    mut_regex = mutator.with_regex_replacement_table(df_table, pattern_column=\"pattern\", rng=rng)\n\n    (srs_mut,) = mut_regex([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert (srs_mut == [\"a1\"] * 100 + [\"d2\"] * 50).all()"
            },
            "tests/test_mutator.py::test_with_regex_replacement_table_unnamed_capture_group_partial": {
                "testid": "tests/test_mutator.py::test_with_regex_replacement_table_unnamed_capture_group_partial",
                "result": "passed",
                "test_implementation": "def test_with_regex_replacement_table_unnamed_capture_group_partial(rng):\n    srs = pd.Series([\"abc\", \"def\"] * 100)\n\n    df_table = pd.DataFrame.from_dict({\"pattern\": [\"a(bc)\", \"d(ef)\"], \"1\": [\"1\", \"2\"]})\n\n    mut_regex = mutator.with_regex_replacement_table(df_table, pattern_column=\"pattern\", rng=rng)\n\n    (srs_mut,) = mut_regex([srs], 0.5)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs == srs_mut).any()\n    assert (srs != srs_mut).any()"
            },
            "tests/test_mutator.py::test_with_regex_replacement_table_named_capture_group": {
                "testid": "tests/test_mutator.py::test_with_regex_replacement_table_named_capture_group",
                "result": "passed",
                "test_implementation": "def test_with_regex_replacement_table_named_capture_group(rng):\n    srs = pd.Series([\"abc\", \"def\"] * 100)\n\n    df_table = pd.DataFrame.from_dict({\"pattern\": [\"a(?P<foo>bc)\", \"d(?P<foo>ef)\"], \"foo\": [\"1\", \"2\"]})\n\n    mut_regex = mutator.with_regex_replacement_table(df_table, pattern_column=\"pattern\", rng=rng)\n\n    (srs_mut,) = mut_regex([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert not srs_mut.str.isalpha().all()"
            },
            "tests/test_mutator.py::test_with_regex_replacement_table_flags": {
                "testid": "tests/test_mutator.py::test_with_regex_replacement_table_flags",
                "result": "passed",
                "test_implementation": "def test_with_regex_replacement_table_flags(rng):\n    srs = pd.Series([\"abc\", \"def\", \"ABC\", \"DEF\"] * 100)\n\n    df_table = pd.DataFrame.from_dict(\n        {\n            \"pattern\": [\"a(bc)\", \"d(ef)\"],\n            \"1\": [\"1\", \"2\"],\n            \"flags\": [\"i\", \"i\"],  # ignore case flag\n        }\n    )\n\n    mut_regex = mutator.with_regex_replacement_table(df_table, pattern_column=\"pattern\", flags_column=\"flags\", rng=rng)\n\n    (srs_mut,) = mut_regex([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert not srs_mut.str.isalpha().all()"
            },
            "tests/test_mutator.py::test_with_regex_replacement_table_warn_p": {
                "testid": "tests/test_mutator.py::test_with_regex_replacement_table_warn_p",
                "result": "passed",
                "test_implementation": "def test_with_regex_replacement_table_warn_p(rng):\n    srs = pd.Series([\"abc\", \"def\"] * 100)\n\n    df_table = pd.DataFrame.from_dict({\"pattern\": [\"a(bc)\"], \"1\": [\"1\"]})\n\n    mut_regex = mutator.with_regex_replacement_table(df_table, pattern_column=\"pattern\", rng=rng)\n\n    with pytest.warns(GeckoWarning) as record:\n        (srs_mut,) = mut_regex([srs], 0.8)\n\n    assert len(record) == 1\n    assert (\n        record[0].message.args[0].startswith(\"with_regex_replacement_table: desired probability of 0.8 cannot be met\")\n    )\n\n    srs_mutated_rows = srs.str.startswith(\"a\")\n\n    assert (srs.loc[srs_mutated_rows] != srs_mut.loc[srs_mutated_rows]).all()\n    assert (srs.loc[~srs_mutated_rows] == srs.loc[~srs_mutated_rows]).all()"
            },
            "tests/test_mutator.py::test_with_regex_replacement_table_raise_no_rules": {
                "testid": "tests/test_mutator.py::test_with_regex_replacement_table_raise_no_rules",
                "result": "passed",
                "test_implementation": "def test_with_regex_replacement_table_raise_no_rules(rng):\n    with pytest.raises(ValueError) as e:\n        _ = mutator.with_regex_replacement_table(pd.DataFrame({\"pattern\": []}), pattern_column=\"pattern\", rng=rng)\n\n    assert str(e.value) == \"must provide at least one regex pattern\""
            },
            "tests/test_mutator.py::test_with_regex_replacement_table_csv": {
                "testid": "tests/test_mutator.py::test_with_regex_replacement_table_csv",
                "result": "passed",
                "test_implementation": "def test_with_regex_replacement_table_csv(rng, tmp_path):\n    srs = pd.Series([\"abc\", \"def\"] * 100)\n    csv_path = write_temporary_csv_file(\n        tmp_path,\n        header=[\"pattern\", \"1\"],\n        rows=[\n            [\"a(bc)\", \"1\"],\n            [\"d(ef)\", \"2\"],\n        ],\n    )\n\n    mut_regex = mutator.with_regex_replacement_table(csv_path, pattern_column=\"pattern\", rng=rng)\n\n    (srs_mut,) = mut_regex([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert not srs_mut.str.isalpha().all()"
            },
            "tests/test_mutator.py::test_with_regex_replacement_table_partial[pattern0]": {
                "testid": "tests/test_mutator.py::test_with_regex_replacement_table_partial[pattern0]",
                "result": "passed",
                "test_implementation": "def test_with_regex_replacement_table_partial(rng, pattern):\n    srs = pd.Series([\"aaa\", \"bbb\", \"ccc\"])\n    mut_regex = mutator.with_regex_replacement_table(\n        pd.DataFrame.from_dict(\n            {\n                \"pattern\": pattern,\n                \"value\": [\"0\", \"1\", \"2\"],\n            }\n        ),\n        pattern_column=\"pattern\",\n        rng=rng,\n    )\n\n    (srs_mut,) = mut_regex([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert (srs_mut == [\"0aa\", \"b1b\", \"cc2\"]).all()"
            },
            "tests/test_mutator.py::test_with_regex_replacement_table_partial[pattern1]": {
                "testid": "tests/test_mutator.py::test_with_regex_replacement_table_partial[pattern1]",
                "result": "passed",
                "test_implementation": "def test_with_regex_replacement_table_partial(rng, pattern):\n    srs = pd.Series([\"aaa\", \"bbb\", \"ccc\"])\n    mut_regex = mutator.with_regex_replacement_table(\n        pd.DataFrame.from_dict(\n            {\n                \"pattern\": pattern,\n                \"value\": [\"0\", \"1\", \"2\"],\n            }\n        ),\n        pattern_column=\"pattern\",\n        rng=rng,\n    )\n\n    (srs_mut,) = mut_regex([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert (srs_mut == [\"0aa\", \"b1b\", \"cc2\"]).all()"
            },
            "tests/test_mutator.py::test_with_regex_replacement_table_random_values": {
                "testid": "tests/test_mutator.py::test_with_regex_replacement_table_random_values",
                "result": "passed",
                "test_implementation": "def test_with_regex_replacement_table_random_values(rng):\n    srs = pd.Series([\"aaa\"] * 1_000)\n    df_regex_replacement_table = pd.DataFrame.from_dict({\"pattern\": [\".(a).\", \".(a).\", \".(a).\"], \"1\": [\"0\", \"1\", \"2\"]})\n\n    mut_regex_replacement_table = mutator.with_regex_replacement_table(\n        df_regex_replacement_table,\n        pattern_column=\"pattern\",\n        rng=rng,\n    )\n\n    (srs_mut,) = mut_regex_replacement_table([srs], 1)\n\n    assert len(srs) == len(srs_mut)\n    assert (srs != srs_mut).all()\n    assert len(srs_mut.unique()) == 3"
            },
            "tests/test_mutator.py::test_mutate_data_frame": {
                "testid": "tests/test_mutator.py::test_mutate_data_frame",
                "result": "passed",
                "test_implementation": "def test_mutate_data_frame(rng):\n    lowercase_char_count = len(string.ascii_lowercase)\n\n    def random_unique_lowercase_strings():\n        return random_strings(\n            n_strings=100_000,\n            str_len=lowercase_char_count,\n            charset=string.ascii_lowercase,\n            unique=True,\n            rng=rng,\n        )\n\n    df = pd.DataFrame.from_dict(\n        {\n            \"col_1\": random_unique_lowercase_strings(),\n            \"col_2\": random_unique_lowercase_strings(),\n            \"col_3\": random_unique_lowercase_strings(),\n            \"col_4\": random_unique_lowercase_strings(),\n        }\n    )\n\n    df_mut = mutator.mutate_data_frame(\n        df,\n        [\n            # col 1 should have these mutators applied to all rows\n            (\n                \"col_1\",\n                [\n                    mutator.with_delete(rng=rng),\n                    mutator.with_uppercase(rng=rng),\n                ],\n            ),\n            # col 2 should have these mutators applied to approx. 50% of all rows\n            (\n                \"col_2\",\n                [\n                    (0.5, mutator.with_insert(charset=string.ascii_uppercase, rng=rng)),\n                ],\n            ),\n            # col 3 and 4 should be permuted\n            ((\"col_3\", \"col_4\"), mutator.with_permute(rng=rng)),\n        ],\n    )\n\n    # for col_1, ensure that all mutators were applied\n    assert (df[\"col_1\"] != df_mut[\"col_1\"]).all()\n\n    assert (df_mut[\"col_1\"].str.len() == lowercase_char_count - 1).all()\n    assert df_mut[\"col_1\"].str.upper().all()\n\n    # for col_2, check that the amount of mutated and untouched columns roughly matches\n    df_mut_col_2_str_lens = df_mut[\"col_2\"].str.len().value_counts()\n\n    assert (\n        abs(df_mut_col_2_str_lens[lowercase_char_count] - df_mut_col_2_str_lens[lowercase_char_count + 1])\n        / len(df_mut[\"col_1\"])\n        < 0.01\n    )\n\n    # for col_3 and col_4, check that the columns were correctly permuted\n    assert (df_mut[\"col_3\"] == df[\"col_4\"]).all()\n    assert (df_mut[\"col_4\"] == df[\"col_3\"]).all()"
            }
        },
        "SRS_document": "# Software Requirements Specification: Gecko Data Generation and Mutation Library\n\n## Table of Contents\n\n1.  [Introduction](#1-introduction)\n    1.1. [Purpose](#11-purpose)\n    1.2. [Scope](#12-scope)\n    1.3. [Definitions, Acronyms, and Abbreviations](#13-definitions-acronyms-and-abbreviations)\n    1.4. [References](#14-references)\n    1.5. [Overview](#15-overview)\n2.  [Overall Description](#2-overall-description)\n    2.1. [Product Perspective](#21-product-perspective)\n    2.2. [Product Functions](#22-product-functions)\n    2.3. [User Characteristics](#23-user-characteristics)\n    2.4. [Constraints](#24-constraints)\n    2.5. [Assumptions and Dependencies](#25-assumptions-and-dependencies)\n3.  [Specific Requirements](#3-specific-requirements)\n    3.1. [Functional Requirements](#31-functional-requirements)\n        3.1.1. [Data Generation (Generator Module)](#311-data-generation-generator-module)\n        3.1.2. [Data Mutation (Mutator Module)](#312-data-mutation-mutator-module)\n        3.1.3. [General System Functionality](#313-general-system-functionality)\n    3.2. [Non-Functional Requirements](#32-non-functional-requirements)\n    3.3. [External Interface Requirements](#33-external-interface-requirements)\n    3.4. [Other Requirements](#34-other-requirements)\n        3.4.1. [Error Handling](#341-error-handling)\n\n## 1. Introduction\n\n### 1.1. Purpose\nThis Software Requirements Specification (SRS) document defines the requirements for the Gecko Data Generation and Mutation Library. Its primary role is to serve as the sole source of requirements for software developers who will be assessed on their ability to implement a complete, functional software project based on this SRS. The final implementation will be verified against a comprehensive set of original test cases, including private tests not provided during development.\n\n### 1.2. Scope\nThe Gecko library is designed for the bulk generation and mutation of realistic personal data. It provides functionalities to:\n*   Generate synthetic datasets based on various inputs like frequency tables, statistical distributions, or custom functions.\n*   Introduce deliberate errors (mutations) into datasets to simulate real-world data imperfections, such as typos, OCR errors, or value replacements.\nThe library consists of two main modules: `generator` for data creation and `mutator` for data modification.\n\n### 1.3. Definitions, Acronyms, and Abbreviations\n*   **SRS:** Software Requirements Specification\n*   **RNG:** Random Number Generator\n*   **CLDR:** Common Locale Data Repository (typically XML files describing keyboard layouts and other locale data)\n*   **CSV:** Comma-Separated Values\n*   **DataFrame:** Pandas DataFrame, a 2-dimensional labeled data structure.\n*   **Series:** Pandas Series, a 1-dimensional labeled array.\n*   **SUT:** System Under Test (the Gecko library)\n\n### 1.4. References\n*   Original Gecko README.md (provided as context)\n*   Original Gecko source code (provided as context for SRS generation only)\n*   Original Gecko test suite (provided as context for SRS generation and partially to developers)\n\n### 1.5. Overview\nThis document is organized into three main sections:\n*   **Section 1 (Introduction):** Provides purpose, scope, definitions, and an overview of the SRS.\n*   **Section 2 (Overall Description):** Describes the product perspective, its functions, user characteristics, and constraints.\n*   **Section 3 (Specific Requirements):** Details all functional requirements, non-functional requirements (if any meet the strict criteria), external interface requirements, and other requirements such as error handling. This section forms the core of the specification for developers.\n\n## 2. Overall Description\n\n### 2.1. Product Perspective\nGecko is a Python library intended to be used by other developers or data scientists who need to create synthetic datasets or introduce controlled errors into existing datasets, particularly for testing record linkage algorithms or other data processing pipelines. It builds upon concepts from the original GeCo framework but offers a modernized API, improved performance using NumPy and Pandas, and enhanced reproducibility.\n\n### 2.2. Product Functions\nThe Gecko library provides the following key functional capabilities:\n1.  **Data Generation:**\n    *   Creation of data columns from custom Python functions.\n    *   Generation of numeric data from uniform or normal distributions.\n    *   Generation of data based on single or multi-column frequency tables (from CSV files or DataFrames), preserving specified distributions and inter-column dependencies.\n    *   Generation of datetime strings within a specified range, format, and granularity.\n    *   Combination of multiple data generators, with optional weighting, to produce composite datasets.\n    *   Assembly of generated data columns into a Pandas DataFrame.\n2.  **Data Mutation:**\n    *   Modification of data columns using custom Python functions.\n    *   Introduction of keyboard-based typos using CLDR keymap files.\n    *   Phonetic replacement of character sequences based on configurable rules.\n    *   General string replacement based on configurable tables.\n    *   Replacement of values with a designated \"missing\" value.\n    *   Structural string edits: character insertion, deletion, transposition, and substitution.\n    *   Conversion of string case (to uppercase or lowercase).\n    *   Replacement of categorical values with other values from the same category set.\n    *   Permutation of values across multiple columns for the same record.\n    *   Offsetting of datetime values by random amounts.\n    *   Mutation by replacing, prepending, or appending data generated from another generator.\n    *   Regex-based string replacements using configurable rules.\n    *   Duplication (repetition) of string content.\n    *   Application of a group of different mutators based on specified probabilities.\n    *   Targeted application of various mutations to specific columns within a Pandas DataFrame.\n3.  **Reproducibility:**\n    *   All random operations are controlled by a configurable Random Number Generator (RNG), allowing for reproducible outputs when the RNG is seeded.\n\n### 2.3. User Characteristics\nThe primary users of this library are Python developers and data scientists who:\n*   Need to generate synthetic data for software testing, particularly in data-intensive applications like record linkage.\n*   Require the ability to introduce a variety of controlled, realistic errors into datasets.\n*   Are comfortable working with Python, Pandas DataFrames, and statistical concepts for data generation.\n\n### 2.4. Constraints\n*   The system shall be implemented as a Python library.\n*   The system's external data structures for batch processing (input/output of primary functions like `to_data_frame` and `mutate_data_frame`, and internal representation for generator/mutator chains) shall be Pandas DataFrames and Series, as specified in [Section 3.3 External Interface Requirements](#33-external-interface-requirements).\n*   The system relies on external data formats for configuration where specified (e.g., CSV for frequency tables, CLDR XML for keymaps).\n\n### 2.5. Assumptions and Dependencies\n*   Users are expected to provide valid input data sources (e.g., correctly formatted CSV files, CLDR files).\n*   The library is intended for use in a standard Python environment where Pandas and NumPy libraries are available.\n\n## 3. Specific Requirements\n\n### 3.1. Functional Requirements\nFunctional requirements are identified by a unique ID (FR-XXX-YYY-ZZZ).\n\n#### 3.1.1. Data Generation (Generator Module)\n\n*   **FR-GEN-FUNC-001:** Generate data from a custom Python function.\n    *   The system shall provide a mechanism to generate a series of string values by repeatedly invoking a user-supplied Python callable.\n    *   **Inputs:** A Python callable that returns a string, the number of items to generate, an optional Random Number Generator (RNG), and any additional positional or keyword arguments to be passed to the user's callable.\n    *   **Output:** A list containing one Pandas Series, where each element is a string generated by one call to the user's function.\n\n*   **FR-GEN-UDIST-001:** Generate string representations of numbers from a uniform distribution.\n    *   The system shall generate a series of numbers drawn from a uniform distribution and format them as strings.\n    *   **Inputs:** Lower bound (inclusive, int or float), upper bound (exclusive, int or float), decimal precision for formatting (int), number of items to generate, and an optional RNG. Default bounds [0, 1), default precision 6.\n    *   **Output:** A list containing one Pandas Series of string-formatted numbers.\n\n*   **FR-GEN-NDIST-001:** Generate string representations of numbers from a normal distribution.\n    *   The system shall generate a series of numbers drawn from a normal (Gaussian) distribution and format them as strings.\n    *   **Inputs:** Mean (float), standard deviation (float), decimal precision for formatting (int), number of items to generate, and an optional RNG. Default mean 0, sd 1, precision 6.\n    *   **Output:** A list containing one Pandas Series of string-formatted numbers.\n\n*   **FR-GEN-FTBL-001:** Generate data from a single-column frequency table.\n    *   The system shall generate a series of values whose distribution approximates the frequencies specified in an input frequency table.\n    *   **Inputs:**\n        *   `data_source`: A path to a CSV file or a Pandas DataFrame.\n        *   `value_column`: Identifier (name or index) of the column containing values to generate.\n        *   `freq_column`: Identifier (name or index) of the column containing absolute frequencies.\n        *   Number of items to generate.\n        *   Optional: RNG, CSV file encoding (default 'utf-8'), CSV delimiter (default ',').\n    *   **Output:** A list containing one Pandas Series.\n    *   **Behavior:** Empty strings in the value column of the source table shall be treated as valid string values, not as missing/NaN.\n\n*   **FR-GEN-FTBL-002:** Validate frequency table column identifiers for single-column generation.\n    *   The system shall ensure that `value_column` and `freq_column` identifiers are of the same type (e.g., both strings or both integers).\n    *   The system shall ensure that these identifiers are either strings or integers.\n    *   If validation fails, a `ValueError` shall be raised.\n\n*   **FR-GEN-MFTBL-001:** Generate data from a multi-column frequency table maintaining inter-column dependencies.\n    *   The system shall generate multiple series of values whose joint distribution approximates the frequencies specified in an input frequency table with multiple value columns. This preserves relationships between values across the generated columns as defined in the table.\n    *   **Inputs:**\n        *   `data_source`: A path to a CSV file or a Pandas DataFrame.\n        *   `value_columns`: A list of identifiers (names or indices) for the value columns.\n        *   `freq_column`: Identifier (name or index) of the column containing absolute frequencies for value tuples.\n        *   Number of items to generate.\n        *   Optional: RNG, CSV file encoding (default 'utf-8'), CSV delimiter (default ',').\n    *   **Output:** A list of Pandas Series, one for each specified `value_column`.\n    *   **Behavior:** Empty strings in value columns of the source table shall be treated as valid string values.\n\n*   **FR-GEN-MFTBL-002:** Validate `value_columns` list for multi-column frequency table generation.\n    *   The system shall ensure the `value_columns` list is not empty.\n    *   If validation fails, a `ValueError` shall be raised.\n\n*   **FR-GEN-MFTBL-003:** Validate column identifiers for multi-column frequency table generation.\n    *   The system shall ensure all identifiers in `value_columns` and the `freq_column` identifier are of the same type (e.g., all strings or all integers).\n    *   The system shall ensure these identifiers are either strings or integers.\n    *   If validation fails, a `ValueError` shall be raised.\n\n*   **FR-GEN-DT-001:** Generate datetime strings within a specified range and format.\n    *   The system shall generate a series of datetime strings, randomly distributed within a given start and end datetime, formatted according to a specified format string, and with randomness constrained by a specified time unit.\n    *   **Inputs:**\n        *   `start_dt`: Start of the range (ISO 8601 string or `numpy.datetime64`).\n        *   `end_dt`: End of the range (ISO 8601 string or `numpy.datetime64`).\n        *   `dt_format`: Python `strftime`-compatible format string for output.\n        *   `unit`: Smallest unit of time that random variation applies to. Accepted values: \"d\", \"days\", \"h\", \"hours\", \"m\", \"minutes\", \"s\", \"seconds\".\n        *   Number of items to generate.\n        *   Optional: RNG.\n    *   **Output:** A list containing one Pandas Series of formatted datetime strings.\n    *   **Validation:**\n        *   `start_dt` must not be greater than or equal to `end_dt`. If not, raise `ValueError`.\n        *   Invalid datetime strings for `start_dt` or `end_dt` shall raise `ValueError`.\n    *   **Unit Behavior:**\n        *   If unit is \"d\" or \"days\", generated datetimes will vary in year, month, day; time components (H,M,S) will be 00:00:00.\n        *   If unit is \"h\" or \"hours\", generated datetimes will vary up to the hour; minute and second components will be 00:00.\n        *   If unit is \"m\" or \"minutes\", generated datetimes will vary up to the minute; second component will be 00.\n        *   If unit is \"s\" or \"seconds\", generated datetimes will vary up to the second.\n\n*   **FR-GEN-DT-002:** Convert datetime unit alias to standard representation.\n    *   The system shall convert user-friendly datetime unit strings (e.g., \"d\", \"days\", \"h\", \"hours\", \"m\", \"minutes\", \"s\", \"seconds\") to a corresponding standard internal time unit character recognized by Pandas (e.g., \"D\", \"h\", \"m\", \"s\").\n    *   If an unrecognized unit string is provided, a `ValueError` shall be raised.\n\n*   **FR-GEN-GRP-001:** Generate data by combining outputs from multiple sub-generators with weighting and shuffling.\n    *   The system shall combine data generated by a list of sub-generators into a single set of output series.\n    *   **Inputs:**\n        *   `generator_lst`: A list where each element is either a sub-generator or a tuple `(weight, sub_generator)`.\n        *   Number of items to generate (`count`).\n        *   Optional: `max_rounding_adjustment` (int, default 0), RNG.\n    *   **Output:** A list of Pandas Series. The number of output series must match the number of series returned by each sub-generator (which must be consistent across all sub-generators).\n    *   **Behavior:**\n        *   If weights are not provided, each sub-generator contributes an equal proportion of the total `count`.\n        *   If weights are provided, each sub-generator contributes a proportion of `count` according to its weight. The sum of all provided weights must be 1.0.\n        *   The final output series are formed by concatenating the corresponding series from all sub-generators and then shuffling the rows globally (all output series shuffled with the same random row order).\n    *   **Validation:**\n        *   All sub-generators must return the same number of series. If not, raise `ValueError`.\n        *   If weights are used, their sum must be 1.0. If not, raise `ValueError`.\n        *   The sum of rows allocated to sub-generators (after rounding proportions to integers) must equal `count`. If not, and `max_rounding_adjustment` is insufficient to cover the discrepancy, raise `ValueError`. `max_rounding_adjustment` must not be negative.\n\n*   **FR-GEN-DF-001:** Create a Pandas DataFrame from specified column generators.\n    *   The system shall construct a Pandas DataFrame by populating columns using specified sub-generators.\n    *   **Inputs:**\n        *   `generator_lst`: A list of tuples, where each tuple is `(column_names, sub_generator)`. `column_names` can be a single string or a tuple of strings.\n        *   `count`: Total number of rows to generate for the DataFrame.\n    *   **Output:** A Pandas DataFrame.\n    *   **Behavior:** Each sub-generator is invoked to produce `count` items for its assigned column(s).\n    *   **Validation:**\n        *   `generator_lst` must not be empty. If empty, raise `ValueError`.\n        *   `count` must be positive. If not, raise `ValueError`.\n        *   The number of series returned by a sub-generator must match the number of column names it is assigned to in `column_names`. If mismatched, raise `ValueError`.\n\n#### 3.1.2. Data Mutation (Mutator Module)\nMutators generally operate on a list of input Pandas Series and are influenced by a probability `p`. They return a list of mutated Pandas Series.\n\n*   **FR-MUT-PROB-001:** Validate mutation probability.\n    *   The system shall ensure that any mutation probability `p` supplied to a mutator is between 0.0 and 1.0, inclusive.\n    *   If `p` is outside this range, a `ValueError` shall be raised.\n\n*   **FR-MUT-WARN-P-001:** Issue warning if desired mutation probability cannot be met.\n    *   If a mutator cannot achieve the target mutation probability `p` because fewer than `p * total_rows` are eligible for the specific mutation (due to data characteristics), the system shall issue a `GeckoWarning` indicating the actual achievable probability.\n\n*   **FR-MUT-FUNC-001:** Mutate series using a custom Python function.\n    *   The system shall allow mutation of series values by applying a user-supplied Python callable.\n    *   **Inputs:** A Python callable (receives a string value and any custom args/kwargs, returns a mutated string), list of Pandas Series, probability `p` (fraction of rows to attempt mutation on), optional RNG, and any additional positional or keyword arguments for the user's callable.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly, the custom function is applied to the string value in each input series.\n\n*   **FR-MUT-CLDR-001:** Mutate series by simulating keyboard typos using a CLDR keymap.\n    *   The system shall introduce typos into string values based on character proximity on a keyboard layout defined by a CLDR keymap file.\n    *   **Inputs:** Path to a CLDR XML keymap file, list of Pandas Series, probability `p`, optional RNG. Optional: `charset` (string or list of characters eligible for mutation).\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly:\n        *   A character within the string is chosen (if `charset` is provided, only characters from this set are considered).\n        *   The chosen character is replaced by one of its valid neighbors on the keyboard (horizontal, vertical, or case-swapped variant) as defined in the CLDR file. The replacement neighbor is chosen randomly from available valid options.\n        *   If a chosen character has no valid neighbors/variants, it remains unchanged for that specific mutation attempt.\n    *   **CLDR Parsing:** The system must parse the CLDR XML file to determine character positions, including shift-modified characters, and identify neighboring keys.\n\n*   **FR-MUT-PHON-001:** Mutate series using phonetic replacements from a table.\n    *   The system shall replace substrings with phonetically similar ones based on rules from a table.\n    *   **Inputs:** `data_source` (path to CSV or DataFrame for rules), `source_column` ID, `target_column` ID, `flags_column` ID, list of Pandas Series, probability `p`, optional RNG, CSV encoding, CSV delimiter.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly:\n        *   The system identifies a substring matching a `source` pattern from the rule table.\n        *   Matching considers `flags`: `^` (match at start of string), `$` (match at end), `_` (match in middle). If flags are empty/NaN/None for a rule, it can match anywhere.\n        *   The matched substring is replaced by the corresponding `target` string from the rule.\n        *   The system shall adhere to FR-MUT-RAREFAVOR-001 for rule selection.\n    *   **Validation:** The rule table must provide at least one phonetic replacement rule. If not, raise `ValueError`. Flags column must contain valid flag characters (`^`, `$`, `_`) or be empty.\n\n*   **FR-MUT-REPL-001:** Mutate series using direct string replacements from a table.\n    *   The system shall substitute substrings or entire strings based on a replacement table.\n    *   **Inputs:** `data_source` (path to CSV or DataFrame for table), `source_column` ID, `target_column` ID, list of Pandas Series, probability `p`, optional RNG, `inline` (bool, default False), `reverse` (bool, default False), CSV encoding, CSV delimiter.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly:\n        *   If `inline` is False, the entire string is replaced if it matches a `source` value from the table.\n        *   If `inline` is True, the first occurrence of a `source` substring is replaced.\n        *   The replacement is a `target` value from the table corresponding to the matched `source`. If multiple `target` values exist for a `source`, one is chosen randomly.\n        *   If `reverse` is True, the table is also used \"backwards\" (target becomes source, source becomes target).\n        *   The system shall adhere to FR-MUT-RAREFAVOR-001 for rule selection.\n\n*   **FR-MUT-MISS-001:** Replace series values with a specified missing value.\n    *   The system shall replace entire string values with a user-specified \"missing\" value representation.\n    *   **Inputs:** `value` (string to represent missing, default \"\"), list of Pandas Series, probability `p`, optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly (excluding rows already containing `value`), the entire string value is replaced by `value`.\n\n*   **FR-MUT-INS-001:** Insert a random character into series strings.\n    *   The system shall insert a randomly chosen character at a random position within strings.\n    *   **Inputs:** `charset` (string or list of characters to sample from, default `string.ascii_letters`), list of Pandas Series, probability `p`, optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly, a character is chosen randomly from `charset` and inserted at a random position within the string (including at the beginning or end).\n\n*   **FR-MUT-DEL-001:** Delete a random character from series strings.\n    *   The system shall delete a character at a random position from strings.\n    *   **Inputs:** List of Pandas Series, probability `p`, optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly (from rows with string length >= 1), a character at a random position is deleted.\n\n*   **FR-MUT-TRAN-001:** Transpose (swap) two adjacent characters in series strings.\n    *   The system shall swap two neighboring characters at a random position within strings.\n    *   **Inputs:** List of Pandas Series, probability `p`, optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly (from rows with string length >= 2), a random position (not the last character) is chosen, and the character at this position is swapped with the character at the next position.\n\n*   **FR-MUT-SUB-001:** Substitute a character in series strings with a random one.\n    *   The system shall replace a character at a random position with a new character drawn randomly from a specified charset.\n    *   **Inputs:** `charset` (string or list of characters to sample from, default `string.ascii_letters`), list of Pandas Series, probability `p`, optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly (from rows with string length >= 1), a character at a random position is replaced by a character chosen randomly from `charset`.\n\n*   **FR-MUT-NOOP-001:** Perform no operation (identity transformation).\n    *   The system shall provide a mutator that returns the input series unchanged.\n    *   **Inputs:** List of Pandas Series, probability `p`.\n    *   **Output:** The original list of Pandas Series.\n\n*   **FR-MUT-CAT-001:** Replace series values with a different random value from a categorical set.\n    *   The system shall replace values in a series with a *different* random value chosen from a predefined set of categorical values.\n    *   **Inputs:** `data_source` (path to CSV or DataFrame for categorical values), `value_column` ID, list of Pandas Series, probability `p`, optional RNG, CSV encoding, CSV delimiter.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly, if the row's current value is present in the categorical set, it is replaced by another, different value randomly chosen from that set.\n    *   **Validation:** The categorical set (unique values in `value_column`) must contain at least two unique values. If not, raise `ValueError`.\n\n*   **FR-MUT-PERM-001:** Permute values across corresponding rows of multiple series.\n    *   The system shall permute (shuffle) values across multiple input series for selected rows, ensuring no value remains in its original series for that row.\n    *   **Inputs:** List of Pandas Series (at least two, all of the same length and with aligned indices), probability `p`, optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly, the values at that row index across all input series are permuted. The permutation is chosen such that if the original values were `(s1_row_i, s2_row_i, ..., sk_row_i)`, the new values `(s'1_row_i, s'2_row_i, ..., s'k_row_i)` are a permutation where `s'j_row_i` is not from the original `sj_row_i`.\n    *   **Validation:** The input list must contain at least two series. All series must be of the same length. If not, raise `ValueError`.\n\n*   **FR-MUT-LOWER-001:** Convert series strings to lowercase.\n    *   The system shall convert string values to lowercase.\n    *   **Inputs:** List of Pandas Series, probability `p`, optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly (from rows not already entirely lowercase), the string value is converted to lowercase.\n\n*   **FR-MUT-UPPER-001:** Convert series strings to uppercase.\n    *   The system shall convert string values to uppercase.\n    *   **Inputs:** List of Pandas Series, probability `p`, optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly (from rows not already entirely uppercase), the string value is converted to uppercase.\n\n*   **FR-MUT-DTOFF-001:** Offset datetime strings by a random amount.\n    *   The system shall modify datetime strings by adding or subtracting a random duration.\n    *   **Inputs:** `max_delta` (int > 0, maximum amount of units for offset), `unit` (datetime unit: \"d\", \"days\", etc.), `dt_format` (strftime string for parsing/formatting), `prevent_wraparound` (bool, default False), list of Pandas Series, probability `p`, optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly:\n        *   The string value is parsed as a datetime according to `dt_format`.\n        *   A random offset (between `-max_delta` and `+max_delta` units, excluding 0) is applied.\n        *   The modified datetime is formatted back to a string using `dt_format`.\n        *   If `prevent_wraparound` is True, a mutation is skipped if it would cause a change in a larger time unit (e.g., offsetting days changes the month).\n    *   **Validation:** `max_delta` must be positive. If not, raise `ValueError`. `dt_format` must be valid for parsing series content.\n\n*   **FR-MUT-GENR-001:** Mutate series using data from a sub-generator.\n    *   The system shall modify series values by replacing, prepending, or appending content generated by a sub-generator.\n    *   **Inputs:** `generator` (a sub-generator function), `mode` (\"replace\", \"prepend\", or \"append\"), `join_with` (string for joining, default \" \"), list of Pandas Series, probability `p`, optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly:\n        *   New values are generated using the `generator` (matching number of selected rows).\n        *   If `mode` is \"replace\", original values are replaced by new values.\n        *   If `mode` is \"prepend\", new values are prepended to original values, joined by `join_with`.\n        *   If `mode` is \"append\", new values are appended to original values, joined by `join_with`.\n        *   The `join_with` string can contain `{}` as a placeholder for the generated value when prepending or appending, to allow constructions like `prefix{generated_value}suffix`. Only the first `{}` is used.\n    *   **Validation:**\n        *   All input series must have the same length and aligned indices. If not, raise `ValueError`.\n        *   The sub-generator must produce the same number of series as provided in the input `srs_lst`. If not, raise `ValueError`.\n\n*   **FR-MUT-REGEX-001:** Mutate series using regex-based replacements from a table.\n    *   The system shall perform string substitutions based on regular expression patterns and replacement rules defined in a table.\n    *   **Inputs:** `data_source` (path to CSV or DataFrame for table), `pattern_column` name, `flags_column` name (optional), list of Pandas Series, probability `p`, optional RNG, CSV encoding, CSV delimiter.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly:\n        *   A regex pattern from the `pattern_column` is matched against the string. Regex flags (e.g., 'i' for ignorecase, 'a' for ASCII) can be specified in the `flags_column`.\n        *   The replacement string is constructed using values from other columns in the rule table. These columns are referenced by capture group number (e.g., column \"1\" for the first unnamed group) or capture group name (e.g., column \"foo\" for `(?P<foo>...)`).\n        *   The system shall adhere to FR-MUT-RAREFAVOR-001 for rule selection.\n    *   **Validation:** Rule table must provide at least one regex pattern. `pattern_column` must exist. If `flags_column` is specified, it must exist. Columns referenced by capture groups in patterns must exist in the table. If not, raise `ValueError`.\n\n*   **FR-MUT-REPT-001:** Repeat the content of series strings.\n    *   The system shall duplicate the content of strings, optionally joined by a specified character.\n    *   **Inputs:** `join_with` (string for joining, default \" \"), list of Pandas Series, probability `p`, optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly, the string value `s` is replaced by `s + join_with + s`.\n\n*   **FR-MUT-MGRP-001:** Apply one of a group of mutators to series based on weights.\n    *   The system shall apply one mutator chosen from a group to selected rows, where the choice of mutator is weighted.\n    *   **Inputs:** `mutator_lst` (list of mutators, or list of `(weight, mutator)` tuples), list of Pandas Series, probability `p` (overall probability of applying any mutator from the group), optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For each row selected based on the overall `p`:\n        *   One mutator is chosen from `mutator_lst`. If unweighted, choice is uniform. If weighted, choice is based on provided weights.\n        *   The chosen mutator is applied to that row (effectively with probability 1.0 for its specific action on that row).\n        *   If weights are provided and sum to less than 1.0, a \"no-operation\" mutator (FR-MUT-NOOP-001) is implicitly added with the remaining probability weight.\n    *   **Validation:**\n        *   All input series must have the same length. If not, raise `ValueError`.\n        *   If weights are provided, each weight must be > 0. Sum of weights must not be > 1.0. Sum of weights must be > 0. If violated, raise `ValueError`.\n\n*   **FR-MUT-RAREFAVOR-001:** Prioritize transformations based on rule applicability.\n    *   When a mutator relies on a set of transformation rules from a table (e.g., phonetic, replacement, regex) and a string could be transformed by multiple rules:\n        1.  The system shall determine rule applicability by first considering rules that match the fewest total strings in the input series (rarer rules are processed with higher priority).\n        2.  When selecting a specific rule to apply to a string that matches multiple (remaining) rules, the selection mechanism should effectively increase the probability of applying *a* rule to strings that have fewer overall matching rule options left.\n        3.  Once a rule is applied to a string, that string is typically not considered for further transformations by other rules within the same mutator invocation for that string for that specific applied rule.\n    *   This applies to: `with_phonetic_replacement_table` (FR-MUT-PHON-001), `with_replacement_table` (FR-MUT-REPL-001), `with_regex_replacement_table` (FR-MUT-REGEX-001).\n\n*   **FR-MUT-DF-001:** Mutate a DataFrame by applying specified mutators to columns.\n    *   The system shall apply a sequence of specified mutators to designated columns of an input Pandas DataFrame.\n    *   **Inputs:**\n        *   `df_in`: The input Pandas DataFrame.\n        *   `mutator_lst`: A list of specifications. Each specification is a tuple: `(column_spec, mutator_definition)`.\n            *   `column_spec`: A string (single column name) or a tuple of strings (multiple column names).\n            *   `mutator_definition`:\n                *   A single mutator function.\n                *   A tuple `(probability, mutator_function)`.\n                *   A list of mutator functions.\n                *   A list of `(probability, mutator_function)` tuples.\n    *   **Output:** A new Pandas DataFrame with mutations applied.\n    *   **Behavior:**\n        *   For each `(column_spec, mutator_definition)` in `mutator_lst`:\n            *   The specified column(s) from `df_in` (or the result of the previous mutation step for these columns) are extracted.\n            *   If `mutator_definition` is a single mutator or a `(probability, mutator)` tuple, it's treated as a list containing one such item.\n            *   If `mutator_definition` is a list of mutator functions, each is treated as `(1.0, mutator_function)`.\n            *   The (now list of) weighted mutators are applied *sequentially* to the extracted column(s). The output of one mutator in the sequence becomes the input to the next, each applied with its specified probability.\n    *   **Validation:**\n        *   Column names in `column_spec` must exist in `df_in`. If not, raise `ValueError`.\n        *   Probabilities specified in `mutator_definition` must be in the range (0, 1]. If not, raise `ValueError`.\n\n#### 3.1.3. General System Functionality\n\n*   **FR-SYS-RNG-001:** Utilize a configurable Random Number Generator (RNG).\n    *   All system operations involving randomness (e.g., value selection, probability checks, shuffling) must use an RNG instance.\n    *   This RNG shall be configurable by the user (e.g., by passing an `np.random.Generator` instance), allowing for reproducible results if the RNG is seeded.\n    *   If no RNG is provided by the user for a function that requires one, a default `np.random.Generator` instance shall be used.\n\n### 3.2. Non-Functional Requirements\nNo non-functional requirements (NFRs) have been identified that are directly and explicitly validated by a dedicated original test case, as per the project's NFR inclusion criteria.\n\n### 3.3. External Interface Requirements\n\n*   **EIR-CSV-INPUT-001:** CSV File Format for Tables.\n    *   The system shall be able to read data from CSV files as input for frequency tables (FR-GEN-FTBL-001, FR-GEN-MFTBL-001), replacement tables (FR-MUT-REPL-001), phonetic tables (FR-MUT-PHON-001), categorical value lists (FR-MUT-CAT-001), and regex rule tables (FR-MUT-REGEX-001).\n    *   **Configurable Parameters:**\n        *   Delimiter: Default is ','.\n        *   Encoding: Default is 'utf-8'.\n    *   **Header Row:** The presence of a header row in the CSV file is inferred from the type of column identifiers provided to the function utilizing the CSV:\n        *   If column identifiers are strings (column names), a header row at index 0 is assumed.\n        *   If column identifiers are integers (column indices), no header row is assumed.\n    *   **Data Handling:** For frequency tables, replacement tables, and similar, values are generally read as strings. Empty fields in CSVs are treated as empty strings, not NaN, unless specified otherwise by a particular function's data handling for NaN values (e.g. frequency table generator specifically keeps empty strings as values).\n\n*   **EIR-DATAFRAME-INPUT-001:** Pandas DataFrame as Input for Tables.\n    *   The system shall accept Pandas DataFrames as an alternative input source (to CSV files) for frequency tables, replacement tables, phonetic tables, categorical value lists, and regex rule tables.\n\n*   **EIR-CLDR-XML-INPUT-001:** CLDR Keymap File Format.\n    *   The system shall parse and utilize keyboard layout information from CLDR (Common Locale Data Repository) XML files for the keyboard typo mutator (FR-MUT-CLDR-001).\n    *   The system must interpret XML structure including:\n        *   `<keyMap>` elements, potentially with a `modifiers=\"shift\"` attribute.\n        *   `<map>` elements nested within `<keyMap>`, with `iso` (ISO keyboard position, e.g., \"C01\") and `to` (character output) attributes.\n    *   The system must correctly unescape characters found in the `to` attribute (e.g., HTML entities, Unicode entities like `\\u{22}`).\n\n*   **EIR-PANDAS-SERIES-IO-001:** Generator and Mutator Functional Signatures.\n    *   Generator factory functions (e.g., `generator.from_frequency_table`) shall return a callable (the \"generator instance\"). This generator instance shall:\n        *   Accept an integer `count` (number of items to generate).\n        *   Return a `list[pandas.Series]`.\n    *   Mutator factory functions (e.g., `mutator.with_delete`) shall return a callable (the \"mutator instance\"). This mutator instance shall:\n        *   Accept a `list[pandas.Series]` (data to mutate) and an optional `float` probability `p`.\n        *   Return a `list[pandas.Series]` (mutated data).\n\n*   **EIR-PANDAS-DATAFRAME-MAIN-001:** DataFrame for Primary Generation and Mutation Operations.\n    *   The `gecko.generator.to_data_frame` function shall accept generator specifications and return a `pandas.DataFrame`.\n    *   The `gecko.mutator.mutate_data_frame` function shall accept a `pandas.DataFrame` and mutator specifications, and return a `pandas.DataFrame`.\n\n### 3.4. Other Requirements\n\n#### 3.4.1. Error Handling\n\n*   **OHR-ERR-VAL-001:** Input Validation Errors.\n    *   The system shall raise `ValueError` when provided with invalid input parameters that make an operation impossible, ambiguous, or would lead to an inconsistent state. This includes, but is not limited to:\n        *   Non-positive counts for generation.\n        *   Probabilities outside the [0,1] range.\n        *   Mismatched column specifications or types.\n        *   Empty or malformed input tables/rules where specific content is required.\n        *   Invalid date ranges or formats.\n\n*   **OHR-WARN-GECKO-001:** GeckoWarning for Non-Fatal Issues.\n    *   The system shall issue a `GeckoWarning` (a custom class derived from `UserWarning`) for situations where an operation can proceed but the outcome might not perfectly align with the user's request due to data characteristics or inherent limitations. This primarily applies when a desired mutation probability cannot be fully achieved (see FR-MUT-WARN-P-001).\n",
        "structured_requirements": [
            {
                "requirement_id": "FR-GEN-FUNC-001",
                "requirement_description": "Generate data from a custom Python function.\n    *   The system shall provide a mechanism to generate a series of string values by repeatedly invoking a user-supplied Python callable.\n    *   **Inputs:** A Python callable that returns a string, the number of items to generate, an optional Random Number Generator (RNG), and any additional positional or keyword arguments to be passed to the user's callable.\n    *   **Output:** A list containing one Pandas Series, where each element is a string generated by one call to the user's function.",
                "test_traceability": [
                    {
                        "id": "tests/test_generator.py::test_from_function",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/generator.py::from_function",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-UDIST-001",
                "requirement_description": "Generate string representations of numbers from a uniform distribution.\n    *   The system shall generate a series of numbers drawn from a uniform distribution and format them as strings.\n    *   **Inputs:** Lower bound (inclusive, int or float), upper bound (exclusive, int or float), decimal precision for formatting (int), number of items to generate, and an optional RNG. Default bounds [0, 1), default precision 6.\n    *   **Output:** A list containing one Pandas Series of string-formatted numbers.",
                "test_traceability": [
                    {
                        "id": "tests/test_generator.py::test_from_uniform_distribution",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/generator.py::from_uniform_distribution",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-NDIST-001",
                "requirement_description": "Generate string representations of numbers from a normal distribution.\n    *   The system shall generate a series of numbers drawn from a normal (Gaussian) distribution and format them as strings.\n    *   **Inputs:** Mean (float), standard deviation (float), decimal precision for formatting (int), number of items to generate, and an optional RNG. Default mean 0, sd 1, precision 6.\n    *   **Output:** A list containing one Pandas Series of string-formatted numbers.",
                "test_traceability": [
                    {
                        "id": "tests/test_generator.py::test_from_normal_distribution",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/generator.py::from_normal_distribution",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-FTBL-001",
                "requirement_description": "Generate data from a single-column frequency table.\n    *   The system shall generate a series of values whose distribution approximates the frequencies specified in an input frequency table.\n    *   **Inputs:**\n        *   `data_source`: A path to a CSV file or a Pandas DataFrame.\n        *   `value_column`: Identifier (name or index) of the column containing values to generate.\n        *   `freq_column`: Identifier (name or index) of the column containing absolute frequencies.\n        *   Number of items to generate.\n        *   Optional: RNG, CSV file encoding (default 'utf-8'), CSV delimiter (default ',').\n    *   **Output:** A list containing one Pandas Series.\n    *   **Behavior:** Empty strings in the value column of the source table shall be treated as valid string values, not as missing/NaN.",
                "test_traceability": [
                    {
                        "id": "tests/test_generator.py::test_from_frequency_table_no_header",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_frequency_table_with_header",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_frequency_table_tsv",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_frequency_table",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_frequency_table_nan",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_frequency_table_df",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/generator.py::from_frequency_table",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-FTBL-002",
                "requirement_description": "Validate frequency table column identifiers for single-column generation.\n    *   The system shall ensure that `value_column` and `freq_column` identifiers are of the same type (e.g., both strings or both integers).\n    *   The system shall ensure that these identifiers are either strings or integers.\n    *   If validation fails, a `ValueError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "FR-GEN-FTBL-001",
                        "description": "Implicitly tested by successful runs of tests for FR-GEN-FTBL-001. Direct error case not explicitly isolated in tests."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/generator.py::from_frequency_table",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-MFTBL-001",
                "requirement_description": "Generate data from a multi-column frequency table maintaining inter-column dependencies.\n    *   The system shall generate multiple series of values whose joint distribution approximates the frequencies specified in an input frequency table with multiple value columns. This preserves relationships between values across the generated columns as defined in the table.\n    *   **Inputs:**\n        *   `data_source`: A path to a CSV file or a Pandas DataFrame.\n        *   `value_columns`: A list of identifiers (names or indices) for the value columns.\n        *   `freq_column`: Identifier (name or index) of the column containing absolute frequencies for value tuples.\n        *   Number of items to generate.\n        *   Optional: RNG, CSV file encoding (default 'utf-8'), CSV delimiter (default ',').\n    *   **Output:** A list of Pandas Series, one for each specified `value_column`.\n    *   **Behavior:** Empty strings in value columns of the source table shall be treated as valid string values.",
                "test_traceability": [
                    {
                        "id": "tests/test_generator.py::test_from_multicolumn_frequency_table",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_multicolumn_frequency_table_nan",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_multicolumn_frequency_table_df",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/generator.py::from_multicolumn_frequency_table",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-MFTBL-002",
                "requirement_description": "Validate `value_columns` list for multi-column frequency table generation.\n    *   The system shall ensure the `value_columns` list is not empty.\n    *   If validation fails, a `ValueError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "Implicitly tested. Direct error case not explicitly isolated in tests.",
                        "description": "Implicitly tested. Direct error case not explicitly isolated in tests."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/generator.py::from_multicolumn_frequency_table",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-MFTBL-003",
                "requirement_description": "Validate column identifiers for multi-column frequency table generation.\n    *   The system shall ensure all identifiers in `value_columns` and the `freq_column` identifier are of the same type (e.g., all strings or all integers).\n    *   The system shall ensure these identifiers are either strings or integers.\n    *   If validation fails, a `ValueError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "Implicitly tested. Direct error case not explicitly isolated in tests.",
                        "description": "Implicitly tested. Direct error case not explicitly isolated in tests."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/generator.py::from_multicolumn_frequency_table",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-DT-001",
                "requirement_description": "Generate datetime strings within a specified range and format.\n    *   The system shall generate a series of datetime strings, randomly distributed within a given start and end datetime, formatted according to a specified format string, and with randomness constrained by a specified time unit.\n    *   **Inputs:**\n        *   `start_dt`: Start of the range (ISO 8601 string or `numpy.datetime64`).\n        *   `end_dt`: End of the range (ISO 8601 string or `numpy.datetime64`).\n        *   `dt_format`: Python `strftime`-compatible format string for output.\n        *   `unit`: Smallest unit of time that random variation applies to. Accepted values: \"d\", \"days\", \"h\", \"hours\", \"m\", \"minutes\", \"s\", \"seconds\".\n        *   Number of items to generate.\n        *   Optional: RNG.\n    *   **Output:** A list containing one Pandas Series of formatted datetime strings.\n    *   **Validation:**\n        *   `start_dt` must not be greater than or equal to `end_dt`. If not, raise `ValueError`.\n        *   Invalid datetime strings for `start_dt` or `end_dt` shall raise `ValueError`.\n    *   **Unit Behavior:**\n        *   If unit is \"d\" or \"days\", generated datetimes will vary in year, month, day; time components (H,M,S) will be 00:00:00.\n        *   If unit is \"h\" or \"hours\", generated datetimes will vary up to the hour; minute and second components will be 00:00.\n        *   If unit is \"m\" or \"minutes\", generated datetimes will vary up to the minute; second component will be 00.\n        *   If unit is \"s\" or \"seconds\", generated datetimes will vary up to the second.",
                "test_traceability": [
                    {
                        "id": "tests/test_generator.py::test_from_datetime_range",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_datetime_range_invalid_start_datetime",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_datetime_range_invalid_end_datetime",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_datetime_range_all_units",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_datetime_range_end_before_start",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/generator.py::from_datetime_range",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-DT-002",
                "requirement_description": "Convert datetime unit alias to standard representation.\n    *   The system shall convert user-friendly datetime unit strings (e.g., \"d\", \"days\", \"h\", \"hours\", \"m\", \"minutes\", \"s\", \"seconds\") to a corresponding standard internal time unit character recognized by Pandas (e.g., \"D\", \"h\", \"m\", \"s\").\n    *   If an unrecognized unit string is provided, a `ValueError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "tests/test_generator.py::test_from_datetime_range_all_units",
                        "description": "Logic is covered by `tests/test_generator.py::test_from_datetime_range_all_units` which tests various units. No separate unit test for `convert_gecko_date_time_unit_to_pandas`."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/_typedefs.py::convert_gecko_date_time_unit_to_pandas",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-GRP-001",
                "requirement_description": "Generate data by combining outputs from multiple sub-generators with weighting and shuffling.\n    *   The system shall combine data generated by a list of sub-generators into a single set of output series.\n    *   **Inputs:**\n        *   `generator_lst`: A list where each element is either a sub-generator or a tuple `(weight, sub_generator)`.\n        *   Number of items to generate (`count`).\n        *   Optional: `max_rounding_adjustment` (int, default 0), RNG.\n    *   **Output:** A list of Pandas Series. The number of output series must match the number of series returned by each sub-generator (which must be consistent across all sub-generators).\n    *   **Behavior:**\n        *   If weights are not provided, each sub-generator contributes an equal proportion of the total `count`.\n        *   If weights are provided, each sub-generator contributes a proportion of `count` according to its weight. The sum of all provided weights must be 1.0.\n        *   The final output series are formed by concatenating the corresponding series from all sub-generators and then shuffling the rows globally (all output series shuffled with the same random row order).\n    *   **Validation:**\n        *   All sub-generators must return the same number of series. If not, raise `ValueError`.\n        *   If weights are used, their sum must be 1.0. If not, raise `ValueError`.\n        *   The sum of rows allocated to sub-generators (after rounding proportions to integers) must equal `count`. If not, and `max_rounding_adjustment` is insufficient to cover the discrepancy, raise `ValueError`. `max_rounding_adjustment` must not be negative.",
                "test_traceability": [
                    {
                        "id": "tests/test_generator.py::test_from_group_single_column_same_weight",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_group_single_column_different_weight",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_group_multiple_column_same_weight",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_group_multiple_column_different_weight",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_group_raise_different_column_counts",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_group_raise_p_sum_not_1",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_group_raise_row_count",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_group_rounding_adjustment_positive",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_group_rounding_adjustment_negative",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_group_raise_rounding_adjustment_not_high_enough",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_group_weight_sanity_check",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/generator.py::from_group",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-GEN-DF-001",
                "requirement_description": "Create a Pandas DataFrame from specified column generators.\n    *   The system shall construct a Pandas DataFrame by populating columns using specified sub-generators.\n    *   **Inputs:**\n        *   `generator_lst`: A list of tuples, where each tuple is `(column_names, sub_generator)`. `column_names` can be a single string or a tuple of strings.\n        *   `count`: Total number of rows to generate for the DataFrame.\n    *   **Output:** A Pandas DataFrame.\n    *   **Behavior:** Each sub-generator is invoked to produce `count` items for its assigned column(s).\n    *   **Validation:**\n        *   `generator_lst` must not be empty. If empty, raise `ValueError`.\n        *   `count` must be positive. If not, raise `ValueError`.\n        *   The number of series returned by a sub-generator must match the number of column names it is assigned to in `column_names`. If mismatched, raise `ValueError`.",
                "test_traceability": [
                    {
                        "id": "tests/test_generator.py::test_to_dataframe_error_empty_list",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_to_dataframe_error_count_not_positive",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_to_dataframe",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/generator.py::to_data_frame",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MUT-PROB-001",
                "requirement_description": "Validate mutation probability.\n    *   The system shall ensure that any mutation probability `p` supplied to a mutator is between 0.0 and 1.0, inclusive.\n    *   If `p` is outside this range, a `ValueError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "_check_probability_in_bounds",
                        "description": "Implicitly verified by all mutator tests that accept a probability. Direct error case not explicitly isolated in tests for `_check_probability_in_bounds`."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/mutator.py::_check_probability_in_bounds",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MUT-WARN-P-001",
                "requirement_description": "Issue warning if desired mutation probability cannot be met.\n    *   If a mutator cannot achieve the target mutation probability `p` because fewer than `p * total_rows` are eligible for the specific mutation (due to data characteristics), the system shall issue a `GeckoWarning` indicating the actual achievable probability.",
                "test_traceability": [
                    {
                        "id": "tests/test_mutator.py::test_with_cldr_keymap_file_warn_low_p",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_missing_value_existing",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_replacement_table_warn_p",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_delete_warn_p",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_transpose_warn_p",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_substitute_warn_p",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_uppercase_warn_p",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_lowercase_warn_p",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_categorical_values_warn_p",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_phonetic_replacement_table_warn_p",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_regex_replacement_table_warn_p",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/mutator.py::_warn_p",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MUT-FUNC-001",
                "requirement_description": "Mutate series using a custom Python function.\n    *   The system shall allow mutation of series values by applying a user-supplied Python callable.\n    *   **Inputs:** A Python callable (receives a string value and any custom args/kwargs, returns a mutated string), list of Pandas Series, probability `p` (fraction of rows to attempt mutation on), optional RNG, and any additional positional or keyword arguments for the user's callable.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly, the custom function is applied to the string value in each input series.",
                "test_traceability": [
                    {
                        "id": "tests/test_mutator.py::test_with_function",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_function_partial",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/mutator.py::with_function",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MUT-CLDR-001",
                "requirement_description": "Mutate series by simulating keyboard typos using a CLDR keymap.\n    *   The system shall introduce typos into string values based on character proximity on a keyboard layout defined by a CLDR keymap file.\n    *   **Inputs:** Path to a CLDR XML keymap file, list of Pandas Series, probability `p`, optional RNG. Optional: `charset` (string or list of characters eligible for mutation).\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly:\n        *   A character within the string is chosen (if `charset` is provided, only characters from this set are considered).\n        *   The chosen character is replaced by one of its valid neighbors on the keyboard (horizontal, vertical, or case-swapped variant) as defined in the CLDR file. The replacement neighbor is chosen randomly from available valid options.\n        *   If a chosen character has no valid neighbors/variants, it remains unchanged for that specific mutation attempt.\n    *   **CLDR Parsing:** The system must parse the CLDR XML file to determine character positions, including shift-modified characters, and identify neighboring keys.",
                "test_traceability": [
                    {
                        "id": "tests/test_mutator.py::test_with_cldr_keymap_file",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_cldr_keymap_file_partial",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_cldr_keymap_file_multiple_options",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_cldr_keymap_file_warn_low_p",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/mutator.py::with_cldr_keymap_file",
                        "description": ""
                    },
                    {
                        "id": "gecko/_cldr.py",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MUT-PHON-001",
                "requirement_description": "Mutate series using phonetic replacements from a table.\n    *   The system shall replace substrings with phonetically similar ones based on rules from a table.\n    *   **Inputs:** `data_source` (path to CSV or DataFrame for rules), `source_column` ID, `target_column` ID, `flags_column` ID, list of Pandas Series, probability `p`, optional RNG, CSV encoding, CSV delimiter.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly:\n        *   The system identifies a substring matching a `source` pattern from the rule table.\n        *   Matching considers `flags`: `^` (match at start of string), `$` (match at end), `_` (match in middle). If flags are empty/NaN/None for a rule, it can match anywhere.\n        *   The matched substring is replaced by the corresponding `target` string from the rule.\n        *   The system shall adhere to FR-MUT-RAREFAVOR-001 for rule selection.\n    *   **Validation:** The rule table must provide at least one phonetic replacement rule. If not, raise `ValueError`. Flags column must contain valid flag characters (`^`, `$`, `_`) or be empty.",
                "test_traceability": [
                    {
                        "id": "tests/test_mutator.py::test_with_phonetic_replacement_table",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_phonetic_replacement_table_random_values",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_phonetic_replacement_table_partial",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_phonetic_replacement_table_no_flags",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_phonetic_replacement_table_csv",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_phonetic_replacement_table_warn_p",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_phonetic_replacement_table_raise_no_rules",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/mutator.py::with_phonetic_replacement_table",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MUT-REPL-001",
                "requirement_description": "Mutate series using direct string replacements from a table.\n    *   The system shall substitute substrings or entire strings based on a replacement table.\n    *   **Inputs:** `data_source` (path to CSV or DataFrame for table), `source_column` ID, `target_column` ID, list of Pandas Series, probability `p`, optional RNG, `inline` (bool, default False), `reverse` (bool, default False), CSV encoding, CSV delimiter.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly:\n        *   If `inline` is False, the entire string is replaced if it matches a `source` value from the table.\n        *   If `inline` is True, the first occurrence of a `source` substring is replaced.\n        *   The replacement is a `target` value from the table corresponding to the matched `source`. If multiple `target` values exist for a `source`, one is chosen randomly.\n        *   If `reverse` is True, the table is also used \"backwards\" (target becomes source, source becomes target).\n        *   The system shall adhere to FR-MUT-RAREFAVOR-001 for rule selection.",
                "test_traceability": [
                    {
                        "id": "tests/test_mutator.py::test_with_replacement_table",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_replacement_table_random_values",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_replacement_table_favor_rare_replacements",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_replacement_table_partial",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_replacement_table_reverse",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_replacement_table_inline",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_replacement_table_warn_p",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_replacement_table_csv",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/mutator.py::with_replacement_table",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MUT-MISS-001",
                "requirement_description": "Replace series values with a specified missing value.\n    *   The system shall replace entire string values with a user-specified \"missing\" value representation.\n    *   **Inputs:** `value` (string to represent missing, default \"\"), list of Pandas Series, probability `p`, optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly (excluding rows already containing `value`), the entire string value is replaced by `value`.",
                "test_traceability": [
                    {
                        "id": "tests/test_mutator.py::test_with_missing_value",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_missing_value_partial",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_missing_value_existing",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/mutator.py::with_missing_value",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MUT-INS-001",
                "requirement_description": "Insert a random character into series strings.\n    *   The system shall insert a randomly chosen character at a random position within strings.\n    *   **Inputs:** `charset` (string or list of characters to sample from, default `string.ascii_letters`), list of Pandas Series, probability `p`, optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly, a character is chosen randomly from `charset` and inserted at a random position within the string (including at the beginning or end).",
                "test_traceability": [
                    {
                        "id": "tests/test_mutator.py::test_with_insert",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_insert_partial",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_insert_charset",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/mutator.py::with_insert",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MUT-DEL-001",
                "requirement_description": "Delete a random character from series strings.\n    *   The system shall delete a character at a random position from strings.\n    *   **Inputs:** List of Pandas Series, probability `p`, optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly (from rows with string length >= 1), a character at a random position is deleted.",
                "test_traceability": [
                    {
                        "id": "tests/test_mutator.py::test_with_delete",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_delete_partial",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_delete_warn_p",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/mutator.py::with_delete",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MUT-TRAN-001",
                "requirement_description": "Transpose (swap) two adjacent characters in series strings.\n    *   The system shall swap two neighboring characters at a random position within strings.\n    *   **Inputs:** List of Pandas Series, probability `p`, optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly (from rows with string length >= 2), a random position (not the last character) is chosen, and the character at this position is swapped with the character at the next position.",
                "test_traceability": [
                    {
                        "id": "tests/test_mutator.py::test_with_transpose",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_transpose_partial",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_transpose_warn_p",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/mutator.py::with_transpose",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MUT-SUB-001",
                "requirement_description": "Substitute a character in series strings with a random one.\n    *   The system shall replace a character at a random position with a new character drawn randomly from a specified charset.\n    *   **Inputs:** `charset` (string or list of characters to sample from, default `string.ascii_letters`), list of Pandas Series, probability `p`, optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly (from rows with string length >= 1), a character at a random position is replaced by a character chosen randomly from `charset`.",
                "test_traceability": [
                    {
                        "id": "tests/test_mutator.py::test_with_substitute",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_substitute_partial",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_substitute_charset",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_substitute_warn_p",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/mutator.py::with_substitute",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MUT-NOOP-001",
                "requirement_description": "Perform no operation (identity transformation).\n    *   The system shall provide a mutator that returns the input series unchanged.\n    *   **Inputs:** List of Pandas Series, probability `p`.\n    *   **Output:** The original list of Pandas Series.",
                "test_traceability": [
                    {
                        "id": "tests/test_mutator.py::test_with_group_padded",
                        "description": "No direct test, but used implicitly by `with_group` padding (e.g. tests/test_mutator.py::test_with_group_padded)."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/mutator.py::with_noop",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MUT-CAT-001",
                "requirement_description": "Replace series values with a different random value from a categorical set.\n    *   The system shall replace values in a series with a *different* random value chosen from a predefined set of categorical values.\n    *   **Inputs:** `data_source` (path to CSV or DataFrame for categorical values), `value_column` ID, list of Pandas Series, probability `p`, optional RNG, CSV encoding, CSV delimiter.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly, if the row's current value is present in the categorical set, it is replaced by another, different value randomly chosen from that set.\n    *   **Validation:** The categorical set (unique values in `value_column`) must contain at least two unique values. If not, raise `ValueError`.",
                "test_traceability": [
                    {
                        "id": "tests/test_mutator.py::test_with_categorical_values",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_categorical_values_partial",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_categorical_values_warn_p",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_categorical_values_raise_too_few_values",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_categorical_values_csv",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/mutator.py::with_categorical_values",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MUT-PERM-001",
                "requirement_description": "Permute values across corresponding rows of multiple series.\n    *   The system shall permute (shuffle) values across multiple input series for selected rows, ensuring no value remains in its original series for that row.\n    *   **Inputs:** List of Pandas Series (at least two, all of the same length and with aligned indices), probability `p`, optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly, the values at that row index across all input series are permuted. The permutation is chosen such that if the original values were `(s1_row_i, s2_row_i, ..., sk_row_i)`, the new values `(s'1_row_i, s'2_row_i, ..., s'k_row_i)` are a permutation where `s'j_row_i` is not from the original `sj_row_i`.\n    *   **Validation:** The input list must contain at least two series. All series must be of the same length. If not, raise `ValueError`.",
                "test_traceability": [
                    {
                        "id": "tests/test_mutator.py::test_with_permute",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_permute_multicolumn",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_permute_partial",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/mutator.py::with_permute",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MUT-LOWER-001",
                "requirement_description": "Convert series strings to lowercase.\n    *   The system shall convert string values to lowercase.\n    *   **Inputs:** List of Pandas Series, probability `p`, optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly (from rows not already entirely lowercase), the string value is converted to lowercase.",
                "test_traceability": [
                    {
                        "id": "tests/test_mutator.py::test_with_lowercase",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_lowercase_partial",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_lowercase_warn_p",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/mutator.py::with_lowercase",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MUT-UPPER-001",
                "requirement_description": "Convert series strings to uppercase.\n    *   The system shall convert string values to uppercase.\n    *   **Inputs:** List of Pandas Series, probability `p`, optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly (from rows not already entirely uppercase), the string value is converted to uppercase.",
                "test_traceability": [
                    {
                        "id": "tests/test_mutator.py::test_with_uppercase",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_uppercase_partial",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_uppercase_warn_p",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/mutator.py::with_uppercase",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MUT-DTOFF-001",
                "requirement_description": "Offset datetime strings by a random amount.\n    *   The system shall modify datetime strings by adding or subtracting a random duration.\n    *   **Inputs:** `max_delta` (int > 0, maximum amount of units for offset), `unit` (datetime unit: \"d\", \"days\", etc.), `dt_format` (strftime string for parsing/formatting), `prevent_wraparound` (bool, default False), list of Pandas Series, probability `p`, optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly:\n        *   The string value is parsed as a datetime according to `dt_format`.\n        *   A random offset (between `-max_delta` and `+max_delta` units, excluding 0) is applied.\n        *   The modified datetime is formatted back to a string using `dt_format`.\n        *   If `prevent_wraparound` is True, a mutation is skipped if it would cause a change in a larger time unit (e.g., offsetting days changes the month).\n    *   **Validation:** `max_delta` must be positive. If not, raise `ValueError`. `dt_format` must be valid for parsing series content.",
                "test_traceability": [
                    {
                        "id": "tests/test_mutator.py::test_with_datetime_offset",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_datetime_offset_partial",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_datetime_offset_prevent_wraparound",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_datetime_offset_custom_format",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_datetime_offset_raise_invalid_delta",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/mutator.py::with_datetime_offset",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MUT-GENR-001",
                "requirement_description": "Mutate series using data from a sub-generator.\n    *   The system shall modify series values by replacing, prepending, or appending content generated by a sub-generator.\n    *   **Inputs:** `generator` (a sub-generator function), `mode` (\"replace\", \"prepend\", or \"append\"), `join_with` (string for joining, default \" \"), list of Pandas Series, probability `p`, optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly:\n        *   New values are generated using the `generator` (matching number of selected rows).\n        *   If `mode` is \"replace\", original values are replaced by new values.\n        *   If `mode` is \"prepend\", new values are prepended to original values, joined by `join_with`.\n        *   If `mode` is \"append\", new values are appended to original values, joined by `join_with`.\n        *   The `join_with` string can contain `{}` as a placeholder for the generated value when prepending or appending, to allow constructions like `prefix{generated_value}suffix`. Only the first `{}` is used.\n    *   **Validation:**\n        *   All input series must have the same length and aligned indices. If not, raise `ValueError`.\n        *   The sub-generator must produce the same number of series as provided in the input `srs_lst`. If not, raise `ValueError`.",
                "test_traceability": [
                    {
                        "id": "tests/test_mutator.py::test_with_generator_replace",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_generator_partial",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_generator_prepend",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_generator_append",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_generator_prepend_join_char",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_generator_append_join_char",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_generator_prepend_join_char_insert",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_generator_append_join_char_insert",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_generator_multi_column",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_generator_raise_mismatched_columns",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/mutator.py::with_generator",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MUT-REGEX-001",
                "requirement_description": "Mutate series using regex-based replacements from a table.\n    *   The system shall perform string substitutions based on regular expression patterns and replacement rules defined in a table.\n    *   **Inputs:** `data_source` (path to CSV or DataFrame for table), `pattern_column` name, `flags_column` name (optional), list of Pandas Series, probability `p`, optional RNG, CSV encoding, CSV delimiter.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly:\n        *   A regex pattern from the `pattern_column` is matched against the string. Regex flags (e.g., 'i' for ignorecase, 'a' for ASCII) can be specified in the `flags_column`.\n        *   The replacement string is constructed using values from other columns in the rule table. These columns are referenced by capture group number (e.g., column \"1\" for the first unnamed group) or capture group name (e.g., column \"foo\" for `(?P<foo>...)`).\n        *   The system shall adhere to FR-MUT-RAREFAVOR-001 for rule selection.\n    *   **Validation:** Rule table must provide at least one regex pattern. `pattern_column` must exist. If `flags_column` is specified, it must exist. Columns referenced by capture groups in patterns must exist in the table. If not, raise `ValueError`.",
                "test_traceability": [
                    {
                        "id": "tests/test_mutator.py::test_with_regex_replacement_table_unnamed_capture_group",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_regex_replacement_table_favor_rare_regexes",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_regex_replacement_table_unnamed_capture_group_partial",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_regex_replacement_table_named_capture_group",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_regex_replacement_table_flags",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_regex_replacement_table_warn_p",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_regex_replacement_table_raise_no_rules",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_regex_replacement_table_csv",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_regex_replacement_table_partial",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_regex_replacement_table_random_values",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/mutator.py::with_regex_replacement_table",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MUT-REPT-001",
                "requirement_description": "Repeat the content of series strings.\n    *   The system shall duplicate the content of strings, optionally joined by a specified character.\n    *   **Inputs:** `join_with` (string for joining, default \" \"), list of Pandas Series, probability `p`, optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For a `p` fraction of rows selected randomly, the string value `s` is replaced by `s + join_with + s`.",
                "test_traceability": [
                    {
                        "id": "tests/test_mutator.py::test_with_repeat",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_repeat_partial",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_repeat_join_character",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/mutator.py::with_repeat",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MUT-MGRP-001",
                "requirement_description": "Apply one of a group of mutators to series based on weights.\n    *   The system shall apply one mutator chosen from a group to selected rows, where the choice of mutator is weighted.\n    *   **Inputs:** `mutator_lst` (list of mutators, or list of `(weight, mutator)` tuples), list of Pandas Series, probability `p` (overall probability of applying any mutator from the group), optional RNG.\n    *   **Output:** A list of mutated Pandas Series.\n    *   **Behavior:** For each row selected based on the overall `p`:\n        *   One mutator is chosen from `mutator_lst`. If unweighted, choice is uniform. If weighted, choice is based on provided weights.\n        *   The chosen mutator is applied to that row (effectively with probability 1.0 for its specific action on that row).\n        *   If weights are provided and sum to less than 1.0, a \"no-operation\" mutator (FR-MUT-NOOP-001) is implicitly added with the remaining probability weight.\n    *   **Validation:**\n        *   All input series must have the same length. If not, raise `ValueError`.\n        *   If weights are provided, each weight must be > 0. Sum of weights must not be > 1.0. Sum of weights must be > 0. If violated, raise `ValueError`.",
                "test_traceability": [
                    {
                        "id": "tests/test_mutator.py::test_with_group",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_group_partial",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_group_weighted",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_group_padded",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_group_raise_p_sum_too_high",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_group_raise_p_sum_too_low",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/mutator.py::with_group",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-MUT-RAREFAVOR-001",
                "requirement_description": "Prioritize transformations based on rule applicability.\n    *   When a mutator relies on a set of transformation rules from a table (e.g., phonetic, replacement, regex) and a string could be transformed by multiple rules:\n        1.  The system shall determine rule applicability by first considering rules that match the fewest total strings in the input series (rarer rules are processed with higher priority).\n        2.  When selecting a specific rule to apply to a string that matches multiple (remaining) rules, the selection mechanism should effectively increase the probability of applying *a* rule to strings that have fewer overall matching rule options left.\n        3.  Once a rule is applied to a string, that string is typically not considered for further transformations by other rules within the same mutator invocation for that string for that specific applied rule.\n    *   This applies to: `with_phonetic_replacement_table` (FR-MUT-PHON-001), `with_replacement_table` (FR-MUT-REPL-001), `with_regex_replacement_table` (FR-MUT-REGEX-001).",
                "test_traceability": [
                    {
                        "id": "tests/test_mutator.py::test_with_replacement_table_favor_rare_replacements",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_phonetic_replacement_table",
                        "description": "behavior embedded in processing logic)"
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_regex_replacement_table_favor_rare_regexes",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/mutator.py",
                        "description": "Derived from analysis of `_dfbitlookup` usage in `gecko/mutator.py` for the relevant table-based mutator functions."
                    }
                ]
            },
            {
                "requirement_id": "FR-MUT-DF-001",
                "requirement_description": "Mutate a DataFrame by applying specified mutators to columns.\n    *   The system shall apply a sequence of specified mutators to designated columns of an input Pandas DataFrame.\n    *   **Inputs:**\n        *   `df_in`: The input Pandas DataFrame.\n        *   `mutator_lst`: A list of specifications. Each specification is a tuple: `(column_spec, mutator_definition)`.\n            *   `column_spec`: A string (single column name) or a tuple of strings (multiple column names).\n            *   `mutator_definition`:\n                *   A single mutator function.\n                *   A tuple `(probability, mutator_function)`.\n                *   A list of mutator functions.\n                *   A list of `(probability, mutator_function)` tuples.\n    *   **Output:** A new Pandas DataFrame with mutations applied.\n    *   **Behavior:**\n        *   For each `(column_spec, mutator_definition)` in `mutator_lst`:\n            *   The specified column(s) from `df_in` (or the result of the previous mutation step for these columns) are extracted.\n            *   If `mutator_definition` is a single mutator or a `(probability, mutator)` tuple, it's treated as a list containing one such item.\n            *   If `mutator_definition` is a list of mutator functions, each is treated as `(1.0, mutator_function)`.\n            *   The (now list of) weighted mutators are applied *sequentially* to the extracted column(s). The output of one mutator in the sequence becomes the input to the next, each applied with its specified probability.\n    *   **Validation:**\n        *   Column names in `column_spec` must exist in `df_in`. If not, raise `ValueError`.\n        *   Probabilities specified in `mutator_definition` must be in the range (0, 1]. If not, raise `ValueError`.",
                "test_traceability": [
                    {
                        "id": "tests/test_mutator.py::test_mutate_data_frame",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/mutator.py::mutate_data_frame",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SYS-RNG-001",
                "requirement_description": "Utilize a configurable Random Number Generator (RNG).\n    *   All system operations involving randomness (e.g., value selection, probability checks, shuffling) must use an RNG instance.\n    *   This RNG shall be configurable by the user (e.g., by passing an `np.random.Generator` instance), allowing for reproducible results if the RNG is seeded.\n    *   If no RNG is provided by the user for a function that requires one, a default `np.random.Generator` instance shall be used.",
                "test_traceability": [
                    {
                        "id": "tests/conftest.py",
                        "description": "The `rng` fixture in `tests/conftest.py` and its usage throughout `tests/test_generator.py` and `tests/test_mutator.py` (e.g., `test_from_uniform_distribution(rng)`)."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/generator.py",
                        "description": "Numerous functions across `gecko/generator.py` and `gecko/mutator.py` accept an `rng` parameter."
                    }
                ]
            },
            {
                "requirement_id": "EIR-CSV-INPUT-001",
                "requirement_description": "CSV File Format for Tables.\n    *   The system shall be able to read data from CSV files as input for frequency tables (FR-GEN-FTBL-001, FR-GEN-MFTBL-001), replacement tables (FR-MUT-REPL-001), phonetic tables (FR-MUT-PHON-001), categorical value lists (FR-MUT-CAT-001), and regex rule tables (FR-MUT-REGEX-001).\n    *   **Configurable Parameters:**\n        *   Delimiter: Default is ','.\n        *   Encoding: Default is 'utf-8'.\n    *   **Header Row:** The presence of a header row in the CSV file is inferred from the type of column identifiers provided to the function utilizing the CSV:\n        *   If column identifiers are strings (column names), a header row at index 0 is assumed.\n        *   If column identifiers are integers (column indices), no header row is assumed.\n    *   **Data Handling:** For frequency tables, replacement tables, and similar, values are generally read as strings. Empty fields in CSVs are treated as empty strings, not NaN, unless specified otherwise by a particular function's data handling for NaN values (e.g. frequency table generator specifically keeps empty strings as values).",
                "test_traceability": [
                    {
                        "id": "tests/test_generator.py::test_from_frequency_table_no_header",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_frequency_table_tsv",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_replacement_table_csv",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_phonetic_replacement_table_csv",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_categorical_values_csv",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_regex_replacement_table_csv",
                        "description": ""
                    }
                ],
                "code_traceability": []
            },
            {
                "requirement_id": "EIR-DATAFRAME-INPUT-001",
                "requirement_description": "Pandas DataFrame as Input for Tables.\n    *   The system shall accept Pandas DataFrames as an alternative input source (to CSV files) for frequency tables, replacement tables, phonetic tables, categorical value lists, and regex rule tables.",
                "test_traceability": [
                    {
                        "id": "tests/test_generator.py::test_from_frequency_table_df",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_multicolumn_frequency_table_df",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_replacement_table",
                        "description": "(can take DataFrame by implication of `data_source` type hint and internal handling)."
                    }
                ],
                "code_traceability": []
            },
            {
                "requirement_id": "EIR-CLDR-XML-INPUT-001",
                "requirement_description": "CLDR Keymap File Format.\n    *   The system shall parse and utilize keyboard layout information from CLDR (Common Locale Data Repository) XML files for the keyboard typo mutator (FR-MUT-CLDR-001).\n    *   The system must interpret XML structure including:\n        *   `<keyMap>` elements, potentially with a `modifiers=\"shift\"` attribute.\n        *   `<map>` elements nested within `<keyMap>`, with `iso` (ISO keyboard position, e.g., \"C01\") and `to` (character output) attributes.\n    *   The system must correctly unescape characters found in the `to` attribute (e.g., HTML entities, Unicode entities like `\\u{22}`).",
                "test_traceability": [
                    {
                        "id": "tests/test_mutator.py::test_with_cldr_keymap_file",
                        "description": "The asset `tests/assets/de-t-k0-windows.xml` serves as an example of the expected format."
                    }
                ],
                "code_traceability": []
            },
            {
                "requirement_id": "EIR-PANDAS-SERIES-IO-001",
                "requirement_description": "Generator and Mutator Functional Signatures.\n    *   Generator factory functions (e.g., `generator.from_frequency_table`) shall return a callable (the \"generator instance\"). This generator instance shall:\n        *   Accept an integer `count` (number of items to generate).\n        *   Return a `list[pandas.Series]`.\n    *   Mutator factory functions (e.g., `mutator.with_delete`) shall return a callable (the \"mutator instance\"). This mutator instance shall:\n        *   Accept a `list[pandas.Series]` (data to mutate) and an optional `float` probability `p`.\n        *   Return a `list[pandas.Series]` (mutated data).",
                "test_traceability": [
                    {
                        "id": "_typedefs.Generator",
                        "description": "Defined by `_typedefs.Generator` and `_typedefs.Mutator` and consistently used in all generator and mutator tests in `tests/test_generator.py` and `tests/test_mutator.py`."
                    }
                ],
                "code_traceability": []
            },
            {
                "requirement_id": "EIR-PANDAS-DATAFRAME-MAIN-001",
                "requirement_description": "DataFrame for Primary Generation and Mutation Operations.\n    *   The `gecko.generator.to_data_frame` function shall accept generator specifications and return a `pandas.DataFrame`.\n    *   The `gecko.mutator.mutate_data_frame` function shall accept a `pandas.DataFrame` and mutator specifications, and return a `pandas.DataFrame`.",
                "test_traceability": [
                    {
                        "id": "tests/test_generator.py::test_to_dataframe",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_mutate_data_frame",
                        "description": ""
                    }
                ],
                "code_traceability": []
            },
            {
                "requirement_id": "OHR-ERR-VAL-001",
                "requirement_description": "Input Validation Errors.\n    *   The system shall raise `ValueError` when provided with invalid input parameters that make an operation impossible, ambiguous, or would lead to an inconsistent state. This includes, but is not limited to:\n        *   Non-positive counts for generation.\n        *   Probabilities outside the [0,1] range.\n        *   Mismatched column specifications or types.\n        *   Empty or malformed input tables/rules where specific content is required.\n        *   Invalid date ranges or formats.",
                "test_traceability": [
                    {
                        "id": "tests/test_dfbitlookup.py::test_with_capacity_raise_rows_too_low",
                        "description": ""
                    },
                    {
                        "id": "tests/test_generator.py::test_from_datetime_range_invalid_start_datetime",
                        "description": ""
                    },
                    {
                        "id": "tests/test_mutator.py::test_with_group_raise_p_sum_too_high",
                        "description": ""
                    }
                ],
                "code_traceability": []
            },
            {
                "requirement_id": "OHR-WARN-GECKO-001",
                "requirement_description": "GeckoWarning for Non-Fatal Issues.\n    *   The system shall issue a `GeckoWarning` (a custom class derived from `UserWarning`) for situations where an operation can proceed but the outcome might not perfectly align with the user's request due to data characteristics or inherent limitations. This primarily applies when a desired mutation probability cannot be fully achieved (see FR-MUT-WARN-P-001).",
                "test_traceability": [
                    {
                        "id": "FR-MUT-WARN-P-001",
                        "description": "Covered by tests for FR-MUT-WARN-P-001, e.g., `tests/test_mutator.py::test_with_cldr_keymap_file_warn_low_p`."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "gecko/_typedefs.py::GeckoWarning",
                        "description": ""
                    },
                    {
                        "id": "gecko/mutator.py::_warn_p",
                        "description": ""
                    }
                ]
            }
        ],
        "commit_sha": "d0d2aa5c7afdacdb1aa33bacf9f2b6da678aa44d",
        "full_code_skeleton": "--- File: gecko/generator.py ---\n```python\n_P = _te.ParamSpec(\"_P\")\n\n\ndef from_function(func: _t.Callable[_P, str], *args: object, **kwargs: object) -> _gt.Generator:\n    \"\"\"\n    Generate data from an arbitrary function that returns a single value at a time.\n\n    Notes:\n        This function should be used sparingly since it is not vectorized.\n        Only use it for testing purposes or if performance is not important.\n\n    Args:\n        func: function to invoke to generate data from\n        *args: positional arguments to pass to `func`\n        **kwargs: keyword arguments to pass to `func`\n\n    Returns:\n        function returning list with strings generated from custom function\n    \"\"\"\n    pass\n\n\ndef from_uniform_distribution(\n    low: _t.Union[int, float] = 0,\n    high: _t.Union[int, float] = 1,\n    precision: int = 6,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from a uniform distribution.\n\n    Args:\n        low: lower limit of uniform distribution (inclusive)\n        high: upper limit of uniform distribution (exclusive)\n        precision: decimal precision of the numbers generated from the uniform distribution\n        rng: random number generator to use\n\n    Returns:\n        function returning list with numbers drawn from a uniform distribution formatted as strings\n    \"\"\"\n    pass\n\n\ndef from_normal_distribution(\n    mean: float = 0,\n    sd: float = 1,\n    precision: int = 6,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from a normal distribution.\n\n    Args:\n        mean: mean of the normal distribution\n        sd: standard deviation of the normal distribution\n        precision: decimal precision of the numbers generated from the normal distribution\n        rng: random number generator to use\n\n    Returns:\n        function returning list with numbers drawn from a normal distribution formatted as strings\n    \"\"\"\n    pass\n\n\ndef from_frequency_table(\n    data_source: _t.Union[str, PathLike[str], pd.DataFrame],\n    value_column: _t.Union[str, int] = 0,\n    freq_column: _t.Union[str, int] = 1,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from a frequency table.\n    The frequency table must be provided in CSV format and contain at least two columns: one containing values to\n    generate and one containing their assigned absolute frequencies.\n    Values generated by this function will have a distribution similar to the frequencies listed in the input file.\n    If the value and frequency column are provided as strings, then it is automatically assumed that the CSV file\n    has a header row.\n\n    Args:\n        data_source: path to CSV file or data frame to use as frequency table\n        value_column: name or index of the value column\n        freq_column: name or index of the frequency column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function returning list with single series containing values generated from the input file\n    \"\"\"\n    pass\n\n\ndef from_multicolumn_frequency_table(\n    data_source: _t.Union[str, PathLike[str], pd.DataFrame],\n    value_columns: _t.Union[int, str, list[int], list[str]] = 0,\n    freq_column: _t.Union[int, str] = 1,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from a frequency table with multiple interdependent columns..\n    The frequency table must be provided in CSV format and contain at least two columns: one containing values to\n    generate and one containing their assigned absolute frequencies.\n    Values generated by this function will have a distribution similar to the frequencies listed in the input file.\n    If the values and frequency column are provided as strings, then it is automatically assumed that the CSV file\n    has a header row.\n\n    Args:\n        data_source: path to CSV file or data frame to use as frequency table\n        value_columns: names or indices of the value columns\n        freq_column: name or index of the frequency column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function returning list with as many series as there are value columns specified containing values generated from the input file\n    \"\"\"\n    pass\n\n\ndef from_datetime_range(\n    start_dt: _t.Union[str, np.datetime64],\n    end_dt: _t.Union[str, np.datetime64],\n    dt_format: str,\n    unit: _gt.DateTimeUnit,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from a range of dates and times.\n    The start and end datetime must be provided either as a ISO 8601 datetime string or a NumPy datetime object.\n    The output format must include the same format codes as specified in the `datetime` Python module for the\n    `strftime` function.\n    The unit specifies the smallest unit of time that may change when generating random dates and times.\n    For example if `D` is specified, generated dates will only differ in their days, months and years, leaving hours,\n    minutes and seconds unaffected.\n    The same applies for `h`, `m` and `s` for hours, minutes and seconds respectively.\n\n    Args:\n        start_dt: datetime string or object for start of range\n        end_dt: datetime string or object for end of range\n        dt_format: output format for generated datetimes\n        unit: smallest unit of time that may change when generating random dates and times\n        rng: random number generator to use\n\n    Returns:\n        function returning list of random datetime strings within the specified range\n    \"\"\"\n    pass\n\n\n_WeightedGenerator = tuple[_t.Union[int, float], _gt.Generator]\n\n\ndef _is_weighted_generator(x: object) -> _te.TypeGuard[_WeightedGenerator]:\n    pass\n\n\ndef from_group(\n    generator_lst: _t.Union[list[_gt.Generator], list[_WeightedGenerator]],\n    max_rounding_adjustment: int = 0,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from multiple generators.\n    Unless explicitly specified, all generators will generate data with equal probability.\n    Alternatively generators can be assigned fixed probabilities.\n    The output of each generator is then shuffled.\n    If all generators generate multiple series, then all series are shuffled the same.\n    Due to rounding errors, it may occur that the computed amount of rows to generate for each generator does\n    not exactly sum up to the desired amount of rows.\n    To compensate, this generator allows the specification of a maximum amount of rows that may be added or removed\n    to random generators to match the target amount of rows.\n\n    Args:\n        generator_lst: list of (weighted) generators\n        max_rounding_adjustment: maximum amount of rows to add or remove if the computed amount of total rows does not match the desired amount of rows\n        rng: random number generator to use\n\n    Returns:\n        function returning list of random data generated using supplied generators\n    \"\"\"\n    pass\n\n\n_GeneratorSpec = list[tuple[_t.Union[str, tuple[str, ...]], _gt.Generator]]\n\n\ndef to_data_frame(\n    generator_lst: _GeneratorSpec,\n    count: int,\n) -> pd.DataFrame:\n    \"\"\"\n    Generate data frame by using multiple generators at once.\n    Column names must be mapped to their respective generators.\n    A generator can be assigned to one or multiple column names, but it must always match the amount of series\n    that the generator returns.\n\n    Args:\n        generator_lst: list of column names to generators\n        count: amount of records to generate\n\n    Returns:\n        data frame with columns and rows generated as specified\n    \"\"\"\n    pass\n```\n--- File: gecko/_typedefs.py ---\n```python\nGenerator = _t.Callable[[int], list[pd.Series]]\nMutator = _t.Callable[[list[pd.Series], _t.Optional[float]], list[pd.Series]]\nDateTimeUnit = _t.Literal[\"d\", \"days\", \"h\", \"hours\", \"m\", \"minutes\", \"s\", \"seconds\"]\n\n\nclass GeckoWarning(UserWarning):\n    \"\"\"\n    Generic class that represents all warnings emitted by Gecko.\n    \"\"\"\n\n    pass\n\n\ndef convert_gecko_date_time_unit_to_pandas(unit: str) -> str:\n    pass\n```\n--- File: gecko/__init__.py ---\n```python\n```\n--- File: gecko/mutator.py ---\n```python\nclass _PhoneticReplacementRule(_t.NamedTuple):\n    pattern: str\n    replacement: str\n    flag: str\n\n\ndef _check_probability_in_bounds(p: float):\n    pass\n\n\n@dataclass(frozen=True)\nclass KeyMutation:\n    row: list[str] = field(default_factory=list)\n    col: list[str] = field(default_factory=list)\n\n\n_P = _te.ParamSpec(\"_P\")\n\n\ndef _warn_p(fn_name: str, p_expected: float, p_actual: float):\n    pass\n\n\ndef with_function(\n    func: _t.Callable[_te.Concatenate[str, _P], str],\n    rng: _t.Optional[np.random.Generator] = None,\n    *args: object,\n    **kwargs: object,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series using an arbitrary function that mutates a single value at a time.\n\n    Notes:\n        This function should be used sparingly since it is not vectorized.\n        Only use it for testing purposes or if performance is not important.\n\n    Args:\n        func: function to mutate values with\n        rng: random number generator to use\n        *args: positional arguments to pass to `func`\n        **kwargs: keyword arguments to pass to `func`\n\n    Returns:\n        function that mutates series using the custom function\n    \"\"\"\n    pass\n\n\ndef with_cldr_keymap_file(\n    cldr_path: _t.Union[PathLike, str],\n    charset: _t.Optional[_t.Union[str, list[str]]] = None,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly introducing typos.\n    Potential typos are sourced from a Common Locale Data Repository (CLDR) keymap.\n    Any character may be replaced with one of its horizontal or vertical neighbors on a keyboard.\n    They may also be replaced with its upper- or lowercase variant.\n    It is possible for a string to not be modified if a selected character has no possible replacements.\n    If the `charset` parameter is `None`, then any character present on the keymap may be mutated.\n\n    Args:\n        cldr_path: path to CLDR keymap file\n        charset: character string or list of characters that may be mutated\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series using a keymap\n    \"\"\"\n    pass\n\n\ndef with_phonetic_replacement_table(\n    data_source: _t.Union[PathLike, str, pd.DataFrame],\n    source_column: _t.Union[int, str] = 0,\n    target_column: _t.Union[int, str] = 1,\n    flags_column: _t.Union[int, str] = 2,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly replacing character sequences with others that sound similar.\n    The rules for similar-sounding character sequences are sourced from a table.\n    This table must have at least three columns: a source, target and a flag column.\n    A source pattern is mapped to its target under the rules imposed by the provided flags.\n    These flags determine where such a replacement can take place within a string.\n    If no flags are defined, it is implied that this replacement can take place anywhere in a string.\n    Conversely, if `^`, `$`, `_`, or any combination of the three are set, it implies that a replacement\n    can only occur at the start, end or in the middle of a string.\n    If the source, target and flags column are provided as strings, and if a path to a CSV file is\n    provided to this function, then it is automatically assumed that the CSV file has a header row.\n\n    Args:\n        data_source: path to CSV file or data frame containing phonetic replacement rules\n        source_column: name or index of source column\n        target_column: name or index of target column\n        flags_column: name or index of flag column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n       function that mutates series using phonetic rules sourced from a table\n    \"\"\"\n    pass\n\n\ndef with_replacement_table(\n    data_source: _t.Union[PathLike, str, pd.DataFrame],\n    source_column: _t.Union[str, int] = 0,\n    target_column: _t.Union[str, int] = 1,\n    inline: bool = False,\n    reverse: bool = False,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly substituting character sequences from a replacement table.\n    The table must have at least two columns: a source and a target value column.\n    A source value may have multiple target values that it can map to.\n    Strings that do not contain any possible source values are not mutated.\n    It is possible for a string to not be modified if no target value could be picked for its assigned source value.\n    This can only happen if a source value is mapped to multiple target values.\n    In this case, each target value will be independently selected or not.\n    If the source and target column are provided as strings, and a path to a CSV file is provided\n    to this function, then it is automatically assumed that the CSV file has a header row.\n    The mutator will favor less common replacements over more common ones.\n\n    Args:\n        data_source: path to CSV file or data frame containing replacement table\n        source_column: name or index of the source column\n        target_column: name or index of the target column\n        inline: whether to perform replacements inline\n        reverse: whether to allow replacements from target to source column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series according to a replacement table\n    \"\"\"\n    pass\n\n\ndef with_missing_value(\n    value: str = \"\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by replacing its values with a representative \"missing\" value.\n\n    Args:\n        value: \"missing\" value to replace select entries with\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by overwriting it with a \"missing\" value\n    \"\"\"\n    pass\n\n\ndef with_insert(\n    charset: _t.Union[str, list[str]] = string.ascii_letters,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by inserting random characters.\n    The characters are drawn from the provided charset.\n\n    Args:\n        charset: character string or list of characters to sample from\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by injecting random characters\n    \"\"\"\n    pass\n\n\ndef with_delete(rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly deleting characters.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by deleting random characters\n    \"\"\"\n    pass\n\n\ndef with_transpose(rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly swapping neighboring characters.\n\n    Notes:\n        It is possible for the same two neighboring characters to be swapped.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by swapping adjacent characters\n    \"\"\"\n    pass\n\n\ndef with_substitute(\n    charset: _t.Union[str, list[str]] = string.ascii_letters,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate data by replacing single characters with a new one.\n    The characters are drawn from the provided charset.\n\n    Notes:\n        It is possible for a character to be replaced by itself.\n\n    Args:\n        charset: character string or list of characters to sample from\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by substituting random characters\n    \"\"\"\n    pass\n\n\ndef with_noop() -> _gt.Mutator:\n    \"\"\"\n    Mutate series by not mutating it at all.\n    This mutator returns the input series as-is.\n    You might use it to leave a certain percentage of records in a series untouched.\n\n    Returns:\n        function that does not mutate series\n    \"\"\"\n    pass\n\n\ndef with_categorical_values(\n    data_source: _t.Union[PathLike, str, pd.DataFrame],\n    value_column: _t.Union[str, int] = 0,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by replacing values with another from a list of categorical values.\n    This mutator reads all unique values from a singular column.\n    All values within a series will be replaced with a different random value from this column.\n    If the value column is provided as a string, and a path to a CSV file is provided to this\n    function, then it is automatically assumed that the CSV file has a header row.\n\n    Args:\n        data_source: path to CSV file or data frame containing values\n        value_column: name or index of value column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by replacing values with a different one from a limited set of permitted values\n    \"\"\"\n    pass\n\n\ndef with_permute(rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by permuting their contents.\n    This function ensures that rows are permuted in such a way that no value remains in the series\n    it originated from.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by permuting their contents\n    \"\"\"\n    pass\n\n\ndef with_lowercase(rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by converting its contents to lowercase.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by converting its contents to lowercase\n    \"\"\"\n    pass\n\n\ndef with_uppercase(rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by converting its contents to uppercase.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by converting its contents to uppercase\n    \"\"\"\n    pass\n\n\ndef with_datetime_offset(\n    max_delta: int,\n    unit: _gt.DateTimeUnit,\n    dt_format: str,\n    prevent_wraparound: bool = False,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by treating their contents it as datetime information and offsetting it by random amounts.\n    The delta and the unit specify which datetime field should be affected, where possible values are\n    `d` and `days`, `h` and `hours`, `m` and `minutes`, `s` and `seconds`.\n    The datetime format must include the same format codes as specified in the `datetime` Python module for the\n    `strftime` function.\n    By setting `prevent_wraparound` to `True`, this mutator will not apply a mutation if it will cause an\n    unrelated field to change its value, e.g. when subtracting a day from July 1st, 2001.\n\n    Args:\n        max_delta: maximum amount of units to change by\n        unit: affected datetime field\n        dt_format: input and output datetime format\n        prevent_wraparound: `True` if unrelated fields should not be modified, `False` otherwise\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by applying random date and time offsets to them\n    \"\"\"\n    pass\n\n\ndef with_generator(\n    generator: _gt.Generator,\n    mode: _t.Literal[\"prepend\", \"append\", \"replace\"],\n    join_with: str = \" \",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by replacing its content by appending, prepending or replacing it with data from another generator.\n    A string to join generated data with when appending or prepending can be provided.\n    Using `{}` in the `join_with` parameter will cause it to be replaced by generated values.\n    Only the first occurrence of `{}` will be replaced.\n\n    Args:\n        generator: generator to source data from\n        mode: either append, prepend or replace\n        join_with: string to join present and generated data with\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series using another generator\n    \"\"\"\n    pass\n\n\ndef _new_regex_replacement_fn(srs: pd.Series) -> _t.Callable[[re.Match], str]:\n    pass\n\n\ndef _parse_regex_flags(regex_flags_val: str) -> int:\n    pass\n\n\ndef with_regex_replacement_table(\n    data_source: _t.Union[PathLike, str, pd.DataFrame],\n    pattern_column: str = \"pattern\",\n    flags_column: _t.Optional[str] = None,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by performing regex-based substitutions sourced from a table.\n    This table must contain a column with the regex patterns to look for and columns for each capture group to look up\n    substitutions.\n    When using regular capture groups, the columns must be numbered starting with 1.\n    When using named capture groups, the columns must be named after the capture groups they are supposed to substitute.\n\n    Args:\n        data_source: path to CSV file or data frame containing regex-based substitutions\n        pattern_column: name of regex pattern column\n        flags_column: name of regex flag column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by performing regex-based substitutions\n    \"\"\"\n    pass\n\n\ndef with_repeat(join_with: str = \" \", rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by repeating its contents.\n    By default, selected entries will be duplicated and separated by a whitespace.\n\n    Args:\n        join_with: joining character to use, space by default\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by repeating its contents\n    \"\"\"\n    pass\n\n\n_WeightedMutatorDef = tuple[_t.Union[int, float], _gt.Mutator]\n\n\ndef _is_weighted_mutator_tuple(\n    x: object,\n) -> _te.TypeGuard[_WeightedMutatorDef]:\n    pass\n\n\ndef _is_weighted_mutator_tuple_list(\n    x: object,\n) -> _te.TypeGuard[list[_WeightedMutatorDef]]:\n    pass\n\n\ndef with_group(\n    mutator_lst: _t.Union[list[_gt.Mutator], list[_WeightedMutatorDef]],\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by applying multiple mutators on it.\n    The mutators are applied in the order that they are provided in to this function.\n    When providing a list of mutators, each row will be affected by each mutator with an equal probability.\n    When providing a list of weighted mutators, each row will be affected by each mutator with the\n    specified probabilities.\n    If the probabilities do not sum up to 1, an additional mutator is added which does not modify input data.\n\n    Args:\n        mutator_lst: list of mutators or weighted mutators\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series using multiple mutually exclusive mutators at once\n    \"\"\"\n    pass\n\n\n_MutatorDef = _t.Union[_gt.Mutator, tuple[_t.Union[int, float], _gt.Mutator]]\n_MutatorSpec = list[tuple[_t.Union[str, tuple[str, ...]], _t.Union[_MutatorDef, list[_MutatorDef]]]]\n\n\ndef mutate_data_frame(\n    df_in: pd.DataFrame,\n    mutator_lst: _MutatorSpec,\n) -> pd.DataFrame:\n    \"\"\"\n    Mutate a data frame by applying several mutators on select columns.\n    This function takes a list which contains columns and mutators that are assigned to them.\n    A column may be assigned a single mutator, a mutator with a probability, a list of mutators where each is applied\n    with the same probability, and a list of weighted mutators where each is applied with its assigned probability.\n\n    Args:\n        df_in: data frame to mutate\n        mutator_lst: list of columns with their mutator assignments\n\n    Returns:\n        data frame with columns mutated as specified\n    \"\"\"\n    pass\n```\n--- File: gecko/_dfbitlookup.py ---\n```python\ndef with_capacity(rows: int, capacity: int, index: _t.Optional[pd.Index] = None):\n    \"\"\"\n    Construct a new data frame that is capable of storing the desired capacity of bits for the desired\n    number of rows.\n    An index object can be supplied to align the data frame returned by this function with another\n    Pandas object.\n\n    Args:\n        rows: amount of rows\n        capacity: maximum amount of bits\n        index: index to align to\n\n    Returns:\n        Data frame to set and test bits on across all of its rows\n    \"\"\"\n    pass\n\n\ndef _divmod(num: int, div: int):\n    \"\"\"\n    Alternative for the built-in divmod function which returns ints instead of floats.\n\n    Args:\n        num: dividend\n        div: divisor\n\n    Returns:\n        quotient and remainder as integers\n    \"\"\"\n    pass\n\n\ndef set_index(df: pd.DataFrame, mask: _te.Union[pd.Series, slice, list[bool]], idx: int):\n    \"\"\"\n    Set a bit on all selected rows at the specified index.\n\n    Args:\n        df: data frame to perform operation on\n        mask: series or list of booleans to select rows to set bit in with\n        idx: index of the bit to set\n    \"\"\"\n    pass\n\n\ndef test_index(df: pd.DataFrame, idx: int) -> pd.Series:\n    \"\"\"\n    Test a bit on all rows at the specified index.\n\n    Args:\n        df: data frame to perform operation on\n        idx: index of the bit to test\n\n    Returns:\n        series of booleans representing rows where the selected bit is set\n    \"\"\"\n    pass\n\n\ndef any_set(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Test whether any bits are set for each row.\n\n    Args:\n        df: data frame to perform operation on\n\n    Returns:\n        series of booleans representing rows where any bit is set\n    \"\"\"\n    pass\n\n\ndef count_bits_per_index(df: pd.DataFrame, capacity: _t.Optional[int] = None) -> list[tuple[int, int]]:\n    \"\"\"\n    Count the bits set for each index across all rows.\n    If provided, this function will use the capacity argument as the upper bound for indices to count.\n    If not provided, it will be inferred from the number of columns in the data frame.\n\n    Args:\n        df: data frame to perform operation on\n        capacity: maximum amount of bits to test\n\n    Returns:\n        list of tuples where the first int representing the index and the second int representing the number of set bits\n    \"\"\"\n    pass\n\n\ndef count_bits_per_row(df: pd.DataFrame, capacity: _t.Optional[int] = None) -> pd.Series:\n    pass\n```\n--- File: gecko/_cldr.py ---\n```python\ndef uppercase_char_to_index(char: str) -> int:\n    pass\n\n\ndef unescape_kb_char(char: str) -> str:\n    pass\n\n\n@lru_cache\ndef decode_iso_kb_pos(iso_kb_pos_str: str) -> (int, int):\n    pass\n\n\ndef get_neighbor_kb_pos_for(kb_pos: tuple[int, int, int], max_row: int, max_col: int) -> list[tuple[int, int, int]]:\n    pass\n```",
        "full_code_skeleton_structured": [
            {
                "file_path": "gecko/generator.py",
                "code": "_P = _te.ParamSpec(\"_P\")\n\n\ndef from_function(func: _t.Callable[_P, str], *args: object, **kwargs: object) -> _gt.Generator:\n    \"\"\"\n    Generate data from an arbitrary function that returns a single value at a time.\n\n    Notes:\n        This function should be used sparingly since it is not vectorized.\n        Only use it for testing purposes or if performance is not important.\n\n    Args:\n        func: function to invoke to generate data from\n        *args: positional arguments to pass to `func`\n        **kwargs: keyword arguments to pass to `func`\n\n    Returns:\n        function returning list with strings generated from custom function\n    \"\"\"\n    pass\n\n\ndef from_uniform_distribution(\n    low: _t.Union[int, float] = 0,\n    high: _t.Union[int, float] = 1,\n    precision: int = 6,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from a uniform distribution.\n\n    Args:\n        low: lower limit of uniform distribution (inclusive)\n        high: upper limit of uniform distribution (exclusive)\n        precision: decimal precision of the numbers generated from the uniform distribution\n        rng: random number generator to use\n\n    Returns:\n        function returning list with numbers drawn from a uniform distribution formatted as strings\n    \"\"\"\n    pass\n\n\ndef from_normal_distribution(\n    mean: float = 0,\n    sd: float = 1,\n    precision: int = 6,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from a normal distribution.\n\n    Args:\n        mean: mean of the normal distribution\n        sd: standard deviation of the normal distribution\n        precision: decimal precision of the numbers generated from the normal distribution\n        rng: random number generator to use\n\n    Returns:\n        function returning list with numbers drawn from a normal distribution formatted as strings\n    \"\"\"\n    pass\n\n\ndef from_frequency_table(\n    data_source: _t.Union[str, PathLike[str], pd.DataFrame],\n    value_column: _t.Union[str, int] = 0,\n    freq_column: _t.Union[str, int] = 1,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from a frequency table.\n    The frequency table must be provided in CSV format and contain at least two columns: one containing values to\n    generate and one containing their assigned absolute frequencies.\n    Values generated by this function will have a distribution similar to the frequencies listed in the input file.\n    If the value and frequency column are provided as strings, then it is automatically assumed that the CSV file\n    has a header row.\n\n    Args:\n        data_source: path to CSV file or data frame to use as frequency table\n        value_column: name or index of the value column\n        freq_column: name or index of the frequency column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function returning list with single series containing values generated from the input file\n    \"\"\"\n    pass\n\n\ndef from_multicolumn_frequency_table(\n    data_source: _t.Union[str, PathLike[str], pd.DataFrame],\n    value_columns: _t.Union[int, str, list[int], list[str]] = 0,\n    freq_column: _t.Union[int, str] = 1,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from a frequency table with multiple interdependent columns..\n    The frequency table must be provided in CSV format and contain at least two columns: one containing values to\n    generate and one containing their assigned absolute frequencies.\n    Values generated by this function will have a distribution similar to the frequencies listed in the input file.\n    If the values and frequency column are provided as strings, then it is automatically assumed that the CSV file\n    has a header row.\n\n    Args:\n        data_source: path to CSV file or data frame to use as frequency table\n        value_columns: names or indices of the value columns\n        freq_column: name or index of the frequency column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function returning list with as many series as there are value columns specified containing values generated from the input file\n    \"\"\"\n    pass\n\n\ndef from_datetime_range(\n    start_dt: _t.Union[str, np.datetime64],\n    end_dt: _t.Union[str, np.datetime64],\n    dt_format: str,\n    unit: _gt.DateTimeUnit,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from a range of dates and times.\n    The start and end datetime must be provided either as a ISO 8601 datetime string or a NumPy datetime object.\n    The output format must include the same format codes as specified in the `datetime` Python module for the\n    `strftime` function.\n    The unit specifies the smallest unit of time that may change when generating random dates and times.\n    For example if `D` is specified, generated dates will only differ in their days, months and years, leaving hours,\n    minutes and seconds unaffected.\n    The same applies for `h`, `m` and `s` for hours, minutes and seconds respectively.\n\n    Args:\n        start_dt: datetime string or object for start of range\n        end_dt: datetime string or object for end of range\n        dt_format: output format for generated datetimes\n        unit: smallest unit of time that may change when generating random dates and times\n        rng: random number generator to use\n\n    Returns:\n        function returning list of random datetime strings within the specified range\n    \"\"\"\n    pass\n\n\n_WeightedGenerator = tuple[_t.Union[int, float], _gt.Generator]\n\n\ndef _is_weighted_generator(x: object) -> _te.TypeGuard[_WeightedGenerator]:\n    pass\n\n\ndef from_group(\n    generator_lst: _t.Union[list[_gt.Generator], list[_WeightedGenerator]],\n    max_rounding_adjustment: int = 0,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from multiple generators.\n    Unless explicitly specified, all generators will generate data with equal probability.\n    Alternatively generators can be assigned fixed probabilities.\n    The output of each generator is then shuffled.\n    If all generators generate multiple series, then all series are shuffled the same.\n    Due to rounding errors, it may occur that the computed amount of rows to generate for each generator does\n    not exactly sum up to the desired amount of rows.\n    To compensate, this generator allows the specification of a maximum amount of rows that may be added or removed\n    to random generators to match the target amount of rows.\n\n    Args:\n        generator_lst: list of (weighted) generators\n        max_rounding_adjustment: maximum amount of rows to add or remove if the computed amount of total rows does not match the desired amount of rows\n        rng: random number generator to use\n\n    Returns:\n        function returning list of random data generated using supplied generators\n    \"\"\"\n    pass\n\n\n_GeneratorSpec = list[tuple[_t.Union[str, tuple[str, ...]], _gt.Generator]]\n\n\ndef to_data_frame(\n    generator_lst: _GeneratorSpec,\n    count: int,\n) -> pd.DataFrame:\n    \"\"\"\n    Generate data frame by using multiple generators at once.\n    Column names must be mapped to their respective generators.\n    A generator can be assigned to one or multiple column names, but it must always match the amount of series\n    that the generator returns.\n\n    Args:\n        generator_lst: list of column names to generators\n        count: amount of records to generate\n\n    Returns:\n        data frame with columns and rows generated as specified\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "gecko/_typedefs.py",
                "code": "Generator = _t.Callable[[int], list[pd.Series]]\nMutator = _t.Callable[[list[pd.Series], _t.Optional[float]], list[pd.Series]]\nDateTimeUnit = _t.Literal[\"d\", \"days\", \"h\", \"hours\", \"m\", \"minutes\", \"s\", \"seconds\"]\n\n\nclass GeckoWarning(UserWarning):\n    \"\"\"\n    Generic class that represents all warnings emitted by Gecko.\n    \"\"\"\n\n    pass\n\n\ndef convert_gecko_date_time_unit_to_pandas(unit: str) -> str:\n    pass\n"
            },
            {
                "file_path": "gecko/__init__.py",
                "code": ""
            },
            {
                "file_path": "gecko/mutator.py",
                "code": "class _PhoneticReplacementRule(_t.NamedTuple):\n    pattern: str\n    replacement: str\n    flag: str\n\n\ndef _check_probability_in_bounds(p: float):\n    pass\n\n\n@dataclass(frozen=True)\nclass KeyMutation:\n    row: list[str] = field(default_factory=list)\n    col: list[str] = field(default_factory=list)\n\n\n_P = _te.ParamSpec(\"_P\")\n\n\ndef _warn_p(fn_name: str, p_expected: float, p_actual: float):\n    pass\n\n\ndef with_function(\n    func: _t.Callable[_te.Concatenate[str, _P], str],\n    rng: _t.Optional[np.random.Generator] = None,\n    *args: object,\n    **kwargs: object,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series using an arbitrary function that mutates a single value at a time.\n\n    Notes:\n        This function should be used sparingly since it is not vectorized.\n        Only use it for testing purposes or if performance is not important.\n\n    Args:\n        func: function to mutate values with\n        rng: random number generator to use\n        *args: positional arguments to pass to `func`\n        **kwargs: keyword arguments to pass to `func`\n\n    Returns:\n        function that mutates series using the custom function\n    \"\"\"\n    pass\n\n\ndef with_cldr_keymap_file(\n    cldr_path: _t.Union[PathLike, str],\n    charset: _t.Optional[_t.Union[str, list[str]]] = None,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly introducing typos.\n    Potential typos are sourced from a Common Locale Data Repository (CLDR) keymap.\n    Any character may be replaced with one of its horizontal or vertical neighbors on a keyboard.\n    They may also be replaced with its upper- or lowercase variant.\n    It is possible for a string to not be modified if a selected character has no possible replacements.\n    If the `charset` parameter is `None`, then any character present on the keymap may be mutated.\n\n    Args:\n        cldr_path: path to CLDR keymap file\n        charset: character string or list of characters that may be mutated\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series using a keymap\n    \"\"\"\n    pass\n\n\ndef with_phonetic_replacement_table(\n    data_source: _t.Union[PathLike, str, pd.DataFrame],\n    source_column: _t.Union[int, str] = 0,\n    target_column: _t.Union[int, str] = 1,\n    flags_column: _t.Union[int, str] = 2,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly replacing character sequences with others that sound similar.\n    The rules for similar-sounding character sequences are sourced from a table.\n    This table must have at least three columns: a source, target and a flag column.\n    A source pattern is mapped to its target under the rules imposed by the provided flags.\n    These flags determine where such a replacement can take place within a string.\n    If no flags are defined, it is implied that this replacement can take place anywhere in a string.\n    Conversely, if `^`, `$`, `_`, or any combination of the three are set, it implies that a replacement\n    can only occur at the start, end or in the middle of a string.\n    If the source, target and flags column are provided as strings, and if a path to a CSV file is\n    provided to this function, then it is automatically assumed that the CSV file has a header row.\n\n    Args:\n        data_source: path to CSV file or data frame containing phonetic replacement rules\n        source_column: name or index of source column\n        target_column: name or index of target column\n        flags_column: name or index of flag column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n       function that mutates series using phonetic rules sourced from a table\n    \"\"\"\n    pass\n\n\ndef with_replacement_table(\n    data_source: _t.Union[PathLike, str, pd.DataFrame],\n    source_column: _t.Union[str, int] = 0,\n    target_column: _t.Union[str, int] = 1,\n    inline: bool = False,\n    reverse: bool = False,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly substituting character sequences from a replacement table.\n    The table must have at least two columns: a source and a target value column.\n    A source value may have multiple target values that it can map to.\n    Strings that do not contain any possible source values are not mutated.\n    It is possible for a string to not be modified if no target value could be picked for its assigned source value.\n    This can only happen if a source value is mapped to multiple target values.\n    In this case, each target value will be independently selected or not.\n    If the source and target column are provided as strings, and a path to a CSV file is provided\n    to this function, then it is automatically assumed that the CSV file has a header row.\n    The mutator will favor less common replacements over more common ones.\n\n    Args:\n        data_source: path to CSV file or data frame containing replacement table\n        source_column: name or index of the source column\n        target_column: name or index of the target column\n        inline: whether to perform replacements inline\n        reverse: whether to allow replacements from target to source column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series according to a replacement table\n    \"\"\"\n    pass\n\n\ndef with_missing_value(\n    value: str = \"\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by replacing its values with a representative \"missing\" value.\n\n    Args:\n        value: \"missing\" value to replace select entries with\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by overwriting it with a \"missing\" value\n    \"\"\"\n    pass\n\n\ndef with_insert(\n    charset: _t.Union[str, list[str]] = string.ascii_letters,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by inserting random characters.\n    The characters are drawn from the provided charset.\n\n    Args:\n        charset: character string or list of characters to sample from\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by injecting random characters\n    \"\"\"\n    pass\n\n\ndef with_delete(rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly deleting characters.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by deleting random characters\n    \"\"\"\n    pass\n\n\ndef with_transpose(rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly swapping neighboring characters.\n\n    Notes:\n        It is possible for the same two neighboring characters to be swapped.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by swapping adjacent characters\n    \"\"\"\n    pass\n\n\ndef with_substitute(\n    charset: _t.Union[str, list[str]] = string.ascii_letters,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate data by replacing single characters with a new one.\n    The characters are drawn from the provided charset.\n\n    Notes:\n        It is possible for a character to be replaced by itself.\n\n    Args:\n        charset: character string or list of characters to sample from\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by substituting random characters\n    \"\"\"\n    pass\n\n\ndef with_noop() -> _gt.Mutator:\n    \"\"\"\n    Mutate series by not mutating it at all.\n    This mutator returns the input series as-is.\n    You might use it to leave a certain percentage of records in a series untouched.\n\n    Returns:\n        function that does not mutate series\n    \"\"\"\n    pass\n\n\ndef with_categorical_values(\n    data_source: _t.Union[PathLike, str, pd.DataFrame],\n    value_column: _t.Union[str, int] = 0,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by replacing values with another from a list of categorical values.\n    This mutator reads all unique values from a singular column.\n    All values within a series will be replaced with a different random value from this column.\n    If the value column is provided as a string, and a path to a CSV file is provided to this\n    function, then it is automatically assumed that the CSV file has a header row.\n\n    Args:\n        data_source: path to CSV file or data frame containing values\n        value_column: name or index of value column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by replacing values with a different one from a limited set of permitted values\n    \"\"\"\n    pass\n\n\ndef with_permute(rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by permuting their contents.\n    This function ensures that rows are permuted in such a way that no value remains in the series\n    it originated from.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by permuting their contents\n    \"\"\"\n    pass\n\n\ndef with_lowercase(rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by converting its contents to lowercase.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by converting its contents to lowercase\n    \"\"\"\n    pass\n\n\ndef with_uppercase(rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by converting its contents to uppercase.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by converting its contents to uppercase\n    \"\"\"\n    pass\n\n\ndef with_datetime_offset(\n    max_delta: int,\n    unit: _gt.DateTimeUnit,\n    dt_format: str,\n    prevent_wraparound: bool = False,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by treating their contents it as datetime information and offsetting it by random amounts.\n    The delta and the unit specify which datetime field should be affected, where possible values are\n    `d` and `days`, `h` and `hours`, `m` and `minutes`, `s` and `seconds`.\n    The datetime format must include the same format codes as specified in the `datetime` Python module for the\n    `strftime` function.\n    By setting `prevent_wraparound` to `True`, this mutator will not apply a mutation if it will cause an\n    unrelated field to change its value, e.g. when subtracting a day from July 1st, 2001.\n\n    Args:\n        max_delta: maximum amount of units to change by\n        unit: affected datetime field\n        dt_format: input and output datetime format\n        prevent_wraparound: `True` if unrelated fields should not be modified, `False` otherwise\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by applying random date and time offsets to them\n    \"\"\"\n    pass\n\n\ndef with_generator(\n    generator: _gt.Generator,\n    mode: _t.Literal[\"prepend\", \"append\", \"replace\"],\n    join_with: str = \" \",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by replacing its content by appending, prepending or replacing it with data from another generator.\n    A string to join generated data with when appending or prepending can be provided.\n    Using `{}` in the `join_with` parameter will cause it to be replaced by generated values.\n    Only the first occurrence of `{}` will be replaced.\n\n    Args:\n        generator: generator to source data from\n        mode: either append, prepend or replace\n        join_with: string to join present and generated data with\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series using another generator\n    \"\"\"\n    pass\n\n\ndef _new_regex_replacement_fn(srs: pd.Series) -> _t.Callable[[re.Match], str]:\n    pass\n\n\ndef _parse_regex_flags(regex_flags_val: str) -> int:\n    pass\n\n\ndef with_regex_replacement_table(\n    data_source: _t.Union[PathLike, str, pd.DataFrame],\n    pattern_column: str = \"pattern\",\n    flags_column: _t.Optional[str] = None,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by performing regex-based substitutions sourced from a table.\n    This table must contain a column with the regex patterns to look for and columns for each capture group to look up\n    substitutions.\n    When using regular capture groups, the columns must be numbered starting with 1.\n    When using named capture groups, the columns must be named after the capture groups they are supposed to substitute.\n\n    Args:\n        data_source: path to CSV file or data frame containing regex-based substitutions\n        pattern_column: name of regex pattern column\n        flags_column: name of regex flag column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by performing regex-based substitutions\n    \"\"\"\n    pass\n\n\ndef with_repeat(join_with: str = \" \", rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by repeating its contents.\n    By default, selected entries will be duplicated and separated by a whitespace.\n\n    Args:\n        join_with: joining character to use, space by default\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by repeating its contents\n    \"\"\"\n    pass\n\n\n_WeightedMutatorDef = tuple[_t.Union[int, float], _gt.Mutator]\n\n\ndef _is_weighted_mutator_tuple(\n    x: object,\n) -> _te.TypeGuard[_WeightedMutatorDef]:\n    pass\n\n\ndef _is_weighted_mutator_tuple_list(\n    x: object,\n) -> _te.TypeGuard[list[_WeightedMutatorDef]]:\n    pass\n\n\ndef with_group(\n    mutator_lst: _t.Union[list[_gt.Mutator], list[_WeightedMutatorDef]],\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by applying multiple mutators on it.\n    The mutators are applied in the order that they are provided in to this function.\n    When providing a list of mutators, each row will be affected by each mutator with an equal probability.\n    When providing a list of weighted mutators, each row will be affected by each mutator with the\n    specified probabilities.\n    If the probabilities do not sum up to 1, an additional mutator is added which does not modify input data.\n\n    Args:\n        mutator_lst: list of mutators or weighted mutators\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series using multiple mutually exclusive mutators at once\n    \"\"\"\n    pass\n\n\n_MutatorDef = _t.Union[_gt.Mutator, tuple[_t.Union[int, float], _gt.Mutator]]\n_MutatorSpec = list[tuple[_t.Union[str, tuple[str, ...]], _t.Union[_MutatorDef, list[_MutatorDef]]]]\n\n\ndef mutate_data_frame(\n    df_in: pd.DataFrame,\n    mutator_lst: _MutatorSpec,\n) -> pd.DataFrame:\n    \"\"\"\n    Mutate a data frame by applying several mutators on select columns.\n    This function takes a list which contains columns and mutators that are assigned to them.\n    A column may be assigned a single mutator, a mutator with a probability, a list of mutators where each is applied\n    with the same probability, and a list of weighted mutators where each is applied with its assigned probability.\n\n    Args:\n        df_in: data frame to mutate\n        mutator_lst: list of columns with their mutator assignments\n\n    Returns:\n        data frame with columns mutated as specified\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "gecko/_dfbitlookup.py",
                "code": "def with_capacity(rows: int, capacity: int, index: _t.Optional[pd.Index] = None):\n    \"\"\"\n    Construct a new data frame that is capable of storing the desired capacity of bits for the desired\n    number of rows.\n    An index object can be supplied to align the data frame returned by this function with another\n    Pandas object.\n\n    Args:\n        rows: amount of rows\n        capacity: maximum amount of bits\n        index: index to align to\n\n    Returns:\n        Data frame to set and test bits on across all of its rows\n    \"\"\"\n    pass\n\n\ndef _divmod(num: int, div: int):\n    \"\"\"\n    Alternative for the built-in divmod function which returns ints instead of floats.\n\n    Args:\n        num: dividend\n        div: divisor\n\n    Returns:\n        quotient and remainder as integers\n    \"\"\"\n    pass\n\n\ndef set_index(df: pd.DataFrame, mask: _te.Union[pd.Series, slice, list[bool]], idx: int):\n    \"\"\"\n    Set a bit on all selected rows at the specified index.\n\n    Args:\n        df: data frame to perform operation on\n        mask: series or list of booleans to select rows to set bit in with\n        idx: index of the bit to set\n    \"\"\"\n    pass\n\n\ndef test_index(df: pd.DataFrame, idx: int) -> pd.Series:\n    \"\"\"\n    Test a bit on all rows at the specified index.\n\n    Args:\n        df: data frame to perform operation on\n        idx: index of the bit to test\n\n    Returns:\n        series of booleans representing rows where the selected bit is set\n    \"\"\"\n    pass\n\n\ndef any_set(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Test whether any bits are set for each row.\n\n    Args:\n        df: data frame to perform operation on\n\n    Returns:\n        series of booleans representing rows where any bit is set\n    \"\"\"\n    pass\n\n\ndef count_bits_per_index(df: pd.DataFrame, capacity: _t.Optional[int] = None) -> list[tuple[int, int]]:\n    \"\"\"\n    Count the bits set for each index across all rows.\n    If provided, this function will use the capacity argument as the upper bound for indices to count.\n    If not provided, it will be inferred from the number of columns in the data frame.\n\n    Args:\n        df: data frame to perform operation on\n        capacity: maximum amount of bits to test\n\n    Returns:\n        list of tuples where the first int representing the index and the second int representing the number of set bits\n    \"\"\"\n    pass\n\n\ndef count_bits_per_row(df: pd.DataFrame, capacity: _t.Optional[int] = None) -> pd.Series:\n    pass\n"
            },
            {
                "file_path": "gecko/_cldr.py",
                "code": "def uppercase_char_to_index(char: str) -> int:\n    pass\n\n\ndef unescape_kb_char(char: str) -> str:\n    pass\n\n\n@lru_cache\ndef decode_iso_kb_pos(iso_kb_pos_str: str) -> (int, int):\n    pass\n\n\ndef get_neighbor_kb_pos_for(kb_pos: tuple[int, int, int], max_row: int, max_col: int) -> list[tuple[int, int, int]]:\n    pass\n"
            }
        ],
        "minimal_code_skeleton": "--- File: gecko/__init__.py ---\n```python\nclass GeckoWarning(UserWarning):\n    \"\"\"\n    Generic class that represents all warnings emitted by Gecko.\n    \"\"\"\n    pass\n\nGenerator = _t.Callable[[int], list[pd.Series]]\nMutator = _t.Callable[[list[pd.Series], _t.Optional[float]], list[pd.Series]]\n```\n--- File: gecko/_cldr.py ---\n```python\ndef uppercase_char_to_index(char: str) -> int:\n    pass\n\ndef unescape_kb_char(char: str) -> str:\n    pass\n\ndef decode_iso_kb_pos(iso_kb_pos_str: str) -> (int, int):\n    pass\n\ndef get_neighbor_kb_pos_for(kb_pos: tuple[int, int, int], max_row: int, max_col: int) -> list[tuple[int, int, int]]:\n    pass\n```\n--- File: gecko/_dfbitlookup.py ---\n```python\ndef with_capacity(rows: int, capacity: int, index: _t.Optional[pd.Index] = None):\n    \"\"\"\n    Construct a new data frame that is capable of storing the desired capacity of bits for the desired\n    number of rows.\n    An index object can be supplied to align the data frame returned by this function with another\n    Pandas object.\n\n    Args:\n        rows: amount of rows\n        capacity: maximum amount of bits\n        index: index to align to\n\n    Returns:\n        Data frame to set and test bits on across all of its rows\n    \"\"\"\n    pass\n\ndef set_index(df: pd.DataFrame, mask: _te.Union[pd.Series, slice, list[bool]], idx: int):\n    \"\"\"\n    Set a bit on all selected rows at the specified index.\n\n    Args:\n        df: data frame to perform operation on\n        mask: series or list of booleans to select rows to set bit in with\n        idx: index of the bit to set\n    \"\"\"\n    pass\n\ndef test_index(df: pd.DataFrame, idx: int) -> pd.Series:\n    \"\"\"\n    Test a bit on all rows at the specified index.\n\n    Args:\n        df: data frame to perform operation on\n        idx: index of the bit to test\n\n    Returns:\n        series of booleans representing rows where the selected bit is set\n    \"\"\"\n    pass\n\ndef any_set(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Test whether any bits are set for each row.\n\n    Args:\n        df: data frame to perform operation on\n\n    Returns:\n        series of booleans representing rows where any bit is set\n    \"\"\"\n    pass\n\ndef count_bits_per_index(df: pd.DataFrame, capacity: _t.Optional[int] = None) -> list[tuple[int, int]]:\n    \"\"\"\n    Count the bits set for each index across all rows.\n    If provided, this function will use the capacity argument as the upper bound for indices to count.\n    If not provided, it will be inferred from the number of columns in the data frame.\n\n    Args:\n        df: data frame to perform operation on\n        capacity: maximum amount of bits to test\n\n    Returns:\n        list of tuples where the first int representing the index and the second int representing the number of set bits\n    \"\"\"\n    pass\n\ndef count_bits_per_row(df: pd.DataFrame, capacity: _t.Optional[int] = None) -> pd.Series:\n    pass\n```\n--- File: gecko/_typedefs.py ---\n```python\nGenerator = _t.Callable[[int], list[pd.Series]]\nMutator = _t.Callable[[list[pd.Series], _t.Optional[float]], list[pd.Series]]\nDateTimeUnit = _t.Literal[\"d\", \"days\", \"h\", \"hours\", \"m\", \"minutes\", \"s\", \"seconds\"]\n```\n--- File: gecko/generator.py ---\n```python\n_P = _te.ParamSpec(\"_P\")\n_WeightedGenerator = tuple[_t.Union[int, float], _gt.Generator]\n_GeneratorSpec = list[tuple[_t.Union[str, tuple[str, ...]], _gt.Generator]]\n\ndef from_function(func: _t.Callable[_P, str], *args: object, **kwargs: object) -> _gt.Generator:\n    \"\"\"\n    Generate data from an arbitrary function that returns a single value at a time.\n\n    Notes:\n        This function should be used sparingly since it is not vectorized.\n        Only use it for testing purposes or if performance is not important.\n\n    Args:\n        func: function to invoke to generate data from\n        *args: positional arguments to pass to `func`\n        **kwargs: keyword arguments to pass to `func`\n\n    Returns:\n        function returning list with strings generated from custom function\n    \"\"\"\n    pass\n\ndef from_uniform_distribution(\n    low: _t.Union[int, float] = 0,\n    high: _t.Union[int, float] = 1,\n    precision: int = 6,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from a uniform distribution.\n\n    Args:\n        low: lower limit of uniform distribution (inclusive)\n        high: upper limit of uniform distribution (exclusive)\n        precision: decimal precision of the numbers generated from the uniform distribution\n        rng: random number generator to use\n\n    Returns:\n        function returning list with numbers drawn from a uniform distribution formatted as strings\n    \"\"\"\n    pass\n\ndef from_normal_distribution(\n    mean: float = 0,\n    sd: float = 1,\n    precision: int = 6,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from a normal distribution.\n\n    Args:\n        mean: mean of the normal distribution\n        sd: standard deviation of the normal distribution\n        precision: decimal precision of the numbers generated from the normal distribution\n        rng: random number generator to use\n\n    Returns:\n        function returning list with numbers drawn from a normal distribution formatted as strings\n    \"\"\"\n    pass\n\ndef from_frequency_table(\n    data_source: _t.Union[str, PathLike[str], pd.DataFrame],\n    value_column: _t.Union[str, int] = 0,\n    freq_column: _t.Union[str, int] = 1,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from a frequency table.\n    The frequency table must be provided in CSV format and contain at least two columns: one containing values to\n    generate and one containing their assigned absolute frequencies.\n    Values generated by this function will have a distribution similar to the frequencies listed in the input file.\n    If the value and frequency column are provided as strings, then it is automatically assumed that the CSV file\n    has a header row.\n\n    Args:\n        data_source: path to CSV file or data frame to use as frequency table\n        value_column: name or index of the value column\n        freq_column: name or index of the frequency column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function returning list with single series containing values generated from the input file\n    \"\"\"\n    pass\n\ndef from_multicolumn_frequency_table(\n    data_source: _t.Union[str, PathLike[str], pd.DataFrame],\n    value_columns: _t.Union[int, str, list[int], list[str]] = 0,\n    freq_column: _t.Union[int, str] = 1,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from a frequency table with multiple interdependent columns..\n    The frequency table must be provided in CSV format and contain at least two columns: one containing values to\n    generate and one containing their assigned absolute frequencies.\n    Values generated by this function will have a distribution similar to the frequencies listed in the input file.\n    If the values and frequency column are provided as strings, then it is automatically assumed that the CSV file\n    has a header row.\n\n    Args:\n        data_source: path to CSV file or data frame to use as frequency table\n        value_columns: names or indices of the value columns\n        freq_column: name or index of the frequency column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function returning list with as many series as there are value columns specified containing values generated from the input file\n    \"\"\"\n    pass\n\ndef from_datetime_range(\n    start_dt: _t.Union[str, np.datetime64],\n    end_dt: _t.Union[str, np.datetime64],\n    dt_format: str,\n    unit: _gt.DateTimeUnit,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from a range of dates and times.\n    The start and end datetime must be provided either as a ISO 8601 datetime string or a NumPy datetime object.\n    The output format must include the same format codes as specified in the `datetime` Python module for the\n    `strftime` function.\n    The unit specifies the smallest unit of time that may change when generating random dates and times.\n    For example if `D` is specified, generated dates will only differ in their days, months and years, leaving hours,\n    minutes and seconds unaffected.\n    The same applies for `h`, `m` and `s` for hours, minutes and seconds respectively.\n\n    Args:\n        start_dt: datetime string or object for start of range\n        end_dt: datetime string or object for end of range\n        dt_format: output format for generated datetimes\n        unit: smallest unit of time that may change when generating random dates and times\n        rng: random number generator to use\n\n    Returns:\n        function returning list of random datetime strings within the specified range\n    \"\"\"\n    pass\n\ndef from_group(\n    generator_lst: _t.Union[list[_gt.Generator], list[_WeightedGenerator]],\n    max_rounding_adjustment: int = 0,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from multiple generators.\n    Unless explicitly specified, all generators will generate data with equal probability.\n    Alternatively generators can be assigned fixed probabilities.\n    The output of each generator is then shuffled.\n    If all generators generate multiple series, then all series are shuffled the same.\n    Due to rounding errors, it may occur that the computed amount of rows to generate for each generator does\n    not exactly sum up to the desired amount of rows.\n    To compensate, this generator allows the specification of a maximum amount of rows that may be added or removed\n    to random generators to match the target amount of rows.\n\n    Args:\n        generator_lst: list of (weighted) generators\n        max_rounding_adjustment: maximum amount of rows to add or remove if the computed amount of total rows does not match the desired amount of rows\n        rng: random number generator to use\n\n    Returns:\n        function returning list of random data generated using supplied generators\n    \"\"\"\n    pass\n\ndef to_data_frame(\n    generator_lst: _GeneratorSpec,\n    count: int,\n) -> pd.DataFrame:\n    \"\"\"\n    Generate data frame by using multiple generators at once.\n    Column names must be mapped to their respective generators.\n    A generator can be assigned to one or multiple column names, but it must always match the amount of series\n    that the generator returns.\n\n    Args:\n        generator_lst: list of column names to generators\n        count: amount of records to generate\n\n    Returns:\n        data frame with columns and rows generated as specified\n    \"\"\"\n    pass\n```\n--- File: gecko/mutator.py ---\n```python\n_P = _te.ParamSpec(\"_P\")\n_WeightedMutatorDef = tuple[_t.Union[int, float], _gt.Mutator]\n_MutatorDef = _t.Union[_gt.Mutator, tuple[_t.Union[int, float], _gt.Mutator]]\n_MutatorSpec = list[tuple[_t.Union[str, tuple[str, ...]], _t.Union[_MutatorDef, list[_MutatorDef]]]]\n\ndef with_function(\n    func: _t.Callable[_te.Concatenate[str, _P], str],\n    rng: _t.Optional[np.random.Generator] = None,\n    *args: object,\n    **kwargs: object,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series using an arbitrary function that mutates a single value at a time.\n\n    Notes:\n        This function should be used sparingly since it is not vectorized.\n        Only use it for testing purposes or if performance is not important.\n\n    Args:\n        func: function to mutate values with\n        rng: random number generator to use\n        *args: positional arguments to pass to `func`\n        **kwargs: keyword arguments to pass to `func`\n\n    Returns:\n        function that mutates series using the custom function\n    \"\"\"\n    pass\n\ndef with_cldr_keymap_file(\n    cldr_path: _t.Union[PathLike, str],\n    charset: _t.Optional[_t.Union[str, list[str]]] = None,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly introducing typos.\n    Potential typos are sourced from a Common Locale Data Repository (CLDR) keymap.\n    Any character may be replaced with one of its horizontal or vertical neighbors on a keyboard.\n    They may also be replaced with its upper- or lowercase variant.\n    It is possible for a string to not be modified if a selected character has no possible replacements.\n    If the `charset` parameter is `None`, then any character present on the keymap may be mutated.\n\n    Args:\n        cldr_path: path to CLDR keymap file\n        charset: character string or list of characters that may be mutated\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series using a keymap\n    \"\"\"\n    pass\n\ndef with_phonetic_replacement_table(\n    data_source: _t.Union[PathLike, str, pd.DataFrame],\n    source_column: _t.Union[int, str] = 0,\n    target_column: _t.Union[int, str] = 1,\n    flags_column: _t.Union[int, str] = 2,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly replacing character sequences with others that sound similar.\n    The rules for similar-sounding character sequences are sourced from a table.\n    This table must have at least three columns: a source, target and a flag column.\n    A source pattern is mapped to its target under the rules imposed by the provided flags.\n    These flags determine where such a replacement can take place within a string.\n    If no flags are defined, it is implied that this replacement can take place anywhere in a string.\n    Conversely, if `^`, `$`, `_`, or any combination of the three are set, it implies that a replacement\n    can only occur at the start, end or in the middle of a string.\n    If the source, target and flags column are provided as strings, and if a path to a CSV file is\n    provided to this function, then it is automatically assumed that the CSV file has a header row.\n\n    Args:\n        data_source: path to CSV file or data frame containing phonetic replacement rules\n        source_column: name or index of source column\n        target_column: name or index of target column\n        flags_column: name or index of flag column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n       function that mutates series using phonetic rules sourced from a table\n    \"\"\"\n    pass\n\ndef with_replacement_table(\n    data_source: _t.Union[PathLike, str, pd.DataFrame],\n    source_column: _t.Union[str, int] = 0,\n    target_column: _t.Union[str, int] = 1,\n    inline: bool = False,\n    reverse: bool = False,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly substituting character sequences from a replacement table.\n    The table must have at least two columns: a source and a target value column.\n    A source value may have multiple target values that it can map to.\n    Strings that do not contain any possible source values are not mutated.\n    It is possible for a string to not be modified if no target value could be picked for its assigned source value.\n    This can only happen if a source value is mapped to multiple target values.\n    In this case, each target value will be independently selected or not.\n    If the source and target column are provided as strings, and a path to a CSV file is provided\n    to this function, then it is automatically assumed that the CSV file has a header row.\n    The mutator will favor less common replacements over more common ones.\n\n    Args:\n        data_source: path to CSV file or data frame containing replacement table\n        source_column: name or index of the source column\n        target_column: name or index of the target column\n        inline: whether to perform replacements inline\n        reverse: whether to allow replacements from target to source column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series according to a replacement table\n    \"\"\"\n    pass\n\ndef with_missing_value(\n    value: str = \"\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by replacing its values with a representative \"missing\" value.\n\n    Args:\n        value: \"missing\" value to replace select entries with\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by overwriting it with a \"missing\" value\n    \"\"\"\n    pass\n\ndef with_insert(\n    charset: _t.Union[str, list[str]] = string.ascii_letters,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by inserting random characters.\n    The characters are drawn from the provided charset.\n\n    Args:\n        charset: character string or list of characters to sample from\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by injecting random characters\n    \"\"\"\n    pass\n\ndef with_delete(rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly deleting characters.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by deleting random characters\n    \"\"\"\n    pass\n\ndef with_transpose(rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly swapping neighboring characters.\n\n    Notes:\n        It is possible for the same two neighboring characters to be swapped.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by swapping adjacent characters\n    \"\"\"\n    pass\n\ndef with_substitute(\n    charset: _t.Union[str, list[str]] = string.ascii_letters,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate data by replacing single characters with a new one.\n    The characters are drawn from the provided charset.\n\n    Notes:\n        It is possible for a character to be replaced by itself.\n\n    Args:\n        charset: character string or list of characters to sample from\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by substituting random characters\n    \"\"\"\n    pass\n\ndef with_categorical_values(\n    data_source: _t.Union[PathLike, str, pd.DataFrame],\n    value_column: _t.Union[str, int] = 0,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by replacing values with another from a list of categorical values.\n    This mutator reads all unique values from a singular column.\n    All values within a series will be replaced with a different random value from this column.\n    If the value column is provided as a string, and a path to a CSV file is provided to this\n    function, then it is automatically assumed that the CSV file has a header row.\n\n    Args:\n        data_source: path to CSV file or data frame containing values\n        value_column: name or index of value column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by replacing values with a different one from a limited set of permitted values\n    \"\"\"\n    pass\n\ndef with_permute(rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by permuting their contents.\n    This function ensures that rows are permuted in such a way that no value remains in the series\n    it originated from.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by permuting their contents\n    \"\"\"\n    pass\n\ndef with_lowercase(rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by converting its contents to lowercase.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by converting its contents to lowercase\n    \"\"\"\n    pass\n\ndef with_uppercase(rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by converting its contents to uppercase.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by converting its contents to uppercase\n    \"\"\"\n    pass\n\ndef with_datetime_offset(\n    max_delta: int,\n    unit: _gt.DateTimeUnit,\n    dt_format: str,\n    prevent_wraparound: bool = False,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by treating their contents it as datetime information and offsetting it by random amounts.\n    The delta and the unit specify which datetime field should be affected, where possible values are\n    `d` and `days`, `h` and `hours`, `m` and `minutes`, `s` and `seconds`.\n    The datetime format must include the same format codes as specified in the `datetime` Python module for the\n    `strftime` function.\n    By setting `prevent_wraparound` to `True`, this mutator will not apply a mutation if it will cause an\n    unrelated field to change its value, e.g. when subtracting a day from July 1st, 2001.\n\n    Args:\n        max_delta: maximum amount of units to change by\n        unit: affected datetime field\n        dt_format: input and output datetime format\n        prevent_wraparound: `True` if unrelated fields should not be modified, `False` otherwise\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by applying random date and time offsets to them\n    \"\"\"\n    pass\n\ndef with_generator(\n    generator: _gt.Generator,\n    mode: _t.Literal[\"prepend\", \"append\", \"replace\"],\n    join_with: str = \" \",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by replacing its content by appending, prepending or replacing it with data from another generator.\n    A string to join generated data with when appending or prepending can be provided.\n    Using `{}` in the `join_with` parameter will cause it to be replaced by generated values.\n    Only the first occurrence of `{}` will be replaced.\n\n    Args:\n        generator: generator to source data from\n        mode: either append, prepend or replace\n        join_with: string to join present and generated data with\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series using another generator\n    \"\"\"\n    pass\n\ndef with_regex_replacement_table(\n    data_source: _t.Union[PathLike, str, pd.DataFrame],\n    pattern_column: str = \"pattern\",\n    flags_column: _t.Optional[str] = None,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by performing regex-based substitutions sourced from a table.\n    This table must contain a column with the regex patterns to look for and columns for each capture group to look up\n    substitutions.\n    When using regular capture groups, the columns must be numbered starting with 1.\n    When using named capture groups, the columns must be named after the capture groups they are supposed to substitute.\n\n    Args:\n        data_source: path to CSV file or data frame containing regex-based substitutions\n        pattern_column: name of regex pattern column\n        flags_column: name of regex flag column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by performing regex-based substitutions\n    \"\"\"\n    pass\n\ndef with_repeat(join_with: str = \" \", rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by repeating its contents.\n    By default, selected entries will be duplicated and separated by a whitespace.\n\n    Args:\n        join_with: joining character to use, space by default\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by repeating its contents\n    \"\"\"\n    pass\n\ndef with_group(\n    mutator_lst: _t.Union[list[_gt.Mutator], list[_WeightedMutatorDef]],\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by applying multiple mutators on it.\n    The mutators are applied in the order that they are provided in to this function.\n    When providing a list of mutators, each row will be affected by each mutator with an equal probability.\n    When providing a list of weighted mutators, each row will be affected by each mutator with the\n    specified probabilities.\n    If the probabilities do not sum up to 1, an additional mutator is added which does not modify input data.\n\n    Args:\n        mutator_lst: list of mutators or weighted mutators\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series using multiple mutually exclusive mutators at once\n    \"\"\"\n    pass\n\ndef mutate_data_frame(\n    df_in: pd.DataFrame,\n    mutator_lst: _MutatorSpec,\n) -> pd.DataFrame:\n    \"\"\"\n    Mutate a data frame by applying several mutators on select columns.\n    This function takes a list which contains columns and mutators that are assigned to them.\n    A column may be assigned a single mutator, a mutator with a probability, a list of mutators where each is applied\n    with the same probability, and a list of weighted mutators where each is applied with its assigned probability.\n\n    Args:\n        df_in: data frame to mutate\n        mutator_lst: list of columns with their mutator assignments\n\n    Returns:\n        data frame with columns mutated as specified\n    \"\"\"\n    pass\n```",
        "minimal_code_skeleton_structured": [
            {
                "file_path": "gecko/__init__.py",
                "code": "class GeckoWarning(UserWarning):\n    \"\"\"\n    Generic class that represents all warnings emitted by Gecko.\n    \"\"\"\n    pass\n\nGenerator = _t.Callable[[int], list[pd.Series]]\nMutator = _t.Callable[[list[pd.Series], _t.Optional[float]], list[pd.Series]]\n"
            },
            {
                "file_path": "gecko/_cldr.py",
                "code": "def uppercase_char_to_index(char: str) -> int:\n    pass\n\ndef unescape_kb_char(char: str) -> str:\n    pass\n\ndef decode_iso_kb_pos(iso_kb_pos_str: str) -> (int, int):\n    pass\n\ndef get_neighbor_kb_pos_for(kb_pos: tuple[int, int, int], max_row: int, max_col: int) -> list[tuple[int, int, int]]:\n    pass\n"
            },
            {
                "file_path": "gecko/_dfbitlookup.py",
                "code": "def with_capacity(rows: int, capacity: int, index: _t.Optional[pd.Index] = None):\n    \"\"\"\n    Construct a new data frame that is capable of storing the desired capacity of bits for the desired\n    number of rows.\n    An index object can be supplied to align the data frame returned by this function with another\n    Pandas object.\n\n    Args:\n        rows: amount of rows\n        capacity: maximum amount of bits\n        index: index to align to\n\n    Returns:\n        Data frame to set and test bits on across all of its rows\n    \"\"\"\n    pass\n\ndef set_index(df: pd.DataFrame, mask: _te.Union[pd.Series, slice, list[bool]], idx: int):\n    \"\"\"\n    Set a bit on all selected rows at the specified index.\n\n    Args:\n        df: data frame to perform operation on\n        mask: series or list of booleans to select rows to set bit in with\n        idx: index of the bit to set\n    \"\"\"\n    pass\n\ndef test_index(df: pd.DataFrame, idx: int) -> pd.Series:\n    \"\"\"\n    Test a bit on all rows at the specified index.\n\n    Args:\n        df: data frame to perform operation on\n        idx: index of the bit to test\n\n    Returns:\n        series of booleans representing rows where the selected bit is set\n    \"\"\"\n    pass\n\ndef any_set(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Test whether any bits are set for each row.\n\n    Args:\n        df: data frame to perform operation on\n\n    Returns:\n        series of booleans representing rows where any bit is set\n    \"\"\"\n    pass\n\ndef count_bits_per_index(df: pd.DataFrame, capacity: _t.Optional[int] = None) -> list[tuple[int, int]]:\n    \"\"\"\n    Count the bits set for each index across all rows.\n    If provided, this function will use the capacity argument as the upper bound for indices to count.\n    If not provided, it will be inferred from the number of columns in the data frame.\n\n    Args:\n        df: data frame to perform operation on\n        capacity: maximum amount of bits to test\n\n    Returns:\n        list of tuples where the first int representing the index and the second int representing the number of set bits\n    \"\"\"\n    pass\n\ndef count_bits_per_row(df: pd.DataFrame, capacity: _t.Optional[int] = None) -> pd.Series:\n    pass\n"
            },
            {
                "file_path": "gecko/_typedefs.py",
                "code": "Generator = _t.Callable[[int], list[pd.Series]]\nMutator = _t.Callable[[list[pd.Series], _t.Optional[float]], list[pd.Series]]\nDateTimeUnit = _t.Literal[\"d\", \"days\", \"h\", \"hours\", \"m\", \"minutes\", \"s\", \"seconds\"]\n"
            },
            {
                "file_path": "gecko/generator.py",
                "code": "_P = _te.ParamSpec(\"_P\")\n_WeightedGenerator = tuple[_t.Union[int, float], _gt.Generator]\n_GeneratorSpec = list[tuple[_t.Union[str, tuple[str, ...]], _gt.Generator]]\n\ndef from_function(func: _t.Callable[_P, str], *args: object, **kwargs: object) -> _gt.Generator:\n    \"\"\"\n    Generate data from an arbitrary function that returns a single value at a time.\n\n    Notes:\n        This function should be used sparingly since it is not vectorized.\n        Only use it for testing purposes or if performance is not important.\n\n    Args:\n        func: function to invoke to generate data from\n        *args: positional arguments to pass to `func`\n        **kwargs: keyword arguments to pass to `func`\n\n    Returns:\n        function returning list with strings generated from custom function\n    \"\"\"\n    pass\n\ndef from_uniform_distribution(\n    low: _t.Union[int, float] = 0,\n    high: _t.Union[int, float] = 1,\n    precision: int = 6,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from a uniform distribution.\n\n    Args:\n        low: lower limit of uniform distribution (inclusive)\n        high: upper limit of uniform distribution (exclusive)\n        precision: decimal precision of the numbers generated from the uniform distribution\n        rng: random number generator to use\n\n    Returns:\n        function returning list with numbers drawn from a uniform distribution formatted as strings\n    \"\"\"\n    pass\n\ndef from_normal_distribution(\n    mean: float = 0,\n    sd: float = 1,\n    precision: int = 6,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from a normal distribution.\n\n    Args:\n        mean: mean of the normal distribution\n        sd: standard deviation of the normal distribution\n        precision: decimal precision of the numbers generated from the normal distribution\n        rng: random number generator to use\n\n    Returns:\n        function returning list with numbers drawn from a normal distribution formatted as strings\n    \"\"\"\n    pass\n\ndef from_frequency_table(\n    data_source: _t.Union[str, PathLike[str], pd.DataFrame],\n    value_column: _t.Union[str, int] = 0,\n    freq_column: _t.Union[str, int] = 1,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from a frequency table.\n    The frequency table must be provided in CSV format and contain at least two columns: one containing values to\n    generate and one containing their assigned absolute frequencies.\n    Values generated by this function will have a distribution similar to the frequencies listed in the input file.\n    If the value and frequency column are provided as strings, then it is automatically assumed that the CSV file\n    has a header row.\n\n    Args:\n        data_source: path to CSV file or data frame to use as frequency table\n        value_column: name or index of the value column\n        freq_column: name or index of the frequency column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function returning list with single series containing values generated from the input file\n    \"\"\"\n    pass\n\ndef from_multicolumn_frequency_table(\n    data_source: _t.Union[str, PathLike[str], pd.DataFrame],\n    value_columns: _t.Union[int, str, list[int], list[str]] = 0,\n    freq_column: _t.Union[int, str] = 1,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from a frequency table with multiple interdependent columns..\n    The frequency table must be provided in CSV format and contain at least two columns: one containing values to\n    generate and one containing their assigned absolute frequencies.\n    Values generated by this function will have a distribution similar to the frequencies listed in the input file.\n    If the values and frequency column are provided as strings, then it is automatically assumed that the CSV file\n    has a header row.\n\n    Args:\n        data_source: path to CSV file or data frame to use as frequency table\n        value_columns: names or indices of the value columns\n        freq_column: name or index of the frequency column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function returning list with as many series as there are value columns specified containing values generated from the input file\n    \"\"\"\n    pass\n\ndef from_datetime_range(\n    start_dt: _t.Union[str, np.datetime64],\n    end_dt: _t.Union[str, np.datetime64],\n    dt_format: str,\n    unit: _gt.DateTimeUnit,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from a range of dates and times.\n    The start and end datetime must be provided either as a ISO 8601 datetime string or a NumPy datetime object.\n    The output format must include the same format codes as specified in the `datetime` Python module for the\n    `strftime` function.\n    The unit specifies the smallest unit of time that may change when generating random dates and times.\n    For example if `D` is specified, generated dates will only differ in their days, months and years, leaving hours,\n    minutes and seconds unaffected.\n    The same applies for `h`, `m` and `s` for hours, minutes and seconds respectively.\n\n    Args:\n        start_dt: datetime string or object for start of range\n        end_dt: datetime string or object for end of range\n        dt_format: output format for generated datetimes\n        unit: smallest unit of time that may change when generating random dates and times\n        rng: random number generator to use\n\n    Returns:\n        function returning list of random datetime strings within the specified range\n    \"\"\"\n    pass\n\ndef from_group(\n    generator_lst: _t.Union[list[_gt.Generator], list[_WeightedGenerator]],\n    max_rounding_adjustment: int = 0,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Generator:\n    \"\"\"\n    Generate data from multiple generators.\n    Unless explicitly specified, all generators will generate data with equal probability.\n    Alternatively generators can be assigned fixed probabilities.\n    The output of each generator is then shuffled.\n    If all generators generate multiple series, then all series are shuffled the same.\n    Due to rounding errors, it may occur that the computed amount of rows to generate for each generator does\n    not exactly sum up to the desired amount of rows.\n    To compensate, this generator allows the specification of a maximum amount of rows that may be added or removed\n    to random generators to match the target amount of rows.\n\n    Args:\n        generator_lst: list of (weighted) generators\n        max_rounding_adjustment: maximum amount of rows to add or remove if the computed amount of total rows does not match the desired amount of rows\n        rng: random number generator to use\n\n    Returns:\n        function returning list of random data generated using supplied generators\n    \"\"\"\n    pass\n\ndef to_data_frame(\n    generator_lst: _GeneratorSpec,\n    count: int,\n) -> pd.DataFrame:\n    \"\"\"\n    Generate data frame by using multiple generators at once.\n    Column names must be mapped to their respective generators.\n    A generator can be assigned to one or multiple column names, but it must always match the amount of series\n    that the generator returns.\n\n    Args:\n        generator_lst: list of column names to generators\n        count: amount of records to generate\n\n    Returns:\n        data frame with columns and rows generated as specified\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "gecko/mutator.py",
                "code": "_P = _te.ParamSpec(\"_P\")\n_WeightedMutatorDef = tuple[_t.Union[int, float], _gt.Mutator]\n_MutatorDef = _t.Union[_gt.Mutator, tuple[_t.Union[int, float], _gt.Mutator]]\n_MutatorSpec = list[tuple[_t.Union[str, tuple[str, ...]], _t.Union[_MutatorDef, list[_MutatorDef]]]]\n\ndef with_function(\n    func: _t.Callable[_te.Concatenate[str, _P], str],\n    rng: _t.Optional[np.random.Generator] = None,\n    *args: object,\n    **kwargs: object,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series using an arbitrary function that mutates a single value at a time.\n\n    Notes:\n        This function should be used sparingly since it is not vectorized.\n        Only use it for testing purposes or if performance is not important.\n\n    Args:\n        func: function to mutate values with\n        rng: random number generator to use\n        *args: positional arguments to pass to `func`\n        **kwargs: keyword arguments to pass to `func`\n\n    Returns:\n        function that mutates series using the custom function\n    \"\"\"\n    pass\n\ndef with_cldr_keymap_file(\n    cldr_path: _t.Union[PathLike, str],\n    charset: _t.Optional[_t.Union[str, list[str]]] = None,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly introducing typos.\n    Potential typos are sourced from a Common Locale Data Repository (CLDR) keymap.\n    Any character may be replaced with one of its horizontal or vertical neighbors on a keyboard.\n    They may also be replaced with its upper- or lowercase variant.\n    It is possible for a string to not be modified if a selected character has no possible replacements.\n    If the `charset` parameter is `None`, then any character present on the keymap may be mutated.\n\n    Args:\n        cldr_path: path to CLDR keymap file\n        charset: character string or list of characters that may be mutated\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series using a keymap\n    \"\"\"\n    pass\n\ndef with_phonetic_replacement_table(\n    data_source: _t.Union[PathLike, str, pd.DataFrame],\n    source_column: _t.Union[int, str] = 0,\n    target_column: _t.Union[int, str] = 1,\n    flags_column: _t.Union[int, str] = 2,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly replacing character sequences with others that sound similar.\n    The rules for similar-sounding character sequences are sourced from a table.\n    This table must have at least three columns: a source, target and a flag column.\n    A source pattern is mapped to its target under the rules imposed by the provided flags.\n    These flags determine where such a replacement can take place within a string.\n    If no flags are defined, it is implied that this replacement can take place anywhere in a string.\n    Conversely, if `^`, `$`, `_`, or any combination of the three are set, it implies that a replacement\n    can only occur at the start, end or in the middle of a string.\n    If the source, target and flags column are provided as strings, and if a path to a CSV file is\n    provided to this function, then it is automatically assumed that the CSV file has a header row.\n\n    Args:\n        data_source: path to CSV file or data frame containing phonetic replacement rules\n        source_column: name or index of source column\n        target_column: name or index of target column\n        flags_column: name or index of flag column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n       function that mutates series using phonetic rules sourced from a table\n    \"\"\"\n    pass\n\ndef with_replacement_table(\n    data_source: _t.Union[PathLike, str, pd.DataFrame],\n    source_column: _t.Union[str, int] = 0,\n    target_column: _t.Union[str, int] = 1,\n    inline: bool = False,\n    reverse: bool = False,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly substituting character sequences from a replacement table.\n    The table must have at least two columns: a source and a target value column.\n    A source value may have multiple target values that it can map to.\n    Strings that do not contain any possible source values are not mutated.\n    It is possible for a string to not be modified if no target value could be picked for its assigned source value.\n    This can only happen if a source value is mapped to multiple target values.\n    In this case, each target value will be independently selected or not.\n    If the source and target column are provided as strings, and a path to a CSV file is provided\n    to this function, then it is automatically assumed that the CSV file has a header row.\n    The mutator will favor less common replacements over more common ones.\n\n    Args:\n        data_source: path to CSV file or data frame containing replacement table\n        source_column: name or index of the source column\n        target_column: name or index of the target column\n        inline: whether to perform replacements inline\n        reverse: whether to allow replacements from target to source column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series according to a replacement table\n    \"\"\"\n    pass\n\ndef with_missing_value(\n    value: str = \"\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by replacing its values with a representative \"missing\" value.\n\n    Args:\n        value: \"missing\" value to replace select entries with\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by overwriting it with a \"missing\" value\n    \"\"\"\n    pass\n\ndef with_insert(\n    charset: _t.Union[str, list[str]] = string.ascii_letters,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by inserting random characters.\n    The characters are drawn from the provided charset.\n\n    Args:\n        charset: character string or list of characters to sample from\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by injecting random characters\n    \"\"\"\n    pass\n\ndef with_delete(rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly deleting characters.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by deleting random characters\n    \"\"\"\n    pass\n\ndef with_transpose(rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly swapping neighboring characters.\n\n    Notes:\n        It is possible for the same two neighboring characters to be swapped.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by swapping adjacent characters\n    \"\"\"\n    pass\n\ndef with_substitute(\n    charset: _t.Union[str, list[str]] = string.ascii_letters,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate data by replacing single characters with a new one.\n    The characters are drawn from the provided charset.\n\n    Notes:\n        It is possible for a character to be replaced by itself.\n\n    Args:\n        charset: character string or list of characters to sample from\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by substituting random characters\n    \"\"\"\n    pass\n\ndef with_categorical_values(\n    data_source: _t.Union[PathLike, str, pd.DataFrame],\n    value_column: _t.Union[str, int] = 0,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by replacing values with another from a list of categorical values.\n    This mutator reads all unique values from a singular column.\n    All values within a series will be replaced with a different random value from this column.\n    If the value column is provided as a string, and a path to a CSV file is provided to this\n    function, then it is automatically assumed that the CSV file has a header row.\n\n    Args:\n        data_source: path to CSV file or data frame containing values\n        value_column: name or index of value column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by replacing values with a different one from a limited set of permitted values\n    \"\"\"\n    pass\n\ndef with_permute(rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by permuting their contents.\n    This function ensures that rows are permuted in such a way that no value remains in the series\n    it originated from.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by permuting their contents\n    \"\"\"\n    pass\n\ndef with_lowercase(rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by converting its contents to lowercase.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by converting its contents to lowercase\n    \"\"\"\n    pass\n\ndef with_uppercase(rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by converting its contents to uppercase.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by converting its contents to uppercase\n    \"\"\"\n    pass\n\ndef with_datetime_offset(\n    max_delta: int,\n    unit: _gt.DateTimeUnit,\n    dt_format: str,\n    prevent_wraparound: bool = False,\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by treating their contents it as datetime information and offsetting it by random amounts.\n    The delta and the unit specify which datetime field should be affected, where possible values are\n    `d` and `days`, `h` and `hours`, `m` and `minutes`, `s` and `seconds`.\n    The datetime format must include the same format codes as specified in the `datetime` Python module for the\n    `strftime` function.\n    By setting `prevent_wraparound` to `True`, this mutator will not apply a mutation if it will cause an\n    unrelated field to change its value, e.g. when subtracting a day from July 1st, 2001.\n\n    Args:\n        max_delta: maximum amount of units to change by\n        unit: affected datetime field\n        dt_format: input and output datetime format\n        prevent_wraparound: `True` if unrelated fields should not be modified, `False` otherwise\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by applying random date and time offsets to them\n    \"\"\"\n    pass\n\ndef with_generator(\n    generator: _gt.Generator,\n    mode: _t.Literal[\"prepend\", \"append\", \"replace\"],\n    join_with: str = \" \",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by replacing its content by appending, prepending or replacing it with data from another generator.\n    A string to join generated data with when appending or prepending can be provided.\n    Using `{}` in the `join_with` parameter will cause it to be replaced by generated values.\n    Only the first occurrence of `{}` will be replaced.\n\n    Args:\n        generator: generator to source data from\n        mode: either append, prepend or replace\n        join_with: string to join present and generated data with\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series using another generator\n    \"\"\"\n    pass\n\ndef with_regex_replacement_table(\n    data_source: _t.Union[PathLike, str, pd.DataFrame],\n    pattern_column: str = \"pattern\",\n    flags_column: _t.Optional[str] = None,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by performing regex-based substitutions sourced from a table.\n    This table must contain a column with the regex patterns to look for and columns for each capture group to look up\n    substitutions.\n    When using regular capture groups, the columns must be numbered starting with 1.\n    When using named capture groups, the columns must be named after the capture groups they are supposed to substitute.\n\n    Args:\n        data_source: path to CSV file or data frame containing regex-based substitutions\n        pattern_column: name of regex pattern column\n        flags_column: name of regex flag column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by performing regex-based substitutions\n    \"\"\"\n    pass\n\ndef with_repeat(join_with: str = \" \", rng: _t.Optional[np.random.Generator] = None) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by repeating its contents.\n    By default, selected entries will be duplicated and separated by a whitespace.\n\n    Args:\n        join_with: joining character to use, space by default\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by repeating its contents\n    \"\"\"\n    pass\n\ndef with_group(\n    mutator_lst: _t.Union[list[_gt.Mutator], list[_WeightedMutatorDef]],\n    rng: _t.Optional[np.random.Generator] = None,\n) -> _gt.Mutator:\n    \"\"\"\n    Mutate series by applying multiple mutators on it.\n    The mutators are applied in the order that they are provided in to this function.\n    When providing a list of mutators, each row will be affected by each mutator with an equal probability.\n    When providing a list of weighted mutators, each row will be affected by each mutator with the\n    specified probabilities.\n    If the probabilities do not sum up to 1, an additional mutator is added which does not modify input data.\n\n    Args:\n        mutator_lst: list of mutators or weighted mutators\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series using multiple mutually exclusive mutators at once\n    \"\"\"\n    pass\n\ndef mutate_data_frame(\n    df_in: pd.DataFrame,\n    mutator_lst: _MutatorSpec,\n) -> pd.DataFrame:\n    \"\"\"\n    Mutate a data frame by applying several mutators on select columns.\n    This function takes a list which contains columns and mutators that are assigned to them.\n    A column may be assigned a single mutator, a mutator with a probability, a list of mutators where each is applied\n    with the same probability, and a list of weighted mutators where each is applied with its assigned probability.\n\n    Args:\n        df_in: data frame to mutate\n        mutator_lst: list of columns with their mutator assignments\n\n    Returns:\n        data frame with columns mutated as specified\n    \"\"\"\n    pass\n"
            }
        ],
        "minimal_test_cases": [
            {
                "test_id": "tests/test_mutator.py::test_with_cldr_keymap_file_warn_low_p",
                "covers": [
                    "gecko.GeckoWarning - verifying it is raised for unmet probability conditions"
                ]
            },
            {
                "test_id": "tests/test_generator.py::test_from_function",
                "covers": [
                    "gecko.generator.from_function - happy path"
                ]
            },
            {
                "test_id": "tests/test_generator.py::test_from_uniform_distribution",
                "covers": [
                    "gecko.generator.from_uniform_distribution - happy path"
                ]
            },
            {
                "test_id": "tests/test_generator.py::test_from_normal_distribution",
                "covers": [
                    "gecko.generator.from_normal_distribution - happy path"
                ]
            },
            {
                "test_id": "tests/test_generator.py::test_from_frequency_table",
                "covers": [
                    "gecko.generator.from_frequency_table - happy path with CSV file input"
                ]
            },
            {
                "test_id": "tests/test_generator.py::test_from_multicolumn_frequency_table",
                "covers": [
                    "gecko.generator.from_multicolumn_frequency_table - happy path with CSV file input"
                ]
            },
            {
                "test_id": "tests/test_generator.py::test_from_datetime_range",
                "covers": [
                    "gecko.generator.from_datetime_range - happy path"
                ]
            },
            {
                "test_id": "tests/test_generator.py::test_from_group_single_column_same_weight",
                "covers": [
                    "gecko.generator.from_group - happy path with single column, same weight"
                ]
            },
            {
                "test_id": "tests/test_generator.py::test_to_dataframe",
                "covers": [
                    "gecko.generator.to_data_frame - happy path integration of multiple generators"
                ]
            },
            {
                "test_id": "tests/test_mutator.py::test_with_cldr_keymap_file",
                "covers": [
                    "gecko.mutator.with_cldr_keymap_file - happy path, full mutation"
                ]
            },
            {
                "test_id": "tests/test_mutator.py::test_with_phonetic_replacement_table",
                "covers": [
                    "gecko.mutator.with_phonetic_replacement_table - happy path with DataFrame input"
                ]
            },
            {
                "test_id": "tests/test_mutator.py::test_with_replacement_table",
                "covers": [
                    "gecko.mutator.with_replacement_table - happy path with DataFrame input"
                ]
            },
            {
                "test_id": "tests/test_mutator.py::test_with_missing_value",
                "covers": [
                    "gecko.mutator.with_missing_value - happy path"
                ]
            },
            {
                "test_id": "tests/test_mutator.py::test_with_insert",
                "covers": [
                    "gecko.mutator.with_insert - happy path"
                ]
            },
            {
                "test_id": "tests/test_mutator.py::test_with_delete",
                "covers": [
                    "gecko.mutator.with_delete - happy path"
                ]
            },
            {
                "test_id": "tests/test_mutator.py::test_with_transpose",
                "covers": [
                    "gecko.mutator.with_transpose - happy path"
                ]
            },
            {
                "test_id": "tests/test_mutator.py::test_with_substitute",
                "covers": [
                    "gecko.mutator.with_substitute - happy path"
                ]
            },
            {
                "test_id": "tests/test_mutator.py::test_with_group_padded",
                "covers": [
                    "gecko.mutator.with_noop - implicit usage via group probability padding"
                ]
            },
            {
                "test_id": "tests/test_mutator.py::test_with_categorical_values",
                "covers": [
                    "gecko.mutator.with_categorical_values - happy path with DataFrame input"
                ]
            },
            {
                "test_id": "tests/test_mutator.py::test_with_function",
                "covers": [
                    "gecko.mutator.with_function - happy path"
                ]
            },
            {
                "test_id": "tests/test_mutator.py::test_with_permute",
                "covers": [
                    "gecko.mutator.with_permute - happy path for two columns"
                ]
            },
            {
                "test_id": "tests/test_mutator.py::test_with_lowercase",
                "covers": [
                    "gecko.mutator.with_lowercase - happy path"
                ]
            },
            {
                "test_id": "tests/test_mutator.py::test_with_uppercase",
                "covers": [
                    "gecko.mutator.with_uppercase - happy path"
                ]
            },
            {
                "test_id": "tests/test_mutator.py::test_with_datetime_offset[d]",
                "covers": [
                    "gecko.mutator.with_datetime_offset - happy path with 'days' unit"
                ]
            },
            {
                "test_id": "tests/test_mutator.py::test_with_generator_replace",
                "covers": [
                    "gecko.mutator.with_generator - happy path, replace mode"
                ]
            },
            {
                "test_id": "tests/test_mutator.py::test_with_regex_replacement_table_unnamed_capture_group",
                "covers": [
                    "gecko.mutator.with_regex_replacement_table - happy path with unnamed capture groups"
                ]
            },
            {
                "test_id": "tests/test_mutator.py::test_with_repeat",
                "covers": [
                    "gecko.mutator.with_repeat - happy path"
                ]
            },
            {
                "test_id": "tests/test_mutator.py::test_with_group",
                "covers": [
                    "gecko.mutator.with_group - happy path grouping multiple mutators"
                ]
            },
            {
                "test_id": "tests/test_mutator.py::test_mutate_data_frame",
                "covers": [
                    "gecko.mutator.mutate_data_frame - happy path integration of column-specific mutators"
                ]
            }
        ]
    },
    {
        "idx": 31948,
        "repo_name": "chrisK824_retry",
        "url": "https://github.com/chrisK824/retry",
        "description": "A simple yet powerful generic retry decorator in Python",
        "stars": 5,
        "forks": 0,
        "language": "python",
        "size": 73,
        "created_at": "2024-03-18T16:52:06+00:00",
        "updated_at": "2024-11-18T09:04:19+00:00",
        "pypi_info": {
            "name": "retry-reloaded",
            "version": "0.0.8",
            "url": "https://files.pythonhosted.org/packages/3d/3c/59ad0602a926a5563173a3cc882917cf0899cd06f546d71ab35baba57d59/retry_reloaded-0.0.8.tar.gz"
        },
        "judge_info": {
            "language": "python",
            "is_good_project": false,
            "reason": "",
            "python_file_num": 15,
            "comment_ratio": 0.19937694704049844,
            "pyfile_content_length": 52712,
            "pyfile_code_lines": 1605,
            "test_file_exist": true,
            "test_file_content_length": 15041,
            "pytest_framework": true,
            "test_case_num": 44,
            "metadata_path": [
                "setup.py"
            ],
            "readme_content_length": 6221,
            "llm_reason": "The project is to create a Python library that provides a generic retry decorator. \n\n**Positive aspects:**\n*   **Self-Contained & Independent:** The core functionality (retry logic, backoff strategies, callbacks) does not require an active internet connection, external APIs, or complex third-party application setups for its operation or testing. Dependencies for the original project are minimal and standard; an AI-rebuilt version would primarily use the Python standard library.\n*   **Clear & Well-Defined Functionality:** The README clearly outlines the features: specific exception handling, excluded exceptions, max retries, timeout, deadline, various backoff strategies (fixed, exponential, linear, random), retry/successful/failure callbacks, logging control, and optional re-raising of the last exception. The API is also described.\n*   **Testable & Verifiable Output:** The project comes with an extensive suite of tests (`test_retry_args.py`, `test_callback.py`, `test_retry.py`, `test_backoff.py`) covering argument validation, core retry logic under various conditions (success, max retries, timeout, deadline), callback execution, and different backoff behaviors. These tests would be invaluable for verifying an AI-generated solution.\n*   **No Graphical User Interface (GUI):** The project is a library, intended to be used programmatically (as a decorator). Interactions are via code, making it suitable for automated testing.\n*   **Appropriate Complexity, Scope & Difficulty (Medium):** Recreating this library involves implementing a moderately complex decorator that manages state (retry counts, timing), handles various configurable parameters, implements multiple distinct backoff algorithms, manages different types of callbacks, and defines custom exceptions. The scope is well-defined by the README and existing features. It's significantly more complex than a trivial example but achievable by a competent AI within a reasonable timeframe (estimated hours to a few days for a human).\n*   **Well-Understood Problem Domain:** Retry mechanisms are a common and well-understood pattern in software development.\n*   **Predominantly Code-Based Solution:** The task is almost entirely about generating Python code for the decorator, helper classes (backoff strategies, callback factory), and custom exceptions.\n*   **Modular Structure:** The original project has a good modular structure (separate files for backoff, callbacks, exceptions, validation, logging, and the main retry logic), which can serve as a good example for the AI.\n\n**Negative aspects or concerns:**\n*   **Feature Richness:** The decorator supports a wide range of features and parameters. Ensuring the AI correctly implements all of them and their interactions (e.g., interplay between `max_retries`, `timeout`, and `deadline`) will require a very precise specification derived from the original project's README and behavior. This is more a challenge for specification than a fundamental flaw of the project as a benchmark.\n*   **Logging Implementation:** While logging is a feature, the specifics of the logging setup might need to be simplified or clearly defined for the AI to avoid getting bogged down in complex logging configurations if that's not the primary focus of the test. The current implementation seems reasonable, though.\n\nOverall, this project is an excellent candidate. It's a realistic, self-contained utility library with clear requirements and strong testability. The 'Medium' difficulty level is ideal for challenging an AI assistant without being excessively complex or requiring domain-specific knowledge beyond common programming patterns.",
            "llm_project_type": "Python utility library for function retrying",
            "llm_rating": 90,
            "llm_difficulty": "Medium"
        },
        "tests": {
            "repo_name": "chrisK824_retry",
            "finish_test": true,
            "test_case_result": {
                "tests/test_backoff.py::test_fixed_backoff[1.0-None]": "passed",
                "tests/test_backoff.py::test_fixed_backoff[1.0-jitter1]": "passed",
                "tests/test_backoff.py::test_fixed_backoff[0.0-None]": "passed",
                "tests/test_backoff.py::test_fixed_backoff[0.0-jitter3]": "passed",
                "tests/test_backoff.py::test_linear_backoff[1.0-0.5-None-None]": "passed",
                "tests/test_backoff.py::test_linear_backoff[1.0-0.5-jitter1-None]": "passed",
                "tests/test_backoff.py::test_linear_backoff[0.0-0.0-None-None]": "passed",
                "tests/test_backoff.py::test_linear_backoff[0.0-0.0-jitter3-None]": "passed",
                "tests/test_backoff.py::test_linear_backoff[1.0-0.5-None-2.0]": "passed",
                "tests/test_backoff.py::test_linear_backoff[1.0-0.5-jitter5-2.0]": "passed",
                "tests/test_backoff.py::test_random_uniform_backoff[1.0-0.5-2.0]": "passed",
                "tests/test_backoff.py::test_random_uniform_backoff[1.0-3.4-5.6]": "passed",
                "tests/test_backoff.py::test_random_uniform_backoff[0.0-0.0-0.0]": "passed",
                "tests/test_backoff.py::test_exponential_backoff[1.0-None-None-None]": "passed",
                "tests/test_backoff.py::test_exponential_backoff[1.0-None-jitter1-None]": "passed",
                "tests/test_backoff.py::test_exponential_backoff[0.0-None-None-None]": "passed",
                "tests/test_backoff.py::test_exponential_backoff[0.0-None-jitter3-None]": "passed",
                "tests/test_backoff.py::test_exponential_backoff[1.0-None-None-10.0]": "passed",
                "tests/test_backoff.py::test_exponential_backoff[1.0-None-jitter5-10.0]": "passed",
                "tests/test_backoff.py::test_fixed_backoff_invalid_jitter": "passed",
                "tests/test_backoff.py::test_linear_backoff_invalid_jitter": "passed",
                "tests/test_backoff.py::test_exponential_backoff_invalid_jitter": "passed",
                "tests/test_backoff.py::test_backoff_invalid_base_delay": "passed",
                "tests/test_callback.py::test_CallbackFactory_callable_function": "passed",
                "tests/test_callback.py::test_CallbackFactory_non_callable_function": "passed",
                "tests/test_callback.py::test_CallbackFactory_arguments_passing": "passed",
                "tests/test_callback.py::test_CallbackFactory_keyword_arguments_passing": "passed",
                "tests/test_callback.py::test_CallbackFactory_arguments_override": "passed",
                "tests/test_callback.py::test_CallbackFactory_partial_arguments_override": "passed",
                "tests/test_callback.py::test_callback_factory_callable_function": "passed",
                "tests/test_callback.py::test_callback_factory_non_callable_function": "passed",
                "tests/test_callback.py::test_callback_factory_arguments_passing": "passed",
                "tests/test_callback.py::test_callback_factory_keyword_arguments_passing": "passed",
                "tests/test_callback.py::test_callback_factory_arguments_override": "passed",
                "tests/test_callback.py::test_callback_factory_partial_arguments_override": "passed",
                "tests/test_retry.py::test_successful_execution": "passed",
                "tests/test_retry.py::test_maximum_retries_reached": "passed",
                "tests/test_retry.py::test_timeout": "passed",
                "tests/test_retry.py::test_deadline": "passed",
                "tests/test_retry.py::test_failure_callback_called": "passed",
                "tests/test_retry.py::test_successful_retry_callback_called": "passed",
                "tests/test_retry.py::test_retry_callback_called": "passed",
                "tests/test_retry.py::test_reraise_exception_true": "passed",
                "tests/test_retry.py::test_reraise_exception_false": "passed",
                "tests/test_retry.py::test_no_retry_on_excluded_exception": "passed",
                "tests/test_retry.py::test_retry_on_mixed_exclusions": "passed",
                "tests/test_retry_args.py::test_valid_arguments": "passed",
                "tests/test_retry_args.py::test_invalid_exceptions": "passed",
                "tests/test_retry_args.py::test_invalid_excluded_exceptions": "passed",
                "tests/test_retry_args.py::test_invalid_max_retries": "passed",
                "tests/test_retry_args.py::test_invalid_backoff": "passed",
                "tests/test_retry_args.py::test_invalid_timeout": "passed",
                "tests/test_retry_args.py::test_invalid_deadline": "passed",
                "tests/test_retry_args.py::test_invalid_logger": "passed",
                "tests/test_retry_args.py::test_invalid_log_retry_traceback": "passed",
                "tests/test_retry_args.py::test_invalid_failure_callback": "passed",
                "tests/test_retry_args.py::test_invalid_retry_callback": "passed",
                "tests/test_retry_args.py::test_invalid_successful_retry_callback": "passed",
                "tests/test_retry_args.py::test_invalid_reraise_exception": "passed"
            },
            "success_count": 59,
            "failed_count": 0,
            "error_count": 0,
            "skipped_count": 0,
            "unknown_count": 0,
            "total_count": 59,
            "success_rate": 1.0,
            "coverage_report": {
                "covered_lines": 256,
                "num_statements": 358,
                "percent_covered": 73.23651452282158,
                "percent_covered_display": "73",
                "missing_lines": 102,
                "excluded_lines": 0,
                "num_branches": 124,
                "num_partial_branches": 15,
                "covered_branches": 97,
                "missing_branches": 27
            },
            "coverage_result": {}
        },
        "codelines_count": 1605,
        "codefiles_count": 15,
        "code_length": 52712,
        "test_files_count": 4,
        "test_code_length": 15041,
        "class_diagram": "@startuml\nclass CallbackFactory {\n    __init__(func): void\n    __call__(): void\n}\nclass BaseRetryException {\n    __init__(logger, message, failure_callback): Unknown\n}\nclass MaxRetriesException {\n    __init__(logger, fname, max_retries, failure_callback): Unknown\n}\nclass RetriesTimeoutException {\n    __init__(logger, fname, elapsed_time, timeout, failure_callback): Unknown\n}\nclass RetriesDeadlineException {\n    __init__(logger, fname, elapsed_time, deadline, failure_callback): Unknown\n}\nclass BackOff {\n    __init__(base_delay, jitter): void\n    _validate_base_delay(base_delay): float\n    _validate_jitter(jitter): Optional[Tuple[float, float]]\n    _validate_step(step): Optional[float]\n    _validate_max(max): Optional[float]\n    _calculate_next_delay(): void\n    delay(): float\n    reset(): Unknown\n}\nclass FixedBackOff {\n    _calculate_next_delay(): void\n}\nclass LinearBackOff {\n    __init__(base_delay, step, jitter, max): void\n    _calculate_next_delay(): void\n}\nclass RandomUniformBackOff {\n    __init__(base_delay, min_delay, max_delay): void\n    _calculate_next_delay(): void\n}\nclass ExponentialBackOff {\n    DEFAULT_BASE: Unknown\n    __init__(base_delay, base, jitter, max): void\n    _calculate_next_delay(): void\n}\nBackOff <|-- RandomUniformBackOff\nBackOff <|-- ExponentialBackOff\nBackOff <|-- LinearBackOff\nBaseRetryException <|-- RetriesDeadlineException\nBaseRetryException <|-- RetriesTimeoutException\nBackOff <|-- FixedBackOff\nBaseRetryException <|-- MaxRetriesException\n@enduml",
        "structure": [
            {
                "file": "setup.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "examples.py",
                "functions": [
                    {
                        "name": "cause_max_retries_error",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "cause_timeout_error",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "cause_deadline_error",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "cause_deadline_error_after_retries",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "retry_callback",
                        "docstring": null,
                        "comments": "Retry until maximum retries are reached\nRandom backoff strategy with an initial delay and\nlimits for min and max delay in next retries\ncallback function between retries by passing a callable function",
                        "args": []
                    },
                    {
                        "name": "retry_with_callback",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "successful_retry_callback",
                        "docstring": null,
                        "comments": "Retry indefinetely as there is no max retries, timeout\nor deadline specified\nExponential backoff strategy with an initial delay of 1 second\nparametrized callback with utility of package to call after successful retry\nsuccessful callback is expected after successful retry on 3rd round",
                        "args": [
                            "value"
                        ]
                    },
                    {
                        "name": "successful_retry_with_callback",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "failure_callback",
                        "docstring": null,
                        "comments": "Retry until maximum retries are reached\nLinear backoff strategy with an initial delay of 0.1 second and 0.1 second as step\nparametrized callback with utility of package to call after failure of all retries\nfailure callback is expected after failing all 3 retries",
                        "args": [
                            "value"
                        ]
                    },
                    {
                        "name": "fail_with_callback",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "retry_with_reraise",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "give_up_on_value_error",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_retry_args.py",
                "functions": [
                    {
                        "name": "test_valid_arguments",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_invalid_exceptions",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_invalid_excluded_exceptions",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_invalid_max_retries",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_invalid_backoff",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_invalid_timeout",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_invalid_deadline",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_invalid_logger",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_invalid_log_retry_traceback",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_invalid_failure_callback",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_invalid_retry_callback",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_invalid_successful_retry_callback",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_invalid_reraise_exception",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/conftest.py",
                "functions": [
                    {
                        "name": "retry_callback",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "successful_retry_callback",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "failure_callback",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_callback.py",
                "functions": [
                    {
                        "name": "test_CallbackFactory_callable_function",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_CallbackFactory_non_callable_function",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_CallbackFactory_arguments_passing",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_CallbackFactory_keyword_arguments_passing",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_CallbackFactory_arguments_override",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_CallbackFactory_partial_arguments_override",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_callback_factory_callable_function",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_callback_factory_non_callable_function",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_callback_factory_arguments_passing",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_callback_factory_keyword_arguments_passing",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_callback_factory_arguments_override",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_callback_factory_partial_arguments_override",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_retry.py",
                "functions": [
                    {
                        "name": "test_successful_execution",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_maximum_retries_reached",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_timeout",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_deadline",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_failure_callback_called",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "failure_callback"
                        ]
                    },
                    {
                        "name": "test_successful_retry_callback_called",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "successful_retry_callback"
                        ]
                    },
                    {
                        "name": "test_retry_callback_called",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "retry_callback"
                        ]
                    },
                    {
                        "name": "test_reraise_exception_true",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_reraise_exception_false",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_no_retry_on_excluded_exception",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_retry_on_mixed_exclusions",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_backoff.py",
                "functions": [
                    {
                        "name": "test_fixed_backoff",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "base_delay",
                            "jitter"
                        ]
                    },
                    {
                        "name": "test_linear_backoff",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "base_delay",
                            "step",
                            "jitter",
                            "max_delay"
                        ]
                    },
                    {
                        "name": "test_random_uniform_backoff",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "base_delay",
                            "min_delay",
                            "max_delay"
                        ]
                    },
                    {
                        "name": "test_exponential_backoff",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "base_delay",
                            "base",
                            "jitter",
                            "max_delay"
                        ]
                    },
                    {
                        "name": "test_fixed_backoff_invalid_jitter",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_linear_backoff_invalid_jitter",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_exponential_backoff_invalid_jitter",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_backoff_invalid_base_delay",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "retry_reloaded/_validate.py",
                "functions": [
                    {
                        "name": "_validate_args",
                        "docstring": "Validate arguments for retry logic.\n\nArgs:\n    exceptions (Tuple[Type[Exception], ...]): Tuple of exception types to catch.\n    excluded_exceptions (Tuple[Type[Exception]], ...): Tuple of exception types not to catch.\n    max_retries (Optional[int]): Maximum number of retries allowed, or None for unlimited retries.\n    backoff (BackOff): BackOff instance to manage retry delays.\n    timeout (Optional[float]): Timeout value for the retry operation in seconds, or None if no timeout.\n    deadline (Optional[float]): Deadline for the retry operation in seconds, or None if no deadline.\n    logger (Optional[logging.Logger]): Logger instance for logging retry information, or None if logging is disabled.\n    log_retry_traceback (bool): Flag to indicate if the traceback should be logged on each retry.\n    failure_callback (Optional[Callable[[], None]]): Callback function to execute upon a failed retry, or None.\n    retry_callback (Optional[Callable[[], None]]): Callback function to execute before each retry attempt, or None.\n    successful_retry_callback (Optional[Callable[[], None]]): Callback function to execute upon a successful retry,\n      or None.\n    reraise_exception (bool): Whether to re-raise the last exception caught in case of failure after retries.\n\nRaises:\n    TypeError: If any of the arguments do not meet the expected types.",
                        "comments": null,
                        "args": [
                            "exceptions",
                            "excluded_exceptions",
                            "max_retries",
                            "backoff",
                            "timeout",
                            "deadline",
                            "logger",
                            "log_retry_traceback",
                            "failure_callback",
                            "retry_callback",
                            "successful_retry_callback",
                            "reraise_exception"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "retry_reloaded/callback.py",
                "functions": [
                    {
                        "name": "callback_factory",
                        "docstring": "Create a callback function that wraps the provided callable function.\n\nParameters:\n    func (Callable): The callable function to be wrapped.\n    *args: Positional arguments to be passed to the function.\n    **kwargs: Keyword arguments to be passed to the function.\n\nReturns:\n    A wrapped function that calls the provided\n    callable function with the specified arguments.\n\nRaises:\n    TypeError: If `func` is not a callable object.",
                        "comments": null,
                        "args": [
                            "func"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "CallbackFactory",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize the CallbackFactory.\n\nParameters:\n    func (Callable): The callable function to be wrapped.\n    *args: Positional arguments to be passed to the function.\n    **kwargs: Keyword arguments to be passed to the function.\n\nRaises:\n    TypeError: If `func` is not a callable object.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "func"
                                ]
                            },
                            {
                                "name": "__call__",
                                "docstring": "Call the wrapped function with provided keyword arguments.\nIf no arguments are provided during calling,\nthen the stored ones (during instance creation) are used.\n\nReturns:\n    The result of calling the wrapped function with provided arguments.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "retry_reloaded/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "retry_reloaded/retry.py",
                "functions": [
                    {
                        "name": "retry",
                        "docstring": "Decorator that adds retry functionality to a function.\n\nParameters:\n    exceptions (Tuple[Type[Exception]], optional): A tuple of exception types that should trigger a retry.\n        Defaults to (Exception,), meaning any exception will trigger a retry.\n    excluded_exceptions (Tuple[Type[Exception]], optional): A tuple of exception types that should not trigger\n        a retry. Defaults to an empty tuple.\n    max_retries (int, optional): The maximum number of retry attempts. Defaults to None (unlimited retries).\n    backoff (BackOff, optional): The backoff strategy to use between retry attempts.\n        Defaults to FixedBackOff(base_delay=0) with base_delay referring to seconds.\n    timeout (float, optional): The maximum time (in seconds) to spend on retries. Defaults to None (no timeout).\n        Timeout check happens right before retry execution of the wrapped function.\n    deadline (float, optional): The deadline (in seconds) for retries. Defaults to None (no deadline).\n        Deadline check happens right after the retry execution of the wrapped function.\n    logger (logging.Logger, optional): The logger instance to use for logging retry attempts. Defaults to retry_logger.\n    log_retry_traceback (bool, optional): Whether to log the traceback of exceptions triggering retries.\n        Defaults to False.\n    failure_callback (Callable, optional): A callback function to call in case of eventual failure after retries.\n        Defaults to None.\n    retry_callback (Callable, optional): A callback function to call between subsequent retry attempts.\n        Defaults to None.\n    successful_retry_callback (Callable, optional): A callback function to call after a successful retry.\n        Defaults to None.\n    reraise_exception (bool, optional): Whether to re-raise the last exception caught in case of failure after retries.\n        Defaults to False.\n\nReturns:\n    Callable: The decorated function.\n\nRaises:\n    TypeError: If any argument has an invalid type.\n\nExample:\n    @retry(exceptions=(ValueError,), max_retries=3, backoff=ExponentialBackOff(), timeout=10, logger=my_logger)\n    def my_function():\n        # Function body",
                        "comments": null,
                        "args": [
                            "exceptions",
                            "excluded_exceptions",
                            "max_retries",
                            "backoff",
                            "timeout",
                            "deadline",
                            "logger",
                            "log_retry_traceback",
                            "failure_callback",
                            "retry_callback",
                            "successful_retry_callback",
                            "reraise_exception"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "retry_reloaded/_logging.py",
                "functions": [
                    {
                        "name": "_init_logger",
                        "docstring": "Initialize logger for retry function.\n\nArgs:\n    name (str): Name for the logger.\n\nReturns:\n    logging.Logger: Logger object configured for retry logging.",
                        "comments": null,
                        "args": [
                            "name"
                        ]
                    },
                    {
                        "name": "_log_retry",
                        "docstring": "Log retry information.\n\nArgs:\n    logger (Optional[logging.Logger]): Logger object to use for logging. If None, logging is skipped.\n    fname (str): Name of the function being retried.\n    max_retries (Optional[int]): Maximum number of retries allowed, or None if unlimited.\n    retries (int): Number of retries attempted so far.\n    timeout (Optional[float]): Timeout value for the retry operation in seconds.\n    deadline (Optional[float]): Deadline for the retry operation in seconds.\n    start_time (float): Start time of the retry operation.\n    delay (float): Delay until the next retry in seconds.\n    exc_info (Optional[Exception]): Information about the exception that triggered the retry.\n\nReturns:\n    None",
                        "comments": null,
                        "args": [
                            "logger",
                            "fname",
                            "max_retries",
                            "retries",
                            "timeout",
                            "deadline",
                            "start_time",
                            "delay",
                            "exc_info"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "retry_reloaded/_exceptions.py",
                "functions": [],
                "classes": [
                    {
                        "name": "BaseRetryException",
                        "docstring": "Base class for retry-related exceptions.\n\nArgs:\n    logger (logging.Logger): Logger object to use for logging the exception message.\n    message (str): Message describing the exception.\n    failure_callback (Optional[Callable]): Callback function to execute upon raising the exception.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "logger",
                                    "message",
                                    "failure_callback"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "MaxRetriesException",
                        "docstring": "Exception raised when the maximum number of retries is reached.\n\nArgs:\n    logger (logging.Logger): Logger object to use for logging the exception message.\n    fname (str): Name of the function for which maximum retries were reached.\n    failure_callback (Optional[Callable]): Callback function to execute upon raising the exception.\n    max_retries (int): Maximum number of retries that have been attempted.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "logger",
                                    "fname",
                                    "max_retries",
                                    "failure_callback"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "RetriesTimeoutException",
                        "docstring": "Exception raised when retry operation exceeds the timeout.\n\nArgs:\n    logger (logging.Logger): Logger object to use for logging the exception message.\n    fname (str): Name of the function for which retry operation exceeded timeout.\n    failure_callback (Optional[Callable]): Callback function to execute upon raising the exception.\n    elapsed_time (float): Time elapsed during the retry operation in seconds.\n    timeout (float): Timeout value in seconds.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "logger",
                                    "fname",
                                    "elapsed_time",
                                    "timeout",
                                    "failure_callback"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "RetriesDeadlineException",
                        "docstring": "Exception raised when retry operation exceeds the deadline.\n\nArgs:\n    logger (logging.Logger): Logger object to use for logging the exception message.\n    fname (str): Name of the function for which retry operation exceeded deadline.\n    failure_callback (Optional[Callable]): Callback function to execute upon raising the exception.\n    elapsed_time (float): Time elapsed during the retry operation in seconds.\n    deadline (float): Deadline value in seconds.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "logger",
                                    "fname",
                                    "elapsed_time",
                                    "deadline",
                                    "failure_callback"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "retry_reloaded/backoff.py",
                "functions": [],
                "classes": [
                    {
                        "name": "BackOff",
                        "docstring": "Base class for implementing backoff strategies.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize BackOff object.\n\nArgs:\n    base_delay (float): Initial delay value, applies on the first round of delay and\n        calculations of next rounds. Defaults to 0.\n    jitter (Optional[Tuple[float, float]]): Tuple specifying the range for jitter (random delay on\n        top of the calculated delay), applying after the first round. If provided, it should be a\n        tuple of two numbers in sorted order. Defaults to None.\n\nRaises:\n    TypeError: If `jitter` is provided and not a tuple of two numbers.\n    ValueError: If the `jitter` values are not in sorted order.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "base_delay",
                                    "jitter"
                                ]
                            },
                            {
                                "name": "_validate_base_delay",
                                "docstring": "Validate the base delay of backoff strategy.\n\nArgs:\n    base_delay (float): Initial delay value, applies on\n        first round of delay and calculations of next rounds.\n\nReturns:\n    float: The validated base delay of backoff strategy.\n\nRaises:\n    TypeError: If `base_delay` is not a number.\n    ValueError: If `base_delay` is negative.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "base_delay"
                                ]
                            },
                            {
                                "name": "_validate_jitter",
                                "docstring": "Validate the jitter values.\n\nArgs:\n    jitter (Optional[Tuple[float, float]]): Tuple specifying the range for jitter.\n\nReturns:\n    Optional[Tuple[float, float]]: The validated jitter values.\n\nRaises:\n    TypeError: If `jitter` is not a tuple of two numbers.\n    ValueError: If `jitter` values are not positive or not in sorted order.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "jitter"
                                ]
                            },
                            {
                                "name": "_validate_step",
                                "docstring": "Validate the step delay value. If step is not specified then base delay of backoff\nstrategy is used instead.\n\nArgs:\n    step (float): Step value to increment delay.\n\nReturns:\n    float: The validated step value.\n\nRaises:\n    TypeError: If `step` is specified and not a number.\n    ValueError: If `step` is specified number but not positive one.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "step"
                                ]
                            },
                            {
                                "name": "_validate_max",
                                "docstring": "Validate the max delay value.\n\nArgs:\n    max (Optional[float]): Maximum delay value.\n\nReturns:\n    Optional[float]: The validated max delay value.\n\nRaises:\n    TypeError: If `max` is not a number.\n    ValueError: If `max` is less than the base delay.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "max"
                                ]
                            },
                            {
                                "name": "_calculate_next_delay",
                                "docstring": "Abstract method to calculate the delay for the next round of backoff.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "delay",
                                "docstring": "Get the current delay.\n\nReturns:\n    float: Current delay value.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "reset",
                                "docstring": "Reset the current delay.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "FixedBackOff",
                        "docstring": "Fixed backoff strategy.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "_calculate_next_delay",
                                "docstring": "Calculate the next round's delay for fixed backoff strategy.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "LinearBackOff",
                        "docstring": "Linear backoff strategy.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize LinearBackOff object.\n\nArgs:\n    base_delay (float): Initial delay value, applies on the first round of delay.\n    step (float): Step value to increment delay. If not specified defaults to base_delay.\n    jitter (Optional[Tuple[float, float]]): Tuple specifying the range for jitter (random delay on\n        top of the calculated delay), applying after the first round. Defaults to None.\n    max (Optional[float]): Maximum delay value. Defaults to None.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "base_delay",
                                    "step",
                                    "jitter",
                                    "max"
                                ]
                            },
                            {
                                "name": "_calculate_next_delay",
                                "docstring": "Calculate the next round's delay for linear backoff strategy.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "RandomUniformBackOff",
                        "docstring": "Random uniform backoff strategy.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize RandomUniformBackOff object.\n\nArgs:\n    base_delay (float): Initial delay value, applies on the first round of delay.\n    min_delay (float): Minimum delay value.\n    max_delay (float): Maximum delay value.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "base_delay",
                                    "min_delay",
                                    "max_delay"
                                ]
                            },
                            {
                                "name": "_calculate_next_delay",
                                "docstring": "Calculate the next round's delay for random uniform backoff strategy.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "ExponentialBackOff",
                        "docstring": "Exponential backoff strategy.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": "Initialize ExponentialBackOff object.\n\nArgs:\n    base_delay (float): Initial delay value, applies on the first round of delay.\n    base (Optional[float]): Value to use as base for exponentiation. Defaults to 2.\n    jitter (Optional[Tuple[float, float]]): Tuple specifying the range for jitter (random delay on\n        top of the calculated delay), applying after the first round. Defaults to None.\n    max (Optional[float]): Maximum delay value. Defaults to None.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "base_delay",
                                    "base",
                                    "jitter",
                                    "max"
                                ]
                            },
                            {
                                "name": "_calculate_next_delay",
                                "docstring": "Calculate the next round's delay for exponential backoff strategy.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": [
                            "DEFAULT_BASE"
                        ]
                    }
                ]
            }
        ],
        "test_cases": {
            "tests/test_backoff.py::test_fixed_backoff[1.0-None]": {
                "testid": "tests/test_backoff.py::test_fixed_backoff[1.0-None]",
                "result": "passed",
                "test_implementation": "def test_fixed_backoff(base_delay, jitter):\n    backoff = FixedBackOff(base_delay, jitter)\n\n    for _round in range(5):\n        delay = backoff.delay\n        assert isinstance(delay, float)\n        if jitter is None:\n            assert delay == base_delay\n        else:\n            low_jitter = jitter[0] if _round else 0\n            high_jitter = jitter[1] if _round else 0\n            assert base_delay + low_jitter <= delay\n            assert delay <= base_delay + high_jitter"
            },
            "tests/test_backoff.py::test_fixed_backoff[1.0-jitter1]": {
                "testid": "tests/test_backoff.py::test_fixed_backoff[1.0-jitter1]",
                "result": "passed",
                "test_implementation": "def test_fixed_backoff(base_delay, jitter):\n    backoff = FixedBackOff(base_delay, jitter)\n\n    for _round in range(5):\n        delay = backoff.delay\n        assert isinstance(delay, float)\n        if jitter is None:\n            assert delay == base_delay\n        else:\n            low_jitter = jitter[0] if _round else 0\n            high_jitter = jitter[1] if _round else 0\n            assert base_delay + low_jitter <= delay\n            assert delay <= base_delay + high_jitter"
            },
            "tests/test_backoff.py::test_fixed_backoff[0.0-None]": {
                "testid": "tests/test_backoff.py::test_fixed_backoff[0.0-None]",
                "result": "passed",
                "test_implementation": "def test_fixed_backoff(base_delay, jitter):\n    backoff = FixedBackOff(base_delay, jitter)\n\n    for _round in range(5):\n        delay = backoff.delay\n        assert isinstance(delay, float)\n        if jitter is None:\n            assert delay == base_delay\n        else:\n            low_jitter = jitter[0] if _round else 0\n            high_jitter = jitter[1] if _round else 0\n            assert base_delay + low_jitter <= delay\n            assert delay <= base_delay + high_jitter"
            },
            "tests/test_backoff.py::test_fixed_backoff[0.0-jitter3]": {
                "testid": "tests/test_backoff.py::test_fixed_backoff[0.0-jitter3]",
                "result": "passed",
                "test_implementation": "def test_fixed_backoff(base_delay, jitter):\n    backoff = FixedBackOff(base_delay, jitter)\n\n    for _round in range(5):\n        delay = backoff.delay\n        assert isinstance(delay, float)\n        if jitter is None:\n            assert delay == base_delay\n        else:\n            low_jitter = jitter[0] if _round else 0\n            high_jitter = jitter[1] if _round else 0\n            assert base_delay + low_jitter <= delay\n            assert delay <= base_delay + high_jitter"
            },
            "tests/test_backoff.py::test_linear_backoff[1.0-0.5-None-None]": {
                "testid": "tests/test_backoff.py::test_linear_backoff[1.0-0.5-None-None]",
                "result": "passed",
                "test_implementation": "def test_linear_backoff(base_delay, step, jitter, max_delay):\n    backoff = LinearBackOff(base_delay, step, jitter, max_delay)\n\n    for _round in range(5):\n        delay = backoff.delay\n        assert isinstance(delay, float)\n\n        if max_delay is not None:\n            expected_delay = min(base_delay + (step * _round), max_delay)\n        else:\n            expected_delay = base_delay + (step * _round)\n\n        if jitter is None:\n            assert delay == expected_delay\n        else:\n            low_jitter = jitter[0] if _round else 0\n            high_jitter = jitter[1] if _round else 0\n            if max_delay is None:\n                assert expected_delay + low_jitter <= delay\n                assert delay <= expected_delay + high_jitter\n            else:\n                assert delay <= max_delay\n\n    backoff.reset()\n    delay = backoff.delay\n    assert delay == base_delay"
            },
            "tests/test_backoff.py::test_linear_backoff[1.0-0.5-jitter1-None]": {
                "testid": "tests/test_backoff.py::test_linear_backoff[1.0-0.5-jitter1-None]",
                "result": "passed",
                "test_implementation": "def test_linear_backoff(base_delay, step, jitter, max_delay):\n    backoff = LinearBackOff(base_delay, step, jitter, max_delay)\n\n    for _round in range(5):\n        delay = backoff.delay\n        assert isinstance(delay, float)\n\n        if max_delay is not None:\n            expected_delay = min(base_delay + (step * _round), max_delay)\n        else:\n            expected_delay = base_delay + (step * _round)\n\n        if jitter is None:\n            assert delay == expected_delay\n        else:\n            low_jitter = jitter[0] if _round else 0\n            high_jitter = jitter[1] if _round else 0\n            if max_delay is None:\n                assert expected_delay + low_jitter <= delay\n                assert delay <= expected_delay + high_jitter\n            else:\n                assert delay <= max_delay\n\n    backoff.reset()\n    delay = backoff.delay\n    assert delay == base_delay"
            },
            "tests/test_backoff.py::test_linear_backoff[0.0-0.0-None-None]": {
                "testid": "tests/test_backoff.py::test_linear_backoff[0.0-0.0-None-None]",
                "result": "passed",
                "test_implementation": "def test_linear_backoff(base_delay, step, jitter, max_delay):\n    backoff = LinearBackOff(base_delay, step, jitter, max_delay)\n\n    for _round in range(5):\n        delay = backoff.delay\n        assert isinstance(delay, float)\n\n        if max_delay is not None:\n            expected_delay = min(base_delay + (step * _round), max_delay)\n        else:\n            expected_delay = base_delay + (step * _round)\n\n        if jitter is None:\n            assert delay == expected_delay\n        else:\n            low_jitter = jitter[0] if _round else 0\n            high_jitter = jitter[1] if _round else 0\n            if max_delay is None:\n                assert expected_delay + low_jitter <= delay\n                assert delay <= expected_delay + high_jitter\n            else:\n                assert delay <= max_delay\n\n    backoff.reset()\n    delay = backoff.delay\n    assert delay == base_delay"
            },
            "tests/test_backoff.py::test_linear_backoff[0.0-0.0-jitter3-None]": {
                "testid": "tests/test_backoff.py::test_linear_backoff[0.0-0.0-jitter3-None]",
                "result": "passed",
                "test_implementation": "def test_linear_backoff(base_delay, step, jitter, max_delay):\n    backoff = LinearBackOff(base_delay, step, jitter, max_delay)\n\n    for _round in range(5):\n        delay = backoff.delay\n        assert isinstance(delay, float)\n\n        if max_delay is not None:\n            expected_delay = min(base_delay + (step * _round), max_delay)\n        else:\n            expected_delay = base_delay + (step * _round)\n\n        if jitter is None:\n            assert delay == expected_delay\n        else:\n            low_jitter = jitter[0] if _round else 0\n            high_jitter = jitter[1] if _round else 0\n            if max_delay is None:\n                assert expected_delay + low_jitter <= delay\n                assert delay <= expected_delay + high_jitter\n            else:\n                assert delay <= max_delay\n\n    backoff.reset()\n    delay = backoff.delay\n    assert delay == base_delay"
            },
            "tests/test_backoff.py::test_linear_backoff[1.0-0.5-None-2.0]": {
                "testid": "tests/test_backoff.py::test_linear_backoff[1.0-0.5-None-2.0]",
                "result": "passed",
                "test_implementation": "def test_linear_backoff(base_delay, step, jitter, max_delay):\n    backoff = LinearBackOff(base_delay, step, jitter, max_delay)\n\n    for _round in range(5):\n        delay = backoff.delay\n        assert isinstance(delay, float)\n\n        if max_delay is not None:\n            expected_delay = min(base_delay + (step * _round), max_delay)\n        else:\n            expected_delay = base_delay + (step * _round)\n\n        if jitter is None:\n            assert delay == expected_delay\n        else:\n            low_jitter = jitter[0] if _round else 0\n            high_jitter = jitter[1] if _round else 0\n            if max_delay is None:\n                assert expected_delay + low_jitter <= delay\n                assert delay <= expected_delay + high_jitter\n            else:\n                assert delay <= max_delay\n\n    backoff.reset()\n    delay = backoff.delay\n    assert delay == base_delay"
            },
            "tests/test_backoff.py::test_linear_backoff[1.0-0.5-jitter5-2.0]": {
                "testid": "tests/test_backoff.py::test_linear_backoff[1.0-0.5-jitter5-2.0]",
                "result": "passed",
                "test_implementation": "def test_linear_backoff(base_delay, step, jitter, max_delay):\n    backoff = LinearBackOff(base_delay, step, jitter, max_delay)\n\n    for _round in range(5):\n        delay = backoff.delay\n        assert isinstance(delay, float)\n\n        if max_delay is not None:\n            expected_delay = min(base_delay + (step * _round), max_delay)\n        else:\n            expected_delay = base_delay + (step * _round)\n\n        if jitter is None:\n            assert delay == expected_delay\n        else:\n            low_jitter = jitter[0] if _round else 0\n            high_jitter = jitter[1] if _round else 0\n            if max_delay is None:\n                assert expected_delay + low_jitter <= delay\n                assert delay <= expected_delay + high_jitter\n            else:\n                assert delay <= max_delay\n\n    backoff.reset()\n    delay = backoff.delay\n    assert delay == base_delay"
            },
            "tests/test_backoff.py::test_random_uniform_backoff[1.0-0.5-2.0]": {
                "testid": "tests/test_backoff.py::test_random_uniform_backoff[1.0-0.5-2.0]",
                "result": "passed",
                "test_implementation": "def test_random_uniform_backoff(base_delay, min_delay, max_delay):\n    backoff = RandomUniformBackOff(base_delay, min_delay, max_delay)\n\n    delay = backoff.delay\n    assert isinstance(delay, float)\n    assert delay == base_delay\n    for _ in range(5):\n        delay = backoff.delay\n        assert isinstance(delay, float)\n        assert min_delay <= delay <= max_delay"
            },
            "tests/test_backoff.py::test_random_uniform_backoff[1.0-3.4-5.6]": {
                "testid": "tests/test_backoff.py::test_random_uniform_backoff[1.0-3.4-5.6]",
                "result": "passed",
                "test_implementation": "def test_random_uniform_backoff(base_delay, min_delay, max_delay):\n    backoff = RandomUniformBackOff(base_delay, min_delay, max_delay)\n\n    delay = backoff.delay\n    assert isinstance(delay, float)\n    assert delay == base_delay\n    for _ in range(5):\n        delay = backoff.delay\n        assert isinstance(delay, float)\n        assert min_delay <= delay <= max_delay"
            },
            "tests/test_backoff.py::test_random_uniform_backoff[0.0-0.0-0.0]": {
                "testid": "tests/test_backoff.py::test_random_uniform_backoff[0.0-0.0-0.0]",
                "result": "passed",
                "test_implementation": "def test_random_uniform_backoff(base_delay, min_delay, max_delay):\n    backoff = RandomUniformBackOff(base_delay, min_delay, max_delay)\n\n    delay = backoff.delay\n    assert isinstance(delay, float)\n    assert delay == base_delay\n    for _ in range(5):\n        delay = backoff.delay\n        assert isinstance(delay, float)\n        assert min_delay <= delay <= max_delay"
            },
            "tests/test_backoff.py::test_exponential_backoff[1.0-None-None-None]": {
                "testid": "tests/test_backoff.py::test_exponential_backoff[1.0-None-None-None]",
                "result": "passed",
                "test_implementation": "def test_exponential_backoff(base_delay, base, jitter, max_delay):\n    backoff = ExponentialBackOff(base_delay, base, jitter, max_delay)\n\n    for _round in range(5):\n        delay = backoff.delay\n        assert isinstance(delay, float)\n        base_value = base if base is not None else 2\n\n        if max_delay is not None:\n            expected_delay = min(base_delay * (base_value**_round), max_delay)\n        else:\n            expected_delay = base_delay * (base_value**_round)\n\n        if jitter is None:\n            assert delay == expected_delay\n        else:\n            low_jitter = jitter[0] if _round else 0\n            high_jitter = jitter[1] if _round else 0\n            if max_delay is None:\n                assert expected_delay + low_jitter <= delay\n                assert delay <= expected_delay + high_jitter\n            else:\n                assert delay <= max_delay\n\n    backoff.reset()\n    delay = backoff.delay\n    assert delay == base_delay"
            },
            "tests/test_backoff.py::test_exponential_backoff[1.0-None-jitter1-None]": {
                "testid": "tests/test_backoff.py::test_exponential_backoff[1.0-None-jitter1-None]",
                "result": "passed",
                "test_implementation": "def test_exponential_backoff(base_delay, base, jitter, max_delay):\n    backoff = ExponentialBackOff(base_delay, base, jitter, max_delay)\n\n    for _round in range(5):\n        delay = backoff.delay\n        assert isinstance(delay, float)\n        base_value = base if base is not None else 2\n\n        if max_delay is not None:\n            expected_delay = min(base_delay * (base_value**_round), max_delay)\n        else:\n            expected_delay = base_delay * (base_value**_round)\n\n        if jitter is None:\n            assert delay == expected_delay\n        else:\n            low_jitter = jitter[0] if _round else 0\n            high_jitter = jitter[1] if _round else 0\n            if max_delay is None:\n                assert expected_delay + low_jitter <= delay\n                assert delay <= expected_delay + high_jitter\n            else:\n                assert delay <= max_delay\n\n    backoff.reset()\n    delay = backoff.delay\n    assert delay == base_delay"
            },
            "tests/test_backoff.py::test_exponential_backoff[0.0-None-None-None]": {
                "testid": "tests/test_backoff.py::test_exponential_backoff[0.0-None-None-None]",
                "result": "passed",
                "test_implementation": "def test_exponential_backoff(base_delay, base, jitter, max_delay):\n    backoff = ExponentialBackOff(base_delay, base, jitter, max_delay)\n\n    for _round in range(5):\n        delay = backoff.delay\n        assert isinstance(delay, float)\n        base_value = base if base is not None else 2\n\n        if max_delay is not None:\n            expected_delay = min(base_delay * (base_value**_round), max_delay)\n        else:\n            expected_delay = base_delay * (base_value**_round)\n\n        if jitter is None:\n            assert delay == expected_delay\n        else:\n            low_jitter = jitter[0] if _round else 0\n            high_jitter = jitter[1] if _round else 0\n            if max_delay is None:\n                assert expected_delay + low_jitter <= delay\n                assert delay <= expected_delay + high_jitter\n            else:\n                assert delay <= max_delay\n\n    backoff.reset()\n    delay = backoff.delay\n    assert delay == base_delay"
            },
            "tests/test_backoff.py::test_exponential_backoff[0.0-None-jitter3-None]": {
                "testid": "tests/test_backoff.py::test_exponential_backoff[0.0-None-jitter3-None]",
                "result": "passed",
                "test_implementation": "def test_exponential_backoff(base_delay, base, jitter, max_delay):\n    backoff = ExponentialBackOff(base_delay, base, jitter, max_delay)\n\n    for _round in range(5):\n        delay = backoff.delay\n        assert isinstance(delay, float)\n        base_value = base if base is not None else 2\n\n        if max_delay is not None:\n            expected_delay = min(base_delay * (base_value**_round), max_delay)\n        else:\n            expected_delay = base_delay * (base_value**_round)\n\n        if jitter is None:\n            assert delay == expected_delay\n        else:\n            low_jitter = jitter[0] if _round else 0\n            high_jitter = jitter[1] if _round else 0\n            if max_delay is None:\n                assert expected_delay + low_jitter <= delay\n                assert delay <= expected_delay + high_jitter\n            else:\n                assert delay <= max_delay\n\n    backoff.reset()\n    delay = backoff.delay\n    assert delay == base_delay"
            },
            "tests/test_backoff.py::test_exponential_backoff[1.0-None-None-10.0]": {
                "testid": "tests/test_backoff.py::test_exponential_backoff[1.0-None-None-10.0]",
                "result": "passed",
                "test_implementation": "def test_exponential_backoff(base_delay, base, jitter, max_delay):\n    backoff = ExponentialBackOff(base_delay, base, jitter, max_delay)\n\n    for _round in range(5):\n        delay = backoff.delay\n        assert isinstance(delay, float)\n        base_value = base if base is not None else 2\n\n        if max_delay is not None:\n            expected_delay = min(base_delay * (base_value**_round), max_delay)\n        else:\n            expected_delay = base_delay * (base_value**_round)\n\n        if jitter is None:\n            assert delay == expected_delay\n        else:\n            low_jitter = jitter[0] if _round else 0\n            high_jitter = jitter[1] if _round else 0\n            if max_delay is None:\n                assert expected_delay + low_jitter <= delay\n                assert delay <= expected_delay + high_jitter\n            else:\n                assert delay <= max_delay\n\n    backoff.reset()\n    delay = backoff.delay\n    assert delay == base_delay"
            },
            "tests/test_backoff.py::test_exponential_backoff[1.0-None-jitter5-10.0]": {
                "testid": "tests/test_backoff.py::test_exponential_backoff[1.0-None-jitter5-10.0]",
                "result": "passed",
                "test_implementation": "def test_exponential_backoff(base_delay, base, jitter, max_delay):\n    backoff = ExponentialBackOff(base_delay, base, jitter, max_delay)\n\n    for _round in range(5):\n        delay = backoff.delay\n        assert isinstance(delay, float)\n        base_value = base if base is not None else 2\n\n        if max_delay is not None:\n            expected_delay = min(base_delay * (base_value**_round), max_delay)\n        else:\n            expected_delay = base_delay * (base_value**_round)\n\n        if jitter is None:\n            assert delay == expected_delay\n        else:\n            low_jitter = jitter[0] if _round else 0\n            high_jitter = jitter[1] if _round else 0\n            if max_delay is None:\n                assert expected_delay + low_jitter <= delay\n                assert delay <= expected_delay + high_jitter\n            else:\n                assert delay <= max_delay\n\n    backoff.reset()\n    delay = backoff.delay\n    assert delay == base_delay"
            },
            "tests/test_backoff.py::test_fixed_backoff_invalid_jitter": {
                "testid": "tests/test_backoff.py::test_fixed_backoff_invalid_jitter",
                "result": "passed",
                "test_implementation": "def test_fixed_backoff_invalid_jitter():\n    with pytest.raises(ValueError):\n        FixedBackOff(1.0, (0.5, 0.1))\n\n    with pytest.raises(TypeError):\n        FixedBackOff(1.0, (0.5,))\n\n    with pytest.raises(TypeError):\n        FixedBackOff(1.0, (0.5, 0.1, 0.2))\n\n    with pytest.raises(TypeError):\n        FixedBackOff(1.0, (0.5, 'a'))\n\n    with pytest.raises(TypeError):\n        FixedBackOff(1.0, ('a', 0.5))\n\n    with pytest.raises(TypeError):\n        FixedBackOff(1.0, ('a', 'b'))"
            },
            "tests/test_backoff.py::test_linear_backoff_invalid_jitter": {
                "testid": "tests/test_backoff.py::test_linear_backoff_invalid_jitter",
                "result": "passed",
                "test_implementation": "def test_linear_backoff_invalid_jitter():\n    with pytest.raises(ValueError):\n        LinearBackOff(1.0, 0.5, (0.5, 0.1))\n\n    with pytest.raises(TypeError):\n        LinearBackOff(1.0, 0.5, (0.5,))\n\n    with pytest.raises(TypeError):\n        LinearBackOff(1.0, 0.5, (0.5, 0.1, 0.2))\n\n    with pytest.raises(TypeError):\n        LinearBackOff(1.0, 0.5, (0.5, 'a'))\n\n    with pytest.raises(TypeError):\n        LinearBackOff(1.0, 0.5, ('a', 0.5))\n\n    with pytest.raises(TypeError):\n        LinearBackOff(1.0, 0.5, ('a', 'b'))"
            },
            "tests/test_backoff.py::test_exponential_backoff_invalid_jitter": {
                "testid": "tests/test_backoff.py::test_exponential_backoff_invalid_jitter",
                "result": "passed",
                "test_implementation": "def test_exponential_backoff_invalid_jitter():\n    with pytest.raises(ValueError):\n        ExponentialBackOff(1.0, jitter=(0.5, 0.1))\n\n    with pytest.raises(TypeError):\n        ExponentialBackOff(1.0, jitter=(0.5,))\n\n    with pytest.raises(TypeError):\n        ExponentialBackOff(1.0, jitter=(0.5, 0.1, 0.2))\n\n    with pytest.raises(TypeError):\n        ExponentialBackOff(1.0, jitter=(0.5, 'a'))\n\n    with pytest.raises(TypeError):\n        ExponentialBackOff(1.0, jitter=('a', 0.5))\n\n    with pytest.raises(TypeError):\n        ExponentialBackOff(1.0, jitter=('a', 'b'))"
            },
            "tests/test_backoff.py::test_backoff_invalid_base_delay": {
                "testid": "tests/test_backoff.py::test_backoff_invalid_base_delay",
                "result": "passed",
                "test_implementation": "def test_backoff_invalid_base_delay():\n    with pytest.raises(ValueError):\n        ExponentialBackOff(-1)\n\n    with pytest.raises(TypeError):\n        LinearBackOff(\"not float\")\n\n    with pytest.raises(TypeError):\n        RandomUniformBackOff(None)"
            },
            "tests/test_callback.py::test_CallbackFactory_callable_function": {
                "testid": "tests/test_callback.py::test_CallbackFactory_callable_function",
                "result": "passed",
                "test_implementation": "def test_CallbackFactory_callable_function():\n    def dummy_func():\n        pass\n\n    _callback = CallbackFactory(dummy_func)\n    assert callable(_callback.func)"
            },
            "tests/test_callback.py::test_CallbackFactory_non_callable_function": {
                "testid": "tests/test_callback.py::test_CallbackFactory_non_callable_function",
                "result": "passed",
                "test_implementation": "def test_CallbackFactory_non_callable_function():\n    with pytest.raises(TypeError):\n        _ = CallbackFactory(\"not_callable\")"
            },
            "tests/test_callback.py::test_CallbackFactory_arguments_passing": {
                "testid": "tests/test_callback.py::test_CallbackFactory_arguments_passing",
                "result": "passed",
                "test_implementation": "def test_CallbackFactory_arguments_passing():\n    def dummy_func(x, y):\n        return x * y\n\n    _callback = CallbackFactory(dummy_func, 2, 3)\n    assert _callback() == 6"
            },
            "tests/test_callback.py::test_CallbackFactory_keyword_arguments_passing": {
                "testid": "tests/test_callback.py::test_CallbackFactory_keyword_arguments_passing",
                "result": "passed",
                "test_implementation": "def test_CallbackFactory_keyword_arguments_passing():\n    def dummy_func(x, y, z=1):\n        return x + y + z\n\n    _callback = CallbackFactory(dummy_func, 2, 3, z=4)\n    assert _callback() == 9"
            },
            "tests/test_callback.py::test_CallbackFactory_arguments_override": {
                "testid": "tests/test_callback.py::test_CallbackFactory_arguments_override",
                "result": "passed",
                "test_implementation": "def test_CallbackFactory_arguments_override():\n    def dummy_func(x, y):\n        return x * y\n\n    _callback = CallbackFactory(dummy_func, 2, 3)\n    assert _callback(x=3, y=3) == 9"
            },
            "tests/test_callback.py::test_CallbackFactory_partial_arguments_override": {
                "testid": "tests/test_callback.py::test_CallbackFactory_partial_arguments_override",
                "result": "passed",
                "test_implementation": "def test_CallbackFactory_partial_arguments_override():\n    def dummy_func(x, y, z=1):\n        return x + y + z\n\n    _callback = CallbackFactory(dummy_func, 2, 3, z=4)\n    assert _callback(y=5) == 11"
            },
            "tests/test_callback.py::test_callback_factory_callable_function": {
                "testid": "tests/test_callback.py::test_callback_factory_callable_function",
                "result": "passed",
                "test_implementation": "def test_callback_factory_callable_function():\n    def dummy_func():\n        pass\n\n    _callback = callback_factory(dummy_func)\n    assert callable(_callback)"
            },
            "tests/test_callback.py::test_callback_factory_non_callable_function": {
                "testid": "tests/test_callback.py::test_callback_factory_non_callable_function",
                "result": "passed",
                "test_implementation": "def test_callback_factory_non_callable_function():\n    with pytest.raises(TypeError):\n        _ = callback_factory(\"not_callable\")"
            },
            "tests/test_callback.py::test_callback_factory_arguments_passing": {
                "testid": "tests/test_callback.py::test_callback_factory_arguments_passing",
                "result": "passed",
                "test_implementation": "def test_callback_factory_arguments_passing():\n    def dummy_func(x, y):\n        return x * y\n\n    _callback = callback_factory(dummy_func, 2, 3)\n    assert _callback() == 6"
            },
            "tests/test_callback.py::test_callback_factory_keyword_arguments_passing": {
                "testid": "tests/test_callback.py::test_callback_factory_keyword_arguments_passing",
                "result": "passed",
                "test_implementation": "def test_callback_factory_keyword_arguments_passing():\n    def dummy_func(x, y, z=1):\n        return x + y + z\n\n    _callback = callback_factory(dummy_func, 2, 3, z=4)\n    assert _callback() == 9"
            },
            "tests/test_callback.py::test_callback_factory_arguments_override": {
                "testid": "tests/test_callback.py::test_callback_factory_arguments_override",
                "result": "passed",
                "test_implementation": "def test_callback_factory_arguments_override():\n    def dummy_func(x, y):\n        return x * y\n\n    _callback = callback_factory(dummy_func, 2, 3)\n    assert _callback(x=3, y=3) == 9"
            },
            "tests/test_callback.py::test_callback_factory_partial_arguments_override": {
                "testid": "tests/test_callback.py::test_callback_factory_partial_arguments_override",
                "result": "passed",
                "test_implementation": "def test_callback_factory_partial_arguments_override():\n    def dummy_func(x, y, z=1):\n        return x + y + z\n\n    _callback = callback_factory(dummy_func, 2, 3, z=4)\n    assert _callback(y=5) == 11"
            },
            "tests/test_retry.py::test_successful_execution": {
                "testid": "tests/test_retry.py::test_successful_execution",
                "result": "passed",
                "test_implementation": "def test_successful_execution():\n    retries = 0\n\n    @retry(max_retries=3)\n    def successful_function():\n        nonlocal retries\n        retries += 1\n        if retries < 3:\n            raise ValueError(\"Simulating failure\")\n        return \"Success\"\n\n    result = successful_function()\n    assert result == \"Success\"\n    assert retries == 3"
            },
            "tests/test_retry.py::test_maximum_retries_reached": {
                "testid": "tests/test_retry.py::test_maximum_retries_reached",
                "result": "passed",
                "test_implementation": "def test_maximum_retries_reached():\n    retries = 0\n\n    @retry(max_retries=2)\n    def failure_function():\n        nonlocal retries\n        retries += 1\n        raise ValueError(\"Simulating failure\")\n\n    with pytest.raises(MaxRetriesException):\n        failure_function()\n\n    assert retries == 3"
            },
            "tests/test_retry.py::test_timeout": {
                "testid": "tests/test_retry.py::test_timeout",
                "result": "passed",
                "test_implementation": "def test_timeout():\n    retries = 0\n    timeout = 2\n\n    @retry(timeout=timeout, backoff=FixedBackOff(base_delay=1))\n    def timeout_function():\n        nonlocal retries\n        retries += 1\n        raise ValueError(\"Simulating failure\")\n\n    with pytest.raises(RetriesTimeoutException):\n        timeout_function()\n\n    assert retries == timeout"
            },
            "tests/test_retry.py::test_deadline": {
                "testid": "tests/test_retry.py::test_deadline",
                "result": "passed",
                "test_implementation": "def test_deadline():\n    retries = 0\n    deadline = 2\n\n    @retry(deadline=deadline, backoff=FixedBackOff(base_delay=1))\n    def deadline_function():\n        nonlocal retries\n        retries += 1\n        if retries < deadline:\n            raise ValueError(\"Simulating failure\")\n        else:\n            sleep(deadline)\n\n    with pytest.raises(RetriesDeadlineException):\n        deadline_function()\n\n    assert retries == deadline"
            },
            "tests/test_retry.py::test_failure_callback_called": {
                "testid": "tests/test_retry.py::test_failure_callback_called",
                "result": "passed",
                "test_implementation": "def test_failure_callback_called(failure_callback):\n    @retry(max_retries=1, failure_callback=failure_callback)\n    def fail_with_callback():\n        raise ValueError(\"Simulating failure\")\n\n    with pytest.raises(MaxRetriesException):\n        fail_with_callback()\n\n    failure_callback.assert_called_once()"
            },
            "tests/test_retry.py::test_successful_retry_callback_called": {
                "testid": "tests/test_retry.py::test_successful_retry_callback_called",
                "result": "passed",
                "test_implementation": "def test_successful_retry_callback_called(successful_retry_callback):\n    retries = 0\n    max_retries = 2\n\n    @retry(max_retries=max_retries, successful_retry_callback=successful_retry_callback)\n    def successful_retry_with_callback():\n        nonlocal retries\n        retries += 1\n        if retries < max_retries:\n            raise ValueError(\"Simulating failure\")\n\n    successful_retry_with_callback()\n\n    successful_retry_callback.assert_called_once()"
            },
            "tests/test_retry.py::test_retry_callback_called": {
                "testid": "tests/test_retry.py::test_retry_callback_called",
                "result": "passed",
                "test_implementation": "def test_retry_callback_called(retry_callback):\n    max_retries = 2\n\n    @retry(max_retries=max_retries, retry_callback=retry_callback)\n    def retry_with_callback():\n        raise ValueError(\"Simulating failure\")\n\n    with pytest.raises(MaxRetriesException):\n        retry_with_callback()\n\n    retry_callback.call_count = max_retries"
            },
            "tests/test_retry.py::test_reraise_exception_true": {
                "testid": "tests/test_retry.py::test_reraise_exception_true",
                "result": "passed",
                "test_implementation": "def test_reraise_exception_true():\n    retries = 0\n    max_retries = 2\n\n    @retry(max_retries=max_retries, reraise_exception=True)\n    def function_that_fails():\n        nonlocal retries\n        retries += 1\n        raise ValueError(\"Simulating failure\")\n\n    with pytest.raises(ValueError, match=\"Simulating failure\"):\n        function_that_fails()\n\n    assert retries == max_retries + 1"
            },
            "tests/test_retry.py::test_reraise_exception_false": {
                "testid": "tests/test_retry.py::test_reraise_exception_false",
                "result": "passed",
                "test_implementation": "def test_reraise_exception_false():\n    retries = 0\n    max_retries = 2\n\n    @retry(max_retries=max_retries, reraise_exception=False)\n    def function_that_fails():\n        nonlocal retries\n        retries += 1\n        raise ValueError(\"Simulating failure\")\n\n    with pytest.raises(MaxRetriesException):\n        function_that_fails()\n\n    assert retries == max_retries + 1"
            },
            "tests/test_retry.py::test_no_retry_on_excluded_exception": {
                "testid": "tests/test_retry.py::test_no_retry_on_excluded_exception",
                "result": "passed",
                "test_implementation": "def test_no_retry_on_excluded_exception():\n    retries = 0\n\n    @retry(excluded_exceptions=(ValueError,), max_retries=2)\n    def raise_value_error():\n        nonlocal retries\n        retries += 1\n        raise ValueError(\"Simulating ValueError\")\n\n    with pytest.raises(ValueError):\n        raise_value_error()\n\n    assert retries == 1"
            },
            "tests/test_retry.py::test_retry_on_mixed_exclusions": {
                "testid": "tests/test_retry.py::test_retry_on_mixed_exclusions",
                "result": "passed",
                "test_implementation": "def test_retry_on_mixed_exclusions():\n    retries = 0\n\n    @retry(exceptions=(ValueError, TypeError), excluded_exceptions=(ValueError,), max_retries=5)\n    def raise_mixed_exceptions():\n        nonlocal retries\n        retries += 1\n        if retries == 5:\n            raise ValueError(\"Simulating excluded ValueError\")\n        raise TypeError(\"Simulating TypeError\")\n\n    with pytest.raises(ValueError, match=\"Simulating excluded ValueError\"):\n        raise_mixed_exceptions()\n\n    assert retries == 5"
            },
            "tests/test_retry_args.py::test_valid_arguments": {
                "testid": "tests/test_retry_args.py::test_valid_arguments",
                "result": "passed",
                "test_implementation": "def test_valid_arguments():\n    @retry()\n    def valid_function():\n        return \"Valid function\"\n\n    assert callable(valid_function)"
            },
            "tests/test_retry_args.py::test_invalid_exceptions": {
                "testid": "tests/test_retry_args.py::test_invalid_exceptions",
                "result": "passed",
                "test_implementation": "def test_invalid_exceptions():\n    with pytest.raises(TypeError):\n        @retry(exceptions=(ValueError, \"not_an_exception_subclass\"))\n        def invalid_exceptions_function():\n            pass"
            },
            "tests/test_retry_args.py::test_invalid_excluded_exceptions": {
                "testid": "tests/test_retry_args.py::test_invalid_excluded_exceptions",
                "result": "passed",
                "test_implementation": "def test_invalid_excluded_exceptions():\n    with pytest.raises(TypeError):\n        @retry(excluded_exceptions=(ValueError, \"not_an_exception_subclass\"))\n        def invalid_exceptions_function():\n            pass"
            },
            "tests/test_retry_args.py::test_invalid_max_retries": {
                "testid": "tests/test_retry_args.py::test_invalid_max_retries",
                "result": "passed",
                "test_implementation": "def test_invalid_max_retries():\n    with pytest.raises(TypeError):\n        @retry(max_retries=\"not_an_integer\")\n        def invalid_max_retries_function():\n            pass"
            },
            "tests/test_retry_args.py::test_invalid_backoff": {
                "testid": "tests/test_retry_args.py::test_invalid_backoff",
                "result": "passed",
                "test_implementation": "def test_invalid_backoff():\n    with pytest.raises(TypeError):\n        @retry(backoff=\"not_a_backoff_instance\")\n        def invalid_backoff_function():\n            pass"
            },
            "tests/test_retry_args.py::test_invalid_timeout": {
                "testid": "tests/test_retry_args.py::test_invalid_timeout",
                "result": "passed",
                "test_implementation": "def test_invalid_timeout():\n    with pytest.raises(TypeError):\n        @retry(timeout=\"not_a_float\")\n        def invalid_timeout_function():\n            pass"
            },
            "tests/test_retry_args.py::test_invalid_deadline": {
                "testid": "tests/test_retry_args.py::test_invalid_deadline",
                "result": "passed",
                "test_implementation": "def test_invalid_deadline():\n    with pytest.raises(TypeError):\n        @retry(deadline=\"not_a_float\")\n        def invalid_deadline_function():\n            pass"
            },
            "tests/test_retry_args.py::test_invalid_logger": {
                "testid": "tests/test_retry_args.py::test_invalid_logger",
                "result": "passed",
                "test_implementation": "def test_invalid_logger():\n    with pytest.raises(TypeError):\n        @retry(logger=\"not_a_logger_instance\")\n        def invalid_logger_function():\n            pass"
            },
            "tests/test_retry_args.py::test_invalid_log_retry_traceback": {
                "testid": "tests/test_retry_args.py::test_invalid_log_retry_traceback",
                "result": "passed",
                "test_implementation": "def test_invalid_log_retry_traceback():\n    with pytest.raises(TypeError):\n        @retry(log_retry_traceback=\"not_a_boolean\")\n        def invalid_log_retry_traceback_function():\n            pass"
            },
            "tests/test_retry_args.py::test_invalid_failure_callback": {
                "testid": "tests/test_retry_args.py::test_invalid_failure_callback",
                "result": "passed",
                "test_implementation": "def test_invalid_failure_callback():\n    with pytest.raises(TypeError):\n        @retry(failure_callback=\"not_a_callable\")\n        def invalid_failure_callback_function():\n            pass"
            },
            "tests/test_retry_args.py::test_invalid_retry_callback": {
                "testid": "tests/test_retry_args.py::test_invalid_retry_callback",
                "result": "passed",
                "test_implementation": "def test_invalid_retry_callback():\n    with pytest.raises(TypeError):\n        @retry(retry_callback=\"not_a_callable\")\n        def invalid_retry_callback_function():\n            pass"
            },
            "tests/test_retry_args.py::test_invalid_successful_retry_callback": {
                "testid": "tests/test_retry_args.py::test_invalid_successful_retry_callback",
                "result": "passed",
                "test_implementation": "def test_invalid_successful_retry_callback():\n    with pytest.raises(TypeError):\n        @retry(successful_retry_callback=\"not_a_callable\")\n        def invalid_successful_retry_callback_function():\n            pass"
            },
            "tests/test_retry_args.py::test_invalid_reraise_exception": {
                "testid": "tests/test_retry_args.py::test_invalid_reraise_exception",
                "result": "passed",
                "test_implementation": "def test_invalid_reraise_exception():\n    with pytest.raises(TypeError):\n        @retry(reraise_exception=\"not_a_boolean\")\n        def invalid_reraise_exception_function():\n            pass"
            }
        },
        "SRS_document": "**Software Requirements Specification: Retry Library**\n\n**Table of Contents**\n1.  Introduction\n    1.1  Purpose\n    1.2  Scope\n    1.3  Definitions, Acronyms, and Abbreviations\n2.  Overall Description\n    2.1  Product Perspective\n    2.2  Product Functions\n    2.3  User Characteristics\n    2.4  Constraints\n    2.5  Assumptions and Dependencies\n3.  Specific Requirements\n    3.1  Functional Requirements\n        3.1.1  Core Retry Decorator (`@retry`)\n        3.1.2  Backoff Strategies\n        3.1.3  Callback Creation Utilities\n        3.1.4  Custom Exceptions\n        3.1.5  Argument Validation\n    3.2  Non-Functional Requirements\n    3.3  External Interface Requirements\n        3.3.1  Public API\n\n---\n\n**1. Introduction**\n\n**1.1 Purpose**\nThis Software Requirements Specification (SRS) document defines the functional and non-functional requirements for a Python library providing a generic retry decorator. The primary purpose of this SRS is to serve as a definitive guide for software developers who will be tasked with implementing this library. Their implementation will be assessed based on its adherence to these requirements, verified by a comprehensive suite of test cases (both public and private).\n\nThis document aims to be exceptionally clear, unambiguous, and functionally comprehensive, describing *what* the system must do rather than *how* it is implemented internally. This allows developers to make their own design and implementation choices while ensuring all specified functionalities are met.\n\n**1.2 Scope**\nThe software to be developed is a Python library offering a decorator (`@retry`) that enables functions to be automatically retried upon encountering specified exceptions. The library will support:\n*   Configurable exception types for retrying and exclusion.\n*   Limits on retries based on count, timeout, or deadline.\n*   Various backoff strategies (fixed, linear, exponential, random) to control delay between retries.\n*   Callbacks for different stages of the retry process (between retries, on final success, on final failure).\n*   Configurable logging for retry attempts.\n*   Optional re-raising of the original exception after all retries are exhausted.\n*   Utilities for creating and managing callback functions with pre-bound arguments.\n\nThe library is intended for use by Python developers in their applications to add resilience to operations that might fail intermittently.\n\n**1.3 Definitions, Acronyms, and Abbreviations**\n*   **SRS:** Software Requirements Specification\n*   **API:** Application Programming Interface\n*   **Decorator:** A Python design pattern that allows adding new functionality to an existing object (typically a function or method) without modifying its structure.\n*   **Backoff Strategy:** An algorithm used to determine the waiting time between retry attempts.\n*   **Jitter:** A small random variation added to backoff delays to prevent thundering herd problems.\n*   **Callback:** A function passed as an argument to another function, which is then invoked by the outer function at a specific point or upon a specific event.\n\n---\n\n**2. Overall Description**\n\n**2.1 Product Perspective**\nThe retry library is a self-contained Python module designed to be easily integrated into other Python projects. It acts as a utility that enhances function calls with robust retry capabilities. It has no external system dependencies beyond a standard Python environment (version 3.7 or higher).\n\n**2.2 Product Functions**\nThe key functions of the retry library are:\n1.  **Function Decoration:** Provide a decorator that wraps target functions to enable retry logic.\n2.  **Conditional Retrying:** Allow users to specify which exceptions should trigger a retry and which should be excluded.\n3.  **Retry Control:** Enable configuration of maximum retry attempts, overall timeout for retries, and an absolute deadline for completion.\n4.  **Delay Management:** Implement various backoff strategies (fixed, linear, exponential, random uniform) to manage the delay between retry attempts, including optional jitter.\n5.  **Event-Driven Callbacks:** Support execution of user-defined callback functions at various points: between retries, after a successful retry sequence, and after all retries have failed.\n6.  **Exception Handling:** Provide specific custom exceptions to indicate different retry failure reasons (e.g., max retries reached, timeout, deadline).\n7.  **Flexible Logging:** Allow integration with standard Python logging for monitoring retry behavior, with control over log verbosity (e.g., traceback logging).\n8.  **Callback Argument Binding:** Offer utilities to create callback functions with pre-bound arguments.\n9.  **Argument Validation:** Ensure that configuration parameters provided to the library are of the correct type and within valid ranges, raising errors for invalid inputs.\n\n**2.3 User Characteristics**\nThe primary users of this library are Python developers who need to build resilient applications that can gracefully handle transient failures in function calls (e.g., network requests, database operations). Users are expected to be familiar with Python programming concepts, including decorators, exceptions, and functions.\n\n**2.4 Constraints**\n*   The library must be compatible with Python 3.7 and newer versions.\n*   The library should be installable via `pip`.\n*   The core retry logic must be implemented as a Python decorator.\n\n**2.5 Assumptions and Dependencies**\n*   The system relies on the standard Python `time` module for time-related operations (sleep, measuring elapsed time).\n*   The system relies on the standard Python `logging` module for logging functionality.\n*   The system relies on the standard Python `functools` module for `wraps`.\n*   The system relies on the standard Python `random` module for jitter and random backoff.\n*   The system relies on the standard Python `inspect` module for callback argument binding.\n*   Developers using the library are responsible for providing valid callable functions and exception types.\n\n---\n\n**3. Specific Requirements**\n\n**3.1 Functional Requirements**\n\n**3.1.1 Core Retry Decorator (`@retry`)**\n\nThis section describes the functional behavior of the main `@retry` decorator.\n\n**3.1.1.1 Basic Operation**\n*   **FR-DEC-001:** The system shall provide a decorator named `retry` that, when applied to a function, modifies its behavior to automatically retry execution upon encountering specified exceptions.\n*   **FR-DEC-002:** If the decorated function executes successfully on any attempt (either the first or a subsequent retry), its result shall be returned to the caller.\n*   **FR-DEC-003:** The retry mechanism shall support retrying functions with positional (`*args`) and keyword (`**kwargs`) arguments, passing them transparently to the decorated function on each attempt.\n\n**3.1.1.2 Exception Filtering**\n*   **FR-DEC-EF-001:** The `retry` decorator shall accept an `exceptions` parameter, a tuple of exception types. The system shall trigger a retry only if the decorated function raises an exception that is an instance of one of these types (or their subtypes).\n*   **FR-DEC-EF-002:** If the `exceptions` parameter is not provided, the system shall default to retrying on any exception that is a subclass of Python's built-in `Exception`.\n*   **FR-DEC-EF-003:** The `retry` decorator shall accept an `excluded_exceptions` parameter, a tuple of exception types. If the decorated function raises an exception that is an instance of one of these types (or their subtypes), the system shall not retry and shall immediately propagate the raised exception, even if it also matches an exception in the `exceptions` parameter.\n*   **FR-DEC-EF-004:** If the `excluded_exceptions` parameter is not provided, the system shall default to an empty tuple (no exceptions explicitly excluded beyond standard Python behavior).\n*   **FR-DEC-EF-005:** The effective set of exceptions that trigger a retry shall be those in the `exceptions` list that are not also in the `excluded_exceptions` list.\n*   **FR-DEC-EF-006:** If the effective set of target exceptions (after considering `exceptions` and `excluded_exceptions`) is empty, the system shall default to retrying on any exception that is a subclass of Python's built-in `Exception`.\n\n**3.1.1.3 Retry Limiting**\n*   **FR-DEC-RL-001:** The `retry` decorator shall accept a `max_retries` integer parameter. If specified, the system shall attempt to execute the decorated function at most `max_retries` + 1 times (i.e., 1 initial attempt + `max_retries` retries).\n*   **FR-DEC-RL-002:** If `max_retries` is reached and the function has not succeeded, and `reraise_exception` (see FR-DEC-ER-001) is false, the system shall raise a `MaxRetriesException`.\n*   **FR-DEC-RL-003:** If `max_retries` is not provided or is `None`, the system shall retry indefinitely, subject to other limits like `timeout` or `deadline`.\n*   **FR-DEC-RL-004:** The `retry` decorator shall accept a `timeout` float parameter (seconds). The system shall measure the total elapsed time from the start of the first attempt. Before each subsequent retry attempt, if the elapsed time exceeds `timeout`, the system shall stop retrying.\n*   **FR-DEC-RL-005:** If a `timeout` is exceeded, and `reraise_exception` (see FR-DEC-ER-001) is false or no prior application exception occurred, the system shall raise a `RetriesTimeoutException`.\n*   **FR-DEC-RL-006:** The `retry` decorator shall accept a `deadline` float parameter (seconds). The system shall measure the total elapsed time from the start of the first attempt. After each attempt (initial or retry) of the decorated function completes (successfully or with an exception), if the elapsed time exceeds `deadline`, the system shall stop further retries.\n*   **FR-DEC-RL-007:** If a `deadline` is exceeded, and `reraise_exception` (see FR-DEC-ER-001) is false or no prior application exception occurred, the system shall raise a `RetriesDeadlineException`.\n*   **FR-DEC-RL-008:** If `RetriesTimeoutException` or `RetriesDeadlineException` is to be raised and the `reraise_exception` flag is true and an application exception (one that triggered a retry, not a retry-specific exception) had previously occurred, the system shall re-raise that last recorded application exception instead of the timeout/deadline exception.\n\n**3.1.1.4 Backoff Strategy Integration**\n*   **FR-DEC-BS-001:** The `retry` decorator shall accept a `backoff` parameter, which must be an instance of a Backoff strategy class (see section 3.1.2).\n*   **FR-DEC-BS-002:** Before each retry attempt (but not before the initial attempt), the system shall query the provided `backoff` object for a delay duration and shall pause execution for that duration.\n*   **FR-DEC-BS-003:** If the `backoff` parameter is not provided, the system shall default to using a `FixedBackOff` strategy with a `base_delay` of 0 seconds.\n*   **FR-DEC-BS-004:** The retry decorator shall use a deep copy of the provided backoff strategy instance to ensure that retry attempts for different calls to the decorated function, or concurrent calls, do not interfere with each other's backoff state.\n*   **FR-DEC-BS-005:** The backoff state (e.g., current delay round) for a given call to the decorated function shall be reset at the beginning of its retry sequence.\n\n**3.1.1.5 Callback Invocation**\n*   **FR-DEC-CB-001:** The `retry` decorator shall accept a `retry_callback` parameter, which can be a callable. If provided, this callback shall be invoked after an attempt fails and before the delay/next retry, but not after the final failed attempt if `max_retries` is reached or other limits exceeded.\n*   **FR-DEC-CB-002:** The `retry` decorator shall accept a `successful_retry_callback` parameter, which can be a callable. If provided, and the decorated function succeeds after one or more retries (i.e., not on the first attempt), this callback shall be invoked after the successful execution and before returning the result.\n*   **FR-DEC-CB-003:** The `successful_retry_callback` shall not be invoked if the decorated function succeeds on its first attempt.\n*   **FR-DEC-CB-004:** The `retry` decorator shall accept a `failure_callback` parameter, which can be a callable. If provided, and all retry attempts are exhausted (due to `max_retries`, `timeout`, or `deadline`) without success, this callback shall be invoked before raising the final retry-specific exception (e.g., `MaxRetriesException`).\n*   **FR-DEC-CB-005:** The `failure_callback` shall not be invoked if the system is re-raising the original application exception (see FR-DEC-ER-001).\n    *   **Revised FR-DEC-CB-005:** The `failure_callback`, if provided, shall be invoked when a retry-terminating condition (`max_retries`, `timeout`, or `deadline`) is met and the system determines that retries should cease, typically as part of constructing a retry-specific exception (e.g., `MaxRetriesException`).\n\n**3.1.1.6 Exception Re-raising**\n*   **FR-DEC-ER-001:** The `retry` decorator shall accept a `reraise_exception` boolean parameter (defaulting to `False`).\n*   **FR-DEC-ER-002:** If `reraise_exception` is `True` and all retry attempts are exhausted (due to `max_retries`, `timeout`, or `deadline`) and at least one application exception was caught, the system shall re-raise the last caught application exception instead of a retry-specific exception (e.g., `MaxRetriesException`).\n*   **FR-DEC-ER-003:** If `reraise_exception` is `False` (the default), and all retry attempts are exhausted, the system shall raise the appropriate retry-specific exception (`MaxRetriesException`, `RetriesTimeoutException`, or `RetriesDeadlineException`).\n\n**3.1.1.7 Logging**\n*   **FR-DEC-LOG-001:** The `retry` decorator shall accept a `logger` parameter, which can be a `logging.Logger` instance or `None`.\n*   **FR-DEC-LOG-002:** If a `logger` instance is provided, the system shall log information about retry attempts at the `WARNING` level.\n*   **FR-DEC-LOG-003:** If `logger` is `None` or not provided, the system shall use a default package-level logger (`retry_reloaded`). (Correction based on code: default is `retry_logger` from `_init_logger(__package__)`. If `logger` is passed as `None`, logging is skipped by `_log_retry`).\n    *   **Revised FR-DEC-LOG-003:** If the `logger` parameter is not explicitly set to `None` by the user, the system shall use a default package-level logger named \"retry_reloaded\". If `logger` is explicitly set to `None`, no logging for retry attempts shall occur.\n*   **FR-DEC-LOG-004:** The log message for a retry attempt shall include: the name of the function being retried, the delay until the next retry.\n*   **FR-DEC-LOG-005:** If `max_retries` is configured, the log message for a retry attempt shall include the number of remaining retries.\n*   **FR-DEC-LOG-006:** If `timeout` or `deadline` is configured, the log message for a retry attempt shall include the remaining time until the earliest of these limits is reached.\n*   **FR-DEC-LOG-007:** The `retry` decorator shall accept a `log_retry_traceback` boolean parameter (defaulting to `False`).\n*   **FR-DEC-LOG-008:** If `log_retry_traceback` is `True` and a logger is active, the system shall include the traceback of the exception that triggered the retry in the log message.\n*   **FR-DEC-LOG-009:** The default package logger (\"retry_reloaded\") shall be configured with a `StreamHandler`, log at `DEBUG` level, and use the format `\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"`. Propagation shall be disabled for this default logger.\n\n**3.1.2 Backoff Strategies**\n\nThese requirements apply to the backoff strategy classes provided by the library.\n\n**3.1.2.1 General Backoff Behavior (`BackOff` base class)**\n*   **FR-BO-GEN-001:** All backoff strategies shall provide a `delay` property that, when accessed, returns the calculated delay in seconds for the current retry round.\n*   **FR-BO-GEN-002:** Accessing the `delay` property shall advance the internal state of the backoff strategy to prepare for the next round's delay calculation.\n*   **FR-BO-GEN-003:** All backoff strategies shall accept a `base_delay` float parameter in their constructor, representing an initial or base delay value in seconds. This delay applies to the first calculation round.\n*   **FR-BO-GEN-004:** All backoff strategies (except `RandomUniformBackOff`) shall accept an optional `jitter` parameter in their constructor. `jitter` must be a tuple of two floats `(min_jitter, max_jitter)`.\n*   **FR-BO-GEN-005:** If `jitter` is provided, for retry rounds after the first, a random float value between `min_jitter` and `max_jitter` (inclusive) shall be added to the calculated delay. Jitter is not applied to the first calculated delay (i.e., when round is 0).\n*   **FR-BO-GEN-006:** All backoff strategies shall provide a `reset()` method that resets their internal state (e.g., round counter) so that the next call to `delay` calculates the delay for the first round.\n\n**3.1.2.2 Fixed Backoff (`FixedBackOff`)**\n*   **FR-BO-FIX-001:** The `FixedBackOff` strategy shall always return its configured `base_delay` as the delay duration, plus any applicable jitter (after the first round).\n\n**3.1.2.3 Linear Backoff (`LinearBackOff`)**\n*   **FR-BO-LIN-001:** The `LinearBackOff` strategy shall accept a `step` float parameter in its constructor.\n*   **FR-BO-LIN-002:** The delay for round `n` (0-indexed) shall be calculated as `base_delay + (step * n)`, plus any applicable jitter (after the first round, n > 0).\n*   **FR-BO-LIN-003:** The `LinearBackOff` strategy shall accept an optional `max` float parameter (maximum delay) in its constructor. If provided, the calculated delay shall not exceed this value.\n\n**3.1.2.4 Exponential Backoff (`ExponentialBackOff`)**\n*   **FR-BO-EXP-001:** The `ExponentialBackOff` strategy shall accept an optional `base` float parameter in its constructor (defaulting to 2.0), which is the base for the exponentiation.\n*   **FR-BO-EXP-002:** The delay for round `n` (0-indexed) shall be calculated as `base_delay * (base ** n)`, plus any applicable jitter (after the first round, n > 0).\n*   **FR-BO-EXP-003:** The `ExponentialBackOff` strategy shall accept an optional `max` float parameter (maximum delay) in its constructor. If provided, the calculated delay shall not exceed this value.\n\n**3.1.2.5 Random Uniform Backoff (`RandomUniformBackOff`)**\n*   **FR-BO-RND-001:** The `RandomUniformBackOff` strategy shall accept `min_delay` (float) and `max_delay` (float) parameters in its constructor.\n*   **FR-BO-RND-002:** For the first delay calculation (round 0), `RandomUniformBackOff` shall return its configured `base_delay`.\n*   **FR-BO-RND-003:** For subsequent delay calculations (round > 0), `RandomUniformBackOff` shall return a random float value between `min_delay` and `max_delay` (inclusive).\n\n**3.1.3 Callback Creation Utilities**\n\n**3.1.3.1 `CallbackFactory` Class**\n*   **FR-CBF-CF-001:** The system shall provide a class `CallbackFactory`. Its constructor shall accept a callable `func` and optionally, positional arguments (`*args`) and keyword arguments (`**kwargs`) to be pre-bound to `func`.\n*   **FR-CBF-CF-002:** Positional arguments provided to the `CallbackFactory` constructor shall be mapped to the names of the target function's parameters in the order they are defined.\n*   **FR-CBF-CF-003:** Instances of `CallbackFactory` shall be callable. When called, they shall execute the originally provided `func` with the pre-bound arguments.\n*   **FR-CBF-CF-004:** When a `CallbackFactory` instance is called, any keyword arguments provided at call time shall override corresponding pre-bound keyword arguments or add to them if not previously bound.\n\n**3.1.3.2 `callback_factory` Function**\n*   **FR-CBF-FUNC-001:** The system shall provide a function `callback_factory`. It shall accept a callable `func` and optionally, positional arguments (`*args`) and keyword arguments (`**kwargs`) to be pre-bound to `func`.\n*   **FR-CBF-FUNC-002:** Positional arguments provided to `callback_factory` shall be mapped to the names of the target function's parameters in the order they are defined.\n*   **FR-CBF-FUNC-003:** `callback_factory` shall return a new callable (wrapped function). When this returned callable is invoked, it shall execute the originally provided `func` with the pre-bound arguments.\n*   **FR-CBF-FUNC-004:** When the callable returned by `callback_factory` is invoked, any keyword arguments provided at call time shall override corresponding pre-bound keyword arguments or add to them if not previously bound.\n*   **FR-CBF-FUNC-005:** The callable returned by `callback_factory` shall preserve metadata (like `__name__`, `__doc__`) from the original `func`.\n\n**3.1.4 Custom Exceptions**\n*   **FR-EXC-001:** The system shall define and use a custom exception `MaxRetriesException` which inherits from a common `BaseRetryException`.\n*   **FR-EXC-002:** The system shall define and use a custom exception `RetriesTimeoutException` which inherits from `BaseRetryException`.\n*   **FR-EXC-003:** The system shall define and use a custom exception `RetriesDeadlineException` which inherits from `BaseRetryException`.\n*   **FR-EXC-004:** When a `BaseRetryException` (or its subclass) is initialized:\n    *   If a `logger` instance is provided to its constructor, an error message detailing the failure shall be logged via that logger.\n    *   If a `failure_callback` callable is provided to its constructor, that callback shall be invoked.\n*   **FR-EXC-005:** The `MaxRetriesException` message shall include the name of the function and the maximum number of retries that were attempted.\n*   **FR-EXC-006:** The `RetriesTimeoutException` message shall include the name of the function, the elapsed time, and the configured timeout value.\n*   **FR-EXC-007:** The `RetriesDeadlineException` message shall include the name of the function, the elapsed time, and the configured deadline value.\n\n**3.1.5 Argument Validation**\n\n**3.1.5.1 Retry Decorator Argument Validation**\nThese requirements stem from `_validate_args` and are tested in `tests/test_retry_args.py`.\n*   **FR-VAL-DEC-001:** The `exceptions` parameter for the `retry` decorator must be a tuple. If not, the system shall raise a `TypeError`.\n*   **FR-VAL-DEC-002:** All items in the `exceptions` tuple must be subclasses of `Exception`. If not, the system shall raise a `TypeError`.\n*   **FR-VAL-DEC-003:** The `excluded_exceptions` parameter for the `retry` decorator must be a tuple. (Implied by symmetry with `exceptions` and source code).\n*   **FR-VAL-DEC-004:** All items in the `excluded_exceptions` tuple must be subclasses of `Exception`. If not, the system shall raise a `TypeError`.\n*   **FR-VAL-DEC-005:** The `max_retries` parameter, if provided, must be an integer. If not, the system shall raise a `TypeError`.\n*   **FR-VAL-DEC-006:** The `backoff` parameter must be an instance of a `BackOff` subclass. If not, the system shall raise a `TypeError`.\n*   **FR-VAL-DEC-007:** The `timeout` parameter, if provided, must be a number (int or float). If not, the system shall raise a `TypeError`.\n*   **FR-VAL-DEC-008:** The `deadline` parameter, if provided, must be a number (int or float). If not, the system shall raise a `TypeError`.\n*   **FR-VAL-DEC-009:** The `logger` parameter, if provided, must be an instance of `logging.Logger`. If not, the system shall raise a `TypeError`.\n*   **FR-VAL-DEC-010:** The `log_retry_traceback` parameter must be a boolean. If not, the system shall raise a `TypeError`.\n*   **FR-VAL-DEC-011:** The `failure_callback` parameter, if provided, must be callable. If not, the system shall raise a `TypeError`.\n*   **FR-VAL-DEC-012:** The `retry_callback` parameter, if provided, must be callable. If not, the system shall raise a `TypeError`.\n*   **FR-VAL-DEC-013:** The `successful_retry_callback` parameter, if provided, must be callable. If not, the system shall raise a `TypeError`.\n*   **FR-VAL-DEC-014:** The `reraise_exception` parameter must be a boolean. If not, the system shall raise a `TypeError`.\n\n**3.1.5.2 Backoff Strategy Parameter Validation**\nThese requirements stem from validation methods in `retry_reloaded/backoff.py` and are tested in `tests/test_backoff.py`.\n*   **FR-VAL-BO-001:** The `base_delay` parameter for any backoff strategy constructor must be a non-negative number (int or float). If not a number, a `TypeError` shall be raised. If negative, a `ValueError` shall be raised.\n*   **FR-VAL-BO-002:** The `jitter` parameter for backoff strategy constructors (that support it), if provided, must be a tuple of two numbers `(min_val, max_val)`. If not a tuple or not length 2, a `TypeError` shall be raised. If `min_val` or `max_val` are not numbers, a `TypeError` shall be raised.\n*   **FR-VAL-BO-003:** For the `jitter` parameter, `min_val` and `max_val` must be non-negative. If not, a `ValueError` shall be raised.\n*   **FR-VAL-BO-004:** For the `jitter` parameter, `min_val` must be less than or equal to `max_val`. If `min_val > max_val`, a `ValueError` shall be raised.\n*   **FR-VAL-BO-005:** For `LinearBackOff`, the `step` parameter must be a non-negative number. If not a number, a `TypeError` shall be raised. If negative, a `ValueError` shall be raised.\n*   **FR-VAL-BO-006:** For backoff strategies supporting a `max` delay (e.g., `LinearBackOff`, `ExponentialBackOff`):\n    *   If `max` is provided, it must be a number. If not, a `TypeError` shall be raised.\n    *   `max` must be greater than or equal to the strategy's `base_delay`. If not, a `ValueError` shall be raised.\n\n**3.1.5.3 Callback Utilities Validation**\n*   **FR-VAL-CB-001:** The `func` argument provided to `CallbackFactory` constructor must be callable. If not, a `TypeError` shall be raised.\n*   **FR-VAL-CB-002:** The `func` argument provided to `callback_factory` function must be callable. If not, a `TypeError` shall be raised.\n\n**3.2 Non-Functional Requirements**\n*   **NFR-001:** The library shall be installable using standard Python packaging tools (pip).\n\n*(No other NFRs can be strictly derived from the provided test cases, as the tests primarily focus on functional correctness and input validation, not performance, security, specific usability aspects beyond error messages, or advanced reliability metrics.)*\n\n**3.3 External Interface Requirements**\n\n**3.3.1 Public API**\nThe library shall expose the following components as its public API, accessible directly from the `retry_reloaded` package:\n*   **FR-API-001:** Decorator: `retry`\n*   **FR-API-002:** Exceptions: `MaxRetriesException`, `RetriesTimeoutException`, `RetriesDeadlineException`\n*   **FR-API-003:** Callback Utilities: `CallbackFactory`, `callback_factory`\n*   **FR-API-004:** Backoff Strategies: `FixedBackOff`, `LinearBackOff`, `ExponentialBackOff`, `RandomUniformBackOff`\n\nAll other modules, classes, functions, or variables (e.g., those prefixed with an underscore like `_validate_args`, or internal modules like `_logging`, `_exceptions`, `_validate`) are considered internal implementation details and are not part of the guaranteed public API, unless explicitly listed above.\n\n---\n**End of Document**",
        "structured_requirements": [
            {
                "requirement_id": "FR-DEC-001",
                "requirement_description": "The system shall provide a decorator named `retry` that, when applied to a function, modifies its behavior to automatically retry execution upon encountering specified exceptions.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry.py::test_successful_execution",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-002",
                "requirement_description": "If the decorated function executes successfully on any attempt (either the first or a subsequent retry), its result shall be returned to the caller.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry.py::test_successful_execution",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry::wrapper",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-003",
                "requirement_description": "The retry mechanism shall support retrying functions with positional (`*args`) and keyword (`**kwargs`) arguments, passing them transparently to the decorated function on each attempt.",
                "test_traceability": [
                    {
                        "id": "Implicit in all retry tests.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry::wrapper",
                        "description": "(via `f(*args, **kwargs)`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-EF-001",
                "requirement_description": "The `retry` decorator shall accept an `exceptions` parameter, a tuple of exception types. The system shall trigger a retry only if the decorated function raises an exception that is an instance of one of these types (or their subtypes).",
                "test_traceability": [
                    {
                        "id": "tests/test_retry.py::test_successful_execution",
                        "description": "(implicitly uses default)"
                    },
                    {
                        "id": "examples.py::cause_max_retries_error",
                        "description": "(implicitly uses default)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry::wrapper",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-EF-002",
                "requirement_description": "If the `exceptions` parameter is not provided, the system shall default to retrying on any exception that is a subclass of Python's built-in `Exception`.",
                "test_traceability": [
                    {
                        "id": "examples.py::cause_deadline_error",
                        "description": "(implicitly uses default)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry",
                        "description": "(parameter default `exceptions=(Exception,)`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-EF-003",
                "requirement_description": "The `retry` decorator shall accept an `excluded_exceptions` parameter, a tuple of exception types. If the decorated function raises an exception that is an instance of one of these types (or their subtypes), the system shall not retry and shall immediately propagate the raised exception, even if it also matches an exception in the `exceptions` parameter.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry.py::test_no_retry_on_excluded_exception",
                        "description": ""
                    },
                    {
                        "id": "tests/test_retry.py::test_retry_on_mixed_exclusions",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry::wrapper",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-EF-004",
                "requirement_description": "If the `excluded_exceptions` parameter is not provided, the system shall default to an empty tuple (no exceptions explicitly excluded beyond standard Python behavior).",
                "test_traceability": [
                    {
                        "id": "None",
                        "description": "(default behavior)."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry",
                        "description": "(parameter default `excluded_exceptions=()`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-EF-005",
                "requirement_description": "The effective set of exceptions that trigger a retry shall be those in the `exceptions` list that are not also in the `excluded_exceptions` list.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry.py::test_retry_on_mixed_exclusions",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry",
                        "description": "(logic for `target_exceptions`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-EF-006",
                "requirement_description": "If the effective set of target exceptions (after considering `exceptions` and `excluded_exceptions`) is empty, the system shall default to retrying on any exception that is a subclass of Python's built-in `Exception`.",
                "test_traceability": [
                    {
                        "id": "None",
                        "description": "(Derived from source code analysis)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry",
                        "description": "(logic for `if not target_exceptions: target_exceptions = (Exception,)`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-RL-001",
                "requirement_description": "The `retry` decorator shall accept a `max_retries` integer parameter. If specified, the system shall attempt to execute the decorated function at most `max_retries` + 1 times (i.e., 1 initial attempt + `max_retries` retries).",
                "test_traceability": [
                    {
                        "id": "tests/test_retry.py::test_maximum_retries_reached",
                        "description": ""
                    },
                    {
                        "id": "tests/test_retry.py::test_successful_execution",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry::wrapper",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-RL-002",
                "requirement_description": "If `max_retries` is reached and the function has not succeeded, and `reraise_exception` (see FR-DEC-ER-001) is false, the system shall raise a `MaxRetriesException`.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry.py::test_maximum_retries_reached",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry::wrapper",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-RL-003",
                "requirement_description": "If `max_retries` is not provided or is `None`, the system shall retry indefinitely, subject to other limits like `timeout` or `deadline`.",
                "test_traceability": [
                    {
                        "id": "examples.py::successful_retry_with_callback",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry",
                        "description": "(parameter default `max_retries=None`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-RL-004",
                "requirement_description": "The `retry` decorator shall accept a `timeout` float parameter (seconds). The system shall measure the total elapsed time from the start of the first attempt. Before each subsequent retry attempt, if the elapsed time exceeds `timeout`, the system shall stop retrying.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry.py::test_timeout",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry::wrapper",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-RL-005",
                "requirement_description": "If a `timeout` is exceeded, and `reraise_exception` (see FR-DEC-ER-001) is false or no prior application exception occurred, the system shall raise a `RetriesTimeoutException`.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry.py::test_timeout",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry::wrapper",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-RL-006",
                "requirement_description": "The `retry` decorator shall accept a `deadline` float parameter (seconds). The system shall measure the total elapsed time from the start of the first attempt. After each attempt (initial or retry) of the decorated function completes (successfully or with an exception), if the elapsed time exceeds `deadline`, the system shall stop further retries.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry.py::test_deadline",
                        "description": ""
                    },
                    {
                        "id": "examples.py::cause_deadline_error_after_retries",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry::wrapper",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-RL-007",
                "requirement_description": "If a `deadline` is exceeded, and `reraise_exception` (see FR-DEC-ER-001) is false or no prior application exception occurred, the system shall raise a `RetriesDeadlineException`.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry.py::test_deadline",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry::wrapper",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-RL-008",
                "requirement_description": "If `RetriesTimeoutException` or `RetriesDeadlineException` is to be raised and the `reraise_exception` flag is true and an application exception (one that triggered a retry, not a retry-specific exception) had previously occurred, the system shall re-raise that last recorded application exception instead of the timeout/deadline exception.",
                "test_traceability": [
                    {
                        "id": "None (Derived from source code analysis of interaction). Requires a specific test scenario.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry::wrapper",
                        "description": "(handling of `RetriesTimeoutException`/`RetriesDeadlineException` with `reraise_exception` and `last_exception`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-BS-001",
                "requirement_description": "The `retry` decorator shall accept a `backoff` parameter, which must be an instance of a Backoff strategy class (see section 3.1.2).",
                "test_traceability": [
                    {
                        "id": "tests/test_retry.py::test_timeout",
                        "description": "(uses `FixedBackOff`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-BS-002",
                "requirement_description": "Before each retry attempt (but not before the initial attempt), the system shall query the provided `backoff` object for a delay duration and shall pause execution for that duration.",
                "test_traceability": [
                    {
                        "id": "Implicit in tests like `tests/test_retry.py::test_timeout` where backoff affects timing.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry::wrapper",
                        "description": "(call to `_backoff.delay` and `sleep(delay)`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-BS-003",
                "requirement_description": "If the `backoff` parameter is not provided, the system shall default to using a `FixedBackOff` strategy with a `base_delay` of 0 seconds.",
                "test_traceability": [
                    {
                        "id": "examples.py::cause_max_retries_error",
                        "description": "(implicitly uses default, leading to immediate retries)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry",
                        "description": "(parameter default `backoff=FixedBackOff(base_delay=0)`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-BS-004",
                "requirement_description": "The retry decorator shall use a deep copy of the provided backoff strategy instance to ensure that retry attempts for different calls to the decorated function, or concurrent calls, do not interfere with each other's backoff state.",
                "test_traceability": [
                    {
                        "id": "None",
                        "description": "(Derived from source code analysis, crucial for correct behavior but hard to test in isolation without specific concurrency tests)."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry",
                        "description": "(`_backoff = deepcopy(backoff)`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-BS-005",
                "requirement_description": "The backoff state (e.g., current delay round) for a given call to the decorated function shall be reset at the beginning of its retry sequence.",
                "test_traceability": [
                    {
                        "id": "Implicitly verified by backoff strategy tests like `tests/test_backoff.py::test_linear_backoff`",
                        "description": "(verifying `reset()`) and its correct usage in `retry`."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry",
                        "description": "(`_backoff.reset()`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-CB-001",
                "requirement_description": "The `retry` decorator shall accept a `retry_callback` parameter, which can be a callable. If provided, this callback shall be invoked after an attempt fails and before the delay/next retry, but not after the final failed attempt if `max_retries` is reached or other limits exceeded.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry.py::test_retry_callback_called",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry::wrapper",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-CB-002",
                "requirement_description": "The `retry` decorator shall accept a `successful_retry_callback` parameter, which can be a callable. If provided, and the decorated function succeeds after one or more retries (i.e., not on the first attempt), this callback shall be invoked after the successful execution and before returning the result.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry.py::test_successful_retry_callback_called",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry::wrapper",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-CB-003",
                "requirement_description": "The `successful_retry_callback` shall not be invoked if the decorated function succeeds on its first attempt.",
                "test_traceability": [
                    {
                        "id": "Assumed from \"after a successful retry\". An explicit test for first-attempt success would be good.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry::wrapper",
                        "description": "(condition `if retries > 0 and successful_retry_callback:`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-CB-004",
                "requirement_description": "The `retry` decorator shall accept a `failure_callback` parameter, which can be a callable. If provided, and all retry attempts are exhausted (due to `max_retries`, `timeout`, or `deadline`) without success, this callback shall be invoked before raising the final retry-specific exception (e.g., `MaxRetriesException`).",
                "test_traceability": [
                    {
                        "id": "tests/test_retry.py::test_failure_callback_called",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_exceptions.py::BaseRetryException::__init__",
                        "description": ""
                    },
                    {
                        "id": "MaxRetriesException",
                        "description": ""
                    },
                    {
                        "id": "RetriesTimeoutException",
                        "description": ""
                    },
                    {
                        "id": "RetriesDeadlineException",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-CB-005",
                "requirement_description": "The `failure_callback` shall not be invoked if the system is re-raising the original application exception (see FR-DEC-ER-001).\n    *   **Revised FR-DEC-CB-005:** The `failure_callback`, if provided, shall be invoked when a retry-terminating condition (`max_retries`, `timeout`, or `deadline`) is met and the system determines that retries should cease, typically as part of constructing a retry-specific exception (e.g., `MaxRetriesException`).",
                "test_traceability": [
                    {
                        "id": "tests/test_retry.py::test_failure_callback_called",
                        "description": "confirms it's called with `MaxRetriesException`. Test with `reraise_exception=True` and a failure callback would clarify."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_exceptions.py::BaseRetryException::__init__",
                        "description": "(called by `MaxRetriesException`, `RetriesTimeoutException`, `RetriesDeadlineException` constructors)"
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-ER-001",
                "requirement_description": "The `retry` decorator shall accept a `reraise_exception` boolean parameter (defaulting to `False`).",
                "test_traceability": [
                    {
                        "id": "tests/test_retry.py::test_reraise_exception_true",
                        "description": ""
                    },
                    {
                        "id": "tests/test_retry.py::test_reraise_exception_false",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry",
                        "description": "(parameter default `reraise_exception=False`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-ER-002",
                "requirement_description": "If `reraise_exception` is `True` and all retry attempts are exhausted (due to `max_retries`, `timeout`, or `deadline`) and at least one application exception was caught, the system shall re-raise the last caught application exception instead of a retry-specific exception (e.g., `MaxRetriesException`).",
                "test_traceability": [
                    {
                        "id": "tests/test_retry.py::test_reraise_exception_true",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry::wrapper",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-ER-003",
                "requirement_description": "If `reraise_exception` is `False` (the default), and all retry attempts are exhausted, the system shall raise the appropriate retry-specific exception (`MaxRetriesException`, `RetriesTimeoutException`, or `RetriesDeadlineException`).",
                "test_traceability": [
                    {
                        "id": "tests/test_retry.py::test_reraise_exception_false",
                        "description": ""
                    },
                    {
                        "id": "tests/test_retry.py::test_maximum_retries_reached",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry::wrapper",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-LOG-001",
                "requirement_description": "The `retry` decorator shall accept a `logger` parameter, which can be a `logging.Logger` instance or `None`.",
                "test_traceability": [
                    {
                        "id": "Implicit in examples, `test_invalid_logger` for type.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-LOG-002",
                "requirement_description": "If a `logger` instance is provided, the system shall log information about retry attempts at the `WARNING` level.",
                "test_traceability": [
                    {
                        "id": "README example output, `examples.py` usage.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_logging.py::_log_retry",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-LOG-003",
                "requirement_description": "If `logger` is `None` or not provided, the system shall use a default package-level logger (`retry_reloaded`). (Correction based on code: default is `retry_logger` from `_init_logger(__package__)`. If `logger` is passed as `None`, logging is skipped by `_log_retry`).\n    *   **Revised FR-DEC-LOG-003:** If the `logger` parameter is not explicitly set to `None` by the user, the system shall use a default package-level logger named \"retry_reloaded\". If `logger` is explicitly set to `None`, no logging for retry attempts shall occur.",
                "test_traceability": [
                    {
                        "id": "Examples show default logger.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry",
                        "description": "(parameter default `logger=retry_logger`)"
                    },
                    {
                        "id": "retry_reloaded/_logging.py::_log_retry",
                        "description": "( `if not logger: return`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-LOG-004",
                "requirement_description": "The log message for a retry attempt shall include: the name of the function being retried, the delay until the next retry.",
                "test_traceability": [
                    {
                        "id": "README example output.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_logging.py::_log_retry",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-LOG-005",
                "requirement_description": "If `max_retries` is configured, the log message for a retry attempt shall include the number of remaining retries.",
                "test_traceability": [
                    {
                        "id": "README example output.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_logging.py::_log_retry",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-LOG-006",
                "requirement_description": "If `timeout` or `deadline` is configured, the log message for a retry attempt shall include the remaining time until the earliest of these limits is reached.",
                "test_traceability": [
                    {
                        "id": "README example output.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_logging.py::_log_retry",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-LOG-007",
                "requirement_description": "The `retry` decorator shall accept a `log_retry_traceback` boolean parameter (defaulting to `False`).",
                "test_traceability": [
                    {
                        "id": "tests/test_retry_args.py::test_invalid_log_retry_traceback for type.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-LOG-008",
                "requirement_description": "If `log_retry_traceback` is `True` and a logger is active, the system shall include the traceback of the exception that triggered the retry in the log message.",
                "test_traceability": [
                    {
                        "id": "None",
                        "description": "(functional test needed)."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/retry.py::retry::wrapper",
                        "description": "(`exc_info = original_exc if log_retry_traceback else None`)"
                    },
                    {
                        "id": "retry_reloaded/_logging.py::_log_retry",
                        "description": "(`logger.warning(\"...\", exc_info=exc_info)`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-DEC-LOG-009",
                "requirement_description": "The default package logger (\"retry_reloaded\") shall be configured with a `StreamHandler`, log at `DEBUG` level, and use the format `\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"`. Propagation shall be disabled for this default logger.",
                "test_traceability": [
                    {
                        "id": "None",
                        "description": "(Derived from source code analysis of logger setup)."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_logging.py::_init_logger",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BO-GEN-001",
                "requirement_description": "All backoff strategies shall provide a `delay` property that, when accessed, returns the calculated delay in seconds for the current retry round.",
                "test_traceability": [
                    {
                        "id": "tests/test_backoff.py",
                        "description": "(all tests access `.delay`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/backoff.py::BackOff::delay",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BO-GEN-002",
                "requirement_description": "Accessing the `delay` property shall advance the internal state of the backoff strategy to prepare for the next round's delay calculation.",
                "test_traceability": [
                    {
                        "id": "tests/test_backoff.py",
                        "description": "(e.g., `test_linear_backoff` checks increasing delays)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/backoff.py::BackOff::_calculate_next_delay",
                        "description": "(implemented by subclasses, updates `_round`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-BO-GEN-003",
                "requirement_description": "All backoff strategies shall accept a `base_delay` float parameter in their constructor, representing an initial or base delay value in seconds. This delay applies to the first calculation round.",
                "test_traceability": [
                    {
                        "id": "tests/test_backoff.py",
                        "description": "(all strategy tests use `base_delay`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/backoff.py::BackOff::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BO-GEN-004",
                "requirement_description": "All backoff strategies (except `RandomUniformBackOff`) shall accept an optional `jitter` parameter in their constructor. `jitter` must be a tuple of two floats `(min_jitter, max_jitter)`.",
                "test_traceability": [
                    {
                        "id": "tests/test_backoff.py::test_fixed_backoff",
                        "description": ""
                    },
                    {
                        "id": "test_linear_backoff",
                        "description": ""
                    },
                    {
                        "id": "test_exponential_backoff",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/backoff.py::BackOff::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BO-GEN-005",
                "requirement_description": "If `jitter` is provided, for retry rounds after the first, a random float value between `min_jitter` and `max_jitter` (inclusive) shall be added to the calculated delay. Jitter is not applied to the first calculated delay (i.e., when round is 0).",
                "test_traceability": [
                    {
                        "id": "tests/test_backoff.py::test_fixed_backoff",
                        "description": ""
                    },
                    {
                        "id": "test_linear_backoff",
                        "description": ""
                    },
                    {
                        "id": "test_exponential_backoff",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/backoff.py::FixedBackOff::_calculate_next_delay",
                        "description": ""
                    },
                    {
                        "id": "LinearBackOff::_calculate_next_delay",
                        "description": ""
                    },
                    {
                        "id": "ExponentialBackOff::_calculate_next_delay",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BO-GEN-006",
                "requirement_description": "All backoff strategies shall provide a `reset()` method that resets their internal state (e.g., round counter) so that the next call to `delay` calculates the delay for the first round.",
                "test_traceability": [
                    {
                        "id": "tests/test_backoff.py::test_linear_backoff",
                        "description": ""
                    },
                    {
                        "id": "tests/test_backoff.py::test_exponential_backoff",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/backoff.py::BackOff::reset",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BO-FIX-001",
                "requirement_description": "The `FixedBackOff` strategy shall always return its configured `base_delay` as the delay duration, plus any applicable jitter (after the first round).",
                "test_traceability": [
                    {
                        "id": "tests/test_backoff.py::test_fixed_backoff",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/backoff.py::FixedBackOff::_calculate_next_delay",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BO-LIN-001",
                "requirement_description": "The `LinearBackOff` strategy shall accept a `step` float parameter in its constructor.",
                "test_traceability": [
                    {
                        "id": "tests/test_backoff.py::test_linear_backoff",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/backoff.py::LinearBackOff::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BO-LIN-002",
                "requirement_description": "The delay for round `n` (0-indexed) shall be calculated as `base_delay + (step * n)`, plus any applicable jitter (after the first round, n > 0).",
                "test_traceability": [
                    {
                        "id": "tests/test_backoff.py::test_linear_backoff",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/backoff.py::LinearBackOff::_calculate_next_delay",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BO-LIN-003",
                "requirement_description": "The `LinearBackOff` strategy shall accept an optional `max` float parameter (maximum delay) in its constructor. If provided, the calculated delay shall not exceed this value.",
                "test_traceability": [
                    {
                        "id": "tests/test_backoff.py::test_linear_backoff",
                        "description": "(cases with `max_delay`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/backoff.py::LinearBackOff::_calculate_next_delay",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BO-EXP-001",
                "requirement_description": "The `ExponentialBackOff` strategy shall accept an optional `base` float parameter in its constructor (defaulting to 2.0), which is the base for the exponentiation.",
                "test_traceability": [
                    {
                        "id": "tests/test_backoff.py::test_exponential_backoff",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/backoff.py::ExponentialBackOff::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BO-EXP-002",
                "requirement_description": "The delay for round `n` (0-indexed) shall be calculated as `base_delay * (base ** n)`, plus any applicable jitter (after the first round, n > 0).",
                "test_traceability": [
                    {
                        "id": "tests/test_backoff.py::test_exponential_backoff",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/backoff.py::ExponentialBackOff::_calculate_next_delay",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BO-EXP-003",
                "requirement_description": "The `ExponentialBackOff` strategy shall accept an optional `max` float parameter (maximum delay) in its constructor. If provided, the calculated delay shall not exceed this value.",
                "test_traceability": [
                    {
                        "id": "tests/test_backoff.py::test_exponential_backoff",
                        "description": "(cases with `max_delay`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/backoff.py::ExponentialBackOff::_calculate_next_delay",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BO-RND-001",
                "requirement_description": "The `RandomUniformBackOff` strategy shall accept `min_delay` (float) and `max_delay` (float) parameters in its constructor.",
                "test_traceability": [
                    {
                        "id": "tests/test_backoff.py::test_random_uniform_backoff",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/backoff.py::RandomUniformBackOff::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BO-RND-002",
                "requirement_description": "For the first delay calculation (round 0), `RandomUniformBackOff` shall return its configured `base_delay`.",
                "test_traceability": [
                    {
                        "id": "tests/test_backoff.py::test_random_uniform_backoff",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/backoff.py::RandomUniformBackOff::_calculate_next_delay",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-BO-RND-003",
                "requirement_description": "For subsequent delay calculations (round > 0), `RandomUniformBackOff` shall return a random float value between `min_delay` and `max_delay` (inclusive).",
                "test_traceability": [
                    {
                        "id": "tests/test_backoff.py::test_random_uniform_backoff",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/backoff.py::RandomUniformBackOff::_calculate_next_delay",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CBF-CF-001",
                "requirement_description": "The system shall provide a class `CallbackFactory`. Its constructor shall accept a callable `func` and optionally, positional arguments (`*args`) and keyword arguments (`**kwargs`) to be pre-bound to `func`.",
                "test_traceability": [
                    {
                        "id": "tests/test_callback.py::test_CallbackFactory_callable_function",
                        "description": ""
                    },
                    {
                        "id": "tests/test_callback.py::test_CallbackFactory_arguments_passing",
                        "description": ""
                    },
                    {
                        "id": "tests/test_callback.py::test_CallbackFactory_keyword_arguments_passing",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/callback.py::CallbackFactory::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CBF-CF-002",
                "requirement_description": "Positional arguments provided to the `CallbackFactory` constructor shall be mapped to the names of the target function's parameters in the order they are defined.",
                "test_traceability": [
                    {
                        "id": "tests/test_callback.py::test_CallbackFactory_arguments_passing",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/callback.py::CallbackFactory::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CBF-CF-003",
                "requirement_description": "Instances of `CallbackFactory` shall be callable. When called, they shall execute the originally provided `func` with the pre-bound arguments.",
                "test_traceability": [
                    {
                        "id": "tests/test_callback.py::test_CallbackFactory_arguments_passing",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/callback.py::CallbackFactory::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CBF-CF-004",
                "requirement_description": "When a `CallbackFactory` instance is called, any keyword arguments provided at call time shall override corresponding pre-bound keyword arguments or add to them if not previously bound.",
                "test_traceability": [
                    {
                        "id": "tests/test_callback.py::test_CallbackFactory_arguments_override",
                        "description": ""
                    },
                    {
                        "id": "tests/test_callback.py::test_CallbackFactory_partial_arguments_override",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/callback.py::CallbackFactory::__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CBF-FUNC-001",
                "requirement_description": "The system shall provide a function `callback_factory`. It shall accept a callable `func` and optionally, positional arguments (`*args`) and keyword arguments (`**kwargs`) to be pre-bound to `func`.",
                "test_traceability": [
                    {
                        "id": "tests/test_callback.py::test_callback_factory_callable_function",
                        "description": ""
                    },
                    {
                        "id": "tests/test_callback.py::test_callback_factory_arguments_passing",
                        "description": ""
                    },
                    {
                        "id": "tests/test_callback.py::test_callback_factory_keyword_arguments_passing",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/callback.py::callback_factory",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CBF-FUNC-002",
                "requirement_description": "Positional arguments provided to `callback_factory` shall be mapped to the names of the target function's parameters in the order they are defined.",
                "test_traceability": [
                    {
                        "id": "tests/test_callback.py::test_callback_factory_arguments_passing",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/callback.py::callback_factory",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CBF-FUNC-003",
                "requirement_description": "`callback_factory` shall return a new callable (wrapped function). When this returned callable is invoked, it shall execute the originally provided `func` with the pre-bound arguments.",
                "test_traceability": [
                    {
                        "id": "tests/test_callback.py::test_callback_factory_arguments_passing",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/callback.py::callback_factory::wrapped_func",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CBF-FUNC-004",
                "requirement_description": "When the callable returned by `callback_factory` is invoked, any keyword arguments provided at call time shall override corresponding pre-bound keyword arguments or add to them if not previously bound.",
                "test_traceability": [
                    {
                        "id": "tests/test_callback.py::test_callback_factory_arguments_override",
                        "description": ""
                    },
                    {
                        "id": "tests/test_callback.py::test_callback_factory_partial_arguments_override",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/callback.py::callback_factory::wrapped_func",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CBF-FUNC-005",
                "requirement_description": "The callable returned by `callback_factory` shall preserve metadata (like `__name__`, `__doc__`) from the original `func`.",
                "test_traceability": [
                    {
                        "id": "None",
                        "description": "(Standard @wraps behavior, visual inspection of code)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/callback.py::callback_factory",
                        "description": "(due to `@wraps(func)`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-EXC-001",
                "requirement_description": "The system shall define and use a custom exception `MaxRetriesException` which inherits from a common `BaseRetryException`.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry.py::test_maximum_retries_reached",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_exceptions.py::MaxRetriesException",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXC-002",
                "requirement_description": "The system shall define and use a custom exception `RetriesTimeoutException` which inherits from `BaseRetryException`.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry.py::test_timeout",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_exceptions.py::RetriesTimeoutException",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXC-003",
                "requirement_description": "The system shall define and use a custom exception `RetriesDeadlineException` which inherits from `BaseRetryException`.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry.py::test_deadline",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_exceptions.py::RetriesDeadlineException",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXC-004",
                "requirement_description": "When a `BaseRetryException` (or its subclass) is initialized:\n    *   If a `logger` instance is provided to its constructor, an error message detailing the failure shall be logged via that logger.\n    *   If a `failure_callback` callable is provided to its constructor, that callback shall be invoked.",
                "test_traceability": [
                    {
                        "id": "Implicitly by `test_failure_callback_called` and logging observed in examples.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_exceptions.py::BaseRetryException::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXC-005",
                "requirement_description": "The `MaxRetriesException` message shall include the name of the function and the maximum number of retries that were attempted.",
                "test_traceability": [
                    {
                        "id": "Based on message template and `tests/test_retry.py::test_maximum_retries_reached`.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_exceptions.py::MAX_RETRIES_MESSAGE_TEMPLATE",
                        "description": ""
                    },
                    {
                        "id": "MaxRetriesException",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXC-006",
                "requirement_description": "The `RetriesTimeoutException` message shall include the name of the function, the elapsed time, and the configured timeout value.",
                "test_traceability": [
                    {
                        "id": "Based on message template and `tests/test_retry.py::test_timeout`.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_exceptions.py::TIMEOUT_MESSAGE_TEMPLATE",
                        "description": ""
                    },
                    {
                        "id": "RetriesTimeoutException",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-EXC-007",
                "requirement_description": "The `RetriesDeadlineException` message shall include the name of the function, the elapsed time, and the configured deadline value.",
                "test_traceability": [
                    {
                        "id": "Based on message template and `tests/test_retry.py::test_deadline`.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_exceptions.py::DEADLINE_MESSAGE_TEMPLATE",
                        "description": ""
                    },
                    {
                        "id": "RetriesDeadlineException",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-VAL-DEC-001",
                "requirement_description": "The `exceptions` parameter for the `retry` decorator must be a tuple. If not, the system shall raise a `TypeError`.",
                "test_traceability": [
                    {
                        "id": "None directly for tuple type, but related to `test_invalid_exceptions`. Assumed from source.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_validate.py::_validate_args",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-VAL-DEC-002",
                "requirement_description": "All items in the `exceptions` tuple must be subclasses of `Exception`. If not, the system shall raise a `TypeError`.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry_args.py::test_invalid_exceptions",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_validate.py::_validate_args",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-VAL-DEC-003",
                "requirement_description": "The `excluded_exceptions` parameter for the `retry` decorator must be a tuple. (Implied by symmetry with `exceptions` and source code).",
                "test_traceability": [
                    {
                        "id": "None directly for tuple type, but related to `test_invalid_excluded_exceptions`. Assumed from source.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_validate.py::_validate_args",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-VAL-DEC-004",
                "requirement_description": "All items in the `excluded_exceptions` tuple must be subclasses of `Exception`. If not, the system shall raise a `TypeError`.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry_args.py::test_invalid_excluded_exceptions",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_validate.py::_validate_args",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-VAL-DEC-005",
                "requirement_description": "The `max_retries` parameter, if provided, must be an integer. If not, the system shall raise a `TypeError`.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry_args.py::test_invalid_max_retries",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_validate.py::_validate_args",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-VAL-DEC-006",
                "requirement_description": "The `backoff` parameter must be an instance of a `BackOff` subclass. If not, the system shall raise a `TypeError`.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry_args.py::test_invalid_backoff",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_validate.py::_validate_args",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-VAL-DEC-007",
                "requirement_description": "The `timeout` parameter, if provided, must be a number (int or float). If not, the system shall raise a `TypeError`.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry_args.py::test_invalid_timeout",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_validate.py::_validate_args",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-VAL-DEC-008",
                "requirement_description": "The `deadline` parameter, if provided, must be a number (int or float). If not, the system shall raise a `TypeError`.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry_args.py::test_invalid_deadline",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_validate.py::_validate_args",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-VAL-DEC-009",
                "requirement_description": "The `logger` parameter, if provided, must be an instance of `logging.Logger`. If not, the system shall raise a `TypeError`.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry_args.py::test_invalid_logger",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_validate.py::_validate_args",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-VAL-DEC-010",
                "requirement_description": "The `log_retry_traceback` parameter must be a boolean. If not, the system shall raise a `TypeError`.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry_args.py::test_invalid_log_retry_traceback",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_validate.py::_validate_args",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-VAL-DEC-011",
                "requirement_description": "The `failure_callback` parameter, if provided, must be callable. If not, the system shall raise a `TypeError`.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry_args.py::test_invalid_failure_callback",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_validate.py::_validate_args",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-VAL-DEC-012",
                "requirement_description": "The `retry_callback` parameter, if provided, must be callable. If not, the system shall raise a `TypeError`.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry_args.py::test_invalid_retry_callback",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_validate.py::_validate_args",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-VAL-DEC-013",
                "requirement_description": "The `successful_retry_callback` parameter, if provided, must be callable. If not, the system shall raise a `TypeError`.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry_args.py::test_invalid_successful_retry_callback",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_validate.py::_validate_args",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-VAL-DEC-014",
                "requirement_description": "The `reraise_exception` parameter must be a boolean. If not, the system shall raise a `TypeError`.",
                "test_traceability": [
                    {
                        "id": "tests/test_retry_args.py::test_invalid_reraise_exception",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/_validate.py::_validate_args",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-VAL-BO-001",
                "requirement_description": "The `base_delay` parameter for any backoff strategy constructor must be a non-negative number (int or float). If not a number, a `TypeError` shall be raised. If negative, a `ValueError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "tests/test_backoff.py::test_backoff_invalid_base_delay",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/backoff.py::BackOff::_validate_base_delay",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-VAL-BO-002",
                "requirement_description": "The `jitter` parameter for backoff strategy constructors (that support it), if provided, must be a tuple of two numbers `(min_val, max_val)`. If not a tuple or not length 2, a `TypeError` shall be raised. If `min_val` or `max_val` are not numbers, a `TypeError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "tests/test_backoff.py::test_fixed_backoff_invalid_jitter",
                        "description": ""
                    },
                    {
                        "id": "test_linear_backoff_invalid_jitter",
                        "description": ""
                    },
                    {
                        "id": "test_exponential_backoff_invalid_jitter",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/backoff.py::BackOff::_validate_jitter",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-VAL-BO-003",
                "requirement_description": "For the `jitter` parameter, `min_val` and `max_val` must be non-negative. If not, a `ValueError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "tests/test_backoff.py::test_fixed_backoff_invalid_jitter",
                        "description": "(etc. - though current tests primarily focus on type and order)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/backoff.py::BackOff::_validate_jitter",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-VAL-BO-004",
                "requirement_description": "For the `jitter` parameter, `min_val` must be less than or equal to `max_val`. If `min_val > max_val`, a `ValueError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "tests/test_backoff.py::test_fixed_backoff_invalid_jitter",
                        "description": "(e.g., `(0.5, 0.1)`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/backoff.py::BackOff::_validate_jitter",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-VAL-BO-005",
                "requirement_description": "For `LinearBackOff`, the `step` parameter must be a non-negative number. If not a number, a `TypeError` shall be raised. If negative, a `ValueError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "Implicitly tested by providing valid steps. Specific invalid step tests could be added.",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/backoff.py::BackOff::_validate_step",
                        "description": "(used by `LinearBackOff`)"
                    }
                ]
            },
            {
                "requirement_id": "FR-VAL-BO-006",
                "requirement_description": "For backoff strategies supporting a `max` delay (e.g., `LinearBackOff`, `ExponentialBackOff`):\n    *   If `max` is provided, it must be a number. If not, a `TypeError` shall be raised.\n    *   `max` must be greater than or equal to the strategy's `base_delay`. If not, a `ValueError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "Specific invalid max tests could be added (e.g., max < base_delay).",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/backoff.py::BackOff::_validate_max",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-VAL-CB-001",
                "requirement_description": "The `func` argument provided to `CallbackFactory` constructor must be callable. If not, a `TypeError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "tests/test_callback.py::test_CallbackFactory_non_callable_function",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/callback.py::CallbackFactory::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-VAL-CB-002",
                "requirement_description": "The `func` argument provided to `callback_factory` function must be callable. If not, a `TypeError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "tests/test_callback.py::test_callback_factory_non_callable_function",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/callback.py::callback_factory",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "NFR-001",
                "requirement_description": "The library shall be installable using standard Python packaging tools (pip).",
                "test_traceability": [
                    {
                        "id": "setup.py implies this; typically verified by CI/CD or manual installation test, not a unit test. The presence of setup.py is the closest \"test\".",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "setup.py",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-API-001",
                "requirement_description": "Decorator: `retry`",
                "test_traceability": [
                    {
                        "id": "examples.py (import and usage), retry_reloaded/__init__.py",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/__init__.py",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-API-002",
                "requirement_description": "Exceptions: `MaxRetriesException`, `RetriesTimeoutException`, `RetriesDeadlineException`",
                "test_traceability": [
                    {
                        "id": "examples.py (import and usage), retry_reloaded/__init__.py",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/__init__.py",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-API-003",
                "requirement_description": "Callback Utilities: `CallbackFactory`, `callback_factory`",
                "test_traceability": [
                    {
                        "id": "examples.py (import and usage), retry_reloaded/__init__.py",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/__init__.py",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-API-004",
                "requirement_description": "Backoff Strategies: `FixedBackOff`, `LinearBackOff`, `ExponentialBackOff`, `RandomUniformBackOff`",
                "test_traceability": [
                    {
                        "id": "examples.py (import and usage), retry_reloaded/__init__.py",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "retry_reloaded/__init__.py",
                        "description": ""
                    }
                ]
            }
        ],
        "commit_sha": "fb78c863d3adc1607b8683fc3b3cc0d4c79a1879",
        "full_code_skeleton": "--- File: retry_reloaded/_validate.py ---\n```python\ndef _validate_args(\n    exceptions: Tuple[Type[Exception], ...],\n    excluded_exceptions: Tuple[Type[Exception], ...],\n    max_retries: Optional[int],\n    backoff: BackOff,\n    timeout: Optional[float],\n    deadline: Optional[float],\n    logger: Optional[logging.Logger],\n    log_retry_traceback: bool,\n    failure_callback: Optional[Callable[[], None]],\n    retry_callback: Optional[Callable[[], None]],\n    successful_retry_callback: Optional[Callable[[], None]],\n    reraise_exception: bool\n) -> None:\n    \"\"\"\n    Validate arguments for retry logic.\n\n    Args:\n        exceptions (Tuple[Type[Exception], ...]): Tuple of exception types to catch.\n        excluded_exceptions (Tuple[Type[Exception]], ...): Tuple of exception types not to catch.\n        max_retries (Optional[int]): Maximum number of retries allowed, or None for unlimited retries.\n        backoff (BackOff): BackOff instance to manage retry delays.\n        timeout (Optional[float]): Timeout value for the retry operation in seconds, or None if no timeout.\n        deadline (Optional[float]): Deadline for the retry operation in seconds, or None if no deadline.\n        logger (Optional[logging.Logger]): Logger instance for logging retry information, or None if logging is disabled.\n        log_retry_traceback (bool): Flag to indicate if the traceback should be logged on each retry.\n        failure_callback (Optional[Callable[[], None]]): Callback function to execute upon a failed retry, or None.\n        retry_callback (Optional[Callable[[], None]]): Callback function to execute before each retry attempt, or None.\n        successful_retry_callback (Optional[Callable[[], None]]): Callback function to execute upon a successful retry,\n          or None.\n        reraise_exception (bool): Whether to re-raise the last exception caught in case of failure after retries.\n\n    Raises:\n        TypeError: If any of the arguments do not meet the expected types.\n    \"\"\"\n    pass\n```\n--- File: retry_reloaded/callback.py ---\n```python\nclass CallbackFactory():\n    def __init__(self, func: Callable, *args, **kwargs):\n        \"\"\"\n        Initialize the CallbackFactory.\n\n        Parameters:\n            func (Callable): The callable function to be wrapped.\n            *args: Positional arguments to be passed to the function.\n            **kwargs: Keyword arguments to be passed to the function.\n\n        Raises:\n            TypeError: If `func` is not a callable object.\n        \"\"\"\n        pass\n\n    def __call__(self, **override_kwargs):\n        \"\"\"\n        Call the wrapped function with provided keyword arguments.\n        If no arguments are provided during calling,\n        then the stored ones (during instance creation) are used.\n\n        Returns:\n            The result of calling the wrapped function with provided arguments.\n        \"\"\"\n        pass\n\n\ndef callback_factory(func: Callable, *args, **kwargs):\n    \"\"\"\n    Create a callback function that wraps the provided callable function.\n\n    Parameters:\n        func (Callable): The callable function to be wrapped.\n        *args: Positional arguments to be passed to the function.\n        **kwargs: Keyword arguments to be passed to the function.\n\n    Returns:\n        A wrapped function that calls the provided\n        callable function with the specified arguments.\n\n    Raises:\n        TypeError: If `func` is not a callable object.\n    \"\"\"\n    pass\n```\n--- File: retry_reloaded/retry.py ---\n```python\ndef retry(\n    exceptions: Tuple[Type[Exception]] = (Exception,),\n    excluded_exceptions: Tuple[Type[Exception]] = (),\n    max_retries: Union[int, None] = None,\n    backoff: BackOff = FixedBackOff(base_delay=0),\n    timeout: Union[float, None] = None,\n    deadline: Union[float, None] = None,\n    logger: Union[logging.Logger, None] = retry_logger,\n    log_retry_traceback: bool = False,\n    failure_callback: Union[Callable, None] = None,\n    retry_callback: Union[Callable, None] = None,\n    successful_retry_callback: Union[Callable, None] = None,\n    reraise_exception: bool = False\n) -> Callable:\n    \"\"\"\n    Decorator that adds retry functionality to a function.\n\n    Parameters:\n        exceptions (Tuple[Type[Exception]], optional): A tuple of exception types that should trigger a retry.\n            Defaults to (Exception,), meaning any exception will trigger a retry.\n        excluded_exceptions (Tuple[Type[Exception]], optional): A tuple of exception types that should not trigger\n            a retry. Defaults to an empty tuple.\n        max_retries (int, optional): The maximum number of retry attempts. Defaults to None (unlimited retries).\n        backoff (BackOff, optional): The backoff strategy to use between retry attempts.\n            Defaults to FixedBackOff(base_delay=0) with base_delay referring to seconds.\n        timeout (float, optional): The maximum time (in seconds) to spend on retries. Defaults to None (no timeout).\n            Timeout check happens right before retry execution of the wrapped function.\n        deadline (float, optional): The deadline (in seconds) for retries. Defaults to None (no deadline).\n            Deadline check happens right after the retry execution of the wrapped function.\n        logger (logging.Logger, optional): The logger instance to use for logging retry attempts. Defaults to retry_logger.\n        log_retry_traceback (bool, optional): Whether to log the traceback of exceptions triggering retries.\n            Defaults to False.\n        failure_callback (Callable, optional): A callback function to call in case of eventual failure after retries.\n            Defaults to None.\n        retry_callback (Callable, optional): A callback function to call between subsequent retry attempts.\n            Defaults to None.\n        successful_retry_callback (Callable, optional): A callback function to call after a successful retry.\n            Defaults to None.\n        reraise_exception (bool, optional): Whether to re-raise the last exception caught in case of failure after retries.\n            Defaults to False.\n\n    Returns:\n        Callable: The decorated function.\n\n    Raises:\n        TypeError: If any argument has an invalid type.\n\n    Example:\n        @retry(exceptions=(ValueError,), max_retries=3, backoff=ExponentialBackOff(), timeout=10, logger=my_logger)\n        def my_function():\n            # Function body\n    \"\"\"\n    pass\n```\n--- File: retry_reloaded/_logging.py ---\n```python\ndef _init_logger(name: str) -> logging.Logger:\n    \"\"\"\n    Initialize logger for retry function.\n\n    Args:\n        name (str): Name for the logger.\n\n    Returns:\n        logging.Logger: Logger object configured for retry logging.\n    \"\"\"\n    pass\n\n\ndef _log_retry(\n    logger: Optional[logging.Logger],\n    fname: str,\n    max_retries: Optional[int],\n    retries: int,\n    timeout: Optional[float],\n    deadline: Optional[float],\n    start_time: float,\n    delay: float,\n    exc_info: Optional[Exception] = None\n) -> None:\n    \"\"\"\n    Log retry information.\n\n    Args:\n        logger (Optional[logging.Logger]): Logger object to use for logging. If None, logging is skipped.\n        fname (str): Name of the function being retried.\n        max_retries (Optional[int]): Maximum number of retries allowed, or None if unlimited.\n        retries (int): Number of retries attempted so far.\n        timeout (Optional[float]): Timeout value for the retry operation in seconds.\n        deadline (Optional[float]): Deadline for the retry operation in seconds.\n        start_time (float): Start time of the retry operation.\n        delay (float): Delay until the next retry in seconds.\n        exc_info (Optional[Exception]): Information about the exception that triggered the retry.\n\n    Returns:\n        None\n    \"\"\"\n    pass\n```\n--- File: retry_reloaded/_exceptions.py ---\n```python\nclass BaseRetryException(Exception):\n    \"\"\"\n    Base class for retry-related exceptions.\n\n    Args:\n        logger (logging.Logger): Logger object to use for logging the exception message.\n        message (str): Message describing the exception.\n        failure_callback (Optional[Callable]): Callback function to execute upon raising the exception.\n    \"\"\"\n\n    def __init__(\n        self,\n        logger: logging.Logger,\n        message: str,\n        failure_callback: Optional[Callable] = None\n    ) -> None:\n        pass\n\n\nclass MaxRetriesException(BaseRetryException):\n    \"\"\"\n    Exception raised when the maximum number of retries is reached.\n\n    Args:\n        logger (logging.Logger): Logger object to use for logging the exception message.\n        fname (str): Name of the function for which maximum retries were reached.\n        failure_callback (Optional[Callable]): Callback function to execute upon raising the exception.\n        max_retries (int): Maximum number of retries that have been attempted.\n    \"\"\"\n\n    def __init__(\n        self,\n        logger: logging.Logger,\n        fname: str,\n        max_retries: int,\n        failure_callback: Optional[Callable] = None\n    ) -> None:\n        pass\n\n\nclass RetriesTimeoutException(BaseRetryException):\n    \"\"\"\n    Exception raised when retry operation exceeds the timeout.\n\n    Args:\n        logger (logging.Logger): Logger object to use for logging the exception message.\n        fname (str): Name of the function for which retry operation exceeded timeout.\n        failure_callback (Optional[Callable]): Callback function to execute upon raising the exception.\n        elapsed_time (float): Time elapsed during the retry operation in seconds.\n        timeout (float): Timeout value in seconds.\n    \"\"\"\n\n    def __init__(\n        self,\n        logger: logging.Logger,\n        fname: str,\n        elapsed_time: float,\n        timeout: float,\n        failure_callback: Optional[Callable] = None\n    ) -> None:\n        pass\n\n\nclass RetriesDeadlineException(BaseRetryException):\n    \"\"\"\n    Exception raised when retry operation exceeds the deadline.\n\n    Args:\n        logger (logging.Logger): Logger object to use for logging the exception message.\n        fname (str): Name of the function for which retry operation exceeded deadline.\n        failure_callback (Optional[Callable]): Callback function to execute upon raising the exception.\n        elapsed_time (float): Time elapsed during the retry operation in seconds.\n        deadline (float): Deadline value in seconds.\n    \"\"\"\n\n    def __init__(\n        self,\n        logger: logging.Logger,\n        fname: str,\n        elapsed_time: float,\n        deadline: float,\n        failure_callback: Optional[Callable] = None,\n    ) -> None:\n        pass\n```\n--- File: retry_reloaded/backoff.py ---\n```python\nclass BackOff(ABC):\n    \"\"\"\n    Base class for implementing backoff strategies.\n    \"\"\"\n    def __init__(self, base_delay: float = 0, jitter: Optional[Tuple[float, float]] = None):\n        \"\"\"\n        Initialize BackOff object.\n\n        Args:\n            base_delay (float): Initial delay value, applies on the first round of delay and\n                calculations of next rounds. Defaults to 0.\n            jitter (Optional[Tuple[float, float]]): Tuple specifying the range for jitter (random delay on\n                top of the calculated delay), applying after the first round. If provided, it should be a\n                tuple of two numbers in sorted order. Defaults to None.\n\n        Raises:\n            TypeError: If `jitter` is provided and not a tuple of two numbers.\n            ValueError: If the `jitter` values are not in sorted order.\n        \"\"\"\n        pass\n\n    def _validate_base_delay(self, base_delay: float) -> float:\n        \"\"\"\n        Validate the base delay of backoff strategy.\n\n        Args:\n            base_delay (float): Initial delay value, applies on\n                first round of delay and calculations of next rounds.\n\n        Returns:\n            float: The validated base delay of backoff strategy.\n\n        Raises:\n            TypeError: If `base_delay` is not a number.\n            ValueError: If `base_delay` is negative.\n        \"\"\"\n        pass\n\n    def _validate_jitter(self, jitter: Optional[Tuple[float, float]]) -> Optional[Tuple[float, float]]:\n        \"\"\"\n        Validate the jitter values.\n\n        Args:\n            jitter (Optional[Tuple[float, float]]): Tuple specifying the range for jitter.\n\n        Returns:\n            Optional[Tuple[float, float]]: The validated jitter values.\n\n        Raises:\n            TypeError: If `jitter` is not a tuple of two numbers.\n            ValueError: If `jitter` values are not positive or not in sorted order.\n        \"\"\"\n        pass\n\n    def _validate_step(self, step: Optional[float]) -> Optional[float]:\n        \"\"\"\n        Validate the step delay value. If step is not specified then base delay of backoff\n        strategy is used instead.\n\n        Args:\n            step (float): Step value to increment delay.\n\n        Returns:\n            float: The validated step value.\n\n        Raises:\n            TypeError: If `step` is specified and not a number.\n            ValueError: If `step` is specified number but not positive one.\n        \"\"\"\n        pass\n\n    def _validate_max(self, max: Optional[float]) -> Optional[float]:\n        \"\"\"\n        Validate the max delay value.\n\n        Args:\n            max (Optional[float]): Maximum delay value.\n\n        Returns:\n            Optional[float]: The validated max delay value.\n\n        Raises:\n            TypeError: If `max` is not a number.\n            ValueError: If `max` is less than the base delay.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def _calculate_next_delay(self):\n        \"\"\"\n        Abstract method to calculate the delay for the next round of backoff.\n        \"\"\"\n        pass\n\n    @property\n    def delay(self) -> float:\n        \"\"\"\n        Get the current delay.\n\n        Returns:\n            float: Current delay value.\n        \"\"\"\n        pass\n\n    def reset(self) -> None:\n        \"\"\"\n        Reset the current delay.\n        \"\"\"\n        pass\n\n\nclass FixedBackOff(BackOff):\n    \"\"\"\n    Fixed backoff strategy.\n    \"\"\"\n    def _calculate_next_delay(self):\n        \"\"\"\n        Calculate the next round's delay for fixed backoff strategy.\n        \"\"\"\n        pass\n\n\nclass LinearBackOff(BackOff):\n    \"\"\"\n    Linear backoff strategy.\n    \"\"\"\n    def __init__(self, base_delay: float, step: float, jitter: Optional[Tuple[float, float]] = None,\n                 max: Optional[float] = None):\n        \"\"\"\n        Initialize LinearBackOff object.\n\n        Args:\n            base_delay (float): Initial delay value, applies on the first round of delay.\n            step (float): Step value to increment delay. If not specified defaults to base_delay.\n            jitter (Optional[Tuple[float, float]]): Tuple specifying the range for jitter (random delay on\n                top of the calculated delay), applying after the first round. Defaults to None.\n            max (Optional[float]): Maximum delay value. Defaults to None.\n        \"\"\"\n        pass\n\n    def _calculate_next_delay(self):\n        \"\"\"\n        Calculate the next round's delay for linear backoff strategy.\n        \"\"\"\n        pass\n\n\nclass RandomUniformBackOff(BackOff):\n    \"\"\"\n    Random uniform backoff strategy.\n    \"\"\"\n    def __init__(self, base_delay: float, min_delay: float, max_delay: float):\n        \"\"\"\n        Initialize RandomUniformBackOff object.\n\n        Args:\n            base_delay (float): Initial delay value, applies on the first round of delay.\n            min_delay (float): Minimum delay value.\n            max_delay (float): Maximum delay value.\n        \"\"\"\n        pass\n\n    def _calculate_next_delay(self):\n        \"\"\"\n        Calculate the next round's delay for random uniform backoff strategy.\n        \"\"\"\n        pass\n\n\nclass ExponentialBackOff(BackOff):\n    \"\"\"\n    Exponential backoff strategy.\n    \"\"\"\n    def __init__(self, base_delay: float, base: Optional[float] = None, jitter: Optional[Tuple[float, float]] = None,\n                 max: Optional[float] = None):\n        \"\"\"\n        Initialize ExponentialBackOff object.\n\n        Args:\n            base_delay (float): Initial delay value, applies on the first round of delay.\n            base (Optional[float]): Value to use as base for exponentiation. Defaults to 2.\n            jitter (Optional[Tuple[float, float]]): Tuple specifying the range for jitter (random delay on\n                top of the calculated delay), applying after the first round. Defaults to None.\n            max (Optional[float]): Maximum delay value. Defaults to None.\n        \"\"\"\n        pass\n\n    def _calculate_next_delay(self):\n        \"\"\"\n        Calculate the next round's delay for exponential backoff strategy.\n        \"\"\"\n        pass\n```",
        "full_code_skeleton_structured": [
            {
                "file_path": "retry_reloaded/_validate.py",
                "code": "def _validate_args(\n    exceptions: Tuple[Type[Exception], ...],\n    excluded_exceptions: Tuple[Type[Exception], ...],\n    max_retries: Optional[int],\n    backoff: BackOff,\n    timeout: Optional[float],\n    deadline: Optional[float],\n    logger: Optional[logging.Logger],\n    log_retry_traceback: bool,\n    failure_callback: Optional[Callable[[], None]],\n    retry_callback: Optional[Callable[[], None]],\n    successful_retry_callback: Optional[Callable[[], None]],\n    reraise_exception: bool\n) -> None:\n    \"\"\"\n    Validate arguments for retry logic.\n\n    Args:\n        exceptions (Tuple[Type[Exception], ...]): Tuple of exception types to catch.\n        excluded_exceptions (Tuple[Type[Exception]], ...): Tuple of exception types not to catch.\n        max_retries (Optional[int]): Maximum number of retries allowed, or None for unlimited retries.\n        backoff (BackOff): BackOff instance to manage retry delays.\n        timeout (Optional[float]): Timeout value for the retry operation in seconds, or None if no timeout.\n        deadline (Optional[float]): Deadline for the retry operation in seconds, or None if no deadline.\n        logger (Optional[logging.Logger]): Logger instance for logging retry information, or None if logging is disabled.\n        log_retry_traceback (bool): Flag to indicate if the traceback should be logged on each retry.\n        failure_callback (Optional[Callable[[], None]]): Callback function to execute upon a failed retry, or None.\n        retry_callback (Optional[Callable[[], None]]): Callback function to execute before each retry attempt, or None.\n        successful_retry_callback (Optional[Callable[[], None]]): Callback function to execute upon a successful retry,\n          or None.\n        reraise_exception (bool): Whether to re-raise the last exception caught in case of failure after retries.\n\n    Raises:\n        TypeError: If any of the arguments do not meet the expected types.\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "retry_reloaded/callback.py",
                "code": "class CallbackFactory():\n    def __init__(self, func: Callable, *args, **kwargs):\n        \"\"\"\n        Initialize the CallbackFactory.\n\n        Parameters:\n            func (Callable): The callable function to be wrapped.\n            *args: Positional arguments to be passed to the function.\n            **kwargs: Keyword arguments to be passed to the function.\n\n        Raises:\n            TypeError: If `func` is not a callable object.\n        \"\"\"\n        pass\n\n    def __call__(self, **override_kwargs):\n        \"\"\"\n        Call the wrapped function with provided keyword arguments.\n        If no arguments are provided during calling,\n        then the stored ones (during instance creation) are used.\n\n        Returns:\n            The result of calling the wrapped function with provided arguments.\n        \"\"\"\n        pass\n\n\ndef callback_factory(func: Callable, *args, **kwargs):\n    \"\"\"\n    Create a callback function that wraps the provided callable function.\n\n    Parameters:\n        func (Callable): The callable function to be wrapped.\n        *args: Positional arguments to be passed to the function.\n        **kwargs: Keyword arguments to be passed to the function.\n\n    Returns:\n        A wrapped function that calls the provided\n        callable function with the specified arguments.\n\n    Raises:\n        TypeError: If `func` is not a callable object.\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "retry_reloaded/retry.py",
                "code": "def retry(\n    exceptions: Tuple[Type[Exception]] = (Exception,),\n    excluded_exceptions: Tuple[Type[Exception]] = (),\n    max_retries: Union[int, None] = None,\n    backoff: BackOff = FixedBackOff(base_delay=0),\n    timeout: Union[float, None] = None,\n    deadline: Union[float, None] = None,\n    logger: Union[logging.Logger, None] = retry_logger,\n    log_retry_traceback: bool = False,\n    failure_callback: Union[Callable, None] = None,\n    retry_callback: Union[Callable, None] = None,\n    successful_retry_callback: Union[Callable, None] = None,\n    reraise_exception: bool = False\n) -> Callable:\n    \"\"\"\n    Decorator that adds retry functionality to a function.\n\n    Parameters:\n        exceptions (Tuple[Type[Exception]], optional): A tuple of exception types that should trigger a retry.\n            Defaults to (Exception,), meaning any exception will trigger a retry.\n        excluded_exceptions (Tuple[Type[Exception]], optional): A tuple of exception types that should not trigger\n            a retry. Defaults to an empty tuple.\n        max_retries (int, optional): The maximum number of retry attempts. Defaults to None (unlimited retries).\n        backoff (BackOff, optional): The backoff strategy to use between retry attempts.\n            Defaults to FixedBackOff(base_delay=0) with base_delay referring to seconds.\n        timeout (float, optional): The maximum time (in seconds) to spend on retries. Defaults to None (no timeout).\n            Timeout check happens right before retry execution of the wrapped function.\n        deadline (float, optional): The deadline (in seconds) for retries. Defaults to None (no deadline).\n            Deadline check happens right after the retry execution of the wrapped function.\n        logger (logging.Logger, optional): The logger instance to use for logging retry attempts. Defaults to retry_logger.\n        log_retry_traceback (bool, optional): Whether to log the traceback of exceptions triggering retries.\n            Defaults to False.\n        failure_callback (Callable, optional): A callback function to call in case of eventual failure after retries.\n            Defaults to None.\n        retry_callback (Callable, optional): A callback function to call between subsequent retry attempts.\n            Defaults to None.\n        successful_retry_callback (Callable, optional): A callback function to call after a successful retry.\n            Defaults to None.\n        reraise_exception (bool, optional): Whether to re-raise the last exception caught in case of failure after retries.\n            Defaults to False.\n\n    Returns:\n        Callable: The decorated function.\n\n    Raises:\n        TypeError: If any argument has an invalid type.\n\n    Example:\n        @retry(exceptions=(ValueError,), max_retries=3, backoff=ExponentialBackOff(), timeout=10, logger=my_logger)\n        def my_function():\n            # Function body\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "retry_reloaded/_logging.py",
                "code": "def _init_logger(name: str) -> logging.Logger:\n    \"\"\"\n    Initialize logger for retry function.\n\n    Args:\n        name (str): Name for the logger.\n\n    Returns:\n        logging.Logger: Logger object configured for retry logging.\n    \"\"\"\n    pass\n\n\ndef _log_retry(\n    logger: Optional[logging.Logger],\n    fname: str,\n    max_retries: Optional[int],\n    retries: int,\n    timeout: Optional[float],\n    deadline: Optional[float],\n    start_time: float,\n    delay: float,\n    exc_info: Optional[Exception] = None\n) -> None:\n    \"\"\"\n    Log retry information.\n\n    Args:\n        logger (Optional[logging.Logger]): Logger object to use for logging. If None, logging is skipped.\n        fname (str): Name of the function being retried.\n        max_retries (Optional[int]): Maximum number of retries allowed, or None if unlimited.\n        retries (int): Number of retries attempted so far.\n        timeout (Optional[float]): Timeout value for the retry operation in seconds.\n        deadline (Optional[float]): Deadline for the retry operation in seconds.\n        start_time (float): Start time of the retry operation.\n        delay (float): Delay until the next retry in seconds.\n        exc_info (Optional[Exception]): Information about the exception that triggered the retry.\n\n    Returns:\n        None\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "retry_reloaded/_exceptions.py",
                "code": "class BaseRetryException(Exception):\n    \"\"\"\n    Base class for retry-related exceptions.\n\n    Args:\n        logger (logging.Logger): Logger object to use for logging the exception message.\n        message (str): Message describing the exception.\n        failure_callback (Optional[Callable]): Callback function to execute upon raising the exception.\n    \"\"\"\n\n    def __init__(\n        self,\n        logger: logging.Logger,\n        message: str,\n        failure_callback: Optional[Callable] = None\n    ) -> None:\n        pass\n\n\nclass MaxRetriesException(BaseRetryException):\n    \"\"\"\n    Exception raised when the maximum number of retries is reached.\n\n    Args:\n        logger (logging.Logger): Logger object to use for logging the exception message.\n        fname (str): Name of the function for which maximum retries were reached.\n        failure_callback (Optional[Callable]): Callback function to execute upon raising the exception.\n        max_retries (int): Maximum number of retries that have been attempted.\n    \"\"\"\n\n    def __init__(\n        self,\n        logger: logging.Logger,\n        fname: str,\n        max_retries: int,\n        failure_callback: Optional[Callable] = None\n    ) -> None:\n        pass\n\n\nclass RetriesTimeoutException(BaseRetryException):\n    \"\"\"\n    Exception raised when retry operation exceeds the timeout.\n\n    Args:\n        logger (logging.Logger): Logger object to use for logging the exception message.\n        fname (str): Name of the function for which retry operation exceeded timeout.\n        failure_callback (Optional[Callable]): Callback function to execute upon raising the exception.\n        elapsed_time (float): Time elapsed during the retry operation in seconds.\n        timeout (float): Timeout value in seconds.\n    \"\"\"\n\n    def __init__(\n        self,\n        logger: logging.Logger,\n        fname: str,\n        elapsed_time: float,\n        timeout: float,\n        failure_callback: Optional[Callable] = None\n    ) -> None:\n        pass\n\n\nclass RetriesDeadlineException(BaseRetryException):\n    \"\"\"\n    Exception raised when retry operation exceeds the deadline.\n\n    Args:\n        logger (logging.Logger): Logger object to use for logging the exception message.\n        fname (str): Name of the function for which retry operation exceeded deadline.\n        failure_callback (Optional[Callable]): Callback function to execute upon raising the exception.\n        elapsed_time (float): Time elapsed during the retry operation in seconds.\n        deadline (float): Deadline value in seconds.\n    \"\"\"\n\n    def __init__(\n        self,\n        logger: logging.Logger,\n        fname: str,\n        elapsed_time: float,\n        deadline: float,\n        failure_callback: Optional[Callable] = None,\n    ) -> None:\n        pass\n"
            },
            {
                "file_path": "retry_reloaded/backoff.py",
                "code": "class BackOff(ABC):\n    \"\"\"\n    Base class for implementing backoff strategies.\n    \"\"\"\n    def __init__(self, base_delay: float = 0, jitter: Optional[Tuple[float, float]] = None):\n        \"\"\"\n        Initialize BackOff object.\n\n        Args:\n            base_delay (float): Initial delay value, applies on the first round of delay and\n                calculations of next rounds. Defaults to 0.\n            jitter (Optional[Tuple[float, float]]): Tuple specifying the range for jitter (random delay on\n                top of the calculated delay), applying after the first round. If provided, it should be a\n                tuple of two numbers in sorted order. Defaults to None.\n\n        Raises:\n            TypeError: If `jitter` is provided and not a tuple of two numbers.\n            ValueError: If the `jitter` values are not in sorted order.\n        \"\"\"\n        pass\n\n    def _validate_base_delay(self, base_delay: float) -> float:\n        \"\"\"\n        Validate the base delay of backoff strategy.\n\n        Args:\n            base_delay (float): Initial delay value, applies on\n                first round of delay and calculations of next rounds.\n\n        Returns:\n            float: The validated base delay of backoff strategy.\n\n        Raises:\n            TypeError: If `base_delay` is not a number.\n            ValueError: If `base_delay` is negative.\n        \"\"\"\n        pass\n\n    def _validate_jitter(self, jitter: Optional[Tuple[float, float]]) -> Optional[Tuple[float, float]]:\n        \"\"\"\n        Validate the jitter values.\n\n        Args:\n            jitter (Optional[Tuple[float, float]]): Tuple specifying the range for jitter.\n\n        Returns:\n            Optional[Tuple[float, float]]: The validated jitter values.\n\n        Raises:\n            TypeError: If `jitter` is not a tuple of two numbers.\n            ValueError: If `jitter` values are not positive or not in sorted order.\n        \"\"\"\n        pass\n\n    def _validate_step(self, step: Optional[float]) -> Optional[float]:\n        \"\"\"\n        Validate the step delay value. If step is not specified then base delay of backoff\n        strategy is used instead.\n\n        Args:\n            step (float): Step value to increment delay.\n\n        Returns:\n            float: The validated step value.\n\n        Raises:\n            TypeError: If `step` is specified and not a number.\n            ValueError: If `step` is specified number but not positive one.\n        \"\"\"\n        pass\n\n    def _validate_max(self, max: Optional[float]) -> Optional[float]:\n        \"\"\"\n        Validate the max delay value.\n\n        Args:\n            max (Optional[float]): Maximum delay value.\n\n        Returns:\n            Optional[float]: The validated max delay value.\n\n        Raises:\n            TypeError: If `max` is not a number.\n            ValueError: If `max` is less than the base delay.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def _calculate_next_delay(self):\n        \"\"\"\n        Abstract method to calculate the delay for the next round of backoff.\n        \"\"\"\n        pass\n\n    @property\n    def delay(self) -> float:\n        \"\"\"\n        Get the current delay.\n\n        Returns:\n            float: Current delay value.\n        \"\"\"\n        pass\n\n    def reset(self) -> None:\n        \"\"\"\n        Reset the current delay.\n        \"\"\"\n        pass\n\n\nclass FixedBackOff(BackOff):\n    \"\"\"\n    Fixed backoff strategy.\n    \"\"\"\n    def _calculate_next_delay(self):\n        \"\"\"\n        Calculate the next round's delay for fixed backoff strategy.\n        \"\"\"\n        pass\n\n\nclass LinearBackOff(BackOff):\n    \"\"\"\n    Linear backoff strategy.\n    \"\"\"\n    def __init__(self, base_delay: float, step: float, jitter: Optional[Tuple[float, float]] = None,\n                 max: Optional[float] = None):\n        \"\"\"\n        Initialize LinearBackOff object.\n\n        Args:\n            base_delay (float): Initial delay value, applies on the first round of delay.\n            step (float): Step value to increment delay. If not specified defaults to base_delay.\n            jitter (Optional[Tuple[float, float]]): Tuple specifying the range for jitter (random delay on\n                top of the calculated delay), applying after the first round. Defaults to None.\n            max (Optional[float]): Maximum delay value. Defaults to None.\n        \"\"\"\n        pass\n\n    def _calculate_next_delay(self):\n        \"\"\"\n        Calculate the next round's delay for linear backoff strategy.\n        \"\"\"\n        pass\n\n\nclass RandomUniformBackOff(BackOff):\n    \"\"\"\n    Random uniform backoff strategy.\n    \"\"\"\n    def __init__(self, base_delay: float, min_delay: float, max_delay: float):\n        \"\"\"\n        Initialize RandomUniformBackOff object.\n\n        Args:\n            base_delay (float): Initial delay value, applies on the first round of delay.\n            min_delay (float): Minimum delay value.\n            max_delay (float): Maximum delay value.\n        \"\"\"\n        pass\n\n    def _calculate_next_delay(self):\n        \"\"\"\n        Calculate the next round's delay for random uniform backoff strategy.\n        \"\"\"\n        pass\n\n\nclass ExponentialBackOff(BackOff):\n    \"\"\"\n    Exponential backoff strategy.\n    \"\"\"\n    def __init__(self, base_delay: float, base: Optional[float] = None, jitter: Optional[Tuple[float, float]] = None,\n                 max: Optional[float] = None):\n        \"\"\"\n        Initialize ExponentialBackOff object.\n\n        Args:\n            base_delay (float): Initial delay value, applies on the first round of delay.\n            base (Optional[float]): Value to use as base for exponentiation. Defaults to 2.\n            jitter (Optional[Tuple[float, float]]): Tuple specifying the range for jitter (random delay on\n                top of the calculated delay), applying after the first round. Defaults to None.\n            max (Optional[float]): Maximum delay value. Defaults to None.\n        \"\"\"\n        pass\n\n    def _calculate_next_delay(self):\n        \"\"\"\n        Calculate the next round's delay for exponential backoff strategy.\n        \"\"\"\n        pass\n"
            }
        ],
        "minimal_code_skeleton": "--- File: retry_reloaded/retry.py ---\n```python\ndef retry(\n    exceptions: Tuple[Type[Exception]] = (Exception,),\n    excluded_exceptions: Tuple[Type[Exception]] = (),\n    max_retries: Union[int, None] = None,\n    backoff: BackOff = FixedBackOff(base_delay=0),\n    timeout: Union[float, None] = None,\n    deadline: Union[float, None] = None,\n    logger: Union[logging.Logger, None] = None,\n    log_retry_traceback: bool = False,\n    failure_callback: Union[Callable, None] = None,\n    retry_callback: Union[Callable, None] = None,\n    successful_retry_callback: Union[Callable, None] = None,\n    reraise_exception: bool = False\n) -> Callable:\n    \"\"\"\n    Decorator that adds retry functionality to a function.\n\n    Parameters:\n        exceptions (Tuple[Type[Exception]], optional): A tuple of exception types that should trigger a retry.\n            Defaults to (Exception,), meaning any exception will trigger a retry.\n        excluded_exceptions (Tuple[Type[Exception]], optional): A tuple of exception types that should not trigger\n            a retry. Defaults to an empty tuple.\n        max_retries (int, optional): The maximum number of retry attempts. Defaults to None (unlimited retries).\n        backoff (BackOff, optional): The backoff strategy to use between retry attempts.\n            Defaults to FixedBackOff(base_delay=0) with base_delay referring to seconds.\n        timeout (float, optional): The maximum time (in seconds) to spend on retries. Defaults to None (no timeout).\n            Timeout check happens right before retry execution of the wrapped function.\n        deadline (float, optional): The deadline (in seconds) for retries. Defaults to None (no deadline).\n            Deadline check happens right after the retry execution of the wrapped function.\n        logger (logging.Logger, optional): The logger instance to use for logging retry attempts. Defaults to retry_logger.\n        log_retry_traceback (bool, optional): Whether to log the traceback of exceptions triggering retries.\n            Defaults to False.\n        failure_callback (Callable, optional): A callback function to call in case of eventual failure after retries.\n            Defaults to None.\n        retry_callback (Callable, optional): A callback function to call between subsequent retry attempts.\n            Defaults to None.\n        successful_retry_callback (Callable, optional): A callback function to call after a successful retry.\n            Defaults to None.\n        reraise_exception (bool, optional): Whether to re-raise the last exception caught in case of failure after retries.\n            Defaults to False.\n\n    Returns:\n        Callable: The decorated function.\n\n    Raises:\n        TypeError: If any argument has an invalid type.\n\n    Example:\n        @retry(exceptions=(ValueError,), max_retries=3, backoff=ExponentialBackOff(), timeout=10, logger=my_logger)\n        def my_function():\n            # Function body\n    \"\"\"\n    pass\n\n```\n--- File: retry_reloaded/callback.py ---\n```python\nclass CallbackFactory():\n    def __init__(self, func: Callable, *args, **kwargs):\n        \"\"\"\n        Initialize the CallbackFactory.\n\n        Parameters:\n            func (Callable): The callable function to be wrapped.\n            *args: Positional arguments to be passed to the function.\n            **kwargs: Keyword arguments to be passed to the function.\n\n        Raises:\n            TypeError: If `func` is not a callable object.\n        \"\"\"\n        pass\n\n    def __call__(self, **override_kwargs):\n        \"\"\"\n        Call the wrapped function with provided keyword arguments.\n        If no arguments are provided during calling,\n        then the stored ones (during instance creation) are used.\n\n        Returns:\n            The result of calling the wrapped function with provided arguments.\n        \"\"\"\n        pass\n\n\ndef callback_factory(func: Callable, *args, **kwargs):\n    \"\"\"\n    Create a callback function that wraps the provided callable function.\n\n    Parameters:\n        func (Callable): The callable function to be wrapped.\n        *args: Positional arguments to be passed to the function.\n        **kwargs: Keyword arguments to be passed to the function.\n\n    Returns:\n        A wrapped function that calls the provided\n        callable function with the specified arguments.\n\n    Raises:\n        TypeError: If `func` is not a callable object.\n    \"\"\"\n    pass\n\n```\n--- File: retry_reloaded/_exceptions.py ---\n```python\nclass BaseRetryException(Exception):\n    \"\"\"\n    Base class for retry-related exceptions.\n\n    Args:\n        logger (logging.Logger): Logger object to use for logging the exception message.\n        message (str): Message describing the exception.\n        failure_callback (Optional[Callable]): Callback function to execute upon raising the exception.\n    \"\"\"\n\n    def __init__(\n        self,\n        logger: logging.Logger,\n        message: str,\n        failure_callback: Optional[Callable] = None\n    ) -> None:\n        pass\n\n\nclass MaxRetriesException(BaseRetryException):\n    \"\"\"\n    Exception raised when the maximum number of retries is reached.\n\n    Args:\n        logger (logging.Logger): Logger object to use for logging the exception message.\n        fname (str): Name of the function for which maximum retries were reached.\n        failure_callback (Optional[Callable]): Callback function to execute upon raising the exception.\n        max_retries (int): Maximum number of retries that have been attempted.\n    \"\"\"\n\n    def __init__(\n        self,\n        logger: logging.Logger,\n        fname: str,\n        max_retries: int,\n        failure_callback: Optional[Callable] = None\n    ) -> None:\n        pass\n\n\nclass RetriesTimeoutException(BaseRetryException):\n    \"\"\"\n    Exception raised when retry operation exceeds the timeout.\n\n    Args:\n        logger (logging.Logger): Logger object to use for logging the exception message.\n        fname (str): Name of the function for which retry operation exceeded timeout.\n        failure_callback (Optional[Callable]): Callback function to execute upon raising the exception.\n        elapsed_time (float): Time elapsed during the retry operation in seconds.\n        timeout (float): Timeout value in seconds.\n    \"\"\"\n\n    def __init__(\n        self,\n        logger: logging.Logger,\n        fname: str,\n        elapsed_time: float,\n        timeout: float,\n        failure_callback: Optional[Callable] = None\n    ) -> None:\n        pass\n\n\nclass RetriesDeadlineException(BaseRetryException):\n    \"\"\"\n    Exception raised when retry operation exceeds the deadline.\n\n    Args:\n        logger (logging.Logger): Logger object to use for logging the exception message.\n        fname (str): Name of the function for which retry operation exceeded deadline.\n        failure_callback (Optional[Callable]): Callback function to execute upon raising the exception.\n        elapsed_time (float): Time elapsed during the retry operation in seconds.\n        deadline (float): Deadline value in seconds.\n    \"\"\"\n\n    def __init__(\n        self,\n        logger: logging.Logger,\n        fname: str,\n        elapsed_time: float,\n        deadline: float,\n        failure_callback: Optional[Callable] = None,\n    ) -> None:\n        pass\n\n```\n--- File: retry_reloaded/backoff.py ---\n```python\nclass BackOff(ABC):\n    \"\"\"\n    Base class for implementing backoff strategies.\n    \"\"\"\n    def __init__(self, base_delay: float = 0, jitter: Optional[Tuple[float, float]] = None):\n        \"\"\"\n        Initialize BackOff object.\n\n        Args:\n            base_delay (float): Initial delay value, applies on the first round of delay and\n                calculations of next rounds. Defaults to 0.\n            jitter (Optional[Tuple[float, float]]): Tuple specifying the range for jitter (random delay on\n                top of the calculated delay), applying after the first round. If provided, it should be a\n                tuple of two numbers in sorted order. Defaults to None.\n\n        Raises:\n            TypeError: If `jitter` is provided and not a tuple of two numbers.\n            ValueError: If the `jitter` values are not in sorted order.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def _calculate_next_delay(self):\n        \"\"\"\n        Abstract method to calculate the delay for the next round of backoff.\n        \"\"\"\n        pass\n\n    @property\n    def delay(self) -> float:\n        \"\"\"\n        Get the current delay.\n\n        Returns:\n            float: Current delay value.\n        \"\"\"\n        pass\n\n    def reset(self) -> None:\n        \"\"\"\n        Reset the current delay.\n        \"\"\"\n        pass\n\n\nclass FixedBackOff(BackOff):\n    \"\"\"\n    Fixed backoff strategy.\n    \"\"\"\n    def _calculate_next_delay(self):\n        \"\"\"\n        Calculate the next round's delay for fixed backoff strategy.\n        \"\"\"\n        pass\n\n\nclass LinearBackOff(BackOff):\n    \"\"\"\n    Linear backoff strategy.\n    \"\"\"\n    def __init__(self, base_delay: float, step: float, jitter: Optional[Tuple[float, float]] = None,\n                 max: Optional[float] = None):\n        \"\"\"\n        Initialize LinearBackOff object.\n\n        Args:\n            base_delay (float): Initial delay value, applies on the first round of delay.\n            step (float): Step value to increment delay. If not specified defaults to base_delay.\n            jitter (Optional[Tuple[float, float]]): Tuple specifying the range for jitter (random delay on\n                top of the calculated delay), applying after the first round. Defaults to None.\n            max (Optional[float]): Maximum delay value. Defaults to None.\n        \"\"\"\n        pass\n\n    def _calculate_next_delay(self):\n        \"\"\"\n        Calculate the next round's delay for linear backoff strategy.\n        \"\"\"\n        pass\n\n\nclass RandomUniformBackOff(BackOff):\n    \"\"\"\n    Random uniform backoff strategy.\n    \"\"\"\n    def __init__(self, base_delay: float, min_delay: float, max_delay: float):\n        \"\"\"\n        Initialize RandomUniformBackOff object.\n\n        Args:\n            base_delay (float): Initial delay value, applies on the first round of delay.\n            min_delay (float): Minimum delay value.\n            max_delay (float): Maximum delay value.\n        \"\"\"\n        pass\n\n    def _calculate_next_delay(self):\n        \"\"\"\n        Calculate the next round's delay for random uniform backoff strategy.\n        \"\"\"\n        pass\n\n\nclass ExponentialBackOff(BackOff):\n    \"\"\"\n    Exponential backoff strategy.\n    \"\"\"\n    def __init__(self, base_delay: float, base: Optional[float] = None, jitter: Optional[Tuple[float, float]] = None,\n                 max: Optional[float] = None):\n        \"\"\"\n        Initialize ExponentialBackOff object.\n\n        Args:\n            base_delay (float): Initial delay value, applies on the first round of delay.\n            base (Optional[float]): Value to use as base for exponentiation. Defaults to 2.\n            jitter (Optional[Tuple[float, float]]): Tuple specifying the range for jitter (random delay on\n                top of the calculated delay), applying after the first round. Defaults to None.\n            max (Optional[float]): Maximum delay value. Defaults to None.\n        \"\"\"\n        pass\n\n    def _calculate_next_delay(self):\n        \"\"\"\n        Calculate the next round's delay for exponential backoff strategy.\n        \"\"\"\n        pass\n\n```",
        "minimal_code_skeleton_structured": [
            {
                "file_path": "retry_reloaded/retry.py",
                "code": "def retry(\n    exceptions: Tuple[Type[Exception]] = (Exception,),\n    excluded_exceptions: Tuple[Type[Exception]] = (),\n    max_retries: Union[int, None] = None,\n    backoff: BackOff = FixedBackOff(base_delay=0),\n    timeout: Union[float, None] = None,\n    deadline: Union[float, None] = None,\n    logger: Union[logging.Logger, None] = None,\n    log_retry_traceback: bool = False,\n    failure_callback: Union[Callable, None] = None,\n    retry_callback: Union[Callable, None] = None,\n    successful_retry_callback: Union[Callable, None] = None,\n    reraise_exception: bool = False\n) -> Callable:\n    \"\"\"\n    Decorator that adds retry functionality to a function.\n\n    Parameters:\n        exceptions (Tuple[Type[Exception]], optional): A tuple of exception types that should trigger a retry.\n            Defaults to (Exception,), meaning any exception will trigger a retry.\n        excluded_exceptions (Tuple[Type[Exception]], optional): A tuple of exception types that should not trigger\n            a retry. Defaults to an empty tuple.\n        max_retries (int, optional): The maximum number of retry attempts. Defaults to None (unlimited retries).\n        backoff (BackOff, optional): The backoff strategy to use between retry attempts.\n            Defaults to FixedBackOff(base_delay=0) with base_delay referring to seconds.\n        timeout (float, optional): The maximum time (in seconds) to spend on retries. Defaults to None (no timeout).\n            Timeout check happens right before retry execution of the wrapped function.\n        deadline (float, optional): The deadline (in seconds) for retries. Defaults to None (no deadline).\n            Deadline check happens right after the retry execution of the wrapped function.\n        logger (logging.Logger, optional): The logger instance to use for logging retry attempts. Defaults to retry_logger.\n        log_retry_traceback (bool, optional): Whether to log the traceback of exceptions triggering retries.\n            Defaults to False.\n        failure_callback (Callable, optional): A callback function to call in case of eventual failure after retries.\n            Defaults to None.\n        retry_callback (Callable, optional): A callback function to call between subsequent retry attempts.\n            Defaults to None.\n        successful_retry_callback (Callable, optional): A callback function to call after a successful retry.\n            Defaults to None.\n        reraise_exception (bool, optional): Whether to re-raise the last exception caught in case of failure after retries.\n            Defaults to False.\n\n    Returns:\n        Callable: The decorated function.\n\n    Raises:\n        TypeError: If any argument has an invalid type.\n\n    Example:\n        @retry(exceptions=(ValueError,), max_retries=3, backoff=ExponentialBackOff(), timeout=10, logger=my_logger)\n        def my_function():\n            # Function body\n    \"\"\"\n    pass\n\n"
            },
            {
                "file_path": "retry_reloaded/callback.py",
                "code": "class CallbackFactory():\n    def __init__(self, func: Callable, *args, **kwargs):\n        \"\"\"\n        Initialize the CallbackFactory.\n\n        Parameters:\n            func (Callable): The callable function to be wrapped.\n            *args: Positional arguments to be passed to the function.\n            **kwargs: Keyword arguments to be passed to the function.\n\n        Raises:\n            TypeError: If `func` is not a callable object.\n        \"\"\"\n        pass\n\n    def __call__(self, **override_kwargs):\n        \"\"\"\n        Call the wrapped function with provided keyword arguments.\n        If no arguments are provided during calling,\n        then the stored ones (during instance creation) are used.\n\n        Returns:\n            The result of calling the wrapped function with provided arguments.\n        \"\"\"\n        pass\n\n\ndef callback_factory(func: Callable, *args, **kwargs):\n    \"\"\"\n    Create a callback function that wraps the provided callable function.\n\n    Parameters:\n        func (Callable): The callable function to be wrapped.\n        *args: Positional arguments to be passed to the function.\n        **kwargs: Keyword arguments to be passed to the function.\n\n    Returns:\n        A wrapped function that calls the provided\n        callable function with the specified arguments.\n\n    Raises:\n        TypeError: If `func` is not a callable object.\n    \"\"\"\n    pass\n\n"
            },
            {
                "file_path": "retry_reloaded/_exceptions.py",
                "code": "class BaseRetryException(Exception):\n    \"\"\"\n    Base class for retry-related exceptions.\n\n    Args:\n        logger (logging.Logger): Logger object to use for logging the exception message.\n        message (str): Message describing the exception.\n        failure_callback (Optional[Callable]): Callback function to execute upon raising the exception.\n    \"\"\"\n\n    def __init__(\n        self,\n        logger: logging.Logger,\n        message: str,\n        failure_callback: Optional[Callable] = None\n    ) -> None:\n        pass\n\n\nclass MaxRetriesException(BaseRetryException):\n    \"\"\"\n    Exception raised when the maximum number of retries is reached.\n\n    Args:\n        logger (logging.Logger): Logger object to use for logging the exception message.\n        fname (str): Name of the function for which maximum retries were reached.\n        failure_callback (Optional[Callable]): Callback function to execute upon raising the exception.\n        max_retries (int): Maximum number of retries that have been attempted.\n    \"\"\"\n\n    def __init__(\n        self,\n        logger: logging.Logger,\n        fname: str,\n        max_retries: int,\n        failure_callback: Optional[Callable] = None\n    ) -> None:\n        pass\n\n\nclass RetriesTimeoutException(BaseRetryException):\n    \"\"\"\n    Exception raised when retry operation exceeds the timeout.\n\n    Args:\n        logger (logging.Logger): Logger object to use for logging the exception message.\n        fname (str): Name of the function for which retry operation exceeded timeout.\n        failure_callback (Optional[Callable]): Callback function to execute upon raising the exception.\n        elapsed_time (float): Time elapsed during the retry operation in seconds.\n        timeout (float): Timeout value in seconds.\n    \"\"\"\n\n    def __init__(\n        self,\n        logger: logging.Logger,\n        fname: str,\n        elapsed_time: float,\n        timeout: float,\n        failure_callback: Optional[Callable] = None\n    ) -> None:\n        pass\n\n\nclass RetriesDeadlineException(BaseRetryException):\n    \"\"\"\n    Exception raised when retry operation exceeds the deadline.\n\n    Args:\n        logger (logging.Logger): Logger object to use for logging the exception message.\n        fname (str): Name of the function for which retry operation exceeded deadline.\n        failure_callback (Optional[Callable]): Callback function to execute upon raising the exception.\n        elapsed_time (float): Time elapsed during the retry operation in seconds.\n        deadline (float): Deadline value in seconds.\n    \"\"\"\n\n    def __init__(\n        self,\n        logger: logging.Logger,\n        fname: str,\n        elapsed_time: float,\n        deadline: float,\n        failure_callback: Optional[Callable] = None,\n    ) -> None:\n        pass\n\n"
            },
            {
                "file_path": "retry_reloaded/backoff.py",
                "code": "class BackOff(ABC):\n    \"\"\"\n    Base class for implementing backoff strategies.\n    \"\"\"\n    def __init__(self, base_delay: float = 0, jitter: Optional[Tuple[float, float]] = None):\n        \"\"\"\n        Initialize BackOff object.\n\n        Args:\n            base_delay (float): Initial delay value, applies on the first round of delay and\n                calculations of next rounds. Defaults to 0.\n            jitter (Optional[Tuple[float, float]]): Tuple specifying the range for jitter (random delay on\n                top of the calculated delay), applying after the first round. If provided, it should be a\n                tuple of two numbers in sorted order. Defaults to None.\n\n        Raises:\n            TypeError: If `jitter` is provided and not a tuple of two numbers.\n            ValueError: If the `jitter` values are not in sorted order.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def _calculate_next_delay(self):\n        \"\"\"\n        Abstract method to calculate the delay for the next round of backoff.\n        \"\"\"\n        pass\n\n    @property\n    def delay(self) -> float:\n        \"\"\"\n        Get the current delay.\n\n        Returns:\n            float: Current delay value.\n        \"\"\"\n        pass\n\n    def reset(self) -> None:\n        \"\"\"\n        Reset the current delay.\n        \"\"\"\n        pass\n\n\nclass FixedBackOff(BackOff):\n    \"\"\"\n    Fixed backoff strategy.\n    \"\"\"\n    def _calculate_next_delay(self):\n        \"\"\"\n        Calculate the next round's delay for fixed backoff strategy.\n        \"\"\"\n        pass\n\n\nclass LinearBackOff(BackOff):\n    \"\"\"\n    Linear backoff strategy.\n    \"\"\"\n    def __init__(self, base_delay: float, step: float, jitter: Optional[Tuple[float, float]] = None,\n                 max: Optional[float] = None):\n        \"\"\"\n        Initialize LinearBackOff object.\n\n        Args:\n            base_delay (float): Initial delay value, applies on the first round of delay.\n            step (float): Step value to increment delay. If not specified defaults to base_delay.\n            jitter (Optional[Tuple[float, float]]): Tuple specifying the range for jitter (random delay on\n                top of the calculated delay), applying after the first round. Defaults to None.\n            max (Optional[float]): Maximum delay value. Defaults to None.\n        \"\"\"\n        pass\n\n    def _calculate_next_delay(self):\n        \"\"\"\n        Calculate the next round's delay for linear backoff strategy.\n        \"\"\"\n        pass\n\n\nclass RandomUniformBackOff(BackOff):\n    \"\"\"\n    Random uniform backoff strategy.\n    \"\"\"\n    def __init__(self, base_delay: float, min_delay: float, max_delay: float):\n        \"\"\"\n        Initialize RandomUniformBackOff object.\n\n        Args:\n            base_delay (float): Initial delay value, applies on the first round of delay.\n            min_delay (float): Minimum delay value.\n            max_delay (float): Maximum delay value.\n        \"\"\"\n        pass\n\n    def _calculate_next_delay(self):\n        \"\"\"\n        Calculate the next round's delay for random uniform backoff strategy.\n        \"\"\"\n        pass\n\n\nclass ExponentialBackOff(BackOff):\n    \"\"\"\n    Exponential backoff strategy.\n    \"\"\"\n    def __init__(self, base_delay: float, base: Optional[float] = None, jitter: Optional[Tuple[float, float]] = None,\n                 max: Optional[float] = None):\n        \"\"\"\n        Initialize ExponentialBackOff object.\n\n        Args:\n            base_delay (float): Initial delay value, applies on the first round of delay.\n            base (Optional[float]): Value to use as base for exponentiation. Defaults to 2.\n            jitter (Optional[Tuple[float, float]]): Tuple specifying the range for jitter (random delay on\n                top of the calculated delay), applying after the first round. Defaults to None.\n            max (Optional[float]): Maximum delay value. Defaults to None.\n        \"\"\"\n        pass\n\n    def _calculate_next_delay(self):\n        \"\"\"\n        Calculate the next round's delay for exponential backoff strategy.\n        \"\"\"\n        pass\n\n"
            }
        ],
        "minimal_test_cases": [
            {
                "test_id": "tests/test_retry.py::test_successful_execution",
                "covers": [
                    "retry_reloaded.retry.retry - successful execution after retries (default FixedBackOff)"
                ]
            },
            {
                "test_id": "tests/test_callback.py::test_CallbackFactory_arguments_passing",
                "covers": [
                    "retry_reloaded.callback.CallbackFactory.__init__ - instantiation with positional arguments",
                    "retry_reloaded.callback.CallbackFactory.__call__ - execution with initial arguments"
                ]
            },
            {
                "test_id": "tests/test_callback.py::test_callback_factory_arguments_passing",
                "covers": [
                    "retry_reloaded.callback.callback_factory - creating and executing a callback with positional arguments"
                ]
            },
            {
                "test_id": "tests/test_backoff.py::test_fixed_backoff[1.0-None]",
                "covers": [
                    "retry_reloaded.backoff.FixedBackOff.__init__ - basic instantiation without jitter",
                    "retry_reloaded.backoff.FixedBackOff.delay - getting fixed delay"
                ]
            },
            {
                "test_id": "tests/test_backoff.py::test_linear_backoff[1.0-0.5-None-None]",
                "covers": [
                    "retry_reloaded.backoff.LinearBackOff.__init__ - basic instantiation without jitter or max_delay",
                    "retry_reloaded.backoff.LinearBackOff.delay - getting linearly increasing delay",
                    "retry_reloaded.backoff.LinearBackOff.reset - resetting delay calculation"
                ]
            },
            {
                "test_id": "tests/test_backoff.py::test_exponential_backoff[1.0-None-None-None]",
                "covers": [
                    "retry_reloaded.backoff.ExponentialBackOff.__init__ - basic instantiation without jitter or max_delay",
                    "retry_reloaded.backoff.ExponentialBackOff.delay - getting exponentially increasing delay",
                    "retry_reloaded.backoff.ExponentialBackOff.reset - resetting delay calculation"
                ]
            },
            {
                "test_id": "tests/test_backoff.py::test_random_uniform_backoff[1.0-0.5-2.0]",
                "covers": [
                    "retry_reloaded.backoff.RandomUniformBackOff.__init__ - instantiation with base, min, and max delay",
                    "retry_reloaded.backoff.RandomUniformBackOff.delay - getting random delay within range (and base delay first)"
                ]
            },
            {
                "test_id": "tests/test_retry.py::test_maximum_retries_reached",
                "covers": [
                    "retry_reloaded.retry.retry - max_retries parameter and behavior",
                    "retry_reloaded._exceptions.MaxRetriesException - raising on max retries reached"
                ]
            },
            {
                "test_id": "tests/test_retry.py::test_timeout",
                "covers": [
                    "retry_reloaded.retry.retry - timeout parameter and behavior",
                    "retry_reloaded._exceptions.RetriesTimeoutException - raising on timeout",
                    "retry_reloaded.backoff.FixedBackOff - usage as backoff strategy in retry"
                ]
            },
            {
                "test_id": "tests/test_retry.py::test_deadline",
                "covers": [
                    "retry_reloaded.retry.retry - deadline parameter and behavior",
                    "retry_reloaded._exceptions.RetriesDeadlineException - raising on deadline",
                    "retry_reloaded.backoff.FixedBackOff - usage as backoff strategy in retry"
                ]
            },
            {
                "test_id": "tests/test_retry.py::test_failure_callback_called",
                "covers": [
                    "retry_reloaded.retry.retry - failure_callback parameter functionality"
                ]
            },
            {
                "test_id": "tests/test_retry.py::test_successful_retry_callback_called",
                "covers": [
                    "retry_reloaded.retry.retry - successful_retry_callback parameter functionality"
                ]
            },
            {
                "test_id": "tests/test_retry.py::test_retry_callback_called",
                "covers": [
                    "retry_reloaded.retry.retry - retry_callback parameter functionality"
                ]
            },
            {
                "test_id": "tests/test_retry.py::test_reraise_exception_true",
                "covers": [
                    "retry_reloaded.retry.retry - reraise_exception=True parameter functionality"
                ]
            },
            {
                "test_id": "tests/test_retry.py::test_retry_on_mixed_exclusions",
                "covers": [
                    "retry_reloaded.retry.retry - exceptions and excluded_exceptions parameters interaction"
                ]
            }
        ]
    },
    {
        "idx": 65129,
        "repo_name": "sr-murthy_continuedfractions",
        "url": "https://github.com/sr-murthy/continuedfractions",
        "description": "Object-oriented continued fractions with Python.",
        "stars": 5,
        "forks": 0,
        "language": "python",
        "size": 2732,
        "created_at": "2024-02-11T23:07:26+00:00",
        "updated_at": "2025-04-19T17:18:35+00:00",
        "pypi_info": {
            "name": "continuedfractions",
            "version": "0.20.1",
            "url": "https://files.pythonhosted.org/packages/75/10/0990b402b64816f832b2fc40d033b0ae7eac5056ba6cb23de05843af6791/continuedfractions-0.20.1.tar.gz"
        },
        "judge_info": {
            "language": "python",
            "is_good_project": false,
            "reason": "",
            "python_file_num": 10,
            "comment_ratio": 0.4329896907216495,
            "pyfile_content_length": 194211,
            "pyfile_code_lines": 5238,
            "test_file_exist": true,
            "test_file_content_length": 67783,
            "pytest_framework": true,
            "test_case_num": 45,
            "metadata_path": [
                "pyproject.toml"
            ],
            "readme_content_length": 3224,
            "llm_reason": "Positive aspects: The project is a self-contained mathematical library with clear, well-defined functionality based on established number theory concepts (continued fractions, Farey sequences, etc.). It requires no internet, external APIs, or complex services for its core logic or testing, making it suitable for a constrained AI environment. It has extensive unit tests using pytest (and sympy for verification), enabling programmatic verification of the AI's output. The project is purely code-based (no GUI) and its complexity seems appropriate (Medium difficulty) for an AI to replicate from scratch within a reasonable timeframe  involving non-trivial algorithms and OOP design but not requiring novel research. Negative aspects: The primary challenge lies in correctly implementing the mathematical algorithms, which requires some domain understanding beyond basic programming, although the concepts are standard. The reliance on sympy in tests needs to be managed in the benchmark setup, but it doesn't affect the core library's self-containment.",
            "llm_project_type": "Mathematical library / Number theory utility library",
            "llm_rating": 85,
            "llm_difficulty": "Medium"
        },
        "tests": {
            "repo_name": "sr-murthy_continuedfractions",
            "finish_test": true,
            "test_case_result": {
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements0-expected0]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements3]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf15-cf25-1-expected_right_mediant5]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand10-expected10-expected_elements10]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements1-expected1]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[4-4-expected_semiconvergent9]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand6-expected6-expected_elements6]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs16-expected_fraction_obj16-expected_elements16-3-expected_counter16-expected_khinchin_mean16-expected_convergents16-expected_ref_right_order2_mediant16-expected_ref_left_order2_mediant16-expected_ref_simple_mediant16-3.245-expected_decimal_value16]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance9-new_elements9-expected_comparative_instance9]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__invalid_elements__value_error_raised[instance0-invalid_elements0]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements4]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements5]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand7-expected7-expected_elements7]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand8-expected8-expected_elements8]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__invalid_elements__value_error_raised[instance1-invalid_elements1]": "passed",
                "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__invalid_elements__value_error_raised[elements2]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__rational_operations": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand0-expected0-expected_elements0]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance5-new_elements5-expected_comparative_instance5]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance6-new_elements6-expected_comparative_instance6]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs4-expected_fraction_obj4-expected_elements4-4-expected_counter4-expected_khinchin_mean4-expected_convergents4-expected_ref_right_order2_mediant4-expected_ref_left_order2_mediant4-expected_ref_simple_mediant4--3.245-expected_decimal_value4]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[1--1]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[0-0]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[1-0]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance2-tail_elements2-expected_comparative_instance2]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance3-tail_elements3-expected_comparative_instance3]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[3-3-expected_semiconvergent5]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf19-cf29-1000000-expected_right_mediant9]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf10-cf20-expected_simple_mediant0]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf11-cf21-expected_simple_mediant1]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf13-cf23-expected_simple_mediant3]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-5.25-expected26]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x27-expected27]": "passed",
                "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__invalid_elements__value_error_raised[elements0]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance1-new_elements1-expected_comparative_instance1]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance2-new_elements2-expected_comparative_instance2]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance4-tail_elements4-expected_comparative_instance4]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[1.5-expected6]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand11-expected11-expected_elements11]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand12-expected12-expected_elements12]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand14-expected14-expected_elements14]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements4-expected4]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance3-new_elements3-expected_comparative_instance3]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance7-new_elements7-expected_comparative_instance7]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r10-elements10]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs17-expected_fraction_obj17-expected_elements17-1-expected_counter17-expected_khinchin_mean17-expected_convergents17-expected_ref_right_order2_mediant17-expected_ref_left_order2_mediant17-expected_ref_simple_mediant17-0.1-expected_decimal_value17]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements5-expected5]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements6-expected6]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r11-elements11]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[5000-expected0]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[4-1-expected_semiconvergent6]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[4-2-expected_semiconvergent7]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[-1-1]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[5-1]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs20-expected_fraction_obj20-expected_elements20-12-expected_counter20-expected_khinchin_mean20-expected_convergents20-expected_ref_right_order2_mediant20-expected_ref_left_order2_mediant20-expected_ref_simple_mediant20-0.7271927710843373-expected_decimal_value20]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs18-expected_fraction_obj18-expected_elements18-1-expected_counter18-expected_khinchin_mean18-expected_convergents18-expected_ref_right_order2_mediant18-expected_ref_left_order2_mediant18-expected_ref_simple_mediant18-0.05-expected_decimal_value18]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__invalid_elements__value_error_raised[instance1-invalid_elements1]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs5-expected_fraction_obj5-expected_elements5-3-expected_counter5-expected_khinchin_mean5-expected_convergents5-expected_ref_right_order2_mediant5-expected_ref_left_order2_mediant5-expected_ref_simple_mediant5-3.245-expected_decimal_value5]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[-1-not an int]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[0-not an int]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[1-not an int]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf17-cf27-expected_simple_mediant7]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-0.3333-expected18]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-0.3333-expected19]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x20-expected20]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[0-1]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs8-expected_fraction_obj8-expected_elements8-2-expected_counter8-expected_khinchin_mean8-expected_convergents8-expected_ref_right_order2_mediant8-expected_ref_left_order2_mediant8-expected_ref_simple_mediant8--5.25-expected_decimal_value8]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs9-expected_fraction_obj9-expected_elements9-0-expected_counter9-None-expected_convergents9-expected_ref_right_order2_mediant9-expected_ref_left_order2_mediant9-expected_ref_simple_mediant9-123456789.0-expected_decimal_value9]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[not an int--1]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[not an int-0]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__invalid_elements__value_error_raised[instance3-invalid_elements3]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__invalid_elements__value_error_raised[instance4-invalid_elements4]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements0]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x10-expected10]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-3.245-expected11]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-3.245-expected12]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements11]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements12]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__invalid_elements__value_error_raised[instance2-invalid_elements2]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__invalid_elements__value_error_raised[instance3-invalid_elements3]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x7-expected7]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[3.245-expected8]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand2-expected2-expected_elements2]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance0-tail_elements0-expected_comparative_instance0]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance6-tail_elements6-expected_comparative_instance6]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance7-tail_elements7-expected_comparative_instance7]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance8-tail_elements8-expected_comparative_instance8]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs0-expected_fraction_obj0-expected_elements0-1-expected_counter0-expected_khinchin_mean0-expected_convergents0-expected_ref_right_order2_mediant0-expected_ref_left_order2_mediant0-expected_ref_simple_mediant0-1.5-expected_decimal_value0]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf19-cf29-2-expected_left_mediant9]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand15-expected15-expected_elements15]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r0-elements0]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf14-cf24-expected_simple_mediant4]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf15-cf25-expected_simple_mediant5]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf15-cf25-1-expected_left_mediant5]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[5.25-expected22]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[5000.0-expected2]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x3-expected3]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[1.5-expected4]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r2-elements2]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand3-expected3-expected_elements3]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements2-expected2]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs10-expected_fraction_obj10-expected_elements10-2-expected_counter10-expected_khinchin_mean10-expected_convergents10-expected_ref_right_order2_mediant10-expected_ref_left_order2_mediant10-expected_ref_simple_mediant10-0.3-expected_decimal_value10]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand4-expected4-expected_elements4]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf11-cf21-2-expected_right_mediant1]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[2-1-expected_semiconvergent1]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf113-cf213-3-expected_left_mediant13]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements13]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf16-cf26-2-expected_left_mediant6]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf17-cf27-3-expected_left_mediant7]": "passed",
                "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements7-fraction7]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements1]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements7]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r6-elements6]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r7-elements7]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r8-elements8]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements8]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements9]": "passed",
                "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements8-fraction8]": "passed",
                "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements9-fraction9]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[2-2-expected_semiconvergent2]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x23-expected23]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x24-expected24]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf11-cf21-2-expected_left_mediant1]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf12-cf22-3-expected_left_mediant2]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf13-cf23-1-expected_left_mediant3]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[3-1-expected_semiconvergent3]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs1-expected_fraction_obj1-expected_elements1-1-expected_counter1-expected_khinchin_mean1-expected_convergents1-expected_ref_right_order2_mediant1-expected_ref_left_order2_mediant1-expected_ref_simple_mediant1-1.5-expected_decimal_value1]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf16-cf26-1-expected_right_mediant6]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf17-cf27-1-expected_right_mediant7]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf12-cf22-3-expected_right_mediant2]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r3-elements3]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements7]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements8]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements9]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r4-elements4]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements7]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements8]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements15]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs6-expected_fraction_obj6-expected_elements6-2-expected_counter6-expected_khinchin_mean6-expected_convergents6-expected_ref_right_order2_mediant6-expected_ref_left_order2_mediant6-expected_ref_simple_mediant6-0.3333-expected_decimal_value6]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements4-expected_convergents4]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements5-expected_convergents5]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf114-cf214-1-expected_left_mediant14]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements11]": "passed",
                "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational115-rational215-1-expected_mediant15]": "passed",
                "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational116-rational216-2-expected_mediant16]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs2-expected_fraction_obj2-expected_elements2-0-expected_counter2-None-expected_convergents2-expected_ref_right_order2_mediant2-expected_ref_left_order2_mediant2-expected_ref_simple_mediant2--5000.0-expected_decimal_value2]": "passed",
                "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational15-rational25-right-1-expected_mediant5]": "passed",
                "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational16-rational26-right-1-expected_mediant6]": "passed",
                "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements3-fraction3]": "passed",
                "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements4-fraction4]": "passed",
                "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements5-fraction5]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs12-expected_fraction_obj12-expected_elements12-4-expected_counter12-expected_khinchin_mean12-expected_convergents12-expected_ref_right_order2_mediant12-expected_ref_left_order2_mediant12-expected_ref_simple_mediant12--3.245-expected_decimal_value12]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[1-elements3]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[-1-elements4]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[3-elements5]": "passed",
                "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[1-elements0]": "passed",
                "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[1-elements1]": "passed",
                "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[1-elements2]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[1-elements7]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[1-elements8]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[2-elements9]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements3]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements4]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements5]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements6-expected_convergents6]": "passed",
                "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational17-rational27-2-expected_mediant7]": "passed",
                "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational18-rational28-3-expected_mediant8]": "passed",
                "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational19-rational29-10-expected_mediant9]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements3]": "passed",
                "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[1-elements8]": "passed",
                "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[2-elements9]": "passed",
                "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[1-elements0-expected_convergent0]": "passed",
                "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational17-rational27-right-1-expected_mediant7]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements11]": "passed",
                "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational111-rational211-2-expected_mediant11]": "passed",
                "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational112-rational212-2-expected_mediant12]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[2-expected_coprime_integers1]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[3-expected_coprime_integers2]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[4-expected_coprime_integers3]": "passed",
                "tests/units/test_lib.py::TestMediant::test_mediant__invalid_dir_or_order__value_error_raised[rational15-rational25-not right-0]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[3-1-None-expected_coprime_integers3]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[3-2-None-expected_coprime_integers4]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[3-1-3-expected_coprime_integers5]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements4]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements5]": "passed",
                "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational19-rational29-right-1000000-expected_mediant9]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__invalid_args__raises_value_error[not an integer-1-None]": "passed",
                "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational11-rational21-right-2-expected_mediant1]": "passed",
                "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational10-rational20-1-expected_mediant0]": "passed",
                "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational11-rational21-2-expected_mediant1]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements8-expected8]": "passed",
                "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational113-rational213-1-expected_mediant13]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements0-expected_convergents0]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements1-expected_convergents1]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements2-expected_convergents2]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements9-expected9]": "passed",
                "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational13-rational23-1-expected_mediant3]": "passed",
                "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational14-rational24-1-expected_mediant4]": "passed",
                "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational15-rational25-2-expected_mediant5]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[0-elements1-expected_remainder1]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[0-elements2-expected_remainder2]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[1-elements3-expected_remainder3]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements8-expected_convergents8]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[1-elements0]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[1-elements1]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__invalid_args__raises_value_error[0.1-1-2]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__invalid_args__raises_value_error[3-0-2]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__invalid_args__raises_value_error[3-3-2]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[4-1-None-expected_coprime_integers7]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[4-2-None-expected_coprime_integers8]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[4-3-None-expected_coprime_integers9]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf110-cf210-3-expected_left_mediant10]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements10-expected10]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf115-cf215-1000000-expected_left_mediant15]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-649/200-expected14]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[3.245-expected15]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf111-cf211-1-expected_left_mediant11]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[10-expected_coprime_integers9]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[1-1-None-expected_coprime_integers0]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[2-1-None-expected_coprime_integers1]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[0.3333-expected16]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[4-2-4-expected_coprime_integers11]": "passed",
                "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational12-rational22-right-3-expected_mediant2]": "passed",
                "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational13-rational23-right-1-expected_mediant3]": "passed",
                "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[3-elements10-expected_convergent10]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__invalid_args__raises_value_error[0-1-2]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements9]": "passed",
                "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements0-fraction0]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[4-2-3-expected_coprime_integers12]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-1-None-expected_coprime_integers13]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements0]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements1]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements12]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements13]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[6-expected_coprime_integers5]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[7-expected_coprime_integers6]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[8-expected_coprime_integers7]": "passed",
                "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements1-fraction1]": "passed",
                "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[2-elements6-expected_convergent6]": "passed",
                "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[3-elements7-expected_convergent7]": "passed",
                "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[0-elements8-expected_convergent8]": "passed",
                "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational117-rational217-1000000-expected_mediant17]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[4-elements13-expected_remainder13]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[0-elements5-expected_remainder5]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[0-elements9-expected_remainder9]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[1-elements10-expected_remainder10]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[2-elements11-expected_remainder11]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements7-expected_remainders7]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements8-expected_remainders8]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements9-expected_remainders9]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements0-expected_remainders0]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements0]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements1]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements1-expected_remainders1]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements3-expected_remainders3]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements4-expected_remainders4]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements5-expected_remainders5]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[1-elements6-expected_remainder6]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[2-elements7-expected_remainder7]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs13-expected_fraction_obj13-expected_elements13-0-expected_counter13-None-expected_convergents13-expected_ref_right_order2_mediant13-expected_ref_left_order2_mediant13-expected_ref_simple_mediant13-123456789.0-expected_decimal_value13]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-3-None-expected_coprime_integers15]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-4-None-expected_coprime_integers16]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf13-cf23-1-expected_right_mediant3]": "passed",
                "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[2-elements2-expected_convergent2]": "passed",
                "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[3-elements3-expected_convergent3]": "passed",
                "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[2-elements4-expected_convergent4]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements12]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements13]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-1-5-expected_coprime_integers17]": "passed",
                "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[-1-elements4]": "passed",
                "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[2-elements5]": "passed",
                "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[1-elements6]": "passed",
                "tests/units/test_lib.py::TestMediant::test_mediant__invalid_dir_or_order__value_error_raised[rational11-rational21-not left-1]": "passed",
                "tests/units/test_lib.py::TestMediant::test_mediant__invalid_dir_or_order__value_error_raised[rational12-rational22-right-0]": "passed",
                "tests/units/test_lib.py::TestMediant::test_mediant__invalid_dir_or_order__value_error_raised[rational13-rational23-not right-1]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-6-None-expected_coprime_integers35]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs14-expected_fraction_obj14-expected_elements14-1-expected_counter14-expected_khinchin_mean14-expected_convergents14-expected_ref_right_order2_mediant14-expected_ref_left_order2_mediant14-expected_ref_simple_mediant14-1.5-expected_decimal_value14]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-2-7-expected_coprime_integers51]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-2-None-expected_coprime_integers43]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-4-None-expected_coprime_integers59]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-5-None-expected_coprime_integers60]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-1-7-expected_coprime_integers36]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-2-7-expected_coprime_integers37]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-2-None-expected_coprime_integers31]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-3-None-expected_coprime_integers32]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-2-3-expected_coprime_integers55]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-6-None-expected_coprime_integers61]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-3-None-expected_coprime_integers23]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-4-None-expected_coprime_integers24]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-5-None-expected_coprime_integers25]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-8-None-expected_coprime_integers63]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-1-9-expected_coprime_integers64]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-9-expected_coprime_integers65]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-2-5-expected_coprime_integers39]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-2-4-expected_coprime_integers40]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-2-3-expected_coprime_integers41]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-7-expected_coprime_integers67]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-6-expected_coprime_integers68]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-5-expected_coprime_integers69]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-3-None-expected_coprime_integers44]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-4-None-expected_coprime_integers45]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-2-4-expected_coprime_integers19]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-2-3-expected_coprime_integers20]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-1-None-expected_coprime_integers21]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-6-None-expected_coprime_integers47]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-7-None-expected_coprime_integers48]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-1-8-expected_coprime_integers49]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-5-None-expected_coprime_integers76]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-6-None-expected_coprime_integers77]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-7-None-expected_coprime_integers78]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-1-10-expected_coprime_integers81]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-9-expected_coprime_integers82]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-8-expected_coprime_integers83]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-4-None-expected_coprime_integers33]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-3-expected_coprime_integers71]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-8-None-expected_coprime_integers79]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-2-5-expected_coprime_integers27]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-2-4-expected_coprime_integers28]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-2-3-expected_coprime_integers29]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-2-6-expected_coprime_integers52]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-2-5-expected_coprime_integers53]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-1-None-expected_coprime_integers72]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-None-expected_coprime_integers73]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-3-None-expected_coprime_integers74]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-5-expected_coprime_integers86]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-4-expected_coprime_integers87]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-7-expected_coprime_integers84]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-1-None-expected_coprime_integers56]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-None-expected_coprime_integers57]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search_root__invalid_args__raises_value_error[1-root3]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[2-root0-expected_pairs0]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[3-expected_totient_value2]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[9999-expected_totient_value17]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-3-expected_coprime_integers88]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[1-expected_totient_value0]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[100-expected_totient_value12]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[10000000-expected_totient_value27]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[10000001-expected_totient_value28]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__backtrack[8-visited2-expected_backtracked_tuple2]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__backtrack[10-visited3-expected_backtracked_tuple3]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search_root__invalid_args__raises_value_error[not an integer-root0]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search[10-expected_pairs5]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs[1-expected_pairs0]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[5]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[6]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[7]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[8]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[100001-expected_totient_value22]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[999]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[10]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[11]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[99]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[10-root4-expected_pairs4]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[2-root5-expected_pairs5]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[3-root6-expected_pairs6]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[4-expected_totient_value3]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[5-expected_totient_value4]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs[2-expected_pairs1]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs[3-expected_pairs2]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs[4-expected_pairs3]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[10-root9-expected_pairs9]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs[10-expected_pairs5]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[101-expected_totient_value13]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search[1-expected_pairs0]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search_root__invalid_args__raises_value_error[1-root1]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[6-expected_totient_value5]": "passed",
                "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence[4-expected_sequence3]": "passed",
                "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence__invalid_args__raises_value_error[n2]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[8-expected_totient_value7]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__invalid_args__raises_value_error[n0]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[4-root7-expected_pairs7]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[3-root1-expected_pairs1]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[10000-expected_totient_value18]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[100]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search__invalid_args__raises_value_error[n0]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[999-expected_totient_value14]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[1]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search[2-expected_pairs1]": "passed",
                "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence[5-expected_sequence4]": "passed",
                "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence__invalid_args__raises_value_error[n3]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[9-expected_totient_value8]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__invalid_args__raises_value_error[n1]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[10001-expected_totient_value19]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[4-root2-expected_pairs2]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[1000-expected_totient_value15]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search__invalid_args__raises_value_error[n1]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[2]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search[3-expected_pairs2]": "passed",
                "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence[10-expected_sequence5]": "passed",
                "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence[1-expected_sequence0]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[10-expected_totient_value9]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__invalid_args__raises_value_error[n2]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search__invalid_args__raises_value_error[n2]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[3]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs19-expected_fraction_obj19-expected_elements19-1-expected_counter19-expected_khinchin_mean19-expected_convergents19-expected_ref_right_order2_mediant19-expected_ref_left_order2_mediant19-expected_ref_simple_mediant19-0.25-expected_decimal_value19]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf16-cf26-expected_simple_mediant6]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance0-new_elements0-expected_comparative_instance0]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__invalid_elements__value_error_raised[instance2-invalid_elements2]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[4-3-expected_semiconvergent8]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search[4-expected_pairs3]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[5-root8-expected_pairs8]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf112-cf212-2-expected_left_mediant12]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf12-cf22-expected_simple_mediant2]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs3-expected_fraction_obj3-expected_elements3-3-expected_counter3-expected_khinchin_mean3-expected_convergents3-expected_ref_right_order2_mediant3-expected_ref_left_order2_mediant3-expected_ref_simple_mediant3-3.245-expected_decimal_value3]": "passed",
                "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence[2-expected_sequence1]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance4-new_elements4-expected_comparative_instance4]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf10-cf20-1-expected_right_mediant0]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-6-expected_coprime_integers85]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search_root__invalid_args__raises_value_error[not an integer-root2]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements7-expected7]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements6]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[7-expected_totient_value6]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__invalid_elements__value_error_raised[instance0-invalid_elements0]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[1001-expected_totient_value16]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance8-new_elements8-expected_comparative_instance8]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__invalid_args__raises_value_error[n3]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs[5-expected_pairs4]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements14]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand13-expected13-expected_elements13]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[5-root3-expected_pairs3]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand1-expected1-expected_elements1]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[9]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[-1--1]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r5-elements5]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf10-cf20-1-expected_left_mediant0]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf14-cf24-1-expected_left_mediant4]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r1-elements1]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs7-expected_fraction_obj7-expected_elements7-3-expected_counter7-expected_khinchin_mean7-expected_convergents7-expected_ref_right_order2_mediant7-expected_ref_left_order2_mediant7-expected_ref_simple_mediant7--0.3333-expected_decimal_value7]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements10]": "passed",
                "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements2-fraction2]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[not an int-1]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[1-1-expected_semiconvergent0]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[3.245-expected9]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[1-elements2]": "passed",
                "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__invalid_elements__value_error_raised[elements1]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance5-tail_elements5-expected_comparative_instance5]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance1-tail_elements1-expected_comparative_instance1]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-5.25-expected25]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand9-expected9-expected_elements9]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs15-expected_fraction_obj15-expected_elements15-1-expected_counter15-expected_khinchin_mean15-expected_convergents15-expected_ref_right_order2_mediant15-expected_ref_left_order2_mediant15-expected_ref_simple_mediant15--3.75-expected_decimal_value15]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs11-expected_fraction_obj11-expected_elements11-1-expected_counter11-expected_khinchin_mean11-expected_convergents11-expected_ref_right_order2_mediant11-expected_ref_left_order2_mediant11-expected_ref_simple_mediant11-0.1-expected_decimal_value11]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements2]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[0.3333-expected17]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements3-expected3]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements10]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf18-cf28-1-expected_left_mediant8]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[2-expected_totient_value1]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-5000-expected1]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[101]": "passed",
                "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[1-elements7]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf14-cf24-1-expected_right_mediant4]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x13-expected13]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements3-expected_convergents3]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r9-elements9]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf18-cf28-1-expected_right_mediant8]": "passed",
                "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements10-fraction10]": "passed",
                "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[1-elements3]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[5.25-expected21]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[not an int-not an int]": "passed",
                "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[4-elements9-expected_convergent9]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements7-expected_convergents7]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements2]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[3-2-expected_semiconvergent4]": "passed",
                "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[1-elements5-expected_convergent5]": "passed",
                "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements6-fraction6]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements6]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[0-elements0-expected_remainder0]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[0-elements4-expected_remainder4]": "passed",
                "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[0-elements1-expected_convergent1]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements10]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements6]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements2]": "passed",
                "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand5-expected5-expected_elements5]": "passed",
                "tests/units/test_lib.py::TestMediant::test_mediant__invalid_dir_or_order__value_error_raised[rational14-rational24-not left-0]": "passed",
                "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements14]": "passed",
                "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[3/2-expected5]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements2-expected_remainders2]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[3-elements8-expected_remainder8]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements14]": "passed",
                "tests/units/test_lib.py::TestMediant::test_mediant__invalid_dir_or_order__value_error_raised[rational10-rational20-left-0]": "passed",
                "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational10-rational20-right-1-expected_mediant0]": "passed",
                "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements6-expected_remainders6]": "passed",
                "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational114-rational214-2-expected_mediant14]": "passed",
                "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational110-rational210-1-expected_mediant10]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[5-expected_coprime_integers4]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[1-expected_coprime_integers0]": "passed",
                "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational12-rational22-3-expected_mediant2]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[3-elements12-expected_remainder12]": "passed",
                "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational18-rational28-right-1-expected_mediant8]": "passed",
                "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[1-elements6]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[2-1-2-expected_coprime_integers2]": "passed",
                "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational16-rational26-1-expected_mediant6]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[9-expected_coprime_integers8]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__invalid_args__raises_value_error[-1-1-2]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[3-2-3-expected_coprime_integers6]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-1-None-expected_coprime_integers30]": "passed",
                "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational14-rational24-right-1-expected_mediant4]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-2-5-expected_coprime_integers18]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-2-None-expected_coprime_integers22]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-1-None-expected_coprime_integers42]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-1-6-expected_coprime_integers26]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-5-None-expected_coprime_integers34]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-5-None-expected_coprime_integers46]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[4-1-4-expected_coprime_integers10]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-2-6-expected_coprime_integers38]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-2-8-expected_coprime_integers50]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-2-None-expected_coprime_integers14]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-2-4-expected_coprime_integers54]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-3-None-expected_coprime_integers58]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-4-expected_coprime_integers70]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-8-expected_coprime_integers66]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-7-None-expected_coprime_integers62]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search[5-expected_pairs4]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-4-None-expected_coprime_integers75]": "passed",
                "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence[3-expected_sequence2]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search__invalid_args__raises_value_error[n3]": "passed",
                "tests/units/test_utils.py::TestNamedCallableProxy::test_NamedCallableProxy__creation_and_initialisation[<lambda>-x |--> x^2-expected_callable_proxy0]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-9-None-expected_coprime_integers80]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__backtrack[5-visited1-expected_backtracked_tuple1]": "passed",
                "tests/units/test_utils.py::TestNamedCallableProxy::test_NamedCallableProxy__creation_and_initialisation[<lambda>-None-expected_callable_proxy1]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[99-expected_totient_value11]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[1000000-expected_totient_value24]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[999999-expected_totient_value23]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[100000-expected_totient_value21]": "passed",
                "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence__invalid_args__raises_value_error[n1]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__backtrack[3-visited0-expected_backtracked_tuple0]": "passed",
                "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence__invalid_args__raises_value_error[n0]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[4]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[9999999-expected_totient_value26]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[1000001-expected_totient_value25]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[1001]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[99999-expected_totient_value20]": "passed",
                "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[11-expected_totient_value10]": "passed",
                "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[1000]": "passed",
                "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__creation_and_initialisation": "passed"
            },
            "success_count": 535,
            "failed_count": 0,
            "error_count": 0,
            "skipped_count": 0,
            "unknown_count": 0,
            "total_count": 535,
            "success_rate": 1.0,
            "coverage_report": {
                "covered_lines": 375,
                "num_statements": 375,
                "percent_covered": 100.0,
                "percent_covered_display": "100",
                "missing_lines": 0,
                "excluded_lines": 91,
                "num_branches": 104,
                "num_partial_branches": 0,
                "covered_branches": 104,
                "missing_branches": 0
            },
            "coverage_result": {}
        },
        "codelines_count": 5238,
        "codefiles_count": 10,
        "code_length": 194211,
        "test_files_count": 4,
        "test_code_length": 67783,
        "class_diagram": "@startuml\nclass TestCoprimeIntegers {\n    test_coprime_integers__invalid_args__raises_value_error(n, start, stop): void\n    test_coprime_integers__default_start_and_stop_values(n, expected_coprime_integers): void\n    test_coprime_integers__custom_start_and_stop_values(n, start, stop, expected_coprime_integers): void\n    test_coprime_integers__verify_against_totient_value(n, expected_totient_value): void\n}\nclass TestKSRMTree {\n    test_KSRMTree__creation_and_initialisation(): void\n    test_KSRMTree__backtrack(n, visited, expected_backtracked_tuple): void\n    test_KSRMTree_search_root__invalid_args__raises_value_error(n, root): void\n    test_KSRMTree__search_root(n, root, expected_pairs): void\n    test_KSRMTree_search__invalid_args__raises_value_error(n): void\n    test_KSRMTree_search(n, expected_pairs): void\n}\nclass TestCoprimePairs {\n    test_coprime_pairs__invalid_args__raises_value_error(n): void\n    test_coprime_pairs(n, expected_pairs): void\n    test_coprime_pairs__verify_against_summatory_totient_value(n): void\n}\nclass TestFareySequence {\n    test_farey_sequence__invalid_args__raises_value_error(n): void\n    test_farey_sequence(n, expected_sequence): void\n}\nclass TestContinuedFractionRational {\n    test_continued_fraction_rational__valid_integers__correct_elements_generated(r, elements): void\n}\nclass TestContinuedFractionReal {\n    test_continued_fraction_real__valid_inputs__correct_elements_generated(x, expected): void\n}\nclass TestFractionFromElements {\n    test_fraction_from_elements__invalid_elements__value_error_raised(elements): void\n    test_fraction_from_elements__valid_elements__correct_fraction_returned(elements, fraction): void\n}\nclass TestConvergent {\n    test_convergent__invalid_elements__value_error_raised(k, elements): void\n    test_convergent__valid_elements__correct_convergent_returned(k, elements, expected_convergent): void\n}\nclass TestConvergents {\n    test_convergents__invalid_elements__value_error_raised(invalid_elements): void\n    test_convergents__valid_elements__correct_convergents_generated(in_elements, expected_convergents): void\n}\nclass TestRemainder {\n    test_remainder__invalid_elements__value_error_raised(k, elements): void\n    test_remainder__valid_elements__correct_remainder_returned(k, elements, expected_remainder): void\n}\nclass TestRemainders {\n    test_remainders__invalid_elements__value_error_raised(invalid_elements): void\n    test_remainders__valid_elements__correct_remainders_generated(in_elements, expected_remainders): void\n}\nclass TestMediant {\n    test_mediant__invalid_dir_or_order__value_error_raised(rational1, rational2, dir, k): void\n    test_left_mediant__two_ordered_rationals__correct_mediant_returned(rational1, rational2, k, expected_mediant): void\n    test_right_mediant__two_ordered_rationals__correct_mediant_returned(rational1, rational2, dir_, k, expected_mediant): void\n}\nclass TestNamedCallableProxy {\n    test_NamedCallableProxy__creation_and_initialisation(callable_, name, expected_callable_proxy): void\n}\nclass TestContinuedFraction {\n    test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised(valid_inputs, expected_fraction_obj, expected_elements, expected_order, expected_counter, expected_khinchin_mean, expected_convergents, expected_ref_right_order2_mediant, expected_ref_left_order2_mediant, expected_ref_simple_mediant, expected_float_value, expected_decimal_value): void\n    test_ContinuedFraction__from_elements__invalid_elements__value_error_raised(invalid_elements): void\n    test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned(elements, expected): void\n    test_ContinuedFraction__extend__invalid_elements__value_error_raised(instance, invalid_elements): void\n    test_ContinuedFraction__extend__valid_elements__correctly_extended(instance, new_elements, expected_comparative_instance): void\n    test_ContinuedFraction__truncate__invalid_elements__value_error_raised(instance, invalid_elements): void\n    test_ContinuedFraction__truncate__valid_elements__correctly_truncated(instance, tail_elements, expected_comparative_instance): void\n    test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned(cf1, cf2, k, expected_left_mediant): void\n    test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned(cf1, cf2, k, expected_right_mediant): void\n    test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned(cf1, cf2, expected_simple_mediant): void\n    test_ContinuedFraction__semiconvergent__invalid_args(k, m): void\n    test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned(k, m, expected_semiconvergent): void\n    test_ContinuedFraction__rational_operations(): void\n    test___neg__(operand, expected, expected_elements): void\n}\nclass NamedCallableProxy {\n    __slots__: Unknown\n    _callable: Callable\n    _name: str\n    __new__(): NamedCallableProxy\n    __repr__(): str\n    __eq__(other): bool\n    __call__(): Any\n}\nclass ContinuedFraction {\n    __slots__: Unknown\n    _elements: tuple[int]\n    __new__(cls): ContinuedFraction\n    from_elements(cls): ContinuedFraction\n    extend(): Unknown\n    truncate(): Unknown\n    __eq__(): bool\n    __hash__(): int\n    __add__(): void\n    __radd__(): void\n    __sub__(): void\n    __rsub__(): void\n    __mul__(): void\n    __rmul__(): void\n    __truediv__(): void\n    __rtruediv__(): void\n    __floordiv__(): void\n    __rfloordiv__(): void\n    __divmod__(): void\n    __rdivmod__(): void\n    __pow__(): ContinuedFraction\n    __rpow__(): void\n    __pos__(): ContinuedFraction\n    __neg__(): ContinuedFraction\n    __abs__(): ContinuedFraction\n    as_float(): float\n    as_decimal(): Decimal\n    elements(): tuple[int]\n    order(): int\n    counter(): collections.Counter\n    khinchin_mean(): Unknown\n    convergent(): ContinuedFraction\n    convergents(): Generator[tuple[int, ContinuedFraction], Unknown, Unknown]\n    even_convergents(): Generator[tuple[int, ContinuedFraction], Unknown, Unknown]\n    odd_convergents(): Generator[tuple[int, ContinuedFraction], Unknown, Unknown]\n    semiconvergent(): ContinuedFraction\n    remainder(): ContinuedFraction\n    remainders(): Generator[tuple[int, ContinuedFraction], Unknown, Unknown]\n    left_mediant(): ContinuedFraction\n    right_mediant(): ContinuedFraction\n    mediant(): ContinuedFraction\n}\nclass KSRMTree {\n    __slots__: Unknown\n    _roots: tuple[KSRMNode, KSRMNode]\n    _branches: tuple[KSRMBranch]\n    __new__(cls): KSRMTree\n    roots(): Literal[Unknown]\n    branches(): tuple[KSRMBranch]\n    _backtrack(): tuple[KSRMNode, KSRMBranch, int, KSRMBranch]\n    search_root(): Generator[KSRMNode, Unknown, Unknown]\n    search(): Generator[KSRMNode, Unknown, Unknown]\n}\nContinuedFraction --> ContinuedFraction\nTestNamedCallableProxy --> NamedCallableProxy\nKSRMTree --> KSRMTree\nNamedCallableProxy --> NamedCallableProxy\nTestContinuedFraction --> ContinuedFraction\nTestKSRMTree --> KSRMTree\nContinuedFraction ..> ContinuedFraction\nTestNamedCallableProxy ..> NamedCallableProxy\nTestContinuedFraction ..> ContinuedFraction\nKSRMTree ..> KSRMTree\nTestKSRMTree ..> KSRMTree\nNamedCallableProxy ..> NamedCallableProxy\n@enduml",
        "structure": [
            {
                "file": "tests/units/test_sequences.py",
                "functions": [],
                "classes": [
                    {
                        "name": "TestCoprimeIntegers",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_coprime_integers__invalid_args__raises_value_error",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "n",
                                    "start",
                                    "stop"
                                ]
                            },
                            {
                                "name": "test_coprime_integers__default_start_and_stop_values",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "n",
                                    "expected_coprime_integers"
                                ]
                            },
                            {
                                "name": "test_coprime_integers__custom_start_and_stop_values",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "n",
                                    "start",
                                    "stop",
                                    "expected_coprime_integers"
                                ]
                            },
                            {
                                "name": "test_coprime_integers__verify_against_totient_value",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "n",
                                    "expected_totient_value"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TestKSRMTree",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_KSRMTree__creation_and_initialisation",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_KSRMTree__backtrack",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "n",
                                    "visited",
                                    "expected_backtracked_tuple"
                                ]
                            },
                            {
                                "name": "test_KSRMTree_search_root__invalid_args__raises_value_error",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "n",
                                    "root"
                                ]
                            },
                            {
                                "name": "test_KSRMTree__search_root",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "n",
                                    "root",
                                    "expected_pairs"
                                ]
                            },
                            {
                                "name": "test_KSRMTree_search__invalid_args__raises_value_error",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "n"
                                ]
                            },
                            {
                                "name": "test_KSRMTree_search",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "n",
                                    "expected_pairs"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TestCoprimePairs",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_coprime_pairs__invalid_args__raises_value_error",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "n"
                                ]
                            },
                            {
                                "name": "test_coprime_pairs",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "n",
                                    "expected_pairs"
                                ]
                            },
                            {
                                "name": "test_coprime_pairs__verify_against_summatory_totient_value",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "n"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TestFareySequence",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_farey_sequence__invalid_args__raises_value_error",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "n"
                                ]
                            },
                            {
                                "name": "test_farey_sequence",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "n",
                                    "expected_sequence"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/units/test_lib.py",
                "functions": [],
                "classes": [
                    {
                        "name": "TestContinuedFractionRational",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_continued_fraction_rational__valid_integers__correct_elements_generated",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "r",
                                    "elements"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TestContinuedFractionReal",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_continued_fraction_real__valid_inputs__correct_elements_generated",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "x",
                                    "expected"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TestFractionFromElements",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_fraction_from_elements__invalid_elements__value_error_raised",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "elements"
                                ]
                            },
                            {
                                "name": "test_fraction_from_elements__valid_elements__correct_fraction_returned",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "elements",
                                    "fraction"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TestConvergent",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_convergent__invalid_elements__value_error_raised",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "k",
                                    "elements"
                                ]
                            },
                            {
                                "name": "test_convergent__valid_elements__correct_convergent_returned",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "k",
                                    "elements",
                                    "expected_convergent"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TestConvergents",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_convergents__invalid_elements__value_error_raised",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "invalid_elements"
                                ]
                            },
                            {
                                "name": "test_convergents__valid_elements__correct_convergents_generated",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "in_elements",
                                    "expected_convergents"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TestRemainder",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_remainder__invalid_elements__value_error_raised",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "k",
                                    "elements"
                                ]
                            },
                            {
                                "name": "test_remainder__valid_elements__correct_remainder_returned",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "k",
                                    "elements",
                                    "expected_remainder"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TestRemainders",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_remainders__invalid_elements__value_error_raised",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "invalid_elements"
                                ]
                            },
                            {
                                "name": "test_remainders__valid_elements__correct_remainders_generated",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "in_elements",
                                    "expected_remainders"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TestMediant",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_mediant__invalid_dir_or_order__value_error_raised",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "rational1",
                                    "rational2",
                                    "dir",
                                    "k"
                                ]
                            },
                            {
                                "name": "test_left_mediant__two_ordered_rationals__correct_mediant_returned",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "rational1",
                                    "rational2",
                                    "k",
                                    "expected_mediant"
                                ]
                            },
                            {
                                "name": "test_right_mediant__two_ordered_rationals__correct_mediant_returned",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "rational1",
                                    "rational2",
                                    "dir_",
                                    "k",
                                    "expected_mediant"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/units/test_utils.py",
                "functions": [],
                "classes": [
                    {
                        "name": "TestNamedCallableProxy",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_NamedCallableProxy__creation_and_initialisation",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "callable_",
                                    "name",
                                    "expected_callable_proxy"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/units/test_continuedfraction.py",
                "functions": [],
                "classes": [
                    {
                        "name": "TestContinuedFraction",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "valid_inputs",
                                    "expected_fraction_obj",
                                    "expected_elements",
                                    "expected_order",
                                    "expected_counter",
                                    "expected_khinchin_mean",
                                    "expected_convergents",
                                    "expected_ref_right_order2_mediant",
                                    "expected_ref_left_order2_mediant",
                                    "expected_ref_simple_mediant",
                                    "expected_float_value",
                                    "expected_decimal_value"
                                ]
                            },
                            {
                                "name": "test_ContinuedFraction__from_elements__invalid_elements__value_error_raised",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "invalid_elements"
                                ]
                            },
                            {
                                "name": "test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "elements",
                                    "expected"
                                ]
                            },
                            {
                                "name": "test_ContinuedFraction__extend__invalid_elements__value_error_raised",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "instance",
                                    "invalid_elements"
                                ]
                            },
                            {
                                "name": "test_ContinuedFraction__extend__valid_elements__correctly_extended",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "instance",
                                    "new_elements",
                                    "expected_comparative_instance"
                                ]
                            },
                            {
                                "name": "test_ContinuedFraction__truncate__invalid_elements__value_error_raised",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "instance",
                                    "invalid_elements"
                                ]
                            },
                            {
                                "name": "test_ContinuedFraction__truncate__valid_elements__correctly_truncated",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "instance",
                                    "tail_elements",
                                    "expected_comparative_instance"
                                ]
                            },
                            {
                                "name": "test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "cf1",
                                    "cf2",
                                    "k",
                                    "expected_left_mediant"
                                ]
                            },
                            {
                                "name": "test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "cf1",
                                    "cf2",
                                    "k",
                                    "expected_right_mediant"
                                ]
                            },
                            {
                                "name": "test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "cf1",
                                    "cf2",
                                    "expected_simple_mediant"
                                ]
                            },
                            {
                                "name": "test_ContinuedFraction__semiconvergent__invalid_args",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "k",
                                    "m"
                                ]
                            },
                            {
                                "name": "test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "k",
                                    "m",
                                    "expected_semiconvergent"
                                ]
                            },
                            {
                                "name": "test_ContinuedFraction__rational_operations",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test___neg__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "operand",
                                    "expected",
                                    "expected_elements"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "docs/conf.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "src/continuedfractions/version.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "src/continuedfractions/lib.py",
                "functions": [
                    {
                        "name": "continued_fraction_rational",
                        "docstring": "Core continued fraction algorithm implementation which generates the ordered sequence of elements of the (finite) simple continued fraction of the given rational number.\n\nThe resulting sequence of elements, :math:`a_0,a_1,\\ldots a_n`, defines a simple continued fraction of the form:\n\n.. math::\n\n   a_0 + \\cfrac{1}{a_1 + \\cfrac{1}{a_2 + \\ddots\\cfrac{1}{a_{n - 1} + \\cfrac{1}{a_n}}}}\n\nwhich is also written more compactly as:\n\n.. math::\n\n   [a_0; a_1, a_2\\ldots, a_n]\n\nThe order of the continued fraction is said to be :math:`n`. If the last\nelement :math:`a_n = 1` the sequence can be rewritten as\n:math:`[a_0; a_1, a_2\\ldots, a_{n - 1} + 1]`, which is then unique as a\nsimple continued fraction representation of the rational number.\n\nNegative rational numbers can also be represented in this way, provided we\nuse the `Euclidean division lemma <https://en.wikipedia.org/wiki/Euclid%27s_lemma>`_.\nThis is described in more detail in the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/creating-continued-fractions.html#negative-continued-fractions>`_.\n\nFor a definition of \"continued fraction\", \"element\", \"order\",\n\"finite continued fraction\", \"simple continued fraction\", please consult\nthe `package documentation <https://continuedfractions.readthedocs.io/en/stable>`_,\nor any online resource such as `Wikipedia <https://en.wikipedia.org/wiki/Continued_fraction>`_,\nor suitable books on number theory.\n\nParameters\n----------\nfrac : `fractions.Fraction`\n    The rational number to represented as a simple continued fraction.\n\nYields\n------\nint\n    Elements of a unique simple continued fraction of the given rational\n    number.\n\nExamples\n--------\nA few examples are given below of how this function can be used.\n\n>>> for e in continued_fraction_rational(Fraction(649, 200)):\n...     print(e)\n... \n3\n4\n12\n4\n>>> list(continued_fraction_rational(Fraction(415, 93)))\n[4, 2, 6, 7]\n>>> list(continued_fraction_rational(Fraction(-649, 200)))\n[-4, 1, 3, 12, 4]\n>>> list(continued_fraction_rational(Fraction(123235, 334505)))\n[0, 2, 1, 2, 1, 1, 250, 1, 13]\n\nNotes\n-----\nEvery rational number has exactly two simple continued fractions, one of\nwhich has an additional element of :math:`1` as its last element,\ni.e. :math:`[a_0;a_1,a_2,\\ldots,a_{n - 1}, 1]`. But this form can be\nreduced by adding the :math:`1` to the second last element, :math:`a_{n - 1}`,\nproducing the shorter form :math:`[a_0;a_1,a_2,\\ldots, a_{n - 1} + 1]`,\nwhere the last element is now :math:`> 1`.\n\nThe simple continued fraction representation generated by this function is\nthe shorter version, and is thus unique.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "continued_fraction_real",
                        "docstring": "Generates a finite sequence of elements (coefficients) of a (simple) continued fraction of the given real number.\n\nThe result is a finite sequence even though the given number :math:`x` may\nbe irrational or not exactly representable as a real number. \n\nThe simple continued fraction representation of :math:`x` is a number of\nthe form\n\n.. math::\n\n   a_0 + \\cfrac{1}{a_1 + \\cfrac{1}{a_2 + \\ddots}}\n\nwhere :math:`a_0 = [x]` is the integer part of :math:`x`, and the\n:math:`a_1,a_2\\ldots` are the (non-negative) quotients obtained by a\nrepeated application of `Euclidean division <https://en.wikipedia.org/wiki/Euclidean_division>`_\nto the fractional part :math:`x - [x]`, which is called the remainder.\n\nIf the last element :math:`a_n = 1` the sequence can be rewritten as\n:math:`[a_0; a_1, a_2\\ldots, a_{n - 1} + 1]`.\n\nAs Python :py:class:`float` values, like all floating point\nimplementations, are `finite precision representations <https://docs.python.org/3/tutorial/floatingpoint.html>`_\nof real numbers, the resulting simple continued fraction  of :math:`x`\ngenerated by this function may be approximate, not exact, and also not\nnecessarily unique.\n\nFor non-rational real numbers it is best to pass :py:class:`decimal.Decimal`\nvalues, with the `context precision <https://docs.python.org/3.12/library/decimal.html#context-objects>`_\nset to the highest level possible.\n\nThe results for rational numbers are guaranteed to be exact however large\nthe number, subject to memory and hardware limitations of the running\nenvironment.\n\nInvalid values will generate an error in either the\n:py:class:`fractions.Fraction` or :py:class:`decimal.Decimal` classes -\nno errors are raised directly in the function itself.\n\nParameters\n----------\nx : int, float, str, decimal.Decimal\n    The real number to represent as a simple continued fraction.\n\nYields\n------\nint\n    Elements of a simple continued fraction of the given real number.\n\nExamples\n--------\nA few examples are given below of how this function can be used.\n\n>>> list(continued_fraction_real(5000))\n[5000]\n>>> list(continued_fraction_real(-5000.0))\n[-5000]\n>>> list(continued_fraction_real(2/5))\n[0, 2, 2, 1801439850948198]\n>>> list(continued_fraction_real('2/5'))\n[0, 2, 2]\n>>> list(continued_fraction_real('-1/3'))\n[-1, 1, 2]\n>>> list(continued_fraction_real(1/1j))\nTraceback (most recent call last):\n...\nTypeError: conversion from complex to Decimal is not supported\n>>> list(continued_fraction_real(\"not a numeric string\"))\nTraceback (most recent call last):\n...\ndecimal.InvalidOperation: [<class 'decimal.ConversionSyntax'>]\n>>> list(continued_fraction_real(-649/200))\n[-4, 1, 3, 12, 3, 1, 234562480591, 2, 5, 2]\n>>> list(continued_fraction_real('-649/200'))\n[-4, 1, 3, 12, 4]\n>>> list(continued_fraction_real('-649/-200'))\nTraceback (most recent call last):\n...\nValueError: Invalid literal for Fraction: '-649/-200'\n>>> list(continued_fraction_real(Decimal('0.3333')))\n[0, 3, 3333]",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "convergent",
                        "docstring": "Returns the :math:`k`-th convergent of a (simple) continued fraction from a sequence of its elements.\n\nGiven a (simple) continued fraction  :math:`[a_0;a_1,a_2,\\ldots]` the\n:math:`k`-th convergent is defined as:\n\n.. math::\n\n   C_k = a_0 + \\cfrac{1}{a_1 + \\cfrac{1}{a_2 \\ddots \\cfrac{1}{a_{k-1} + \\cfrac{1}{a_k}}}}\n\nThe result is a :py:class:`fractions.Fraction` instance.\n\nThe integer :math:`k` is called the order of the convergent, and if \n:math:`[a_0;a_1,a_2,\\ldots]` is finite of order :math:`n` then it has\nexactly :math:`n + 1` convergents :math:`C_0,C_1,C_2,\\ldots,C_n` where\nthe :math:`k`-th convergent :math:`C_k = \\frac{p_k}{q_k}` is given by\nthe recurrence relation:\n\n.. math::\n   \n   \\begin{align}\n   p_k &= a_kp_{k - 1} + p_{k - 2} \\\\\n   q_k &= a_kq_{k - 1} + q_{k - 2},        \\hskip{3em}    k \\geq 3\n   \\end{align}\n\nwhere :math:`p_0 = a_0`, :math:`q_0 = 1`, :math:`p_1 = p_1p_0 + 1`,\nand :math:`q_1 = p_1`.\n\nThis function is a faithful implementation of this algorithm.\n\nA :py:class:`ValueError` is raised if :math:`k` is not an integer or is an\ninteger greater than the number of elements, or if any of the elements are\nnot integers.\n\nParameters\n----------\nk : `int`\n    The order of the convergent. Must be a non-negative integer less than\n    the number of elements.\n\n*elements : `int`\n    A variable-length sequence of integer elements of a continued fraction.\n\nReturns\n-------\nfractions.Fraction\n    A rational fraction constructed from the given sequence of elements of\n    a continued fraction, representing the :math:`k`-order convergent of a\n    (finite) simple continued fraction as given by a sequence of elements.\n\nRaises\n------\nValueError\n    If :math:`k` is not a non-negative integer less than the number of\n    elements, or if any of the elements are not integers.\n\nExamples\n--------\n>>> convergent(0, 3, 4, 12, 4)\nFraction(3, 1)\n>>> convergent(1, 3, 4, 12, 4)\nFraction(13, 4)\n>>> convergent(2, 3, 4, 12, 4)\nFraction(159, 49)\n>>> convergent(3, 3, 4, 12, 4)\nFraction(649, 200)\n>>> convergent(3)\nTraceback (most recent call last):\n...\nValueError: `k` must be a non-negative integer not exceeding the order of \nthe continued fraction (number of tail elements), and the tail \nelements must all be positive integers.\n>>> convergent(-1, 3, 4, 12, 4)\nTraceback (most recent call last):\n...\nValueError: `k` must be a non-negative integer not exceeding the order of \nthe continued fraction (number of tail elements), and the tail \nelements must all be positive integers.\n>>> convergent(4, 3, 4, 12, 4)\nTraceback (most recent call last):\n...\nValueError: `k` must be a non-negative integer not exceeding the order of \nthe continued fraction (number of tail elements), and the tail \nelements must all be positive integers.",
                        "comments": null,
                        "args": [
                            "k"
                        ]
                    },
                    {
                        "name": "convergents",
                        "docstring": "Generates an (ordered) sequence of all convergents of a (simple) continued fraction from a sequence of its elements.\n\nIf :math:`n` is the order of the continued fraction represented by the\ngiven sequence of its elements then there are :math:`n + 1` convergents\n:math:`C_0, C_1, \\ldots, C_n`, and the function generates these in that\norder.\n\nSee the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/exploring-continued-fractions.html#convergents-and-rational-approximations>`_\nfor more details on convergents.\n\nParameters\n----------\n*elements : `int`\n    A variable-length sequence of integer elements of a (simple)\n    continued fraction.\n\nYields\n------\nfractions.Fraction\n    Each element generated is a :py:class:`fractions.Fraction` instance and\n    a :math:`k`-th convergent of the given continued fraction.\n\nRaises\n------\nValueError\n    If there are any non-integer elements, or the tail elements are not\n    positive integers.\n\nExamples\n--------\n>>> tuple(convergents(3))\n(Fraction(3, 1),)\n>>> tuple(convergents(3, 2))\n(Fraction(3, 1), Fraction(7, 2))\n>>> tuple(convergents(3, 4, 12, 4))\n(Fraction(3, 1), Fraction(13, 4), Fraction(159, 49), Fraction(649, 200))\n>>> tuple(convergents(-5, 1, 1, 6, 7))\n(Fraction(-5, 1), Fraction(-4, 1), Fraction(-9, 2), Fraction(-58, 13), Fraction(-415, 93))\n>>> tuple(convergents(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))\n(Fraction(1, 1), Fraction(3, 2), Fraction(10, 7), Fraction(43, 30), Fraction(225, 157), Fraction(1393, 972), Fraction(9976, 6961), Fraction(81201, 56660), Fraction(740785, 516901), Fraction(7489051, 5225670))",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "fraction_from_elements",
                        "docstring": "Returns the rational number represented by a (simple) continued fraction from a sequence of its elements.\n\nThe elements must be given as positional arguments, which means that if\nthey are contained in an iterable then they must be unpacked using the\nunpacking operator ``*``, as described in the examples below.\n\nParameters\n----------\n*elements : `int`\n    A variable-length sequence of integer elements of a simple continued\n    fraction.\n\nReturns\n-------\nfractions.Fraction\n    A rational number constructed from a sequence of elements of a simple\n    continued fraction which represents the number.\n\nRaises\n------\nValueError\n    If any of the elements are not integers.\n\nExamples\n--------\n>>> fraction_from_elements(3, 4, 12, 4)\nFraction(649, 200)\n>>> fraction_from_elements(-4, 1, 3, 12, 4)\nFraction(-649, 200)\n>>> fraction_from_elements(4, 2, 6, 7)\nFraction(415, 93)\n>>> fraction_from_elements(*[4, 2, 6, 7])\nFraction(415, 93)\n>>> fraction_from_elements(4.5, 2, 6, 7)\nTraceback (most recent call last):\n...\nValueError: Continued fraction elements must be integers",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "remainder",
                        "docstring": "Returns the :math:`k`-th remainder of a (simple) continued fraction from a sequence of its elements.\n\nGiven a (simple) continued fraction  :math:`[a_0;a_1,a_2,\\ldots]` the\n:math:`k`-th remainder :math:`R_k` is the (simple) continued fraction\n:math:`[a_k; a_{k + 1}, a_{k + 2}, \\ldots]`:\n\n.. math::\n\n   R_k = a_k + \\cfrac{1}{a_{k + 1} + \\cfrac{1}{a_{k + 2} \\ddots }}\n\nwhere :math:`R_0` is just the original continued fraction, i.e.\n:math:`R_0 = [a_0; a_1, a_2, \\ldots]`.\n\nThe remainders satisfy the recurrence relation:\n\n.. math::\n\n   R_{k - 1} = a_{k - 1} + \\frac{1}{R_k}, \\hskip{3em} k \\geq 1\n\nIf the continued fraction :math:`[a_0; a_1, a_2,\\ldots]` is finite of\norder :math:`n` then all :math:`R_k` are rational. If we let\n:math:`R_k = \\frac{s_k}{t_k}` then the recurrence relation above can\nbe written as:\n\n.. math::\n\n   R_{k - 1} = \\frac{s_{k - 1}}{t_{k - 1}} = \\frac{a_{k - 1}s_k + t_k}{s_k}, \\hskip{3em} k \\geq 1\n\nAs this library only deals with finite continued fractions, this function\nalways produces remainders as instances of :py:class:`~fractions.Fraction`.\n\nThe integer :math:`k` must be non-negative and cannot exceed the order\nof the continued fraction, i.e. the number of its tail elements.\n\nA :py:class:`ValueError` is raised if :math:`k` is not an integer, or is an\ninteger greater than the number of elements, or if any of the elements are\nnot integers, or if any of the tail elements are not positive integers.\n\nParameters\n----------\nk : `int`\n    The index of the remainder. Must be a non-negative integer not\n    exceeding the order of the continued fraction.\n\n*elements : `int`\n    A variable-length sequence of integer elements of a (simple) continued\n    fraction.\n\nReturns\n-------\nfractions.Fraction\n    A rational fraction constructed from the given sequence of elements of\n    a continued fraction, representing its :math:`k`-th remainder, as\n    defined above.\n\nRaises\n------\nValueError\n    If :math:`k` is not an integer, or is an integer greater than the\n    number of elements, or if any of the elements are not integers, or if\n    any of the tail elements are not positive integers.\n\nExamples\n--------\n>>> remainder(0, 3, 4, 12, 4)\nFraction(649, 200)\n>>> remainder(1, 3, 4, 12, 4)\nFraction(200, 49)\n>>> remainder(2, 3, 4, 12, 4)\nFraction(49, 4)\n>>> remainder(3, 3, 4, 12, 4)\nFraction(4, 1)\n>>> remainder(0, -5, 1, 1, 6, 7)\nFraction(-415, 93)\n>>> remainder(1, -5, 1, 1, 6, 7)\nFraction(93, 50)\n>>> remainder(2, -5, 1, 1, 6, 7)\nFraction(50, 43)\n>>> remainder(3, -5, 1, 1, 6, 7)\nFraction(43, 7)\n>>> remainder(4, -5, 1, 1, 6, 7)\nFraction(7, 1)\n>>> remainder(1)\nTraceback (most recent call last):\n...\nValueError: `k` must be a non-negative integer not exceeding the order of \nthe continued fraction (number of tail elements), and the tail \nelements must all be positive integers.\n>>> remainder(-1, 3, 4, 12, 4)\nTraceback (most recent call last):\n...\nValueError: `k` must be a non-negative integer not exceeding the order of \nthe continued fraction (number of tail elements), and the tail \nelements must all be positive integers.\n>>> remainder(4, 3, 4, 12, 4)\nTraceback (most recent call last):\n...\nValueError: `k` must be a non-negative integer not exceeding the order of \nthe continued fraction (number of tail elements), and the tail \nelements must all be positive integers.\n>>> remainder(1, 3, 0, 12, 4)\nTraceback (most recent call last):\n...\nValueError: `k` must be a non-negative integer not exceeding the order of \nthe continued fraction (number of tail elements), and the tail \nelements must all be positive integers.\n>>> remainder(1, 3, -1, 12, 4)\nTraceback (most recent call last):\n...\nValueError: `k` must be a non-negative integer not exceeding the order of \nthe continued fraction (number of tail elements), and the tail \nelements must all be positive integers.",
                        "comments": null,
                        "args": [
                            "k"
                        ]
                    },
                    {
                        "name": "remainders",
                        "docstring": "Generates an (ordered) sequence of all remainders of a (simple) continued fraction from a sequence of its elements in descending order of index.\n\nIf :math:`n` is the order of the continued fraction represented by the\ngiven sequence of its elements then there are :math:`n + 1` remainders\n:math:`R_0, R_1, \\ldots, R_n`, and the function generates these in\nreverse order :math:`R_0, R_1, \\ldots, R_n`.\n\nSee the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/exploring-continued-fractions.html#remainders>`_\nfor more details on remainders.\n\nParameters\n----------\n*elements : `int`\n    A variable-length sequence of integer elements of a (simple)\n    continued fraction.\n\nYields\n------\nfractions.Fraction\n    Each element generated is a :py:class:`fractions.Fraction` instance and\n    a :math:`k`-th remainder of the given continued fraction.\n\nRaises\n------\nValueError\n    If no elements are given, or there are any non-integer elements, or\n    the tail elements are not positive integers.\n\nExamples\n--------\n>>> tuple(remainders(3))\n(Fraction(3, 1),)\n>>> tuple(remainders(3, 2))\n(Fraction(2, 1), Fraction(7, 2))\n>>> tuple(remainders(3, 4, 12, 4))\n(Fraction(4, 1), Fraction(49, 4), Fraction(200, 49), Fraction(649, 200))\n>>> tuple(remainders(-5, 1, 1, 6, 7))\n(Fraction(7, 1), Fraction(43, 7), Fraction(50, 43), Fraction(93, 50), Fraction(-415, 93))\n>>> tuple(remainders(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))\n(Fraction(10, 1), Fraction(91, 10), Fraction(738, 91), Fraction(5257, 738), Fraction(32280, 5257), Fraction(166657, 32280), Fraction(698908, 166657), Fraction(2263381, 698908), Fraction(5225670, 2263381), Fraction(7489051, 5225670))\n>>> tuple(remainders())\nTraceback (most recent call last):\n...\nValueError: Continued fraction elements must be integers, and all \ntail elements (from the 1st element onwards) must be positive.\n>>> tuple(remainders(0, 0))\nTraceback (most recent call last):\n...\nValueError: Continued fraction elements must be integers, and all \ntail elements (from the 1st element onwards) must be positive.\n>>> tuple(remainders(1, 0))\nTraceback (most recent call last):\n...\nValueError: Continued fraction elements must be integers, and all \ntail elements (from the 1st element onwards) must be positive.\n>>> tuple(remainders(1, 2, -1))\nTraceback (most recent call last):\n...\nValueError: Continued fraction elements must be integers, and all \ntail elements (from the 1st element onwards) must be positive.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "mediant",
                        "docstring": "Returns the :math:`k`-th left- or right-mediant of two rational numbers.\n\nFor a positive integer :math:`k`, the :math:`k`-th left-mediant of two\nrational numbers :math:`r = \\frac{a}{b}` and :math:`s = \\frac{c}{d}`,\nwhere :math:`b, d, b + d \\neq 0`, is defined as:\n\n.. math::\n\n   \\frac{ka + c}{kb + d}, \\hskip{3em}    k \\geq 1\n\nwhile the :math:`k`-th right mediant is defined as:\n\n.. math::\n\n   \\frac{a + kc}{b + kd}, \\hskip{3em}    k \\geq 1\n\nIf we assume that :math:`r < s` and :math:`bd > 0` then these mediants\nhave the property that:\n\n.. math::\n\n   \\frac{a}{b} < \\frac{ka + c}{kb + d} \\leq \\frac{a + kc}{b + kd} < \\frac{c}{d},   \\hskip{3em} k \\geq 1\n\nwhere equality holds for :math:`k = 1`. If we let :math:`k \\to \\infty`\nthen the mediants converge to opposite limits:\n\n.. math::\n\n  \\begin{align}\n  \\lim_{k \\to \\infty} \\frac{ka + c}{kb + d} &= \\frac{a}{b} \\\\\n  \\lim_{k \\to \\infty} \\frac{a + kc}{b + kd} &= \\frac{c}{d}\n  \\end{align}\n\nFor more information consult the\n`documentation <https://continuedfractions.readthedocs.io/en/latest/sources/mediants.html>`_.\n\nFor the left mediant use ``dir=\"left\"``, while for the right use\n``dir=\"right\"``. The default is ``dir=\"right\"``. For ``k = 1`` the left and\nright mediants are identical to the simple mediant :math:`\\frac{a + c}{b + d}`.\n\nParameters\n----------\nr : `fractions.Fraction`\n    The first rational number.\n\ns : `fractions.Fraction`\n    The second rational number.\n\ndir : `str`, default='right'\n    The \"direction\" of the mediant - `'left'` or `'right'`, as defined\n    above.\n\nk : `int`, default=1\n    The order of the mediant, as defined above.\n\nReturns\n-------\nfractions.Fraction\n    The `k`-th left- or right-mediant of the two given rational numbers.\n\nExamples\n--------\n>>> mediant(Fraction(1, 2), Fraction(3, 5))\nFraction(4, 7)\n>>> mediant(Fraction(1, 2), Fraction(3, 5), dir='left')\nFraction(4, 7)\n>>> mediant(Fraction(1, 2), Fraction(3, 5), k=2)\nFraction(7, 12)\n>>> mediant(Fraction(1, 2), Fraction(3, 5), dir='left', k=2)\nFraction(5, 9)\n>>> mediant(Fraction(1, 2), Fraction(3, 5), k=3, dir='right')\nFraction(10, 17)\n>>> mediant(Fraction(1, 2), Fraction(3, 5), k=3, dir='left')\nFraction(6, 11)",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": []
            },
            {
                "file": "src/continuedfractions/utils.py",
                "functions": [],
                "classes": [
                    {
                        "name": "NamedCallableProxy",
                        "docstring": "Class wrapper to have named callable proxies, which can also work as :py:class:`enum.Enum` values.\n\nAdapted from Stack Overflow solution by Ceppo93:\n\n    https://stackoverflow.com/a/40486992",
                        "comments": "-- 3rd party libraries --\n-- Internal libraries --",
                        "methods": [
                            {
                                "name": "__new__",
                                "docstring": "Constructor\n\nParameters\n----------\ncallable_ : `callable`\n    The callable to name and proxy.\n\nname : `str`, default=None\n    The user-defined name of the callable to use in :py:func:`~continuedfractions.utils.__repr__`.\n    If :py:data:`None` the Python-defined default will be used.\n\nReturns\n-------\ncallable\n    A named callable proxy.\n\nExamples\n--------\n>>> square = NamedCallableProxy(lambda x: x ** 2, name=\"square: x |--> x^2\")\n>>> square\nNamedCallableProxy(\"square: x |--> x^2\")\n>>> list(map(square, [1, 2, 3, 4, 5]))\n[1, 4, 9, 16, 25]",
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "__repr__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__eq__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "__call__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": [
                            "__slots__"
                        ]
                    }
                ]
            },
            {
                "file": "src/continuedfractions/continuedfraction.py",
                "functions": [],
                "classes": [
                    {
                        "name": "ContinuedFraction",
                        "docstring": "An object-oriented representation of a (finite) simple continued fraction.\n\nAn implementation of simple continued fractions as Python objects and\ninstances of the standard library :py:class:`fractions.Fraction` class, with\nvarious properties for the continued fraction, including its elements\n(or coefficients), the order, convergents, and remainders.\n\nThe term \"simple continued fraction\" denotes a specific type of continued\nfraction where the fractional terms only have numerators of :math:`1`.\n\nExamples\n--------\nConstruct the continued fraction for the rational `649/200`.\n\n>>> cf = ContinuedFraction(649, 200)\n>>> cf\nContinuedFraction(649, 200)\n>>> cf.as_float()\n3.245\n\nInspect the elements, order, convergents, and remainders.\n\n>>> cf.elements\n(3, 4, 12, 4)\n>>> cf.order\n3\n>>> cf.convergent(0), cf.convergent(1), cf.convergent(2), cf.convergent(3)\n(ContinuedFraction(3, 1), ContinuedFraction(13, 4), ContinuedFraction(159, 49), ContinuedFraction(649, 200))\n>>> cf.remainder(0), cf.remainder(1), cf.remainder(2), cf.remainder(3)\n(ContinuedFraction(649, 200), ContinuedFraction(200, 49), ContinuedFraction(49, 4), ContinuedFraction(4, 1))\n\nInspect the element counts.\n\n>>> cf.counter\nCounter({4: 2, 3: 1, 12: 1})\n\nCheck some properties of the convergents and remainders.\n\n>>> assert cf.remainder(1) == 1 / (cf - cf.convergent(0))\n\nConstruct continued fractions from element sequences.\n\n>>> cf_inverse = ContinuedFraction.from_elements(0, 3, 4, 12, 4)\n>>> cf_inverse\nContinuedFraction(200, 649)\n>>> assert cf_inverse == 1/cf\n>>> assert cf * cf_inverse == 1\n>>> cf_negative_inverse = ContinuedFraction.from_elements(-1, 1, 2, 4, 12, 4)\n>>> cf_negative_inverse\nContinuedFraction(-200, 649)\n>>> assert cf_negative_inverse == -1/cf\n>>> assert cf * cf_negative_inverse == -1",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__new__",
                                "docstring": "Creates, initialises and returns instances of this class.\n\nArguments can be any which are valid for creating objects of the\n:py:class:`fractions.Fraction` superclass.\n\nFor clarification, valid arguments can be one of the following:\n\n* a single instance of :py:class:`numbers.Rational`, including\n  :py:class:`int`, :py:class:`fractions.Fraction` or\n  :py:class:`ContinuedFraction`, named or unnamed\n* a pair of  :py:class:`numbers.Rational` instances, including\n  :py:class:`int`, :py:class:`fractions.Fraction` and\n  :py:class:`ContinuedFraction`, named or unnamed\n* a single :py:class:`float` or :py:class:`decimal.Decimal` value\n  that is not a special value such as :py:data:`math.nan`,\n  ``float('inf')``, or ``Decimal('infinity')``\n* a single numeric valid string (:py:class:`str`) - validity is\n  determined in the superclass by the\n  :py:data:`fractions._RATIONAL_FORMAT` test\n\nReturns\n-------\nContinuedFraction\n    A :py:class:`ContinuedFraction` instance.\n\nExamples\n--------\nSeveral example are given below of constructing the simple continued\nfraction for the number :math:`\\frac{-649}{200}` in different ways.\n\n>>> ContinuedFraction(-649, 200)\nContinuedFraction(-649, 200)\n>>> ContinuedFraction('-3.245')\nContinuedFraction(-649, 200)\n>>> ContinuedFraction(Decimal('-3.245'))\nContinuedFraction(-649, 200)\n>>> ContinuedFraction('-649/200')\nContinuedFraction(-649, 200)\n>>> ContinuedFraction(Fraction(-649, 200))\nContinuedFraction(-649, 200)\n>>> ContinuedFraction(ContinuedFraction(649, -200))\nContinuedFraction(-649, 200)\n>>> ContinuedFraction(Fraction(-649), 200)\nContinuedFraction(-649, 200)\n>>> ContinuedFraction(649, Fraction(-200))\nContinuedFraction(-649, 200)\n>>> ContinuedFraction(Fraction(-649), ContinuedFraction(200))\nContinuedFraction(-649, 200)\n\nIn each of the examples above, the minus sign can be removed from\nthe arguments to the :py:class:`numbers.Rational` instance and\ninstead attached to the outer class, e.g.:\n\n>>> -ContinuedFraction(649, 200)\nContinuedFraction(-649, 200)\n>>> -ContinuedFraction('3.245')\nContinuedFraction(-649, 200)\n>>> -ContinuedFraction('649/200')\nContinuedFraction(-649, 200)\n\nInvalid arguments will raise errors in the\n:py:class:`fractions.Fraction` superclass.",
                                "comments": null,
                                "args": [
                                    "cls"
                                ]
                            },
                            {
                                "name": "from_elements",
                                "docstring": "Returns a :py:class:`ContinuedFraction` instance from a sequence of (integer) elements of a (finite) simple continued fraction.\n\nInvalid elements will trigger a :py:class:`ValueError`.\n\nParameters\n----------\n*elements : int\n    An ordered sequence of integer elements of a (finite) simple\n    continued fraction.\n\nReturns\n-------\nContinuedFraction\n    A new and fully initialised instance of :py:class:`ContinuedFraction` with\n    the given element sequence.\n\nRaises\n------\nValueError\n    If any elements are not integers, or any elements after the 1st\n    are not positive.\n\nExamples\n--------\nConstructing a continued fraction for the rational :math:`\\frac{649}{200}` using\nthe element sequence :math:`3, 4, 12, 4`.\n\n>>> c1 = ContinuedFraction.from_elements(3, 4, 12, 4)\n>>> c1\nContinuedFraction(649, 200)\n\nConstructing the continued fraction of the (multiplicative) inverse :math:`\\frac{200}{649}`\nusing the element sequence :math:`0, 3, 4, 12, 4`.\n\n>>> c2 = ContinuedFraction.from_elements(0, 3, 4, 12, 4)\n>>> c2\nContinuedFraction(200, 649)\n\nValidation for elements containing non-integers or negative integers.\n\n>>> ContinuedFraction.from_elements('0', 1)\nTraceback (most recent call last):\n...\nValueError: Continued fraction elements must be integers, and all elements after the 1st must be positive\n>>> ContinuedFraction.from_elements(0, 1, 2.5)\nTraceback (most recent call last):\n...\nValueError: Continued fraction elements must be integers, and all elements after the 1st must be positive\n>>> ContinuedFraction.from_elements(1, 0)\nTraceback (most recent call last):\n...\nValueError: Continued fraction elements must be integers, and all elements after the 1st must be positive\n>>> ContinuedFraction.from_elements(1, -1)\nTraceback (most recent call last):\n...\nValueError: Continued fraction elements must be integers, and all elements after the 1st must be positive",
                                "comments": null,
                                "args": [
                                    "cls"
                                ]
                            },
                            {
                                "name": "extend",
                                "docstring": "Performs an in-place extension of the tail of the current sequence of elements.\n\nRaises a :py:class:`ValueError` if there are no new elements, or are\nnot positive integers.\n\n.. note::\n\n   As this method performs an in-place modification of the existing/\n   current instance the object ID remains the same.\n\nParameters\n----------\nelements\n    An (ordered) sequence of new (integer) elements by which the tail\n    of the existing sequence of elements is extended.\n\nRaises\n------\nValueError\n    If no new elements provided, or the new elements provided are not\n    positive integers.\n\nExamples\n--------\n>>> cf = ContinuedFraction('3.245')\n>>> cf\nContinuedFraction(649, 200)\n>>> cf.elements\n(3, 4, 12, 4)\n>>> cf.order\n3\n>>> tuple(cf.convergents)\n((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)), (2, ContinuedFraction(159, 49)), (3, ContinuedFraction(649, 200)))\n>>> tuple(cf.remainders)\n((3, ContinuedFraction(4, 1)), (2, ContinuedFraction(49, 4)), (1, ContinuedFraction(200, 49)), (0, ContinuedFraction(649, 200)))\n>>> cf.extend(5, 2)\n>>> cf\nContinuedFraction(7457, 2298)\n>>> cf.elements\n(3, 4, 12, 4, 5, 2)\n>>> cf.order\n5\n>>> tuple(cf.convergents)\n((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)), (2, ContinuedFraction(159, 49)), (3, ContinuedFraction(649, 200)), (4, ContinuedFraction(3404, 1049)), (5, ContinuedFraction(7457, 2298)))\n>>> tuple(cf.remainders)\n((5, ContinuedFraction(2, 1)), (4, ContinuedFraction(11, 2)), (3, ContinuedFraction(46, 11)), (2, ContinuedFraction(563, 46)), (1, ContinuedFraction(2298, 563)), (0, ContinuedFraction(7457, 2298)))\n>>> cf = ContinuedFraction(649, 200)\n>>> cf.extend(0, 1)\nTraceback (most recent call last):\n...\nValueError: The elements/coefficients to be added to the tail must be positive integers.\n>>> cf.extend(1, -1)\nTraceback (most recent call last):\n...\nValueError: The elements/coefficients to be added to the tail must be positive integers.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "truncate",
                                "docstring": "Performs an in-place truncation of the tail of the existing sequence of elements.\n\nRaises a :py:class:`ValueError` if the tail elements provided are not\npositive integers, or do not form a segment of the existing tail. This\nincludes the case where the length of the tail elements provided exceed\nthe length of the existing tail, i.e. the order of the continued\nfraction represented by the instance.\n\n.. note::\n\n   The tail elements provided must be positive integers which form a\n   subsequence of the tail of the original sequence ending with the\n   last element, e.g. with respect to the complete sequence of elements\n   ``(3, 4, 12, 4)`` a value of ``12, 4`` for ``*tail_elements`` would\n   be valid, but ``4, 12`` would be invalid as it does not represent\n   a segment of the tail, and ``3, 4, 12, 4`` would also be invalid\n   as it includes the head ``3``.\n\n.. note::\n\n   As this method performs an in-place modification of the existing/\n   current instance the object ID remains the same.\n\nParameters\n----------\ntail_elements\n    An (ordered) sequence of (integer) elements to truncate from the\n    tail of the existing sequence of elements.\n\nRaises\n------\nValueError\n    If no tail elements are provided, or the tail elements provided do\n    not represent a valid segment of the existing tail.\n\nExamples\n--------\n>>> cf = ContinuedFraction('3.245')\n>>> cf\nContinuedFraction(649, 200)\n>>> cf.elements\n(3, 4, 12, 4)\n>>> cf.order\n3\n>>> cf.counter\nCounter({4: 2, 3: 1, 12: 1})\n>>> tuple(cf.convergents)\n((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)), (2, ContinuedFraction(159, 49)), (3, ContinuedFraction(649, 200)))\n>>> tuple(cf.remainders)\n((3, ContinuedFraction(4, 1)), (2, ContinuedFraction(49, 4)), (1, ContinuedFraction(200, 49)), (0, ContinuedFraction(649, 200)))\n>>> cf.truncate(12, 4)\n>>> cf\nContinuedFraction(13, 4)\n>>> cf.elements\n(3, 4)\n>>> cf.order\n1\n>>> tuple(cf.convergents)\n((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)))\n>>> tuple(cf.remainders)\n((1, ContinuedFraction(4, 1)), (0, ContinuedFraction(13, 4)))\n>>> cf = ContinuedFraction(649, 200)\n>>> cf.truncate(4, 12)\nTraceback (most recent call last):\n...\nValueError: The elements/coefficients to be truncated from the tail must form a valid segment of the existing tail.\n>>> cf.truncate(3, 4, 12, 4)\nTraceback (most recent call last):\n...\nValueError: The elements/coefficients to be truncated from the tail must form a valid segment of the existing tail.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__eq__",
                                "docstring": "Custom equality check.\n\nCompares the sequence of elements/coefficients of ``self`` with\nthat of ``other`` if ``other`` is also a\n:py:class:`~continuedfractions.continuedfraction.ContinuedFraction`\ninstance, otherwise calls the superclass :py:class:`~fractions.Fraction`\nequality check.\n\nReturns\n-------\nbool\n    The boolean result of the equality check.",
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "__hash__",
                                "docstring": "Custom hash.\n\nCustom hash which hashes the sequence of elements/coefficients - as\nthis is always defined as a finite, non-empty tuple the hash is\nalways defined.\n\nReturns\n-------\nint\n    The hash of the\n    :py:class:`~continuedfractions.continuedfraction.ContinuedFraction`\n    instance.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__add__",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "__radd__",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "__sub__",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "__rsub__",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "__mul__",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "__rmul__",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "__truediv__",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "__rtruediv__",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "__floordiv__",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "__rfloordiv__",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "__divmod__",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "__rdivmod__",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "__pow__",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "__rpow__",
                                "docstring": null,
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "__pos__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__neg__",
                                "docstring": "Division-free negation for a finite simple continued fraction, as\ndescribed `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/creating-continued-fractions.html#negative-continued-fractions>`_.\n\nThe basic algorithm can be described as follows: if\n:math:`[a_0; a_1,\\ldots, a_n]` is the simple continued fraction of a\n**positive** rational number :math:`\\frac{a}{b}` of finite order\n:math:`n` then  :math:`-\\frac{a}{b}` has the simple continued\nfraction:\n\n.. math::\n\n   \\begin{cases}\n   [-a_0;]                                      \\hskip{3em} & n = 0 \\\\\n   [-(a_0 + 1); 2]                              \\hskip{3em} & n = 1 \\text{ and } a_1 = 2 \\\\\n   [-(a_0 + 1); a_2 + 1, a_3,\\ldots, a_n]      \\hskip{3em} & n \\geq 2 \\text{ and } a_1 = 1 \\\\\n   [-(a_0 + 1); 1, a_1 - 1, a_2, \\ldots,a_n]   \\hskip{3em} & n \\geq 2 \\text{ and } a_1 \\geq 2\n   \\end{cases}\n\nIn applying this algorithm there is an assumption that the last element\n:math:`a_n > 1`, as any simple continued fraction of type\n:math:`[a_0; a_1,\\ldots, a_{n} = 1]` can be reduced to the simple\ncontinued fraction :math:`[a_0; a_1,\\ldots, a_{n - 1} + 1]`.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__abs__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "as_float",
                                "docstring": "Returns the :py:class:`float` value of the continued fraction.\n\nReturns\n-------\nfloat\n    The :py:class:`float` value of the continued fraction.\n\nExamples\n--------\nNote that the default :py:mod:`decimal` context precision of :math:`28`\nis used in these examples.\n\n>>> import math\n>>> math.pi\n3.141592653589793\n\nNow construct a :py:class:`ContinuedFraction` instance from it, and check the \n:py:class:`float` value.\n\n>>> cf = ContinuedFraction(math.pi)\n>>> cf\nContinuedFraction(884279719003555, 281474976710656)\n>>> cf.as_float()\n3.141592653589793",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "as_decimal",
                                "docstring": "Returns the :py:class:`decimal.Decimal` value of the continued fraction.\n\nReturns\n-------\ndecimal.Decimal\n    The :py:class:`decimal.Decimal` representation of the continued fraction.\n\nExamples\n--------\nNote that the default :py:mod:`decimal` context precision of :math:`28`\nis used in these examples.\n\n>>> import math\n>>> math.pi\n3.141592653589793\n\nNow construct a :py:class:`ContinuedFraction` instance from it, and check the \n:py:class:`float` value.\n\n>>> cf = ContinuedFraction(math.pi)\n>>> cf\nContinuedFraction(884279719003555, 281474976710656)\n>>> cf.as_decimal()\nDecimal('3.141592653589793115997963469')",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "elements",
                                "docstring": ":py:class:`tuple`: The (ordered) sequence of elements of the continued fraction.\n\nExamples\n--------\n>>> cf = ContinuedFraction('.12345')\n>>> cf\nContinuedFraction(2469, 20000)\n>>> cf.elements\n(0, 8, 9, 1, 21, 1, 1, 5)",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "order",
                                "docstring": ":py:class:`int`: The order of the continued fraction, which is the number of its elements minus :math:`1`.\n\nExamples\n--------\n>>> cf = ContinuedFraction('.12345')\n>>> cf\nContinuedFraction(2469, 20000)\n>>> len(cf.elements)\n8\n>>> cf.order\n7",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "counter",
                                "docstring": ":py:class:`collections.Counter` : A counter for the elements.\n\nExamples\n--------\n>>> cf = ContinuedFraction(928374923, 8249234)\n>>> cf.counter\nCounter({1: 6, 2: 3, 24: 2, 112: 1, 5: 1, 3: 1})",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "khinchin_mean",
                                "docstring": ":py:class:`decimal.Decimal` or :py:data:`None`: The Khinchin mean of the continued fraction, which is defined as the geometric mean of all its elements after the 1st.\n\nWe define the Khinchin mean :math:`K_n` of a (simple) continued\nfraction :math:`[a_0; a_1, a_2, \\ldots, a_n]` as:\n\n.. math::\n\n   K_n := \\sqrt[n]{a_1a_2 \\cdots a_n} = \\left( a_1a_2 \\cdots a_n \\right)^{\\frac{1}{n}}, \\hskip{3em} n \\geq 1\n\nThis property is intended to make it easier to study the limit of\n:math:`K_n` as :math:`n \\to \\infty`.  See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/exploring-continued-fractions.html#khinchin-means-khinchin-s-constant>`_\nfor more details.\n\nIn the special case of integers or fractions representing integers,\nwhose continued fraction representations consist of only a single\nelement, a null value is returned.\n\nExamples\n--------\nNote that the default :py:mod:`decimal` context precision of :math:`28`\nis used in these examples.\n\n>>> ContinuedFraction(649, 200).elements\n(3, 4, 12, 4)\n>>> ContinuedFraction(649, 200).khinchin_mean\nDecimal('5.76899828122963409526846589869819581508636474609375')\n>>> ContinuedFraction(415, 93).elements\n(4, 2, 6, 7)\n>>> ContinuedFraction(415, 93).khinchin_mean\nDecimal('4.37951913988788898990378584130667150020599365234375')\n>>> (ContinuedFraction(649, 200) + ContinuedFraction(415, 93)).elements\n(7, 1, 2, 2, 2, 1, 1, 11, 1, 2, 12)\n>>> (ContinuedFraction(649, 200) + ContinuedFraction(415, 93)).khinchin_mean\nDecimal('2.15015313349074244086978069390170276165008544921875')\n>>> ContinuedFraction(5000).khinchin_mean",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "convergent",
                                "docstring": "Returns the :math:`k`-th (simple) convergent of the continued fraction.\n\nGiven a (simple) continued fraction  :math:`[a_0;a_1,a_2,\\ldots]` the\n:math:`k`-th convergent is defined as:\n\n.. math::\n\n   C_k = a_0 + \\cfrac{1}{a_1 + \\cfrac{1}{a_2 \\ddots \\cfrac{1}{a_{k-1} + \\cfrac{1}{a_k}}}}\n\nThe result is a :py:class:`~continuedfractions.continuedfraction.ContinuedFraction` instance.\n\nIf  the continued fraction is of order :math:`n` then it has exactly\n:math:`n + 1` convergents :math:`C_0,C_1,C_2,\\ldots,C_n` where\nthe :math:`k`-th convergent :math:`C_k = \\frac{p_k}{q_k}` is given by\nthe recurrence relation:\n\n.. math::\n   \n   \\begin{align}\n   p_k &= a_kp_{k - 1} + p_{k - 2} \\\\\n   q_k &= a_kq_{k - 1} + q_{k - 2},        \\hskip{3em}    k \\geq 3\n   \\end{align}\n\nwhere :math:`p_0 = a_0`, :math:`q_0 = 1`, :math:`p_1 = p_1p_0 + 1`,\nand :math:`q_1 = p_1`.\n\nParameters\n----------\nk : int\n    The index of the convergent, as described above.\n\nReturns\n-------\nContinuedFraction\n    A new :py:class:`ContinuedFraction` instance representing the :math:`k`-th\n    (simple) convergent of the original continued fraction, as\n    described above.\n\nExamples\n--------\n>>> cf = ContinuedFraction('.12345')\n>>> cf\nContinuedFraction(2469, 20000)\n>>> cf.convergent(0)\nContinuedFraction(0, 1)\n>>> cf.convergent(2)\nContinuedFraction(9, 73)\n>>> cf.convergent(6)\nContinuedFraction(448, 3629)\n>>> cf.convergent(7)\nContinuedFraction(2469, 20000)",
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "convergents",
                                "docstring": "Generates an enumerated sequence of all convergents of the continued fraction.\n\nThe convergents are generated as tuples of :py:class:`int` and\n:py:class:`~continuedfraction.continuedfraction.ContinuedFraction`\ninstances, where the integers represent the indices of the convergents.\n\nIf :math:`n` is the order of the continued fraction then :math:`n + 1`\nconvergents :math:`C_0, C_1, \\ldots, C_n` are generated in that order.\n\nYields\n------\ntuple\n    A tuple of convergent index (:py:class:`int`) and convergents\n    (:py:class:`~continuedfractions.continuedfraction.ContinuedFraction`)\n    of the continued fraction.\n\nExamples\n--------\n>>> cf = ContinuedFraction('3.245')\n>>> tuple(cf.convergents)\n((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)), (2, ContinuedFraction(159, 49)), (3, ContinuedFraction(649, 200)))",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "even_convergents",
                                "docstring": "Generates an enumerated sequence of all even-order convergents of the continued fraction.\n\nThe convergents are generated as tuples of :py:class:`int` and\n:py:class:`~continuedfraction.continuedfraction.ContinuedFraction`\ninstances, where the integers represent the indices of the convergents.\n\nIf :math:`n` is the order of the continued fraction then only the even-\nindexed convergents :math:`C_0, C_2, C_4, \\ldots` are generated.\n\nYields\n------\ntuple\n    A tuple of convergent index (:py:class:`int`) and convergents\n    (:py:class:`~continuedfractions.continuedfraction.ContinuedFraction`)\n    of the continued fraction.\n\nExamples\n--------\n>>> tuple(ContinuedFraction('3.245').even_convergents)\n((0, ContinuedFraction(3, 1)), (2, ContinuedFraction(159, 49)))",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "odd_convergents",
                                "docstring": "Generates an enumerated sequence of all odd-order convergents of the continued fraction.\n\nThe convergents are generated as tuples of :py:class:`int` and\n:py:class:`~continuedfraction.continuedfraction.ContinuedFraction`\ninstances, where the integers represent the indices of the convergents.\n\nIf :math:`n` is the order of the continued fraction then only the odd-\nindexed convergents :math:`C_1, C_3, C_5, \\ldots` are generated.\n\nYields\n------\ntuple\n    A tuple of convergent index (:py:class:`int`) and convergents\n    (:py:class:`~continuedfractions.continuedfraction.ContinuedFraction`)\n    of the continued fraction.\n\nExamples\n--------\n>>> tuple(ContinuedFraction('3.245').odd_convergents)\n((1, ContinuedFraction(13, 4)), (3, ContinuedFraction(649, 200)))",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "semiconvergent",
                                "docstring": "Returns the :math:`m`-th semiconvergent of two consecutive convergents :math:`p_{k - 1}` and :math:`p_k` of the continued fraction.\n\nThe integer :math:`k` must be positive and determine two consecutive\nconvergents :math:`p_{k - 1}` and :math:`p_k` of a (finite, simple)\ncontinued fraction.\n\nThe integer :math:`m` can be any positive integer.\n\nParameters\n----------\nk : int\n    The integer :math:`k` determining two consecutive convergents\n    :math:`p_{k - 1}` and :math:`p_k` of a (finite, simple) continued\n    fraction\n    :math:`[a_0; a_1, \\ldots, a_{k}, a_{k + 1}, \\ldots, a_n]`.\n\nm : int\n    The index of the semiconvergent of the convergents\n    :math:`p_{k - 1}` and :math:`p_k`.\n\nReturns\n-------\nContinuedFraction\n    The :math:`m`-th semiconvergent of the convergents\n    :math:`p_{k - 1}` and :math:`p_k`.\n\nRaises\n------\nValueError\n    If :math:`k` or :math:`m` are not positive integers, or :math:`k`\n    is an integer that does **not** satisfy :math:`1 \\leq k \\leq n`\n    where :math:`n` is the order of the (finite, simple) continued\n    fraction of which :math:`p_{k - 1}` and :math:`p_k` are\n    convergents.\n\nExamples\n--------\n>>> cf = ContinuedFraction(-415, 93)\n>>> cf.elements\n(-5, 1, 1, 6, 7)\n>>> tuple(cf.convergents)\n((0, ContinuedFraction(-5, 1)), (1, ContinuedFraction(-4, 1)), (2, ContinuedFraction(-9, 2)), (3, ContinuedFraction(-58, 13)), (4, ContinuedFraction(-415, 93)))\n>>> cf.semiconvergent(3, 1)\nContinuedFraction(-67, 15)\n>>> cf.semiconvergent(3, 2)\nContinuedFraction(-125, 28)\n>>> cf.semiconvergent(3, 3)\nContinuedFraction(-183, 41)\n>>> cf.semiconvergent(3, 4)\nContinuedFraction(-241, 54)\n>>> cf.semiconvergent(3, 5)\nContinuedFraction(-299, 67)\n>>> cf.semiconvergent(3, 6)\nContinuedFraction(-357, 80)\n>>> cf.semiconvergent(3, 7)\nContinuedFraction(-415, 93)",
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "remainder",
                                "docstring": "Returns the :math:`k`-th remainder of the continued fraction.\n\nGiven a (simple) continued fraction  :math:`[a_0;a_1,a_2,\\ldots]` the\n:math:`k`-th remainder :math:`R_k` is the (simple) continued fraction\n:math:`[a_k; a_{k + 1}, a_{k + 2}, \\ldots]`:\n\n.. math::\n\n   R_k = a_k + \\cfrac{1}{a_{k + 1} + \\cfrac{1}{a_{k + 2} \\ddots }}\n\nwhere :math:`R_0` is just the original continued fraction, i.e.\n:math:`R_0 = [a_0; a_1, a_2, \\ldots]`.\n\nThe result is a :py:class:`~continuedfractions.continuedfraction.ContinuedFraction` instance.\n\nThe remainders satisfy the recurrence relation:\n\n.. math::\n\n   R_{k - 1} = a_{k - 1} + \\frac{1}{R_k}, \\hskip{3em} k \\geq 1\n\nIf the original continued fraction is finite then its remainders are all\nfinite and rational.\n\nAs this class implements finite simple continued fractions, this method\nalways produces rational numbers.\n\nThe integer :math:`k` must be non-negative and cannot exceed the order\nof the continued fraction, i.e. the number of its tail elements, and \nthe tail elements must define a valid finite simple continued fraction.\n\nParameters\n----------\nk : int\n    The index of the remainder, as described above.\n\nReturns\n-------\nContinuedFraction\n    A new :py:class:`ContinuedFraction` instance representing the :math:`k`-th\n    remainder of the original continued fraction, as described above.\n\nExamples\n--------\n>>> cf = ContinuedFraction('.12345')\n>>> cf\nContinuedFraction(2469, 20000)\n>>> cf.remainder(0)\nContinuedFraction(2469, 20000)\n>>> cf.remainder(2)\nContinuedFraction(2469, 248)\n>>> cf.remainder(6)\nContinuedFraction(6, 5)\n>>> cf.remainder(7)\nContinuedFraction(5, 1)",
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "remainders",
                                "docstring": "Generates an enumerated sequence of all remainders of the continued fraction in descending order of index.\n\nIf :math:`n` is the order of the continued fraction then there are\n:math:`n + 1` remainders :math:`R_0, R_1, \\ldots, R_n`, and the method\ngenerates these in reverse order :math:`R_0, R_1, \\ldots, R_n`.\n\nSee the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/exploring-continued-fractions.html#remainders>`_\nfor more details on remainders.\n\nThe remainders are generated as tuples of :py:class:`int`\nand :py:class:`~continuedfraction.continuedfraction.ContinuedFraction`\ninstances, where the integers represent the indexes of the remainders.\n\nYields\n------\ntuple\n    A tuple of remainder indices (:py:class:`int`) and remainders\n    (:py:class:`~continuedfractions.continuedfraction.ContinuedFraction`)\n    of the continued fraction.\n\nExamples\n--------\n>>> tuple(ContinuedFraction('3.245').remainders)\n((3, ContinuedFraction(4, 1)), (2, ContinuedFraction(49, 4)), (1, ContinuedFraction(200, 49)), (0, ContinuedFraction(649, 200)))\n>>> tuple(ContinuedFraction(-415, 93).remainders)\n((4, ContinuedFraction(7, 1)), (3, ContinuedFraction(43, 7)), (2, ContinuedFraction(50, 43)), (1, ContinuedFraction(93, 50)), (0, ContinuedFraction(-415, 93)))",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "left_mediant",
                                "docstring": "Returns the :math:`k`-th left-mediant of the continued fraction with another rational number.\n\nFor a positive integer :math:`k`, the :math:`k`-th left-mediant of two\nrational numbers :math:`r = \\frac{a}{b}` and :math:`s = \\frac{c}{d}`,\nwhere :math:`b, d, b + d \\neq 0`, is defined as:\n\n.. math::\n\n   \\frac{ka + c}{kb + d}, \\hskip{3em}    k \\geq 1\n\nwhile the :math:`k`-th right mediant is defined as:\n\n.. math::\n\n   \\frac{a + kc}{b + kd}, \\hskip{3em}    k \\geq 1\n\nIf we assume that :math:`r < s` and :math:`bd > 0` then these mediants\nhave the property that:\n\n.. math::\n\n   \\frac{a}{b} < \\frac{ka + c}{kb + d} \\leq \\frac{a + kc}{b + kd} < \\frac{c}{d},   \\hskip{3em} k \\geq 1\n\nwhere equality holds for :math:`k = 1`. If we let :math:`k \\to \\infty`\nthen the mediants converge to opposite limits:\n\n.. math::\n\n  \\begin{align}\n  \\lim_{k \\to \\infty} \\frac{ka + c}{kb + d} &= \\frac{a}{b} \\\\\n  \\lim_{k \\to \\infty} \\frac{a + kc}{b + kd} &= \\frac{c}{d}\n  \\end{align}\n\nFor more information consult the\n`documentation <https://continuedfractions.readthedocs.io/en/latest/sources/mediants.html>`_.\n\nThe method is cached (with :py:func:`functools.cache`), which makes calls\nafter the initial call much faster.\n\nParameters\n----------\nother : fractions.Fraction, ContinuedFraction\n    The second fraction to use to calculate the :math:`k`-th mediant with\n    the first.\n\nk : int, default=1\n    The order of the mediant, as defined above.        \n\nReturns\n-------\nContinuedFraction\n    The :math:`k`-th left-mediant of the original fraction and the second\n    fraction, as a :py:class:`ContinuedFraction` instance.\n\nExamples\n--------\n>>> c1 = ContinuedFraction('1/2')\n>>> c2 = ContinuedFraction(3, 5)\n>>> c1, c2\n(ContinuedFraction(1, 2), ContinuedFraction(3, 5))\n>>> c1.left_mediant(c2)\nContinuedFraction(4, 7)\n>>> c1.left_mediant(c2, k=2)\nContinuedFraction(5, 9)\n>>> c1.left_mediant(c2, k=3)\nContinuedFraction(6, 11)\n>>> c1.left_mediant(c2, k=100)\nContinuedFraction(103, 205)\n>>> assert c1.left_mediant(c2, k=2) < c1.right_mediant(c2, k=2)\n>>> assert c1.left_mediant(c2, k=3) < c1.right_mediant(c2, k=3)\n>>> assert c1.left_mediant(c2, k=100) < c1.right_mediant(c2, k=100)",
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "right_mediant",
                                "docstring": "Returns the :math:`k`-th right-mediant of the continued fraction with another rational number.\n\nFor a positive integer :math:`k`, the :math:`k`-th right-mediant of two\nrational numbers :math:`r = \\frac{a}{b}` and :math:`s = \\frac{c}{d}`,\nwhere :math:`b, d, b + d \\neq 0`, is defined as:\n\n.. math::\n\n   \\frac{a + kc}{b + kd}, \\hskip{3em}    k \\geq 1\n\nwhile the :math:`k`-th left-mediant is defined as:\n\n.. math::\n\n   \\frac{ka + c}{kb + d}, \\hskip{3em}    k \\geq 1\n\nIf we assume that :math:`r < s` and :math:`bd > 0` then these mediants\nhave the property that:\n\n.. math::\n\n   \\frac{a}{b} < \\frac{ka + c}{kb + d} \\leq \\frac{a + kc}{b + kd} < \\frac{c}{d},   \\hskip{3em} k \\geq 1\n\nwhere equality holds for :math:`k = 1`. If we let :math:`k \\to \\infty`\nthen the mediants converge to opposite limits:\n\n.. math::\n\n  \\begin{align}\n  \\lim_{k \\to \\infty} \\frac{ka + c}{kb + d} &= \\frac{a}{b} \\\\\n  \\lim_{k \\to \\infty} \\frac{a + kc}{b + kd} &= \\frac{c}{d}\n  \\end{align}\n\nFor more information consult the\n`documentation <https://continuedfractions.readthedocs.io/en/latest/sources/mediants.html>`_.\n\nParameters\n----------\nother : fractions.Fraction, ContinuedFraction\n    The second fraction to use to calculate the :math:`k`-th mediant with\n    the first.\n\nk : int, default=1\n    The order of the mediant, as defined above.        \n\nReturns\n-------\nContinuedFraction\n    The :math:`k`-th right-mediant of the original fraction and the second\n    fraction, as a :py:class:`ContinuedFraction` instance.\n\nExamples\n--------\n>>> c1 = ContinuedFraction('1/2')\n>>> c2 = ContinuedFraction(3, 5)\n>>> c1, c2\n(ContinuedFraction(1, 2), ContinuedFraction(3, 5))\n>>> c1.right_mediant(c2)\nContinuedFraction(4, 7)\n>>> c1.right_mediant(c2, k=2)\nContinuedFraction(7, 12)\n>>> c1.right_mediant(c2, k=3)\nContinuedFraction(10, 17)\n>>> c1.right_mediant(c2, k=100)\nContinuedFraction(301, 502)\n>>> assert c1.left_mediant(c2, k=2) < c1.right_mediant(c2, k=2)\n>>> assert c1.left_mediant(c2, k=3) < c1.right_mediant(c2, k=3)\n>>> assert c1.left_mediant(c2, k=100) < c1.right_mediant(c2, k=100)",
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "mediant",
                                "docstring": "Returns the simple mediant of the continued fraction with another continued fraction.\n\nThe simple mediant of two rational numbers :math:`r = \\frac{a}{b}`\nand :math:`s = \\frac{c}{d}`, where :math:`b, d, b + d \\neq 0`, is\ndefined as:\n\n.. math::\n\n   \\frac{a + c}{b + d}\n\nThe resulting value :math:`\\frac{a + c}{b + d}` is the same as the\n1st order left- or right-mediant of :math:`r = \\frac{a}{b}`\nand :math:`s = \\frac{c}{d}`. So this method would produce the same\nresult as the :py:meth:`~continuedfractions.continuedfraction.ContinuedFraction.left_mediant`\nor :py:meth:`~continuedfractions.continuedfraction.ContinuedFraction.right_mediant`\nmethods where the order :math:`k` is set to :math:`1`.\n\nFor more information consult the\n`documentation <https://continuedfractions.readthedocs.io/en/latest/sources/mediants.html>`_.\n\nParameters\n----------\nother : fractions.Fraction, ContinuedFraction\n    The other continued fraction.\n\nReturns\n-------\nContinuedFraction\n    The simple mediant of the original fraction and the other continued\n    fraction.\n\nExamples\n--------\n>>> ContinuedFraction(1, 2).mediant(ContinuedFraction(3, 5))\nContinuedFraction(4, 7)\n>>> assert ContinuedFraction(1, 2).mediant(ContinuedFraction(3, 5)) == ContinuedFraction(1, 2).left_mediant(ContinuedFraction(3, 5), k=1)\n>>> assert ContinuedFraction(1, 2).mediant(ContinuedFraction(3, 5)) == ContinuedFraction(1, 2).right_mediant(ContinuedFraction(3, 5), k=1)",
                                "comments": null,
                                "args": []
                            }
                        ],
                        "attributes": [
                            "__slots__"
                        ]
                    }
                ]
            },
            {
                "file": "src/continuedfractions/sequences.py",
                "functions": [
                    {
                        "name": "coprime_integers_generator",
                        "docstring": "Generates a sequence of (positive) integers :math:`1 \\leq m < n` coprime to a given positive integer :math:`n`.\n\nThe tuple is sorted in descending order of magnitude.\n\nThe optional ``start`` and ``stop`` parameters can be used to bound the\nthe range of (positive) integers in which integers coprime to the given\n:math:`n` are sought.\n\nFor :math:`n = 1, 2` the ``start`` value is effectively ignored, but\nif :math:`n > 1` then the ``start`` value must be an integer in the range\n:math:`1..n - 1`.\n\nThe ``stop`` value defaults to ``None``, which is then internally\ninitialised to :math:`n`; if :math:`n > 1` and ``stop`` is given then it\nmust be an integer in the range :math:`\\text{start} + 1..n`.\n\nParameters\n----------\nn : int\n    The positive integer for which (positive) coprime integers\n    :math:`m < n` are sought.\n\nstart : int, default=1\n    The lower bound of the range of (positive) integers in which integers\n    coprime to the given :math:`n` are sought. For :math:`n = 1, 2` the\n    ``start`` value is effectively ignored, but if :math:`n > 1` then the\n    ``start`` value must be in the range :math:`1..n - 1`.\n\nstop : int, default=None\n    The upper bound of the range of (positive) integers in which integers\n    coprime to the given :math:`n` are sought. The ``stop`` value defaults\n    to ``None``, which is then internally initialised to :math:`n`; if\n    :math:`n > 1` and ``stop`` is given then it must be an integer in the\n    range :math:`\\text{start} + 1..n`.\n\nRaises\n------\nValueError\n    If :math:`n` is either not a positive integer, or :math:`n > 1` such\n    that either the ``start`` value is **not** in the range\n    :math:`1..n - 1` or the ``stop`` value is **not** in the range\n    :math:`\\text{start} + 1..n`.\n\nYields\n------\nint\n    A sequence of (positive) integers :math:`1 \\leq m < n` coprime to a\n    given positive integer :math:`n`.\n\nExamples\n--------\nExamples using the default ``start`` and ``stop`` values:\n\n>>> tuple(coprime_integers_generator(1))\n(1,)\n>>> tuple(coprime_integers_generator(2))\n(1,)\n>>> tuple(coprime_integers_generator(3))\n(2, 1)\n>>> tuple(coprime_integers_generator(4))\n(3, 1)\n>>> tuple(coprime_integers_generator(5))\n(4, 3, 2, 1)\n>>> tuple(coprime_integers_generator(6))\n(5, 1)\n>>> tuple(coprime_integers_generator(7))\n(6, 5, 4, 3, 2, 1)\n>>> tuple(coprime_integers_generator(8))\n(7, 5, 3, 1)\n>>> tuple(coprime_integers_generator(9))\n(8, 7, 5, 4, 2, 1)\n>>> tuple(coprime_integers_generator(10))\n(9, 7, 3, 1)\n>>> tuple(coprime_integers_generator(11))\n(10, 9, 8, 7, 6, 5, 4, 3, 2, 1)\n\nExamples using custom ``start`` and ``stop`` values:\n\n>>> tuple(coprime_integers_generator(3, start=0))\nTraceback (most recent call last):\n...\nValueError: `n` must be a positive integer; if `n` > 1 then the `start` value must be a positive integer in the range 1..n - 1; and if given the `stop` value must be a positive integer in the range `start` + 1..n\n>>> tuple(coprime_integers_generator(3, start=2))\n(2,)\n>>> tuple(coprime_integers_generator(3, start=3))\nTraceback (most recent call last):\n...\nValueError: `n` must be a positive integer; if `n` > 1 then the `start` value must be a positive integer in the range 1..n - 1; and if given the `stop` value must be a positive integer in the range `start` + 1..n\n>>> tuple(coprime_integers_generator(23, start=5, stop=21))\n(21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5)\n>>> tuple(coprime_integers_generator(5, start=2))\n(4, 3, 2)\n>>> tuple(coprime_integers_generator(5, start=3))\n(4, 3)\n>>> tuple(coprime_integers_generator(6, start=2))\n(5,)\n>>> tuple(coprime_integers_generator(6, start=3))\n(5,)\n>>> tuple(coprime_integers_generator(6, start=4))\n(5,)\n>>> tuple(coprime_integers_generator(7, start=2))\n(6, 5, 4, 3, 2)\n>>> tuple(coprime_integers_generator(7, start=3))\n(6, 5, 4, 3)\n>>> tuple(coprime_integers_generator(7, start=4))\n(6, 5, 4)\n>>> tuple(coprime_integers_generator(7, start=5))\n(6, 5)",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "coprime_integers",
                        "docstring": "Returns a sequence of (positive) integers :math:`1 \\leq m < n` coprime to a given positive integer :math:`n`.\n\nWrapper of :py:class:`~continuedfractions.sequences.coprime_integers_generator`.\n\nThe tuple is sorted in descending order of magnitude.\n\nThe optional ``start`` and ``stop`` parameters can be used to bound the\nthe range of (positive) integers in which integers coprime to the given\n:math:`n` are sought.\n\nFor :math:`n = 1, 2` the ``start`` value is effectively ignored, but\nif :math:`n > 1` then the ``start`` value must be an integer in the range\n:math:`1..n - 1`.\n\nThe ``stop`` value defaults to ``None``, which is then internally\ninitialised to :math:`n`; if :math:`n > 1` and ``stop`` is given then it\nmust be an integer in the range :math:`\\text{start} + 1..n`.\n\nParameters\n----------\nn : int\n    The positive integer for which (positive) coprime integers\n    :math:`m < n` are sought.\n\nstart : int, default=1\n    The lower bound of the range of (positive) integers in which integers\n    coprime to the given :math:`n` are sought. For :math:`n = 1, 2` the\n    ``start`` value is effectively ignored, but if :math:`n > 1` then the\n    ``start`` value must be in the range :math:`1..n - 1`.\n\nstop : int, default=None\n    The upper bound of the range of (positive) integers in which integers\n    coprime to the given :math:`n` are sought. The ``stop`` value defaults\n    to ``None``, which is then internally initialised to :math:`n`; if\n    :math:`n > 1` and ``stop`` is given then it must be an integer in the\n    range :math:`\\text{start} + 1..n`.\n\nReturns\n-------\ntuple\n    A sequence of (positive) integers :math:`1 \\leq m < n` coprime to a\n    given positive integer :math:`n`.\n\nExamples\n--------\nExamples using the default ``start`` and ``stop`` values:\n\n>>> coprime_integers(1)\n(1,)\n>>> coprime_integers(2)\n(1,)\n>>> coprime_integers(3)\n(2, 1)\n>>> coprime_integers(4)\n(3, 1)\n>>> coprime_integers(5)\n(4, 3, 2, 1)\n>>> coprime_integers(6)\n(5, 1)\n>>> coprime_integers(7)\n(6, 5, 4, 3, 2, 1)\n>>> coprime_integers(8)\n(7, 5, 3, 1)\n>>> coprime_integers(9)\n(8, 7, 5, 4, 2, 1)\n>>> coprime_integers(10)\n(9, 7, 3, 1)\n>>> coprime_integers(11)\n(10, 9, 8, 7, 6, 5, 4, 3, 2, 1)\n\nExamples using custom ``start`` and ``stop`` values:\n\n>>> coprime_integers(3, start=2)\n(2,)\n>>> coprime_integers(3, start=3)\nTraceback (most recent call last):\n...    \nValueError: `n` must be a positive integer; if `n` > 1 then the `start` value must be a positive integer in the range 1..n - 1; and if given the `stop` value must be a positive integer in the range `start` + 1..n\n>>> coprime_integers(23, start=5, stop=21)\n(21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5)\n>>> coprime_integers(5, start=2)\n(4, 3, 2)\n>>> coprime_integers(5, start=3)\n(4, 3)\n>>> coprime_integers(6, start=2)\n(5,)\n>>> coprime_integers(6, start=3)\n(5,)\n>>> coprime_integers(6, start=4)\n(5,)\n>>> coprime_integers(7, start=2)\n(6, 5, 4, 3, 2)\n>>> coprime_integers(7, start=3)\n(6, 5, 4, 3)\n>>> coprime_integers(7, start=4)\n(6, 5, 4)\n>>> coprime_integers(7, start=5)\n(6, 5)",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "coprime_pairs_generator",
                        "docstring": "Generates a sequence (tuple) of all pairs of (positive) coprime integers :math:`<= n`.\n\nCalls the KSRM tree :py:meth:`~continuedfractions.sequences.KSRMTree.search`\nto perform the search up to :math:`n - 1` and then uses\n:py:func:`~continuedfractions.sequences.coprime_integers` for the search\nfor pairs involving :math:`n`.\n\nA :py:class:`ValueError` is raised if ``n`` is not an :py:class:`int`\nor is an :py:class:`int` less than :math:`1`.\n\nParameters\n----------\nn : int\n    The positive integer for which coprime pairs :math:`(a, b)`, with\n    :math:`1 \\leq b < a \\leq n`, are sought.\n\nRaises\n------\nValueError\n    If ``n`` is not an :py:class:`int` or is an :py:class:`int` less than\n    :math:`1`.\n\nYields\n------\ntuple\n    A :py:class:`tuple` of pairs of coprime integers :math:`(a, b)`, with\n    :math:`1 \\leq b < a \\leq n`.\n\nExamples\n--------\nA few examples of coprime pairs generation:\n\n>>> tuple(coprime_pairs_generator(1))\n((1, 1),)\n>>> tuple(coprime_pairs_generator(2))\n((1, 1), (2, 1))\n>>> tuple(coprime_pairs_generator(3))\n((1, 1), (2, 1), (3, 2), (3, 1))\n>>> tuple(coprime_pairs_generator(5))\n((1, 1), (2, 1), (3, 2), (3, 1), (4, 3), (4, 1), (5, 4), (5, 3), (5, 2), (5, 1))\n>>> tuple(coprime_pairs_generator(10))\n((1, 1), (2, 1), (3, 2), (4, 3), (5, 4), (6, 5), (7, 6), (8, 7), (8, 3), (7, 2), (5, 2), (8, 5), (4, 1), (7, 4), (6, 1), (8, 1), (3, 1), (5, 3), (7, 5), (7, 3), (5, 1), (7, 1), (9, 8), (9, 7), (9, 5), (9, 4), (9, 2), (9, 1), (10, 9), (10, 7), (10, 3), (10, 1))",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "coprime_pairs",
                        "docstring": "Returns a sequence (tuple) of all pairs of (positive) coprime integers :math:`<= n`.\n\nWrapper of :py:func:`~continuedfractions.sequences.coprime_pairs_generator`.\n\nParameters\n----------\nn : int\n    The positive integer for which coprime pairs :math:`(a, b)`, with\n    :math:`1 \\leq b < a \\leq n`, are sought.\n\nReturns\n-------\ntuple\n    A :py:class:`tuple` of pairs of coprime integers :math:`(a, b)`, with\n    :math:`1 \\leq b < a \\leq n`.\n\nExamples\n--------\nA few examples of computing coprime pairs:\n\n>>> coprime_pairs(1)\n((1, 1),)\n>>> coprime_pairs(2)\n((1, 1), (2, 1))\n>>> coprime_pairs(3)\n((1, 1), (2, 1), (3, 2), (3, 1))\n>>> coprime_pairs(5)\n((1, 1), (2, 1), (3, 2), (3, 1), (4, 3), (4, 1), (5, 4), (5, 3), (5, 2), (5, 1))\n>>> coprime_pairs(10)\n((1, 1), (2, 1), (3, 2), (4, 3), (5, 4), (6, 5), (7, 6), (8, 7), (8, 3), (7, 2), (5, 2), (8, 5), (4, 1), (7, 4), (6, 1), (8, 1), (3, 1), (5, 3), (7, 5), (7, 3), (5, 1), (7, 1), (9, 8), (9, 7), (9, 5), (9, 4), (9, 2), (9, 1), (10, 9), (10, 7), (10, 3), (10, 1))",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "farey_sequence_generator",
                        "docstring": "Generates an (ordered) sequence (tuple) of rational numbers forming the Farey sequence of order :math:`n`.\n\nThe elements of the sequence are yielded as\n:py:class:`~continuedfractions.continuedfraction.ContinuedFraction`\ninstances, in ascending order of magnitude.\n\nSee the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/sequences.html#sequences-farey-sequences>`_\nfor more details.\n\nParameters\n----------\nn : int:\n    The order of the Farey sequence.\n\nRaises\n------\nValueError\n    If :math:`n` is not a positive integer.\n\nYields\n------\nContinuedFraction\n    A sequence of\n    :py:class:`~continuedfractions.continuedfraction.ContinuedFraction`\n    instances representing the elements of the Farey sequence of order\n    :math:`n`, in ascending order of magnitude.\n\nExamples\n--------\n>>> tuple(farey_sequence_generator(1))\n(ContinuedFraction(0, 1), ContinuedFraction(1, 1))\n>>> tuple(farey_sequence_generator(2))\n(ContinuedFraction(0, 1), ContinuedFraction(1, 2), ContinuedFraction(1, 1))\n>>> tuple(farey_sequence_generator(3))\n(ContinuedFraction(0, 1), ContinuedFraction(1, 3), ContinuedFraction(1, 2), ContinuedFraction(2, 3), ContinuedFraction(1, 1))\n>>> tuple(farey_sequence_generator(4))\n(ContinuedFraction(0, 1), ContinuedFraction(1, 4), ContinuedFraction(1, 3), ContinuedFraction(1, 2), ContinuedFraction(2, 3), ContinuedFraction(3, 4), ContinuedFraction(1, 1))\n>>> tuple(farey_sequence_generator(5))\n(ContinuedFraction(0, 1), ContinuedFraction(1, 5), ContinuedFraction(1, 4), ContinuedFraction(1, 3), ContinuedFraction(2, 5), ContinuedFraction(1, 2), ContinuedFraction(3, 5), ContinuedFraction(2, 3), ContinuedFraction(3, 4), ContinuedFraction(4, 5), ContinuedFraction(1, 1))",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "farey_sequence",
                        "docstring": "Returns an (ordered) sequence (tuple) of rational numbers forming the Farey sequence of order :math:`n`.\n\nWrapper of :py:func:`~continuedfractions.sequences.farey_sequence_generator`.\n\nThe elements of the sequence are returned as\n:py:class:`~continuedfractions.continuedfraction.ContinuedFraction`\ninstances, in ascending order of magnitude.\n\nSee the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/sequences.html#sequences-farey-sequences>`_\nfor more details.\n\nParameters\n----------\nn : int:\n    The order of the Farey sequence.\n\nReturns\n-------\ntuple\n    A :py:class:`tuple` of ``ContinuedFraction`` instances representing the\n    elements of the Farey sequence of order :math:`n`, generated in\n    ascending order of magnitude.\n\nExamples\n--------\n>>> farey_sequence(1)\n(ContinuedFraction(0, 1), ContinuedFraction(1, 1))\n>>> farey_sequence(2)\n(ContinuedFraction(0, 1), ContinuedFraction(1, 2), ContinuedFraction(1, 1))\n>>> farey_sequence(3)\n(ContinuedFraction(0, 1), ContinuedFraction(1, 3), ContinuedFraction(1, 2), ContinuedFraction(2, 3), ContinuedFraction(1, 1))\n>>> farey_sequence(4)\n(ContinuedFraction(0, 1), ContinuedFraction(1, 4), ContinuedFraction(1, 3), ContinuedFraction(1, 2), ContinuedFraction(2, 3), ContinuedFraction(3, 4), ContinuedFraction(1, 1))\n>>> farey_sequence(5)\n(ContinuedFraction(0, 1), ContinuedFraction(1, 5), ContinuedFraction(1, 4), ContinuedFraction(1, 3), ContinuedFraction(2, 5), ContinuedFraction(1, 2), ContinuedFraction(3, 5), ContinuedFraction(2, 3), ContinuedFraction(3, 4), ContinuedFraction(4, 5), ContinuedFraction(1, 1))",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": [
                    {
                        "name": "KSRMTree",
                        "docstring": "An implicit/generative class implementation of the Kanga-Saunders-Randall-Mitchell (KSRM) ternary trees for representing and generating pairs of all (positive) coprime integers.\n\nThe term \"KSRM trees\" is the author's, and refers to the trees presented in the following papers:\n\n* Kanga, A. R. (1990). The Family Tree of Pythagorean Triplets. The Mathematical Gazette, 26(15), 15-17.\n* Mitchell, D. W. (2001). An Alternative Characterisation of All Primitive Pythagorean Triples. The Mathematical Gazette, 85(503), 273-275. https://doi.org/10.2307/3622017\n* Saunders, R., & Randall, T. (1994). The family tree of the Pythagorean triplets revisited. The Mathematical Gazette, 78(482), 190-193. https://doi.org/10.2307/3618576\n\n.. note::\n\n   The class is named ``KSRMTree`` purely for convenience, but it is\n   actually a representation of two (ternary) subtrees.\n\n.. note::\n\n   The author could not access the Kanga paper online, but the core result\n   is described clearly in the papers of Saunders and Randall, and of\n   Mitchell.\n\nSee the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/sequences.html#ksrm-trees>`_\nfor more details.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__new__",
                                "docstring": "Class constructor.\n\nCreates and initialises a new instance with the minimum set of required\nattributes - for the roots and branch generating functions, which we\ncall branches.",
                                "comments": null,
                                "args": [
                                    "cls"
                                ]
                            },
                            {
                                "name": "roots",
                                "docstring": ":py:class:`tuple`: The tuple of roots of the KSRM trees, which are :math:`(2, 1)` and :math:`(3, 1)`.\n\nFor more details see the following papers:\n\n* Kanga, A. R. (1990). The Family Tree of Pythagorean Triplets. The Mathematical Gazette, 26(15), 15-17.\n* Mitchell, D. W. (2001). An Alternative Characterisation of All Primitive Pythagorean Triples. The Mathematical Gazette, 85(503), 273-275. https://doi.org/10.2307/3622017\n* Saunders, R., & Randall, T. (1994). The family tree of the Pythagorean triplets revisited. The Mathematical Gazette, 78(482), 190-193. https://doi.org/10.2307/3618576\n\nor the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/sequences.html#ksrm-trees>`_.\n\nExamples\n--------\n>>> KSRMTree().roots\n((2, 1), (3, 1))",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "branches",
                                "docstring": ":py:class:`tuple`: The tuple of three branch generating functions of the KSRM trees.\n\nThere are three branch generating functions, given by the mappings:\n\n.. math::\n\n   \\begin{align}\n   (a, b) &\\longmapsto (2a - b, a) \\\\\n   (a, b) &\\longmapsto (2a + b, a) \\\\\n   (a, b) &\\longmapsto (a + 2b, b)\n   \\end{align}\n\nFor more details see the following papers:\n\n* Kanga, A. R. (1990). The Family Tree of Pythagorean Triplets. The Mathematical Gazette, 26(15), 15-17.\n* Mitchell, D. W. (2001). An Alternative Characterisation of All Primitive Pythagorean Triples. The Mathematical Gazette, 85(503), 273-275. https://doi.org/10.2307/3622017\n* Saunders, R., & Randall, T. (1994). The family tree of the Pythagorean triplets revisited. The Mathematical Gazette, 78(482), 190-193. https://doi.org/10.2307/3618576\n\nor the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/sequences.html#ksrm-trees>`_.\n\nExamples\n--------\nGenerating the first two generations of children for the parent\n:math:`(2, 1)`.\n\n>>> tree = KSRMTree()\n>>> tree.branches\n(NamedCallableProxy(\"KSRM tree branch #1: (x, y) |--> (2x - y, x)\"), NamedCallableProxy(\"KSRM tree branch #2: (x, y) |--> (2x + y, x)\"), NamedCallableProxy(\"KSRM tree branch #3: (x, y) |--> (x + 2y, y)\"))\n>>> tree.branches[0](2, 1)\n(3, 2)\n>>> tree.branches[1](2, 1)\n(5, 2)\n>>> tree.branches[2](2, 1)\n(4, 1)\n>>> tree.branches[0](*tree.branches[0](2, 1))\n(4, 3)\n>>> tree.branches[1](*tree.branches[0](2, 1))\n(8, 3)\n>>> tree.branches[2](*tree.branches[0](2, 1))\n(7, 2)\n>>> tree.branches[0](*tree.branches[1](2, 1))\n(8, 5)\n>>> tree.branches[1](*tree.branches[1](2, 1))\n(12, 5)\n>>> tree.branches[2](*tree.branches[1](2, 1))\n(9, 2)\n>>> tree.branches[0](*tree.branches[2](2, 1))\n(7, 4)\n>>> tree.branches[1](*tree.branches[2](2, 1))\n(9, 4)\n>>> tree.branches[2](*tree.branches[2](2, 1))\n(6, 1)",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "_backtrack",
                                "docstring": "Backtracks on the KSRM coprime pairs trees from a failed node to the nearest previously visited node that satisfies the node bound.\n\nA private function that backtracks on the KSRM coprime pairs trees: the\nprocedure is that, given a (positive) integer :math:`n > 2`, for which\ncoprime pairs are being sought, and a sequence (list) of pairs of\nvisited nodes and their associated generating branches in the KSRM\ntree, and assuming that the last element of the visited sequence\ncontains the node that \"failed\", the function identifies the nearest\npreviously visited node whose first component satisifes the test\n:math:`< n` **and** and whose associated generating branch is not equal\nto the third branch given by :math:`(x, y) \\longmapsto (x + 2y, y)`.\n\n.. note::\n\n   The function assumes that the last node in the incoming sequence\n   of visited nodes and generating branch pairs represents a \"failed\"\n   node, i.e. whose first component failed the test :math:`\\leq n`\n   during the search. No attempt is made to validate or verify the\n   failed node, and the only purpose of the function is to backtrack\n   to the nearest previously visited node which meets the requirements\n   listed above.\n\n.. note::\n\n   There is no input validation as this is a private function which\n   will be called from\n   :py:meth:`~continuedfractions.sequences.KSRMTree.search_root`. So\n   results for invalid arguments will most likely be incorrect or\n   unexpected.\n\nParameters\n----------\nn : int\n    The (positive) integer :math:`> 2` which is passed by the root\n    search method or the general tree search method.\n\nvisited : list\n    A sequence of visited nodes and associated generating branches in\n    the KSRM coprime pairs tree.\n\nnode_bound : int, default=None\n    A bound to check that :math:`a < n` for a node :math:`(a, b)`. The\n    actual default value is the incoming :math:`n`, and this is set\n    internally.\n\nReturns\n-------\ntuple\n    A tuple consisting of the following values in order: (1) the\n    target node in the visited sequence to backtrack to, (2) the\n    associated generating branch function (the lambda for branch #1,\n    or branch #2, or branch #3), (3) the index of the target node\n    and branch pair in the visited sequence, (4) the generating\n    branch of the successor node of the target node returned as (1).\n\nExamples\n--------\nAn example where :math:`n = 5` and the failed node is :math:`(6, 1)`,\nwhich was the successor node to :math:`(4, 1)` from the third branch.\n\n>>> tree = KSRMTree()\n>>> tree.branches\n(NamedCallableProxy(\"KSRM tree branch #1: (x, y) |--> (2x - y, x)\"), NamedCallableProxy(\"KSRM tree branch #2: (x, y) |--> (2x + y, x)\"), NamedCallableProxy(\"KSRM tree branch #3: (x, y) |--> (x + 2y, y)\"))\n>>> visited = [((2, 1), None), ((4, 1), tree.branches[-1]), ((6, 1), tree.branches[-1])]\n>>> tree._backtrack(5, visited)\n((2, 1), None, 0, NamedCallableProxy(\"KSRM tree branch #3: (x, y) |--> (x + 2y, y)\"))\n\nAn example where :math:`n = 8` and the failed node is :math:`(19, 8)`,\nwhich was the successor node to :math:`(8, 3)` from the first branch.\n\n>>> tree = KSRMTree()\n>>> tree.branches\n(NamedCallableProxy(\"KSRM tree branch #1: (x, y) |--> (2x - y, x)\"), NamedCallableProxy(\"KSRM tree branch #2: (x, y) |--> (2x + y, x)\"), NamedCallableProxy(\"KSRM tree branch #3: (x, y) |--> (x + 2y, y)\"))\n>>> visited = [((2, 1), None), ((3, 2),tree.branches[0]), ((8, 3),tree.branches[1]), ((19, 8), tree.branches[0])]\n>>> tree._backtrack(8, visited)\n((3, 2), NamedCallableProxy(\"KSRM tree branch #1: (x, y) |--> (2x - y, x)\"), 1, NamedCallableProxy(\"KSRM tree branch #2: (x, y) |--> (2x + y, x)\"))",
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "search_root",
                                "docstring": "Depth-first branch-and-bound generative search function (in pre-order, NLMR), with backtracking and pruning, on the KSRM coprime pairs trees, starting from the given root node.\n\nThe given root node need not be the canonical roots, :math:`(2, 1)`,\n:math:`(3, 1)`, but can be any of their successor nodes.\n\nIt is required that :math:`n \\geq 2`, otherwise a\n:py:class:`ValueError` is raised.\n\nThe search implementation is an iterative version of a depth-first\nbranch-and-bound search (DFS) procedure, with backtracking and pruning,\nin which nodes are traversed in NLMR pre-order (root -> left -> mid ->\nright) and bounds and checks are applied to the nodes, including\npruning failed or unnecessary nodes, before further traversal or\nbacktracking:\n\n#. Visit the current node :math:`(a, b)` and check :math:`a \\leq n`.\n#. If the check is successful iteratively traverse the current node's\n   first child and its children, then the second child and its \n   children, and then the third child and its children, applying the\n   check :math:`a \\leq n` to each visited node.\n#. If a check fails for any node backtrack to the nearest previously\n   visited node which meets a stricter check :math:`a < n` and which\n   has unvisited child nodes, while pruning all visited intermediate\n   nodes after the backtracked target node and leading up to the failed\n   node, including the failed node. By design the backtracked target\n   node will have untraversed children on at least one branch, and the\n   traversal can begin again, as described above.\n\nParameters\n----------\nn : int\n    The positive integer for which coprime pairs :math:`(a, b)`, with\n    :math:`1 \\leq b < a \\leq n`, are sought.\n\nroot : tuple\n    The \"root\" node from which to search - this can be either of the\n    canonical roots, :math:`(2, 1)`, :math:`(3, 1)`, but also any of\n    their successor nodes.\n\nRaises\n------\nValueError\n    If ``n`` is not an integer or is :math:`< 2`.\n\nYields\n------\ntuple\n    Pairs of coprime integers :math:`(a, b)`, with\n    :math:`1 \\leq b < a \\leq n`.\n\nExamples\n--------\nSearching from the root :math:`(2, 1)` for coprime pairs for\n:math:`n = 5`:\n\n>>> tree = KSRMTree()\n>>> list(tree.search_root(5, (2, 1)))\n[(2, 1), (3, 2), (4, 3), (5, 4), (5, 2), (4, 1)]\n>>> assert tree.roots[0] == (2, 1)\n>>> list(tree.search_root(5, tree.roots[0]))\n[(2, 1), (3, 2), (4, 3), (5, 4), (5, 2), (4, 1)]\n\nThe same type of search from the root :math:`(3, 1)`:\n\n>>> list(tree.search_root(5, (3, 1)))\n[(3, 1), (5, 3), (5, 1)]\n>>> assert tree.roots[1] == (3, 1)\n>>> list(tree.search_root(5, tree.roots[1]))\n[(3, 1), (5, 3), (5, 1)]",
                                "comments": null,
                                "args": []
                            },
                            {
                                "name": "search",
                                "docstring": "Depth-first branch-and-bound generative search function (in pre-order, NLMR) on the KSRM coprime pairs trees to find all pairs of coprime (positive) integers not exceeding the given integer :math:`n \\geq 1`.\n\nSee the :py:meth:`~continuedfractions.sequences.KSRMTree.search_root`\nmethod for details of the implementation for the root-based search.\n\nThis method mainly calls the root-based search method\n:py:meth:`~continuedfractions.sequences.KSRMTree.search_root` for the\ntwo canonical roots :math:`(2, 1)` and :math:`(3, 1)`.\n\nParameters\n----------\nn : int\n    The positive integer for which coprime pairs :math:`(a, b)`, with\n    :math:`1 \\leq b < a \\leq n`, are sought.\n\nRaises\n------\nValueError\n    If ``n`` is not an integer or is :math:`< 1`.\n\nYields\n------\ntuple\n    Pairs of coprime integers :math:`(a, b)`, with\n    :math:`1 \\leq b < a \\leq n`.\n\nExamples\n--------\nA few examples of invalid and valid searches:\n\n>>> tree = KSRMTree()\n>>> list(tree.search(\"not an integer\"))\nTraceback (most recent call last):\n...\nValueError: `n` must be a positive integer >= 1\n>>> list(tree.search(1))\n[(1, 1)]\n>>> list(tree.search(2))\n[(1, 1), (2, 1)]\n>>> list(tree.search(3))\n[(1, 1), (2, 1), (3, 2), (3, 1)]\n>>> list(tree.search(5))\n[(1, 1), (2, 1), (3, 2), (4, 3), (4, 1), (3, 1), (5, 4), (5, 3), (5, 2), (5, 1)]\n>>> list(tree.search(10))\n[(1, 1), (2, 1), (3, 2), (4, 3), (5, 4), (6, 5), (7, 6), (8, 7), (9, 8), (8, 3), (7, 2), (5, 2), (8, 5), (9, 2), (4, 1), (7, 4), (9, 4), (6, 1), (8, 1), (3, 1), (5, 3), (7, 5), (9, 7), (7, 3), (5, 1), (9, 5), (7, 1), (9, 1), (10, 9), (10, 7), (10, 3), (10, 1)]",
                                "comments": null,
                                "args": []
                            }
                        ],
                        "attributes": [
                            "__slots__"
                        ]
                    }
                ]
            }
        ],
        "test_cases": {
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements0-expected0]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements0-expected0]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned(self, elements, expected):\n            received = ContinuedFraction.from_elements(*elements)\n\n            assert received == expected\n            assert received.elements == expected.elements"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements3]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements3]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__invalid_elements__value_error_raised(self, invalid_elements):\n        with pytest.raises(ValueError):\n            ContinuedFraction.from_elements(*invalid_elements)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf15-cf25-1-expected_right_mediant5]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf15-cf25-1-expected_right_mediant5]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_right_mediant):\n    \n        assert cf1.right_mediant(cf2, k=k) == expected_right_mediant"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand10-expected10-expected_elements10]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand10-expected10-expected_elements10]",
                "result": "passed",
                "test_implementation": "    def test___neg__(self, operand, expected, expected_elements):\n        received = -operand\n\n        assert expected == received\n        assert received.elements == expected_elements"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements1-expected1]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements1-expected1]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned(self, elements, expected):\n            received = ContinuedFraction.from_elements(*elements)\n\n            assert received == expected\n            assert received.elements == expected.elements"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[4-4-expected_semiconvergent9]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[4-4-expected_semiconvergent9]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned(self, k, m, expected_semiconvergent):\n        test_cf = ContinuedFraction(-415, 93)\n\n        assert test_cf.semiconvergent(k, m) == expected_semiconvergent\n        assert test_cf.semiconvergent(k, m) == test_cf.convergent(k - 1).right_mediant(test_cf.convergent(k), k=m)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand6-expected6-expected_elements6]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand6-expected6-expected_elements6]",
                "result": "passed",
                "test_implementation": "    def test___neg__(self, operand, expected, expected_elements):\n        received = -operand\n\n        assert expected == received\n        assert received.elements == expected_elements"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs16-expected_fraction_obj16-expected_elements16-3-expected_counter16-expected_khinchin_mean16-expected_convergents16-expected_ref_right_order2_mediant16-expected_ref_left_order2_mediant16-expected_ref_simple_mediant16-3.245-expected_decimal_value16]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs16-expected_fraction_obj16-expected_elements16-3-expected_counter16-expected_khinchin_mean16-expected_convergents16-expected_ref_right_order2_mediant16-expected_ref_left_order2_mediant16-expected_ref_simple_mediant16-3.245-expected_decimal_value16]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised(\n        self,\n        valid_inputs,\n        expected_fraction_obj,\n        expected_elements,\n        expected_order,\n        expected_counter,\n        expected_khinchin_mean,\n        expected_convergents,\n        expected_ref_right_order2_mediant,\n        expected_ref_left_order2_mediant,\n        expected_ref_simple_mediant,\n        expected_float_value,\n        expected_decimal_value\n    ):\n        expected = expected_fraction_obj\n\n        # The received ``ContinuedFraction`` object\n        received = ContinuedFraction(*valid_inputs)\n\n        # Compare the received and expected objects AS ``fractions.Fraction``\n        # objects\n        assert received == expected\n\n        # Compare the float values\n        assert received.as_float() == expected_float_value\n\n        # Compare the decimal values\n        try:\n            assert received.as_decimal() == expected_decimal_value\n        except decimal.Inexact:\n            pass\n\n        # Compare the element sequences\n        assert received.elements == expected_elements\n\n        # Compare the orders\n        assert received.order == expected_order\n\n        # Compare the element counters\n        assert received.counter == expected_counter\n\n        # Compare the Khinchin means\n        assert received.khinchin_mean == expected_khinchin_mean\n\n        # Compare the convergents using the ``.convergent`` method\n        assert not any(\n            received.convergent(k) != expected_convergents[k][1]\n            for k in range(received.order + 1)\n        )\n\n        # Compare the convergents using the ``.convergents`` property\n        assert tuple(received.convergents) == expected_convergents\n\n        # Compare the even-order convergents using the ``.even_order_convergents` property\n        assert tuple(received.even_convergents) == tuple((k, expected_convergents[k][1]) for k in range(0, received.order + 1, 2))\n\n        # Compare the order-order convergents using the ``.odd_order_convergents` property\n        assert tuple(received.odd_convergents) == tuple((k, expected_convergents[k][1]) for k in range(1, received.order + 1, 2))\n\n        # Compare the 2nd order right- and left-mediants, and also the simple\n        # mediant, using a reference continued fraction of ``1/1``\n        assert received.right_mediant(1, k=2) == expected_ref_right_order2_mediant\n        assert received.left_mediant(1, k=2) == expected_ref_left_order2_mediant\n        assert received.mediant(1) == expected_ref_simple_mediant\n\n        expected_remainders = tuple(\n            (k, ContinuedFraction.from_elements(*expected_elements[k:]))\n            for k in reversed(range(received.order + 1))\n        )\n        # Compare the remainders using the ``.remainder`` method\n        assert all(\n            received.remainder(k) == expected_remainders[::-1][k][1]\n            for k in reversed(range(received.order + 1))\n        )\n\n        # Compare the remainders using the ``.remainders`` property\n        assert tuple(received.remainders) == expected_remainders"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance9-new_elements9-expected_comparative_instance9]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance9-new_elements9-expected_comparative_instance9]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__extend__valid_elements__correctly_extended(self, instance, new_elements, expected_comparative_instance):\n        original_id = id(instance)\n        original_elements = instance.elements\n\n        instance.extend(*new_elements)\n\n        assert id(instance) == original_id\n        assert instance == expected_comparative_instance\n        assert hash(instance) == hash(expected_comparative_instance)\n        assert instance == ContinuedFraction.from_elements(*original_elements, *new_elements)\n        assert instance.order == expected_comparative_instance.order\n        assert instance.counter == expected_comparative_instance.counter\n        assert tuple(instance.convergents) == tuple(expected_comparative_instance.convergents)\n        assert tuple(instance.remainders) == tuple(expected_comparative_instance.remainders)\n        assert instance.khinchin_mean == expected_comparative_instance.khinchin_mean"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__invalid_elements__value_error_raised[instance0-invalid_elements0]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__invalid_elements__value_error_raised[instance0-invalid_elements0]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__truncate__invalid_elements__value_error_raised(self, instance, invalid_elements):\n        with pytest.raises(ValueError):\n            instance.truncate(*invalid_elements)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements4]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements4]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__invalid_elements__value_error_raised(self, invalid_elements):\n        with pytest.raises(ValueError):\n            ContinuedFraction.from_elements(*invalid_elements)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements5]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements5]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__invalid_elements__value_error_raised(self, invalid_elements):\n        with pytest.raises(ValueError):\n            ContinuedFraction.from_elements(*invalid_elements)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand7-expected7-expected_elements7]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand7-expected7-expected_elements7]",
                "result": "passed",
                "test_implementation": "    def test___neg__(self, operand, expected, expected_elements):\n        received = -operand\n\n        assert expected == received\n        assert received.elements == expected_elements"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand8-expected8-expected_elements8]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand8-expected8-expected_elements8]",
                "result": "passed",
                "test_implementation": "    def test___neg__(self, operand, expected, expected_elements):\n        received = -operand\n\n        assert expected == received\n        assert received.elements == expected_elements"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__invalid_elements__value_error_raised[instance1-invalid_elements1]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__invalid_elements__value_error_raised[instance1-invalid_elements1]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__truncate__invalid_elements__value_error_raised(self, instance, invalid_elements):\n        with pytest.raises(ValueError):\n            instance.truncate(*invalid_elements)"
            },
            "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__invalid_elements__value_error_raised[elements2]": {
                "testid": "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__invalid_elements__value_error_raised[elements2]",
                "result": "passed",
                "test_implementation": "\tdef test_fraction_from_elements__invalid_elements__value_error_raised(self, elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tfraction_from_elements(*elements)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__rational_operations": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__rational_operations",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__rational_operations(self):\n        f0 = ContinuedFraction(2, 1)\n        f1 = ContinuedFraction(649, 200)\n        f2 = ContinuedFraction(-649, 200)\n        f3 = ContinuedFraction(3, 2)\n        f4 = ContinuedFraction(5, 3)\n\n        assert -f0 == -(f0) == f0.__neg__() == ContinuedFraction(*convergent(0, -2).as_integer_ratio())\n\n        assert -f1 == f2 == f1.__neg__() == ContinuedFraction(*convergent(4, -4, 1, 3, 12, 4).as_integer_ratio())\n\n        assert -f2 == f1 == f2.__neg__()\n\n        assert -f3 == -(f3) == f3.__neg__() == ContinuedFraction(*convergent(1, -2, 2).as_integer_ratio())\n\n        assert -f4 == -(f4) == f4.__neg__() == ContinuedFraction(*convergent(1, -2, 3).as_integer_ratio())\n\n        assert f1 + f2 == ContinuedFraction(0, 1)\n\n        assert f1 + 1 == 1 + f1 == ContinuedFraction('4.245')\n\n        assert f1.__radd__(f2) == f2.__radd__(f1)\n\n        assert f1.__radd__(1) == 1 + f1\n\n        assert f1 - f2 == ContinuedFraction(649, 100)\n\n        assert f1 - 1 == ContinuedFraction('2.245')\n\n        assert 1 - f1 == f1.__rsub__(1) == ContinuedFraction('-2.245')\n\n        assert f1 - 4 == ContinuedFraction('-0.755')\n\n        assert 4 - f1 == ContinuedFraction('0.755')\n\n        assert f1.__rsub__(f2) == f2.__radd__(-f1)\n\n        assert -f1 + f2 == ContinuedFraction(-649, 100)\n\n        assert -f1 - f2 == ContinuedFraction(0, 1)\n\n        assert f1 * f2 == ContinuedFraction(-421201, 40000)\n\n        assert f1.__rmul__(f2) == f2.__rmul__(f1)\n\n        assert f1 * 0 == f2 * 0 == ContinuedFraction(0, 1)\n\n        assert f1 * 1 == f2 * -1\n\n        assert f1 / f2 == ContinuedFraction(-1, 1)\n\n        assert f1 // f2 == f2 // f1\n\n        assert f1 // 2 == ContinuedFraction(1, 1)\n\n        assert 2 // f1 == ContinuedFraction(0, 1)\n\n        assert f1 * (1 / f2) == f1 * (f2 ** -1) == ContinuedFraction(-1, 1)\n\n        assert divmod(f1, f2) == (ContinuedFraction(-1, 1), ContinuedFraction(0, 1))\n\n        assert f1.__rdivmod__(f2) == (ContinuedFraction(-1, 1), ContinuedFraction(0, 1))\n\n        assert f1.__rdivmod__(2) == (ContinuedFraction(0, 1), ContinuedFraction(2, 1))\n\n        assert f2.__rdivmod__(2) == (ContinuedFraction(-1, 1), ContinuedFraction(-249, 200))\n\n        assert f1 ** 3 == ContinuedFraction(273359449, 8000000)\n\n        assert f1.__rpow__(2) == Fraction(2) ** f1\n\n        assert +f1 == f1\n\n        assert -f1 == ContinuedFraction(-f1.numerator, f1.denominator) == ContinuedFraction(Fraction(-f1))\n\n        assert abs(f2) == f1"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand0-expected0-expected_elements0]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand0-expected0-expected_elements0]",
                "result": "passed",
                "test_implementation": "    def test___neg__(self, operand, expected, expected_elements):\n        received = -operand\n\n        assert expected == received\n        assert received.elements == expected_elements"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance5-new_elements5-expected_comparative_instance5]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance5-new_elements5-expected_comparative_instance5]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__extend__valid_elements__correctly_extended(self, instance, new_elements, expected_comparative_instance):\n        original_id = id(instance)\n        original_elements = instance.elements\n\n        instance.extend(*new_elements)\n\n        assert id(instance) == original_id\n        assert instance == expected_comparative_instance\n        assert hash(instance) == hash(expected_comparative_instance)\n        assert instance == ContinuedFraction.from_elements(*original_elements, *new_elements)\n        assert instance.order == expected_comparative_instance.order\n        assert instance.counter == expected_comparative_instance.counter\n        assert tuple(instance.convergents) == tuple(expected_comparative_instance.convergents)\n        assert tuple(instance.remainders) == tuple(expected_comparative_instance.remainders)\n        assert instance.khinchin_mean == expected_comparative_instance.khinchin_mean"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance6-new_elements6-expected_comparative_instance6]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance6-new_elements6-expected_comparative_instance6]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__extend__valid_elements__correctly_extended(self, instance, new_elements, expected_comparative_instance):\n        original_id = id(instance)\n        original_elements = instance.elements\n\n        instance.extend(*new_elements)\n\n        assert id(instance) == original_id\n        assert instance == expected_comparative_instance\n        assert hash(instance) == hash(expected_comparative_instance)\n        assert instance == ContinuedFraction.from_elements(*original_elements, *new_elements)\n        assert instance.order == expected_comparative_instance.order\n        assert instance.counter == expected_comparative_instance.counter\n        assert tuple(instance.convergents) == tuple(expected_comparative_instance.convergents)\n        assert tuple(instance.remainders) == tuple(expected_comparative_instance.remainders)\n        assert instance.khinchin_mean == expected_comparative_instance.khinchin_mean"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs4-expected_fraction_obj4-expected_elements4-4-expected_counter4-expected_khinchin_mean4-expected_convergents4-expected_ref_right_order2_mediant4-expected_ref_left_order2_mediant4-expected_ref_simple_mediant4--3.245-expected_decimal_value4]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs4-expected_fraction_obj4-expected_elements4-4-expected_counter4-expected_khinchin_mean4-expected_convergents4-expected_ref_right_order2_mediant4-expected_ref_left_order2_mediant4-expected_ref_simple_mediant4--3.245-expected_decimal_value4]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised(\n        self,\n        valid_inputs,\n        expected_fraction_obj,\n        expected_elements,\n        expected_order,\n        expected_counter,\n        expected_khinchin_mean,\n        expected_convergents,\n        expected_ref_right_order2_mediant,\n        expected_ref_left_order2_mediant,\n        expected_ref_simple_mediant,\n        expected_float_value,\n        expected_decimal_value\n    ):\n        expected = expected_fraction_obj\n\n        # The received ``ContinuedFraction`` object\n        received = ContinuedFraction(*valid_inputs)\n\n        # Compare the received and expected objects AS ``fractions.Fraction``\n        # objects\n        assert received == expected\n\n        # Compare the float values\n        assert received.as_float() == expected_float_value\n\n        # Compare the decimal values\n        try:\n            assert received.as_decimal() == expected_decimal_value\n        except decimal.Inexact:\n            pass\n\n        # Compare the element sequences\n        assert received.elements == expected_elements\n\n        # Compare the orders\n        assert received.order == expected_order\n\n        # Compare the element counters\n        assert received.counter == expected_counter\n\n        # Compare the Khinchin means\n        assert received.khinchin_mean == expected_khinchin_mean\n\n        # Compare the convergents using the ``.convergent`` method\n        assert not any(\n            received.convergent(k) != expected_convergents[k][1]\n            for k in range(received.order + 1)\n        )\n\n        # Compare the convergents using the ``.convergents`` property\n        assert tuple(received.convergents) == expected_convergents\n\n        # Compare the even-order convergents using the ``.even_order_convergents` property\n        assert tuple(received.even_convergents) == tuple((k, expected_convergents[k][1]) for k in range(0, received.order + 1, 2))\n\n        # Compare the order-order convergents using the ``.odd_order_convergents` property\n        assert tuple(received.odd_convergents) == tuple((k, expected_convergents[k][1]) for k in range(1, received.order + 1, 2))\n\n        # Compare the 2nd order right- and left-mediants, and also the simple\n        # mediant, using a reference continued fraction of ``1/1``\n        assert received.right_mediant(1, k=2) == expected_ref_right_order2_mediant\n        assert received.left_mediant(1, k=2) == expected_ref_left_order2_mediant\n        assert received.mediant(1) == expected_ref_simple_mediant\n\n        expected_remainders = tuple(\n            (k, ContinuedFraction.from_elements(*expected_elements[k:]))\n            for k in reversed(range(received.order + 1))\n        )\n        # Compare the remainders using the ``.remainder`` method\n        assert all(\n            received.remainder(k) == expected_remainders[::-1][k][1]\n            for k in reversed(range(received.order + 1))\n        )\n\n        # Compare the remainders using the ``.remainders`` property\n        assert tuple(received.remainders) == expected_remainders"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[1--1]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[1--1]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__invalid_args(self, k, m):\n        test_cf = ContinuedFraction(-415, 93)\n\n        with pytest.raises(ValueError):\n            test_cf.semiconvergent(k, m)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[0-0]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[0-0]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__invalid_args(self, k, m):\n        test_cf = ContinuedFraction(-415, 93)\n\n        with pytest.raises(ValueError):\n            test_cf.semiconvergent(k, m)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[1-0]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[1-0]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__invalid_args(self, k, m):\n        test_cf = ContinuedFraction(-415, 93)\n\n        with pytest.raises(ValueError):\n            test_cf.semiconvergent(k, m)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance2-tail_elements2-expected_comparative_instance2]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance2-tail_elements2-expected_comparative_instance2]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__truncate__valid_elements__correctly_truncated(self, instance, tail_elements, expected_comparative_instance):\n        original_id = id(instance)\n        original_elements = instance.elements\n        order = instance.order\n        truncation_length = len(tail_elements)\n\n        instance.truncate(*tail_elements)\n\n        assert id(instance) == original_id\n        assert instance == expected_comparative_instance\n        assert hash(instance) == hash(expected_comparative_instance)\n        assert instance == ContinuedFraction.from_elements(*original_elements[:order + 1 - truncation_length])\n        assert instance.order == expected_comparative_instance.order\n        assert instance.counter == expected_comparative_instance.counter\n        assert tuple(instance.convergents) == tuple(expected_comparative_instance.convergents)\n        assert tuple(instance.remainders) == tuple(expected_comparative_instance.remainders)\n        assert instance.khinchin_mean == expected_comparative_instance.khinchin_mean"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance3-tail_elements3-expected_comparative_instance3]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance3-tail_elements3-expected_comparative_instance3]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__truncate__valid_elements__correctly_truncated(self, instance, tail_elements, expected_comparative_instance):\n        original_id = id(instance)\n        original_elements = instance.elements\n        order = instance.order\n        truncation_length = len(tail_elements)\n\n        instance.truncate(*tail_elements)\n\n        assert id(instance) == original_id\n        assert instance == expected_comparative_instance\n        assert hash(instance) == hash(expected_comparative_instance)\n        assert instance == ContinuedFraction.from_elements(*original_elements[:order + 1 - truncation_length])\n        assert instance.order == expected_comparative_instance.order\n        assert instance.counter == expected_comparative_instance.counter\n        assert tuple(instance.convergents) == tuple(expected_comparative_instance.convergents)\n        assert tuple(instance.remainders) == tuple(expected_comparative_instance.remainders)\n        assert instance.khinchin_mean == expected_comparative_instance.khinchin_mean"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[3-3-expected_semiconvergent5]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[3-3-expected_semiconvergent5]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned(self, k, m, expected_semiconvergent):\n        test_cf = ContinuedFraction(-415, 93)\n\n        assert test_cf.semiconvergent(k, m) == expected_semiconvergent\n        assert test_cf.semiconvergent(k, m) == test_cf.convergent(k - 1).right_mediant(test_cf.convergent(k), k=m)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf19-cf29-1000000-expected_right_mediant9]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf19-cf29-1000000-expected_right_mediant9]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_right_mediant):\n    \n        assert cf1.right_mediant(cf2, k=k) == expected_right_mediant"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf10-cf20-expected_simple_mediant0]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf10-cf20-expected_simple_mediant0]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, expected_simple_mediant):\n    \n        assert cf1.mediant(cf2) == expected_simple_mediant"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf11-cf21-expected_simple_mediant1]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf11-cf21-expected_simple_mediant1]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, expected_simple_mediant):\n    \n        assert cf1.mediant(cf2) == expected_simple_mediant"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf13-cf23-expected_simple_mediant3]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf13-cf23-expected_simple_mediant3]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, expected_simple_mediant):\n    \n        assert cf1.mediant(cf2) == expected_simple_mediant"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-5.25-expected26]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-5.25-expected26]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x27-expected27]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x27-expected27]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__invalid_elements__value_error_raised[elements0]": {
                "testid": "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__invalid_elements__value_error_raised[elements0]",
                "result": "passed",
                "test_implementation": "\tdef test_fraction_from_elements__invalid_elements__value_error_raised(self, elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tfraction_from_elements(*elements)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance1-new_elements1-expected_comparative_instance1]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance1-new_elements1-expected_comparative_instance1]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__extend__valid_elements__correctly_extended(self, instance, new_elements, expected_comparative_instance):\n        original_id = id(instance)\n        original_elements = instance.elements\n\n        instance.extend(*new_elements)\n\n        assert id(instance) == original_id\n        assert instance == expected_comparative_instance\n        assert hash(instance) == hash(expected_comparative_instance)\n        assert instance == ContinuedFraction.from_elements(*original_elements, *new_elements)\n        assert instance.order == expected_comparative_instance.order\n        assert instance.counter == expected_comparative_instance.counter\n        assert tuple(instance.convergents) == tuple(expected_comparative_instance.convergents)\n        assert tuple(instance.remainders) == tuple(expected_comparative_instance.remainders)\n        assert instance.khinchin_mean == expected_comparative_instance.khinchin_mean"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance2-new_elements2-expected_comparative_instance2]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance2-new_elements2-expected_comparative_instance2]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__extend__valid_elements__correctly_extended(self, instance, new_elements, expected_comparative_instance):\n        original_id = id(instance)\n        original_elements = instance.elements\n\n        instance.extend(*new_elements)\n\n        assert id(instance) == original_id\n        assert instance == expected_comparative_instance\n        assert hash(instance) == hash(expected_comparative_instance)\n        assert instance == ContinuedFraction.from_elements(*original_elements, *new_elements)\n        assert instance.order == expected_comparative_instance.order\n        assert instance.counter == expected_comparative_instance.counter\n        assert tuple(instance.convergents) == tuple(expected_comparative_instance.convergents)\n        assert tuple(instance.remainders) == tuple(expected_comparative_instance.remainders)\n        assert instance.khinchin_mean == expected_comparative_instance.khinchin_mean"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance4-tail_elements4-expected_comparative_instance4]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance4-tail_elements4-expected_comparative_instance4]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__truncate__valid_elements__correctly_truncated(self, instance, tail_elements, expected_comparative_instance):\n        original_id = id(instance)\n        original_elements = instance.elements\n        order = instance.order\n        truncation_length = len(tail_elements)\n\n        instance.truncate(*tail_elements)\n\n        assert id(instance) == original_id\n        assert instance == expected_comparative_instance\n        assert hash(instance) == hash(expected_comparative_instance)\n        assert instance == ContinuedFraction.from_elements(*original_elements[:order + 1 - truncation_length])\n        assert instance.order == expected_comparative_instance.order\n        assert instance.counter == expected_comparative_instance.counter\n        assert tuple(instance.convergents) == tuple(expected_comparative_instance.convergents)\n        assert tuple(instance.remainders) == tuple(expected_comparative_instance.remainders)\n        assert instance.khinchin_mean == expected_comparative_instance.khinchin_mean"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[1.5-expected6]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[1.5-expected6]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand11-expected11-expected_elements11]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand11-expected11-expected_elements11]",
                "result": "passed",
                "test_implementation": "    def test___neg__(self, operand, expected, expected_elements):\n        received = -operand\n\n        assert expected == received\n        assert received.elements == expected_elements"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand12-expected12-expected_elements12]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand12-expected12-expected_elements12]",
                "result": "passed",
                "test_implementation": "    def test___neg__(self, operand, expected, expected_elements):\n        received = -operand\n\n        assert expected == received\n        assert received.elements == expected_elements"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand14-expected14-expected_elements14]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand14-expected14-expected_elements14]",
                "result": "passed",
                "test_implementation": "    def test___neg__(self, operand, expected, expected_elements):\n        received = -operand\n\n        assert expected == received\n        assert received.elements == expected_elements"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements4-expected4]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements4-expected4]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned(self, elements, expected):\n            received = ContinuedFraction.from_elements(*elements)\n\n            assert received == expected\n            assert received.elements == expected.elements"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance3-new_elements3-expected_comparative_instance3]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance3-new_elements3-expected_comparative_instance3]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__extend__valid_elements__correctly_extended(self, instance, new_elements, expected_comparative_instance):\n        original_id = id(instance)\n        original_elements = instance.elements\n\n        instance.extend(*new_elements)\n\n        assert id(instance) == original_id\n        assert instance == expected_comparative_instance\n        assert hash(instance) == hash(expected_comparative_instance)\n        assert instance == ContinuedFraction.from_elements(*original_elements, *new_elements)\n        assert instance.order == expected_comparative_instance.order\n        assert instance.counter == expected_comparative_instance.counter\n        assert tuple(instance.convergents) == tuple(expected_comparative_instance.convergents)\n        assert tuple(instance.remainders) == tuple(expected_comparative_instance.remainders)\n        assert instance.khinchin_mean == expected_comparative_instance.khinchin_mean"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance7-new_elements7-expected_comparative_instance7]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance7-new_elements7-expected_comparative_instance7]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__extend__valid_elements__correctly_extended(self, instance, new_elements, expected_comparative_instance):\n        original_id = id(instance)\n        original_elements = instance.elements\n\n        instance.extend(*new_elements)\n\n        assert id(instance) == original_id\n        assert instance == expected_comparative_instance\n        assert hash(instance) == hash(expected_comparative_instance)\n        assert instance == ContinuedFraction.from_elements(*original_elements, *new_elements)\n        assert instance.order == expected_comparative_instance.order\n        assert instance.counter == expected_comparative_instance.counter\n        assert tuple(instance.convergents) == tuple(expected_comparative_instance.convergents)\n        assert tuple(instance.remainders) == tuple(expected_comparative_instance.remainders)\n        assert instance.khinchin_mean == expected_comparative_instance.khinchin_mean"
            },
            "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r10-elements10]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r10-elements10]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_rational__valid_integers__correct_elements_generated(self, r, elements):\n\t\t\n\t\texpected = elements\n\n\t\tassert tuple(continued_fraction_rational(r)) == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs17-expected_fraction_obj17-expected_elements17-1-expected_counter17-expected_khinchin_mean17-expected_convergents17-expected_ref_right_order2_mediant17-expected_ref_left_order2_mediant17-expected_ref_simple_mediant17-0.1-expected_decimal_value17]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs17-expected_fraction_obj17-expected_elements17-1-expected_counter17-expected_khinchin_mean17-expected_convergents17-expected_ref_right_order2_mediant17-expected_ref_left_order2_mediant17-expected_ref_simple_mediant17-0.1-expected_decimal_value17]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised(\n        self,\n        valid_inputs,\n        expected_fraction_obj,\n        expected_elements,\n        expected_order,\n        expected_counter,\n        expected_khinchin_mean,\n        expected_convergents,\n        expected_ref_right_order2_mediant,\n        expected_ref_left_order2_mediant,\n        expected_ref_simple_mediant,\n        expected_float_value,\n        expected_decimal_value\n    ):\n        expected = expected_fraction_obj\n\n        # The received ``ContinuedFraction`` object\n        received = ContinuedFraction(*valid_inputs)\n\n        # Compare the received and expected objects AS ``fractions.Fraction``\n        # objects\n        assert received == expected\n\n        # Compare the float values\n        assert received.as_float() == expected_float_value\n\n        # Compare the decimal values\n        try:\n            assert received.as_decimal() == expected_decimal_value\n        except decimal.Inexact:\n            pass\n\n        # Compare the element sequences\n        assert received.elements == expected_elements\n\n        # Compare the orders\n        assert received.order == expected_order\n\n        # Compare the element counters\n        assert received.counter == expected_counter\n\n        # Compare the Khinchin means\n        assert received.khinchin_mean == expected_khinchin_mean\n\n        # Compare the convergents using the ``.convergent`` method\n        assert not any(\n            received.convergent(k) != expected_convergents[k][1]\n            for k in range(received.order + 1)\n        )\n\n        # Compare the convergents using the ``.convergents`` property\n        assert tuple(received.convergents) == expected_convergents\n\n        # Compare the even-order convergents using the ``.even_order_convergents` property\n        assert tuple(received.even_convergents) == tuple((k, expected_convergents[k][1]) for k in range(0, received.order + 1, 2))\n\n        # Compare the order-order convergents using the ``.odd_order_convergents` property\n        assert tuple(received.odd_convergents) == tuple((k, expected_convergents[k][1]) for k in range(1, received.order + 1, 2))\n\n        # Compare the 2nd order right- and left-mediants, and also the simple\n        # mediant, using a reference continued fraction of ``1/1``\n        assert received.right_mediant(1, k=2) == expected_ref_right_order2_mediant\n        assert received.left_mediant(1, k=2) == expected_ref_left_order2_mediant\n        assert received.mediant(1) == expected_ref_simple_mediant\n\n        expected_remainders = tuple(\n            (k, ContinuedFraction.from_elements(*expected_elements[k:]))\n            for k in reversed(range(received.order + 1))\n        )\n        # Compare the remainders using the ``.remainder`` method\n        assert all(\n            received.remainder(k) == expected_remainders[::-1][k][1]\n            for k in reversed(range(received.order + 1))\n        )\n\n        # Compare the remainders using the ``.remainders`` property\n        assert tuple(received.remainders) == expected_remainders"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements5-expected5]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements5-expected5]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned(self, elements, expected):\n            received = ContinuedFraction.from_elements(*elements)\n\n            assert received == expected\n            assert received.elements == expected.elements"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements6-expected6]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements6-expected6]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned(self, elements, expected):\n            received = ContinuedFraction.from_elements(*elements)\n\n            assert received == expected\n            assert received.elements == expected.elements"
            },
            "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r11-elements11]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r11-elements11]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_rational__valid_integers__correct_elements_generated(self, r, elements):\n\t\t\n\t\texpected = elements\n\n\t\tassert tuple(continued_fraction_rational(r)) == expected"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[5000-expected0]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[5000-expected0]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[4-1-expected_semiconvergent6]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[4-1-expected_semiconvergent6]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned(self, k, m, expected_semiconvergent):\n        test_cf = ContinuedFraction(-415, 93)\n\n        assert test_cf.semiconvergent(k, m) == expected_semiconvergent\n        assert test_cf.semiconvergent(k, m) == test_cf.convergent(k - 1).right_mediant(test_cf.convergent(k), k=m)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[4-2-expected_semiconvergent7]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[4-2-expected_semiconvergent7]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned(self, k, m, expected_semiconvergent):\n        test_cf = ContinuedFraction(-415, 93)\n\n        assert test_cf.semiconvergent(k, m) == expected_semiconvergent\n        assert test_cf.semiconvergent(k, m) == test_cf.convergent(k - 1).right_mediant(test_cf.convergent(k), k=m)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[-1-1]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[-1-1]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__invalid_args(self, k, m):\n        test_cf = ContinuedFraction(-415, 93)\n\n        with pytest.raises(ValueError):\n            test_cf.semiconvergent(k, m)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[5-1]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[5-1]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__invalid_args(self, k, m):\n        test_cf = ContinuedFraction(-415, 93)\n\n        with pytest.raises(ValueError):\n            test_cf.semiconvergent(k, m)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs20-expected_fraction_obj20-expected_elements20-12-expected_counter20-expected_khinchin_mean20-expected_convergents20-expected_ref_right_order2_mediant20-expected_ref_left_order2_mediant20-expected_ref_simple_mediant20-0.7271927710843373-expected_decimal_value20]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs20-expected_fraction_obj20-expected_elements20-12-expected_counter20-expected_khinchin_mean20-expected_convergents20-expected_ref_right_order2_mediant20-expected_ref_left_order2_mediant20-expected_ref_simple_mediant20-0.7271927710843373-expected_decimal_value20]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised(\n        self,\n        valid_inputs,\n        expected_fraction_obj,\n        expected_elements,\n        expected_order,\n        expected_counter,\n        expected_khinchin_mean,\n        expected_convergents,\n        expected_ref_right_order2_mediant,\n        expected_ref_left_order2_mediant,\n        expected_ref_simple_mediant,\n        expected_float_value,\n        expected_decimal_value\n    ):\n        expected = expected_fraction_obj\n\n        # The received ``ContinuedFraction`` object\n        received = ContinuedFraction(*valid_inputs)\n\n        # Compare the received and expected objects AS ``fractions.Fraction``\n        # objects\n        assert received == expected\n\n        # Compare the float values\n        assert received.as_float() == expected_float_value\n\n        # Compare the decimal values\n        try:\n            assert received.as_decimal() == expected_decimal_value\n        except decimal.Inexact:\n            pass\n\n        # Compare the element sequences\n        assert received.elements == expected_elements\n\n        # Compare the orders\n        assert received.order == expected_order\n\n        # Compare the element counters\n        assert received.counter == expected_counter\n\n        # Compare the Khinchin means\n        assert received.khinchin_mean == expected_khinchin_mean\n\n        # Compare the convergents using the ``.convergent`` method\n        assert not any(\n            received.convergent(k) != expected_convergents[k][1]\n            for k in range(received.order + 1)\n        )\n\n        # Compare the convergents using the ``.convergents`` property\n        assert tuple(received.convergents) == expected_convergents\n\n        # Compare the even-order convergents using the ``.even_order_convergents` property\n        assert tuple(received.even_convergents) == tuple((k, expected_convergents[k][1]) for k in range(0, received.order + 1, 2))\n\n        # Compare the order-order convergents using the ``.odd_order_convergents` property\n        assert tuple(received.odd_convergents) == tuple((k, expected_convergents[k][1]) for k in range(1, received.order + 1, 2))\n\n        # Compare the 2nd order right- and left-mediants, and also the simple\n        # mediant, using a reference continued fraction of ``1/1``\n        assert received.right_mediant(1, k=2) == expected_ref_right_order2_mediant\n        assert received.left_mediant(1, k=2) == expected_ref_left_order2_mediant\n        assert received.mediant(1) == expected_ref_simple_mediant\n\n        expected_remainders = tuple(\n            (k, ContinuedFraction.from_elements(*expected_elements[k:]))\n            for k in reversed(range(received.order + 1))\n        )\n        # Compare the remainders using the ``.remainder`` method\n        assert all(\n            received.remainder(k) == expected_remainders[::-1][k][1]\n            for k in reversed(range(received.order + 1))\n        )\n\n        # Compare the remainders using the ``.remainders`` property\n        assert tuple(received.remainders) == expected_remainders"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs18-expected_fraction_obj18-expected_elements18-1-expected_counter18-expected_khinchin_mean18-expected_convergents18-expected_ref_right_order2_mediant18-expected_ref_left_order2_mediant18-expected_ref_simple_mediant18-0.05-expected_decimal_value18]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs18-expected_fraction_obj18-expected_elements18-1-expected_counter18-expected_khinchin_mean18-expected_convergents18-expected_ref_right_order2_mediant18-expected_ref_left_order2_mediant18-expected_ref_simple_mediant18-0.05-expected_decimal_value18]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised(\n        self,\n        valid_inputs,\n        expected_fraction_obj,\n        expected_elements,\n        expected_order,\n        expected_counter,\n        expected_khinchin_mean,\n        expected_convergents,\n        expected_ref_right_order2_mediant,\n        expected_ref_left_order2_mediant,\n        expected_ref_simple_mediant,\n        expected_float_value,\n        expected_decimal_value\n    ):\n        expected = expected_fraction_obj\n\n        # The received ``ContinuedFraction`` object\n        received = ContinuedFraction(*valid_inputs)\n\n        # Compare the received and expected objects AS ``fractions.Fraction``\n        # objects\n        assert received == expected\n\n        # Compare the float values\n        assert received.as_float() == expected_float_value\n\n        # Compare the decimal values\n        try:\n            assert received.as_decimal() == expected_decimal_value\n        except decimal.Inexact:\n            pass\n\n        # Compare the element sequences\n        assert received.elements == expected_elements\n\n        # Compare the orders\n        assert received.order == expected_order\n\n        # Compare the element counters\n        assert received.counter == expected_counter\n\n        # Compare the Khinchin means\n        assert received.khinchin_mean == expected_khinchin_mean\n\n        # Compare the convergents using the ``.convergent`` method\n        assert not any(\n            received.convergent(k) != expected_convergents[k][1]\n            for k in range(received.order + 1)\n        )\n\n        # Compare the convergents using the ``.convergents`` property\n        assert tuple(received.convergents) == expected_convergents\n\n        # Compare the even-order convergents using the ``.even_order_convergents` property\n        assert tuple(received.even_convergents) == tuple((k, expected_convergents[k][1]) for k in range(0, received.order + 1, 2))\n\n        # Compare the order-order convergents using the ``.odd_order_convergents` property\n        assert tuple(received.odd_convergents) == tuple((k, expected_convergents[k][1]) for k in range(1, received.order + 1, 2))\n\n        # Compare the 2nd order right- and left-mediants, and also the simple\n        # mediant, using a reference continued fraction of ``1/1``\n        assert received.right_mediant(1, k=2) == expected_ref_right_order2_mediant\n        assert received.left_mediant(1, k=2) == expected_ref_left_order2_mediant\n        assert received.mediant(1) == expected_ref_simple_mediant\n\n        expected_remainders = tuple(\n            (k, ContinuedFraction.from_elements(*expected_elements[k:]))\n            for k in reversed(range(received.order + 1))\n        )\n        # Compare the remainders using the ``.remainder`` method\n        assert all(\n            received.remainder(k) == expected_remainders[::-1][k][1]\n            for k in reversed(range(received.order + 1))\n        )\n\n        # Compare the remainders using the ``.remainders`` property\n        assert tuple(received.remainders) == expected_remainders"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__invalid_elements__value_error_raised[instance1-invalid_elements1]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__invalid_elements__value_error_raised[instance1-invalid_elements1]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__extend__invalid_elements__value_error_raised(self, instance, invalid_elements):\n        with pytest.raises(ValueError):\n            instance.extend(*invalid_elements)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs5-expected_fraction_obj5-expected_elements5-3-expected_counter5-expected_khinchin_mean5-expected_convergents5-expected_ref_right_order2_mediant5-expected_ref_left_order2_mediant5-expected_ref_simple_mediant5-3.245-expected_decimal_value5]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs5-expected_fraction_obj5-expected_elements5-3-expected_counter5-expected_khinchin_mean5-expected_convergents5-expected_ref_right_order2_mediant5-expected_ref_left_order2_mediant5-expected_ref_simple_mediant5-3.245-expected_decimal_value5]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised(\n        self,\n        valid_inputs,\n        expected_fraction_obj,\n        expected_elements,\n        expected_order,\n        expected_counter,\n        expected_khinchin_mean,\n        expected_convergents,\n        expected_ref_right_order2_mediant,\n        expected_ref_left_order2_mediant,\n        expected_ref_simple_mediant,\n        expected_float_value,\n        expected_decimal_value\n    ):\n        expected = expected_fraction_obj\n\n        # The received ``ContinuedFraction`` object\n        received = ContinuedFraction(*valid_inputs)\n\n        # Compare the received and expected objects AS ``fractions.Fraction``\n        # objects\n        assert received == expected\n\n        # Compare the float values\n        assert received.as_float() == expected_float_value\n\n        # Compare the decimal values\n        try:\n            assert received.as_decimal() == expected_decimal_value\n        except decimal.Inexact:\n            pass\n\n        # Compare the element sequences\n        assert received.elements == expected_elements\n\n        # Compare the orders\n        assert received.order == expected_order\n\n        # Compare the element counters\n        assert received.counter == expected_counter\n\n        # Compare the Khinchin means\n        assert received.khinchin_mean == expected_khinchin_mean\n\n        # Compare the convergents using the ``.convergent`` method\n        assert not any(\n            received.convergent(k) != expected_convergents[k][1]\n            for k in range(received.order + 1)\n        )\n\n        # Compare the convergents using the ``.convergents`` property\n        assert tuple(received.convergents) == expected_convergents\n\n        # Compare the even-order convergents using the ``.even_order_convergents` property\n        assert tuple(received.even_convergents) == tuple((k, expected_convergents[k][1]) for k in range(0, received.order + 1, 2))\n\n        # Compare the order-order convergents using the ``.odd_order_convergents` property\n        assert tuple(received.odd_convergents) == tuple((k, expected_convergents[k][1]) for k in range(1, received.order + 1, 2))\n\n        # Compare the 2nd order right- and left-mediants, and also the simple\n        # mediant, using a reference continued fraction of ``1/1``\n        assert received.right_mediant(1, k=2) == expected_ref_right_order2_mediant\n        assert received.left_mediant(1, k=2) == expected_ref_left_order2_mediant\n        assert received.mediant(1) == expected_ref_simple_mediant\n\n        expected_remainders = tuple(\n            (k, ContinuedFraction.from_elements(*expected_elements[k:]))\n            for k in reversed(range(received.order + 1))\n        )\n        # Compare the remainders using the ``.remainder`` method\n        assert all(\n            received.remainder(k) == expected_remainders[::-1][k][1]\n            for k in reversed(range(received.order + 1))\n        )\n\n        # Compare the remainders using the ``.remainders`` property\n        assert tuple(received.remainders) == expected_remainders"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[-1-not an int]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[-1-not an int]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__invalid_args(self, k, m):\n        test_cf = ContinuedFraction(-415, 93)\n\n        with pytest.raises(ValueError):\n            test_cf.semiconvergent(k, m)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[0-not an int]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[0-not an int]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__invalid_args(self, k, m):\n        test_cf = ContinuedFraction(-415, 93)\n\n        with pytest.raises(ValueError):\n            test_cf.semiconvergent(k, m)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[1-not an int]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[1-not an int]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__invalid_args(self, k, m):\n        test_cf = ContinuedFraction(-415, 93)\n\n        with pytest.raises(ValueError):\n            test_cf.semiconvergent(k, m)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf17-cf27-expected_simple_mediant7]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf17-cf27-expected_simple_mediant7]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, expected_simple_mediant):\n    \n        assert cf1.mediant(cf2) == expected_simple_mediant"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-0.3333-expected18]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-0.3333-expected18]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-0.3333-expected19]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-0.3333-expected19]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x20-expected20]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x20-expected20]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[0-1]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[0-1]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__invalid_args(self, k, m):\n        test_cf = ContinuedFraction(-415, 93)\n\n        with pytest.raises(ValueError):\n            test_cf.semiconvergent(k, m)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs8-expected_fraction_obj8-expected_elements8-2-expected_counter8-expected_khinchin_mean8-expected_convergents8-expected_ref_right_order2_mediant8-expected_ref_left_order2_mediant8-expected_ref_simple_mediant8--5.25-expected_decimal_value8]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs8-expected_fraction_obj8-expected_elements8-2-expected_counter8-expected_khinchin_mean8-expected_convergents8-expected_ref_right_order2_mediant8-expected_ref_left_order2_mediant8-expected_ref_simple_mediant8--5.25-expected_decimal_value8]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised(\n        self,\n        valid_inputs,\n        expected_fraction_obj,\n        expected_elements,\n        expected_order,\n        expected_counter,\n        expected_khinchin_mean,\n        expected_convergents,\n        expected_ref_right_order2_mediant,\n        expected_ref_left_order2_mediant,\n        expected_ref_simple_mediant,\n        expected_float_value,\n        expected_decimal_value\n    ):\n        expected = expected_fraction_obj\n\n        # The received ``ContinuedFraction`` object\n        received = ContinuedFraction(*valid_inputs)\n\n        # Compare the received and expected objects AS ``fractions.Fraction``\n        # objects\n        assert received == expected\n\n        # Compare the float values\n        assert received.as_float() == expected_float_value\n\n        # Compare the decimal values\n        try:\n            assert received.as_decimal() == expected_decimal_value\n        except decimal.Inexact:\n            pass\n\n        # Compare the element sequences\n        assert received.elements == expected_elements\n\n        # Compare the orders\n        assert received.order == expected_order\n\n        # Compare the element counters\n        assert received.counter == expected_counter\n\n        # Compare the Khinchin means\n        assert received.khinchin_mean == expected_khinchin_mean\n\n        # Compare the convergents using the ``.convergent`` method\n        assert not any(\n            received.convergent(k) != expected_convergents[k][1]\n            for k in range(received.order + 1)\n        )\n\n        # Compare the convergents using the ``.convergents`` property\n        assert tuple(received.convergents) == expected_convergents\n\n        # Compare the even-order convergents using the ``.even_order_convergents` property\n        assert tuple(received.even_convergents) == tuple((k, expected_convergents[k][1]) for k in range(0, received.order + 1, 2))\n\n        # Compare the order-order convergents using the ``.odd_order_convergents` property\n        assert tuple(received.odd_convergents) == tuple((k, expected_convergents[k][1]) for k in range(1, received.order + 1, 2))\n\n        # Compare the 2nd order right- and left-mediants, and also the simple\n        # mediant, using a reference continued fraction of ``1/1``\n        assert received.right_mediant(1, k=2) == expected_ref_right_order2_mediant\n        assert received.left_mediant(1, k=2) == expected_ref_left_order2_mediant\n        assert received.mediant(1) == expected_ref_simple_mediant\n\n        expected_remainders = tuple(\n            (k, ContinuedFraction.from_elements(*expected_elements[k:]))\n            for k in reversed(range(received.order + 1))\n        )\n        # Compare the remainders using the ``.remainder`` method\n        assert all(\n            received.remainder(k) == expected_remainders[::-1][k][1]\n            for k in reversed(range(received.order + 1))\n        )\n\n        # Compare the remainders using the ``.remainders`` property\n        assert tuple(received.remainders) == expected_remainders"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs9-expected_fraction_obj9-expected_elements9-0-expected_counter9-None-expected_convergents9-expected_ref_right_order2_mediant9-expected_ref_left_order2_mediant9-expected_ref_simple_mediant9-123456789.0-expected_decimal_value9]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs9-expected_fraction_obj9-expected_elements9-0-expected_counter9-None-expected_convergents9-expected_ref_right_order2_mediant9-expected_ref_left_order2_mediant9-expected_ref_simple_mediant9-123456789.0-expected_decimal_value9]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised(\n        self,\n        valid_inputs,\n        expected_fraction_obj,\n        expected_elements,\n        expected_order,\n        expected_counter,\n        expected_khinchin_mean,\n        expected_convergents,\n        expected_ref_right_order2_mediant,\n        expected_ref_left_order2_mediant,\n        expected_ref_simple_mediant,\n        expected_float_value,\n        expected_decimal_value\n    ):\n        expected = expected_fraction_obj\n\n        # The received ``ContinuedFraction`` object\n        received = ContinuedFraction(*valid_inputs)\n\n        # Compare the received and expected objects AS ``fractions.Fraction``\n        # objects\n        assert received == expected\n\n        # Compare the float values\n        assert received.as_float() == expected_float_value\n\n        # Compare the decimal values\n        try:\n            assert received.as_decimal() == expected_decimal_value\n        except decimal.Inexact:\n            pass\n\n        # Compare the element sequences\n        assert received.elements == expected_elements\n\n        # Compare the orders\n        assert received.order == expected_order\n\n        # Compare the element counters\n        assert received.counter == expected_counter\n\n        # Compare the Khinchin means\n        assert received.khinchin_mean == expected_khinchin_mean\n\n        # Compare the convergents using the ``.convergent`` method\n        assert not any(\n            received.convergent(k) != expected_convergents[k][1]\n            for k in range(received.order + 1)\n        )\n\n        # Compare the convergents using the ``.convergents`` property\n        assert tuple(received.convergents) == expected_convergents\n\n        # Compare the even-order convergents using the ``.even_order_convergents` property\n        assert tuple(received.even_convergents) == tuple((k, expected_convergents[k][1]) for k in range(0, received.order + 1, 2))\n\n        # Compare the order-order convergents using the ``.odd_order_convergents` property\n        assert tuple(received.odd_convergents) == tuple((k, expected_convergents[k][1]) for k in range(1, received.order + 1, 2))\n\n        # Compare the 2nd order right- and left-mediants, and also the simple\n        # mediant, using a reference continued fraction of ``1/1``\n        assert received.right_mediant(1, k=2) == expected_ref_right_order2_mediant\n        assert received.left_mediant(1, k=2) == expected_ref_left_order2_mediant\n        assert received.mediant(1) == expected_ref_simple_mediant\n\n        expected_remainders = tuple(\n            (k, ContinuedFraction.from_elements(*expected_elements[k:]))\n            for k in reversed(range(received.order + 1))\n        )\n        # Compare the remainders using the ``.remainder`` method\n        assert all(\n            received.remainder(k) == expected_remainders[::-1][k][1]\n            for k in reversed(range(received.order + 1))\n        )\n\n        # Compare the remainders using the ``.remainders`` property\n        assert tuple(received.remainders) == expected_remainders"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[not an int--1]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[not an int--1]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__invalid_args(self, k, m):\n        test_cf = ContinuedFraction(-415, 93)\n\n        with pytest.raises(ValueError):\n            test_cf.semiconvergent(k, m)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[not an int-0]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[not an int-0]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__invalid_args(self, k, m):\n        test_cf = ContinuedFraction(-415, 93)\n\n        with pytest.raises(ValueError):\n            test_cf.semiconvergent(k, m)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__invalid_elements__value_error_raised[instance3-invalid_elements3]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__invalid_elements__value_error_raised[instance3-invalid_elements3]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__truncate__invalid_elements__value_error_raised(self, instance, invalid_elements):\n        with pytest.raises(ValueError):\n            instance.truncate(*invalid_elements)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__invalid_elements__value_error_raised[instance4-invalid_elements4]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__invalid_elements__value_error_raised[instance4-invalid_elements4]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__truncate__invalid_elements__value_error_raised(self, instance, invalid_elements):\n        with pytest.raises(ValueError):\n            instance.truncate(*invalid_elements)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements0]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements0]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__invalid_elements__value_error_raised(self, invalid_elements):\n        with pytest.raises(ValueError):\n            ContinuedFraction.from_elements(*invalid_elements)"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x10-expected10]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x10-expected10]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-3.245-expected11]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-3.245-expected11]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-3.245-expected12]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-3.245-expected12]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements11]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements11]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__invalid_elements__value_error_raised(self, invalid_elements):\n        with pytest.raises(ValueError):\n            ContinuedFraction.from_elements(*invalid_elements)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements12]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements12]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__invalid_elements__value_error_raised(self, invalid_elements):\n        with pytest.raises(ValueError):\n            ContinuedFraction.from_elements(*invalid_elements)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__invalid_elements__value_error_raised[instance2-invalid_elements2]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__invalid_elements__value_error_raised[instance2-invalid_elements2]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__extend__invalid_elements__value_error_raised(self, instance, invalid_elements):\n        with pytest.raises(ValueError):\n            instance.extend(*invalid_elements)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__invalid_elements__value_error_raised[instance3-invalid_elements3]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__invalid_elements__value_error_raised[instance3-invalid_elements3]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__extend__invalid_elements__value_error_raised(self, instance, invalid_elements):\n        with pytest.raises(ValueError):\n            instance.extend(*invalid_elements)"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x7-expected7]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x7-expected7]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[3.245-expected8]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[3.245-expected8]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand2-expected2-expected_elements2]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand2-expected2-expected_elements2]",
                "result": "passed",
                "test_implementation": "    def test___neg__(self, operand, expected, expected_elements):\n        received = -operand\n\n        assert expected == received\n        assert received.elements == expected_elements"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance0-tail_elements0-expected_comparative_instance0]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance0-tail_elements0-expected_comparative_instance0]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__truncate__valid_elements__correctly_truncated(self, instance, tail_elements, expected_comparative_instance):\n        original_id = id(instance)\n        original_elements = instance.elements\n        order = instance.order\n        truncation_length = len(tail_elements)\n\n        instance.truncate(*tail_elements)\n\n        assert id(instance) == original_id\n        assert instance == expected_comparative_instance\n        assert hash(instance) == hash(expected_comparative_instance)\n        assert instance == ContinuedFraction.from_elements(*original_elements[:order + 1 - truncation_length])\n        assert instance.order == expected_comparative_instance.order\n        assert instance.counter == expected_comparative_instance.counter\n        assert tuple(instance.convergents) == tuple(expected_comparative_instance.convergents)\n        assert tuple(instance.remainders) == tuple(expected_comparative_instance.remainders)\n        assert instance.khinchin_mean == expected_comparative_instance.khinchin_mean"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance6-tail_elements6-expected_comparative_instance6]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance6-tail_elements6-expected_comparative_instance6]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__truncate__valid_elements__correctly_truncated(self, instance, tail_elements, expected_comparative_instance):\n        original_id = id(instance)\n        original_elements = instance.elements\n        order = instance.order\n        truncation_length = len(tail_elements)\n\n        instance.truncate(*tail_elements)\n\n        assert id(instance) == original_id\n        assert instance == expected_comparative_instance\n        assert hash(instance) == hash(expected_comparative_instance)\n        assert instance == ContinuedFraction.from_elements(*original_elements[:order + 1 - truncation_length])\n        assert instance.order == expected_comparative_instance.order\n        assert instance.counter == expected_comparative_instance.counter\n        assert tuple(instance.convergents) == tuple(expected_comparative_instance.convergents)\n        assert tuple(instance.remainders) == tuple(expected_comparative_instance.remainders)\n        assert instance.khinchin_mean == expected_comparative_instance.khinchin_mean"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance7-tail_elements7-expected_comparative_instance7]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance7-tail_elements7-expected_comparative_instance7]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__truncate__valid_elements__correctly_truncated(self, instance, tail_elements, expected_comparative_instance):\n        original_id = id(instance)\n        original_elements = instance.elements\n        order = instance.order\n        truncation_length = len(tail_elements)\n\n        instance.truncate(*tail_elements)\n\n        assert id(instance) == original_id\n        assert instance == expected_comparative_instance\n        assert hash(instance) == hash(expected_comparative_instance)\n        assert instance == ContinuedFraction.from_elements(*original_elements[:order + 1 - truncation_length])\n        assert instance.order == expected_comparative_instance.order\n        assert instance.counter == expected_comparative_instance.counter\n        assert tuple(instance.convergents) == tuple(expected_comparative_instance.convergents)\n        assert tuple(instance.remainders) == tuple(expected_comparative_instance.remainders)\n        assert instance.khinchin_mean == expected_comparative_instance.khinchin_mean"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance8-tail_elements8-expected_comparative_instance8]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance8-tail_elements8-expected_comparative_instance8]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__truncate__valid_elements__correctly_truncated(self, instance, tail_elements, expected_comparative_instance):\n        original_id = id(instance)\n        original_elements = instance.elements\n        order = instance.order\n        truncation_length = len(tail_elements)\n\n        instance.truncate(*tail_elements)\n\n        assert id(instance) == original_id\n        assert instance == expected_comparative_instance\n        assert hash(instance) == hash(expected_comparative_instance)\n        assert instance == ContinuedFraction.from_elements(*original_elements[:order + 1 - truncation_length])\n        assert instance.order == expected_comparative_instance.order\n        assert instance.counter == expected_comparative_instance.counter\n        assert tuple(instance.convergents) == tuple(expected_comparative_instance.convergents)\n        assert tuple(instance.remainders) == tuple(expected_comparative_instance.remainders)\n        assert instance.khinchin_mean == expected_comparative_instance.khinchin_mean"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs0-expected_fraction_obj0-expected_elements0-1-expected_counter0-expected_khinchin_mean0-expected_convergents0-expected_ref_right_order2_mediant0-expected_ref_left_order2_mediant0-expected_ref_simple_mediant0-1.5-expected_decimal_value0]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs0-expected_fraction_obj0-expected_elements0-1-expected_counter0-expected_khinchin_mean0-expected_convergents0-expected_ref_right_order2_mediant0-expected_ref_left_order2_mediant0-expected_ref_simple_mediant0-1.5-expected_decimal_value0]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised(\n        self,\n        valid_inputs,\n        expected_fraction_obj,\n        expected_elements,\n        expected_order,\n        expected_counter,\n        expected_khinchin_mean,\n        expected_convergents,\n        expected_ref_right_order2_mediant,\n        expected_ref_left_order2_mediant,\n        expected_ref_simple_mediant,\n        expected_float_value,\n        expected_decimal_value\n    ):\n        expected = expected_fraction_obj\n\n        # The received ``ContinuedFraction`` object\n        received = ContinuedFraction(*valid_inputs)\n\n        # Compare the received and expected objects AS ``fractions.Fraction``\n        # objects\n        assert received == expected\n\n        # Compare the float values\n        assert received.as_float() == expected_float_value\n\n        # Compare the decimal values\n        try:\n            assert received.as_decimal() == expected_decimal_value\n        except decimal.Inexact:\n            pass\n\n        # Compare the element sequences\n        assert received.elements == expected_elements\n\n        # Compare the orders\n        assert received.order == expected_order\n\n        # Compare the element counters\n        assert received.counter == expected_counter\n\n        # Compare the Khinchin means\n        assert received.khinchin_mean == expected_khinchin_mean\n\n        # Compare the convergents using the ``.convergent`` method\n        assert not any(\n            received.convergent(k) != expected_convergents[k][1]\n            for k in range(received.order + 1)\n        )\n\n        # Compare the convergents using the ``.convergents`` property\n        assert tuple(received.convergents) == expected_convergents\n\n        # Compare the even-order convergents using the ``.even_order_convergents` property\n        assert tuple(received.even_convergents) == tuple((k, expected_convergents[k][1]) for k in range(0, received.order + 1, 2))\n\n        # Compare the order-order convergents using the ``.odd_order_convergents` property\n        assert tuple(received.odd_convergents) == tuple((k, expected_convergents[k][1]) for k in range(1, received.order + 1, 2))\n\n        # Compare the 2nd order right- and left-mediants, and also the simple\n        # mediant, using a reference continued fraction of ``1/1``\n        assert received.right_mediant(1, k=2) == expected_ref_right_order2_mediant\n        assert received.left_mediant(1, k=2) == expected_ref_left_order2_mediant\n        assert received.mediant(1) == expected_ref_simple_mediant\n\n        expected_remainders = tuple(\n            (k, ContinuedFraction.from_elements(*expected_elements[k:]))\n            for k in reversed(range(received.order + 1))\n        )\n        # Compare the remainders using the ``.remainder`` method\n        assert all(\n            received.remainder(k) == expected_remainders[::-1][k][1]\n            for k in reversed(range(received.order + 1))\n        )\n\n        # Compare the remainders using the ``.remainders`` property\n        assert tuple(received.remainders) == expected_remainders"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf19-cf29-2-expected_left_mediant9]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf19-cf29-2-expected_left_mediant9]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_left_mediant):\n    \n        assert cf1.left_mediant(cf2, k=k) == expected_left_mediant"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand15-expected15-expected_elements15]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand15-expected15-expected_elements15]",
                "result": "passed",
                "test_implementation": "    def test___neg__(self, operand, expected, expected_elements):\n        received = -operand\n\n        assert expected == received\n        assert received.elements == expected_elements"
            },
            "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r0-elements0]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r0-elements0]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_rational__valid_integers__correct_elements_generated(self, r, elements):\n\t\t\n\t\texpected = elements\n\n\t\tassert tuple(continued_fraction_rational(r)) == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf14-cf24-expected_simple_mediant4]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf14-cf24-expected_simple_mediant4]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, expected_simple_mediant):\n    \n        assert cf1.mediant(cf2) == expected_simple_mediant"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf15-cf25-expected_simple_mediant5]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf15-cf25-expected_simple_mediant5]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, expected_simple_mediant):\n    \n        assert cf1.mediant(cf2) == expected_simple_mediant"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf15-cf25-1-expected_left_mediant5]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf15-cf25-1-expected_left_mediant5]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_left_mediant):\n    \n        assert cf1.left_mediant(cf2, k=k) == expected_left_mediant"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[5.25-expected22]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[5.25-expected22]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[5000.0-expected2]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[5000.0-expected2]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x3-expected3]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x3-expected3]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[1.5-expected4]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[1.5-expected4]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r2-elements2]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r2-elements2]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_rational__valid_integers__correct_elements_generated(self, r, elements):\n\t\t\n\t\texpected = elements\n\n\t\tassert tuple(continued_fraction_rational(r)) == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand3-expected3-expected_elements3]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand3-expected3-expected_elements3]",
                "result": "passed",
                "test_implementation": "    def test___neg__(self, operand, expected, expected_elements):\n        received = -operand\n\n        assert expected == received\n        assert received.elements == expected_elements"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements2-expected2]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements2-expected2]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned(self, elements, expected):\n            received = ContinuedFraction.from_elements(*elements)\n\n            assert received == expected\n            assert received.elements == expected.elements"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs10-expected_fraction_obj10-expected_elements10-2-expected_counter10-expected_khinchin_mean10-expected_convergents10-expected_ref_right_order2_mediant10-expected_ref_left_order2_mediant10-expected_ref_simple_mediant10-0.3-expected_decimal_value10]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs10-expected_fraction_obj10-expected_elements10-2-expected_counter10-expected_khinchin_mean10-expected_convergents10-expected_ref_right_order2_mediant10-expected_ref_left_order2_mediant10-expected_ref_simple_mediant10-0.3-expected_decimal_value10]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised(\n        self,\n        valid_inputs,\n        expected_fraction_obj,\n        expected_elements,\n        expected_order,\n        expected_counter,\n        expected_khinchin_mean,\n        expected_convergents,\n        expected_ref_right_order2_mediant,\n        expected_ref_left_order2_mediant,\n        expected_ref_simple_mediant,\n        expected_float_value,\n        expected_decimal_value\n    ):\n        expected = expected_fraction_obj\n\n        # The received ``ContinuedFraction`` object\n        received = ContinuedFraction(*valid_inputs)\n\n        # Compare the received and expected objects AS ``fractions.Fraction``\n        # objects\n        assert received == expected\n\n        # Compare the float values\n        assert received.as_float() == expected_float_value\n\n        # Compare the decimal values\n        try:\n            assert received.as_decimal() == expected_decimal_value\n        except decimal.Inexact:\n            pass\n\n        # Compare the element sequences\n        assert received.elements == expected_elements\n\n        # Compare the orders\n        assert received.order == expected_order\n\n        # Compare the element counters\n        assert received.counter == expected_counter\n\n        # Compare the Khinchin means\n        assert received.khinchin_mean == expected_khinchin_mean\n\n        # Compare the convergents using the ``.convergent`` method\n        assert not any(\n            received.convergent(k) != expected_convergents[k][1]\n            for k in range(received.order + 1)\n        )\n\n        # Compare the convergents using the ``.convergents`` property\n        assert tuple(received.convergents) == expected_convergents\n\n        # Compare the even-order convergents using the ``.even_order_convergents` property\n        assert tuple(received.even_convergents) == tuple((k, expected_convergents[k][1]) for k in range(0, received.order + 1, 2))\n\n        # Compare the order-order convergents using the ``.odd_order_convergents` property\n        assert tuple(received.odd_convergents) == tuple((k, expected_convergents[k][1]) for k in range(1, received.order + 1, 2))\n\n        # Compare the 2nd order right- and left-mediants, and also the simple\n        # mediant, using a reference continued fraction of ``1/1``\n        assert received.right_mediant(1, k=2) == expected_ref_right_order2_mediant\n        assert received.left_mediant(1, k=2) == expected_ref_left_order2_mediant\n        assert received.mediant(1) == expected_ref_simple_mediant\n\n        expected_remainders = tuple(\n            (k, ContinuedFraction.from_elements(*expected_elements[k:]))\n            for k in reversed(range(received.order + 1))\n        )\n        # Compare the remainders using the ``.remainder`` method\n        assert all(\n            received.remainder(k) == expected_remainders[::-1][k][1]\n            for k in reversed(range(received.order + 1))\n        )\n\n        # Compare the remainders using the ``.remainders`` property\n        assert tuple(received.remainders) == expected_remainders"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand4-expected4-expected_elements4]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand4-expected4-expected_elements4]",
                "result": "passed",
                "test_implementation": "    def test___neg__(self, operand, expected, expected_elements):\n        received = -operand\n\n        assert expected == received\n        assert received.elements == expected_elements"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf11-cf21-2-expected_right_mediant1]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf11-cf21-2-expected_right_mediant1]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_right_mediant):\n    \n        assert cf1.right_mediant(cf2, k=k) == expected_right_mediant"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[2-1-expected_semiconvergent1]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[2-1-expected_semiconvergent1]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned(self, k, m, expected_semiconvergent):\n        test_cf = ContinuedFraction(-415, 93)\n\n        assert test_cf.semiconvergent(k, m) == expected_semiconvergent\n        assert test_cf.semiconvergent(k, m) == test_cf.convergent(k - 1).right_mediant(test_cf.convergent(k), k=m)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf113-cf213-3-expected_left_mediant13]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf113-cf213-3-expected_left_mediant13]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_left_mediant):\n    \n        assert cf1.left_mediant(cf2, k=k) == expected_left_mediant"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements13]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements13]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__invalid_elements__value_error_raised(self, invalid_elements):\n        with pytest.raises(ValueError):\n            ContinuedFraction.from_elements(*invalid_elements)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf16-cf26-2-expected_left_mediant6]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf16-cf26-2-expected_left_mediant6]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_left_mediant):\n    \n        assert cf1.left_mediant(cf2, k=k) == expected_left_mediant"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf17-cf27-3-expected_left_mediant7]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf17-cf27-3-expected_left_mediant7]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_left_mediant):\n    \n        assert cf1.left_mediant(cf2, k=k) == expected_left_mediant"
            },
            "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements7-fraction7]": {
                "testid": "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements7-fraction7]",
                "result": "passed",
                "test_implementation": "\tdef test_fraction_from_elements__valid_elements__correct_fraction_returned(self, elements, fraction):\n\t\t\n\t\texpected = fraction\n\n\t\tassert fraction_from_elements(*elements) == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements1]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements1]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__invalid_elements__value_error_raised(self, invalid_elements):\n        with pytest.raises(ValueError):\n            ContinuedFraction.from_elements(*invalid_elements)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements7]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements7]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__invalid_elements__value_error_raised(self, invalid_elements):\n        with pytest.raises(ValueError):\n            ContinuedFraction.from_elements(*invalid_elements)"
            },
            "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r6-elements6]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r6-elements6]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_rational__valid_integers__correct_elements_generated(self, r, elements):\n\t\t\n\t\texpected = elements\n\n\t\tassert tuple(continued_fraction_rational(r)) == expected"
            },
            "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r7-elements7]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r7-elements7]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_rational__valid_integers__correct_elements_generated(self, r, elements):\n\t\t\n\t\texpected = elements\n\n\t\tassert tuple(continued_fraction_rational(r)) == expected"
            },
            "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r8-elements8]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r8-elements8]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_rational__valid_integers__correct_elements_generated(self, r, elements):\n\t\t\n\t\texpected = elements\n\n\t\tassert tuple(continued_fraction_rational(r)) == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements8]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements8]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__invalid_elements__value_error_raised(self, invalid_elements):\n        with pytest.raises(ValueError):\n            ContinuedFraction.from_elements(*invalid_elements)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements9]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements9]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__invalid_elements__value_error_raised(self, invalid_elements):\n        with pytest.raises(ValueError):\n            ContinuedFraction.from_elements(*invalid_elements)"
            },
            "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements8-fraction8]": {
                "testid": "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements8-fraction8]",
                "result": "passed",
                "test_implementation": "\tdef test_fraction_from_elements__valid_elements__correct_fraction_returned(self, elements, fraction):\n\t\t\n\t\texpected = fraction\n\n\t\tassert fraction_from_elements(*elements) == expected"
            },
            "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements9-fraction9]": {
                "testid": "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements9-fraction9]",
                "result": "passed",
                "test_implementation": "\tdef test_fraction_from_elements__valid_elements__correct_fraction_returned(self, elements, fraction):\n\t\t\n\t\texpected = fraction\n\n\t\tassert fraction_from_elements(*elements) == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[2-2-expected_semiconvergent2]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[2-2-expected_semiconvergent2]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned(self, k, m, expected_semiconvergent):\n        test_cf = ContinuedFraction(-415, 93)\n\n        assert test_cf.semiconvergent(k, m) == expected_semiconvergent\n        assert test_cf.semiconvergent(k, m) == test_cf.convergent(k - 1).right_mediant(test_cf.convergent(k), k=m)"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x23-expected23]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x23-expected23]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x24-expected24]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x24-expected24]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf11-cf21-2-expected_left_mediant1]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf11-cf21-2-expected_left_mediant1]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_left_mediant):\n    \n        assert cf1.left_mediant(cf2, k=k) == expected_left_mediant"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf12-cf22-3-expected_left_mediant2]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf12-cf22-3-expected_left_mediant2]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_left_mediant):\n    \n        assert cf1.left_mediant(cf2, k=k) == expected_left_mediant"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf13-cf23-1-expected_left_mediant3]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf13-cf23-1-expected_left_mediant3]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_left_mediant):\n    \n        assert cf1.left_mediant(cf2, k=k) == expected_left_mediant"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[3-1-expected_semiconvergent3]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[3-1-expected_semiconvergent3]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned(self, k, m, expected_semiconvergent):\n        test_cf = ContinuedFraction(-415, 93)\n\n        assert test_cf.semiconvergent(k, m) == expected_semiconvergent\n        assert test_cf.semiconvergent(k, m) == test_cf.convergent(k - 1).right_mediant(test_cf.convergent(k), k=m)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs1-expected_fraction_obj1-expected_elements1-1-expected_counter1-expected_khinchin_mean1-expected_convergents1-expected_ref_right_order2_mediant1-expected_ref_left_order2_mediant1-expected_ref_simple_mediant1-1.5-expected_decimal_value1]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs1-expected_fraction_obj1-expected_elements1-1-expected_counter1-expected_khinchin_mean1-expected_convergents1-expected_ref_right_order2_mediant1-expected_ref_left_order2_mediant1-expected_ref_simple_mediant1-1.5-expected_decimal_value1]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised(\n        self,\n        valid_inputs,\n        expected_fraction_obj,\n        expected_elements,\n        expected_order,\n        expected_counter,\n        expected_khinchin_mean,\n        expected_convergents,\n        expected_ref_right_order2_mediant,\n        expected_ref_left_order2_mediant,\n        expected_ref_simple_mediant,\n        expected_float_value,\n        expected_decimal_value\n    ):\n        expected = expected_fraction_obj\n\n        # The received ``ContinuedFraction`` object\n        received = ContinuedFraction(*valid_inputs)\n\n        # Compare the received and expected objects AS ``fractions.Fraction``\n        # objects\n        assert received == expected\n\n        # Compare the float values\n        assert received.as_float() == expected_float_value\n\n        # Compare the decimal values\n        try:\n            assert received.as_decimal() == expected_decimal_value\n        except decimal.Inexact:\n            pass\n\n        # Compare the element sequences\n        assert received.elements == expected_elements\n\n        # Compare the orders\n        assert received.order == expected_order\n\n        # Compare the element counters\n        assert received.counter == expected_counter\n\n        # Compare the Khinchin means\n        assert received.khinchin_mean == expected_khinchin_mean\n\n        # Compare the convergents using the ``.convergent`` method\n        assert not any(\n            received.convergent(k) != expected_convergents[k][1]\n            for k in range(received.order + 1)\n        )\n\n        # Compare the convergents using the ``.convergents`` property\n        assert tuple(received.convergents) == expected_convergents\n\n        # Compare the even-order convergents using the ``.even_order_convergents` property\n        assert tuple(received.even_convergents) == tuple((k, expected_convergents[k][1]) for k in range(0, received.order + 1, 2))\n\n        # Compare the order-order convergents using the ``.odd_order_convergents` property\n        assert tuple(received.odd_convergents) == tuple((k, expected_convergents[k][1]) for k in range(1, received.order + 1, 2))\n\n        # Compare the 2nd order right- and left-mediants, and also the simple\n        # mediant, using a reference continued fraction of ``1/1``\n        assert received.right_mediant(1, k=2) == expected_ref_right_order2_mediant\n        assert received.left_mediant(1, k=2) == expected_ref_left_order2_mediant\n        assert received.mediant(1) == expected_ref_simple_mediant\n\n        expected_remainders = tuple(\n            (k, ContinuedFraction.from_elements(*expected_elements[k:]))\n            for k in reversed(range(received.order + 1))\n        )\n        # Compare the remainders using the ``.remainder`` method\n        assert all(\n            received.remainder(k) == expected_remainders[::-1][k][1]\n            for k in reversed(range(received.order + 1))\n        )\n\n        # Compare the remainders using the ``.remainders`` property\n        assert tuple(received.remainders) == expected_remainders"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf16-cf26-1-expected_right_mediant6]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf16-cf26-1-expected_right_mediant6]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_right_mediant):\n    \n        assert cf1.right_mediant(cf2, k=k) == expected_right_mediant"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf17-cf27-1-expected_right_mediant7]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf17-cf27-1-expected_right_mediant7]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_right_mediant):\n    \n        assert cf1.right_mediant(cf2, k=k) == expected_right_mediant"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf12-cf22-3-expected_right_mediant2]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf12-cf22-3-expected_right_mediant2]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_right_mediant):\n    \n        assert cf1.right_mediant(cf2, k=k) == expected_right_mediant"
            },
            "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r3-elements3]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r3-elements3]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_rational__valid_integers__correct_elements_generated(self, r, elements):\n\t\t\n\t\texpected = elements\n\n\t\tassert tuple(continued_fraction_rational(r)) == expected"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements7]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements7]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tlist(convergents(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements8]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements8]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tlist(convergents(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements9]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements9]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tlist(convergents(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r4-elements4]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r4-elements4]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_rational__valid_integers__correct_elements_generated(self, r, elements):\n\t\t\n\t\texpected = elements\n\n\t\tassert tuple(continued_fraction_rational(r)) == expected"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements7]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements7]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\ttuple(remainders(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements8]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements8]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\ttuple(remainders(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements15]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements15]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\ttuple(remainders(*invalid_elements))"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs6-expected_fraction_obj6-expected_elements6-2-expected_counter6-expected_khinchin_mean6-expected_convergents6-expected_ref_right_order2_mediant6-expected_ref_left_order2_mediant6-expected_ref_simple_mediant6-0.3333-expected_decimal_value6]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs6-expected_fraction_obj6-expected_elements6-2-expected_counter6-expected_khinchin_mean6-expected_convergents6-expected_ref_right_order2_mediant6-expected_ref_left_order2_mediant6-expected_ref_simple_mediant6-0.3333-expected_decimal_value6]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised(\n        self,\n        valid_inputs,\n        expected_fraction_obj,\n        expected_elements,\n        expected_order,\n        expected_counter,\n        expected_khinchin_mean,\n        expected_convergents,\n        expected_ref_right_order2_mediant,\n        expected_ref_left_order2_mediant,\n        expected_ref_simple_mediant,\n        expected_float_value,\n        expected_decimal_value\n    ):\n        expected = expected_fraction_obj\n\n        # The received ``ContinuedFraction`` object\n        received = ContinuedFraction(*valid_inputs)\n\n        # Compare the received and expected objects AS ``fractions.Fraction``\n        # objects\n        assert received == expected\n\n        # Compare the float values\n        assert received.as_float() == expected_float_value\n\n        # Compare the decimal values\n        try:\n            assert received.as_decimal() == expected_decimal_value\n        except decimal.Inexact:\n            pass\n\n        # Compare the element sequences\n        assert received.elements == expected_elements\n\n        # Compare the orders\n        assert received.order == expected_order\n\n        # Compare the element counters\n        assert received.counter == expected_counter\n\n        # Compare the Khinchin means\n        assert received.khinchin_mean == expected_khinchin_mean\n\n        # Compare the convergents using the ``.convergent`` method\n        assert not any(\n            received.convergent(k) != expected_convergents[k][1]\n            for k in range(received.order + 1)\n        )\n\n        # Compare the convergents using the ``.convergents`` property\n        assert tuple(received.convergents) == expected_convergents\n\n        # Compare the even-order convergents using the ``.even_order_convergents` property\n        assert tuple(received.even_convergents) == tuple((k, expected_convergents[k][1]) for k in range(0, received.order + 1, 2))\n\n        # Compare the order-order convergents using the ``.odd_order_convergents` property\n        assert tuple(received.odd_convergents) == tuple((k, expected_convergents[k][1]) for k in range(1, received.order + 1, 2))\n\n        # Compare the 2nd order right- and left-mediants, and also the simple\n        # mediant, using a reference continued fraction of ``1/1``\n        assert received.right_mediant(1, k=2) == expected_ref_right_order2_mediant\n        assert received.left_mediant(1, k=2) == expected_ref_left_order2_mediant\n        assert received.mediant(1) == expected_ref_simple_mediant\n\n        expected_remainders = tuple(\n            (k, ContinuedFraction.from_elements(*expected_elements[k:]))\n            for k in reversed(range(received.order + 1))\n        )\n        # Compare the remainders using the ``.remainder`` method\n        assert all(\n            received.remainder(k) == expected_remainders[::-1][k][1]\n            for k in reversed(range(received.order + 1))\n        )\n\n        # Compare the remainders using the ``.remainders`` property\n        assert tuple(received.remainders) == expected_remainders"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements4-expected_convergents4]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements4-expected_convergents4]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__valid_elements__correct_convergents_generated(self, in_elements, expected_convergents):\n\t\tassert tuple(convergents(*in_elements)) == tuple(expected_convergents)"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements5-expected_convergents5]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements5-expected_convergents5]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__valid_elements__correct_convergents_generated(self, in_elements, expected_convergents):\n\t\tassert tuple(convergents(*in_elements)) == tuple(expected_convergents)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf114-cf214-1-expected_left_mediant14]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf114-cf214-1-expected_left_mediant14]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_left_mediant):\n    \n        assert cf1.left_mediant(cf2, k=k) == expected_left_mediant"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements11]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements11]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tlist(convergents(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational115-rational215-1-expected_mediant15]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational115-rational215-1-expected_mediant15]",
                "result": "passed",
                "test_implementation": "\tdef test_left_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir='left', k=k) == expected_mediant"
            },
            "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational116-rational216-2-expected_mediant16]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational116-rational216-2-expected_mediant16]",
                "result": "passed",
                "test_implementation": "\tdef test_left_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir='left', k=k) == expected_mediant"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs2-expected_fraction_obj2-expected_elements2-0-expected_counter2-None-expected_convergents2-expected_ref_right_order2_mediant2-expected_ref_left_order2_mediant2-expected_ref_simple_mediant2--5000.0-expected_decimal_value2]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs2-expected_fraction_obj2-expected_elements2-0-expected_counter2-None-expected_convergents2-expected_ref_right_order2_mediant2-expected_ref_left_order2_mediant2-expected_ref_simple_mediant2--5000.0-expected_decimal_value2]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised(\n        self,\n        valid_inputs,\n        expected_fraction_obj,\n        expected_elements,\n        expected_order,\n        expected_counter,\n        expected_khinchin_mean,\n        expected_convergents,\n        expected_ref_right_order2_mediant,\n        expected_ref_left_order2_mediant,\n        expected_ref_simple_mediant,\n        expected_float_value,\n        expected_decimal_value\n    ):\n        expected = expected_fraction_obj\n\n        # The received ``ContinuedFraction`` object\n        received = ContinuedFraction(*valid_inputs)\n\n        # Compare the received and expected objects AS ``fractions.Fraction``\n        # objects\n        assert received == expected\n\n        # Compare the float values\n        assert received.as_float() == expected_float_value\n\n        # Compare the decimal values\n        try:\n            assert received.as_decimal() == expected_decimal_value\n        except decimal.Inexact:\n            pass\n\n        # Compare the element sequences\n        assert received.elements == expected_elements\n\n        # Compare the orders\n        assert received.order == expected_order\n\n        # Compare the element counters\n        assert received.counter == expected_counter\n\n        # Compare the Khinchin means\n        assert received.khinchin_mean == expected_khinchin_mean\n\n        # Compare the convergents using the ``.convergent`` method\n        assert not any(\n            received.convergent(k) != expected_convergents[k][1]\n            for k in range(received.order + 1)\n        )\n\n        # Compare the convergents using the ``.convergents`` property\n        assert tuple(received.convergents) == expected_convergents\n\n        # Compare the even-order convergents using the ``.even_order_convergents` property\n        assert tuple(received.even_convergents) == tuple((k, expected_convergents[k][1]) for k in range(0, received.order + 1, 2))\n\n        # Compare the order-order convergents using the ``.odd_order_convergents` property\n        assert tuple(received.odd_convergents) == tuple((k, expected_convergents[k][1]) for k in range(1, received.order + 1, 2))\n\n        # Compare the 2nd order right- and left-mediants, and also the simple\n        # mediant, using a reference continued fraction of ``1/1``\n        assert received.right_mediant(1, k=2) == expected_ref_right_order2_mediant\n        assert received.left_mediant(1, k=2) == expected_ref_left_order2_mediant\n        assert received.mediant(1) == expected_ref_simple_mediant\n\n        expected_remainders = tuple(\n            (k, ContinuedFraction.from_elements(*expected_elements[k:]))\n            for k in reversed(range(received.order + 1))\n        )\n        # Compare the remainders using the ``.remainder`` method\n        assert all(\n            received.remainder(k) == expected_remainders[::-1][k][1]\n            for k in reversed(range(received.order + 1))\n        )\n\n        # Compare the remainders using the ``.remainders`` property\n        assert tuple(received.remainders) == expected_remainders"
            },
            "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational15-rational25-right-1-expected_mediant5]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational15-rational25-right-1-expected_mediant5]",
                "result": "passed",
                "test_implementation": "\tdef test_right_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, dir_, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir=dir_, k=k) == expected_mediant"
            },
            "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational16-rational26-right-1-expected_mediant6]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational16-rational26-right-1-expected_mediant6]",
                "result": "passed",
                "test_implementation": "\tdef test_right_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, dir_, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir=dir_, k=k) == expected_mediant"
            },
            "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements3-fraction3]": {
                "testid": "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements3-fraction3]",
                "result": "passed",
                "test_implementation": "\tdef test_fraction_from_elements__valid_elements__correct_fraction_returned(self, elements, fraction):\n\t\t\n\t\texpected = fraction\n\n\t\tassert fraction_from_elements(*elements) == expected"
            },
            "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements4-fraction4]": {
                "testid": "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements4-fraction4]",
                "result": "passed",
                "test_implementation": "\tdef test_fraction_from_elements__valid_elements__correct_fraction_returned(self, elements, fraction):\n\t\t\n\t\texpected = fraction\n\n\t\tassert fraction_from_elements(*elements) == expected"
            },
            "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements5-fraction5]": {
                "testid": "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements5-fraction5]",
                "result": "passed",
                "test_implementation": "\tdef test_fraction_from_elements__valid_elements__correct_fraction_returned(self, elements, fraction):\n\t\t\n\t\texpected = fraction\n\n\t\tassert fraction_from_elements(*elements) == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs12-expected_fraction_obj12-expected_elements12-4-expected_counter12-expected_khinchin_mean12-expected_convergents12-expected_ref_right_order2_mediant12-expected_ref_left_order2_mediant12-expected_ref_simple_mediant12--3.245-expected_decimal_value12]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs12-expected_fraction_obj12-expected_elements12-4-expected_counter12-expected_khinchin_mean12-expected_convergents12-expected_ref_right_order2_mediant12-expected_ref_left_order2_mediant12-expected_ref_simple_mediant12--3.245-expected_decimal_value12]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised(\n        self,\n        valid_inputs,\n        expected_fraction_obj,\n        expected_elements,\n        expected_order,\n        expected_counter,\n        expected_khinchin_mean,\n        expected_convergents,\n        expected_ref_right_order2_mediant,\n        expected_ref_left_order2_mediant,\n        expected_ref_simple_mediant,\n        expected_float_value,\n        expected_decimal_value\n    ):\n        expected = expected_fraction_obj\n\n        # The received ``ContinuedFraction`` object\n        received = ContinuedFraction(*valid_inputs)\n\n        # Compare the received and expected objects AS ``fractions.Fraction``\n        # objects\n        assert received == expected\n\n        # Compare the float values\n        assert received.as_float() == expected_float_value\n\n        # Compare the decimal values\n        try:\n            assert received.as_decimal() == expected_decimal_value\n        except decimal.Inexact:\n            pass\n\n        # Compare the element sequences\n        assert received.elements == expected_elements\n\n        # Compare the orders\n        assert received.order == expected_order\n\n        # Compare the element counters\n        assert received.counter == expected_counter\n\n        # Compare the Khinchin means\n        assert received.khinchin_mean == expected_khinchin_mean\n\n        # Compare the convergents using the ``.convergent`` method\n        assert not any(\n            received.convergent(k) != expected_convergents[k][1]\n            for k in range(received.order + 1)\n        )\n\n        # Compare the convergents using the ``.convergents`` property\n        assert tuple(received.convergents) == expected_convergents\n\n        # Compare the even-order convergents using the ``.even_order_convergents` property\n        assert tuple(received.even_convergents) == tuple((k, expected_convergents[k][1]) for k in range(0, received.order + 1, 2))\n\n        # Compare the order-order convergents using the ``.odd_order_convergents` property\n        assert tuple(received.odd_convergents) == tuple((k, expected_convergents[k][1]) for k in range(1, received.order + 1, 2))\n\n        # Compare the 2nd order right- and left-mediants, and also the simple\n        # mediant, using a reference continued fraction of ``1/1``\n        assert received.right_mediant(1, k=2) == expected_ref_right_order2_mediant\n        assert received.left_mediant(1, k=2) == expected_ref_left_order2_mediant\n        assert received.mediant(1) == expected_ref_simple_mediant\n\n        expected_remainders = tuple(\n            (k, ContinuedFraction.from_elements(*expected_elements[k:]))\n            for k in reversed(range(received.order + 1))\n        )\n        # Compare the remainders using the ``.remainder`` method\n        assert all(\n            received.remainder(k) == expected_remainders[::-1][k][1]\n            for k in reversed(range(received.order + 1))\n        )\n\n        # Compare the remainders using the ``.remainders`` property\n        assert tuple(received.remainders) == expected_remainders"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[1-elements3]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[1-elements3]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__invalid_elements__value_error_raised(self, k, elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tremainder(k, *elements)"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[-1-elements4]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[-1-elements4]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__invalid_elements__value_error_raised(self, k, elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tremainder(k, *elements)"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[3-elements5]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[3-elements5]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__invalid_elements__value_error_raised(self, k, elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tremainder(k, *elements)"
            },
            "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[1-elements0]": {
                "testid": "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[1-elements0]",
                "result": "passed",
                "test_implementation": "\tdef test_convergent__invalid_elements__value_error_raised(self, k, elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tconvergent(k, *elements)"
            },
            "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[1-elements1]": {
                "testid": "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[1-elements1]",
                "result": "passed",
                "test_implementation": "\tdef test_convergent__invalid_elements__value_error_raised(self, k, elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tconvergent(k, *elements)"
            },
            "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[1-elements2]": {
                "testid": "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[1-elements2]",
                "result": "passed",
                "test_implementation": "\tdef test_convergent__invalid_elements__value_error_raised(self, k, elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tconvergent(k, *elements)"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[1-elements7]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[1-elements7]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__invalid_elements__value_error_raised(self, k, elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tremainder(k, *elements)"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[1-elements8]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[1-elements8]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__invalid_elements__value_error_raised(self, k, elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tremainder(k, *elements)"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[2-elements9]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[2-elements9]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__invalid_elements__value_error_raised(self, k, elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tremainder(k, *elements)"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements3]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements3]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\ttuple(remainders(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements4]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements4]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\ttuple(remainders(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements5]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements5]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\ttuple(remainders(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements6-expected_convergents6]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements6-expected_convergents6]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__valid_elements__correct_convergents_generated(self, in_elements, expected_convergents):\n\t\tassert tuple(convergents(*in_elements)) == tuple(expected_convergents)"
            },
            "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational17-rational27-2-expected_mediant7]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational17-rational27-2-expected_mediant7]",
                "result": "passed",
                "test_implementation": "\tdef test_left_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir='left', k=k) == expected_mediant"
            },
            "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational18-rational28-3-expected_mediant8]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational18-rational28-3-expected_mediant8]",
                "result": "passed",
                "test_implementation": "\tdef test_left_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir='left', k=k) == expected_mediant"
            },
            "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational19-rational29-10-expected_mediant9]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational19-rational29-10-expected_mediant9]",
                "result": "passed",
                "test_implementation": "\tdef test_left_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir='left', k=k) == expected_mediant"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements3]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements3]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tlist(convergents(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[1-elements8]": {
                "testid": "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[1-elements8]",
                "result": "passed",
                "test_implementation": "\tdef test_convergent__invalid_elements__value_error_raised(self, k, elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tconvergent(k, *elements)"
            },
            "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[2-elements9]": {
                "testid": "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[2-elements9]",
                "result": "passed",
                "test_implementation": "\tdef test_convergent__invalid_elements__value_error_raised(self, k, elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tconvergent(k, *elements)"
            },
            "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[1-elements0-expected_convergent0]": {
                "testid": "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[1-elements0-expected_convergent0]",
                "result": "passed",
                "test_implementation": "\tdef test_convergent__valid_elements__correct_convergent_returned(self, k, elements, expected_convergent):\n\t\n\t\tassert convergent(k, *elements) == expected_convergent"
            },
            "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational17-rational27-right-1-expected_mediant7]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational17-rational27-right-1-expected_mediant7]",
                "result": "passed",
                "test_implementation": "\tdef test_right_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, dir_, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir=dir_, k=k) == expected_mediant"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements11]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements11]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\ttuple(remainders(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational111-rational211-2-expected_mediant11]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational111-rational211-2-expected_mediant11]",
                "result": "passed",
                "test_implementation": "\tdef test_left_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir='left', k=k) == expected_mediant"
            },
            "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational112-rational212-2-expected_mediant12]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational112-rational212-2-expected_mediant12]",
                "result": "passed",
                "test_implementation": "\tdef test_left_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir='left', k=k) == expected_mediant"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[2-expected_coprime_integers1]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[2-expected_coprime_integers1]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__default_start_and_stop_values(self, n, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[3-expected_coprime_integers2]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[3-expected_coprime_integers2]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__default_start_and_stop_values(self, n, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[4-expected_coprime_integers3]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[4-expected_coprime_integers3]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__default_start_and_stop_values(self, n, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n)\n\n        assert received == expected"
            },
            "tests/units/test_lib.py::TestMediant::test_mediant__invalid_dir_or_order__value_error_raised[rational15-rational25-not right-0]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_mediant__invalid_dir_or_order__value_error_raised[rational15-rational25-not right-0]",
                "result": "passed",
                "test_implementation": "\tdef test_mediant__invalid_dir_or_order__value_error_raised(self, rational1, rational2, dir, k):\n\t\twith pytest.raises(ValueError):\n\t\t\tmediant(rational1, rational2, dir=dir, k=k)"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[3-1-None-expected_coprime_integers3]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[3-1-None-expected_coprime_integers3]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[3-2-None-expected_coprime_integers4]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[3-2-None-expected_coprime_integers4]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[3-1-3-expected_coprime_integers5]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[3-1-3-expected_coprime_integers5]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements4]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements4]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tlist(convergents(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements5]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements5]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tlist(convergents(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational19-rational29-right-1000000-expected_mediant9]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational19-rational29-right-1000000-expected_mediant9]",
                "result": "passed",
                "test_implementation": "\tdef test_right_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, dir_, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir=dir_, k=k) == expected_mediant"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__invalid_args__raises_value_error[not an integer-1-None]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__invalid_args__raises_value_error[not an integer-1-None]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__invalid_args__raises_value_error(self, n, start, stop):\n        with pytest.raises(ValueError):\n            coprime_integers(n, start=start, stop=stop)"
            },
            "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational11-rational21-right-2-expected_mediant1]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational11-rational21-right-2-expected_mediant1]",
                "result": "passed",
                "test_implementation": "\tdef test_right_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, dir_, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir=dir_, k=k) == expected_mediant"
            },
            "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational10-rational20-1-expected_mediant0]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational10-rational20-1-expected_mediant0]",
                "result": "passed",
                "test_implementation": "\tdef test_left_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir='left', k=k) == expected_mediant"
            },
            "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational11-rational21-2-expected_mediant1]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational11-rational21-2-expected_mediant1]",
                "result": "passed",
                "test_implementation": "\tdef test_left_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir='left', k=k) == expected_mediant"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements8-expected8]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements8-expected8]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned(self, elements, expected):\n            received = ContinuedFraction.from_elements(*elements)\n\n            assert received == expected\n            assert received.elements == expected.elements"
            },
            "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational113-rational213-1-expected_mediant13]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational113-rational213-1-expected_mediant13]",
                "result": "passed",
                "test_implementation": "\tdef test_left_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir='left', k=k) == expected_mediant"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements0-expected_convergents0]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements0-expected_convergents0]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__valid_elements__correct_convergents_generated(self, in_elements, expected_convergents):\n\t\tassert tuple(convergents(*in_elements)) == tuple(expected_convergents)"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements1-expected_convergents1]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements1-expected_convergents1]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__valid_elements__correct_convergents_generated(self, in_elements, expected_convergents):\n\t\tassert tuple(convergents(*in_elements)) == tuple(expected_convergents)"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements2-expected_convergents2]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements2-expected_convergents2]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__valid_elements__correct_convergents_generated(self, in_elements, expected_convergents):\n\t\tassert tuple(convergents(*in_elements)) == tuple(expected_convergents)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements9-expected9]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements9-expected9]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned(self, elements, expected):\n            received = ContinuedFraction.from_elements(*elements)\n\n            assert received == expected\n            assert received.elements == expected.elements"
            },
            "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational13-rational23-1-expected_mediant3]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational13-rational23-1-expected_mediant3]",
                "result": "passed",
                "test_implementation": "\tdef test_left_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir='left', k=k) == expected_mediant"
            },
            "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational14-rational24-1-expected_mediant4]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational14-rational24-1-expected_mediant4]",
                "result": "passed",
                "test_implementation": "\tdef test_left_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir='left', k=k) == expected_mediant"
            },
            "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational15-rational25-2-expected_mediant5]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational15-rational25-2-expected_mediant5]",
                "result": "passed",
                "test_implementation": "\tdef test_left_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir='left', k=k) == expected_mediant"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[0-elements1-expected_remainder1]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[0-elements1-expected_remainder1]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__valid_elements__correct_remainder_returned(self, k, elements, expected_remainder):\n\t\n\t\tassert remainder(k, *elements) == expected_remainder"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[0-elements2-expected_remainder2]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[0-elements2-expected_remainder2]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__valid_elements__correct_remainder_returned(self, k, elements, expected_remainder):\n\t\n\t\tassert remainder(k, *elements) == expected_remainder"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[1-elements3-expected_remainder3]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[1-elements3-expected_remainder3]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__valid_elements__correct_remainder_returned(self, k, elements, expected_remainder):\n\t\n\t\tassert remainder(k, *elements) == expected_remainder"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements8-expected_convergents8]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements8-expected_convergents8]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__valid_elements__correct_convergents_generated(self, in_elements, expected_convergents):\n\t\tassert tuple(convergents(*in_elements)) == tuple(expected_convergents)"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[1-elements0]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[1-elements0]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__invalid_elements__value_error_raised(self, k, elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tremainder(k, *elements)"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[1-elements1]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[1-elements1]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__invalid_elements__value_error_raised(self, k, elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tremainder(k, *elements)"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__invalid_args__raises_value_error[0.1-1-2]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__invalid_args__raises_value_error[0.1-1-2]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__invalid_args__raises_value_error(self, n, start, stop):\n        with pytest.raises(ValueError):\n            coprime_integers(n, start=start, stop=stop)"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__invalid_args__raises_value_error[3-0-2]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__invalid_args__raises_value_error[3-0-2]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__invalid_args__raises_value_error(self, n, start, stop):\n        with pytest.raises(ValueError):\n            coprime_integers(n, start=start, stop=stop)"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__invalid_args__raises_value_error[3-3-2]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__invalid_args__raises_value_error[3-3-2]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__invalid_args__raises_value_error(self, n, start, stop):\n        with pytest.raises(ValueError):\n            coprime_integers(n, start=start, stop=stop)"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[4-1-None-expected_coprime_integers7]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[4-1-None-expected_coprime_integers7]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[4-2-None-expected_coprime_integers8]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[4-2-None-expected_coprime_integers8]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[4-3-None-expected_coprime_integers9]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[4-3-None-expected_coprime_integers9]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf110-cf210-3-expected_left_mediant10]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf110-cf210-3-expected_left_mediant10]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_left_mediant):\n    \n        assert cf1.left_mediant(cf2, k=k) == expected_left_mediant"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements10-expected10]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements10-expected10]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned(self, elements, expected):\n            received = ContinuedFraction.from_elements(*elements)\n\n            assert received == expected\n            assert received.elements == expected.elements"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf115-cf215-1000000-expected_left_mediant15]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf115-cf215-1000000-expected_left_mediant15]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_left_mediant):\n    \n        assert cf1.left_mediant(cf2, k=k) == expected_left_mediant"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-649/200-expected14]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-649/200-expected14]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[3.245-expected15]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[3.245-expected15]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf111-cf211-1-expected_left_mediant11]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf111-cf211-1-expected_left_mediant11]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_left_mediant):\n    \n        assert cf1.left_mediant(cf2, k=k) == expected_left_mediant"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[10-expected_coprime_integers9]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[10-expected_coprime_integers9]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__default_start_and_stop_values(self, n, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[1-1-None-expected_coprime_integers0]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[1-1-None-expected_coprime_integers0]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[2-1-None-expected_coprime_integers1]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[2-1-None-expected_coprime_integers1]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[0.3333-expected16]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[0.3333-expected16]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[4-2-4-expected_coprime_integers11]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[4-2-4-expected_coprime_integers11]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational12-rational22-right-3-expected_mediant2]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational12-rational22-right-3-expected_mediant2]",
                "result": "passed",
                "test_implementation": "\tdef test_right_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, dir_, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir=dir_, k=k) == expected_mediant"
            },
            "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational13-rational23-right-1-expected_mediant3]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational13-rational23-right-1-expected_mediant3]",
                "result": "passed",
                "test_implementation": "\tdef test_right_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, dir_, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir=dir_, k=k) == expected_mediant"
            },
            "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[3-elements10-expected_convergent10]": {
                "testid": "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[3-elements10-expected_convergent10]",
                "result": "passed",
                "test_implementation": "\tdef test_convergent__valid_elements__correct_convergent_returned(self, k, elements, expected_convergent):\n\t\n\t\tassert convergent(k, *elements) == expected_convergent"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__invalid_args__raises_value_error[0-1-2]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__invalid_args__raises_value_error[0-1-2]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__invalid_args__raises_value_error(self, n, start, stop):\n        with pytest.raises(ValueError):\n            coprime_integers(n, start=start, stop=stop)"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements9]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements9]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\ttuple(remainders(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements0-fraction0]": {
                "testid": "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements0-fraction0]",
                "result": "passed",
                "test_implementation": "\tdef test_fraction_from_elements__valid_elements__correct_fraction_returned(self, elements, fraction):\n\t\t\n\t\texpected = fraction\n\n\t\tassert fraction_from_elements(*elements) == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[4-2-3-expected_coprime_integers12]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[4-2-3-expected_coprime_integers12]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-1-None-expected_coprime_integers13]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-1-None-expected_coprime_integers13]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements0]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements0]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tlist(convergents(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements1]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements1]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tlist(convergents(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements12]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements12]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tlist(convergents(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements13]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements13]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tlist(convergents(*invalid_elements))"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[6-expected_coprime_integers5]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[6-expected_coprime_integers5]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__default_start_and_stop_values(self, n, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[7-expected_coprime_integers6]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[7-expected_coprime_integers6]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__default_start_and_stop_values(self, n, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[8-expected_coprime_integers7]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[8-expected_coprime_integers7]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__default_start_and_stop_values(self, n, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n)\n\n        assert received == expected"
            },
            "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements1-fraction1]": {
                "testid": "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements1-fraction1]",
                "result": "passed",
                "test_implementation": "\tdef test_fraction_from_elements__valid_elements__correct_fraction_returned(self, elements, fraction):\n\t\t\n\t\texpected = fraction\n\n\t\tassert fraction_from_elements(*elements) == expected"
            },
            "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[2-elements6-expected_convergent6]": {
                "testid": "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[2-elements6-expected_convergent6]",
                "result": "passed",
                "test_implementation": "\tdef test_convergent__valid_elements__correct_convergent_returned(self, k, elements, expected_convergent):\n\t\n\t\tassert convergent(k, *elements) == expected_convergent"
            },
            "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[3-elements7-expected_convergent7]": {
                "testid": "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[3-elements7-expected_convergent7]",
                "result": "passed",
                "test_implementation": "\tdef test_convergent__valid_elements__correct_convergent_returned(self, k, elements, expected_convergent):\n\t\n\t\tassert convergent(k, *elements) == expected_convergent"
            },
            "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[0-elements8-expected_convergent8]": {
                "testid": "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[0-elements8-expected_convergent8]",
                "result": "passed",
                "test_implementation": "\tdef test_convergent__valid_elements__correct_convergent_returned(self, k, elements, expected_convergent):\n\t\n\t\tassert convergent(k, *elements) == expected_convergent"
            },
            "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational117-rational217-1000000-expected_mediant17]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational117-rational217-1000000-expected_mediant17]",
                "result": "passed",
                "test_implementation": "\tdef test_left_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir='left', k=k) == expected_mediant"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[4-elements13-expected_remainder13]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[4-elements13-expected_remainder13]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__valid_elements__correct_remainder_returned(self, k, elements, expected_remainder):\n\t\n\t\tassert remainder(k, *elements) == expected_remainder"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[0-elements5-expected_remainder5]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[0-elements5-expected_remainder5]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__valid_elements__correct_remainder_returned(self, k, elements, expected_remainder):\n\t\n\t\tassert remainder(k, *elements) == expected_remainder"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[0-elements9-expected_remainder9]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[0-elements9-expected_remainder9]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__valid_elements__correct_remainder_returned(self, k, elements, expected_remainder):\n\t\n\t\tassert remainder(k, *elements) == expected_remainder"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[1-elements10-expected_remainder10]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[1-elements10-expected_remainder10]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__valid_elements__correct_remainder_returned(self, k, elements, expected_remainder):\n\t\n\t\tassert remainder(k, *elements) == expected_remainder"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[2-elements11-expected_remainder11]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[2-elements11-expected_remainder11]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__valid_elements__correct_remainder_returned(self, k, elements, expected_remainder):\n\t\n\t\tassert remainder(k, *elements) == expected_remainder"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements7-expected_remainders7]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements7-expected_remainders7]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__valid_elements__correct_remainders_generated(self, in_elements, expected_remainders):\n\t\tassert tuple(remainders(*in_elements)) == tuple(expected_remainders)"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements8-expected_remainders8]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements8-expected_remainders8]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__valid_elements__correct_remainders_generated(self, in_elements, expected_remainders):\n\t\tassert tuple(remainders(*in_elements)) == tuple(expected_remainders)"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements9-expected_remainders9]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements9-expected_remainders9]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__valid_elements__correct_remainders_generated(self, in_elements, expected_remainders):\n\t\tassert tuple(remainders(*in_elements)) == tuple(expected_remainders)"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements0-expected_remainders0]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements0-expected_remainders0]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__valid_elements__correct_remainders_generated(self, in_elements, expected_remainders):\n\t\tassert tuple(remainders(*in_elements)) == tuple(expected_remainders)"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements0]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements0]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\ttuple(remainders(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements1]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements1]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\ttuple(remainders(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements1-expected_remainders1]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements1-expected_remainders1]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__valid_elements__correct_remainders_generated(self, in_elements, expected_remainders):\n\t\tassert tuple(remainders(*in_elements)) == tuple(expected_remainders)"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements3-expected_remainders3]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements3-expected_remainders3]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__valid_elements__correct_remainders_generated(self, in_elements, expected_remainders):\n\t\tassert tuple(remainders(*in_elements)) == tuple(expected_remainders)"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements4-expected_remainders4]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements4-expected_remainders4]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__valid_elements__correct_remainders_generated(self, in_elements, expected_remainders):\n\t\tassert tuple(remainders(*in_elements)) == tuple(expected_remainders)"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements5-expected_remainders5]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements5-expected_remainders5]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__valid_elements__correct_remainders_generated(self, in_elements, expected_remainders):\n\t\tassert tuple(remainders(*in_elements)) == tuple(expected_remainders)"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[1-elements6-expected_remainder6]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[1-elements6-expected_remainder6]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__valid_elements__correct_remainder_returned(self, k, elements, expected_remainder):\n\t\n\t\tassert remainder(k, *elements) == expected_remainder"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[2-elements7-expected_remainder7]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[2-elements7-expected_remainder7]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__valid_elements__correct_remainder_returned(self, k, elements, expected_remainder):\n\t\n\t\tassert remainder(k, *elements) == expected_remainder"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs13-expected_fraction_obj13-expected_elements13-0-expected_counter13-None-expected_convergents13-expected_ref_right_order2_mediant13-expected_ref_left_order2_mediant13-expected_ref_simple_mediant13-123456789.0-expected_decimal_value13]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs13-expected_fraction_obj13-expected_elements13-0-expected_counter13-None-expected_convergents13-expected_ref_right_order2_mediant13-expected_ref_left_order2_mediant13-expected_ref_simple_mediant13-123456789.0-expected_decimal_value13]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised(\n        self,\n        valid_inputs,\n        expected_fraction_obj,\n        expected_elements,\n        expected_order,\n        expected_counter,\n        expected_khinchin_mean,\n        expected_convergents,\n        expected_ref_right_order2_mediant,\n        expected_ref_left_order2_mediant,\n        expected_ref_simple_mediant,\n        expected_float_value,\n        expected_decimal_value\n    ):\n        expected = expected_fraction_obj\n\n        # The received ``ContinuedFraction`` object\n        received = ContinuedFraction(*valid_inputs)\n\n        # Compare the received and expected objects AS ``fractions.Fraction``\n        # objects\n        assert received == expected\n\n        # Compare the float values\n        assert received.as_float() == expected_float_value\n\n        # Compare the decimal values\n        try:\n            assert received.as_decimal() == expected_decimal_value\n        except decimal.Inexact:\n            pass\n\n        # Compare the element sequences\n        assert received.elements == expected_elements\n\n        # Compare the orders\n        assert received.order == expected_order\n\n        # Compare the element counters\n        assert received.counter == expected_counter\n\n        # Compare the Khinchin means\n        assert received.khinchin_mean == expected_khinchin_mean\n\n        # Compare the convergents using the ``.convergent`` method\n        assert not any(\n            received.convergent(k) != expected_convergents[k][1]\n            for k in range(received.order + 1)\n        )\n\n        # Compare the convergents using the ``.convergents`` property\n        assert tuple(received.convergents) == expected_convergents\n\n        # Compare the even-order convergents using the ``.even_order_convergents` property\n        assert tuple(received.even_convergents) == tuple((k, expected_convergents[k][1]) for k in range(0, received.order + 1, 2))\n\n        # Compare the order-order convergents using the ``.odd_order_convergents` property\n        assert tuple(received.odd_convergents) == tuple((k, expected_convergents[k][1]) for k in range(1, received.order + 1, 2))\n\n        # Compare the 2nd order right- and left-mediants, and also the simple\n        # mediant, using a reference continued fraction of ``1/1``\n        assert received.right_mediant(1, k=2) == expected_ref_right_order2_mediant\n        assert received.left_mediant(1, k=2) == expected_ref_left_order2_mediant\n        assert received.mediant(1) == expected_ref_simple_mediant\n\n        expected_remainders = tuple(\n            (k, ContinuedFraction.from_elements(*expected_elements[k:]))\n            for k in reversed(range(received.order + 1))\n        )\n        # Compare the remainders using the ``.remainder`` method\n        assert all(\n            received.remainder(k) == expected_remainders[::-1][k][1]\n            for k in reversed(range(received.order + 1))\n        )\n\n        # Compare the remainders using the ``.remainders`` property\n        assert tuple(received.remainders) == expected_remainders"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-3-None-expected_coprime_integers15]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-3-None-expected_coprime_integers15]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-4-None-expected_coprime_integers16]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-4-None-expected_coprime_integers16]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf13-cf23-1-expected_right_mediant3]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf13-cf23-1-expected_right_mediant3]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_right_mediant):\n    \n        assert cf1.right_mediant(cf2, k=k) == expected_right_mediant"
            },
            "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[2-elements2-expected_convergent2]": {
                "testid": "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[2-elements2-expected_convergent2]",
                "result": "passed",
                "test_implementation": "\tdef test_convergent__valid_elements__correct_convergent_returned(self, k, elements, expected_convergent):\n\t\n\t\tassert convergent(k, *elements) == expected_convergent"
            },
            "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[3-elements3-expected_convergent3]": {
                "testid": "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[3-elements3-expected_convergent3]",
                "result": "passed",
                "test_implementation": "\tdef test_convergent__valid_elements__correct_convergent_returned(self, k, elements, expected_convergent):\n\t\n\t\tassert convergent(k, *elements) == expected_convergent"
            },
            "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[2-elements4-expected_convergent4]": {
                "testid": "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[2-elements4-expected_convergent4]",
                "result": "passed",
                "test_implementation": "\tdef test_convergent__valid_elements__correct_convergent_returned(self, k, elements, expected_convergent):\n\t\n\t\tassert convergent(k, *elements) == expected_convergent"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements12]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements12]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\ttuple(remainders(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements13]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements13]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\ttuple(remainders(*invalid_elements))"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-1-5-expected_coprime_integers17]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-1-5-expected_coprime_integers17]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[-1-elements4]": {
                "testid": "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[-1-elements4]",
                "result": "passed",
                "test_implementation": "\tdef test_convergent__invalid_elements__value_error_raised(self, k, elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tconvergent(k, *elements)"
            },
            "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[2-elements5]": {
                "testid": "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[2-elements5]",
                "result": "passed",
                "test_implementation": "\tdef test_convergent__invalid_elements__value_error_raised(self, k, elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tconvergent(k, *elements)"
            },
            "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[1-elements6]": {
                "testid": "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[1-elements6]",
                "result": "passed",
                "test_implementation": "\tdef test_convergent__invalid_elements__value_error_raised(self, k, elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tconvergent(k, *elements)"
            },
            "tests/units/test_lib.py::TestMediant::test_mediant__invalid_dir_or_order__value_error_raised[rational11-rational21-not left-1]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_mediant__invalid_dir_or_order__value_error_raised[rational11-rational21-not left-1]",
                "result": "passed",
                "test_implementation": "\tdef test_mediant__invalid_dir_or_order__value_error_raised(self, rational1, rational2, dir, k):\n\t\twith pytest.raises(ValueError):\n\t\t\tmediant(rational1, rational2, dir=dir, k=k)"
            },
            "tests/units/test_lib.py::TestMediant::test_mediant__invalid_dir_or_order__value_error_raised[rational12-rational22-right-0]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_mediant__invalid_dir_or_order__value_error_raised[rational12-rational22-right-0]",
                "result": "passed",
                "test_implementation": "\tdef test_mediant__invalid_dir_or_order__value_error_raised(self, rational1, rational2, dir, k):\n\t\twith pytest.raises(ValueError):\n\t\t\tmediant(rational1, rational2, dir=dir, k=k)"
            },
            "tests/units/test_lib.py::TestMediant::test_mediant__invalid_dir_or_order__value_error_raised[rational13-rational23-not right-1]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_mediant__invalid_dir_or_order__value_error_raised[rational13-rational23-not right-1]",
                "result": "passed",
                "test_implementation": "\tdef test_mediant__invalid_dir_or_order__value_error_raised(self, rational1, rational2, dir, k):\n\t\twith pytest.raises(ValueError):\n\t\t\tmediant(rational1, rational2, dir=dir, k=k)"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-6-None-expected_coprime_integers35]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-6-None-expected_coprime_integers35]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs14-expected_fraction_obj14-expected_elements14-1-expected_counter14-expected_khinchin_mean14-expected_convergents14-expected_ref_right_order2_mediant14-expected_ref_left_order2_mediant14-expected_ref_simple_mediant14-1.5-expected_decimal_value14]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs14-expected_fraction_obj14-expected_elements14-1-expected_counter14-expected_khinchin_mean14-expected_convergents14-expected_ref_right_order2_mediant14-expected_ref_left_order2_mediant14-expected_ref_simple_mediant14-1.5-expected_decimal_value14]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised(\n        self,\n        valid_inputs,\n        expected_fraction_obj,\n        expected_elements,\n        expected_order,\n        expected_counter,\n        expected_khinchin_mean,\n        expected_convergents,\n        expected_ref_right_order2_mediant,\n        expected_ref_left_order2_mediant,\n        expected_ref_simple_mediant,\n        expected_float_value,\n        expected_decimal_value\n    ):\n        expected = expected_fraction_obj\n\n        # The received ``ContinuedFraction`` object\n        received = ContinuedFraction(*valid_inputs)\n\n        # Compare the received and expected objects AS ``fractions.Fraction``\n        # objects\n        assert received == expected\n\n        # Compare the float values\n        assert received.as_float() == expected_float_value\n\n        # Compare the decimal values\n        try:\n            assert received.as_decimal() == expected_decimal_value\n        except decimal.Inexact:\n            pass\n\n        # Compare the element sequences\n        assert received.elements == expected_elements\n\n        # Compare the orders\n        assert received.order == expected_order\n\n        # Compare the element counters\n        assert received.counter == expected_counter\n\n        # Compare the Khinchin means\n        assert received.khinchin_mean == expected_khinchin_mean\n\n        # Compare the convergents using the ``.convergent`` method\n        assert not any(\n            received.convergent(k) != expected_convergents[k][1]\n            for k in range(received.order + 1)\n        )\n\n        # Compare the convergents using the ``.convergents`` property\n        assert tuple(received.convergents) == expected_convergents\n\n        # Compare the even-order convergents using the ``.even_order_convergents` property\n        assert tuple(received.even_convergents) == tuple((k, expected_convergents[k][1]) for k in range(0, received.order + 1, 2))\n\n        # Compare the order-order convergents using the ``.odd_order_convergents` property\n        assert tuple(received.odd_convergents) == tuple((k, expected_convergents[k][1]) for k in range(1, received.order + 1, 2))\n\n        # Compare the 2nd order right- and left-mediants, and also the simple\n        # mediant, using a reference continued fraction of ``1/1``\n        assert received.right_mediant(1, k=2) == expected_ref_right_order2_mediant\n        assert received.left_mediant(1, k=2) == expected_ref_left_order2_mediant\n        assert received.mediant(1) == expected_ref_simple_mediant\n\n        expected_remainders = tuple(\n            (k, ContinuedFraction.from_elements(*expected_elements[k:]))\n            for k in reversed(range(received.order + 1))\n        )\n        # Compare the remainders using the ``.remainder`` method\n        assert all(\n            received.remainder(k) == expected_remainders[::-1][k][1]\n            for k in reversed(range(received.order + 1))\n        )\n\n        # Compare the remainders using the ``.remainders`` property\n        assert tuple(received.remainders) == expected_remainders"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-2-7-expected_coprime_integers51]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-2-7-expected_coprime_integers51]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-2-None-expected_coprime_integers43]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-2-None-expected_coprime_integers43]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-4-None-expected_coprime_integers59]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-4-None-expected_coprime_integers59]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-5-None-expected_coprime_integers60]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-5-None-expected_coprime_integers60]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-1-7-expected_coprime_integers36]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-1-7-expected_coprime_integers36]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-2-7-expected_coprime_integers37]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-2-7-expected_coprime_integers37]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-2-None-expected_coprime_integers31]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-2-None-expected_coprime_integers31]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-3-None-expected_coprime_integers32]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-3-None-expected_coprime_integers32]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-2-3-expected_coprime_integers55]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-2-3-expected_coprime_integers55]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-6-None-expected_coprime_integers61]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-6-None-expected_coprime_integers61]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-3-None-expected_coprime_integers23]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-3-None-expected_coprime_integers23]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-4-None-expected_coprime_integers24]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-4-None-expected_coprime_integers24]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-5-None-expected_coprime_integers25]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-5-None-expected_coprime_integers25]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-8-None-expected_coprime_integers63]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-8-None-expected_coprime_integers63]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-1-9-expected_coprime_integers64]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-1-9-expected_coprime_integers64]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-9-expected_coprime_integers65]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-9-expected_coprime_integers65]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-2-5-expected_coprime_integers39]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-2-5-expected_coprime_integers39]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-2-4-expected_coprime_integers40]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-2-4-expected_coprime_integers40]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-2-3-expected_coprime_integers41]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-2-3-expected_coprime_integers41]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-7-expected_coprime_integers67]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-7-expected_coprime_integers67]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-6-expected_coprime_integers68]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-6-expected_coprime_integers68]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-5-expected_coprime_integers69]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-5-expected_coprime_integers69]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-3-None-expected_coprime_integers44]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-3-None-expected_coprime_integers44]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-4-None-expected_coprime_integers45]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-4-None-expected_coprime_integers45]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-2-4-expected_coprime_integers19]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-2-4-expected_coprime_integers19]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-2-3-expected_coprime_integers20]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-2-3-expected_coprime_integers20]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-1-None-expected_coprime_integers21]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-1-None-expected_coprime_integers21]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-6-None-expected_coprime_integers47]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-6-None-expected_coprime_integers47]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-7-None-expected_coprime_integers48]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-7-None-expected_coprime_integers48]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-1-8-expected_coprime_integers49]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-1-8-expected_coprime_integers49]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-5-None-expected_coprime_integers76]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-5-None-expected_coprime_integers76]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-6-None-expected_coprime_integers77]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-6-None-expected_coprime_integers77]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-7-None-expected_coprime_integers78]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-7-None-expected_coprime_integers78]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-1-10-expected_coprime_integers81]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-1-10-expected_coprime_integers81]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-9-expected_coprime_integers82]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-9-expected_coprime_integers82]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-8-expected_coprime_integers83]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-8-expected_coprime_integers83]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-4-None-expected_coprime_integers33]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-4-None-expected_coprime_integers33]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-3-expected_coprime_integers71]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-3-expected_coprime_integers71]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-8-None-expected_coprime_integers79]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-8-None-expected_coprime_integers79]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-2-5-expected_coprime_integers27]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-2-5-expected_coprime_integers27]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-2-4-expected_coprime_integers28]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-2-4-expected_coprime_integers28]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-2-3-expected_coprime_integers29]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-2-3-expected_coprime_integers29]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-2-6-expected_coprime_integers52]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-2-6-expected_coprime_integers52]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-2-5-expected_coprime_integers53]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-2-5-expected_coprime_integers53]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-1-None-expected_coprime_integers72]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-1-None-expected_coprime_integers72]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-None-expected_coprime_integers73]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-None-expected_coprime_integers73]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-3-None-expected_coprime_integers74]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-3-None-expected_coprime_integers74]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-5-expected_coprime_integers86]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-5-expected_coprime_integers86]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-4-expected_coprime_integers87]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-4-expected_coprime_integers87]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-7-expected_coprime_integers84]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-7-expected_coprime_integers84]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-1-None-expected_coprime_integers56]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-1-None-expected_coprime_integers56]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-None-expected_coprime_integers57]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-None-expected_coprime_integers57]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search_root__invalid_args__raises_value_error[1-root3]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search_root__invalid_args__raises_value_error[1-root3]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree_search_root__invalid_args__raises_value_error(self, n, root):\n        with pytest.raises(ValueError):\n            list(KSRMTree().search_root(n, root))"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[2-root0-expected_pairs0]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[2-root0-expected_pairs0]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree__search_root(self, n, root, expected_pairs):\n        expected = expected_pairs\n\n        received = list(KSRMTree().search_root(n, root))\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[3-expected_totient_value2]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[3-expected_totient_value2]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[9999-expected_totient_value17]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[9999-expected_totient_value17]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-3-expected_coprime_integers88]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-3-expected_coprime_integers88]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[1-expected_totient_value0]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[1-expected_totient_value0]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[100-expected_totient_value12]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[100-expected_totient_value12]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[10000000-expected_totient_value27]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[10000000-expected_totient_value27]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[10000001-expected_totient_value28]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[10000001-expected_totient_value28]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__backtrack[8-visited2-expected_backtracked_tuple2]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__backtrack[8-visited2-expected_backtracked_tuple2]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree__backtrack(self, n, visited, expected_backtracked_tuple):\n        expected = expected_backtracked_tuple\n\n        received = KSRMTree()._backtrack(n, visited)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__backtrack[10-visited3-expected_backtracked_tuple3]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__backtrack[10-visited3-expected_backtracked_tuple3]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree__backtrack(self, n, visited, expected_backtracked_tuple):\n        expected = expected_backtracked_tuple\n\n        received = KSRMTree()._backtrack(n, visited)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search_root__invalid_args__raises_value_error[not an integer-root0]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search_root__invalid_args__raises_value_error[not an integer-root0]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree_search_root__invalid_args__raises_value_error(self, n, root):\n        with pytest.raises(ValueError):\n            list(KSRMTree().search_root(n, root))"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search[10-expected_pairs5]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search[10-expected_pairs5]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree_search(self, n, expected_pairs):\n        expected = expected_pairs\n\n        received = list(KSRMTree().search(n))\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs[1-expected_pairs0]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs[1-expected_pairs0]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs(self, n, expected_pairs):\n        expected = tuple(expected_pairs)\n\n        received = coprime_pairs(n)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[5]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[5]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs__verify_against_summatory_totient_value(self, n):\n        assert len(coprime_pairs(n)) == sum(map(sympy.totient, range(1, n + 1)))"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[6]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[6]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs__verify_against_summatory_totient_value(self, n):\n        assert len(coprime_pairs(n)) == sum(map(sympy.totient, range(1, n + 1)))"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[7]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[7]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs__verify_against_summatory_totient_value(self, n):\n        assert len(coprime_pairs(n)) == sum(map(sympy.totient, range(1, n + 1)))"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[8]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[8]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs__verify_against_summatory_totient_value(self, n):\n        assert len(coprime_pairs(n)) == sum(map(sympy.totient, range(1, n + 1)))"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[100001-expected_totient_value22]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[100001-expected_totient_value22]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[999]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[999]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs__verify_against_summatory_totient_value(self, n):\n        assert len(coprime_pairs(n)) == sum(map(sympy.totient, range(1, n + 1)))"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[10]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[10]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs__verify_against_summatory_totient_value(self, n):\n        assert len(coprime_pairs(n)) == sum(map(sympy.totient, range(1, n + 1)))"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[11]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[11]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs__verify_against_summatory_totient_value(self, n):\n        assert len(coprime_pairs(n)) == sum(map(sympy.totient, range(1, n + 1)))"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[99]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[99]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs__verify_against_summatory_totient_value(self, n):\n        assert len(coprime_pairs(n)) == sum(map(sympy.totient, range(1, n + 1)))"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[10-root4-expected_pairs4]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[10-root4-expected_pairs4]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree__search_root(self, n, root, expected_pairs):\n        expected = expected_pairs\n\n        received = list(KSRMTree().search_root(n, root))\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[2-root5-expected_pairs5]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[2-root5-expected_pairs5]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree__search_root(self, n, root, expected_pairs):\n        expected = expected_pairs\n\n        received = list(KSRMTree().search_root(n, root))\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[3-root6-expected_pairs6]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[3-root6-expected_pairs6]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree__search_root(self, n, root, expected_pairs):\n        expected = expected_pairs\n\n        received = list(KSRMTree().search_root(n, root))\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[4-expected_totient_value3]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[4-expected_totient_value3]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[5-expected_totient_value4]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[5-expected_totient_value4]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs[2-expected_pairs1]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs[2-expected_pairs1]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs(self, n, expected_pairs):\n        expected = tuple(expected_pairs)\n\n        received = coprime_pairs(n)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs[3-expected_pairs2]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs[3-expected_pairs2]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs(self, n, expected_pairs):\n        expected = tuple(expected_pairs)\n\n        received = coprime_pairs(n)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs[4-expected_pairs3]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs[4-expected_pairs3]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs(self, n, expected_pairs):\n        expected = tuple(expected_pairs)\n\n        received = coprime_pairs(n)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[10-root9-expected_pairs9]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[10-root9-expected_pairs9]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree__search_root(self, n, root, expected_pairs):\n        expected = expected_pairs\n\n        received = list(KSRMTree().search_root(n, root))\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs[10-expected_pairs5]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs[10-expected_pairs5]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs(self, n, expected_pairs):\n        expected = tuple(expected_pairs)\n\n        received = coprime_pairs(n)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[101-expected_totient_value13]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[101-expected_totient_value13]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search[1-expected_pairs0]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search[1-expected_pairs0]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree_search(self, n, expected_pairs):\n        expected = expected_pairs\n\n        received = list(KSRMTree().search(n))\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search_root__invalid_args__raises_value_error[1-root1]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search_root__invalid_args__raises_value_error[1-root1]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree_search_root__invalid_args__raises_value_error(self, n, root):\n        with pytest.raises(ValueError):\n            list(KSRMTree().search_root(n, root))"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[6-expected_totient_value5]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[6-expected_totient_value5]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence[4-expected_sequence3]": {
                "testid": "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence[4-expected_sequence3]",
                "result": "passed",
                "test_implementation": "    def test_farey_sequence(self, n, expected_sequence):\n        expected = tuple(expected_sequence)\n\n        received = farey_sequence(n)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence__invalid_args__raises_value_error[n2]": {
                "testid": "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence__invalid_args__raises_value_error[n2]",
                "result": "passed",
                "test_implementation": "    def test_farey_sequence__invalid_args__raises_value_error(self, n):\n        with pytest.raises(ValueError):\n            farey_sequence(n)"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[8-expected_totient_value7]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[8-expected_totient_value7]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__invalid_args__raises_value_error[n0]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__invalid_args__raises_value_error[n0]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs__invalid_args__raises_value_error(self, n):\n        with pytest.raises(ValueError):\n            coprime_pairs(n)"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[4-root7-expected_pairs7]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[4-root7-expected_pairs7]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree__search_root(self, n, root, expected_pairs):\n        expected = expected_pairs\n\n        received = list(KSRMTree().search_root(n, root))\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[3-root1-expected_pairs1]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[3-root1-expected_pairs1]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree__search_root(self, n, root, expected_pairs):\n        expected = expected_pairs\n\n        received = list(KSRMTree().search_root(n, root))\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[10000-expected_totient_value18]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[10000-expected_totient_value18]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[100]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[100]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs__verify_against_summatory_totient_value(self, n):\n        assert len(coprime_pairs(n)) == sum(map(sympy.totient, range(1, n + 1)))"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search__invalid_args__raises_value_error[n0]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search__invalid_args__raises_value_error[n0]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree_search__invalid_args__raises_value_error(self, n):\n        with pytest.raises(ValueError):\n            list(KSRMTree().search(n))"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[999-expected_totient_value14]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[999-expected_totient_value14]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[1]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[1]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs__verify_against_summatory_totient_value(self, n):\n        assert len(coprime_pairs(n)) == sum(map(sympy.totient, range(1, n + 1)))"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search[2-expected_pairs1]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search[2-expected_pairs1]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree_search(self, n, expected_pairs):\n        expected = expected_pairs\n\n        received = list(KSRMTree().search(n))\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence[5-expected_sequence4]": {
                "testid": "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence[5-expected_sequence4]",
                "result": "passed",
                "test_implementation": "    def test_farey_sequence(self, n, expected_sequence):\n        expected = tuple(expected_sequence)\n\n        received = farey_sequence(n)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence__invalid_args__raises_value_error[n3]": {
                "testid": "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence__invalid_args__raises_value_error[n3]",
                "result": "passed",
                "test_implementation": "    def test_farey_sequence__invalid_args__raises_value_error(self, n):\n        with pytest.raises(ValueError):\n            farey_sequence(n)"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[9-expected_totient_value8]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[9-expected_totient_value8]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__invalid_args__raises_value_error[n1]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__invalid_args__raises_value_error[n1]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs__invalid_args__raises_value_error(self, n):\n        with pytest.raises(ValueError):\n            coprime_pairs(n)"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[10001-expected_totient_value19]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[10001-expected_totient_value19]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[4-root2-expected_pairs2]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[4-root2-expected_pairs2]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree__search_root(self, n, root, expected_pairs):\n        expected = expected_pairs\n\n        received = list(KSRMTree().search_root(n, root))\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[1000-expected_totient_value15]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[1000-expected_totient_value15]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search__invalid_args__raises_value_error[n1]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search__invalid_args__raises_value_error[n1]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree_search__invalid_args__raises_value_error(self, n):\n        with pytest.raises(ValueError):\n            list(KSRMTree().search(n))"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[2]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[2]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs__verify_against_summatory_totient_value(self, n):\n        assert len(coprime_pairs(n)) == sum(map(sympy.totient, range(1, n + 1)))"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search[3-expected_pairs2]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search[3-expected_pairs2]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree_search(self, n, expected_pairs):\n        expected = expected_pairs\n\n        received = list(KSRMTree().search(n))\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence[10-expected_sequence5]": {
                "testid": "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence[10-expected_sequence5]",
                "result": "passed",
                "test_implementation": "    def test_farey_sequence(self, n, expected_sequence):\n        expected = tuple(expected_sequence)\n\n        received = farey_sequence(n)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence[1-expected_sequence0]": {
                "testid": "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence[1-expected_sequence0]",
                "result": "passed",
                "test_implementation": "    def test_farey_sequence(self, n, expected_sequence):\n        expected = tuple(expected_sequence)\n\n        received = farey_sequence(n)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[10-expected_totient_value9]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[10-expected_totient_value9]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__invalid_args__raises_value_error[n2]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__invalid_args__raises_value_error[n2]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs__invalid_args__raises_value_error(self, n):\n        with pytest.raises(ValueError):\n            coprime_pairs(n)"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search__invalid_args__raises_value_error[n2]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search__invalid_args__raises_value_error[n2]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree_search__invalid_args__raises_value_error(self, n):\n        with pytest.raises(ValueError):\n            list(KSRMTree().search(n))"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[3]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[3]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs__verify_against_summatory_totient_value(self, n):\n        assert len(coprime_pairs(n)) == sum(map(sympy.totient, range(1, n + 1)))"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs19-expected_fraction_obj19-expected_elements19-1-expected_counter19-expected_khinchin_mean19-expected_convergents19-expected_ref_right_order2_mediant19-expected_ref_left_order2_mediant19-expected_ref_simple_mediant19-0.25-expected_decimal_value19]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs19-expected_fraction_obj19-expected_elements19-1-expected_counter19-expected_khinchin_mean19-expected_convergents19-expected_ref_right_order2_mediant19-expected_ref_left_order2_mediant19-expected_ref_simple_mediant19-0.25-expected_decimal_value19]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised(\n        self,\n        valid_inputs,\n        expected_fraction_obj,\n        expected_elements,\n        expected_order,\n        expected_counter,\n        expected_khinchin_mean,\n        expected_convergents,\n        expected_ref_right_order2_mediant,\n        expected_ref_left_order2_mediant,\n        expected_ref_simple_mediant,\n        expected_float_value,\n        expected_decimal_value\n    ):\n        expected = expected_fraction_obj\n\n        # The received ``ContinuedFraction`` object\n        received = ContinuedFraction(*valid_inputs)\n\n        # Compare the received and expected objects AS ``fractions.Fraction``\n        # objects\n        assert received == expected\n\n        # Compare the float values\n        assert received.as_float() == expected_float_value\n\n        # Compare the decimal values\n        try:\n            assert received.as_decimal() == expected_decimal_value\n        except decimal.Inexact:\n            pass\n\n        # Compare the element sequences\n        assert received.elements == expected_elements\n\n        # Compare the orders\n        assert received.order == expected_order\n\n        # Compare the element counters\n        assert received.counter == expected_counter\n\n        # Compare the Khinchin means\n        assert received.khinchin_mean == expected_khinchin_mean\n\n        # Compare the convergents using the ``.convergent`` method\n        assert not any(\n            received.convergent(k) != expected_convergents[k][1]\n            for k in range(received.order + 1)\n        )\n\n        # Compare the convergents using the ``.convergents`` property\n        assert tuple(received.convergents) == expected_convergents\n\n        # Compare the even-order convergents using the ``.even_order_convergents` property\n        assert tuple(received.even_convergents) == tuple((k, expected_convergents[k][1]) for k in range(0, received.order + 1, 2))\n\n        # Compare the order-order convergents using the ``.odd_order_convergents` property\n        assert tuple(received.odd_convergents) == tuple((k, expected_convergents[k][1]) for k in range(1, received.order + 1, 2))\n\n        # Compare the 2nd order right- and left-mediants, and also the simple\n        # mediant, using a reference continued fraction of ``1/1``\n        assert received.right_mediant(1, k=2) == expected_ref_right_order2_mediant\n        assert received.left_mediant(1, k=2) == expected_ref_left_order2_mediant\n        assert received.mediant(1) == expected_ref_simple_mediant\n\n        expected_remainders = tuple(\n            (k, ContinuedFraction.from_elements(*expected_elements[k:]))\n            for k in reversed(range(received.order + 1))\n        )\n        # Compare the remainders using the ``.remainder`` method\n        assert all(\n            received.remainder(k) == expected_remainders[::-1][k][1]\n            for k in reversed(range(received.order + 1))\n        )\n\n        # Compare the remainders using the ``.remainders`` property\n        assert tuple(received.remainders) == expected_remainders"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf16-cf26-expected_simple_mediant6]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf16-cf26-expected_simple_mediant6]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, expected_simple_mediant):\n    \n        assert cf1.mediant(cf2) == expected_simple_mediant"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance0-new_elements0-expected_comparative_instance0]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance0-new_elements0-expected_comparative_instance0]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__extend__valid_elements__correctly_extended(self, instance, new_elements, expected_comparative_instance):\n        original_id = id(instance)\n        original_elements = instance.elements\n\n        instance.extend(*new_elements)\n\n        assert id(instance) == original_id\n        assert instance == expected_comparative_instance\n        assert hash(instance) == hash(expected_comparative_instance)\n        assert instance == ContinuedFraction.from_elements(*original_elements, *new_elements)\n        assert instance.order == expected_comparative_instance.order\n        assert instance.counter == expected_comparative_instance.counter\n        assert tuple(instance.convergents) == tuple(expected_comparative_instance.convergents)\n        assert tuple(instance.remainders) == tuple(expected_comparative_instance.remainders)\n        assert instance.khinchin_mean == expected_comparative_instance.khinchin_mean"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__invalid_elements__value_error_raised[instance2-invalid_elements2]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__invalid_elements__value_error_raised[instance2-invalid_elements2]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__truncate__invalid_elements__value_error_raised(self, instance, invalid_elements):\n        with pytest.raises(ValueError):\n            instance.truncate(*invalid_elements)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[4-3-expected_semiconvergent8]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[4-3-expected_semiconvergent8]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned(self, k, m, expected_semiconvergent):\n        test_cf = ContinuedFraction(-415, 93)\n\n        assert test_cf.semiconvergent(k, m) == expected_semiconvergent\n        assert test_cf.semiconvergent(k, m) == test_cf.convergent(k - 1).right_mediant(test_cf.convergent(k), k=m)"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search[4-expected_pairs3]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search[4-expected_pairs3]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree_search(self, n, expected_pairs):\n        expected = expected_pairs\n\n        received = list(KSRMTree().search(n))\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[5-root8-expected_pairs8]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[5-root8-expected_pairs8]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree__search_root(self, n, root, expected_pairs):\n        expected = expected_pairs\n\n        received = list(KSRMTree().search_root(n, root))\n\n        assert received == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf112-cf212-2-expected_left_mediant12]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf112-cf212-2-expected_left_mediant12]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_left_mediant):\n    \n        assert cf1.left_mediant(cf2, k=k) == expected_left_mediant"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf12-cf22-expected_simple_mediant2]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned[cf12-cf22-expected_simple_mediant2]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, expected_simple_mediant):\n    \n        assert cf1.mediant(cf2) == expected_simple_mediant"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs3-expected_fraction_obj3-expected_elements3-3-expected_counter3-expected_khinchin_mean3-expected_convergents3-expected_ref_right_order2_mediant3-expected_ref_left_order2_mediant3-expected_ref_simple_mediant3-3.245-expected_decimal_value3]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs3-expected_fraction_obj3-expected_elements3-3-expected_counter3-expected_khinchin_mean3-expected_convergents3-expected_ref_right_order2_mediant3-expected_ref_left_order2_mediant3-expected_ref_simple_mediant3-3.245-expected_decimal_value3]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised(\n        self,\n        valid_inputs,\n        expected_fraction_obj,\n        expected_elements,\n        expected_order,\n        expected_counter,\n        expected_khinchin_mean,\n        expected_convergents,\n        expected_ref_right_order2_mediant,\n        expected_ref_left_order2_mediant,\n        expected_ref_simple_mediant,\n        expected_float_value,\n        expected_decimal_value\n    ):\n        expected = expected_fraction_obj\n\n        # The received ``ContinuedFraction`` object\n        received = ContinuedFraction(*valid_inputs)\n\n        # Compare the received and expected objects AS ``fractions.Fraction``\n        # objects\n        assert received == expected\n\n        # Compare the float values\n        assert received.as_float() == expected_float_value\n\n        # Compare the decimal values\n        try:\n            assert received.as_decimal() == expected_decimal_value\n        except decimal.Inexact:\n            pass\n\n        # Compare the element sequences\n        assert received.elements == expected_elements\n\n        # Compare the orders\n        assert received.order == expected_order\n\n        # Compare the element counters\n        assert received.counter == expected_counter\n\n        # Compare the Khinchin means\n        assert received.khinchin_mean == expected_khinchin_mean\n\n        # Compare the convergents using the ``.convergent`` method\n        assert not any(\n            received.convergent(k) != expected_convergents[k][1]\n            for k in range(received.order + 1)\n        )\n\n        # Compare the convergents using the ``.convergents`` property\n        assert tuple(received.convergents) == expected_convergents\n\n        # Compare the even-order convergents using the ``.even_order_convergents` property\n        assert tuple(received.even_convergents) == tuple((k, expected_convergents[k][1]) for k in range(0, received.order + 1, 2))\n\n        # Compare the order-order convergents using the ``.odd_order_convergents` property\n        assert tuple(received.odd_convergents) == tuple((k, expected_convergents[k][1]) for k in range(1, received.order + 1, 2))\n\n        # Compare the 2nd order right- and left-mediants, and also the simple\n        # mediant, using a reference continued fraction of ``1/1``\n        assert received.right_mediant(1, k=2) == expected_ref_right_order2_mediant\n        assert received.left_mediant(1, k=2) == expected_ref_left_order2_mediant\n        assert received.mediant(1) == expected_ref_simple_mediant\n\n        expected_remainders = tuple(\n            (k, ContinuedFraction.from_elements(*expected_elements[k:]))\n            for k in reversed(range(received.order + 1))\n        )\n        # Compare the remainders using the ``.remainder`` method\n        assert all(\n            received.remainder(k) == expected_remainders[::-1][k][1]\n            for k in reversed(range(received.order + 1))\n        )\n\n        # Compare the remainders using the ``.remainders`` property\n        assert tuple(received.remainders) == expected_remainders"
            },
            "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence[2-expected_sequence1]": {
                "testid": "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence[2-expected_sequence1]",
                "result": "passed",
                "test_implementation": "    def test_farey_sequence(self, n, expected_sequence):\n        expected = tuple(expected_sequence)\n\n        received = farey_sequence(n)\n\n        assert received == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance4-new_elements4-expected_comparative_instance4]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance4-new_elements4-expected_comparative_instance4]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__extend__valid_elements__correctly_extended(self, instance, new_elements, expected_comparative_instance):\n        original_id = id(instance)\n        original_elements = instance.elements\n\n        instance.extend(*new_elements)\n\n        assert id(instance) == original_id\n        assert instance == expected_comparative_instance\n        assert hash(instance) == hash(expected_comparative_instance)\n        assert instance == ContinuedFraction.from_elements(*original_elements, *new_elements)\n        assert instance.order == expected_comparative_instance.order\n        assert instance.counter == expected_comparative_instance.counter\n        assert tuple(instance.convergents) == tuple(expected_comparative_instance.convergents)\n        assert tuple(instance.remainders) == tuple(expected_comparative_instance.remainders)\n        assert instance.khinchin_mean == expected_comparative_instance.khinchin_mean"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf10-cf20-1-expected_right_mediant0]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf10-cf20-1-expected_right_mediant0]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_right_mediant):\n    \n        assert cf1.right_mediant(cf2, k=k) == expected_right_mediant"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-6-expected_coprime_integers85]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-2-6-expected_coprime_integers85]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search_root__invalid_args__raises_value_error[not an integer-root2]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search_root__invalid_args__raises_value_error[not an integer-root2]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree_search_root__invalid_args__raises_value_error(self, n, root):\n        with pytest.raises(ValueError):\n            list(KSRMTree().search_root(n, root))"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements7-expected7]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements7-expected7]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned(self, elements, expected):\n            received = ContinuedFraction.from_elements(*elements)\n\n            assert received == expected\n            assert received.elements == expected.elements"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements6]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements6]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__invalid_elements__value_error_raised(self, invalid_elements):\n        with pytest.raises(ValueError):\n            ContinuedFraction.from_elements(*invalid_elements)"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[7-expected_totient_value6]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[7-expected_totient_value6]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__invalid_elements__value_error_raised[instance0-invalid_elements0]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__invalid_elements__value_error_raised[instance0-invalid_elements0]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__extend__invalid_elements__value_error_raised(self, instance, invalid_elements):\n        with pytest.raises(ValueError):\n            instance.extend(*invalid_elements)"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[1001-expected_totient_value16]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[1001-expected_totient_value16]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance8-new_elements8-expected_comparative_instance8]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance8-new_elements8-expected_comparative_instance8]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__extend__valid_elements__correctly_extended(self, instance, new_elements, expected_comparative_instance):\n        original_id = id(instance)\n        original_elements = instance.elements\n\n        instance.extend(*new_elements)\n\n        assert id(instance) == original_id\n        assert instance == expected_comparative_instance\n        assert hash(instance) == hash(expected_comparative_instance)\n        assert instance == ContinuedFraction.from_elements(*original_elements, *new_elements)\n        assert instance.order == expected_comparative_instance.order\n        assert instance.counter == expected_comparative_instance.counter\n        assert tuple(instance.convergents) == tuple(expected_comparative_instance.convergents)\n        assert tuple(instance.remainders) == tuple(expected_comparative_instance.remainders)\n        assert instance.khinchin_mean == expected_comparative_instance.khinchin_mean"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__invalid_args__raises_value_error[n3]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__invalid_args__raises_value_error[n3]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs__invalid_args__raises_value_error(self, n):\n        with pytest.raises(ValueError):\n            coprime_pairs(n)"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs[5-expected_pairs4]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs[5-expected_pairs4]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs(self, n, expected_pairs):\n        expected = tuple(expected_pairs)\n\n        received = coprime_pairs(n)\n\n        assert received == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements14]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements14]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__invalid_elements__value_error_raised(self, invalid_elements):\n        with pytest.raises(ValueError):\n            ContinuedFraction.from_elements(*invalid_elements)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand13-expected13-expected_elements13]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand13-expected13-expected_elements13]",
                "result": "passed",
                "test_implementation": "    def test___neg__(self, operand, expected, expected_elements):\n        received = -operand\n\n        assert expected == received\n        assert received.elements == expected_elements"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[5-root3-expected_pairs3]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[5-root3-expected_pairs3]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree__search_root(self, n, root, expected_pairs):\n        expected = expected_pairs\n\n        received = list(KSRMTree().search_root(n, root))\n\n        assert received == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand1-expected1-expected_elements1]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand1-expected1-expected_elements1]",
                "result": "passed",
                "test_implementation": "    def test___neg__(self, operand, expected, expected_elements):\n        received = -operand\n\n        assert expected == received\n        assert received.elements == expected_elements"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[9]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[9]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs__verify_against_summatory_totient_value(self, n):\n        assert len(coprime_pairs(n)) == sum(map(sympy.totient, range(1, n + 1)))"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[-1--1]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[-1--1]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__invalid_args(self, k, m):\n        test_cf = ContinuedFraction(-415, 93)\n\n        with pytest.raises(ValueError):\n            test_cf.semiconvergent(k, m)"
            },
            "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r5-elements5]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r5-elements5]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_rational__valid_integers__correct_elements_generated(self, r, elements):\n\t\t\n\t\texpected = elements\n\n\t\tassert tuple(continued_fraction_rational(r)) == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf10-cf20-1-expected_left_mediant0]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf10-cf20-1-expected_left_mediant0]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_left_mediant):\n    \n        assert cf1.left_mediant(cf2, k=k) == expected_left_mediant"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf14-cf24-1-expected_left_mediant4]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf14-cf24-1-expected_left_mediant4]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_left_mediant):\n    \n        assert cf1.left_mediant(cf2, k=k) == expected_left_mediant"
            },
            "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r1-elements1]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r1-elements1]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_rational__valid_integers__correct_elements_generated(self, r, elements):\n\t\t\n\t\texpected = elements\n\n\t\tassert tuple(continued_fraction_rational(r)) == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs7-expected_fraction_obj7-expected_elements7-3-expected_counter7-expected_khinchin_mean7-expected_convergents7-expected_ref_right_order2_mediant7-expected_ref_left_order2_mediant7-expected_ref_simple_mediant7--0.3333-expected_decimal_value7]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs7-expected_fraction_obj7-expected_elements7-3-expected_counter7-expected_khinchin_mean7-expected_convergents7-expected_ref_right_order2_mediant7-expected_ref_left_order2_mediant7-expected_ref_simple_mediant7--0.3333-expected_decimal_value7]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised(\n        self,\n        valid_inputs,\n        expected_fraction_obj,\n        expected_elements,\n        expected_order,\n        expected_counter,\n        expected_khinchin_mean,\n        expected_convergents,\n        expected_ref_right_order2_mediant,\n        expected_ref_left_order2_mediant,\n        expected_ref_simple_mediant,\n        expected_float_value,\n        expected_decimal_value\n    ):\n        expected = expected_fraction_obj\n\n        # The received ``ContinuedFraction`` object\n        received = ContinuedFraction(*valid_inputs)\n\n        # Compare the received and expected objects AS ``fractions.Fraction``\n        # objects\n        assert received == expected\n\n        # Compare the float values\n        assert received.as_float() == expected_float_value\n\n        # Compare the decimal values\n        try:\n            assert received.as_decimal() == expected_decimal_value\n        except decimal.Inexact:\n            pass\n\n        # Compare the element sequences\n        assert received.elements == expected_elements\n\n        # Compare the orders\n        assert received.order == expected_order\n\n        # Compare the element counters\n        assert received.counter == expected_counter\n\n        # Compare the Khinchin means\n        assert received.khinchin_mean == expected_khinchin_mean\n\n        # Compare the convergents using the ``.convergent`` method\n        assert not any(\n            received.convergent(k) != expected_convergents[k][1]\n            for k in range(received.order + 1)\n        )\n\n        # Compare the convergents using the ``.convergents`` property\n        assert tuple(received.convergents) == expected_convergents\n\n        # Compare the even-order convergents using the ``.even_order_convergents` property\n        assert tuple(received.even_convergents) == tuple((k, expected_convergents[k][1]) for k in range(0, received.order + 1, 2))\n\n        # Compare the order-order convergents using the ``.odd_order_convergents` property\n        assert tuple(received.odd_convergents) == tuple((k, expected_convergents[k][1]) for k in range(1, received.order + 1, 2))\n\n        # Compare the 2nd order right- and left-mediants, and also the simple\n        # mediant, using a reference continued fraction of ``1/1``\n        assert received.right_mediant(1, k=2) == expected_ref_right_order2_mediant\n        assert received.left_mediant(1, k=2) == expected_ref_left_order2_mediant\n        assert received.mediant(1) == expected_ref_simple_mediant\n\n        expected_remainders = tuple(\n            (k, ContinuedFraction.from_elements(*expected_elements[k:]))\n            for k in reversed(range(received.order + 1))\n        )\n        # Compare the remainders using the ``.remainder`` method\n        assert all(\n            received.remainder(k) == expected_remainders[::-1][k][1]\n            for k in reversed(range(received.order + 1))\n        )\n\n        # Compare the remainders using the ``.remainders`` property\n        assert tuple(received.remainders) == expected_remainders"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements10]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements10]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__invalid_elements__value_error_raised(self, invalid_elements):\n        with pytest.raises(ValueError):\n            ContinuedFraction.from_elements(*invalid_elements)"
            },
            "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements2-fraction2]": {
                "testid": "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements2-fraction2]",
                "result": "passed",
                "test_implementation": "\tdef test_fraction_from_elements__valid_elements__correct_fraction_returned(self, elements, fraction):\n\t\t\n\t\texpected = fraction\n\n\t\tassert fraction_from_elements(*elements) == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[not an int-1]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[not an int-1]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__invalid_args(self, k, m):\n        test_cf = ContinuedFraction(-415, 93)\n\n        with pytest.raises(ValueError):\n            test_cf.semiconvergent(k, m)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[1-1-expected_semiconvergent0]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[1-1-expected_semiconvergent0]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned(self, k, m, expected_semiconvergent):\n        test_cf = ContinuedFraction(-415, 93)\n\n        assert test_cf.semiconvergent(k, m) == expected_semiconvergent\n        assert test_cf.semiconvergent(k, m) == test_cf.convergent(k - 1).right_mediant(test_cf.convergent(k), k=m)"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[3.245-expected9]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[3.245-expected9]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[1-elements2]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[1-elements2]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__invalid_elements__value_error_raised(self, k, elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tremainder(k, *elements)"
            },
            "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__invalid_elements__value_error_raised[elements1]": {
                "testid": "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__invalid_elements__value_error_raised[elements1]",
                "result": "passed",
                "test_implementation": "\tdef test_fraction_from_elements__invalid_elements__value_error_raised(self, elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tfraction_from_elements(*elements)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance5-tail_elements5-expected_comparative_instance5]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance5-tail_elements5-expected_comparative_instance5]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__truncate__valid_elements__correctly_truncated(self, instance, tail_elements, expected_comparative_instance):\n        original_id = id(instance)\n        original_elements = instance.elements\n        order = instance.order\n        truncation_length = len(tail_elements)\n\n        instance.truncate(*tail_elements)\n\n        assert id(instance) == original_id\n        assert instance == expected_comparative_instance\n        assert hash(instance) == hash(expected_comparative_instance)\n        assert instance == ContinuedFraction.from_elements(*original_elements[:order + 1 - truncation_length])\n        assert instance.order == expected_comparative_instance.order\n        assert instance.counter == expected_comparative_instance.counter\n        assert tuple(instance.convergents) == tuple(expected_comparative_instance.convergents)\n        assert tuple(instance.remainders) == tuple(expected_comparative_instance.remainders)\n        assert instance.khinchin_mean == expected_comparative_instance.khinchin_mean"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance1-tail_elements1-expected_comparative_instance1]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance1-tail_elements1-expected_comparative_instance1]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__truncate__valid_elements__correctly_truncated(self, instance, tail_elements, expected_comparative_instance):\n        original_id = id(instance)\n        original_elements = instance.elements\n        order = instance.order\n        truncation_length = len(tail_elements)\n\n        instance.truncate(*tail_elements)\n\n        assert id(instance) == original_id\n        assert instance == expected_comparative_instance\n        assert hash(instance) == hash(expected_comparative_instance)\n        assert instance == ContinuedFraction.from_elements(*original_elements[:order + 1 - truncation_length])\n        assert instance.order == expected_comparative_instance.order\n        assert instance.counter == expected_comparative_instance.counter\n        assert tuple(instance.convergents) == tuple(expected_comparative_instance.convergents)\n        assert tuple(instance.remainders) == tuple(expected_comparative_instance.remainders)\n        assert instance.khinchin_mean == expected_comparative_instance.khinchin_mean"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-5.25-expected25]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-5.25-expected25]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand9-expected9-expected_elements9]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand9-expected9-expected_elements9]",
                "result": "passed",
                "test_implementation": "    def test___neg__(self, operand, expected, expected_elements):\n        received = -operand\n\n        assert expected == received\n        assert received.elements == expected_elements"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs15-expected_fraction_obj15-expected_elements15-1-expected_counter15-expected_khinchin_mean15-expected_convergents15-expected_ref_right_order2_mediant15-expected_ref_left_order2_mediant15-expected_ref_simple_mediant15--3.75-expected_decimal_value15]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs15-expected_fraction_obj15-expected_elements15-1-expected_counter15-expected_khinchin_mean15-expected_convergents15-expected_ref_right_order2_mediant15-expected_ref_left_order2_mediant15-expected_ref_simple_mediant15--3.75-expected_decimal_value15]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised(\n        self,\n        valid_inputs,\n        expected_fraction_obj,\n        expected_elements,\n        expected_order,\n        expected_counter,\n        expected_khinchin_mean,\n        expected_convergents,\n        expected_ref_right_order2_mediant,\n        expected_ref_left_order2_mediant,\n        expected_ref_simple_mediant,\n        expected_float_value,\n        expected_decimal_value\n    ):\n        expected = expected_fraction_obj\n\n        # The received ``ContinuedFraction`` object\n        received = ContinuedFraction(*valid_inputs)\n\n        # Compare the received and expected objects AS ``fractions.Fraction``\n        # objects\n        assert received == expected\n\n        # Compare the float values\n        assert received.as_float() == expected_float_value\n\n        # Compare the decimal values\n        try:\n            assert received.as_decimal() == expected_decimal_value\n        except decimal.Inexact:\n            pass\n\n        # Compare the element sequences\n        assert received.elements == expected_elements\n\n        # Compare the orders\n        assert received.order == expected_order\n\n        # Compare the element counters\n        assert received.counter == expected_counter\n\n        # Compare the Khinchin means\n        assert received.khinchin_mean == expected_khinchin_mean\n\n        # Compare the convergents using the ``.convergent`` method\n        assert not any(\n            received.convergent(k) != expected_convergents[k][1]\n            for k in range(received.order + 1)\n        )\n\n        # Compare the convergents using the ``.convergents`` property\n        assert tuple(received.convergents) == expected_convergents\n\n        # Compare the even-order convergents using the ``.even_order_convergents` property\n        assert tuple(received.even_convergents) == tuple((k, expected_convergents[k][1]) for k in range(0, received.order + 1, 2))\n\n        # Compare the order-order convergents using the ``.odd_order_convergents` property\n        assert tuple(received.odd_convergents) == tuple((k, expected_convergents[k][1]) for k in range(1, received.order + 1, 2))\n\n        # Compare the 2nd order right- and left-mediants, and also the simple\n        # mediant, using a reference continued fraction of ``1/1``\n        assert received.right_mediant(1, k=2) == expected_ref_right_order2_mediant\n        assert received.left_mediant(1, k=2) == expected_ref_left_order2_mediant\n        assert received.mediant(1) == expected_ref_simple_mediant\n\n        expected_remainders = tuple(\n            (k, ContinuedFraction.from_elements(*expected_elements[k:]))\n            for k in reversed(range(received.order + 1))\n        )\n        # Compare the remainders using the ``.remainder`` method\n        assert all(\n            received.remainder(k) == expected_remainders[::-1][k][1]\n            for k in reversed(range(received.order + 1))\n        )\n\n        # Compare the remainders using the ``.remainders`` property\n        assert tuple(received.remainders) == expected_remainders"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs11-expected_fraction_obj11-expected_elements11-1-expected_counter11-expected_khinchin_mean11-expected_convergents11-expected_ref_right_order2_mediant11-expected_ref_left_order2_mediant11-expected_ref_simple_mediant11-0.1-expected_decimal_value11]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs11-expected_fraction_obj11-expected_elements11-1-expected_counter11-expected_khinchin_mean11-expected_convergents11-expected_ref_right_order2_mediant11-expected_ref_left_order2_mediant11-expected_ref_simple_mediant11-0.1-expected_decimal_value11]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised(\n        self,\n        valid_inputs,\n        expected_fraction_obj,\n        expected_elements,\n        expected_order,\n        expected_counter,\n        expected_khinchin_mean,\n        expected_convergents,\n        expected_ref_right_order2_mediant,\n        expected_ref_left_order2_mediant,\n        expected_ref_simple_mediant,\n        expected_float_value,\n        expected_decimal_value\n    ):\n        expected = expected_fraction_obj\n\n        # The received ``ContinuedFraction`` object\n        received = ContinuedFraction(*valid_inputs)\n\n        # Compare the received and expected objects AS ``fractions.Fraction``\n        # objects\n        assert received == expected\n\n        # Compare the float values\n        assert received.as_float() == expected_float_value\n\n        # Compare the decimal values\n        try:\n            assert received.as_decimal() == expected_decimal_value\n        except decimal.Inexact:\n            pass\n\n        # Compare the element sequences\n        assert received.elements == expected_elements\n\n        # Compare the orders\n        assert received.order == expected_order\n\n        # Compare the element counters\n        assert received.counter == expected_counter\n\n        # Compare the Khinchin means\n        assert received.khinchin_mean == expected_khinchin_mean\n\n        # Compare the convergents using the ``.convergent`` method\n        assert not any(\n            received.convergent(k) != expected_convergents[k][1]\n            for k in range(received.order + 1)\n        )\n\n        # Compare the convergents using the ``.convergents`` property\n        assert tuple(received.convergents) == expected_convergents\n\n        # Compare the even-order convergents using the ``.even_order_convergents` property\n        assert tuple(received.even_convergents) == tuple((k, expected_convergents[k][1]) for k in range(0, received.order + 1, 2))\n\n        # Compare the order-order convergents using the ``.odd_order_convergents` property\n        assert tuple(received.odd_convergents) == tuple((k, expected_convergents[k][1]) for k in range(1, received.order + 1, 2))\n\n        # Compare the 2nd order right- and left-mediants, and also the simple\n        # mediant, using a reference continued fraction of ``1/1``\n        assert received.right_mediant(1, k=2) == expected_ref_right_order2_mediant\n        assert received.left_mediant(1, k=2) == expected_ref_left_order2_mediant\n        assert received.mediant(1) == expected_ref_simple_mediant\n\n        expected_remainders = tuple(\n            (k, ContinuedFraction.from_elements(*expected_elements[k:]))\n            for k in reversed(range(received.order + 1))\n        )\n        # Compare the remainders using the ``.remainder`` method\n        assert all(\n            received.remainder(k) == expected_remainders[::-1][k][1]\n            for k in reversed(range(received.order + 1))\n        )\n\n        # Compare the remainders using the ``.remainders`` property\n        assert tuple(received.remainders) == expected_remainders"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements2]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised[invalid_elements2]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__invalid_elements__value_error_raised(self, invalid_elements):\n        with pytest.raises(ValueError):\n            ContinuedFraction.from_elements(*invalid_elements)"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[0.3333-expected17]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[0.3333-expected17]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements3-expected3]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements3-expected3]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned(self, elements, expected):\n            received = ContinuedFraction.from_elements(*elements)\n\n            assert received == expected\n            assert received.elements == expected.elements"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements10]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements10]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tlist(convergents(*invalid_elements))"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf18-cf28-1-expected_left_mediant8]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned[cf18-cf28-1-expected_left_mediant8]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_left_mediant):\n    \n        assert cf1.left_mediant(cf2, k=k) == expected_left_mediant"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[2-expected_totient_value1]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[2-expected_totient_value1]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-5000-expected1]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[-5000-expected1]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[101]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[101]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs__verify_against_summatory_totient_value(self, n):\n        assert len(coprime_pairs(n)) == sum(map(sympy.totient, range(1, n + 1)))"
            },
            "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[1-elements7]": {
                "testid": "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[1-elements7]",
                "result": "passed",
                "test_implementation": "\tdef test_convergent__invalid_elements__value_error_raised(self, k, elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tconvergent(k, *elements)"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf14-cf24-1-expected_right_mediant4]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf14-cf24-1-expected_right_mediant4]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_right_mediant):\n    \n        assert cf1.right_mediant(cf2, k=k) == expected_right_mediant"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x13-expected13]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x13-expected13]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements3-expected_convergents3]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements3-expected_convergents3]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__valid_elements__correct_convergents_generated(self, in_elements, expected_convergents):\n\t\tassert tuple(convergents(*in_elements)) == tuple(expected_convergents)"
            },
            "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r9-elements9]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r9-elements9]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_rational__valid_integers__correct_elements_generated(self, r, elements):\n\t\t\n\t\texpected = elements\n\n\t\tassert tuple(continued_fraction_rational(r)) == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf18-cf28-1-expected_right_mediant8]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned[cf18-cf28-1-expected_right_mediant8]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned(self, cf1, cf2, k, expected_right_mediant):\n    \n        assert cf1.right_mediant(cf2, k=k) == expected_right_mediant"
            },
            "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements10-fraction10]": {
                "testid": "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements10-fraction10]",
                "result": "passed",
                "test_implementation": "\tdef test_fraction_from_elements__valid_elements__correct_fraction_returned(self, elements, fraction):\n\t\t\n\t\texpected = fraction\n\n\t\tassert fraction_from_elements(*elements) == expected"
            },
            "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[1-elements3]": {
                "testid": "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised[1-elements3]",
                "result": "passed",
                "test_implementation": "\tdef test_convergent__invalid_elements__value_error_raised(self, k, elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tconvergent(k, *elements)"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[5.25-expected21]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[5.25-expected21]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[not an int-not an int]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args[not an int-not an int]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__invalid_args(self, k, m):\n        test_cf = ContinuedFraction(-415, 93)\n\n        with pytest.raises(ValueError):\n            test_cf.semiconvergent(k, m)"
            },
            "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[4-elements9-expected_convergent9]": {
                "testid": "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[4-elements9-expected_convergent9]",
                "result": "passed",
                "test_implementation": "\tdef test_convergent__valid_elements__correct_convergent_returned(self, k, elements, expected_convergent):\n\t\n\t\tassert convergent(k, *elements) == expected_convergent"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements7-expected_convergents7]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements7-expected_convergents7]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__valid_elements__correct_convergents_generated(self, in_elements, expected_convergents):\n\t\tassert tuple(convergents(*in_elements)) == tuple(expected_convergents)"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements2]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements2]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tlist(convergents(*invalid_elements))"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[3-2-expected_semiconvergent4]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[3-2-expected_semiconvergent4]",
                "result": "passed",
                "test_implementation": "    def test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned(self, k, m, expected_semiconvergent):\n        test_cf = ContinuedFraction(-415, 93)\n\n        assert test_cf.semiconvergent(k, m) == expected_semiconvergent\n        assert test_cf.semiconvergent(k, m) == test_cf.convergent(k - 1).right_mediant(test_cf.convergent(k), k=m)"
            },
            "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[1-elements5-expected_convergent5]": {
                "testid": "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[1-elements5-expected_convergent5]",
                "result": "passed",
                "test_implementation": "\tdef test_convergent__valid_elements__correct_convergent_returned(self, k, elements, expected_convergent):\n\t\n\t\tassert convergent(k, *elements) == expected_convergent"
            },
            "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements6-fraction6]": {
                "testid": "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements6-fraction6]",
                "result": "passed",
                "test_implementation": "\tdef test_fraction_from_elements__valid_elements__correct_fraction_returned(self, elements, fraction):\n\t\t\n\t\texpected = fraction\n\n\t\tassert fraction_from_elements(*elements) == expected"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements6]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements6]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tlist(convergents(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[0-elements0-expected_remainder0]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[0-elements0-expected_remainder0]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__valid_elements__correct_remainder_returned(self, k, elements, expected_remainder):\n\t\n\t\tassert remainder(k, *elements) == expected_remainder"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[0-elements4-expected_remainder4]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[0-elements4-expected_remainder4]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__valid_elements__correct_remainder_returned(self, k, elements, expected_remainder):\n\t\n\t\tassert remainder(k, *elements) == expected_remainder"
            },
            "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[0-elements1-expected_convergent1]": {
                "testid": "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[0-elements1-expected_convergent1]",
                "result": "passed",
                "test_implementation": "\tdef test_convergent__valid_elements__correct_convergent_returned(self, k, elements, expected_convergent):\n\t\n\t\tassert convergent(k, *elements) == expected_convergent"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements10]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements10]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\ttuple(remainders(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements6]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements6]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\ttuple(remainders(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements2]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements2]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\ttuple(remainders(*invalid_elements))"
            },
            "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand5-expected5-expected_elements5]": {
                "testid": "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__[operand5-expected5-expected_elements5]",
                "result": "passed",
                "test_implementation": "    def test___neg__(self, operand, expected, expected_elements):\n        received = -operand\n\n        assert expected == received\n        assert received.elements == expected_elements"
            },
            "tests/units/test_lib.py::TestMediant::test_mediant__invalid_dir_or_order__value_error_raised[rational14-rational24-not left-0]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_mediant__invalid_dir_or_order__value_error_raised[rational14-rational24-not left-0]",
                "result": "passed",
                "test_implementation": "\tdef test_mediant__invalid_dir_or_order__value_error_raised(self, rational1, rational2, dir, k):\n\t\twith pytest.raises(ValueError):\n\t\t\tmediant(rational1, rational2, dir=dir, k=k)"
            },
            "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements14]": {
                "testid": "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised[invalid_elements14]",
                "result": "passed",
                "test_implementation": "\tdef test_convergents__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tlist(convergents(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[3/2-expected5]": {
                "testid": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[3/2-expected5]",
                "result": "passed",
                "test_implementation": "\tdef test_continued_fraction_real__valid_inputs__correct_elements_generated(self, x, expected):\n\n\t\tassert tuple(continued_fraction_real(x)) == expected"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements2-expected_remainders2]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements2-expected_remainders2]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__valid_elements__correct_remainders_generated(self, in_elements, expected_remainders):\n\t\tassert tuple(remainders(*in_elements)) == tuple(expected_remainders)"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[3-elements8-expected_remainder8]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[3-elements8-expected_remainder8]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__valid_elements__correct_remainder_returned(self, k, elements, expected_remainder):\n\t\n\t\tassert remainder(k, *elements) == expected_remainder"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements14]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised[invalid_elements14]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__invalid_elements__value_error_raised(self, invalid_elements):\n\t\twith pytest.raises(ValueError):\n\t\t\ttuple(remainders(*invalid_elements))"
            },
            "tests/units/test_lib.py::TestMediant::test_mediant__invalid_dir_or_order__value_error_raised[rational10-rational20-left-0]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_mediant__invalid_dir_or_order__value_error_raised[rational10-rational20-left-0]",
                "result": "passed",
                "test_implementation": "\tdef test_mediant__invalid_dir_or_order__value_error_raised(self, rational1, rational2, dir, k):\n\t\twith pytest.raises(ValueError):\n\t\t\tmediant(rational1, rational2, dir=dir, k=k)"
            },
            "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational10-rational20-right-1-expected_mediant0]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational10-rational20-right-1-expected_mediant0]",
                "result": "passed",
                "test_implementation": "\tdef test_right_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, dir_, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir=dir_, k=k) == expected_mediant"
            },
            "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements6-expected_remainders6]": {
                "testid": "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements6-expected_remainders6]",
                "result": "passed",
                "test_implementation": "\tdef test_remainders__valid_elements__correct_remainders_generated(self, in_elements, expected_remainders):\n\t\tassert tuple(remainders(*in_elements)) == tuple(expected_remainders)"
            },
            "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational114-rational214-2-expected_mediant14]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational114-rational214-2-expected_mediant14]",
                "result": "passed",
                "test_implementation": "\tdef test_left_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir='left', k=k) == expected_mediant"
            },
            "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational110-rational210-1-expected_mediant10]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational110-rational210-1-expected_mediant10]",
                "result": "passed",
                "test_implementation": "\tdef test_left_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir='left', k=k) == expected_mediant"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[5-expected_coprime_integers4]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[5-expected_coprime_integers4]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__default_start_and_stop_values(self, n, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[1-expected_coprime_integers0]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[1-expected_coprime_integers0]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__default_start_and_stop_values(self, n, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n)\n\n        assert received == expected"
            },
            "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational12-rational22-3-expected_mediant2]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational12-rational22-3-expected_mediant2]",
                "result": "passed",
                "test_implementation": "\tdef test_left_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir='left', k=k) == expected_mediant"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[3-elements12-expected_remainder12]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[3-elements12-expected_remainder12]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__valid_elements__correct_remainder_returned(self, k, elements, expected_remainder):\n\t\n\t\tassert remainder(k, *elements) == expected_remainder"
            },
            "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational18-rational28-right-1-expected_mediant8]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational18-rational28-right-1-expected_mediant8]",
                "result": "passed",
                "test_implementation": "\tdef test_right_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, dir_, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir=dir_, k=k) == expected_mediant"
            },
            "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[1-elements6]": {
                "testid": "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised[1-elements6]",
                "result": "passed",
                "test_implementation": "\tdef test_remainder__invalid_elements__value_error_raised(self, k, elements):\n\t\twith pytest.raises(ValueError):\n\t\t\tremainder(k, *elements)"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[2-1-2-expected_coprime_integers2]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[2-1-2-expected_coprime_integers2]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational16-rational26-1-expected_mediant6]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational16-rational26-1-expected_mediant6]",
                "result": "passed",
                "test_implementation": "\tdef test_left_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir='left', k=k) == expected_mediant"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[9-expected_coprime_integers8]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[9-expected_coprime_integers8]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__default_start_and_stop_values(self, n, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__invalid_args__raises_value_error[-1-1-2]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__invalid_args__raises_value_error[-1-1-2]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__invalid_args__raises_value_error(self, n, start, stop):\n        with pytest.raises(ValueError):\n            coprime_integers(n, start=start, stop=stop)"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[3-2-3-expected_coprime_integers6]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[3-2-3-expected_coprime_integers6]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-1-None-expected_coprime_integers30]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-1-None-expected_coprime_integers30]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational14-rational24-right-1-expected_mediant4]": {
                "testid": "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational14-rational24-right-1-expected_mediant4]",
                "result": "passed",
                "test_implementation": "\tdef test_right_mediant__two_ordered_rationals__correct_mediant_returned(self, rational1, rational2, dir_, k, expected_mediant):\n\t\n\t\tassert mediant(rational1, rational2, dir=dir_, k=k) == expected_mediant"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-2-5-expected_coprime_integers18]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-2-5-expected_coprime_integers18]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-2-None-expected_coprime_integers22]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-2-None-expected_coprime_integers22]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-1-None-expected_coprime_integers42]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-1-None-expected_coprime_integers42]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-1-6-expected_coprime_integers26]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[6-1-6-expected_coprime_integers26]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-5-None-expected_coprime_integers34]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-5-None-expected_coprime_integers34]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-5-None-expected_coprime_integers46]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-5-None-expected_coprime_integers46]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[4-1-4-expected_coprime_integers10]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[4-1-4-expected_coprime_integers10]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-2-6-expected_coprime_integers38]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[7-2-6-expected_coprime_integers38]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-2-8-expected_coprime_integers50]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-2-8-expected_coprime_integers50]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-2-None-expected_coprime_integers14]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[5-2-None-expected_coprime_integers14]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-2-4-expected_coprime_integers54]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[8-2-4-expected_coprime_integers54]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-3-None-expected_coprime_integers58]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-3-None-expected_coprime_integers58]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-4-expected_coprime_integers70]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-4-expected_coprime_integers70]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-8-expected_coprime_integers66]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-2-8-expected_coprime_integers66]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-7-None-expected_coprime_integers62]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[9-7-None-expected_coprime_integers62]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search[5-expected_pairs4]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search[5-expected_pairs4]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree_search(self, n, expected_pairs):\n        expected = expected_pairs\n\n        received = list(KSRMTree().search(n))\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-4-None-expected_coprime_integers75]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-4-None-expected_coprime_integers75]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence[3-expected_sequence2]": {
                "testid": "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence[3-expected_sequence2]",
                "result": "passed",
                "test_implementation": "    def test_farey_sequence(self, n, expected_sequence):\n        expected = tuple(expected_sequence)\n\n        received = farey_sequence(n)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search__invalid_args__raises_value_error[n3]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search__invalid_args__raises_value_error[n3]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree_search__invalid_args__raises_value_error(self, n):\n        with pytest.raises(ValueError):\n            list(KSRMTree().search(n))"
            },
            "tests/units/test_utils.py::TestNamedCallableProxy::test_NamedCallableProxy__creation_and_initialisation[<lambda>-x |--> x^2-expected_callable_proxy0]": {
                "testid": "tests/units/test_utils.py::TestNamedCallableProxy::test_NamedCallableProxy__creation_and_initialisation[<lambda>-x |--> x^2-expected_callable_proxy0]",
                "result": "passed",
                "test_implementation": "\tdef test_NamedCallableProxy__creation_and_initialisation(\n\t\tself,\n\t\tcallable_,\n\t\tname,\n\t\texpected_callable_proxy\n\t):\n\t\texpected = expected_callable_proxy\n\n\t\t# The received ``NamedCallableProxy`` object\n\t\treceived = NamedCallableProxy(callable_, name=name)\n\n\t\t# Compare the received and expected objects\n\t\tassert received == expected\n\n\t\t# Compare the names\n\t\tassert received._name == expected._name\n\n\t\t# Assert the ``__repr__`` value - comparison with ``expected`` will\n\t\t# not work as it is a different object in memory compared to\n\t\t# ``received``\n\t\tassert received.__repr__()\n\n\t\t# Compare the outputs for ``__call__``\n\t\tassert received(1) == expected(1) == 1\n\t\tassert received(2) == expected(2) == 4\n\t\tassert received(3) == expected(3) == 9"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-9-None-expected_coprime_integers80]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values[10-9-None-expected_coprime_integers80]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__custom_start_and_stop_values(self, n, start, stop, expected_coprime_integers):\n        expected = expected_coprime_integers\n\n        received = coprime_integers(n, start=start, stop=stop)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__backtrack[5-visited1-expected_backtracked_tuple1]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__backtrack[5-visited1-expected_backtracked_tuple1]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree__backtrack(self, n, visited, expected_backtracked_tuple):\n        expected = expected_backtracked_tuple\n\n        received = KSRMTree()._backtrack(n, visited)\n\n        assert received == expected"
            },
            "tests/units/test_utils.py::TestNamedCallableProxy::test_NamedCallableProxy__creation_and_initialisation[<lambda>-None-expected_callable_proxy1]": {
                "testid": "tests/units/test_utils.py::TestNamedCallableProxy::test_NamedCallableProxy__creation_and_initialisation[<lambda>-None-expected_callable_proxy1]",
                "result": "passed",
                "test_implementation": "\tdef test_NamedCallableProxy__creation_and_initialisation(\n\t\tself,\n\t\tcallable_,\n\t\tname,\n\t\texpected_callable_proxy\n\t):\n\t\texpected = expected_callable_proxy\n\n\t\t# The received ``NamedCallableProxy`` object\n\t\treceived = NamedCallableProxy(callable_, name=name)\n\n\t\t# Compare the received and expected objects\n\t\tassert received == expected\n\n\t\t# Compare the names\n\t\tassert received._name == expected._name\n\n\t\t# Assert the ``__repr__`` value - comparison with ``expected`` will\n\t\t# not work as it is a different object in memory compared to\n\t\t# ``received``\n\t\tassert received.__repr__()\n\n\t\t# Compare the outputs for ``__call__``\n\t\tassert received(1) == expected(1) == 1\n\t\tassert received(2) == expected(2) == 4\n\t\tassert received(3) == expected(3) == 9"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[99-expected_totient_value11]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[99-expected_totient_value11]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[1000000-expected_totient_value24]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[1000000-expected_totient_value24]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[999999-expected_totient_value23]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[999999-expected_totient_value23]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[100000-expected_totient_value21]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[100000-expected_totient_value21]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence__invalid_args__raises_value_error[n1]": {
                "testid": "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence__invalid_args__raises_value_error[n1]",
                "result": "passed",
                "test_implementation": "    def test_farey_sequence__invalid_args__raises_value_error(self, n):\n        with pytest.raises(ValueError):\n            farey_sequence(n)"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__backtrack[3-visited0-expected_backtracked_tuple0]": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__backtrack[3-visited0-expected_backtracked_tuple0]",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree__backtrack(self, n, visited, expected_backtracked_tuple):\n        expected = expected_backtracked_tuple\n\n        received = KSRMTree()._backtrack(n, visited)\n\n        assert received == expected"
            },
            "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence__invalid_args__raises_value_error[n0]": {
                "testid": "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence__invalid_args__raises_value_error[n0]",
                "result": "passed",
                "test_implementation": "    def test_farey_sequence__invalid_args__raises_value_error(self, n):\n        with pytest.raises(ValueError):\n            farey_sequence(n)"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[4]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[4]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs__verify_against_summatory_totient_value(self, n):\n        assert len(coprime_pairs(n)) == sum(map(sympy.totient, range(1, n + 1)))"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[9999999-expected_totient_value26]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[9999999-expected_totient_value26]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[1000001-expected_totient_value25]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[1000001-expected_totient_value25]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[1001]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[1001]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs__verify_against_summatory_totient_value(self, n):\n        assert len(coprime_pairs(n)) == sum(map(sympy.totient, range(1, n + 1)))"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[99999-expected_totient_value20]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[99999-expected_totient_value20]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[11-expected_totient_value10]": {
                "testid": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value[11-expected_totient_value10]",
                "result": "passed",
                "test_implementation": "    def test_coprime_integers__verify_against_totient_value(self, n, expected_totient_value):\n        expected = expected_totient_value\n\n        received = coprime_integers(n)\n\n        assert len(received) == expected"
            },
            "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[1000]": {
                "testid": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value[1000]",
                "result": "passed",
                "test_implementation": "    def test_coprime_pairs__verify_against_summatory_totient_value(self, n):\n        assert len(coprime_pairs(n)) == sum(map(sympy.totient, range(1, n + 1)))"
            },
            "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__creation_and_initialisation": {
                "testid": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__creation_and_initialisation",
                "result": "passed",
                "test_implementation": "    def test_KSRMTree__creation_and_initialisation(self):\n        tree = KSRMTree()\n\n        assert tree.roots == ((2, 1), (3, 1))\n\n        assert tree.branches == (\n            NamedCallableProxy(lambda x, y: (2 * x - y, x), name=\"KSRM tree branch #1: (x, y) |--> (2x - y, x)\"),\n            NamedCallableProxy(lambda x, y: (2 * x + y, x), name=\"KSRM tree branch #2: (x, y) |--> (2x + y, x)\"),\n            NamedCallableProxy(lambda x, y: (x + 2 * y, y), name=\"KSRM tree branch #3: (x, y) |--> (x + 2y, y)\")\n        )"
            }
        },
        "SRS_document": "**Software Requirements Specification: ContinuedFractions Library**\n\n**1. Introduction**\n\n**1.1 Purpose**\nThis Software Requirements Specification (SRS) document defines the functional and non-functional requirements for the `continuedfractions` Python library. The primary purpose of this document is to serve as a definitive guide for software developers who will be assessed on their ability to implement the library based solely on this SRS and a subset of provided test cases. The implementation's success will be measured against a full suite of original test cases (public and private). Therefore, this SRS aims for exceptional clarity, functional comprehensiveness, and an appropriate level of abstraction, focusing on *what* the system must do rather than *how* it is implemented.\n\n**1.2 Scope**\nThe `continuedfractions` library provides tools for working with finite, simple continued fractions as Python objects. It allows users to:\n*   Create continued fraction representations from various numeric types (integers, rationals, floats, decimals, strings).\n*   Convert continued fraction element sequences back to rational numbers.\n*   Access properties of continued fractions such as their elements, order, convergents, and remainders.\n*   Perform arithmetic operations on continued fraction objects.\n*   Generate number theoretic sequences related to continued fractions and coprime numbers, such as Farey sequences and sequences of coprime pairs.\n\nThis SRS covers all user-observable functional capabilities of the library. It does not prescribe internal design, specific algorithms (beyond their mathematical definition if its an external constraint), class names (unless part of a public API), or internal data structures, allowing developers to make their own implementation choices.\n\n**1.3 Definitions, Acronyms, and Abbreviations**\n*   **CF:** Continued Fraction\n*   **SRS:** Software Requirements Specification\n*   **Fraction:** Refers to Python's `fractions.Fraction` class.\n*   **Decimal:** Refers to Python's `decimal.Decimal` class.\n*   **Simple Continued Fraction:** A continued fraction of the form  `a_0 + 1/(a_1 + 1/(a_2 + ...)))` where `a_0` is an integer and `a_i` (for `i >= 1`) are positive integers. Often denoted as `[a_0; a_1, a_2, ...]</code>.\n*   **Elements (or Coefficients):** The terms `a_0, a_1, a_2, ...` in a continued fraction.\n*   **Order:** For a finite simple continued fraction `[a_0; a_1, ..., a_n]`, the order is `n`.\n*   **Convergent:** The rational number obtained by truncating a continued fraction at a certain element. The k-th convergent `C_k` is `[a_0; a_1, ..., a_k]`.\n*   **Remainder:** For a continued fraction `[a_0; a_1, ..., a_n]`, the k-th remainder `R_k` is `[a_k; a_{k+1}, ..., a_n]`.\n*   **Mediant:** The mediant of `a/b` and `c/d` is `(a+c)/(b+d)`. Left/Right mediants involve a factor `k`.\n*   **Coprime Integers:** Two integers are coprime if their greatest common divisor (GCD) is 1.\n*   **Farey Sequence:** A sequence of completely reduced fractions between 0 and 1, which when arranged in order of increasing size have denominators less than or equal to `n`.\n*   **KSRM Tree:** Kanga-Saunders-Randall-Mitchell tree, a ternary tree structure used to generate pairs of coprime integers.\n\n**1.4 References**\n*   Original Source Code (`continuedfractions` Python library)\n*   Original Pytest Test Suite (`tests/units/`)\n*   Python `fractions` module documentation\n*   Python `decimal` module documentation\n*   Standard mathematical texts on Number Theory and Continued Fractions.\n\n**1.5 Overview**\nThis SRS is organized into three main sections:\n*   **Section 1 (Introduction):** Provides purpose, scope, definitions, references, and an overview of the document.\n*   **Section 2 (Overall Description):** Describes the general factors affecting the product and its requirements, such as product perspective, functions, and constraints.\n*   **Section 3 (Specific Requirements):** Details all functional and non-functional requirements. Functional requirements are grouped by major capability.\n\n**2. Overall Description**\n\n**2.1 Product Perspective**\nThe `continuedfractions` library is a Python package designed to extend the capabilities of Python's standard `fractions` library. It provides a `ContinuedFraction` object, which inherits from `fractions.Fraction`, and associated functions to work with the mathematical concept of simple continued fractions. It is intended for users interested in number theory, rational approximations, and exploring properties of continued fractions in an object-oriented manner.\n\n**2.2 Product Functions (Summary)**\nThe `continuedfractions` library will provide the following key functionalities:\n*   Conversion of rational numbers, real numbers (including floats and Decimals), and string representations of numbers into their finite simple continued fraction elements.\n*   Conversion of a sequence of continued fraction elements back into a rational number.\n*   An object-oriented representation of a continued fraction (`ContinuedFraction` class) supporting:\n    *   Access to its elements, order, and other properties (e.g., Khinchin mean).\n    *   Calculation of its convergents, semiconvergents, and remainders.\n    *   In-place modification (extension and truncation of elements).\n    *   Standard arithmetic operations (addition, subtraction, multiplication, division, negation, etc.), yielding `ContinuedFraction` objects.\n    *   Mediant calculations with other rational numbers.\n    *   Conversion to `float` and `Decimal`.\n*   Generation of number theoretic sequences:\n    *   Integers coprime to a given integer `n`.\n    *   Pairs of coprime integers `(a, b)` up to a limit `n`.\n    *   Farey sequences of a given order `n`.\n*   Utility features, such as a named callable proxy.\n\n**2.3 User Characteristics**\nThe intended users are:\n*   Software developers needing to work with continued fractions.\n*   Students and educators learning or teaching number theory.\n*   Researchers and hobbyists exploring mathematical concepts.\nUsers are expected to have a basic understanding of Python programming and familiarity with fundamental number theory concepts, particularly continued fractions.\n\n**2.4 Constraints**\n*   The software must be implemented in Python.\n*   The software must be compatible with the Python `fractions.Fraction` and `decimal.Decimal` types where specified.\n*   The system should correctly handle finite simple continued fractions. Infinite continued fractions are outside the scope.\n*   Numerical precision for `Decimal` related operations should be consistent with Python's `decimal` module behavior.\n\n**2.5 Assumptions and Dependencies**\n*   The system will run in a standard Python environment.\n*   Mathematical definitions (e.g., simple continued fraction, convergent, mediant, coprime) are as per standard number theory literature.\n*   Input values will adhere to specified types unless otherwise noted for validation requirements.\n\n**3. Specific Requirements**\n\n**3.1 Functional Requirements**\n\n**3.1.1 Continued Fraction Element Generation**\n\n*   **FR-001:** The system shall convert a `fractions.Fraction` object into its unique sequence of integer elements representing a simple continued fraction. The last element `a_n` must be `> 1` if the order `n > 0`.\n\n*   **FR-002:** The system shall convert an integer input into a sequence containing that single integer as its continued fraction element.\n\n*   **FR-003:** The system shall convert a floating-point number (`float`) input into a finite sequence of integer elements representing its simple continued fraction. The conversion shall be based on the exact rational value represented by the `float` (as obtainable via `Decimal.from_float().as_integer_ratio()`).\n\n*   **FR-004:** The system shall convert a `decimal.Decimal` input into a finite sequence of integer elements representing its simple continued fraction.\n\n*   **FR-005:** The system shall convert a string representation of an integer or decimal number (e.g., \"5000\", \"-5000\", \"1.5\", \"3.245\") into a finite sequence of integer elements representing its simple continued fraction. The last element `a_n` must be `> 1` if the order `n > 0`.\n\n*   **FR-006:** The system shall convert a string representation of a rational number (e.g., \"3/2\", \"-649/200\") into its unique sequence of integer elements representing a simple continued fraction. The last element `a_n` must be `> 1` if the order `n > 0`.\n\n*   **FR-007:** The system shall correctly generate continued fraction elements for negative rational and real numbers, adhering to the canonical form for negative continued fractions (e.g., `[-a_0; a_1, ...]` may transform to `[-(a_0+1); 1, a_1-1, ...]` or similar based on `a_1`).\n\n**3.1.2 Rational Number from Elements**\n\n*   **FR-010:** The system shall convert a sequence of integer continued fraction elements into a `fractions.Fraction` object representing the rational number.\n\n*   **FR-011:** The system shall validate that all input elements for `fraction_from_elements` are integers. If not, a `ValueError` shall be raised.\n\n**3.1.3 ContinuedFraction Object**\n\n**3.1.3.1 Initialization and Core Properties**\n\n*   **FR-020:** The system shall allow creation of a `ContinuedFraction` object from inputs valid for `fractions.Fraction` (e.g., two integers, a single rational number, a float, a `Decimal`, a numeric string, or another `ContinuedFraction` instance).\n\n*   **FR-021:** Upon creation, a `ContinuedFraction` object shall internally compute and store its unique sequence of simple continued fraction elements (where the last element `a_n > 1` if order `n > 0`).\n\n*   **FR-022:** The system shall allow creation of a `ContinuedFraction` object directly from a sequence of integer elements using a class method (`from_elements`).\n\n*   **FR-023:** When creating a `ContinuedFraction` using `from_elements`, the system shall ensure the stored element sequence is canonical (if the input sequence ends in `1` and has length > 1, it should be converted, e.g., `[a_0; ..., x, 1]` becomes `[a_0; ..., x+1]`).\n\n*   **FR-024:** The system shall validate elements provided to `ContinuedFraction.from_elements`: all elements must be integers, and all elements after the first (tail elements) must be positive. If validation fails, a `ValueError` shall be raised.\n\n*   **FR-025:** A `ContinuedFraction` object shall provide read-only access to its sequence of (integer) elements.\n    *   **Property Name:** `elements`\n\n*   **FR-026:** A `ContinuedFraction` object shall provide read-only access to its order (defined as the number of its elements minus 1).\n    *   **Property Name:** `order`\n\n*   **FR-027:** A `ContinuedFraction` object shall provide access to a counter object (`collections.Counter`) detailing the frequency of each of its elements.\n    *   **Property Name:** `counter`\n\n*   **FR-028:** A `ContinuedFraction` object shall provide its Khinchin mean, calculated as the geometric mean of its tail elements (elements from `a_1` onwards).\n    *   **Property Name:** `khinchin_mean`\n\n*   **FR-029:** If a `ContinuedFraction` has an order of 0 (i.e., only one element `a_0`), its Khinchin mean shall be `None`.\n    *   **Property Name:** `khinchin_mean`\n\n**3.1.3.2 Convergents and Remainders**\n\n*   **FR-030:** A `ContinuedFraction` object shall provide a method to calculate its k-th convergent, returning a new `ContinuedFraction` object.\n    *   **Method Signature (conceptual):** `convergent(k: int) -> ContinuedFraction`\n\n*   **FR-031:** The `convergent(k)` method shall validate `k` to be a non-negative integer not exceeding the order of the `ContinuedFraction`. If invalid, a `ValueError` (or compatible error) should occur.\n    *   **Note:** This is implicitly tested by the underlying `lib.convergent` call, which `ContinuedFraction.convergent` wraps.\n\n*   **FR-032:** A `ContinuedFraction` object shall provide a property to generate all its convergents as (index, `ContinuedFraction` object) pairs, in increasing order of index.\n    *   **Property Name:** `convergents`\n\n*   **FR-033:** A `ContinuedFraction` object shall provide a property to generate its even-indexed convergents as (index, `ContinuedFraction` object) pairs.\n    *   **Property Name:** `even_convergents`\n\n*   **FR-034:** A `ContinuedFraction` object shall provide a property to generate its odd-indexed convergents as (index, `ContinuedFraction` object) pairs.\n    *   **Property Name:** `odd_convergents`\n\n*   **FR-035:** A `ContinuedFraction` object shall provide a method to calculate its m-th semiconvergent between the (k-1)-th and k-th convergents, returning a `ContinuedFraction` object.\n    *   **Method Signature (conceptual):** `semiconvergent(k: int, m: int) -> ContinuedFraction`\n\n*   **FR-036:** The `semiconvergent(k, m)` method shall validate that `k` is an integer `1 <= k <= order` and `m` is a positive integer. If not, a `ValueError` shall be raised.\n\n*   **FR-037:** A `ContinuedFraction` object shall provide a method to calculate its k-th remainder, returning a new `ContinuedFraction` object representing `[a_k; a_{k+1}, ..., a_n]`.\n    *   **Method Signature (conceptual):** `remainder(k: int) -> ContinuedFraction`\n\n*   **FR-038:** The `remainder(k)` method shall validate `k` to be a non-negative integer not exceeding the order of the `ContinuedFraction`. If invalid, a `ValueError` (or compatible error) should occur.\n    *   **Note:** This is implicitly tested by the underlying `lib.remainder` call.\n\n*   **FR-039:** A `ContinuedFraction` object shall provide a property to generate all its remainders as (index, `ContinuedFraction` object) pairs, in descending order of index (from `R_n` down to `R_0`).\n    *   **Property Name:** `remainders`\n\n**3.1.3.3 Element Manipulation**\n\n*   **FR-040:** A `ContinuedFraction` object shall provide a method to extend its element sequence in-place by appending new elements to its tail. The object's rational value and element list must be updated accordingly.\n    *   **Method Signature (conceptual):** `extend(*new_elements: int) -> None`\n\n*   **FR-041:** The `extend` method shall validate that `new_elements` are all positive integers and that at least one new element is provided. If validation fails, a `ValueError` shall be raised.\n\n*   **FR-042:** After `extend`, the `ContinuedFraction`'s element sequence must remain canonical (e.g. last element > 1 if order > 0).\n\n*   **FR-043:** A `ContinuedFraction` object shall provide a method to truncate its element sequence in-place by removing a specified sequence of elements from its tail. The object's rational value and element list must be updated accordingly.\n    *   **Method Signature (conceptual):** `truncate(*tail_elements: int) -> None`\n\n*   **FR-044:** The `truncate` method shall validate that `tail_elements` are provided, are positive integers, and exactly match a terminal segment of the current `ContinuedFraction`'s tail elements. The head element cannot be part of `tail_elements`. If validation fails, a `ValueError` shall be raised.\n\n*   **FR-045:** After `truncate`, if the resulting `ContinuedFraction`'s element sequence is longer than one element and its new last element is 1, it must be made canonical (e.g. `[a_0; ..., x, 1]` becomes `[a_0; ..., x+1]`).\n\n**3.1.3.4 Mediant Operations**\n\n*   **FR-050:** A `ContinuedFraction` object shall provide a method to calculate its k-th left mediant with another `Fraction` (or `ContinuedFraction`), returning a `ContinuedFraction` object.\n    *   **Method Signature (conceptual):** `left_mediant(other: Fraction, k: int = 1) -> ContinuedFraction`\n\n*   **FR-051:** The `left_mediant` method shall require `k` to be a positive integer. An invalid `k` (or other invalid parameters for the underlying mediant function) should result in a `ValueError`.\n\n*   **FR-052:** A `ContinuedFraction` object shall provide a method to calculate its k-th right mediant with another `Fraction` (or `ContinuedFraction`), returning a `ContinuedFraction` object.\n    *   **Method Signature (conceptual):** `right_mediant(other: Fraction, k: int = 1) -> ContinuedFraction`\n\n*   **FR-053:** The `right_mediant` method shall require `k` to be a positive integer. An invalid `k` (or other invalid parameters for the underlying mediant function) should result in a `ValueError`.\n\n*   **FR-054:** A `ContinuedFraction` object shall provide a method to calculate its simple mediant (k=1 mediant) with another `Fraction` (or `ContinuedFraction`), returning a `ContinuedFraction` object.\n    *   **Method Signature (conceptual):** `mediant(other: Fraction) -> ContinuedFraction`\n\n**3.1.3.5 Arithmetic Operations**\nFor FR-060 to FR-069, all operations involving another operand assume the other operand is a type compatible with `fractions.Fraction` arithmetic (e.g., `int`, `fractions.Fraction`, `ContinuedFraction`). The result of these operations must be a `ContinuedFraction` object.\n\n*   **FR-060:** The system shall support addition of a `ContinuedFraction` object with a compatible operand.\n\n*   **FR-061:** The system shall support subtraction of a compatible operand from a `ContinuedFraction` object, and subtraction of a `ContinuedFraction` object from a compatible operand.\n\n*   **FR-062:** The system shall support multiplication of a `ContinuedFraction` object by a compatible operand.\n\n*   **FR-063:** The system shall support true division of a `ContinuedFraction` object by a compatible operand, and true division of a compatible operand by a `ContinuedFraction` object.\n\n*   **FR-064:** The system shall support floor division of a `ContinuedFraction` object by a compatible operand, and floor division of a compatible operand by a `ContinuedFraction` object.\n\n*   **FR-065:** The system shall support the `divmod` operation for a `ContinuedFraction` object with a compatible operand, returning a pair of `ContinuedFraction` objects (quotient, remainder).\n\n*   **FR-066:** The system shall support exponentiation of a `ContinuedFraction` object to a compatible power.\n\n*   **FR-067:** The system shall support exponentiation of a compatible base to a `ContinuedFraction` power (if meaningful and supported by `fractions.Fraction` for the base type).\n\n*   **FR-068:** The system shall support unary positive operation on a `ContinuedFraction` object.\n\n*   **FR-069:** The system shall support unary negation of a `ContinuedFraction` object. The negated `ContinuedFraction` object must represent the correct negative rational value and its elements must be the canonical simple continued fraction elements for that negative value.\n\n*   **FR-070:** The system shall support the absolute value operation on a `ContinuedFraction` object.\n\n**3.1.3.6 Type Conversions**\n\n*   **FR-080:** A `ContinuedFraction` object shall be convertible to a standard Python `float`.\n    *   **Method Name:** `as_float`\n\n*   **FR-081:** A `ContinuedFraction` object shall be convertible to a Python `Decimal` object, maintaining precision as appropriate for `Decimal` arithmetic.\n    *   **Method Name:** `as_decimal`\n\n**3.1.3.7 Comparison and Hashing**\n\n*   **FR-090:** `ContinuedFraction` objects shall be comparable for equality (`==`).\n    *   If both operands are `ContinuedFraction` objects, equality is determined by their respective element sequences.\n    *   If one operand is a `ContinuedFraction` and the other is not, equality comparison shall fall back to the behavior of `fractions.Fraction`.\n\n*   **FR-091:** `ContinuedFraction` objects shall be hashable. The hash value shall be based on their element sequences.\n\n**3.1.4 Standalone Convergent, Remainder, and Mediant Functions (from `lib.py`)**\nThese functions operate on sequences of integer elements or `fractions.Fraction` objects and return `fractions.Fraction` objects.\n\n*   **FR-100:** The system shall provide a function to calculate the k-th convergent from a sequence of integer elements, returning a `fractions.Fraction`.\n    *   **Function Signature (conceptual):** `convergent(k: int, *elements: int) -> Fraction`\n\n*   **FR-101:** The `convergent(k, *elements)` function shall validate that `k` is a non-negative integer not exceeding the number of tail elements, all elements are integers, and all tail elements (`a_i` for `i >= 1`) are positive. If validation fails, a `ValueError` shall be raised.\n\n*   **FR-102:** The system shall provide a function to generate all convergents from a sequence of integer elements, yielding `fractions.Fraction` objects.\n    *   **Function Signature (conceptual):** `convergents(*elements: int) -> Generator[Fraction, None, None]`\n\n*   **FR-103:** The `convergents(*elements)` function shall validate that all elements are integers and all tail elements are positive. If validation fails, a `ValueError` shall be raised. Input must not be empty.\n\n*   **FR-104:** The system shall provide a function to calculate the k-th remainder from a sequence of integer elements, returning a `fractions.Fraction`.\n    *   **Function Signature (conceptual):** `remainder(k: int, *elements: int) -> Fraction`\n\n*   **FR-105:** The `remainder(k, *elements)` function shall validate that `k` is a non-negative integer not exceeding the number of tail elements, all elements are integers, and all tail elements are positive. If validation fails, a `ValueError` shall be raised.\n\n*   **FR-106:** The system shall provide a function to generate all remainders from a sequence of integer elements (in descending order of index), yielding `fractions.Fraction` objects.\n    *   **Function Signature (conceptual):** `remainders(*elements: int) -> Generator[Fraction, None, None]`\n\n*   **FR-107:** The `remainders(*elements)` function shall validate that elements are provided, all elements are integers, and all tail elements are positive. If validation fails, a `ValueError` shall be raised.\n\n*   **FR-108:** The system shall provide a function to calculate the k-th mediant of two `fractions.Fraction` objects, supporting \"left\" and \"right\" directionality.\n    *   **Function Signature (conceptual):** `mediant(r: Fraction, s: Fraction, dir: str = 'right', k: int = 1) -> Fraction`\n\n*   **FR-109:** The `mediant` function shall validate that `dir` is one of 'left' or 'right' and `k` is a positive integer. If validation fails, a `ValueError` shall be raised.\n\n**3.1.5 Number Theoretic Sequences**\n\n**3.1.5.1 Coprime Integers**\n\n*   **FR-110:** The system shall provide a function to generate a sequence of positive integers `m` that are coprime to a given positive integer `n`.\n    *   **Function Signatures (conceptual):** `coprime_integers_generator(n: int, start: int = 1, stop: int = None) -> Generator[int, None, None]`, `coprime_integers(n: int, start: int = 1, stop: int = None) -> tuple[int, ...]`\n\n*   **FR-111:** The `coprime_integers` generation shall support optional `start` and `stop` parameters to define the range `start <= m < stop` for searching coprimes `m` to `n`.\n\n*   **FR-112:** The generated sequence of coprime integers shall be in descending order.\n\n*   **FR-113:** The `coprime_integers` generation shall validate its inputs: `n` must be a positive integer. If `n > 1`, `start` must be an integer `1 <= start < n`. If `stop` is provided and `n > 1`, `stop` must be an integer `start < stop <= n`. If validation fails, a `ValueError` shall be raised.\n\n*   **FR-114:** For default `start` (1) and `stop` (`n`), the count of generated coprime integers for `n` must be equal to Euler's totient function `phi(n)`.\n\n**3.1.5.2 Coprime Pairs (leveraging KSRM concepts)**\n\n**3.1.5.2.1 KSRMTree Public Interface**\n*   **FR-120:** The system shall provide a KSRMTree component representing the Kanga-Saunders-Randall-Mitchell trees for generating coprime pairs.\n\n*   **FR-121:** The KSRMTree component shall expose its root nodes, which must be `((2, 1), (3, 1))`.\n    *   **Property Name:** `KSRMTree().roots`\n\n*   **FR-122:** The KSRMTree component shall expose its three branch generation functions, corresponding to the transformations: `(x,y) -> (2x-y, x)`, `(x,y) -> (2x+y, x)`, and `(x,y) -> (x+2y, y)`. These functions shall be callable.\n    *   **Property Name:** `KSRMTree().branches`\n\n*   **FR-123:** The KSRMTree component shall provide a search method (`search_root`) to find all coprime pairs `(a,b)` with `1 <= b < a <= n`, starting from a given KSRMTree root node.\n    *   **Method Signature (conceptual):** `KSRMTree().search_root(n: int, root: tuple[int, int]) -> Generator[tuple[int, int], None, None]`\n\n*   **FR-124:** The `KSRMTree().search_root` method shall validate that `n` is an integer `>= 2` and the root is a coprime pair. If `n` is less than the first component of the root, it should yield no pairs. Invalid inputs should raise a `ValueError`.\n\n*   **FR-125:** The KSRMTree component shall provide a general search method (`search`) to find all coprime pairs `(a,b)` with `1 <= b < a <= n` (excluding `(n,m)` pairs if `a=n`). This method utilizes searches from its canonical roots. It must also include `(1,1)`.\n    *   **Method Signature (conceptual):** `KSRMTree().search(n: int) -> Generator[tuple[int, int], None, None]`\n\n*   **FR-126:** The `KSRMTree().search` method shall validate that `n` is a positive integer. If not, a `ValueError` shall be raised.\n\n*   **FR-127:** The coprime pairs generated by `KSRMTree().search_root` and `KSRMTree().search` methods shall follow a specific, deterministic order as defined by the KSRM tree traversal logic.\n\n**3.1.5.2.2 Coprime Pair Generation**\n*   **FR-130:** The system shall provide a function to generate a sequence of all pairs of positive coprime integers `(a, b)` such that `1 <= b < a <= n`. For `n=1`, the sequence must contain `(1,1)`.\n    *   **Function Signatures (conceptual):** `coprime_pairs_generator(n: int) -> Generator[tuple[int,int], None, None]`, `coprime_pairs(n: int) -> tuple[tuple[int,int], ...]`\n\n*   **FR-131:** The `coprime_pairs` generation shall validate that `n` is a positive integer. If not, a `ValueError` shall be raised.\n\n*   **FR-132:** The sequence of coprime pairs returned by `coprime_pairs(n)` must be in a specific, deterministic order.\n\n*   **FR-133:** The total number of coprime pairs `(a,b)` where `1 <= b < a <= n` (plus the pair `(1,1)` if `n>=1`) generated by `coprime_pairs(n)` must be equal to `1 + sum(phi(k) for k in 2..n)` where `phi` is Euler's totient function. This is equivalent to `sum(phi(k) for k in 1..n)`.\n\n**3.1.5.3 Farey Sequences**\n\n*   **FR-140:** The system shall provide a function to generate the Farey sequence of a given order `n`.\n    *   **Function Signatures (conceptual):** `farey_sequence_generator(n: int) -> Generator[ContinuedFraction, None, None]`, `farey_sequence(n: int) -> tuple[ContinuedFraction, ...]`\n\n*   **FR-141:** Elements of the generated Farey sequence must be `ContinuedFraction` objects.\n\n*   **FR-142:** The Farey sequence must consist of irreducible fractions `h/k` where `0 <= h <= k <= n` and `gcd(h,k)=1`.\n\n*   **FR-143:** The Farey sequence must be sorted in ascending order of value.\n\n*   **FR-144:** The Farey sequence must start with `ContinuedFraction(0,1)` and end with `ContinuedFraction(1,1)`.\n\n*   **FR-145:** The Farey sequence generation shall validate that `n` is a positive integer. If not, a `ValueError` shall be raised.\n\n**3.1.6 Utilities**\n\n**3.1.6.1 NamedCallableProxy**\n*   **FR-150:** The system shall provide a `NamedCallableProxy` class that wraps a callable object, allowing it to be associated with a user-defined name.\n\n*   **FR-151:** A `NamedCallableProxy` instance must itself be callable, and calling it must execute the wrapped callable with the provided arguments.\n\n*   **FR-152:** The string representation (`repr`) of a `NamedCallableProxy` instance shall include its user-defined name if one was provided during creation. If no name was provided, it should default to the string representation of the wrapped callable.\n\n*   **FR-153:** Two `NamedCallableProxy` instances shall compare as equal if their wrapped callables are functionally equivalent (e.g., possess identical bytecode).\n\n**3.2 Non-Functional Requirements**\nNo non-functional requirements are specified, as there are no explicit original test cases that directly validate NFRs such as performance, security, or usability benchmarks. Functional correctness and adherence to specified input/output behavior are the primary concerns.\n\n**3.3 External Interface Requirements**\n*   **EIR-001:** The system shall accept string inputs for numbers in standard decimal format (e.g., \"123.45\", \"-10\") and fraction format (e.g., \"3/2\", \"-7/5\") where specified for conversion to continued fractions.\n    *   **Reference:** FR-005, FR-006\n\n**3.4 Other Requirements**\nNone.",
        "structured_requirements": [
            {
                "requirement_id": "FR-001",
                "requirement_description": "The system shall convert a `fractions.Fraction` object into its unique sequence of integer elements representing a simple continued fraction. The last element `a_n` must be `> 1` if the order `n > 0`.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/lib.py::continued_fraction_rational",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-002",
                "requirement_description": "The system shall convert an integer input into a sequence containing that single integer as its continued fraction element.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated",
                        "description": "cases with integer inputs"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/lib.py::continued_fraction_real",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-003",
                "requirement_description": "The system shall convert a floating-point number (`float`) input into a finite sequence of integer elements representing its simple continued fraction. The conversion shall be based on the exact rational value represented by the `float` (as obtainable via `Decimal.from_float().as_integer_ratio()`).",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated",
                        "description": "cases with float inputs like `3.245`, `-649/200`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/lib.py::continued_fraction_real",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-004",
                "requirement_description": "The system shall convert a `decimal.Decimal` input into a finite sequence of integer elements representing its simple continued fraction.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated",
                        "description": "cases with `Decimal` inputs"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/lib.py::continued_fraction_real",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-005",
                "requirement_description": "The system shall convert a string representation of an integer or decimal number (e.g., \"5000\", \"-5000\", \"1.5\", \"3.245\") into a finite sequence of integer elements representing its simple continued fraction. The last element `a_n` must be `> 1` if the order `n > 0`.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated",
                        "description": "cases with string decimal/integer inputs"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/lib.py::continued_fraction_real",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-006",
                "requirement_description": "The system shall convert a string representation of a rational number (e.g., \"3/2\", \"-649/200\") into its unique sequence of integer elements representing a simple continued fraction. The last element `a_n` must be `> 1` if the order `n > 0`.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated",
                        "description": "cases with string fraction inputs"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/lib.py::continued_fraction_real",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-007",
                "requirement_description": "The system shall correctly generate continued fraction elements for negative rational and real numbers, adhering to the canonical form for negative continued fractions (e.g., `[-a_0; a_1, ...]` may transform to `[-(a_0+1); 1, a_1-1, ...]` or similar based on `a_1`).",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated",
                        "description": "e.g. `Fraction(-649, 200)`"
                    },
                    {
                        "id": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated",
                        "description": "e.g. `'-3.245'`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/lib.py::continued_fraction_rational",
                        "description": ""
                    },
                    {
                        "id": "src/continuedfractions/lib.py::continued_fraction_real",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-010",
                "requirement_description": "The system shall convert a sequence of integer continued fraction elements into a `fractions.Fraction` object representing the rational number.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/lib.py::fraction_from_elements",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-011",
                "requirement_description": "The system shall validate that all input elements for `fraction_from_elements` are integers. If not, a `ValueError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__invalid_elements__value_error_raised",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/lib.py::fraction_from_elements",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-020",
                "requirement_description": "The system shall allow creation of a `ContinuedFraction` object from inputs valid for `fractions.Fraction` (e.g., two integers, a single rational number, a float, a `Decimal`, a numeric string, or another `ContinuedFraction` instance).",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.__new__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-021",
                "requirement_description": "Upon creation, a `ContinuedFraction` object shall internally compute and store its unique sequence of simple continued fraction elements (where the last element `a_n > 1` if order `n > 0`).",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised",
                        "description": "verified by `expected_elements`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.__new__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-022",
                "requirement_description": "The system shall allow creation of a `ContinuedFraction` object directly from a sequence of integer elements using a class method (`from_elements`).",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.from_elements",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-023",
                "requirement_description": "When creating a `ContinuedFraction` using `from_elements`, the system shall ensure the stored element sequence is canonical (if the input sequence ends in `1` and has length > 1, it should be converted, e.g., `[a_0; ..., x, 1]` becomes `[a_0; ..., x+1]`).",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned",
                        "description": "e.g. `(-2, 1, 1)` becomes `ContinuedFraction(-3,2)` with elements `(-2,2)`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.from_elements",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-024",
                "requirement_description": "The system shall validate elements provided to `ContinuedFraction.from_elements`: all elements must be integers, and all elements after the first (tail elements) must be positive. If validation fails, a `ValueError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__invalid_elements__value_error_raised",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.from_elements",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-025",
                "requirement_description": "A `ContinuedFraction` object shall provide read-only access to its sequence of (integer) elements.\n    *   **Property Name:** `elements`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.elements",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-026",
                "requirement_description": "A `ContinuedFraction` object shall provide read-only access to its order (defined as the number of its elements minus 1).\n    *   **Property Name:** `order`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.order",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-027",
                "requirement_description": "A `ContinuedFraction` object shall provide access to a counter object (`collections.Counter`) detailing the frequency of each of its elements.\n    *   **Property Name:** `counter`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.counter",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-028",
                "requirement_description": "A `ContinuedFraction` object shall provide its Khinchin mean, calculated as the geometric mean of its tail elements (elements from `a_1` onwards).\n    *   **Property Name:** `khinchin_mean`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.khinchin_mean",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-029",
                "requirement_description": "If a `ContinuedFraction` has an order of 0 (i.e., only one element `a_0`), its Khinchin mean shall be `None`.\n    *   **Property Name:** `khinchin_mean`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised",
                        "description": "e.g., case #3, #10, #14"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.khinchin_mean",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-030",
                "requirement_description": "A `ContinuedFraction` object shall provide a method to calculate its k-th convergent, returning a new `ContinuedFraction` object.\n    *   **Method Signature (conceptual):** `convergent(k: int) -> ContinuedFraction`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised",
                        "description": "verified by checking against `expected_convergents`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.convergent",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-031",
                "requirement_description": "The `convergent(k)` method shall validate `k` to be a non-negative integer not exceeding the order of the `ContinuedFraction`. If invalid, a `ValueError` (or compatible error) should occur.\n    *   **Note:** This is implicitly tested by the underlying `lib.convergent` call, which `ContinuedFraction.convergent` wraps.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised",
                        "description": "for underlying logic"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.convergent",
                        "description": "relies on `src/continuedfractions/lib.py::convergent`"
                    }
                ]
            },
            {
                "requirement_id": "FR-032",
                "requirement_description": "A `ContinuedFraction` object shall provide a property to generate all its convergents as (index, `ContinuedFraction` object) pairs, in increasing order of index.\n    *   **Property Name:** `convergents`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.convergents",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-033",
                "requirement_description": "A `ContinuedFraction` object shall provide a property to generate its even-indexed convergents as (index, `ContinuedFraction` object) pairs.\n    *   **Property Name:** `even_convergents`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.even_convergents",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-034",
                "requirement_description": "A `ContinuedFraction` object shall provide a property to generate its odd-indexed convergents as (index, `ContinuedFraction` object) pairs.\n    *   **Property Name:** `odd_convergents`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.odd_convergents",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-035",
                "requirement_description": "A `ContinuedFraction` object shall provide a method to calculate its m-th semiconvergent between the (k-1)-th and k-th convergents, returning a `ContinuedFraction` object.\n    *   **Method Signature (conceptual):** `semiconvergent(k: int, m: int) -> ContinuedFraction`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.semiconvergent",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-036",
                "requirement_description": "The `semiconvergent(k, m)` method shall validate that `k` is an integer `1 <= k <= order` and `m` is a positive integer. If not, a `ValueError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__invalid_args",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.semiconvergent",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-037",
                "requirement_description": "A `ContinuedFraction` object shall provide a method to calculate its k-th remainder, returning a new `ContinuedFraction` object representing `[a_k; a_{k+1}, ..., a_n]`.\n    *   **Method Signature (conceptual):** `remainder(k: int) -> ContinuedFraction`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised",
                        "description": "verified by checking against `expected_remainders`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.remainder",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-038",
                "requirement_description": "The `remainder(k)` method shall validate `k` to be a non-negative integer not exceeding the order of the `ContinuedFraction`. If invalid, a `ValueError` (or compatible error) should occur.\n    *   **Note:** This is implicitly tested by the underlying `lib.remainder` call.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised",
                        "description": "for underlying logic"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.remainder",
                        "description": "relies on `src/continuedfractions/lib.py::remainder`"
                    }
                ]
            },
            {
                "requirement_id": "FR-039",
                "requirement_description": "A `ContinuedFraction` object shall provide a property to generate all its remainders as (index, `ContinuedFraction` object) pairs, in descending order of index (from `R_n` down to `R_0`).\n    *   **Property Name:** `remainders`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.remainders",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-040",
                "requirement_description": "A `ContinuedFraction` object shall provide a method to extend its element sequence in-place by appending new elements to its tail. The object's rational value and element list must be updated accordingly.\n    *   **Method Signature (conceptual):** `extend(*new_elements: int) -> None`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.extend",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-041",
                "requirement_description": "The `extend` method shall validate that `new_elements` are all positive integers and that at least one new element is provided. If validation fails, a `ValueError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__invalid_elements__value_error_raised",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.extend",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-042",
                "requirement_description": "After `extend`, the `ContinuedFraction`'s element sequence must remain canonical (e.g. last element > 1 if order > 0).",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.extend",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-043",
                "requirement_description": "A `ContinuedFraction` object shall provide a method to truncate its element sequence in-place by removing a specified sequence of elements from its tail. The object's rational value and element list must be updated accordingly.\n    *   **Method Signature (conceptual):** `truncate(*tail_elements: int) -> None`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.truncate",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-044",
                "requirement_description": "The `truncate` method shall validate that `tail_elements` are provided, are positive integers, and exactly match a terminal segment of the current `ContinuedFraction`'s tail elements. The head element cannot be part of `tail_elements`. If validation fails, a `ValueError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__invalid_elements__value_error_raised",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.truncate",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-045",
                "requirement_description": "After `truncate`, if the resulting `ContinuedFraction`'s element sequence is longer than one element and its new last element is 1, it must be made canonical (e.g. `[a_0; ..., x, 1]` becomes `[a_0; ..., x+1]`).",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.truncate",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-050",
                "requirement_description": "A `ContinuedFraction` object shall provide a method to calculate its k-th left mediant with another `Fraction` (or `ContinuedFraction`), returning a `ContinuedFraction` object.\n    *   **Method Signature (conceptual):** `left_mediant(other: Fraction, k: int = 1) -> ContinuedFraction`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__left_mediant__two_fractions__correct_mediant_returned",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.left_mediant",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-051",
                "requirement_description": "The `left_mediant` method shall require `k` to be a positive integer. An invalid `k` (or other invalid parameters for the underlying mediant function) should result in a `ValueError`.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestMediant::test_mediant__invalid_dir_or_order__value_error_raised",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.left_mediant",
                        "description": "relies on `src/continuedfractions/lib.py::left_mediant`"
                    }
                ]
            },
            {
                "requirement_id": "FR-052",
                "requirement_description": "A `ContinuedFraction` object shall provide a method to calculate its k-th right mediant with another `Fraction` (or `ContinuedFraction`), returning a `ContinuedFraction` object.\n    *   **Method Signature (conceptual):** `right_mediant(other: Fraction, k: int = 1) -> ContinuedFraction`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__right_mediant__two_fractions__correct_mediant_returned",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.right_mediant",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-053",
                "requirement_description": "The `right_mediant` method shall require `k` to be a positive integer. An invalid `k` (or other invalid parameters for the underlying mediant function) should result in a `ValueError`.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestMediant::test_mediant__invalid_dir_or_order__value_error_raised",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.right_mediant",
                        "description": "relies on `src/continuedfractions/lib.py::right_mediant`"
                    }
                ]
            },
            {
                "requirement_id": "FR-054",
                "requirement_description": "A `ContinuedFraction` object shall provide a method to calculate its simple mediant (k=1 mediant) with another `Fraction` (or `ContinuedFraction`), returning a `ContinuedFraction` object.\n    *   **Method Signature (conceptual):** `mediant(other: Fraction) -> ContinuedFraction`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__simple_mediant__two_fractions__correct_mediant_returned",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.mediant",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-060",
                "requirement_description": "The system shall support addition of a `ContinuedFraction` object with a compatible operand.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__rational_operations",
                        "description": "e.g. `f1 + f2`, `f1 + 1`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.__add__",
                        "description": ""
                    },
                    {
                        "id": "__radd__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-061",
                "requirement_description": "The system shall support subtraction of a compatible operand from a `ContinuedFraction` object, and subtraction of a `ContinuedFraction` object from a compatible operand.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__rational_operations",
                        "description": "e.g. `f1 - f2`, `f1 - 1`, `1 - f1`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.__sub__",
                        "description": ""
                    },
                    {
                        "id": "__rsub__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-062",
                "requirement_description": "The system shall support multiplication of a `ContinuedFraction` object by a compatible operand.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__rational_operations",
                        "description": "e.g. `f1 * f2`, `f1 * 0`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.__mul__",
                        "description": ""
                    },
                    {
                        "id": "__rmul__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-063",
                "requirement_description": "The system shall support true division of a `ContinuedFraction` object by a compatible operand, and true division of a compatible operand by a `ContinuedFraction` object.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__rational_operations",
                        "description": "e.g. `f1 / f2`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.__truediv__",
                        "description": ""
                    },
                    {
                        "id": "__rtruediv__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-064",
                "requirement_description": "The system shall support floor division of a `ContinuedFraction` object by a compatible operand, and floor division of a compatible operand by a `ContinuedFraction` object.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__rational_operations",
                        "description": "e.g. `f1 // f2`, `f1 // 2`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.__floordiv__",
                        "description": ""
                    },
                    {
                        "id": "__rfloordiv__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-065",
                "requirement_description": "The system shall support the `divmod` operation for a `ContinuedFraction` object with a compatible operand, returning a pair of `ContinuedFraction` objects (quotient, remainder).",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__rational_operations",
                        "description": "e.g. `divmod(f1, f2)`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.__divmod__",
                        "description": ""
                    },
                    {
                        "id": "__rdivmod__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-066",
                "requirement_description": "The system shall support exponentiation of a `ContinuedFraction` object to a compatible power.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__rational_operations",
                        "description": "e.g. `f1 ** 3`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.__pow__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-067",
                "requirement_description": "The system shall support exponentiation of a compatible base to a `ContinuedFraction` power (if meaningful and supported by `fractions.Fraction` for the base type).",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__rational_operations",
                        "description": "e.g. `f1.__rpow__(2)`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.__rpow__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-068",
                "requirement_description": "The system shall support unary positive operation on a `ContinuedFraction` object.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__rational_operations",
                        "description": "e.g. `+f1`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.__pos__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-069",
                "requirement_description": "The system shall support unary negation of a `ContinuedFraction` object. The negated `ContinuedFraction` object must represent the correct negative rational value and its elements must be the canonical simple continued fraction elements for that negative value.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test___neg__",
                        "description": ""
                    },
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__rational_operations",
                        "description": "e.g. `-f1`, `-f2`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.__neg__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-070",
                "requirement_description": "The system shall support the absolute value operation on a `ContinuedFraction` object.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__rational_operations",
                        "description": "e.g. `abs(f2)`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.__abs__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-080",
                "requirement_description": "A `ContinuedFraction` object shall be convertible to a standard Python `float`.\n    *   **Method Name:** `as_float`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised",
                        "description": "verified by `expected_float_value`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.as_float",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-081",
                "requirement_description": "A `ContinuedFraction` object shall be convertible to a Python `Decimal` object, maintaining precision as appropriate for `Decimal` arithmetic.\n    *   **Method Name:** `as_decimal`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised",
                        "description": "verified by `expected_decimal_value`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.as_decimal",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-090",
                "requirement_description": "`ContinuedFraction` objects shall be comparable for equality (`==`).\n    *   If both operands are `ContinuedFraction` objects, equality is determined by their respective element sequences.\n    *   If one operand is a `ContinuedFraction` and the other is not, equality comparison shall fall back to the behavior of `fractions.Fraction`.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised",
                        "description": ""
                    },
                    {
                        "id": "test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.__eq__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-091",
                "requirement_description": "`ContinuedFraction` objects shall be hashable. The hash value shall be based on their element sequences.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended",
                        "description": "checks `hash(instance) == hash(expected_comparative_instance)`"
                    },
                    {
                        "id": "test_ContinuedFraction__truncate__valid_elements__correctly_truncated",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/continuedfraction.py::ContinuedFraction.__hash__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-100",
                "requirement_description": "The system shall provide a function to calculate the k-th convergent from a sequence of integer elements, returning a `fractions.Fraction`.\n    *   **Function Signature (conceptual):** `convergent(k: int, *elements: int) -> Fraction`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/lib.py::convergent",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-101",
                "requirement_description": "The `convergent(k, *elements)` function shall validate that `k` is a non-negative integer not exceeding the number of tail elements, all elements are integers, and all tail elements (`a_i` for `i >= 1`) are positive. If validation fails, a `ValueError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestConvergent::test_convergent__invalid_elements__value_error_raised",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/lib.py::convergent",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-102",
                "requirement_description": "The system shall provide a function to generate all convergents from a sequence of integer elements, yielding `fractions.Fraction` objects.\n    *   **Function Signature (conceptual):** `convergents(*elements: int) -> Generator[Fraction, None, None]`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/lib.py::convergents",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-103",
                "requirement_description": "The `convergents(*elements)` function shall validate that all elements are integers and all tail elements are positive. If validation fails, a `ValueError` shall be raised. Input must not be empty.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestConvergents::test_convergents__invalid_elements__value_error_raised",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/lib.py::convergents",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-104",
                "requirement_description": "The system shall provide a function to calculate the k-th remainder from a sequence of integer elements, returning a `fractions.Fraction`.\n    *   **Function Signature (conceptual):** `remainder(k: int, *elements: int) -> Fraction`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/lib.py::remainder",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-105",
                "requirement_description": "The `remainder(k, *elements)` function shall validate that `k` is a non-negative integer not exceeding the number of tail elements, all elements are integers, and all tail elements are positive. If validation fails, a `ValueError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestRemainder::test_remainder__invalid_elements__value_error_raised",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/lib.py::remainder",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-106",
                "requirement_description": "The system shall provide a function to generate all remainders from a sequence of integer elements (in descending order of index), yielding `fractions.Fraction` objects.\n    *   **Function Signature (conceptual):** `remainders(*elements: int) -> Generator[Fraction, None, None]`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/lib.py::remainders",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-107",
                "requirement_description": "The `remainders(*elements)` function shall validate that elements are provided, all elements are integers, and all tail elements are positive. If validation fails, a `ValueError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestRemainders::test_remainders__invalid_elements__value_error_raised",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/lib.py::remainders",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-108",
                "requirement_description": "The system shall provide a function to calculate the k-th mediant of two `fractions.Fraction` objects, supporting \"left\" and \"right\" directionality.\n    *   **Function Signature (conceptual):** `mediant(r: Fraction, s: Fraction, dir: str = 'right', k: int = 1) -> Fraction`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned",
                        "description": ""
                    },
                    {
                        "id": "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/lib.py::mediant",
                        "description": "also `left_mediant`, `right_mediant` as partials"
                    }
                ]
            },
            {
                "requirement_id": "FR-109",
                "requirement_description": "The `mediant` function shall validate that `dir` is one of 'left' or 'right' and `k` is a positive integer. If validation fails, a `ValueError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestMediant::test_mediant__invalid_dir_or_order__value_error_raised",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/lib.py::mediant",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-110",
                "requirement_description": "The system shall provide a function to generate a sequence of positive integers `m` that are coprime to a given positive integer `n`.\n    *   **Function Signatures (conceptual):** `coprime_integers_generator(n: int, start: int = 1, stop: int = None) -> Generator[int, None, None]`, `coprime_integers(n: int, start: int = 1, stop: int = None) -> tuple[int, ...]`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values",
                        "description": ""
                    },
                    {
                        "id": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/sequences.py::coprime_integers_generator",
                        "description": ""
                    },
                    {
                        "id": "src/continuedfractions/sequences.py::coprime_integers",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-111",
                "requirement_description": "The `coprime_integers` generation shall support optional `start` and `stop` parameters to define the range `start <= m < stop` for searching coprimes `m` to `n`.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__custom_start_and_stop_values",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/sequences.py::coprime_integers_generator",
                        "description": ""
                    },
                    {
                        "id": "src/continuedfractions/sequences.py::coprime_integers",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-112",
                "requirement_description": "The generated sequence of coprime integers shall be in descending order.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_sequences.py::TestCoprimeIntegers",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/sequences.py::coprime_integers_generator",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-113",
                "requirement_description": "The `coprime_integers` generation shall validate its inputs: `n` must be a positive integer. If `n > 1`, `start` must be an integer `1 <= start < n`. If `stop` is provided and `n > 1`, `stop` must be an integer `start < stop <= n`. If validation fails, a `ValueError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__invalid_args__raises_value_error",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/sequences.py::coprime_integers_generator",
                        "description": ""
                    },
                    {
                        "id": "src/continuedfractions/sequences.py::coprime_integers",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-114",
                "requirement_description": "For default `start` (1) and `stop` (`n`), the count of generated coprime integers for `n` must be equal to Euler's totient function `phi(n)`.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__verify_against_totient_value",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/sequences.py::coprime_integers_generator",
                        "description": ""
                    },
                    {
                        "id": "src/continuedfractions/sequences.py::coprime_integers",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-120",
                "requirement_description": "The system shall provide a KSRMTree component representing the Kanga-Saunders-Randall-Mitchell trees for generating coprime pairs.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__creation_and_initialisation",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/sequences.py::KSRMTree.__new__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-121",
                "requirement_description": "The KSRMTree component shall expose its root nodes, which must be `((2, 1), (3, 1))`.\n    *   **Property Name:** `KSRMTree().roots`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__creation_and_initialisation",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/sequences.py::KSRMTree.roots",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-122",
                "requirement_description": "The KSRMTree component shall expose its three branch generation functions, corresponding to the transformations: `(x,y) -> (2x-y, x)`, `(x,y) -> (2x+y, x)`, and `(x,y) -> (x+2y, y)`. These functions shall be callable.\n    *   **Property Name:** `KSRMTree().branches`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__creation_and_initialisation",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/sequences.py::KSRMTree.branches",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-123",
                "requirement_description": "The KSRMTree component shall provide a search method (`search_root`) to find all coprime pairs `(a,b)` with `1 <= b < a <= n`, starting from a given KSRMTree root node.\n    *   **Method Signature (conceptual):** `KSRMTree().search_root(n: int, root: tuple[int, int]) -> Generator[tuple[int, int], None, None]`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/sequences.py::KSRMTree.search_root",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-124",
                "requirement_description": "The `KSRMTree().search_root` method shall validate that `n` is an integer `>= 2` and the root is a coprime pair. If `n` is less than the first component of the root, it should yield no pairs. Invalid inputs should raise a `ValueError`.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search_root__invalid_args__raises_value_error",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/sequences.py::KSRMTree.search_root",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-125",
                "requirement_description": "The KSRMTree component shall provide a general search method (`search`) to find all coprime pairs `(a,b)` with `1 <= b < a <= n` (excluding `(n,m)` pairs if `a=n`). This method utilizes searches from its canonical roots. It must also include `(1,1)`.\n    *   **Method Signature (conceptual):** `KSRMTree().search(n: int) -> Generator[tuple[int, int], None, None]`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/sequences.py::KSRMTree.search",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-126",
                "requirement_description": "The `KSRMTree().search` method shall validate that `n` is a positive integer. If not, a `ValueError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search__invalid_args__raises_value_error",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/sequences.py::KSRMTree.search",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-127",
                "requirement_description": "The coprime pairs generated by `KSRMTree().search_root` and `KSRMTree().search` methods shall follow a specific, deterministic order as defined by the KSRM tree traversal logic.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root",
                        "description": ""
                    },
                    {
                        "id": "test_KSRMTree_search",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/sequences.py::KSRMTree.search_root",
                        "description": "including internal `_backtrack`"
                    },
                    {
                        "id": "src/continuedfractions/sequences.py::KSRMTree.search",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-130",
                "requirement_description": "The system shall provide a function to generate a sequence of all pairs of positive coprime integers `(a, b)` such that `1 <= b < a <= n`. For `n=1`, the sequence must contain `(1,1)`.\n    *   **Function Signatures (conceptual):** `coprime_pairs_generator(n: int) -> Generator[tuple[int,int], None, None]`, `coprime_pairs(n: int) -> tuple[tuple[int,int], ...]`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/sequences.py::coprime_pairs_generator",
                        "description": ""
                    },
                    {
                        "id": "src/continuedfractions/sequences.py::coprime_pairs",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-131",
                "requirement_description": "The `coprime_pairs` generation shall validate that `n` is a positive integer. If not, a `ValueError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__invalid_args__raises_value_error",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/sequences.py::coprime_pairs_generator",
                        "description": ""
                    },
                    {
                        "id": "src/continuedfractions/sequences.py::coprime_pairs",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-132",
                "requirement_description": "The sequence of coprime pairs returned by `coprime_pairs(n)` must be in a specific, deterministic order.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs",
                        "description": "the `expected_pairs` define this order"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/sequences.py::coprime_pairs_generator",
                        "description": "relies on `KSRMTree.search` and `product` order"
                    }
                ]
            },
            {
                "requirement_id": "FR-133",
                "requirement_description": "The total number of coprime pairs `(a,b)` where `1 <= b < a <= n` (plus the pair `(1,1)` if `n>=1`) generated by `coprime_pairs(n)` must be equal to `1 + sum(phi(k) for k in 2..n)` where `phi` is Euler's totient function. This is equivalent to `sum(phi(k) for k in 1..n)`.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs__verify_against_summatory_totient_value",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/sequences.py::coprime_pairs_generator",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-140",
                "requirement_description": "The system shall provide a function to generate the Farey sequence of a given order `n`.\n    *   **Function Signatures (conceptual):** `farey_sequence_generator(n: int) -> Generator[ContinuedFraction, None, None]`, `farey_sequence(n: int) -> tuple[ContinuedFraction, ...]`",
                "test_traceability": [
                    {
                        "id": "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/sequences.py::farey_sequence_generator",
                        "description": ""
                    },
                    {
                        "id": "src/continuedfractions/sequences.py::farey_sequence",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-141",
                "requirement_description": "Elements of the generated Farey sequence must be `ContinuedFraction` objects.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence",
                        "description": "expected types are `ContinuedFraction`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/sequences.py::farey_sequence_generator",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-142",
                "requirement_description": "The Farey sequence must consist of irreducible fractions `h/k` where `0 <= h <= k <= n` and `gcd(h,k)=1`.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/sequences.py::farey_sequence_generator",
                        "description": "relies on `coprime_pairs`"
                    }
                ]
            },
            {
                "requirement_id": "FR-143",
                "requirement_description": "The Farey sequence must be sorted in ascending order of value.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence",
                        "description": "expected sequences are sorted"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/sequences.py::farey_sequence_generator",
                        "description": "uses `sorted()`"
                    }
                ]
            },
            {
                "requirement_id": "FR-144",
                "requirement_description": "The Farey sequence must start with `ContinuedFraction(0,1)` and end with `ContinuedFraction(1,1)`.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/sequences.py::farey_sequence_generator",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-145",
                "requirement_description": "The Farey sequence generation shall validate that `n` is a positive integer. If not, a `ValueError` shall be raised.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence__invalid_args__raises_value_error",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/sequences.py::farey_sequence_generator",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-150",
                "requirement_description": "The system shall provide a `NamedCallableProxy` class that wraps a callable object, allowing it to be associated with a user-defined name.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_utils.py::TestNamedCallableProxy::test_NamedCallableProxy__creation_and_initialisation",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/utils.py::NamedCallableProxy.__new__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-151",
                "requirement_description": "A `NamedCallableProxy` instance must itself be callable, and calling it must execute the wrapped callable with the provided arguments.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_utils.py::TestNamedCallableProxy::test_NamedCallableProxy__creation_and_initialisation",
                        "description": "checks `received(1) == expected(1)`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/utils.py::NamedCallableProxy.__call__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-152",
                "requirement_description": "The string representation (`repr`) of a `NamedCallableProxy` instance shall include its user-defined name if one was provided during creation. If no name was provided, it should default to the string representation of the wrapped callable.",
                "test_traceability": [
                    {
                        "id": "tests/units/test_utils.py::TestNamedCallableProxy::test_NamedCallableProxy__creation_and_initialisation",
                        "description": "checks `received.__repr__()`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/utils.py::NamedCallableProxy.__repr__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-153",
                "requirement_description": "Two `NamedCallableProxy` instances shall compare as equal if their wrapped callables are functionally equivalent (e.g., possess identical bytecode).",
                "test_traceability": [
                    {
                        "id": "tests/units/test_utils.py::TestNamedCallableProxy::test_NamedCallableProxy__creation_and_initialisation",
                        "description": "checks `received == expected`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/continuedfractions/utils.py::NamedCallableProxy.__eq__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "EIR-001",
                "requirement_description": "The system shall accept string inputs for numbers in standard decimal format (e.g., \"123.45\", \"-10\") and fraction format (e.g., \"3/2\", \"-7/5\") where specified for conversion to continued fractions.\n    *   **Reference:** FR-005, FR-006",
                "test_traceability": [
                    {
                        "id": "tests/units/test_lib.py::TestContinuedFractionReal",
                        "description": ""
                    }
                ],
                "code_traceability": []
            }
        ],
        "commit_sha": "2b6df3e084089d3ba6b02ddbaa35acb419c366dc",
        "full_code_skeleton": "--- File: src/continuedfractions/lib.py ---\n```python\ndef continued_fraction_rational(frac: Fraction, /) -> Generator[int, None, None]:\n    \"\"\"Core continued fraction algorithm implementation which generates the ordered sequence of elements of the (finite) simple continued fraction of the given rational number.\n\n    The resulting sequence of elements, :math:`a_0,a_1,\\\\ldots a_n`, defines a simple continued fraction of the form:\n\n    .. math::\n\n       a_0 + \\\\cfrac{1}{a_1 + \\\\cfrac{1}{a_2 + \\\\ddots\\\\cfrac{1}{a_{n - 1} + \\\\cfrac{1}{a_n}}}}\n\n    which is also written more compactly as:\n\n    .. math::\n\n       [a_0; a_1, a_2\\\\ldots, a_n]\n\n    The order of the continued fraction is said to be :math:`n`. If the last\n    element :math:`a_n = 1` the sequence can be rewritten as\n    :math:`[a_0; a_1, a_2\\\\ldots, a_{n - 1} + 1]`, which is then unique as a\n    simple continued fraction representation of the rational number.\n\n    Negative rational numbers can also be represented in this way, provided we\n    use the `Euclidean division lemma <https://en.wikipedia.org/wiki/Euclid%27s_lemma>`_.\n    This is described in more detail in the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/creating-continued-fractions.html#negative-continued-fractions>`_.\n\n    For a definition of \"continued fraction\", \"element\", \"order\",\n    \"finite continued fraction\", \"simple continued fraction\", please consult\n    the `package documentation <https://continuedfractions.readthedocs.io/en/stable>`_,\n    or any online resource such as `Wikipedia <https://en.wikipedia.org/wiki/Continued_fraction>`_,\n    or suitable books on number theory.\n\n    Parameters\n    ----------\n    frac : `fractions.Fraction`\n        The rational number to represented as a simple continued fraction.\n\n    Yields\n    ------\n    int\n        Elements of a unique simple continued fraction of the given rational\n        number.\n\n    Examples\n    --------\n    A few examples are given below of how this function can be used.\n\n    >>> for e in continued_fraction_rational(Fraction(649, 200)):\n    ...     print(e)\n    ... \n    3\n    4\n    12\n    4\n    >>> list(continued_fraction_rational(Fraction(415, 93)))\n    [4, 2, 6, 7]\n    >>> list(continued_fraction_rational(Fraction(-649, 200)))\n    [-4, 1, 3, 12, 4]\n    >>> list(continued_fraction_rational(Fraction(123235, 334505)))\n    [0, 2, 1, 2, 1, 1, 250, 1, 13]\n\n    Notes\n    -----\n    Every rational number has exactly two simple continued fractions, one of\n    which has an additional element of :math:`1` as its last element,\n    i.e. :math:`[a_0;a_1,a_2,\\\\ldots,a_{n - 1}, 1]`. But this form can be\n    reduced by adding the :math:`1` to the second last element, :math:`a_{n - 1}`,\n    producing the shorter form :math:`[a_0;a_1,a_2,\\\\ldots, a_{n - 1} + 1]`,\n    where the last element is now :math:`> 1`.\n\n    The simple continued fraction representation generated by this function is\n    the shorter version, and is thus unique.\n    \"\"\"\n    pass\n\ndef continued_fraction_real(x: int | float | str | Decimal, /) -> Generator[int, None, None]:\n    \"\"\"Generates a finite sequence of elements (coefficients) of a (simple) continued fraction of the given real number.\n\n    The result is a finite sequence even though the given number :math:`x` may\n    be irrational or not exactly representable as a real number. \n\n    The simple continued fraction representation of :math:`x` is a number of\n    the form\n\n    .. math::\n\n       a_0 + \\\\cfrac{1}{a_1 + \\\\cfrac{1}{a_2 + \\\\ddots}}\n\n    where :math:`a_0 = [x]` is the integer part of :math:`x`, and the\n    :math:`a_1,a_2\\\\ldots` are the (non-negative) quotients obtained by a\n    repeated application of `Euclidean division <https://en.wikipedia.org/wiki/Euclidean_division>`_\n    to the fractional part :math:`x - [x]`, which is called the remainder.\n\n    If the last element :math:`a_n = 1` the sequence can be rewritten as\n    :math:`[a_0; a_1, a_2\\\\ldots, a_{n - 1} + 1]`.\n\n    As Python :py:class:`float` values, like all floating point\n    implementations, are `finite precision representations <https://docs.python.org/3/tutorial/floatingpoint.html>`_\n    of real numbers, the resulting simple continued fraction  of :math:`x`\n    generated by this function may be approximate, not exact, and also not\n    necessarily unique.\n\n    For non-rational real numbers it is best to pass :py:class:`decimal.Decimal`\n    values, with the `context precision <https://docs.python.org/3.12/library/decimal.html#context-objects>`_\n    set to the highest level possible.\n\n    The results for rational numbers are guaranteed to be exact however large\n    the number, subject to memory and hardware limitations of the running\n    environment.\n\n    Invalid values will generate an error in either the\n    :py:class:`fractions.Fraction` or :py:class:`decimal.Decimal` classes -\n    no errors are raised directly in the function itself.\n\n    Parameters\n    ----------\n    x : int, float, str, decimal.Decimal\n        The real number to represent as a simple continued fraction.\n\n    Yields\n    ------\n    int\n        Elements of a simple continued fraction of the given real number.\n\n    Examples\n    --------\n    A few examples are given below of how this function can be used.\n\n    >>> list(continued_fraction_real(5000))\n    [5000]\n    >>> list(continued_fraction_real(-5000.0))\n    [-5000]\n    >>> list(continued_fraction_real(2/5))\n    [0, 2, 2, 1801439850948198]\n    >>> list(continued_fraction_real('2/5'))\n    [0, 2, 2]\n    >>> list(continued_fraction_real('-1/3'))\n    [-1, 1, 2]\n    >>> list(continued_fraction_real(1/1j))\n    Traceback (most recent call last):\n    ...\n    TypeError: conversion from complex to Decimal is not supported\n    >>> list(continued_fraction_real(\"not a numeric string\"))\n    Traceback (most recent call last):\n    ...\n    decimal.InvalidOperation: [<class 'decimal.ConversionSyntax'>]\n    >>> list(continued_fraction_real(-649/200))\n    [-4, 1, 3, 12, 3, 1, 234562480591, 2, 5, 2]\n    >>> list(continued_fraction_real('-649/200'))\n    [-4, 1, 3, 12, 4]\n    >>> list(continued_fraction_real('-649/-200'))\n    Traceback (most recent call last):\n    ...\n    ValueError: Invalid literal for Fraction: '-649/-200'\n    >>> list(continued_fraction_real(Decimal('0.3333')))\n    [0, 3, 3333]\n    \"\"\"\n    pass\n\ndef convergent(k: int, *elements: int) -> Fraction:\n    \"\"\"Returns the :math:`k`-th convergent of a (simple) continued fraction from a sequence of its elements.\n\n    Given a (simple) continued fraction  :math:`[a_0;a_1,a_2,\\\\ldots]` the\n    :math:`k`-th convergent is defined as:\n\n    .. math::\n\n       C_k = a_0 + \\\\cfrac{1}{a_1 + \\\\cfrac{1}{a_2 \\\\ddots \\\\cfrac{1}{a_{k-1} + \\\\cfrac{1}{a_k}}}}\n\n    The result is a :py:class:`fractions.Fraction` instance.\n    \n    The integer :math:`k` is called the order of the convergent, and if \n    :math:`[a_0;a_1,a_2,\\\\ldots]` is finite of order :math:`n` then it has\n    exactly :math:`n + 1` convergents :math:`C_0,C_1,C_2,\\\\ldots,C_n` where\n    the :math:`k`-th convergent :math:`C_k = \\\\frac{p_k}{q_k}` is given by\n    the recurrence relation:\n\n    .. math::\n       \n       \\\\begin{align}\n       p_k &= a_kp_{k - 1} + p_{k - 2} \\\\\\\\\n       q_k &= a_kq_{k - 1} + q_{k - 2},        \\\\hskip{3em}    k \\\\geq 3\n       \\\\end{align}\n\n    where :math:`p_0 = a_0`, :math:`q_0 = 1`, :math:`p_1 = p_1p_0 + 1`,\n    and :math:`q_1 = p_1`.\n\n    This function is a faithful implementation of this algorithm.\n\n    A :py:class:`ValueError` is raised if :math:`k` is not an integer or is an\n    integer greater than the number of elements, or if any of the elements are\n    not integers.\n\n    Parameters\n    ----------\n    k : `int`\n        The order of the convergent. Must be a non-negative integer less than\n        the number of elements.\n\n    *elements : `int`\n        A variable-length sequence of integer elements of a continued fraction.\n\n    Returns\n    -------\n    fractions.Fraction\n        A rational fraction constructed from the given sequence of elements of\n        a continued fraction, representing the :math:`k`-order convergent of a\n        (finite) simple continued fraction as given by a sequence of elements.\n\n    Raises\n    ------\n    ValueError\n        If :math:`k` is not a non-negative integer less than the number of\n        elements, or if any of the elements are not integers.\n\n    Examples\n    --------\n    >>> convergent(0, 3, 4, 12, 4)\n    Fraction(3, 1)\n    >>> convergent(1, 3, 4, 12, 4)\n    Fraction(13, 4)\n    >>> convergent(2, 3, 4, 12, 4)\n    Fraction(159, 49)\n    >>> convergent(3, 3, 4, 12, 4)\n    Fraction(649, 200)\n    >>> convergent(3)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> convergent(-1, 3, 4, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> convergent(4, 3, 4, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    \"\"\"\n    pass\n\ndef convergents(*elements: int) -> Generator[Fraction, None, None]:\n    \"\"\"Generates an (ordered) sequence of all convergents of a (simple) continued fraction from a sequence of its elements.\n\n    If :math:`n` is the order of the continued fraction represented by the\n    given sequence of its elements then there are :math:`n + 1` convergents\n    :math:`C_0, C_1, \\\\ldots, C_n`, and the function generates these in that\n    order.\n\n    See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/exploring-continued-fractions.html#convergents-and-rational-approximations>`_\n    for more details on convergents.\n\n    Parameters\n    ----------\n    *elements : `int`\n        A variable-length sequence of integer elements of a (simple)\n        continued fraction.\n\n    Yields\n    ------\n    fractions.Fraction\n        Each element generated is a :py:class:`fractions.Fraction` instance and\n        a :math:`k`-th convergent of the given continued fraction.\n\n    Raises\n    ------\n    ValueError\n        If there are any non-integer elements, or the tail elements are not\n        positive integers.\n\n    Examples\n    --------\n    >>> tuple(convergents(3))\n    (Fraction(3, 1),)\n    >>> tuple(convergents(3, 2))\n    (Fraction(3, 1), Fraction(7, 2))\n    >>> tuple(convergents(3, 4, 12, 4))\n    (Fraction(3, 1), Fraction(13, 4), Fraction(159, 49), Fraction(649, 200))\n    >>> tuple(convergents(-5, 1, 1, 6, 7))\n    (Fraction(-5, 1), Fraction(-4, 1), Fraction(-9, 2), Fraction(-58, 13), Fraction(-415, 93))\n    >>> tuple(convergents(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))\n    (Fraction(1, 1), Fraction(3, 2), Fraction(10, 7), Fraction(43, 30), Fraction(225, 157), Fraction(1393, 972), Fraction(9976, 6961), Fraction(81201, 56660), Fraction(740785, 516901), Fraction(7489051, 5225670))\n\n    \"\"\"\n    pass\n\ndef fraction_from_elements(*elements: int) -> Fraction:\n    \"\"\"Returns the rational number represented by a (simple) continued fraction from a sequence of its elements.\n\n    The elements must be given as positional arguments, which means that if\n    they are contained in an iterable then they must be unpacked using the\n    unpacking operator ``*``, as described in the examples below.\n\n    Parameters\n    ----------\n    *elements : `int`\n        A variable-length sequence of integer elements of a simple continued\n        fraction.\n\n    Returns\n    -------\n    fractions.Fraction\n        A rational number constructed from a sequence of elements of a simple\n        continued fraction which represents the number.\n\n    Raises\n    ------\n    ValueError\n        If any of the elements are not integers.\n\n    Examples\n    --------\n    >>> fraction_from_elements(3, 4, 12, 4)\n    Fraction(649, 200)\n    >>> fraction_from_elements(-4, 1, 3, 12, 4)\n    Fraction(-649, 200)\n    >>> fraction_from_elements(4, 2, 6, 7)\n    Fraction(415, 93)\n    >>> fraction_from_elements(*[4, 2, 6, 7])\n    Fraction(415, 93)\n    >>> fraction_from_elements(4.5, 2, 6, 7)\n    Traceback (most recent call last):\n    ...\n    ValueError: Continued fraction elements must be integers\n    \"\"\"\n    pass\n\ndef remainder(k: int, *elements: int) -> Fraction:\n    \"\"\"Returns the :math:`k`-th remainder of a (simple) continued fraction from a sequence of its elements.\n\n    Given a (simple) continued fraction  :math:`[a_0;a_1,a_2,\\\\ldots]` the\n    :math:`k`-th remainder :math:`R_k` is the (simple) continued fraction\n    :math:`[a_k; a_{k + 1}, a_{k + 2}, \\\\ldots]`:\n\n    .. math::\n\n       R_k = a_k + \\\\cfrac{1}{a_{k + 1} + \\\\cfrac{1}{a_{k + 2} \\\\ddots }}\n\n    where :math:`R_0` is just the original continued fraction, i.e.\n    :math:`R_0 = [a_0; a_1, a_2, \\\\ldots]`.\n\n    The remainders satisfy the recurrence relation:\n\n    .. math::\n\n       R_{k - 1} = a_{k - 1} + \\\\frac{1}{R_k}, \\\\hskip{3em} k \\\\geq 1\n\n    If the continued fraction :math:`[a_0; a_1, a_2,\\\\ldots]` is finite of\n    order :math:`n` then all :math:`R_k` are rational. If we let\n    :math:`R_k = \\\\frac{s_k}{t_k}` then the recurrence relation above can\n    be written as:\n\n    .. math::\n\n       R_{k - 1} = \\\\frac{s_{k - 1}}{t_{k - 1}} = \\\\frac{a_{k - 1}s_k + t_k}{s_k}, \\\\hskip{3em} k \\\\geq 1\n\n    As this library only deals with finite continued fractions, this function\n    always produces remainders as instances of :py:class:`~fractions.Fraction`.\n\n    The integer :math:`k` must be non-negative and cannot exceed the order\n    of the continued fraction, i.e. the number of its tail elements.\n\n    A :py:class:`ValueError` is raised if :math:`k` is not an integer, or is an\n    integer greater than the number of elements, or if any of the elements are\n    not integers, or if any of the tail elements are not positive integers.\n\n    Parameters\n    ----------\n    k : `int`\n        The index of the remainder. Must be a non-negative integer not\n        exceeding the order of the continued fraction.\n\n    *elements : `int`\n        A variable-length sequence of integer elements of a (simple) continued\n        fraction.\n\n    Returns\n    -------\n    fractions.Fraction\n        A rational fraction constructed from the given sequence of elements of\n        a continued fraction, representing its :math:`k`-th remainder, as\n        defined above.\n\n    Raises\n    ------\n    ValueError\n        If :math:`k` is not an integer, or is an integer greater than the\n        number of elements, or if any of the elements are not integers, or if\n        any of the tail elements are not positive integers.\n\n    Examples\n    --------\n    >>> remainder(0, 3, 4, 12, 4)\n    Fraction(649, 200)\n    >>> remainder(1, 3, 4, 12, 4)\n    Fraction(200, 49)\n    >>> remainder(2, 3, 4, 12, 4)\n    Fraction(49, 4)\n    >>> remainder(3, 3, 4, 12, 4)\n    Fraction(4, 1)\n    >>> remainder(0, -5, 1, 1, 6, 7)\n    Fraction(-415, 93)\n    >>> remainder(1, -5, 1, 1, 6, 7)\n    Fraction(93, 50)\n    >>> remainder(2, -5, 1, 1, 6, 7)\n    Fraction(50, 43)\n    >>> remainder(3, -5, 1, 1, 6, 7)\n    Fraction(43, 7)\n    >>> remainder(4, -5, 1, 1, 6, 7)\n    Fraction(7, 1)\n    >>> remainder(1)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> remainder(-1, 3, 4, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> remainder(4, 3, 4, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> remainder(1, 3, 0, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> remainder(1, 3, -1, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    \"\"\"\n    pass\n\ndef remainders(*elements: int) -> Generator[Fraction, None, None]:\n    \"\"\"Generates an (ordered) sequence of all remainders of a (simple) continued fraction from a sequence of its elements in descending order of index.\n\n    If :math:`n` is the order of the continued fraction represented by the\n    given sequence of its elements then there are :math:`n + 1` remainders\n    :math:`R_0, R_1, \\\\ldots, R_n`, and the function generates these in\n    reverse order :math:`R_0, R_1, \\\\ldots, R_n`.\n\n    See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/exploring-continued-fractions.html#remainders>`_\n    for more details on remainders.\n\n    Parameters\n    ----------\n    *elements : `int`\n        A variable-length sequence of integer elements of a (simple)\n        continued fraction.\n\n    Yields\n    ------\n    fractions.Fraction\n        Each element generated is a :py:class:`fractions.Fraction` instance and\n        a :math:`k`-th remainder of the given continued fraction.\n\n    Raises\n    ------\n    ValueError\n        If no elements are given, or there are any non-integer elements, or\n        the tail elements are not positive integers.\n\n    Examples\n    --------\n    >>> tuple(remainders(3))\n    (Fraction(3, 1),)\n    >>> tuple(remainders(3, 2))\n    (Fraction(2, 1), Fraction(7, 2))\n    >>> tuple(remainders(3, 4, 12, 4))\n    (Fraction(4, 1), Fraction(49, 4), Fraction(200, 49), Fraction(649, 200))\n    >>> tuple(remainders(-5, 1, 1, 6, 7))\n    (Fraction(7, 1), Fraction(43, 7), Fraction(50, 43), Fraction(93, 50), Fraction(-415, 93))\n    >>> tuple(remainders(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))\n    (Fraction(10, 1), Fraction(91, 10), Fraction(738, 91), Fraction(5257, 738), Fraction(32280, 5257), Fraction(166657, 32280), Fraction(698908, 166657), Fraction(2263381, 698908), Fraction(5225670, 2263381), Fraction(7489051, 5225670))\n    >>> tuple(remainders())\n    Traceback (most recent call last):\n    ...\n    ValueError: Continued fraction elements must be integers, and all \n    tail elements (from the 1st element onwards) must be positive.\n    >>> tuple(remainders(0, 0))\n    Traceback (most recent call last):\n    ...\n    ValueError: Continued fraction elements must be integers, and all \n    tail elements (from the 1st element onwards) must be positive.\n    >>> tuple(remainders(1, 0))\n    Traceback (most recent call last):\n    ...\n    ValueError: Continued fraction elements must be integers, and all \n    tail elements (from the 1st element onwards) must be positive.\n    >>> tuple(remainders(1, 2, -1))\n    Traceback (most recent call last):\n    ...\n    ValueError: Continued fraction elements must be integers, and all \n    tail elements (from the 1st element onwards) must be positive.\n    \"\"\"\n    pass\n\ndef mediant(r: Fraction, s: Fraction, /, *, dir: str = 'right', k: int = 1) -> Fraction:\n    \"\"\"Returns the :math:`k`-th left- or right-mediant of two rational numbers.\n\n    For a positive integer :math:`k`, the :math:`k`-th left-mediant of two\n    rational numbers :math:`r = \\\\frac{a}{b}` and :math:`s = \\\\frac{c}{d}`,\n    where :math:`b, d, b + d \\\\neq 0`, is defined as:\n    \n    .. math::\n\n       \\\\frac{ka + c}{kb + d}, \\\\hskip{3em}    k \\\\geq 1\n\n    while the :math:`k`-th right mediant is defined as:\n    \n    .. math::\n\n       \\\\frac{a + kc}{b + kd}, \\\\hskip{3em}    k \\\\geq 1\n\n    If we assume that :math:`r < s` and :math:`bd > 0` then these mediants\n    have the property that:\n   \n    .. math::\n\n       \\\\frac{a}{b} < \\\\frac{ka + c}{kb + d} \\\\leq \\\\frac{a + kc}{b + kd} < \\\\frac{c}{d},   \\\\hskip{3em} k \\\\geq 1\n\n    where equality holds for :math:`k = 1`. If we let :math:`k \\\\to \\\\infty`\n    then the mediants converge to opposite limits:\n\n    .. math::\n\n      \\\\begin{align}\n      \\\\lim_{k \\\\to \\\\infty} \\\\frac{ka + c}{kb + d} &= \\\\frac{a}{b} \\\\\\\\\n      \\\\lim_{k \\\\to \\\\infty} \\\\frac{a + kc}{b + kd} &= \\\\frac{c}{d}\n      \\\\end{align}\n\n    For more information consult the\n    `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/mediants.html>`_.\n\n    For the left mediant use ``dir=\"left\"``, while for the right use\n    ``dir=\"right\"``. The default is ``dir=\"right\"``. For ``k = 1`` the left and\n    right mediants are identical to the simple mediant :math:`\\\\frac{a + c}{b + d}`.\n\n    Parameters\n    ----------\n    r : `fractions.Fraction`\n        The first rational number.\n\n    s : `fractions.Fraction`\n        The second rational number.\n\n    dir : `str`, default='right'\n        The \"direction\" of the mediant - `'left'` or `'right'`, as defined\n        above.\n\n    k : `int`, default=1\n        The order of the mediant, as defined above.\n\n    Returns\n    -------\n    fractions.Fraction\n        The `k`-th left- or right-mediant of the two given rational numbers.\n\n    Examples\n    --------\n    >>> mediant(Fraction(1, 2), Fraction(3, 5))\n    Fraction(4, 7)\n    >>> mediant(Fraction(1, 2), Fraction(3, 5), dir='left')\n    Fraction(4, 7)\n    >>> mediant(Fraction(1, 2), Fraction(3, 5), k=2)\n    Fraction(7, 12)\n    >>> mediant(Fraction(1, 2), Fraction(3, 5), dir='left', k=2)\n    Fraction(5, 9)\n    >>> mediant(Fraction(1, 2), Fraction(3, 5), k=3, dir='right')\n    Fraction(10, 17)\n    >>> mediant(Fraction(1, 2), Fraction(3, 5), k=3, dir='left')\n    Fraction(6, 11)\n    \"\"\"\n    pass\n```\n--- File: src/continuedfractions/utils.py ---\n```python\nclass NamedCallableProxy:\n    \"\"\"Class wrapper to have named callable proxies, which can also work as :py:class:`enum.Enum` values.\n\n    Adapted from Stack Overflow solution by Ceppo93:\n\n        https://stackoverflow.com/a/40486992\n    \"\"\"\n    def __new__(cls, callable_: Callable, /, *, name: str = None) -> NamedCallableProxy:\n        \"\"\"Constructor\n\n        Parameters\n        ----------\n        callable_ : `callable`\n            The callable to name and proxy.\n\n        name : `str`, default=None\n            The user-defined name of the callable to use in :py:func:`~continuedfractions.utils.__repr__`.\n            If :py:data:`None` the Python-defined default will be used.\n\n        Returns\n        -------\n        callable\n            A named callable proxy.\n\n        Examples\n        --------\n        >>> square = NamedCallableProxy(lambda x: x ** 2, name=\"square: x |--> x^2\")\n        >>> square\n        NamedCallableProxy(\"square: x |--> x^2\")\n        >>> list(map(square, [1, 2, 3, 4, 5]))\n        [1, 4, 9, 16, 25]\n        \"\"\"\n        pass\n\n    def __repr__(self) -> str:\n        pass\n\n    def __eq__(self, other: NamedCallableProxy) -> bool:\n        pass\n\n    def __call__(self, *args: Any, **kwargs: Any) -> Any:\n        pass\n```\n--- File: src/continuedfractions/continuedfraction.py ---\n```python\nclass ContinuedFraction(Fraction):\n    \"\"\"An object-oriented representation of a (finite) simple continued fraction.\n\n    An implementation of simple continued fractions as Python objects and\n    instances of the standard library :py:class:`fractions.Fraction` class, with\n    various properties for the continued fraction, including its elements\n    (or coefficients), the order, convergents, and remainders.\n\n    The term \"simple continued fraction\" denotes a specific type of continued\n    fraction where the fractional terms only have numerators of :math:`1`.\n\n    Examples\n    --------\n    Construct the continued fraction for the rational `649/200`.\n\n    >>> cf = ContinuedFraction(649, 200)\n    >>> cf\n    ContinuedFraction(649, 200)\n    >>> cf.as_float()\n    3.245\n\n    Inspect the elements, order, convergents, and remainders.\n\n    >>> cf.elements\n    (3, 4, 12, 4)\n    >>> cf.order\n    3\n    >>> cf.convergent(0), cf.convergent(1), cf.convergent(2), cf.convergent(3)\n    (ContinuedFraction(3, 1), ContinuedFraction(13, 4), ContinuedFraction(159, 49), ContinuedFraction(649, 200))\n    >>> cf.remainder(0), cf.remainder(1), cf.remainder(2), cf.remainder(3)\n    (ContinuedFraction(649, 200), ContinuedFraction(200, 49), ContinuedFraction(49, 4), ContinuedFraction(4, 1))\n\n    Inspect the element counts.\n\n    >>> cf.counter\n    Counter({4: 2, 3: 1, 12: 1})\n\n    Check some properties of the convergents and remainders.\n\n    >>> assert cf.remainder(1) == 1 / (cf - cf.convergent(0))\n\n    Construct continued fractions from element sequences.\n\n    >>> cf_inverse = ContinuedFraction.from_elements(0, 3, 4, 12, 4)\n    >>> cf_inverse\n    ContinuedFraction(200, 649)\n    >>> assert cf_inverse == 1/cf\n    >>> assert cf * cf_inverse == 1\n    >>> cf_negative_inverse = ContinuedFraction.from_elements(-1, 1, 2, 4, 12, 4)\n    >>> cf_negative_inverse\n    ContinuedFraction(-200, 649)\n    >>> assert cf_negative_inverse == -1/cf\n    >>> assert cf * cf_negative_inverse == -1\n    \"\"\"\n    def __new__(cls, *args: Any, **kwargs: Any) -> ContinuedFraction:\n        \"\"\"Creates, initialises and returns instances of this class.\n\n        Arguments can be any which are valid for creating objects of the\n        :py:class:`fractions.Fraction` superclass.\n\n        For clarification, valid arguments can be one of the following:\n\n        * a single instance of :py:class:`numbers.Rational`, including\n          :py:class:`int`, :py:class:`fractions.Fraction` or\n          :py:class:`ContinuedFraction`, named or unnamed\n        * a pair of  :py:class:`numbers.Rational` instances, including\n          :py:class:`int`, :py:class:`fractions.Fraction` and\n          :py:class:`ContinuedFraction`, named or unnamed\n        * a single :py:class:`float` or :py:class:`decimal.Decimal` value\n          that is not a special value such as :py:data:`math.nan`,\n          ``float('inf')``, or ``Decimal('infinity')``\n        * a single numeric valid string (:py:class:`str`) - validity is\n          determined in the superclass by the\n          :py:data:`fractions._RATIONAL_FORMAT` test\n\n        Returns\n        -------\n        ContinuedFraction\n            A :py:class:`ContinuedFraction` instance.\n\n        Examples\n        --------\n        Several example are given below of constructing the simple continued\n        fraction for the number :math:`\\\\frac{-649}{200}` in different ways.\n\n        >>> ContinuedFraction(-649, 200)\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction('-3.245')\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(Decimal('-3.245'))\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction('-649/200')\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(Fraction(-649, 200))\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(ContinuedFraction(649, -200))\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(Fraction(-649), 200)\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(649, Fraction(-200))\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(Fraction(-649), ContinuedFraction(200))\n        ContinuedFraction(-649, 200)\n\n        In each of the examples above, the minus sign can be removed from\n        the arguments to the :py:class:`numbers.Rational` instance and\n        instead attached to the outer class, e.g.:\n\n        >>> -ContinuedFraction(649, 200)\n        ContinuedFraction(-649, 200)\n        >>> -ContinuedFraction('3.245')\n        ContinuedFraction(-649, 200)\n        >>> -ContinuedFraction('649/200')\n        ContinuedFraction(-649, 200)\n\n        Invalid arguments will raise errors in the\n        :py:class:`fractions.Fraction` superclass.\n        \"\"\"\n        pass\n\n    @classmethod\n    def from_elements(cls, *elements: int) -> ContinuedFraction:\n        \"\"\"Returns a :py:class:`ContinuedFraction` instance from a sequence of (integer) elements of a (finite) simple continued fraction.\n\n        Invalid elements will trigger a :py:class:`ValueError`.\n\n        Parameters\n        ----------\n        *elements : int\n            An ordered sequence of integer elements of a (finite) simple\n            continued fraction.\n\n        Returns\n        -------\n        ContinuedFraction\n            A new and fully initialised instance of :py:class:`ContinuedFraction` with\n            the given element sequence.\n\n        Raises\n        ------\n        ValueError\n            If any elements are not integers, or any elements after the 1st\n            are not positive.\n\n        Examples\n        --------\n        Constructing a continued fraction for the rational :math:`\\\\frac{649}{200}` using\n        the element sequence :math:`3, 4, 12, 4`.\n\n        >>> c1 = ContinuedFraction.from_elements(3, 4, 12, 4)\n        >>> c1\n        ContinuedFraction(649, 200)\n\n        Constructing the continued fraction of the (multiplicative) inverse :math:`\\\\frac{200}{649}`\n        using the element sequence :math:`0, 3, 4, 12, 4`.\n\n        >>> c2 = ContinuedFraction.from_elements(0, 3, 4, 12, 4)\n        >>> c2\n        ContinuedFraction(200, 649)\n\n        Validation for elements containing non-integers or negative integers.\n\n        >>> ContinuedFraction.from_elements('0', 1)\n        Traceback (most recent call last):\n        ...\n        ValueError: Continued fraction elements must be integers, and all elements after the 1st must be positive\n        >>> ContinuedFraction.from_elements(0, 1, 2.5)\n        Traceback (most recent call last):\n        ...\n        ValueError: Continued fraction elements must be integers, and all elements after the 1st must be positive\n        >>> ContinuedFraction.from_elements(1, 0)\n        Traceback (most recent call last):\n        ...\n        ValueError: Continued fraction elements must be integers, and all elements after the 1st must be positive\n        >>> ContinuedFraction.from_elements(1, -1)\n        Traceback (most recent call last):\n        ...\n        ValueError: Continued fraction elements must be integers, and all elements after the 1st must be positive\n\n        \"\"\"\n        pass\n\n    def extend(self, *new_elements: int) -> None:\n        \"\"\"Performs an in-place extension of the tail of the current sequence of elements.\n\n        Raises a :py:class:`ValueError` if there are no new elements, or are\n        not positive integers.\n\n        .. note::\n\n           As this method performs an in-place modification of the existing/\n           current instance the object ID remains the same.\n\n        Parameters\n        ----------\n        elements\n            An (ordered) sequence of new (integer) elements by which the tail\n            of the existing sequence of elements is extended.\n\n        Raises\n        ------\n        ValueError\n            If no new elements provided, or the new elements provided are not\n            positive integers.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('3.245')\n        >>> cf\n        ContinuedFraction(649, 200)\n        >>> cf.elements\n        (3, 4, 12, 4)\n        >>> cf.order\n        3\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)), (2, ContinuedFraction(159, 49)), (3, ContinuedFraction(649, 200)))\n        >>> tuple(cf.remainders)\n        ((3, ContinuedFraction(4, 1)), (2, ContinuedFraction(49, 4)), (1, ContinuedFraction(200, 49)), (0, ContinuedFraction(649, 200)))\n        >>> cf.extend(5, 2)\n        >>> cf\n        ContinuedFraction(7457, 2298)\n        >>> cf.elements\n        (3, 4, 12, 4, 5, 2)\n        >>> cf.order\n        5\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)), (2, ContinuedFraction(159, 49)), (3, ContinuedFraction(649, 200)), (4, ContinuedFraction(3404, 1049)), (5, ContinuedFraction(7457, 2298)))\n        >>> tuple(cf.remainders)\n        ((5, ContinuedFraction(2, 1)), (4, ContinuedFraction(11, 2)), (3, ContinuedFraction(46, 11)), (2, ContinuedFraction(563, 46)), (1, ContinuedFraction(2298, 563)), (0, ContinuedFraction(7457, 2298)))\n        >>> cf = ContinuedFraction(649, 200)\n        >>> cf.extend(0, 1)\n        Traceback (most recent call last):\n        ...\n        ValueError: The elements/coefficients to be added to the tail must be positive integers.\n        >>> cf.extend(1, -1)\n        Traceback (most recent call last):\n        ...\n        ValueError: The elements/coefficients to be added to the tail must be positive integers.\n        \"\"\"\n        pass\n\n    def truncate(self, *tail_elements: int) -> None:\n        \"\"\"Performs an in-place truncation of the tail of the existing sequence of elements.\n\n        Raises a :py:class:`ValueError` if the tail elements provided are not\n        positive integers, or do not form a segment of the existing tail. This\n        includes the case where the length of the tail elements provided exceed\n        the length of the existing tail, i.e. the order of the continued\n        fraction represented by the instance.\n\n        .. note::\n\n           The tail elements provided must be positive integers which form a\n           subsequence of the tail of the original sequence ending with the\n           last element, e.g. with respect to the complete sequence of elements\n           ``(3, 4, 12, 4)`` a value of ``12, 4`` for ``*tail_elements`` would\n           be valid, but ``4, 12`` would be invalid as it does not represent\n           a segment of the tail, and ``3, 4, 12, 4`` would also be invalid\n           as it includes the head ``3``.\n\n        .. note::\n\n           As this method performs an in-place modification of the existing/\n           current instance the object ID remains the same.\n\n        Parameters\n        ----------\n        tail_elements\n            An (ordered) sequence of (integer) elements to truncate from the\n            tail of the existing sequence of elements.\n\n        Raises\n        ------\n        ValueError\n            If no tail elements are provided, or the tail elements provided do\n            not represent a valid segment of the existing tail.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('3.245')\n        >>> cf\n        ContinuedFraction(649, 200)\n        >>> cf.elements\n        (3, 4, 12, 4)\n        >>> cf.order\n        3\n        >>> cf.counter\n        Counter({4: 2, 3: 1, 12: 1})\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)), (2, ContinuedFraction(159, 49)), (3, ContinuedFraction(649, 200)))\n        >>> tuple(cf.remainders)\n        ((3, ContinuedFraction(4, 1)), (2, ContinuedFraction(49, 4)), (1, ContinuedFraction(200, 49)), (0, ContinuedFraction(649, 200)))\n        >>> cf.truncate(12, 4)\n        >>> cf\n        ContinuedFraction(13, 4)\n        >>> cf.elements\n        (3, 4)\n        >>> cf.order\n        1\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)))\n        >>> tuple(cf.remainders)\n        ((1, ContinuedFraction(4, 1)), (0, ContinuedFraction(13, 4)))\n        >>> cf = ContinuedFraction(649, 200)\n        >>> cf.truncate(4, 12)\n        Traceback (most recent call last):\n        ...\n        ValueError: The elements/coefficients to be truncated from the tail must form a valid segment of the existing tail.\n        >>> cf.truncate(3, 4, 12, 4)\n        Traceback (most recent call last):\n        ...\n        ValueError: The elements/coefficients to be truncated from the tail must form a valid segment of the existing tail.\n        \"\"\"\n        pass\n\n    def __eq__(self, other, /) -> bool:\n        \"\"\"Custom equality check.\n\n        Compares the sequence of elements/coefficients of ``self`` with\n        that of ``other`` if ``other`` is also a\n        :py:class:`~continuedfractions.continuedfraction.ContinuedFraction`\n        instance, otherwise calls the superclass :py:class:`~fractions.Fraction`\n        equality check.\n\n        Returns\n        -------\n        bool\n            The boolean result of the equality check.\n        \"\"\"\n        pass\n\n    def __hash__(self) -> int:\n        \"\"\"Custom hash.\n\n        Custom hash which hashes the sequence of elements/coefficients - as\n        this is always defined as a finite, non-empty tuple the hash is\n        always defined.\n\n        Returns\n        -------\n        int\n            The hash of the\n            :py:class:`~continuedfractions.continuedfraction.ContinuedFraction`\n            instance.\n        \"\"\"\n        pass\n\n    def __add__(self, other, /):\n        pass\n\n    def __radd__(self, other, /):\n        pass\n\n    def __sub__(self, other, /):\n        pass\n\n    def __rsub__(self, other, /):\n        pass\n\n    def __mul__(self, other, /):\n        pass\n\n    def __rmul__(self, other, /):\n        pass\n\n    def __truediv__(self, other, /):\n        pass\n\n    def __rtruediv__(self, other, /):\n        pass\n\n    def __floordiv__(self, other, /):\n        pass\n\n    def __rfloordiv__(self, other, /):\n        pass\n\n    def __divmod__(self, other, /):\n        pass\n\n    def __rdivmod__(self, other, /):\n        pass\n\n    def __pow__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __rpow__(self, other, /):\n        pass\n\n    def __pos__(self) -> ContinuedFraction:\n        pass\n\n    def __neg__(self) -> ContinuedFraction:\n        \"\"\"\n        Division-free negation for a finite simple continued fraction, as\n        described `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/creating-continued-fractions.html#negative-continued-fractions>`_.\n\n        The basic algorithm can be described as follows: if\n        :math:`[a_0; a_1,\\\\ldots, a_n]` is the simple continued fraction of a\n        **positive** rational number :math:`\\\\frac{a}{b}` of finite order\n        :math:`n` then  :math:`-\\\\frac{a}{b}` has the simple continued\n        fraction:\n\n        .. math::\n\n           \\\\begin{cases}\n           [-a_0;]                                      \\\\hskip{3em} & n = 0 \\\\\\\\\n           [-(a_0 + 1); 2]                              \\\\hskip{3em} & n = 1 \\\\text{ and } a_1 = 2 \\\\\\\\\n           [-(a_0 + 1); a_2 + 1, a_3,\\\\ldots, a_n]      \\\\hskip{3em} & n \\\\geq 2 \\\\text{ and } a_1 = 1 \\\\\\\\\n           [-(a_0 + 1); 1, a_1 - 1, a_2, \\\\ldots,a_n]   \\\\hskip{3em} & n \\\\geq 2 \\\\text{ and } a_1 \\\\geq 2\n           \\\\end{cases}\n\n        In applying this algorithm there is an assumption that the last element\n        :math:`a_n > 1`, as any simple continued fraction of type\n        :math:`[a_0; a_1,\\\\ldots, a_{n} = 1]` can be reduced to the simple\n        continued fraction :math:`[a_0; a_1,\\\\ldots, a_{n - 1} + 1]`.\n        \"\"\"\n        pass\n\n    def __abs__(self) -> ContinuedFraction:\n        pass\n\n    def as_float(self) -> float:\n        \"\"\"Returns the :py:class:`float` value of the continued fraction.\n\n        Returns\n        -------\n        float\n            The :py:class:`float` value of the continued fraction.\n\n        Examples\n        --------\n        Note that the default :py:mod:`decimal` context precision of :math:`28`\n        is used in these examples.\n\n        >>> import math\n        >>> math.pi\n        3.141592653589793\n\n        Now construct a :py:class:`ContinuedFraction` instance from it, and check the \n        :py:class:`float` value.\n\n        >>> cf = ContinuedFraction(math.pi)\n        >>> cf\n        ContinuedFraction(884279719003555, 281474976710656)\n        >>> cf.as_float()\n        3.141592653589793\n        \"\"\"\n        pass\n\n    def as_decimal(self) -> Decimal:\n        \"\"\"Returns the :py:class:`decimal.Decimal` value of the continued fraction.\n\n        Returns\n        -------\n        decimal.Decimal\n            The :py:class:`decimal.Decimal` representation of the continued fraction.\n\n        Examples\n        --------\n        Note that the default :py:mod:`decimal` context precision of :math:`28`\n        is used in these examples.\n\n        >>> import math\n        >>> math.pi\n        3.141592653589793\n\n        Now construct a :py:class:`ContinuedFraction` instance from it, and check the \n        :py:class:`float` value.\n\n        >>> cf = ContinuedFraction(math.pi)\n        >>> cf\n        ContinuedFraction(884279719003555, 281474976710656)\n        >>> cf.as_decimal()\n        Decimal('3.141592653589793115997963469')\n        \"\"\"\n        pass\n\n    @property\n    def elements(self) -> tuple[int]:\n        \"\"\":py:class:`tuple`: The (ordered) sequence of elements of the continued fraction.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('.12345')\n        >>> cf\n        ContinuedFraction(2469, 20000)\n        >>> cf.elements\n        (0, 8, 9, 1, 21, 1, 1, 5)\n        \"\"\"\n        pass\n\n    @property\n    def order(self) -> int:\n        \"\"\":py:class:`int`: The order of the continued fraction, which is the number of its elements minus :math:`1`.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('.12345')\n        >>> cf\n        ContinuedFraction(2469, 20000)\n        >>> len(cf.elements)\n        8\n        >>> cf.order\n        7\n        \"\"\"\n        pass\n\n    @property\n    def counter(self) -> collections.Counter:\n        \"\"\":py:class:`collections.Counter` : A counter for the elements.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction(928374923, 8249234)\n        >>> cf.counter\n        Counter({1: 6, 2: 3, 24: 2, 112: 1, 5: 1, 3: 1})\n        \"\"\"\n        pass\n\n    @property\n    def khinchin_mean(self) -> Decimal | None:\n        \"\"\":py:class:`decimal.Decimal` or :py:data:`None`: The Khinchin mean of the continued fraction, which is defined as the geometric mean of all its elements after the 1st.\n\n        We define the Khinchin mean :math:`K_n` of a (simple) continued\n        fraction :math:`[a_0; a_1, a_2, \\\\ldots, a_n]` as:\n\n        .. math::\n\n           K_n := \\\\sqrt[n]{a_1a_2 \\\\cdots a_n} = \\\\left( a_1a_2 \\\\cdots a_n \\\\right)^{\\\\frac{1}{n}}, \\\\hskip{3em} n \\\\geq 1\n\n        This property is intended to make it easier to study the limit of\n        :math:`K_n` as :math:`n \\\\to \\\\infty`.  See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/exploring-continued-fractions.html#khinchin-means-khinchin-s-constant>`_\n        for more details.\n\n        In the special case of integers or fractions representing integers,\n        whose continued fraction representations consist of only a single\n        element, a null value is returned.\n\n        Examples\n        --------\n        Note that the default :py:mod:`decimal` context precision of :math:`28`\n        is used in these examples.\n\n        >>> ContinuedFraction(649, 200).elements\n        (3, 4, 12, 4)\n        >>> ContinuedFraction(649, 200).khinchin_mean\n        Decimal('5.76899828122963409526846589869819581508636474609375')\n        >>> ContinuedFraction(415, 93).elements\n        (4, 2, 6, 7)\n        >>> ContinuedFraction(415, 93).khinchin_mean\n        Decimal('4.37951913988788898990378584130667150020599365234375')\n        >>> (ContinuedFraction(649, 200) + ContinuedFraction(415, 93)).elements\n        (7, 1, 2, 2, 2, 1, 1, 11, 1, 2, 12)\n        >>> (ContinuedFraction(649, 200) + ContinuedFraction(415, 93)).khinchin_mean\n        Decimal('2.15015313349074244086978069390170276165008544921875')\n        >>> ContinuedFraction(5000).khinchin_mean\n\n        \"\"\"\n        pass\n\n    def convergent(self, k: int, /) -> ContinuedFraction:\n        \"\"\"Returns the :math:`k`-th (simple) convergent of the continued fraction.\n\n        Given a (simple) continued fraction  :math:`[a_0;a_1,a_2,\\\\ldots]` the\n        :math:`k`-th convergent is defined as:\n\n        .. math::\n\n           C_k = a_0 + \\\\cfrac{1}{a_1 + \\\\cfrac{1}{a_2 \\\\ddots \\\\cfrac{1}{a_{k-1} + \\\\cfrac{1}{a_k}}}}\n\n        The result is a :py:class:`~continuedfractions.continuedfraction.ContinuedFraction` instance.\n        \n        If  the continued fraction is of order :math:`n` then it has exactly\n        :math:`n + 1` convergents :math:`C_0,C_1,C_2,\\\\ldots,C_n` where\n        the :math:`k`-th convergent :math:`C_k = \\\\frac{p_k}{q_k}` is given by\n        the recurrence relation:\n\n        .. math::\n           \n           \\\\begin{align}\n           p_k &= a_kp_{k - 1} + p_{k - 2} \\\\\\\\\n           q_k &= a_kq_{k - 1} + q_{k - 2},        \\\\hskip{3em}    k \\\\geq 3\n           \\\\end{align}\n\n        where :math:`p_0 = a_0`, :math:`q_0 = 1`, :math:`p_1 = p_1p_0 + 1`,\n        and :math:`q_1 = p_1`.\n\n        Parameters\n        ----------\n        k : int\n            The index of the convergent, as described above.\n\n        Returns\n        -------\n        ContinuedFraction\n            A new :py:class:`ContinuedFraction` instance representing the :math:`k`-th\n            (simple) convergent of the original continued fraction, as\n            described above.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('.12345')\n        >>> cf\n        ContinuedFraction(2469, 20000)\n        >>> cf.convergent(0)\n        ContinuedFraction(0, 1)\n        >>> cf.convergent(2)\n        ContinuedFraction(9, 73)\n        >>> cf.convergent(6)\n        ContinuedFraction(448, 3629)\n        >>> cf.convergent(7)\n        ContinuedFraction(2469, 20000)\n        \"\"\"\n        pass\n\n    @property\n    def convergents(self) -> Generator[tuple[int, ContinuedFraction], None, None]:\n        \"\"\"Generates an enumerated sequence of all convergents of the continued fraction.\n\n        The convergents are generated as tuples of :py:class:`int` and\n        :py:class:`~continuedfraction.continuedfraction.ContinuedFraction`\n        instances, where the integers represent the indices of the convergents.\n\n        If :math:`n` is the order of the continued fraction then :math:`n + 1`\n        convergents :math:`C_0, C_1, \\\\ldots, C_n` are generated in that order.\n\n        Yields\n        ------\n        tuple\n            A tuple of convergent index (:py:class:`int`) and convergents\n            (:py:class:`~continuedfractions.continuedfraction.ContinuedFraction`)\n            of the continued fraction.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('3.245')\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)), (2, ContinuedFraction(159, 49)), (3, ContinuedFraction(649, 200)))\n        \"\"\"\n        pass\n\n    @property\n    def even_convergents(self) -> Generator[tuple[int, ContinuedFraction], None, None]:\n        \"\"\"Generates an enumerated sequence of all even-order convergents of the continued fraction.\n\n        The convergents are generated as tuples of :py:class:`int` and\n        :py:class:`~continuedfraction.continuedfraction.ContinuedFraction`\n        instances, where the integers represent the indices of the convergents.\n\n        If :math:`n` is the order of the continued fraction then only the even-\n        indexed convergents :math:`C_0, C_2, C_4, \\\\ldots` are generated.\n\n        Yields\n        ------\n        tuple\n            A tuple of convergent index (:py:class:`int`) and convergents\n            (:py:class:`~continuedfractions.continuedfraction.ContinuedFraction`)\n            of the continued fraction.\n\n        Examples\n        --------\n        >>> tuple(ContinuedFraction('3.245').even_convergents)\n        ((0, ContinuedFraction(3, 1)), (2, ContinuedFraction(159, 49)))\n        \"\"\"\n        pass\n\n    @property\n    def odd_convergents(self) -> Generator[tuple[int, ContinuedFraction], None, None]:\n        \"\"\"Generates an enumerated sequence of all odd-order convergents of the continued fraction.\n\n        The convergents are generated as tuples of :py:class:`int` and\n        :py:class:`~continuedfraction.continuedfraction.ContinuedFraction`\n        instances, where the integers represent the indices of the convergents.\n\n        If :math:`n` is the order of the continued fraction then only the odd-\n        indexed convergents :math:`C_1, C_3, C_5, \\\\ldots` are generated.\n\n        Yields\n        ------\n        tuple\n            A tuple of convergent index (:py:class:`int`) and convergents\n            (:py:class:`~continuedfractions.continuedfraction.ContinuedFraction`)\n            of the continued fraction.\n\n        Examples\n        --------\n        >>> tuple(ContinuedFraction('3.245').odd_convergents)\n        ((1, ContinuedFraction(13, 4)), (3, ContinuedFraction(649, 200)))\n        \"\"\"\n        pass\n\n    def semiconvergent(self, k: int, m: int, /) -> ContinuedFraction:\n        \"\"\"Returns the :math:`m`-th semiconvergent of two consecutive convergents :math:`p_{k - 1}` and :math:`p_k` of the continued fraction.\n\n        The integer :math:`k` must be positive and determine two consecutive\n        convergents :math:`p_{k - 1}` and :math:`p_k` of a (finite, simple)\n        continued fraction.\n\n        The integer :math:`m` can be any positive integer.\n\n        Parameters\n        ----------\n        k : int\n            The integer :math:`k` determining two consecutive convergents\n            :math:`p_{k - 1}` and :math:`p_k` of a (finite, simple) continued\n            fraction\n            :math:`[a_0; a_1, \\\\ldots, a_{k}, a_{k + 1}, \\\\ldots, a_n]`.\n\n        m : int\n            The index of the semiconvergent of the convergents\n            :math:`p_{k - 1}` and :math:`p_k`.\n\n        Returns\n        -------\n        ContinuedFraction\n            The :math:`m`-th semiconvergent of the convergents\n            :math:`p_{k - 1}` and :math:`p_k`.\n\n        Raises\n        ------\n        ValueError\n            If :math:`k` or :math:`m` are not positive integers, or :math:`k`\n            is an integer that does **not** satisfy :math:`1 \\\\leq k \\\\leq n`\n            where :math:`n` is the order of the (finite, simple) continued\n            fraction of which :math:`p_{k - 1}` and :math:`p_k` are\n            convergents.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction(-415, 93)\n        >>> cf.elements\n        (-5, 1, 1, 6, 7)\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(-5, 1)), (1, ContinuedFraction(-4, 1)), (2, ContinuedFraction(-9, 2)), (3, ContinuedFraction(-58, 13)), (4, ContinuedFraction(-415, 93)))\n        >>> cf.semiconvergent(3, 1)\n        ContinuedFraction(-67, 15)\n        >>> cf.semiconvergent(3, 2)\n        ContinuedFraction(-125, 28)\n        >>> cf.semiconvergent(3, 3)\n        ContinuedFraction(-183, 41)\n        >>> cf.semiconvergent(3, 4)\n        ContinuedFraction(-241, 54)\n        >>> cf.semiconvergent(3, 5)\n        ContinuedFraction(-299, 67)\n        >>> cf.semiconvergent(3, 6)\n        ContinuedFraction(-357, 80)\n        >>> cf.semiconvergent(3, 7)\n        ContinuedFraction(-415, 93)\n        \"\"\"\n        pass\n\n    def remainder(self, k: int, /) -> ContinuedFraction:\n        \"\"\"Returns the :math:`k`-th remainder of the continued fraction.\n\n        Given a (simple) continued fraction  :math:`[a_0;a_1,a_2,\\\\ldots]` the\n        :math:`k`-th remainder :math:`R_k` is the (simple) continued fraction\n        :math:`[a_k; a_{k + 1}, a_{k + 2}, \\\\ldots]`:\n\n        .. math::\n\n           R_k = a_k + \\\\cfrac{1}{a_{k + 1} + \\\\cfrac{1}{a_{k + 2} \\\\ddots }}\n\n        where :math:`R_0` is just the original continued fraction, i.e.\n        :math:`R_0 = [a_0; a_1, a_2, \\\\ldots]`.\n\n        The result is a :py:class:`~continuedfractions.continuedfraction.ContinuedFraction` instance.\n\n        The remainders satisfy the recurrence relation:\n\n        .. math::\n\n           R_{k - 1} = a_{k - 1} + \\\\frac{1}{R_k}, \\\\hskip{3em} k \\\\geq 1\n\n        If the original continued fraction is finite then its remainders are all\n        finite and rational.\n\n        As this class implements finite simple continued fractions, this method\n        always produces rational numbers.\n\n        The integer :math:`k` must be non-negative and cannot exceed the order\n        of the continued fraction, i.e. the number of its tail elements, and \n        the tail elements must define a valid finite simple continued fraction.\n\n        Parameters\n        ----------\n        k : int\n            The index of the remainder, as described above.\n\n        Returns\n        -------\n        ContinuedFraction\n            A new :py:class:`ContinuedFraction` instance representing the :math:`k`-th\n            remainder of the original continued fraction, as described above.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('.12345')\n        >>> cf\n        ContinuedFraction(2469, 20000)\n        >>> cf.remainder(0)\n        ContinuedFraction(2469, 20000)\n        >>> cf.remainder(2)\n        ContinuedFraction(2469, 248)\n        >>> cf.remainder(6)\n        ContinuedFraction(6, 5)\n        >>> cf.remainder(7)\n        ContinuedFraction(5, 1)\n        \"\"\"\n        pass\n\n    @property\n    def remainders(self) -> Generator[tuple[int, ContinuedFraction], None, None]:\n        \"\"\"Generates an enumerated sequence of all remainders of the continued fraction in descending order of index.\n\n        If :math:`n` is the order of the continued fraction then there are\n        :math:`n + 1` remainders :math:`R_0, R_1, \\\\ldots, R_n`, and the method\n        generates these in reverse order :math:`R_0, R_1, \\\\ldots, R_n`.\n\n        See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/exploring-continued-fractions.html#remainders>`_\n        for more details on remainders.\n\n        The remainders are generated as tuples of :py:class:`int`\n        and :py:class:`~continuedfraction.continuedfraction.ContinuedFraction`\n        instances, where the integers represent the indexes of the remainders.\n\n        Yields\n        ------\n        tuple\n            A tuple of remainder indices (:py:class:`int`) and remainders\n            (:py:class:`~continuedfractions.continuedfraction.ContinuedFraction`)\n            of the continued fraction.\n\n        Examples\n        --------\n        >>> tuple(ContinuedFraction('3.245').remainders)\n        ((3, ContinuedFraction(4, 1)), (2, ContinuedFraction(49, 4)), (1, ContinuedFraction(200, 49)), (0, ContinuedFraction(649, 200)))\n        >>> tuple(ContinuedFraction(-415, 93).remainders)\n        ((4, ContinuedFraction(7, 1)), (3, ContinuedFraction(43, 7)), (2, ContinuedFraction(50, 43)), (1, ContinuedFraction(93, 50)), (0, ContinuedFraction(-415, 93)))\n        \"\"\"\n        pass\n\n    def left_mediant(self, other: Fraction, /, *, k: int = 1) -> ContinuedFraction:\n        \"\"\"Returns the :math:`k`-th left-mediant of the continued fraction with another rational number.\n        \n        For a positive integer :math:`k`, the :math:`k`-th left-mediant of two\n        rational numbers :math:`r = \\\\frac{a}{b}` and :math:`s = \\\\frac{c}{d}`,\n        where :math:`b, d, b + d \\\\neq 0`, is defined as:\n        \n        .. math::\n\n           \\\\frac{ka + c}{kb + d}, \\\\hskip{3em}    k \\\\geq 1\n\n        while the :math:`k`-th right mediant is defined as:\n        \n        .. math::\n\n           \\\\frac{a + kc}{b + kd}, \\\\hskip{3em}    k \\\\geq 1\n\n        If we assume that :math:`r < s` and :math:`bd > 0` then these mediants\n        have the property that:\n       \n        .. math::\n\n           \\\\frac{a}{b} < \\\\frac{ka + c}{kb + d} \\\\leq \\\\frac{a + kc}{b + kd} < \\\\frac{c}{d},   \\\\hskip{3em} k \\\\geq 1\n\n        where equality holds for :math:`k = 1`. If we let :math:`k \\\\to \\\\infty`\n        then the mediants converge to opposite limits:\n\n        .. math::\n\n          \\\\begin{align}\n          \\\\lim_{k \\\\to \\\\infty} \\\\frac{ka + c}{kb + d} &= \\\\frac{a}{b} \\\\\\\\\n          \\\\lim_{k \\\\to \\\\infty} \\\\frac{a + kc}{b + kd} &= \\\\frac{c}{d}\n          \\\\end{align}\n\n        For more information consult the\n        `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/mediants.html>`_.\n\n        The method is cached (with :py:func:`functools.cache`), which makes calls\n        after the initial call much faster.\n\n        Parameters\n        ----------\n        other : fractions.Fraction, ContinuedFraction\n            The second fraction to use to calculate the :math:`k`-th mediant with\n            the first.\n        \n        k : int, default=1\n            The order of the mediant, as defined above.        \n\n        Returns\n        -------\n        ContinuedFraction\n            The :math:`k`-th left-mediant of the original fraction and the second\n            fraction, as a :py:class:`ContinuedFraction` instance.\n\n        Examples\n        --------\n        >>> c1 = ContinuedFraction('1/2')\n        >>> c2 = ContinuedFraction(3, 5)\n        >>> c1, c2\n        (ContinuedFraction(1, 2), ContinuedFraction(3, 5))\n        >>> c1.left_mediant(c2)\n        ContinuedFraction(4, 7)\n        >>> c1.left_mediant(c2, k=2)\n        ContinuedFraction(5, 9)\n        >>> c1.left_mediant(c2, k=3)\n        ContinuedFraction(6, 11)\n        >>> c1.left_mediant(c2, k=100)\n        ContinuedFraction(103, 205)\n        >>> assert c1.left_mediant(c2, k=2) < c1.right_mediant(c2, k=2)\n        >>> assert c1.left_mediant(c2, k=3) < c1.right_mediant(c2, k=3)\n        >>> assert c1.left_mediant(c2, k=100) < c1.right_mediant(c2, k=100)\n        \"\"\"\n        pass\n\n    def right_mediant(self, other: Fraction, /, *, k: int = 1) -> ContinuedFraction:\n        \"\"\"Returns the :math:`k`-th right-mediant of the continued fraction with another rational number.\n        \n        For a positive integer :math:`k`, the :math:`k`-th right-mediant of two\n        rational numbers :math:`r = \\\\frac{a}{b}` and :math:`s = \\\\frac{c}{d}`,\n        where :math:`b, d, b + d \\\\neq 0`, is defined as:\n        \n        .. math::\n\n           \\\\frac{a + kc}{b + kd}, \\\\hskip{3em}    k \\\\geq 1\n\n        while the :math:`k`-th left-mediant is defined as:\n        \n        .. math::\n\n           \\\\frac{ka + c}{kb + d}, \\\\hskip{3em}    k \\\\geq 1\n\n        If we assume that :math:`r < s` and :math:`bd > 0` then these mediants\n        have the property that:\n       \n        .. math::\n\n           \\\\frac{a}{b} < \\\\frac{ka + c}{kb + d} \\\\leq \\\\frac{a + kc}{b + kd} < \\\\frac{c}{d},   \\\\hskip{3em} k \\\\geq 1\n\n        where equality holds for :math:`k = 1`. If we let :math:`k \\\\to \\\\infty`\n        then the mediants converge to opposite limits:\n\n        .. math::\n\n          \\\\begin{align}\n          \\\\lim_{k \\\\to \\\\infty} \\\\frac{ka + c}{kb + d} &= \\\\frac{a}{b} \\\\\\\\\n          \\\\lim_{k \\\\to \\\\infty} \\\\frac{a + kc}{b + kd} &= \\\\frac{c}{d}\n          \\\\end{align}\n\n        For more information consult the\n        `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/mediants.html>`_.\n\n        Parameters\n        ----------\n        other : fractions.Fraction, ContinuedFraction\n            The second fraction to use to calculate the :math:`k`-th mediant with\n            the first.\n        \n        k : int, default=1\n            The order of the mediant, as defined above.        \n\n        Returns\n        -------\n        ContinuedFraction\n            The :math:`k`-th right-mediant of the original fraction and the second\n            fraction, as a :py:class:`ContinuedFraction` instance.\n\n        Examples\n        --------\n        >>> c1 = ContinuedFraction('1/2')\n        >>> c2 = ContinuedFraction(3, 5)\n        >>> c1, c2\n        (ContinuedFraction(1, 2), ContinuedFraction(3, 5))\n        >>> c1.right_mediant(c2)\n        ContinuedFraction(4, 7)\n        >>> c1.right_mediant(c2, k=2)\n        ContinuedFraction(7, 12)\n        >>> c1.right_mediant(c2, k=3)\n        ContinuedFraction(10, 17)\n        >>> c1.right_mediant(c2, k=100)\n        ContinuedFraction(301, 502)\n        >>> assert c1.left_mediant(c2, k=2) < c1.right_mediant(c2, k=2)\n        >>> assert c1.left_mediant(c2, k=3) < c1.right_mediant(c2, k=3)\n        >>> assert c1.left_mediant(c2, k=100) < c1.right_mediant(c2, k=100)\n        \"\"\"\n        pass\n\n    def mediant(self, other: Fraction, /) -> ContinuedFraction:\n        \"\"\"Returns the simple mediant of the continued fraction with another continued fraction.\n        \n        The simple mediant of two rational numbers :math:`r = \\\\frac{a}{b}`\n        and :math:`s = \\\\frac{c}{d}`, where :math:`b, d, b + d \\\\neq 0`, is\n        defined as:\n        \n        .. math::\n\n           \\\\frac{a + c}{b + d}\n\n        The resulting value :math:`\\\\frac{a + c}{b + d}` is the same as the\n        1st order left- or right-mediant of :math:`r = \\\\frac{a}{b}`\n        and :math:`s = \\\\frac{c}{d}`. So this method would produce the same\n        result as the :py:meth:`~continuedfractions.continuedfraction.ContinuedFraction.left_mediant`\n        or :py:meth:`~continuedfractions.continuedfraction.ContinuedFraction.right_mediant`\n        methods where the order :math:`k` is set to :math:`1`.\n\n        For more information consult the\n        `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/mediants.html>`_.\n\n        Parameters\n        ----------\n        other : fractions.Fraction, ContinuedFraction\n            The other continued fraction.\n        \n        Returns\n        -------\n        ContinuedFraction\n            The simple mediant of the original fraction and the other continued\n            fraction.\n\n        Examples\n        --------\n        >>> ContinuedFraction(1, 2).mediant(ContinuedFraction(3, 5))\n        ContinuedFraction(4, 7)\n        >>> assert ContinuedFraction(1, 2).mediant(ContinuedFraction(3, 5)) == ContinuedFraction(1, 2).left_mediant(ContinuedFraction(3, 5), k=1)\n        >>> assert ContinuedFraction(1, 2).mediant(ContinuedFraction(3, 5)) == ContinuedFraction(1, 2).right_mediant(ContinuedFraction(3, 5), k=1)\n        \"\"\"\n        pass\n```\n--- File: src/continuedfractions/sequences.py ---\n```python\ndef coprime_integers_generator(n: int, /, *, start: int = 1, stop: int = None) -> Generator[int, None, None]:\n    \"\"\"Generates a sequence of (positive) integers :math:`1 \\\\leq m < n` coprime to a given positive integer :math:`n`.\n\n    The tuple is sorted in descending order of magnitude.\n\n    The optional ``start`` and ``stop`` parameters can be used to bound the\n    the range of (positive) integers in which integers coprime to the given\n    :math:`n` are sought.\n\n    For :math:`n = 1, 2` the ``start`` value is effectively ignored, but\n    if :math:`n > 1` then the ``start`` value must be an integer in the range\n    :math:`1..n - 1`.\n\n    The ``stop`` value defaults to ``None``, which is then internally\n    initialised to :math:`n`; if :math:`n > 1` and ``stop`` is given then it\n    must be an integer in the range :math:`\\\\text{start} + 1..n`.\n\n    Parameters\n    ----------\n    n : int\n        The positive integer for which (positive) coprime integers\n        :math:`m < n` are sought.\n\n    start : int, default=1\n        The lower bound of the range of (positive) integers in which integers\n        coprime to the given :math:`n` are sought. For :math:`n = 1, 2` the\n        ``start`` value is effectively ignored, but if :math:`n > 1` then the\n        ``start`` value must be in the range :math:`1..n - 1`.\n\n    stop : int, default=None\n        The upper bound of the range of (positive) integers in which integers\n        coprime to the given :math:`n` are sought. The ``stop`` value defaults\n        to ``None``, which is then internally initialised to :math:`n`; if\n        :math:`n > 1` and ``stop`` is given then it must be an integer in the\n        range :math:`\\\\text{start} + 1..n`.\n\n    Raises\n    ------\n    ValueError\n        If :math:`n` is either not a positive integer, or :math:`n > 1` such\n        that either the ``start`` value is **not** in the range\n        :math:`1..n - 1` or the ``stop`` value is **not** in the range\n        :math:`\\\\text{start} + 1..n`.\n\n    Yields\n    ------\n    int\n        A sequence of (positive) integers :math:`1 \\\\leq m < n` coprime to a\n        given positive integer :math:`n`.\n\n    Examples\n    --------\n    Examples using the default ``start`` and ``stop`` values:\n\n    >>> tuple(coprime_integers_generator(1))\n    (1,)\n    >>> tuple(coprime_integers_generator(2))\n    (1,)\n    >>> tuple(coprime_integers_generator(3))\n    (2, 1)\n    >>> tuple(coprime_integers_generator(4))\n    (3, 1)\n    >>> tuple(coprime_integers_generator(5))\n    (4, 3, 2, 1)\n    >>> tuple(coprime_integers_generator(6))\n    (5, 1)\n    >>> tuple(coprime_integers_generator(7))\n    (6, 5, 4, 3, 2, 1)\n    >>> tuple(coprime_integers_generator(8))\n    (7, 5, 3, 1)\n    >>> tuple(coprime_integers_generator(9))\n    (8, 7, 5, 4, 2, 1)\n    >>> tuple(coprime_integers_generator(10))\n    (9, 7, 3, 1)\n    >>> tuple(coprime_integers_generator(11))\n    (10, 9, 8, 7, 6, 5, 4, 3, 2, 1)\n\n    Examples using custom ``start`` and ``stop`` values:\n\n    >>> tuple(coprime_integers_generator(3, start=0))\n    Traceback (most recent call last):\n    ...\n    ValueError: `n` must be a positive integer; if `n` > 1 then the `start` value must be a positive integer in the range 1..n - 1; and if given the `stop` value must be a positive integer in the range `start` + 1..n\n    >>> tuple(coprime_integers_generator(3, start=2))\n    (2,)\n    >>> tuple(coprime_integers_generator(3, start=3))\n    Traceback (most recent call last):\n    ...\n    ValueError: `n` must be a positive integer; if `n` > 1 then the `start` value must be a positive integer in the range 1..n - 1; and if given the `stop` value must be a positive integer in the range `start` + 1..n\n    >>> tuple(coprime_integers_generator(23, start=5, stop=21))\n    (21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5)\n    >>> tuple(coprime_integers_generator(5, start=2))\n    (4, 3, 2)\n    >>> tuple(coprime_integers_generator(5, start=3))\n    (4, 3)\n    >>> tuple(coprime_integers_generator(6, start=2))\n    (5,)\n    >>> tuple(coprime_integers_generator(6, start=3))\n    (5,)\n    >>> tuple(coprime_integers_generator(6, start=4))\n    (5,)\n    >>> tuple(coprime_integers_generator(7, start=2))\n    (6, 5, 4, 3, 2)\n    >>> tuple(coprime_integers_generator(7, start=3))\n    (6, 5, 4, 3)\n    >>> tuple(coprime_integers_generator(7, start=4))\n    (6, 5, 4)\n    >>> tuple(coprime_integers_generator(7, start=5))\n    (6, 5)\n    \"\"\"\n    pass\n\ndef coprime_integers(n: int, /, *, start: int = 1, stop: int = None) -> tuple[int]:\n    \"\"\"Returns a sequence of (positive) integers :math:`1 \\\\leq m < n` coprime to a given positive integer :math:`n`.\n\n    Wrapper of :py:class:`~continuedfractions.sequences.coprime_integers_generator`.\n\n    The tuple is sorted in descending order of magnitude.\n\n    The optional ``start`` and ``stop`` parameters can be used to bound the\n    the range of (positive) integers in which integers coprime to the given\n    :math:`n` are sought.\n\n    For :math:`n = 1, 2` the ``start`` value is effectively ignored, but\n    if :math:`n > 1` then the ``start`` value must be an integer in the range\n    :math:`1..n - 1`.\n\n    The ``stop`` value defaults to ``None``, which is then internally\n    initialised to :math:`n`; if :math:`n > 1` and ``stop`` is given then it\n    must be an integer in the range :math:`\\\\text{start} + 1..n`.\n\n    Parameters\n    ----------\n    n : int\n        The positive integer for which (positive) coprime integers\n        :math:`m < n` are sought.\n\n    start : int, default=1\n        The lower bound of the range of (positive) integers in which integers\n        coprime to the given :math:`n` are sought. For :math:`n = 1, 2` the\n        ``start`` value is effectively ignored, but if :math:`n > 1` then the\n        ``start`` value must be in the range :math:`1..n - 1`.\n\n    stop : int, default=None\n        The upper bound of the range of (positive) integers in which integers\n        coprime to the given :math:`n` are sought. The ``stop`` value defaults\n        to ``None``, which is then internally initialised to :math:`n`; if\n        :math:`n > 1` and ``stop`` is given then it must be an integer in the\n        range :math:`\\\\text{start} + 1..n`.\n\n    Returns\n    -------\n    tuple\n        A sequence of (positive) integers :math:`1 \\\\leq m < n` coprime to a\n        given positive integer :math:`n`.\n\n    Examples\n    --------\n    Examples using the default ``start`` and ``stop`` values:\n\n    >>> coprime_integers(1)\n    (1,)\n    >>> coprime_integers(2)\n    (1,)\n    >>> coprime_integers(3)\n    (2, 1)\n    >>> coprime_integers(4)\n    (3, 1)\n    >>> coprime_integers(5)\n    (4, 3, 2, 1)\n    >>> coprime_integers(6)\n    (5, 1)\n    >>> coprime_integers(7)\n    (6, 5, 4, 3, 2, 1)\n    >>> coprime_integers(8)\n    (7, 5, 3, 1)\n    >>> coprime_integers(9)\n    (8, 7, 5, 4, 2, 1)\n    >>> coprime_integers(10)\n    (9, 7, 3, 1)\n    >>> coprime_integers(11)\n    (10, 9, 8, 7, 6, 5, 4, 3, 2, 1)\n\n    Examples using custom ``start`` and ``stop`` values:\n\n    >>> coprime_integers(3, start=2)\n    (2,)\n    >>> coprime_integers(3, start=3)\n    Traceback (most recent call last):\n    ...    \n    ValueError: `n` must be a positive integer; if `n` > 1 then the `start` value must be a positive integer in the range 1..n - 1; and if given the `stop` value must be a positive integer in the range `start` + 1..n\n    >>> coprime_integers(23, start=5, stop=21)\n    (21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5)\n    >>> coprime_integers(5, start=2)\n    (4, 3, 2)\n    >>> coprime_integers(5, start=3)\n    (4, 3)\n    >>> coprime_integers(6, start=2)\n    (5,)\n    >>> coprime_integers(6, start=3)\n    (5,)\n    >>> coprime_integers(6, start=4)\n    (5,)\n    >>> coprime_integers(7, start=2)\n    (6, 5, 4, 3, 2)\n    >>> coprime_integers(7, start=3)\n    (6, 5, 4, 3)\n    >>> coprime_integers(7, start=4)\n    (6, 5, 4)\n    >>> coprime_integers(7, start=5)\n    (6, 5)\n    \"\"\"\n    pass\n\nclass KSRMTree:\n    \"\"\"An implicit/generative class implementation of the Kanga-Saunders-Randall-Mitchell (KSRM) ternary trees for representing and generating pairs of all (positive) coprime integers.\n\n    The term \"KSRM trees\" is the author's, and refers to the trees presented in the following papers:\n\n    * Kanga, A. R. (1990). The Family Tree of Pythagorean Triplets. The Mathematical Gazette, 26(15), 15-17.\n    * Mitchell, D. W. (2001). An Alternative Characterisation of All Primitive Pythagorean Triples. The Mathematical Gazette, 85(503), 273-275. https://doi.org/10.2307/3622017\n    * Saunders, R., & Randall, T. (1994). The family tree of the Pythagorean triplets revisited. The Mathematical Gazette, 78(482), 190-193. https://doi.org/10.2307/3618576\n\n    .. note::\n\n       The class is named ``KSRMTree`` purely for convenience, but it is\n       actually a representation of two (ternary) subtrees.\n\n    .. note::\n\n       The author could not access the Kanga paper online, but the core result\n       is described clearly in the papers of Saunders and Randall, and of\n       Mitchell.\n\n    See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/sequences.html#ksrm-trees>`_\n    for more details.\n    \"\"\"\n    def __new__(cls) -> KSRMTree:\n        \"\"\"Class constructor.\n\n        Creates and initialises a new instance with the minimum set of required\n        attributes - for the roots and branch generating functions, which we\n        call branches.\n        \"\"\"\n        pass\n\n    @property\n    def roots(self) -> Literal[tuple([(2, 1), (3, 1)])]:\n        \"\"\":py:class:`tuple`: The tuple of roots of the KSRM trees, which are :math:`(2, 1)` and :math:`(3, 1)`.\n\n        For more details see the following papers:\n\n        * Kanga, A. R. (1990). The Family Tree of Pythagorean Triplets. The Mathematical Gazette, 26(15), 15-17.\n        * Mitchell, D. W. (2001). An Alternative Characterisation of All Primitive Pythagorean Triples. The Mathematical Gazette, 85(503), 273-275. https://doi.org/10.2307/3622017\n        * Saunders, R., & Randall, T. (1994). The family tree of the Pythagorean triplets revisited. The Mathematical Gazette, 78(482), 190-193. https://doi.org/10.2307/3618576\n\n        or the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/sequences.html#ksrm-trees>`_.\n\n        Examples\n        --------\n        >>> KSRMTree().roots\n        ((2, 1), (3, 1))\n        \"\"\"\n        pass\n\n    @property\n    def branches(self) -> tuple[KSRMBranch]:\n        \"\"\":py:class:`tuple`: The tuple of three branch generating functions of the KSRM trees.\n\n        There are three branch generating functions, given by the mappings:\n\n        .. math::\n\n           \\\\begin{align}\n           (a, b) &\\\\longmapsto (2a - b, a) \\\\\\\\\n           (a, b) &\\\\longmapsto (2a + b, a) \\\\\\\\\n           (a, b) &\\\\longmapsto (a + 2b, b)\n           \\\\end{align}\n\n        For more details see the following papers:\n\n        * Kanga, A. R. (1990). The Family Tree of Pythagorean Triplets. The Mathematical Gazette, 26(15), 15-17.\n        * Mitchell, D. W. (2001). An Alternative Characterisation of All Primitive Pythagorean Triples. The Mathematical Gazette, 85(503), 273-275. https://doi.org/10.2307/3622017\n        * Saunders, R., & Randall, T. (1994). The family tree of the Pythagorean triplets revisited. The Mathematical Gazette, 78(482), 190-193. https://doi.org/10.2307/3618576\n\n        or the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/sequences.html#ksrm-trees>`_.\n\n        Examples\n        --------\n        Generating the first two generations of children for the parent\n        :math:`(2, 1)`.\n\n        >>> tree = KSRMTree()\n        >>> tree.branches\n        (NamedCallableProxy(\"KSRM tree branch #1: (x, y) |--> (2x - y, x)\"), NamedCallableProxy(\"KSRM tree branch #2: (x, y) |--> (2x + y, x)\"), NamedCallableProxy(\"KSRM tree branch #3: (x, y) |--> (x + 2y, y)\"))\n        >>> tree.branches[0](2, 1)\n        (3, 2)\n        >>> tree.branches[1](2, 1)\n        (5, 2)\n        >>> tree.branches[2](2, 1)\n        (4, 1)\n        >>> tree.branches[0](*tree.branches[0](2, 1))\n        (4, 3)\n        >>> tree.branches[1](*tree.branches[0](2, 1))\n        (8, 3)\n        >>> tree.branches[2](*tree.branches[0](2, 1))\n        (7, 2)\n        >>> tree.branches[0](*tree.branches[1](2, 1))\n        (8, 5)\n        >>> tree.branches[1](*tree.branches[1](2, 1))\n        (12, 5)\n        >>> tree.branches[2](*tree.branches[1](2, 1))\n        (9, 2)\n        >>> tree.branches[0](*tree.branches[2](2, 1))\n        (7, 4)\n        >>> tree.branches[1](*tree.branches[2](2, 1))\n        (9, 4)\n        >>> tree.branches[2](*tree.branches[2](2, 1))\n        (6, 1)\n        \"\"\"\n        pass\n\n    def _backtrack( self, n: int, visited: list[tuple[KSRMNode, KSRMBranch]], /, *, node_bound: int = None ) -> tuple[KSRMNode, KSRMBranch, int, KSRMBranch]:\n        \"\"\"Backtracks on the KSRM coprime pairs trees from a failed node to the nearest previously visited node that satisfies the node bound.\n\n        A private function that backtracks on the KSRM coprime pairs trees: the\n        procedure is that, given a (positive) integer :math:`n > 2`, for which\n        coprime pairs are being sought, and a sequence (list) of pairs of\n        visited nodes and their associated generating branches in the KSRM\n        tree, and assuming that the last element of the visited sequence\n        contains the node that \"failed\", the function identifies the nearest\n        previously visited node whose first component satisifes the test\n        :math:`< n` **and** and whose associated generating branch is not equal\n        to the third branch given by :math:`(x, y) \\\\longmapsto (x + 2y, y)`.\n\n        .. note::\n\n           The function assumes that the last node in the incoming sequence\n           of visited nodes and generating branch pairs represents a \"failed\"\n           node, i.e. whose first component failed the test :math:`\\\\leq n`\n           during the search. No attempt is made to validate or verify the\n           failed node, and the only purpose of the function is to backtrack\n           to the nearest previously visited node which meets the requirements\n           listed above.\n\n        .. note::\n\n           There is no input validation as this is a private function which\n           will be called from\n           :py:meth:`~continuedfractions.sequences.KSRMTree.search_root`. So\n           results for invalid arguments will most likely be incorrect or\n           unexpected.\n\n        Parameters\n        ----------\n        n : int\n            The (positive) integer :math:`> 2` which is passed by the root\n            search method or the general tree search method.\n\n        visited : list\n            A sequence of visited nodes and associated generating branches in\n            the KSRM coprime pairs tree.\n\n        node_bound : int, default=None\n            A bound to check that :math:`a < n` for a node :math:`(a, b)`. The\n            actual default value is the incoming :math:`n`, and this is set\n            internally.\n\n        Returns\n        -------\n        tuple\n            A tuple consisting of the following values in order: (1) the\n            target node in the visited sequence to backtrack to, (2) the\n            associated generating branch function (the lambda for branch #1,\n            or branch #2, or branch #3), (3) the index of the target node\n            and branch pair in the visited sequence, (4) the generating\n            branch of the successor node of the target node returned as (1).\n\n        Examples\n        --------\n        An example where :math:`n = 5` and the failed node is :math:`(6, 1)`,\n        which was the successor node to :math:`(4, 1)` from the third branch.\n\n        >>> tree = KSRMTree()\n        >>> tree.branches\n        (NamedCallableProxy(\"KSRM tree branch #1: (x, y) |--> (2x - y, x)\"), NamedCallableProxy(\"KSRM tree branch #2: (x, y) |--> (2x + y, x)\"), NamedCallableProxy(\"KSRM tree branch #3: (x, y) |--> (x + 2y, y)\"))\n        >>> visited = [((2, 1), None), ((4, 1), tree.branches[-1]), ((6, 1), tree.branches[-1])]\n        >>> tree._backtrack(5, visited)\n        ((2, 1), None, 0, NamedCallableProxy(\"KSRM tree branch #3: (x, y) |--> (x + 2y, y)\"))\n\n        An example where :math:`n = 8` and the failed node is :math:`(19, 8)`,\n        which was the successor node to :math:`(8, 3)` from the first branch.\n\n        >>> tree = KSRMTree()\n        >>> tree.branches\n        (NamedCallableProxy(\"KSRM tree branch #1: (x, y) |--> (2x - y, x)\"), NamedCallableProxy(\"KSRM tree branch #2: (x, y) |--> (2x + y, x)\"), NamedCallableProxy(\"KSRM tree branch #3: (x, y) |--> (x + 2y, y)\"))\n        >>> visited = [((2, 1), None), ((3, 2),tree.branches[0]), ((8, 3),tree.branches[1]), ((19, 8), tree.branches[0])]\n        >>> tree._backtrack(8, visited)\n        ((3, 2), NamedCallableProxy(\"KSRM tree branch #1: (x, y) |--> (2x - y, x)\"), 1, NamedCallableProxy(\"KSRM tree branch #2: (x, y) |--> (2x + y, x)\"))\n        \"\"\"\n        pass\n\n    def search_root(self, n: int, root: KSRMNode, /) -> Generator[KSRMNode, None, None]:\n        \"\"\"Depth-first branch-and-bound generative search function (in pre-order, NLMR), with backtracking and pruning, on the KSRM coprime pairs trees, starting from the given root node.\n\n        The given root node need not be the canonical roots, :math:`(2, 1)`,\n        :math:`(3, 1)`, but can be any of their successor nodes.\n\n        It is required that :math:`n \\\\geq 2`, otherwise a\n        :py:class:`ValueError` is raised.\n\n        The search implementation is an iterative version of a depth-first\n        branch-and-bound search (DFS) procedure, with backtracking and pruning,\n        in which nodes are traversed in NLMR pre-order (root -> left -> mid ->\n        right) and bounds and checks are applied to the nodes, including\n        pruning failed or unnecessary nodes, before further traversal or\n        backtracking:\n        \n        #. Visit the current node :math:`(a, b)` and check :math:`a \\\\leq n`.\n        #. If the check is successful iteratively traverse the current node's\n           first child and its children, then the second child and its \n           children, and then the third child and its children, applying the\n           check :math:`a \\\\leq n` to each visited node.\n        #. If a check fails for any node backtrack to the nearest previously\n           visited node which meets a stricter check :math:`a < n` and which\n           has unvisited child nodes, while pruning all visited intermediate\n           nodes after the backtracked target node and leading up to the failed\n           node, including the failed node. By design the backtracked target\n           node will have untraversed children on at least one branch, and the\n           traversal can begin again, as described above.\n\n        Parameters\n        ----------\n        n : int\n            The positive integer for which coprime pairs :math:`(a, b)`, with\n            :math:`1 \\\\leq b < a \\\\leq n`, are sought.\n\n        root : tuple\n            The \"root\" node from which to search - this can be either of the\n            canonical roots, :math:`(2, 1)`, :math:`(3, 1)`, but also any of\n            their successor nodes.\n\n        Raises\n        ------\n        ValueError\n            If ``n`` is not an integer or is :math:`< 2`.\n\n        Yields\n        ------\n        tuple\n            Pairs of coprime integers :math:`(a, b)`, with\n            :math:`1 \\\\leq b < a \\\\leq n`.\n\n        Examples\n        --------\n        Searching from the root :math:`(2, 1)` for coprime pairs for\n        :math:`n = 5`:\n\n        >>> tree = KSRMTree()\n        >>> list(tree.search_root(5, (2, 1)))\n        [(2, 1), (3, 2), (4, 3), (5, 4), (5, 2), (4, 1)]\n        >>> assert tree.roots[0] == (2, 1)\n        >>> list(tree.search_root(5, tree.roots[0]))\n        [(2, 1), (3, 2), (4, 3), (5, 4), (5, 2), (4, 1)]\n\n        The same type of search from the root :math:`(3, 1)`:\n\n        >>> list(tree.search_root(5, (3, 1)))\n        [(3, 1), (5, 3), (5, 1)]\n        >>> assert tree.roots[1] == (3, 1)\n        >>> list(tree.search_root(5, tree.roots[1]))\n        [(3, 1), (5, 3), (5, 1)]\n        \"\"\"\n        pass\n\n    def search(self, n: int, /) -> Generator[KSRMNode, None, None]:\n        \"\"\"Depth-first branch-and-bound generative search function (in pre-order, NLMR) on the KSRM coprime pairs trees to find all pairs of coprime (positive) integers not exceeding the given integer :math:`n \\\\geq 1`.\n    \n        See the :py:meth:`~continuedfractions.sequences.KSRMTree.search_root`\n        method for details of the implementation for the root-based search.\n\n        This method mainly calls the root-based search method\n        :py:meth:`~continuedfractions.sequences.KSRMTree.search_root` for the\n        two canonical roots :math:`(2, 1)` and :math:`(3, 1)`.\n\n        Parameters\n        ----------\n        n : int\n            The positive integer for which coprime pairs :math:`(a, b)`, with\n            :math:`1 \\\\leq b < a \\\\leq n`, are sought.\n\n        Raises\n        ------\n        ValueError\n            If ``n`` is not an integer or is :math:`< 1`.\n\n        Yields\n        ------\n        tuple\n            Pairs of coprime integers :math:`(a, b)`, with\n            :math:`1 \\\\leq b < a \\\\leq n`.\n\n        Examples\n        --------\n        A few examples of invalid and valid searches:\n\n        >>> tree = KSRMTree()\n        >>> list(tree.search(\"not an integer\"))\n        Traceback (most recent call last):\n        ...\n        ValueError: `n` must be a positive integer >= 1\n        >>> list(tree.search(1))\n        [(1, 1)]\n        >>> list(tree.search(2))\n        [(1, 1), (2, 1)]\n        >>> list(tree.search(3))\n        [(1, 1), (2, 1), (3, 2), (3, 1)]\n        >>> list(tree.search(5))\n        [(1, 1), (2, 1), (3, 2), (4, 3), (4, 1), (3, 1), (5, 4), (5, 3), (5, 2), (5, 1)]\n        >>> list(tree.search(10))\n        [(1, 1), (2, 1), (3, 2), (4, 3), (5, 4), (6, 5), (7, 6), (8, 7), (9, 8), (8, 3), (7, 2), (5, 2), (8, 5), (4, 1), (7, 4), (9, 4), (6, 1), (8, 1), (3, 1), (5, 3), (7, 5), (9, 7), (7, 3), (5, 1), (9, 5), (7, 1), (9, 1), (10, 9), (10, 7), (10, 3), (10, 1)]\n        \"\"\"\n        pass\n\ndef coprime_pairs_generator(n: int, /) -> Generator[KSRMNode, None, None]:\n    \"\"\"Generates a sequence (tuple) of all pairs of (positive) coprime integers :math:`<= n`.\n\n    Calls the KSRM tree :py:meth:`~continuedfractions.sequences.KSRMTree.search`\n    to perform the search up to :math:`n - 1` and then uses\n    :py:func:`~continuedfractions.sequences.coprime_integers` for the search\n    for pairs involving :math:`n`.\n\n    A :py:class:`ValueError` is raised if ``n`` is not an :py:class:`int`\n    or is an :py:class:`int` less than :math:`1`.\n\n    Parameters\n    ----------\n    n : int\n        The positive integer for which coprime pairs :math:`(a, b)`, with\n        :math:`1 \\\\leq b < a \\\\leq n`, are sought.\n\n    Raises\n    ------\n    ValueError\n        If ``n`` is not an :py:class:`int` or is an :py:class:`int` less than\n        :math:`1`.\n\n    Yields\n    ------\n    tuple\n        A :py:class:`tuple` of pairs of coprime integers :math:`(a, b)`, with\n        :math:`1 \\\\leq b < a \\\\leq n`.\n\n    Examples\n    --------\n    A few examples of coprime pairs generation:\n\n    >>> tuple(coprime_pairs_generator(1))\n    ((1, 1),)\n    >>> tuple(coprime_pairs_generator(2))\n    ((1, 1), (2, 1))\n    >>> tuple(coprime_pairs_generator(3))\n    ((1, 1), (2, 1), (3, 2), (3, 1))\n    >>> tuple(coprime_pairs_generator(5))\n    ((1, 1), (2, 1), (3, 2), (3, 1), (4, 3), (4, 1), (5, 4), (5, 3), (5, 2), (5, 1))\n    >>> tuple(coprime_pairs_generator(10))\n    ((1, 1), (2, 1), (3, 2), (4, 3), (5, 4), (6, 5), (7, 6), (8, 7), (8, 3), (7, 2), (5, 2), (8, 5), (4, 1), (7, 4), (6, 1), (8, 1), (3, 1), (5, 3), (7, 5), (7, 3), (5, 1), (7, 1), (9, 8), (9, 7), (9, 5), (9, 4), (9, 2), (9, 1), (10, 9), (10, 7), (10, 3), (10, 1))\n    \"\"\"\n    pass\n\ndef coprime_pairs(n: int, /) -> tuple[KSRMNode]:\n    \"\"\"Returns a sequence (tuple) of all pairs of (positive) coprime integers :math:`<= n`.\n\n    Wrapper of :py:func:`~continuedfractions.sequences.coprime_pairs_generator`.\n\n    Parameters\n    ----------\n    n : int\n        The positive integer for which coprime pairs :math:`(a, b)`, with\n        :math:`1 \\\\leq b < a \\\\leq n`, are sought.\n\n    Returns\n    -------\n    tuple\n        A :py:class:`tuple` of pairs of coprime integers :math:`(a, b)`, with\n        :math:`1 \\\\leq b < a \\\\leq n`.\n\n    Examples\n    --------\n    A few examples of computing coprime pairs:\n\n    >>> coprime_pairs(1)\n    ((1, 1),)\n    >>> coprime_pairs(2)\n    ((1, 1), (2, 1))\n    >>> coprime_pairs(3)\n    ((1, 1), (2, 1), (3, 2), (3, 1))\n    >>> coprime_pairs(5)\n    ((1, 1), (2, 1), (3, 2), (3, 1), (4, 3), (4, 1), (5, 4), (5, 3), (5, 2), (5, 1))\n    >>> coprime_pairs(10)\n    ((1, 1), (2, 1), (3, 2), (4, 3), (5, 4), (6, 5), (7, 6), (8, 7), (8, 3), (7, 2), (5, 2), (8, 5), (4, 1), (7, 4), (6, 1), (8, 1), (3, 1), (5, 3), (7, 5), (7, 3), (5, 1), (7, 1), (9, 8), (9, 7), (9, 5), (9, 4), (9, 2), (9, 1), (10, 9), (10, 7), (10, 3), (10, 1))\n    \"\"\"\n    pass\n\ndef farey_sequence_generator(n: int, /) -> Generator[ContinuedFraction, None, None]:\n    \"\"\"Generates an (ordered) sequence (tuple) of rational numbers forming the Farey sequence of order :math:`n`.\n\n    The elements of the sequence are yielded as\n    :py:class:`~continuedfractions.continuedfraction.ContinuedFraction`\n    instances, in ascending order of magnitude.\n\n    See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/sequences.html#sequences-farey-sequences>`_\n    for more details.\n\n    Parameters\n    ----------\n    n : int:\n        The order of the Farey sequence.\n\n    Raises\n    ------\n    ValueError\n        If :math:`n` is not a positive integer.\n\n    Yields\n    ------\n    ContinuedFraction\n        A sequence of\n        :py:class:`~continuedfractions.continuedfraction.ContinuedFraction`\n        instances representing the elements of the Farey sequence of order\n        :math:`n`, in ascending order of magnitude.\n\n    Examples\n    --------\n    >>> tuple(farey_sequence_generator(1))\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 1))\n    >>> tuple(farey_sequence_generator(2))\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 2), ContinuedFraction(1, 1))\n    >>> tuple(farey_sequence_generator(3))\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 3), ContinuedFraction(1, 2), ContinuedFraction(2, 3), ContinuedFraction(1, 1))\n    >>> tuple(farey_sequence_generator(4))\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 4), ContinuedFraction(1, 3), ContinuedFraction(1, 2), ContinuedFraction(2, 3), ContinuedFraction(3, 4), ContinuedFraction(1, 1))\n    >>> tuple(farey_sequence_generator(5))\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 5), ContinuedFraction(1, 4), ContinuedFraction(1, 3), ContinuedFraction(2, 5), ContinuedFraction(1, 2), ContinuedFraction(3, 5), ContinuedFraction(2, 3), ContinuedFraction(3, 4), ContinuedFraction(4, 5), ContinuedFraction(1, 1))\n    \"\"\"\n    pass\n\ndef farey_sequence(n: int, /) -> tuple[ContinuedFraction]:\n    \"\"\"Returns an (ordered) sequence (tuple) of rational numbers forming the Farey sequence of order :math:`n`.\n\n    Wrapper of :py:func:`~continuedfractions.sequences.farey_sequence_generator`.\n\n    The elements of the sequence are returned as\n    :py:class:`~continuedfractions.continuedfraction.ContinuedFraction`\n    instances, in ascending order of magnitude.\n\n    See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/sequences.html#sequences-farey-sequences>`_\n    for more details.\n\n    Parameters\n    ----------\n    n : int:\n        The order of the Farey sequence.\n\n    Returns\n    -------\n    tuple\n        A :py:class:`tuple` of ``ContinuedFraction`` instances representing the\n        elements of the Farey sequence of order :math:`n`, generated in\n        ascending order of magnitude.\n\n    Examples\n    --------\n    >>> farey_sequence(1)\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 1))\n    >>> farey_sequence(2)\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 2), ContinuedFraction(1, 1))\n    >>> farey_sequence(3)\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 3), ContinuedFraction(1, 2), ContinuedFraction(2, 3), ContinuedFraction(1, 1))\n    >>> farey_sequence(4)\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 4), ContinuedFraction(1, 3), ContinuedFraction(1, 2), ContinuedFraction(2, 3), ContinuedFraction(3, 4), ContinuedFraction(1, 1))\n    >>> farey_sequence(5)\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 5), ContinuedFraction(1, 4), ContinuedFraction(1, 3), ContinuedFraction(2, 5), ContinuedFraction(1, 2), ContinuedFraction(3, 5), ContinuedFraction(2, 3), ContinuedFraction(3, 4), ContinuedFraction(4, 5), ContinuedFraction(1, 1))\n    \"\"\"\n    pass\n```",
        "full_code_skeleton_structured": [
            {
                "file_path": "src/continuedfractions/lib.py",
                "code": "def continued_fraction_rational(frac: Fraction, /) -> Generator[int, None, None]:\n    \"\"\"Core continued fraction algorithm implementation which generates the ordered sequence of elements of the (finite) simple continued fraction of the given rational number.\n\n    The resulting sequence of elements, :math:`a_0,a_1,\\\\ldots a_n`, defines a simple continued fraction of the form:\n\n    .. math::\n\n       a_0 + \\\\cfrac{1}{a_1 + \\\\cfrac{1}{a_2 + \\\\ddots\\\\cfrac{1}{a_{n - 1} + \\\\cfrac{1}{a_n}}}}\n\n    which is also written more compactly as:\n\n    .. math::\n\n       [a_0; a_1, a_2\\\\ldots, a_n]\n\n    The order of the continued fraction is said to be :math:`n`. If the last\n    element :math:`a_n = 1` the sequence can be rewritten as\n    :math:`[a_0; a_1, a_2\\\\ldots, a_{n - 1} + 1]`, which is then unique as a\n    simple continued fraction representation of the rational number.\n\n    Negative rational numbers can also be represented in this way, provided we\n    use the `Euclidean division lemma <https://en.wikipedia.org/wiki/Euclid%27s_lemma>`_.\n    This is described in more detail in the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/creating-continued-fractions.html#negative-continued-fractions>`_.\n\n    For a definition of \"continued fraction\", \"element\", \"order\",\n    \"finite continued fraction\", \"simple continued fraction\", please consult\n    the `package documentation <https://continuedfractions.readthedocs.io/en/stable>`_,\n    or any online resource such as `Wikipedia <https://en.wikipedia.org/wiki/Continued_fraction>`_,\n    or suitable books on number theory.\n\n    Parameters\n    ----------\n    frac : `fractions.Fraction`\n        The rational number to represented as a simple continued fraction.\n\n    Yields\n    ------\n    int\n        Elements of a unique simple continued fraction of the given rational\n        number.\n\n    Examples\n    --------\n    A few examples are given below of how this function can be used.\n\n    >>> for e in continued_fraction_rational(Fraction(649, 200)):\n    ...     print(e)\n    ... \n    3\n    4\n    12\n    4\n    >>> list(continued_fraction_rational(Fraction(415, 93)))\n    [4, 2, 6, 7]\n    >>> list(continued_fraction_rational(Fraction(-649, 200)))\n    [-4, 1, 3, 12, 4]\n    >>> list(continued_fraction_rational(Fraction(123235, 334505)))\n    [0, 2, 1, 2, 1, 1, 250, 1, 13]\n\n    Notes\n    -----\n    Every rational number has exactly two simple continued fractions, one of\n    which has an additional element of :math:`1` as its last element,\n    i.e. :math:`[a_0;a_1,a_2,\\\\ldots,a_{n - 1}, 1]`. But this form can be\n    reduced by adding the :math:`1` to the second last element, :math:`a_{n - 1}`,\n    producing the shorter form :math:`[a_0;a_1,a_2,\\\\ldots, a_{n - 1} + 1]`,\n    where the last element is now :math:`> 1`.\n\n    The simple continued fraction representation generated by this function is\n    the shorter version, and is thus unique.\n    \"\"\"\n    pass\n\ndef continued_fraction_real(x: int | float | str | Decimal, /) -> Generator[int, None, None]:\n    \"\"\"Generates a finite sequence of elements (coefficients) of a (simple) continued fraction of the given real number.\n\n    The result is a finite sequence even though the given number :math:`x` may\n    be irrational or not exactly representable as a real number. \n\n    The simple continued fraction representation of :math:`x` is a number of\n    the form\n\n    .. math::\n\n       a_0 + \\\\cfrac{1}{a_1 + \\\\cfrac{1}{a_2 + \\\\ddots}}\n\n    where :math:`a_0 = [x]` is the integer part of :math:`x`, and the\n    :math:`a_1,a_2\\\\ldots` are the (non-negative) quotients obtained by a\n    repeated application of `Euclidean division <https://en.wikipedia.org/wiki/Euclidean_division>`_\n    to the fractional part :math:`x - [x]`, which is called the remainder.\n\n    If the last element :math:`a_n = 1` the sequence can be rewritten as\n    :math:`[a_0; a_1, a_2\\\\ldots, a_{n - 1} + 1]`.\n\n    As Python :py:class:`float` values, like all floating point\n    implementations, are `finite precision representations <https://docs.python.org/3/tutorial/floatingpoint.html>`_\n    of real numbers, the resulting simple continued fraction  of :math:`x`\n    generated by this function may be approximate, not exact, and also not\n    necessarily unique.\n\n    For non-rational real numbers it is best to pass :py:class:`decimal.Decimal`\n    values, with the `context precision <https://docs.python.org/3.12/library/decimal.html#context-objects>`_\n    set to the highest level possible.\n\n    The results for rational numbers are guaranteed to be exact however large\n    the number, subject to memory and hardware limitations of the running\n    environment.\n\n    Invalid values will generate an error in either the\n    :py:class:`fractions.Fraction` or :py:class:`decimal.Decimal` classes -\n    no errors are raised directly in the function itself.\n\n    Parameters\n    ----------\n    x : int, float, str, decimal.Decimal\n        The real number to represent as a simple continued fraction.\n\n    Yields\n    ------\n    int\n        Elements of a simple continued fraction of the given real number.\n\n    Examples\n    --------\n    A few examples are given below of how this function can be used.\n\n    >>> list(continued_fraction_real(5000))\n    [5000]\n    >>> list(continued_fraction_real(-5000.0))\n    [-5000]\n    >>> list(continued_fraction_real(2/5))\n    [0, 2, 2, 1801439850948198]\n    >>> list(continued_fraction_real('2/5'))\n    [0, 2, 2]\n    >>> list(continued_fraction_real('-1/3'))\n    [-1, 1, 2]\n    >>> list(continued_fraction_real(1/1j))\n    Traceback (most recent call last):\n    ...\n    TypeError: conversion from complex to Decimal is not supported\n    >>> list(continued_fraction_real(\"not a numeric string\"))\n    Traceback (most recent call last):\n    ...\n    decimal.InvalidOperation: [<class 'decimal.ConversionSyntax'>]\n    >>> list(continued_fraction_real(-649/200))\n    [-4, 1, 3, 12, 3, 1, 234562480591, 2, 5, 2]\n    >>> list(continued_fraction_real('-649/200'))\n    [-4, 1, 3, 12, 4]\n    >>> list(continued_fraction_real('-649/-200'))\n    Traceback (most recent call last):\n    ...\n    ValueError: Invalid literal for Fraction: '-649/-200'\n    >>> list(continued_fraction_real(Decimal('0.3333')))\n    [0, 3, 3333]\n    \"\"\"\n    pass\n\ndef convergent(k: int, *elements: int) -> Fraction:\n    \"\"\"Returns the :math:`k`-th convergent of a (simple) continued fraction from a sequence of its elements.\n\n    Given a (simple) continued fraction  :math:`[a_0;a_1,a_2,\\\\ldots]` the\n    :math:`k`-th convergent is defined as:\n\n    .. math::\n\n       C_k = a_0 + \\\\cfrac{1}{a_1 + \\\\cfrac{1}{a_2 \\\\ddots \\\\cfrac{1}{a_{k-1} + \\\\cfrac{1}{a_k}}}}\n\n    The result is a :py:class:`fractions.Fraction` instance.\n    \n    The integer :math:`k` is called the order of the convergent, and if \n    :math:`[a_0;a_1,a_2,\\\\ldots]` is finite of order :math:`n` then it has\n    exactly :math:`n + 1` convergents :math:`C_0,C_1,C_2,\\\\ldots,C_n` where\n    the :math:`k`-th convergent :math:`C_k = \\\\frac{p_k}{q_k}` is given by\n    the recurrence relation:\n\n    .. math::\n       \n       \\\\begin{align}\n       p_k &= a_kp_{k - 1} + p_{k - 2} \\\\\\\\\n       q_k &= a_kq_{k - 1} + q_{k - 2},        \\\\hskip{3em}    k \\\\geq 3\n       \\\\end{align}\n\n    where :math:`p_0 = a_0`, :math:`q_0 = 1`, :math:`p_1 = p_1p_0 + 1`,\n    and :math:`q_1 = p_1`.\n\n    This function is a faithful implementation of this algorithm.\n\n    A :py:class:`ValueError` is raised if :math:`k` is not an integer or is an\n    integer greater than the number of elements, or if any of the elements are\n    not integers.\n\n    Parameters\n    ----------\n    k : `int`\n        The order of the convergent. Must be a non-negative integer less than\n        the number of elements.\n\n    *elements : `int`\n        A variable-length sequence of integer elements of a continued fraction.\n\n    Returns\n    -------\n    fractions.Fraction\n        A rational fraction constructed from the given sequence of elements of\n        a continued fraction, representing the :math:`k`-order convergent of a\n        (finite) simple continued fraction as given by a sequence of elements.\n\n    Raises\n    ------\n    ValueError\n        If :math:`k` is not a non-negative integer less than the number of\n        elements, or if any of the elements are not integers.\n\n    Examples\n    --------\n    >>> convergent(0, 3, 4, 12, 4)\n    Fraction(3, 1)\n    >>> convergent(1, 3, 4, 12, 4)\n    Fraction(13, 4)\n    >>> convergent(2, 3, 4, 12, 4)\n    Fraction(159, 49)\n    >>> convergent(3, 3, 4, 12, 4)\n    Fraction(649, 200)\n    >>> convergent(3)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> convergent(-1, 3, 4, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> convergent(4, 3, 4, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    \"\"\"\n    pass\n\ndef convergents(*elements: int) -> Generator[Fraction, None, None]:\n    \"\"\"Generates an (ordered) sequence of all convergents of a (simple) continued fraction from a sequence of its elements.\n\n    If :math:`n` is the order of the continued fraction represented by the\n    given sequence of its elements then there are :math:`n + 1` convergents\n    :math:`C_0, C_1, \\\\ldots, C_n`, and the function generates these in that\n    order.\n\n    See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/exploring-continued-fractions.html#convergents-and-rational-approximations>`_\n    for more details on convergents.\n\n    Parameters\n    ----------\n    *elements : `int`\n        A variable-length sequence of integer elements of a (simple)\n        continued fraction.\n\n    Yields\n    ------\n    fractions.Fraction\n        Each element generated is a :py:class:`fractions.Fraction` instance and\n        a :math:`k`-th convergent of the given continued fraction.\n\n    Raises\n    ------\n    ValueError\n        If there are any non-integer elements, or the tail elements are not\n        positive integers.\n\n    Examples\n    --------\n    >>> tuple(convergents(3))\n    (Fraction(3, 1),)\n    >>> tuple(convergents(3, 2))\n    (Fraction(3, 1), Fraction(7, 2))\n    >>> tuple(convergents(3, 4, 12, 4))\n    (Fraction(3, 1), Fraction(13, 4), Fraction(159, 49), Fraction(649, 200))\n    >>> tuple(convergents(-5, 1, 1, 6, 7))\n    (Fraction(-5, 1), Fraction(-4, 1), Fraction(-9, 2), Fraction(-58, 13), Fraction(-415, 93))\n    >>> tuple(convergents(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))\n    (Fraction(1, 1), Fraction(3, 2), Fraction(10, 7), Fraction(43, 30), Fraction(225, 157), Fraction(1393, 972), Fraction(9976, 6961), Fraction(81201, 56660), Fraction(740785, 516901), Fraction(7489051, 5225670))\n\n    \"\"\"\n    pass\n\ndef fraction_from_elements(*elements: int) -> Fraction:\n    \"\"\"Returns the rational number represented by a (simple) continued fraction from a sequence of its elements.\n\n    The elements must be given as positional arguments, which means that if\n    they are contained in an iterable then they must be unpacked using the\n    unpacking operator ``*``, as described in the examples below.\n\n    Parameters\n    ----------\n    *elements : `int`\n        A variable-length sequence of integer elements of a simple continued\n        fraction.\n\n    Returns\n    -------\n    fractions.Fraction\n        A rational number constructed from a sequence of elements of a simple\n        continued fraction which represents the number.\n\n    Raises\n    ------\n    ValueError\n        If any of the elements are not integers.\n\n    Examples\n    --------\n    >>> fraction_from_elements(3, 4, 12, 4)\n    Fraction(649, 200)\n    >>> fraction_from_elements(-4, 1, 3, 12, 4)\n    Fraction(-649, 200)\n    >>> fraction_from_elements(4, 2, 6, 7)\n    Fraction(415, 93)\n    >>> fraction_from_elements(*[4, 2, 6, 7])\n    Fraction(415, 93)\n    >>> fraction_from_elements(4.5, 2, 6, 7)\n    Traceback (most recent call last):\n    ...\n    ValueError: Continued fraction elements must be integers\n    \"\"\"\n    pass\n\ndef remainder(k: int, *elements: int) -> Fraction:\n    \"\"\"Returns the :math:`k`-th remainder of a (simple) continued fraction from a sequence of its elements.\n\n    Given a (simple) continued fraction  :math:`[a_0;a_1,a_2,\\\\ldots]` the\n    :math:`k`-th remainder :math:`R_k` is the (simple) continued fraction\n    :math:`[a_k; a_{k + 1}, a_{k + 2}, \\\\ldots]`:\n\n    .. math::\n\n       R_k = a_k + \\\\cfrac{1}{a_{k + 1} + \\\\cfrac{1}{a_{k + 2} \\\\ddots }}\n\n    where :math:`R_0` is just the original continued fraction, i.e.\n    :math:`R_0 = [a_0; a_1, a_2, \\\\ldots]`.\n\n    The remainders satisfy the recurrence relation:\n\n    .. math::\n\n       R_{k - 1} = a_{k - 1} + \\\\frac{1}{R_k}, \\\\hskip{3em} k \\\\geq 1\n\n    If the continued fraction :math:`[a_0; a_1, a_2,\\\\ldots]` is finite of\n    order :math:`n` then all :math:`R_k` are rational. If we let\n    :math:`R_k = \\\\frac{s_k}{t_k}` then the recurrence relation above can\n    be written as:\n\n    .. math::\n\n       R_{k - 1} = \\\\frac{s_{k - 1}}{t_{k - 1}} = \\\\frac{a_{k - 1}s_k + t_k}{s_k}, \\\\hskip{3em} k \\\\geq 1\n\n    As this library only deals with finite continued fractions, this function\n    always produces remainders as instances of :py:class:`~fractions.Fraction`.\n\n    The integer :math:`k` must be non-negative and cannot exceed the order\n    of the continued fraction, i.e. the number of its tail elements.\n\n    A :py:class:`ValueError` is raised if :math:`k` is not an integer, or is an\n    integer greater than the number of elements, or if any of the elements are\n    not integers, or if any of the tail elements are not positive integers.\n\n    Parameters\n    ----------\n    k : `int`\n        The index of the remainder. Must be a non-negative integer not\n        exceeding the order of the continued fraction.\n\n    *elements : `int`\n        A variable-length sequence of integer elements of a (simple) continued\n        fraction.\n\n    Returns\n    -------\n    fractions.Fraction\n        A rational fraction constructed from the given sequence of elements of\n        a continued fraction, representing its :math:`k`-th remainder, as\n        defined above.\n\n    Raises\n    ------\n    ValueError\n        If :math:`k` is not an integer, or is an integer greater than the\n        number of elements, or if any of the elements are not integers, or if\n        any of the tail elements are not positive integers.\n\n    Examples\n    --------\n    >>> remainder(0, 3, 4, 12, 4)\n    Fraction(649, 200)\n    >>> remainder(1, 3, 4, 12, 4)\n    Fraction(200, 49)\n    >>> remainder(2, 3, 4, 12, 4)\n    Fraction(49, 4)\n    >>> remainder(3, 3, 4, 12, 4)\n    Fraction(4, 1)\n    >>> remainder(0, -5, 1, 1, 6, 7)\n    Fraction(-415, 93)\n    >>> remainder(1, -5, 1, 1, 6, 7)\n    Fraction(93, 50)\n    >>> remainder(2, -5, 1, 1, 6, 7)\n    Fraction(50, 43)\n    >>> remainder(3, -5, 1, 1, 6, 7)\n    Fraction(43, 7)\n    >>> remainder(4, -5, 1, 1, 6, 7)\n    Fraction(7, 1)\n    >>> remainder(1)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> remainder(-1, 3, 4, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> remainder(4, 3, 4, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> remainder(1, 3, 0, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> remainder(1, 3, -1, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    \"\"\"\n    pass\n\ndef remainders(*elements: int) -> Generator[Fraction, None, None]:\n    \"\"\"Generates an (ordered) sequence of all remainders of a (simple) continued fraction from a sequence of its elements in descending order of index.\n\n    If :math:`n` is the order of the continued fraction represented by the\n    given sequence of its elements then there are :math:`n + 1` remainders\n    :math:`R_0, R_1, \\\\ldots, R_n`, and the function generates these in\n    reverse order :math:`R_0, R_1, \\\\ldots, R_n`.\n\n    See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/exploring-continued-fractions.html#remainders>`_\n    for more details on remainders.\n\n    Parameters\n    ----------\n    *elements : `int`\n        A variable-length sequence of integer elements of a (simple)\n        continued fraction.\n\n    Yields\n    ------\n    fractions.Fraction\n        Each element generated is a :py:class:`fractions.Fraction` instance and\n        a :math:`k`-th remainder of the given continued fraction.\n\n    Raises\n    ------\n    ValueError\n        If no elements are given, or there are any non-integer elements, or\n        the tail elements are not positive integers.\n\n    Examples\n    --------\n    >>> tuple(remainders(3))\n    (Fraction(3, 1),)\n    >>> tuple(remainders(3, 2))\n    (Fraction(2, 1), Fraction(7, 2))\n    >>> tuple(remainders(3, 4, 12, 4))\n    (Fraction(4, 1), Fraction(49, 4), Fraction(200, 49), Fraction(649, 200))\n    >>> tuple(remainders(-5, 1, 1, 6, 7))\n    (Fraction(7, 1), Fraction(43, 7), Fraction(50, 43), Fraction(93, 50), Fraction(-415, 93))\n    >>> tuple(remainders(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))\n    (Fraction(10, 1), Fraction(91, 10), Fraction(738, 91), Fraction(5257, 738), Fraction(32280, 5257), Fraction(166657, 32280), Fraction(698908, 166657), Fraction(2263381, 698908), Fraction(5225670, 2263381), Fraction(7489051, 5225670))\n    >>> tuple(remainders())\n    Traceback (most recent call last):\n    ...\n    ValueError: Continued fraction elements must be integers, and all \n    tail elements (from the 1st element onwards) must be positive.\n    >>> tuple(remainders(0, 0))\n    Traceback (most recent call last):\n    ...\n    ValueError: Continued fraction elements must be integers, and all \n    tail elements (from the 1st element onwards) must be positive.\n    >>> tuple(remainders(1, 0))\n    Traceback (most recent call last):\n    ...\n    ValueError: Continued fraction elements must be integers, and all \n    tail elements (from the 1st element onwards) must be positive.\n    >>> tuple(remainders(1, 2, -1))\n    Traceback (most recent call last):\n    ...\n    ValueError: Continued fraction elements must be integers, and all \n    tail elements (from the 1st element onwards) must be positive.\n    \"\"\"\n    pass\n\ndef mediant(r: Fraction, s: Fraction, /, *, dir: str = 'right', k: int = 1) -> Fraction:\n    \"\"\"Returns the :math:`k`-th left- or right-mediant of two rational numbers.\n\n    For a positive integer :math:`k`, the :math:`k`-th left-mediant of two\n    rational numbers :math:`r = \\\\frac{a}{b}` and :math:`s = \\\\frac{c}{d}`,\n    where :math:`b, d, b + d \\\\neq 0`, is defined as:\n    \n    .. math::\n\n       \\\\frac{ka + c}{kb + d}, \\\\hskip{3em}    k \\\\geq 1\n\n    while the :math:`k`-th right mediant is defined as:\n    \n    .. math::\n\n       \\\\frac{a + kc}{b + kd}, \\\\hskip{3em}    k \\\\geq 1\n\n    If we assume that :math:`r < s` and :math:`bd > 0` then these mediants\n    have the property that:\n   \n    .. math::\n\n       \\\\frac{a}{b} < \\\\frac{ka + c}{kb + d} \\\\leq \\\\frac{a + kc}{b + kd} < \\\\frac{c}{d},   \\\\hskip{3em} k \\\\geq 1\n\n    where equality holds for :math:`k = 1`. If we let :math:`k \\\\to \\\\infty`\n    then the mediants converge to opposite limits:\n\n    .. math::\n\n      \\\\begin{align}\n      \\\\lim_{k \\\\to \\\\infty} \\\\frac{ka + c}{kb + d} &= \\\\frac{a}{b} \\\\\\\\\n      \\\\lim_{k \\\\to \\\\infty} \\\\frac{a + kc}{b + kd} &= \\\\frac{c}{d}\n      \\\\end{align}\n\n    For more information consult the\n    `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/mediants.html>`_.\n\n    For the left mediant use ``dir=\"left\"``, while for the right use\n    ``dir=\"right\"``. The default is ``dir=\"right\"``. For ``k = 1`` the left and\n    right mediants are identical to the simple mediant :math:`\\\\frac{a + c}{b + d}`.\n\n    Parameters\n    ----------\n    r : `fractions.Fraction`\n        The first rational number.\n\n    s : `fractions.Fraction`\n        The second rational number.\n\n    dir : `str`, default='right'\n        The \"direction\" of the mediant - `'left'` or `'right'`, as defined\n        above.\n\n    k : `int`, default=1\n        The order of the mediant, as defined above.\n\n    Returns\n    -------\n    fractions.Fraction\n        The `k`-th left- or right-mediant of the two given rational numbers.\n\n    Examples\n    --------\n    >>> mediant(Fraction(1, 2), Fraction(3, 5))\n    Fraction(4, 7)\n    >>> mediant(Fraction(1, 2), Fraction(3, 5), dir='left')\n    Fraction(4, 7)\n    >>> mediant(Fraction(1, 2), Fraction(3, 5), k=2)\n    Fraction(7, 12)\n    >>> mediant(Fraction(1, 2), Fraction(3, 5), dir='left', k=2)\n    Fraction(5, 9)\n    >>> mediant(Fraction(1, 2), Fraction(3, 5), k=3, dir='right')\n    Fraction(10, 17)\n    >>> mediant(Fraction(1, 2), Fraction(3, 5), k=3, dir='left')\n    Fraction(6, 11)\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "src/continuedfractions/utils.py",
                "code": "class NamedCallableProxy:\n    \"\"\"Class wrapper to have named callable proxies, which can also work as :py:class:`enum.Enum` values.\n\n    Adapted from Stack Overflow solution by Ceppo93:\n\n        https://stackoverflow.com/a/40486992\n    \"\"\"\n    def __new__(cls, callable_: Callable, /, *, name: str = None) -> NamedCallableProxy:\n        \"\"\"Constructor\n\n        Parameters\n        ----------\n        callable_ : `callable`\n            The callable to name and proxy.\n\n        name : `str`, default=None\n            The user-defined name of the callable to use in :py:func:`~continuedfractions.utils.__repr__`.\n            If :py:data:`None` the Python-defined default will be used.\n\n        Returns\n        -------\n        callable\n            A named callable proxy.\n\n        Examples\n        --------\n        >>> square = NamedCallableProxy(lambda x: x ** 2, name=\"square: x |--> x^2\")\n        >>> square\n        NamedCallableProxy(\"square: x |--> x^2\")\n        >>> list(map(square, [1, 2, 3, 4, 5]))\n        [1, 4, 9, 16, 25]\n        \"\"\"\n        pass\n\n    def __repr__(self) -> str:\n        pass\n\n    def __eq__(self, other: NamedCallableProxy) -> bool:\n        pass\n\n    def __call__(self, *args: Any, **kwargs: Any) -> Any:\n        pass\n"
            },
            {
                "file_path": "src/continuedfractions/continuedfraction.py",
                "code": "class ContinuedFraction(Fraction):\n    \"\"\"An object-oriented representation of a (finite) simple continued fraction.\n\n    An implementation of simple continued fractions as Python objects and\n    instances of the standard library :py:class:`fractions.Fraction` class, with\n    various properties for the continued fraction, including its elements\n    (or coefficients), the order, convergents, and remainders.\n\n    The term \"simple continued fraction\" denotes a specific type of continued\n    fraction where the fractional terms only have numerators of :math:`1`.\n\n    Examples\n    --------\n    Construct the continued fraction for the rational `649/200`.\n\n    >>> cf = ContinuedFraction(649, 200)\n    >>> cf\n    ContinuedFraction(649, 200)\n    >>> cf.as_float()\n    3.245\n\n    Inspect the elements, order, convergents, and remainders.\n\n    >>> cf.elements\n    (3, 4, 12, 4)\n    >>> cf.order\n    3\n    >>> cf.convergent(0), cf.convergent(1), cf.convergent(2), cf.convergent(3)\n    (ContinuedFraction(3, 1), ContinuedFraction(13, 4), ContinuedFraction(159, 49), ContinuedFraction(649, 200))\n    >>> cf.remainder(0), cf.remainder(1), cf.remainder(2), cf.remainder(3)\n    (ContinuedFraction(649, 200), ContinuedFraction(200, 49), ContinuedFraction(49, 4), ContinuedFraction(4, 1))\n\n    Inspect the element counts.\n\n    >>> cf.counter\n    Counter({4: 2, 3: 1, 12: 1})\n\n    Check some properties of the convergents and remainders.\n\n    >>> assert cf.remainder(1) == 1 / (cf - cf.convergent(0))\n\n    Construct continued fractions from element sequences.\n\n    >>> cf_inverse = ContinuedFraction.from_elements(0, 3, 4, 12, 4)\n    >>> cf_inverse\n    ContinuedFraction(200, 649)\n    >>> assert cf_inverse == 1/cf\n    >>> assert cf * cf_inverse == 1\n    >>> cf_negative_inverse = ContinuedFraction.from_elements(-1, 1, 2, 4, 12, 4)\n    >>> cf_negative_inverse\n    ContinuedFraction(-200, 649)\n    >>> assert cf_negative_inverse == -1/cf\n    >>> assert cf * cf_negative_inverse == -1\n    \"\"\"\n    def __new__(cls, *args: Any, **kwargs: Any) -> ContinuedFraction:\n        \"\"\"Creates, initialises and returns instances of this class.\n\n        Arguments can be any which are valid for creating objects of the\n        :py:class:`fractions.Fraction` superclass.\n\n        For clarification, valid arguments can be one of the following:\n\n        * a single instance of :py:class:`numbers.Rational`, including\n          :py:class:`int`, :py:class:`fractions.Fraction` or\n          :py:class:`ContinuedFraction`, named or unnamed\n        * a pair of  :py:class:`numbers.Rational` instances, including\n          :py:class:`int`, :py:class:`fractions.Fraction` and\n          :py:class:`ContinuedFraction`, named or unnamed\n        * a single :py:class:`float` or :py:class:`decimal.Decimal` value\n          that is not a special value such as :py:data:`math.nan`,\n          ``float('inf')``, or ``Decimal('infinity')``\n        * a single numeric valid string (:py:class:`str`) - validity is\n          determined in the superclass by the\n          :py:data:`fractions._RATIONAL_FORMAT` test\n\n        Returns\n        -------\n        ContinuedFraction\n            A :py:class:`ContinuedFraction` instance.\n\n        Examples\n        --------\n        Several example are given below of constructing the simple continued\n        fraction for the number :math:`\\\\frac{-649}{200}` in different ways.\n\n        >>> ContinuedFraction(-649, 200)\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction('-3.245')\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(Decimal('-3.245'))\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction('-649/200')\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(Fraction(-649, 200))\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(ContinuedFraction(649, -200))\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(Fraction(-649), 200)\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(649, Fraction(-200))\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(Fraction(-649), ContinuedFraction(200))\n        ContinuedFraction(-649, 200)\n\n        In each of the examples above, the minus sign can be removed from\n        the arguments to the :py:class:`numbers.Rational` instance and\n        instead attached to the outer class, e.g.:\n\n        >>> -ContinuedFraction(649, 200)\n        ContinuedFraction(-649, 200)\n        >>> -ContinuedFraction('3.245')\n        ContinuedFraction(-649, 200)\n        >>> -ContinuedFraction('649/200')\n        ContinuedFraction(-649, 200)\n\n        Invalid arguments will raise errors in the\n        :py:class:`fractions.Fraction` superclass.\n        \"\"\"\n        pass\n\n    @classmethod\n    def from_elements(cls, *elements: int) -> ContinuedFraction:\n        \"\"\"Returns a :py:class:`ContinuedFraction` instance from a sequence of (integer) elements of a (finite) simple continued fraction.\n\n        Invalid elements will trigger a :py:class:`ValueError`.\n\n        Parameters\n        ----------\n        *elements : int\n            An ordered sequence of integer elements of a (finite) simple\n            continued fraction.\n\n        Returns\n        -------\n        ContinuedFraction\n            A new and fully initialised instance of :py:class:`ContinuedFraction` with\n            the given element sequence.\n\n        Raises\n        ------\n        ValueError\n            If any elements are not integers, or any elements after the 1st\n            are not positive.\n\n        Examples\n        --------\n        Constructing a continued fraction for the rational :math:`\\\\frac{649}{200}` using\n        the element sequence :math:`3, 4, 12, 4`.\n\n        >>> c1 = ContinuedFraction.from_elements(3, 4, 12, 4)\n        >>> c1\n        ContinuedFraction(649, 200)\n\n        Constructing the continued fraction of the (multiplicative) inverse :math:`\\\\frac{200}{649}`\n        using the element sequence :math:`0, 3, 4, 12, 4`.\n\n        >>> c2 = ContinuedFraction.from_elements(0, 3, 4, 12, 4)\n        >>> c2\n        ContinuedFraction(200, 649)\n\n        Validation for elements containing non-integers or negative integers.\n\n        >>> ContinuedFraction.from_elements('0', 1)\n        Traceback (most recent call last):\n        ...\n        ValueError: Continued fraction elements must be integers, and all elements after the 1st must be positive\n        >>> ContinuedFraction.from_elements(0, 1, 2.5)\n        Traceback (most recent call last):\n        ...\n        ValueError: Continued fraction elements must be integers, and all elements after the 1st must be positive\n        >>> ContinuedFraction.from_elements(1, 0)\n        Traceback (most recent call last):\n        ...\n        ValueError: Continued fraction elements must be integers, and all elements after the 1st must be positive\n        >>> ContinuedFraction.from_elements(1, -1)\n        Traceback (most recent call last):\n        ...\n        ValueError: Continued fraction elements must be integers, and all elements after the 1st must be positive\n\n        \"\"\"\n        pass\n\n    def extend(self, *new_elements: int) -> None:\n        \"\"\"Performs an in-place extension of the tail of the current sequence of elements.\n\n        Raises a :py:class:`ValueError` if there are no new elements, or are\n        not positive integers.\n\n        .. note::\n\n           As this method performs an in-place modification of the existing/\n           current instance the object ID remains the same.\n\n        Parameters\n        ----------\n        elements\n            An (ordered) sequence of new (integer) elements by which the tail\n            of the existing sequence of elements is extended.\n\n        Raises\n        ------\n        ValueError\n            If no new elements provided, or the new elements provided are not\n            positive integers.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('3.245')\n        >>> cf\n        ContinuedFraction(649, 200)\n        >>> cf.elements\n        (3, 4, 12, 4)\n        >>> cf.order\n        3\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)), (2, ContinuedFraction(159, 49)), (3, ContinuedFraction(649, 200)))\n        >>> tuple(cf.remainders)\n        ((3, ContinuedFraction(4, 1)), (2, ContinuedFraction(49, 4)), (1, ContinuedFraction(200, 49)), (0, ContinuedFraction(649, 200)))\n        >>> cf.extend(5, 2)\n        >>> cf\n        ContinuedFraction(7457, 2298)\n        >>> cf.elements\n        (3, 4, 12, 4, 5, 2)\n        >>> cf.order\n        5\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)), (2, ContinuedFraction(159, 49)), (3, ContinuedFraction(649, 200)), (4, ContinuedFraction(3404, 1049)), (5, ContinuedFraction(7457, 2298)))\n        >>> tuple(cf.remainders)\n        ((5, ContinuedFraction(2, 1)), (4, ContinuedFraction(11, 2)), (3, ContinuedFraction(46, 11)), (2, ContinuedFraction(563, 46)), (1, ContinuedFraction(2298, 563)), (0, ContinuedFraction(7457, 2298)))\n        >>> cf = ContinuedFraction(649, 200)\n        >>> cf.extend(0, 1)\n        Traceback (most recent call last):\n        ...\n        ValueError: The elements/coefficients to be added to the tail must be positive integers.\n        >>> cf.extend(1, -1)\n        Traceback (most recent call last):\n        ...\n        ValueError: The elements/coefficients to be added to the tail must be positive integers.\n        \"\"\"\n        pass\n\n    def truncate(self, *tail_elements: int) -> None:\n        \"\"\"Performs an in-place truncation of the tail of the existing sequence of elements.\n\n        Raises a :py:class:`ValueError` if the tail elements provided are not\n        positive integers, or do not form a segment of the existing tail. This\n        includes the case where the length of the tail elements provided exceed\n        the length of the existing tail, i.e. the order of the continued\n        fraction represented by the instance.\n\n        .. note::\n\n           The tail elements provided must be positive integers which form a\n           subsequence of the tail of the original sequence ending with the\n           last element, e.g. with respect to the complete sequence of elements\n           ``(3, 4, 12, 4)`` a value of ``12, 4`` for ``*tail_elements`` would\n           be valid, but ``4, 12`` would be invalid as it does not represent\n           a segment of the tail, and ``3, 4, 12, 4`` would also be invalid\n           as it includes the head ``3``.\n\n        .. note::\n\n           As this method performs an in-place modification of the existing/\n           current instance the object ID remains the same.\n\n        Parameters\n        ----------\n        tail_elements\n            An (ordered) sequence of (integer) elements to truncate from the\n            tail of the existing sequence of elements.\n\n        Raises\n        ------\n        ValueError\n            If no tail elements are provided, or the tail elements provided do\n            not represent a valid segment of the existing tail.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('3.245')\n        >>> cf\n        ContinuedFraction(649, 200)\n        >>> cf.elements\n        (3, 4, 12, 4)\n        >>> cf.order\n        3\n        >>> cf.counter\n        Counter({4: 2, 3: 1, 12: 1})\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)), (2, ContinuedFraction(159, 49)), (3, ContinuedFraction(649, 200)))\n        >>> tuple(cf.remainders)\n        ((3, ContinuedFraction(4, 1)), (2, ContinuedFraction(49, 4)), (1, ContinuedFraction(200, 49)), (0, ContinuedFraction(649, 200)))\n        >>> cf.truncate(12, 4)\n        >>> cf\n        ContinuedFraction(13, 4)\n        >>> cf.elements\n        (3, 4)\n        >>> cf.order\n        1\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)))\n        >>> tuple(cf.remainders)\n        ((1, ContinuedFraction(4, 1)), (0, ContinuedFraction(13, 4)))\n        >>> cf = ContinuedFraction(649, 200)\n        >>> cf.truncate(4, 12)\n        Traceback (most recent call last):\n        ...\n        ValueError: The elements/coefficients to be truncated from the tail must form a valid segment of the existing tail.\n        >>> cf.truncate(3, 4, 12, 4)\n        Traceback (most recent call last):\n        ...\n        ValueError: The elements/coefficients to be truncated from the tail must form a valid segment of the existing tail.\n        \"\"\"\n        pass\n\n    def __eq__(self, other, /) -> bool:\n        \"\"\"Custom equality check.\n\n        Compares the sequence of elements/coefficients of ``self`` with\n        that of ``other`` if ``other`` is also a\n        :py:class:`~continuedfractions.continuedfraction.ContinuedFraction`\n        instance, otherwise calls the superclass :py:class:`~fractions.Fraction`\n        equality check.\n\n        Returns\n        -------\n        bool\n            The boolean result of the equality check.\n        \"\"\"\n        pass\n\n    def __hash__(self) -> int:\n        \"\"\"Custom hash.\n\n        Custom hash which hashes the sequence of elements/coefficients - as\n        this is always defined as a finite, non-empty tuple the hash is\n        always defined.\n\n        Returns\n        -------\n        int\n            The hash of the\n            :py:class:`~continuedfractions.continuedfraction.ContinuedFraction`\n            instance.\n        \"\"\"\n        pass\n\n    def __add__(self, other, /):\n        pass\n\n    def __radd__(self, other, /):\n        pass\n\n    def __sub__(self, other, /):\n        pass\n\n    def __rsub__(self, other, /):\n        pass\n\n    def __mul__(self, other, /):\n        pass\n\n    def __rmul__(self, other, /):\n        pass\n\n    def __truediv__(self, other, /):\n        pass\n\n    def __rtruediv__(self, other, /):\n        pass\n\n    def __floordiv__(self, other, /):\n        pass\n\n    def __rfloordiv__(self, other, /):\n        pass\n\n    def __divmod__(self, other, /):\n        pass\n\n    def __rdivmod__(self, other, /):\n        pass\n\n    def __pow__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __rpow__(self, other, /):\n        pass\n\n    def __pos__(self) -> ContinuedFraction:\n        pass\n\n    def __neg__(self) -> ContinuedFraction:\n        \"\"\"\n        Division-free negation for a finite simple continued fraction, as\n        described `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/creating-continued-fractions.html#negative-continued-fractions>`_.\n\n        The basic algorithm can be described as follows: if\n        :math:`[a_0; a_1,\\\\ldots, a_n]` is the simple continued fraction of a\n        **positive** rational number :math:`\\\\frac{a}{b}` of finite order\n        :math:`n` then  :math:`-\\\\frac{a}{b}` has the simple continued\n        fraction:\n\n        .. math::\n\n           \\\\begin{cases}\n           [-a_0;]                                      \\\\hskip{3em} & n = 0 \\\\\\\\\n           [-(a_0 + 1); 2]                              \\\\hskip{3em} & n = 1 \\\\text{ and } a_1 = 2 \\\\\\\\\n           [-(a_0 + 1); a_2 + 1, a_3,\\\\ldots, a_n]      \\\\hskip{3em} & n \\\\geq 2 \\\\text{ and } a_1 = 1 \\\\\\\\\n           [-(a_0 + 1); 1, a_1 - 1, a_2, \\\\ldots,a_n]   \\\\hskip{3em} & n \\\\geq 2 \\\\text{ and } a_1 \\\\geq 2\n           \\\\end{cases}\n\n        In applying this algorithm there is an assumption that the last element\n        :math:`a_n > 1`, as any simple continued fraction of type\n        :math:`[a_0; a_1,\\\\ldots, a_{n} = 1]` can be reduced to the simple\n        continued fraction :math:`[a_0; a_1,\\\\ldots, a_{n - 1} + 1]`.\n        \"\"\"\n        pass\n\n    def __abs__(self) -> ContinuedFraction:\n        pass\n\n    def as_float(self) -> float:\n        \"\"\"Returns the :py:class:`float` value of the continued fraction.\n\n        Returns\n        -------\n        float\n            The :py:class:`float` value of the continued fraction.\n\n        Examples\n        --------\n        Note that the default :py:mod:`decimal` context precision of :math:`28`\n        is used in these examples.\n\n        >>> import math\n        >>> math.pi\n        3.141592653589793\n\n        Now construct a :py:class:`ContinuedFraction` instance from it, and check the \n        :py:class:`float` value.\n\n        >>> cf = ContinuedFraction(math.pi)\n        >>> cf\n        ContinuedFraction(884279719003555, 281474976710656)\n        >>> cf.as_float()\n        3.141592653589793\n        \"\"\"\n        pass\n\n    def as_decimal(self) -> Decimal:\n        \"\"\"Returns the :py:class:`decimal.Decimal` value of the continued fraction.\n\n        Returns\n        -------\n        decimal.Decimal\n            The :py:class:`decimal.Decimal` representation of the continued fraction.\n\n        Examples\n        --------\n        Note that the default :py:mod:`decimal` context precision of :math:`28`\n        is used in these examples.\n\n        >>> import math\n        >>> math.pi\n        3.141592653589793\n\n        Now construct a :py:class:`ContinuedFraction` instance from it, and check the \n        :py:class:`float` value.\n\n        >>> cf = ContinuedFraction(math.pi)\n        >>> cf\n        ContinuedFraction(884279719003555, 281474976710656)\n        >>> cf.as_decimal()\n        Decimal('3.141592653589793115997963469')\n        \"\"\"\n        pass\n\n    @property\n    def elements(self) -> tuple[int]:\n        \"\"\":py:class:`tuple`: The (ordered) sequence of elements of the continued fraction.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('.12345')\n        >>> cf\n        ContinuedFraction(2469, 20000)\n        >>> cf.elements\n        (0, 8, 9, 1, 21, 1, 1, 5)\n        \"\"\"\n        pass\n\n    @property\n    def order(self) -> int:\n        \"\"\":py:class:`int`: The order of the continued fraction, which is the number of its elements minus :math:`1`.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('.12345')\n        >>> cf\n        ContinuedFraction(2469, 20000)\n        >>> len(cf.elements)\n        8\n        >>> cf.order\n        7\n        \"\"\"\n        pass\n\n    @property\n    def counter(self) -> collections.Counter:\n        \"\"\":py:class:`collections.Counter` : A counter for the elements.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction(928374923, 8249234)\n        >>> cf.counter\n        Counter({1: 6, 2: 3, 24: 2, 112: 1, 5: 1, 3: 1})\n        \"\"\"\n        pass\n\n    @property\n    def khinchin_mean(self) -> Decimal | None:\n        \"\"\":py:class:`decimal.Decimal` or :py:data:`None`: The Khinchin mean of the continued fraction, which is defined as the geometric mean of all its elements after the 1st.\n\n        We define the Khinchin mean :math:`K_n` of a (simple) continued\n        fraction :math:`[a_0; a_1, a_2, \\\\ldots, a_n]` as:\n\n        .. math::\n\n           K_n := \\\\sqrt[n]{a_1a_2 \\\\cdots a_n} = \\\\left( a_1a_2 \\\\cdots a_n \\\\right)^{\\\\frac{1}{n}}, \\\\hskip{3em} n \\\\geq 1\n\n        This property is intended to make it easier to study the limit of\n        :math:`K_n` as :math:`n \\\\to \\\\infty`.  See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/exploring-continued-fractions.html#khinchin-means-khinchin-s-constant>`_\n        for more details.\n\n        In the special case of integers or fractions representing integers,\n        whose continued fraction representations consist of only a single\n        element, a null value is returned.\n\n        Examples\n        --------\n        Note that the default :py:mod:`decimal` context precision of :math:`28`\n        is used in these examples.\n\n        >>> ContinuedFraction(649, 200).elements\n        (3, 4, 12, 4)\n        >>> ContinuedFraction(649, 200).khinchin_mean\n        Decimal('5.76899828122963409526846589869819581508636474609375')\n        >>> ContinuedFraction(415, 93).elements\n        (4, 2, 6, 7)\n        >>> ContinuedFraction(415, 93).khinchin_mean\n        Decimal('4.37951913988788898990378584130667150020599365234375')\n        >>> (ContinuedFraction(649, 200) + ContinuedFraction(415, 93)).elements\n        (7, 1, 2, 2, 2, 1, 1, 11, 1, 2, 12)\n        >>> (ContinuedFraction(649, 200) + ContinuedFraction(415, 93)).khinchin_mean\n        Decimal('2.15015313349074244086978069390170276165008544921875')\n        >>> ContinuedFraction(5000).khinchin_mean\n\n        \"\"\"\n        pass\n\n    def convergent(self, k: int, /) -> ContinuedFraction:\n        \"\"\"Returns the :math:`k`-th (simple) convergent of the continued fraction.\n\n        Given a (simple) continued fraction  :math:`[a_0;a_1,a_2,\\\\ldots]` the\n        :math:`k`-th convergent is defined as:\n\n        .. math::\n\n           C_k = a_0 + \\\\cfrac{1}{a_1 + \\\\cfrac{1}{a_2 \\\\ddots \\\\cfrac{1}{a_{k-1} + \\\\cfrac{1}{a_k}}}}\n\n        The result is a :py:class:`~continuedfractions.continuedfraction.ContinuedFraction` instance.\n        \n        If  the continued fraction is of order :math:`n` then it has exactly\n        :math:`n + 1` convergents :math:`C_0,C_1,C_2,\\\\ldots,C_n` where\n        the :math:`k`-th convergent :math:`C_k = \\\\frac{p_k}{q_k}` is given by\n        the recurrence relation:\n\n        .. math::\n           \n           \\\\begin{align}\n           p_k &= a_kp_{k - 1} + p_{k - 2} \\\\\\\\\n           q_k &= a_kq_{k - 1} + q_{k - 2},        \\\\hskip{3em}    k \\\\geq 3\n           \\\\end{align}\n\n        where :math:`p_0 = a_0`, :math:`q_0 = 1`, :math:`p_1 = p_1p_0 + 1`,\n        and :math:`q_1 = p_1`.\n\n        Parameters\n        ----------\n        k : int\n            The index of the convergent, as described above.\n\n        Returns\n        -------\n        ContinuedFraction\n            A new :py:class:`ContinuedFraction` instance representing the :math:`k`-th\n            (simple) convergent of the original continued fraction, as\n            described above.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('.12345')\n        >>> cf\n        ContinuedFraction(2469, 20000)\n        >>> cf.convergent(0)\n        ContinuedFraction(0, 1)\n        >>> cf.convergent(2)\n        ContinuedFraction(9, 73)\n        >>> cf.convergent(6)\n        ContinuedFraction(448, 3629)\n        >>> cf.convergent(7)\n        ContinuedFraction(2469, 20000)\n        \"\"\"\n        pass\n\n    @property\n    def convergents(self) -> Generator[tuple[int, ContinuedFraction], None, None]:\n        \"\"\"Generates an enumerated sequence of all convergents of the continued fraction.\n\n        The convergents are generated as tuples of :py:class:`int` and\n        :py:class:`~continuedfraction.continuedfraction.ContinuedFraction`\n        instances, where the integers represent the indices of the convergents.\n\n        If :math:`n` is the order of the continued fraction then :math:`n + 1`\n        convergents :math:`C_0, C_1, \\\\ldots, C_n` are generated in that order.\n\n        Yields\n        ------\n        tuple\n            A tuple of convergent index (:py:class:`int`) and convergents\n            (:py:class:`~continuedfractions.continuedfraction.ContinuedFraction`)\n            of the continued fraction.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('3.245')\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)), (2, ContinuedFraction(159, 49)), (3, ContinuedFraction(649, 200)))\n        \"\"\"\n        pass\n\n    @property\n    def even_convergents(self) -> Generator[tuple[int, ContinuedFraction], None, None]:\n        \"\"\"Generates an enumerated sequence of all even-order convergents of the continued fraction.\n\n        The convergents are generated as tuples of :py:class:`int` and\n        :py:class:`~continuedfraction.continuedfraction.ContinuedFraction`\n        instances, where the integers represent the indices of the convergents.\n\n        If :math:`n` is the order of the continued fraction then only the even-\n        indexed convergents :math:`C_0, C_2, C_4, \\\\ldots` are generated.\n\n        Yields\n        ------\n        tuple\n            A tuple of convergent index (:py:class:`int`) and convergents\n            (:py:class:`~continuedfractions.continuedfraction.ContinuedFraction`)\n            of the continued fraction.\n\n        Examples\n        --------\n        >>> tuple(ContinuedFraction('3.245').even_convergents)\n        ((0, ContinuedFraction(3, 1)), (2, ContinuedFraction(159, 49)))\n        \"\"\"\n        pass\n\n    @property\n    def odd_convergents(self) -> Generator[tuple[int, ContinuedFraction], None, None]:\n        \"\"\"Generates an enumerated sequence of all odd-order convergents of the continued fraction.\n\n        The convergents are generated as tuples of :py:class:`int` and\n        :py:class:`~continuedfraction.continuedfraction.ContinuedFraction`\n        instances, where the integers represent the indices of the convergents.\n\n        If :math:`n` is the order of the continued fraction then only the odd-\n        indexed convergents :math:`C_1, C_3, C_5, \\\\ldots` are generated.\n\n        Yields\n        ------\n        tuple\n            A tuple of convergent index (:py:class:`int`) and convergents\n            (:py:class:`~continuedfractions.continuedfraction.ContinuedFraction`)\n            of the continued fraction.\n\n        Examples\n        --------\n        >>> tuple(ContinuedFraction('3.245').odd_convergents)\n        ((1, ContinuedFraction(13, 4)), (3, ContinuedFraction(649, 200)))\n        \"\"\"\n        pass\n\n    def semiconvergent(self, k: int, m: int, /) -> ContinuedFraction:\n        \"\"\"Returns the :math:`m`-th semiconvergent of two consecutive convergents :math:`p_{k - 1}` and :math:`p_k` of the continued fraction.\n\n        The integer :math:`k` must be positive and determine two consecutive\n        convergents :math:`p_{k - 1}` and :math:`p_k` of a (finite, simple)\n        continued fraction.\n\n        The integer :math:`m` can be any positive integer.\n\n        Parameters\n        ----------\n        k : int\n            The integer :math:`k` determining two consecutive convergents\n            :math:`p_{k - 1}` and :math:`p_k` of a (finite, simple) continued\n            fraction\n            :math:`[a_0; a_1, \\\\ldots, a_{k}, a_{k + 1}, \\\\ldots, a_n]`.\n\n        m : int\n            The index of the semiconvergent of the convergents\n            :math:`p_{k - 1}` and :math:`p_k`.\n\n        Returns\n        -------\n        ContinuedFraction\n            The :math:`m`-th semiconvergent of the convergents\n            :math:`p_{k - 1}` and :math:`p_k`.\n\n        Raises\n        ------\n        ValueError\n            If :math:`k` or :math:`m` are not positive integers, or :math:`k`\n            is an integer that does **not** satisfy :math:`1 \\\\leq k \\\\leq n`\n            where :math:`n` is the order of the (finite, simple) continued\n            fraction of which :math:`p_{k - 1}` and :math:`p_k` are\n            convergents.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction(-415, 93)\n        >>> cf.elements\n        (-5, 1, 1, 6, 7)\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(-5, 1)), (1, ContinuedFraction(-4, 1)), (2, ContinuedFraction(-9, 2)), (3, ContinuedFraction(-58, 13)), (4, ContinuedFraction(-415, 93)))\n        >>> cf.semiconvergent(3, 1)\n        ContinuedFraction(-67, 15)\n        >>> cf.semiconvergent(3, 2)\n        ContinuedFraction(-125, 28)\n        >>> cf.semiconvergent(3, 3)\n        ContinuedFraction(-183, 41)\n        >>> cf.semiconvergent(3, 4)\n        ContinuedFraction(-241, 54)\n        >>> cf.semiconvergent(3, 5)\n        ContinuedFraction(-299, 67)\n        >>> cf.semiconvergent(3, 6)\n        ContinuedFraction(-357, 80)\n        >>> cf.semiconvergent(3, 7)\n        ContinuedFraction(-415, 93)\n        \"\"\"\n        pass\n\n    def remainder(self, k: int, /) -> ContinuedFraction:\n        \"\"\"Returns the :math:`k`-th remainder of the continued fraction.\n\n        Given a (simple) continued fraction  :math:`[a_0;a_1,a_2,\\\\ldots]` the\n        :math:`k`-th remainder :math:`R_k` is the (simple) continued fraction\n        :math:`[a_k; a_{k + 1}, a_{k + 2}, \\\\ldots]`:\n\n        .. math::\n\n           R_k = a_k + \\\\cfrac{1}{a_{k + 1} + \\\\cfrac{1}{a_{k + 2} \\\\ddots }}\n\n        where :math:`R_0` is just the original continued fraction, i.e.\n        :math:`R_0 = [a_0; a_1, a_2, \\\\ldots]`.\n\n        The result is a :py:class:`~continuedfractions.continuedfraction.ContinuedFraction` instance.\n\n        The remainders satisfy the recurrence relation:\n\n        .. math::\n\n           R_{k - 1} = a_{k - 1} + \\\\frac{1}{R_k}, \\\\hskip{3em} k \\\\geq 1\n\n        If the original continued fraction is finite then its remainders are all\n        finite and rational.\n\n        As this class implements finite simple continued fractions, this method\n        always produces rational numbers.\n\n        The integer :math:`k` must be non-negative and cannot exceed the order\n        of the continued fraction, i.e. the number of its tail elements, and \n        the tail elements must define a valid finite simple continued fraction.\n\n        Parameters\n        ----------\n        k : int\n            The index of the remainder, as described above.\n\n        Returns\n        -------\n        ContinuedFraction\n            A new :py:class:`ContinuedFraction` instance representing the :math:`k`-th\n            remainder of the original continued fraction, as described above.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('.12345')\n        >>> cf\n        ContinuedFraction(2469, 20000)\n        >>> cf.remainder(0)\n        ContinuedFraction(2469, 20000)\n        >>> cf.remainder(2)\n        ContinuedFraction(2469, 248)\n        >>> cf.remainder(6)\n        ContinuedFraction(6, 5)\n        >>> cf.remainder(7)\n        ContinuedFraction(5, 1)\n        \"\"\"\n        pass\n\n    @property\n    def remainders(self) -> Generator[tuple[int, ContinuedFraction], None, None]:\n        \"\"\"Generates an enumerated sequence of all remainders of the continued fraction in descending order of index.\n\n        If :math:`n` is the order of the continued fraction then there are\n        :math:`n + 1` remainders :math:`R_0, R_1, \\\\ldots, R_n`, and the method\n        generates these in reverse order :math:`R_0, R_1, \\\\ldots, R_n`.\n\n        See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/exploring-continued-fractions.html#remainders>`_\n        for more details on remainders.\n\n        The remainders are generated as tuples of :py:class:`int`\n        and :py:class:`~continuedfraction.continuedfraction.ContinuedFraction`\n        instances, where the integers represent the indexes of the remainders.\n\n        Yields\n        ------\n        tuple\n            A tuple of remainder indices (:py:class:`int`) and remainders\n            (:py:class:`~continuedfractions.continuedfraction.ContinuedFraction`)\n            of the continued fraction.\n\n        Examples\n        --------\n        >>> tuple(ContinuedFraction('3.245').remainders)\n        ((3, ContinuedFraction(4, 1)), (2, ContinuedFraction(49, 4)), (1, ContinuedFraction(200, 49)), (0, ContinuedFraction(649, 200)))\n        >>> tuple(ContinuedFraction(-415, 93).remainders)\n        ((4, ContinuedFraction(7, 1)), (3, ContinuedFraction(43, 7)), (2, ContinuedFraction(50, 43)), (1, ContinuedFraction(93, 50)), (0, ContinuedFraction(-415, 93)))\n        \"\"\"\n        pass\n\n    def left_mediant(self, other: Fraction, /, *, k: int = 1) -> ContinuedFraction:\n        \"\"\"Returns the :math:`k`-th left-mediant of the continued fraction with another rational number.\n        \n        For a positive integer :math:`k`, the :math:`k`-th left-mediant of two\n        rational numbers :math:`r = \\\\frac{a}{b}` and :math:`s = \\\\frac{c}{d}`,\n        where :math:`b, d, b + d \\\\neq 0`, is defined as:\n        \n        .. math::\n\n           \\\\frac{ka + c}{kb + d}, \\\\hskip{3em}    k \\\\geq 1\n\n        while the :math:`k`-th right mediant is defined as:\n        \n        .. math::\n\n           \\\\frac{a + kc}{b + kd}, \\\\hskip{3em}    k \\\\geq 1\n\n        If we assume that :math:`r < s` and :math:`bd > 0` then these mediants\n        have the property that:\n       \n        .. math::\n\n           \\\\frac{a}{b} < \\\\frac{ka + c}{kb + d} \\\\leq \\\\frac{a + kc}{b + kd} < \\\\frac{c}{d},   \\\\hskip{3em} k \\\\geq 1\n\n        where equality holds for :math:`k = 1`. If we let :math:`k \\\\to \\\\infty`\n        then the mediants converge to opposite limits:\n\n        .. math::\n\n          \\\\begin{align}\n          \\\\lim_{k \\\\to \\\\infty} \\\\frac{ka + c}{kb + d} &= \\\\frac{a}{b} \\\\\\\\\n          \\\\lim_{k \\\\to \\\\infty} \\\\frac{a + kc}{b + kd} &= \\\\frac{c}{d}\n          \\\\end{align}\n\n        For more information consult the\n        `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/mediants.html>`_.\n\n        The method is cached (with :py:func:`functools.cache`), which makes calls\n        after the initial call much faster.\n\n        Parameters\n        ----------\n        other : fractions.Fraction, ContinuedFraction\n            The second fraction to use to calculate the :math:`k`-th mediant with\n            the first.\n        \n        k : int, default=1\n            The order of the mediant, as defined above.        \n\n        Returns\n        -------\n        ContinuedFraction\n            The :math:`k`-th left-mediant of the original fraction and the second\n            fraction, as a :py:class:`ContinuedFraction` instance.\n\n        Examples\n        --------\n        >>> c1 = ContinuedFraction('1/2')\n        >>> c2 = ContinuedFraction(3, 5)\n        >>> c1, c2\n        (ContinuedFraction(1, 2), ContinuedFraction(3, 5))\n        >>> c1.left_mediant(c2)\n        ContinuedFraction(4, 7)\n        >>> c1.left_mediant(c2, k=2)\n        ContinuedFraction(5, 9)\n        >>> c1.left_mediant(c2, k=3)\n        ContinuedFraction(6, 11)\n        >>> c1.left_mediant(c2, k=100)\n        ContinuedFraction(103, 205)\n        >>> assert c1.left_mediant(c2, k=2) < c1.right_mediant(c2, k=2)\n        >>> assert c1.left_mediant(c2, k=3) < c1.right_mediant(c2, k=3)\n        >>> assert c1.left_mediant(c2, k=100) < c1.right_mediant(c2, k=100)\n        \"\"\"\n        pass\n\n    def right_mediant(self, other: Fraction, /, *, k: int = 1) -> ContinuedFraction:\n        \"\"\"Returns the :math:`k`-th right-mediant of the continued fraction with another rational number.\n        \n        For a positive integer :math:`k`, the :math:`k`-th right-mediant of two\n        rational numbers :math:`r = \\\\frac{a}{b}` and :math:`s = \\\\frac{c}{d}`,\n        where :math:`b, d, b + d \\\\neq 0`, is defined as:\n        \n        .. math::\n\n           \\\\frac{a + kc}{b + kd}, \\\\hskip{3em}    k \\\\geq 1\n\n        while the :math:`k`-th left-mediant is defined as:\n        \n        .. math::\n\n           \\\\frac{ka + c}{kb + d}, \\\\hskip{3em}    k \\\\geq 1\n\n        If we assume that :math:`r < s` and :math:`bd > 0` then these mediants\n        have the property that:\n       \n        .. math::\n\n           \\\\frac{a}{b} < \\\\frac{ka + c}{kb + d} \\\\leq \\\\frac{a + kc}{b + kd} < \\\\frac{c}{d},   \\\\hskip{3em} k \\\\geq 1\n\n        where equality holds for :math:`k = 1`. If we let :math:`k \\\\to \\\\infty`\n        then the mediants converge to opposite limits:\n\n        .. math::\n\n          \\\\begin{align}\n          \\\\lim_{k \\\\to \\\\infty} \\\\frac{ka + c}{kb + d} &= \\\\frac{a}{b} \\\\\\\\\n          \\\\lim_{k \\\\to \\\\infty} \\\\frac{a + kc}{b + kd} &= \\\\frac{c}{d}\n          \\\\end{align}\n\n        For more information consult the\n        `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/mediants.html>`_.\n\n        Parameters\n        ----------\n        other : fractions.Fraction, ContinuedFraction\n            The second fraction to use to calculate the :math:`k`-th mediant with\n            the first.\n        \n        k : int, default=1\n            The order of the mediant, as defined above.        \n\n        Returns\n        -------\n        ContinuedFraction\n            The :math:`k`-th right-mediant of the original fraction and the second\n            fraction, as a :py:class:`ContinuedFraction` instance.\n\n        Examples\n        --------\n        >>> c1 = ContinuedFraction('1/2')\n        >>> c2 = ContinuedFraction(3, 5)\n        >>> c1, c2\n        (ContinuedFraction(1, 2), ContinuedFraction(3, 5))\n        >>> c1.right_mediant(c2)\n        ContinuedFraction(4, 7)\n        >>> c1.right_mediant(c2, k=2)\n        ContinuedFraction(7, 12)\n        >>> c1.right_mediant(c2, k=3)\n        ContinuedFraction(10, 17)\n        >>> c1.right_mediant(c2, k=100)\n        ContinuedFraction(301, 502)\n        >>> assert c1.left_mediant(c2, k=2) < c1.right_mediant(c2, k=2)\n        >>> assert c1.left_mediant(c2, k=3) < c1.right_mediant(c2, k=3)\n        >>> assert c1.left_mediant(c2, k=100) < c1.right_mediant(c2, k=100)\n        \"\"\"\n        pass\n\n    def mediant(self, other: Fraction, /) -> ContinuedFraction:\n        \"\"\"Returns the simple mediant of the continued fraction with another continued fraction.\n        \n        The simple mediant of two rational numbers :math:`r = \\\\frac{a}{b}`\n        and :math:`s = \\\\frac{c}{d}`, where :math:`b, d, b + d \\\\neq 0`, is\n        defined as:\n        \n        .. math::\n\n           \\\\frac{a + c}{b + d}\n\n        The resulting value :math:`\\\\frac{a + c}{b + d}` is the same as the\n        1st order left- or right-mediant of :math:`r = \\\\frac{a}{b}`\n        and :math:`s = \\\\frac{c}{d}`. So this method would produce the same\n        result as the :py:meth:`~continuedfractions.continuedfraction.ContinuedFraction.left_mediant`\n        or :py:meth:`~continuedfractions.continuedfraction.ContinuedFraction.right_mediant`\n        methods where the order :math:`k` is set to :math:`1`.\n\n        For more information consult the\n        `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/mediants.html>`_.\n\n        Parameters\n        ----------\n        other : fractions.Fraction, ContinuedFraction\n            The other continued fraction.\n        \n        Returns\n        -------\n        ContinuedFraction\n            The simple mediant of the original fraction and the other continued\n            fraction.\n\n        Examples\n        --------\n        >>> ContinuedFraction(1, 2).mediant(ContinuedFraction(3, 5))\n        ContinuedFraction(4, 7)\n        >>> assert ContinuedFraction(1, 2).mediant(ContinuedFraction(3, 5)) == ContinuedFraction(1, 2).left_mediant(ContinuedFraction(3, 5), k=1)\n        >>> assert ContinuedFraction(1, 2).mediant(ContinuedFraction(3, 5)) == ContinuedFraction(1, 2).right_mediant(ContinuedFraction(3, 5), k=1)\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "src/continuedfractions/sequences.py",
                "code": "def coprime_integers_generator(n: int, /, *, start: int = 1, stop: int = None) -> Generator[int, None, None]:\n    \"\"\"Generates a sequence of (positive) integers :math:`1 \\\\leq m < n` coprime to a given positive integer :math:`n`.\n\n    The tuple is sorted in descending order of magnitude.\n\n    The optional ``start`` and ``stop`` parameters can be used to bound the\n    the range of (positive) integers in which integers coprime to the given\n    :math:`n` are sought.\n\n    For :math:`n = 1, 2` the ``start`` value is effectively ignored, but\n    if :math:`n > 1` then the ``start`` value must be an integer in the range\n    :math:`1..n - 1`.\n\n    The ``stop`` value defaults to ``None``, which is then internally\n    initialised to :math:`n`; if :math:`n > 1` and ``stop`` is given then it\n    must be an integer in the range :math:`\\\\text{start} + 1..n`.\n\n    Parameters\n    ----------\n    n : int\n        The positive integer for which (positive) coprime integers\n        :math:`m < n` are sought.\n\n    start : int, default=1\n        The lower bound of the range of (positive) integers in which integers\n        coprime to the given :math:`n` are sought. For :math:`n = 1, 2` the\n        ``start`` value is effectively ignored, but if :math:`n > 1` then the\n        ``start`` value must be in the range :math:`1..n - 1`.\n\n    stop : int, default=None\n        The upper bound of the range of (positive) integers in which integers\n        coprime to the given :math:`n` are sought. The ``stop`` value defaults\n        to ``None``, which is then internally initialised to :math:`n`; if\n        :math:`n > 1` and ``stop`` is given then it must be an integer in the\n        range :math:`\\\\text{start} + 1..n`.\n\n    Raises\n    ------\n    ValueError\n        If :math:`n` is either not a positive integer, or :math:`n > 1` such\n        that either the ``start`` value is **not** in the range\n        :math:`1..n - 1` or the ``stop`` value is **not** in the range\n        :math:`\\\\text{start} + 1..n`.\n\n    Yields\n    ------\n    int\n        A sequence of (positive) integers :math:`1 \\\\leq m < n` coprime to a\n        given positive integer :math:`n`.\n\n    Examples\n    --------\n    Examples using the default ``start`` and ``stop`` values:\n\n    >>> tuple(coprime_integers_generator(1))\n    (1,)\n    >>> tuple(coprime_integers_generator(2))\n    (1,)\n    >>> tuple(coprime_integers_generator(3))\n    (2, 1)\n    >>> tuple(coprime_integers_generator(4))\n    (3, 1)\n    >>> tuple(coprime_integers_generator(5))\n    (4, 3, 2, 1)\n    >>> tuple(coprime_integers_generator(6))\n    (5, 1)\n    >>> tuple(coprime_integers_generator(7))\n    (6, 5, 4, 3, 2, 1)\n    >>> tuple(coprime_integers_generator(8))\n    (7, 5, 3, 1)\n    >>> tuple(coprime_integers_generator(9))\n    (8, 7, 5, 4, 2, 1)\n    >>> tuple(coprime_integers_generator(10))\n    (9, 7, 3, 1)\n    >>> tuple(coprime_integers_generator(11))\n    (10, 9, 8, 7, 6, 5, 4, 3, 2, 1)\n\n    Examples using custom ``start`` and ``stop`` values:\n\n    >>> tuple(coprime_integers_generator(3, start=0))\n    Traceback (most recent call last):\n    ...\n    ValueError: `n` must be a positive integer; if `n` > 1 then the `start` value must be a positive integer in the range 1..n - 1; and if given the `stop` value must be a positive integer in the range `start` + 1..n\n    >>> tuple(coprime_integers_generator(3, start=2))\n    (2,)\n    >>> tuple(coprime_integers_generator(3, start=3))\n    Traceback (most recent call last):\n    ...\n    ValueError: `n` must be a positive integer; if `n` > 1 then the `start` value must be a positive integer in the range 1..n - 1; and if given the `stop` value must be a positive integer in the range `start` + 1..n\n    >>> tuple(coprime_integers_generator(23, start=5, stop=21))\n    (21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5)\n    >>> tuple(coprime_integers_generator(5, start=2))\n    (4, 3, 2)\n    >>> tuple(coprime_integers_generator(5, start=3))\n    (4, 3)\n    >>> tuple(coprime_integers_generator(6, start=2))\n    (5,)\n    >>> tuple(coprime_integers_generator(6, start=3))\n    (5,)\n    >>> tuple(coprime_integers_generator(6, start=4))\n    (5,)\n    >>> tuple(coprime_integers_generator(7, start=2))\n    (6, 5, 4, 3, 2)\n    >>> tuple(coprime_integers_generator(7, start=3))\n    (6, 5, 4, 3)\n    >>> tuple(coprime_integers_generator(7, start=4))\n    (6, 5, 4)\n    >>> tuple(coprime_integers_generator(7, start=5))\n    (6, 5)\n    \"\"\"\n    pass\n\ndef coprime_integers(n: int, /, *, start: int = 1, stop: int = None) -> tuple[int]:\n    \"\"\"Returns a sequence of (positive) integers :math:`1 \\\\leq m < n` coprime to a given positive integer :math:`n`.\n\n    Wrapper of :py:class:`~continuedfractions.sequences.coprime_integers_generator`.\n\n    The tuple is sorted in descending order of magnitude.\n\n    The optional ``start`` and ``stop`` parameters can be used to bound the\n    the range of (positive) integers in which integers coprime to the given\n    :math:`n` are sought.\n\n    For :math:`n = 1, 2` the ``start`` value is effectively ignored, but\n    if :math:`n > 1` then the ``start`` value must be an integer in the range\n    :math:`1..n - 1`.\n\n    The ``stop`` value defaults to ``None``, which is then internally\n    initialised to :math:`n`; if :math:`n > 1` and ``stop`` is given then it\n    must be an integer in the range :math:`\\\\text{start} + 1..n`.\n\n    Parameters\n    ----------\n    n : int\n        The positive integer for which (positive) coprime integers\n        :math:`m < n` are sought.\n\n    start : int, default=1\n        The lower bound of the range of (positive) integers in which integers\n        coprime to the given :math:`n` are sought. For :math:`n = 1, 2` the\n        ``start`` value is effectively ignored, but if :math:`n > 1` then the\n        ``start`` value must be in the range :math:`1..n - 1`.\n\n    stop : int, default=None\n        The upper bound of the range of (positive) integers in which integers\n        coprime to the given :math:`n` are sought. The ``stop`` value defaults\n        to ``None``, which is then internally initialised to :math:`n`; if\n        :math:`n > 1` and ``stop`` is given then it must be an integer in the\n        range :math:`\\\\text{start} + 1..n`.\n\n    Returns\n    -------\n    tuple\n        A sequence of (positive) integers :math:`1 \\\\leq m < n` coprime to a\n        given positive integer :math:`n`.\n\n    Examples\n    --------\n    Examples using the default ``start`` and ``stop`` values:\n\n    >>> coprime_integers(1)\n    (1,)\n    >>> coprime_integers(2)\n    (1,)\n    >>> coprime_integers(3)\n    (2, 1)\n    >>> coprime_integers(4)\n    (3, 1)\n    >>> coprime_integers(5)\n    (4, 3, 2, 1)\n    >>> coprime_integers(6)\n    (5, 1)\n    >>> coprime_integers(7)\n    (6, 5, 4, 3, 2, 1)\n    >>> coprime_integers(8)\n    (7, 5, 3, 1)\n    >>> coprime_integers(9)\n    (8, 7, 5, 4, 2, 1)\n    >>> coprime_integers(10)\n    (9, 7, 3, 1)\n    >>> coprime_integers(11)\n    (10, 9, 8, 7, 6, 5, 4, 3, 2, 1)\n\n    Examples using custom ``start`` and ``stop`` values:\n\n    >>> coprime_integers(3, start=2)\n    (2,)\n    >>> coprime_integers(3, start=3)\n    Traceback (most recent call last):\n    ...    \n    ValueError: `n` must be a positive integer; if `n` > 1 then the `start` value must be a positive integer in the range 1..n - 1; and if given the `stop` value must be a positive integer in the range `start` + 1..n\n    >>> coprime_integers(23, start=5, stop=21)\n    (21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5)\n    >>> coprime_integers(5, start=2)\n    (4, 3, 2)\n    >>> coprime_integers(5, start=3)\n    (4, 3)\n    >>> coprime_integers(6, start=2)\n    (5,)\n    >>> coprime_integers(6, start=3)\n    (5,)\n    >>> coprime_integers(6, start=4)\n    (5,)\n    >>> coprime_integers(7, start=2)\n    (6, 5, 4, 3, 2)\n    >>> coprime_integers(7, start=3)\n    (6, 5, 4, 3)\n    >>> coprime_integers(7, start=4)\n    (6, 5, 4)\n    >>> coprime_integers(7, start=5)\n    (6, 5)\n    \"\"\"\n    pass\n\nclass KSRMTree:\n    \"\"\"An implicit/generative class implementation of the Kanga-Saunders-Randall-Mitchell (KSRM) ternary trees for representing and generating pairs of all (positive) coprime integers.\n\n    The term \"KSRM trees\" is the author's, and refers to the trees presented in the following papers:\n\n    * Kanga, A. R. (1990). The Family Tree of Pythagorean Triplets. The Mathematical Gazette, 26(15), 15-17.\n    * Mitchell, D. W. (2001). An Alternative Characterisation of All Primitive Pythagorean Triples. The Mathematical Gazette, 85(503), 273-275. https://doi.org/10.2307/3622017\n    * Saunders, R., & Randall, T. (1994). The family tree of the Pythagorean triplets revisited. The Mathematical Gazette, 78(482), 190-193. https://doi.org/10.2307/3618576\n\n    .. note::\n\n       The class is named ``KSRMTree`` purely for convenience, but it is\n       actually a representation of two (ternary) subtrees.\n\n    .. note::\n\n       The author could not access the Kanga paper online, but the core result\n       is described clearly in the papers of Saunders and Randall, and of\n       Mitchell.\n\n    See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/sequences.html#ksrm-trees>`_\n    for more details.\n    \"\"\"\n    def __new__(cls) -> KSRMTree:\n        \"\"\"Class constructor.\n\n        Creates and initialises a new instance with the minimum set of required\n        attributes - for the roots and branch generating functions, which we\n        call branches.\n        \"\"\"\n        pass\n\n    @property\n    def roots(self) -> Literal[tuple([(2, 1), (3, 1)])]:\n        \"\"\":py:class:`tuple`: The tuple of roots of the KSRM trees, which are :math:`(2, 1)` and :math:`(3, 1)`.\n\n        For more details see the following papers:\n\n        * Kanga, A. R. (1990). The Family Tree of Pythagorean Triplets. The Mathematical Gazette, 26(15), 15-17.\n        * Mitchell, D. W. (2001). An Alternative Characterisation of All Primitive Pythagorean Triples. The Mathematical Gazette, 85(503), 273-275. https://doi.org/10.2307/3622017\n        * Saunders, R., & Randall, T. (1994). The family tree of the Pythagorean triplets revisited. The Mathematical Gazette, 78(482), 190-193. https://doi.org/10.2307/3618576\n\n        or the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/sequences.html#ksrm-trees>`_.\n\n        Examples\n        --------\n        >>> KSRMTree().roots\n        ((2, 1), (3, 1))\n        \"\"\"\n        pass\n\n    @property\n    def branches(self) -> tuple[KSRMBranch]:\n        \"\"\":py:class:`tuple`: The tuple of three branch generating functions of the KSRM trees.\n\n        There are three branch generating functions, given by the mappings:\n\n        .. math::\n\n           \\\\begin{align}\n           (a, b) &\\\\longmapsto (2a - b, a) \\\\\\\\\n           (a, b) &\\\\longmapsto (2a + b, a) \\\\\\\\\n           (a, b) &\\\\longmapsto (a + 2b, b)\n           \\\\end{align}\n\n        For more details see the following papers:\n\n        * Kanga, A. R. (1990). The Family Tree of Pythagorean Triplets. The Mathematical Gazette, 26(15), 15-17.\n        * Mitchell, D. W. (2001). An Alternative Characterisation of All Primitive Pythagorean Triples. The Mathematical Gazette, 85(503), 273-275. https://doi.org/10.2307/3622017\n        * Saunders, R., & Randall, T. (1994). The family tree of the Pythagorean triplets revisited. The Mathematical Gazette, 78(482), 190-193. https://doi.org/10.2307/3618576\n\n        or the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/sequences.html#ksrm-trees>`_.\n\n        Examples\n        --------\n        Generating the first two generations of children for the parent\n        :math:`(2, 1)`.\n\n        >>> tree = KSRMTree()\n        >>> tree.branches\n        (NamedCallableProxy(\"KSRM tree branch #1: (x, y) |--> (2x - y, x)\"), NamedCallableProxy(\"KSRM tree branch #2: (x, y) |--> (2x + y, x)\"), NamedCallableProxy(\"KSRM tree branch #3: (x, y) |--> (x + 2y, y)\"))\n        >>> tree.branches[0](2, 1)\n        (3, 2)\n        >>> tree.branches[1](2, 1)\n        (5, 2)\n        >>> tree.branches[2](2, 1)\n        (4, 1)\n        >>> tree.branches[0](*tree.branches[0](2, 1))\n        (4, 3)\n        >>> tree.branches[1](*tree.branches[0](2, 1))\n        (8, 3)\n        >>> tree.branches[2](*tree.branches[0](2, 1))\n        (7, 2)\n        >>> tree.branches[0](*tree.branches[1](2, 1))\n        (8, 5)\n        >>> tree.branches[1](*tree.branches[1](2, 1))\n        (12, 5)\n        >>> tree.branches[2](*tree.branches[1](2, 1))\n        (9, 2)\n        >>> tree.branches[0](*tree.branches[2](2, 1))\n        (7, 4)\n        >>> tree.branches[1](*tree.branches[2](2, 1))\n        (9, 4)\n        >>> tree.branches[2](*tree.branches[2](2, 1))\n        (6, 1)\n        \"\"\"\n        pass\n\n    def _backtrack( self, n: int, visited: list[tuple[KSRMNode, KSRMBranch]], /, *, node_bound: int = None ) -> tuple[KSRMNode, KSRMBranch, int, KSRMBranch]:\n        \"\"\"Backtracks on the KSRM coprime pairs trees from a failed node to the nearest previously visited node that satisfies the node bound.\n\n        A private function that backtracks on the KSRM coprime pairs trees: the\n        procedure is that, given a (positive) integer :math:`n > 2`, for which\n        coprime pairs are being sought, and a sequence (list) of pairs of\n        visited nodes and their associated generating branches in the KSRM\n        tree, and assuming that the last element of the visited sequence\n        contains the node that \"failed\", the function identifies the nearest\n        previously visited node whose first component satisifes the test\n        :math:`< n` **and** and whose associated generating branch is not equal\n        to the third branch given by :math:`(x, y) \\\\longmapsto (x + 2y, y)`.\n\n        .. note::\n\n           The function assumes that the last node in the incoming sequence\n           of visited nodes and generating branch pairs represents a \"failed\"\n           node, i.e. whose first component failed the test :math:`\\\\leq n`\n           during the search. No attempt is made to validate or verify the\n           failed node, and the only purpose of the function is to backtrack\n           to the nearest previously visited node which meets the requirements\n           listed above.\n\n        .. note::\n\n           There is no input validation as this is a private function which\n           will be called from\n           :py:meth:`~continuedfractions.sequences.KSRMTree.search_root`. So\n           results for invalid arguments will most likely be incorrect or\n           unexpected.\n\n        Parameters\n        ----------\n        n : int\n            The (positive) integer :math:`> 2` which is passed by the root\n            search method or the general tree search method.\n\n        visited : list\n            A sequence of visited nodes and associated generating branches in\n            the KSRM coprime pairs tree.\n\n        node_bound : int, default=None\n            A bound to check that :math:`a < n` for a node :math:`(a, b)`. The\n            actual default value is the incoming :math:`n`, and this is set\n            internally.\n\n        Returns\n        -------\n        tuple\n            A tuple consisting of the following values in order: (1) the\n            target node in the visited sequence to backtrack to, (2) the\n            associated generating branch function (the lambda for branch #1,\n            or branch #2, or branch #3), (3) the index of the target node\n            and branch pair in the visited sequence, (4) the generating\n            branch of the successor node of the target node returned as (1).\n\n        Examples\n        --------\n        An example where :math:`n = 5` and the failed node is :math:`(6, 1)`,\n        which was the successor node to :math:`(4, 1)` from the third branch.\n\n        >>> tree = KSRMTree()\n        >>> tree.branches\n        (NamedCallableProxy(\"KSRM tree branch #1: (x, y) |--> (2x - y, x)\"), NamedCallableProxy(\"KSRM tree branch #2: (x, y) |--> (2x + y, x)\"), NamedCallableProxy(\"KSRM tree branch #3: (x, y) |--> (x + 2y, y)\"))\n        >>> visited = [((2, 1), None), ((4, 1), tree.branches[-1]), ((6, 1), tree.branches[-1])]\n        >>> tree._backtrack(5, visited)\n        ((2, 1), None, 0, NamedCallableProxy(\"KSRM tree branch #3: (x, y) |--> (x + 2y, y)\"))\n\n        An example where :math:`n = 8` and the failed node is :math:`(19, 8)`,\n        which was the successor node to :math:`(8, 3)` from the first branch.\n\n        >>> tree = KSRMTree()\n        >>> tree.branches\n        (NamedCallableProxy(\"KSRM tree branch #1: (x, y) |--> (2x - y, x)\"), NamedCallableProxy(\"KSRM tree branch #2: (x, y) |--> (2x + y, x)\"), NamedCallableProxy(\"KSRM tree branch #3: (x, y) |--> (x + 2y, y)\"))\n        >>> visited = [((2, 1), None), ((3, 2),tree.branches[0]), ((8, 3),tree.branches[1]), ((19, 8), tree.branches[0])]\n        >>> tree._backtrack(8, visited)\n        ((3, 2), NamedCallableProxy(\"KSRM tree branch #1: (x, y) |--> (2x - y, x)\"), 1, NamedCallableProxy(\"KSRM tree branch #2: (x, y) |--> (2x + y, x)\"))\n        \"\"\"\n        pass\n\n    def search_root(self, n: int, root: KSRMNode, /) -> Generator[KSRMNode, None, None]:\n        \"\"\"Depth-first branch-and-bound generative search function (in pre-order, NLMR), with backtracking and pruning, on the KSRM coprime pairs trees, starting from the given root node.\n\n        The given root node need not be the canonical roots, :math:`(2, 1)`,\n        :math:`(3, 1)`, but can be any of their successor nodes.\n\n        It is required that :math:`n \\\\geq 2`, otherwise a\n        :py:class:`ValueError` is raised.\n\n        The search implementation is an iterative version of a depth-first\n        branch-and-bound search (DFS) procedure, with backtracking and pruning,\n        in which nodes are traversed in NLMR pre-order (root -> left -> mid ->\n        right) and bounds and checks are applied to the nodes, including\n        pruning failed or unnecessary nodes, before further traversal or\n        backtracking:\n        \n        #. Visit the current node :math:`(a, b)` and check :math:`a \\\\leq n`.\n        #. If the check is successful iteratively traverse the current node's\n           first child and its children, then the second child and its \n           children, and then the third child and its children, applying the\n           check :math:`a \\\\leq n` to each visited node.\n        #. If a check fails for any node backtrack to the nearest previously\n           visited node which meets a stricter check :math:`a < n` and which\n           has unvisited child nodes, while pruning all visited intermediate\n           nodes after the backtracked target node and leading up to the failed\n           node, including the failed node. By design the backtracked target\n           node will have untraversed children on at least one branch, and the\n           traversal can begin again, as described above.\n\n        Parameters\n        ----------\n        n : int\n            The positive integer for which coprime pairs :math:`(a, b)`, with\n            :math:`1 \\\\leq b < a \\\\leq n`, are sought.\n\n        root : tuple\n            The \"root\" node from which to search - this can be either of the\n            canonical roots, :math:`(2, 1)`, :math:`(3, 1)`, but also any of\n            their successor nodes.\n\n        Raises\n        ------\n        ValueError\n            If ``n`` is not an integer or is :math:`< 2`.\n\n        Yields\n        ------\n        tuple\n            Pairs of coprime integers :math:`(a, b)`, with\n            :math:`1 \\\\leq b < a \\\\leq n`.\n\n        Examples\n        --------\n        Searching from the root :math:`(2, 1)` for coprime pairs for\n        :math:`n = 5`:\n\n        >>> tree = KSRMTree()\n        >>> list(tree.search_root(5, (2, 1)))\n        [(2, 1), (3, 2), (4, 3), (5, 4), (5, 2), (4, 1)]\n        >>> assert tree.roots[0] == (2, 1)\n        >>> list(tree.search_root(5, tree.roots[0]))\n        [(2, 1), (3, 2), (4, 3), (5, 4), (5, 2), (4, 1)]\n\n        The same type of search from the root :math:`(3, 1)`:\n\n        >>> list(tree.search_root(5, (3, 1)))\n        [(3, 1), (5, 3), (5, 1)]\n        >>> assert tree.roots[1] == (3, 1)\n        >>> list(tree.search_root(5, tree.roots[1]))\n        [(3, 1), (5, 3), (5, 1)]\n        \"\"\"\n        pass\n\n    def search(self, n: int, /) -> Generator[KSRMNode, None, None]:\n        \"\"\"Depth-first branch-and-bound generative search function (in pre-order, NLMR) on the KSRM coprime pairs trees to find all pairs of coprime (positive) integers not exceeding the given integer :math:`n \\\\geq 1`.\n    \n        See the :py:meth:`~continuedfractions.sequences.KSRMTree.search_root`\n        method for details of the implementation for the root-based search.\n\n        This method mainly calls the root-based search method\n        :py:meth:`~continuedfractions.sequences.KSRMTree.search_root` for the\n        two canonical roots :math:`(2, 1)` and :math:`(3, 1)`.\n\n        Parameters\n        ----------\n        n : int\n            The positive integer for which coprime pairs :math:`(a, b)`, with\n            :math:`1 \\\\leq b < a \\\\leq n`, are sought.\n\n        Raises\n        ------\n        ValueError\n            If ``n`` is not an integer or is :math:`< 1`.\n\n        Yields\n        ------\n        tuple\n            Pairs of coprime integers :math:`(a, b)`, with\n            :math:`1 \\\\leq b < a \\\\leq n`.\n\n        Examples\n        --------\n        A few examples of invalid and valid searches:\n\n        >>> tree = KSRMTree()\n        >>> list(tree.search(\"not an integer\"))\n        Traceback (most recent call last):\n        ...\n        ValueError: `n` must be a positive integer >= 1\n        >>> list(tree.search(1))\n        [(1, 1)]\n        >>> list(tree.search(2))\n        [(1, 1), (2, 1)]\n        >>> list(tree.search(3))\n        [(1, 1), (2, 1), (3, 2), (3, 1)]\n        >>> list(tree.search(5))\n        [(1, 1), (2, 1), (3, 2), (4, 3), (4, 1), (3, 1), (5, 4), (5, 3), (5, 2), (5, 1)]\n        >>> list(tree.search(10))\n        [(1, 1), (2, 1), (3, 2), (4, 3), (5, 4), (6, 5), (7, 6), (8, 7), (9, 8), (8, 3), (7, 2), (5, 2), (8, 5), (4, 1), (7, 4), (9, 4), (6, 1), (8, 1), (3, 1), (5, 3), (7, 5), (9, 7), (7, 3), (5, 1), (9, 5), (7, 1), (9, 1), (10, 9), (10, 7), (10, 3), (10, 1)]\n        \"\"\"\n        pass\n\ndef coprime_pairs_generator(n: int, /) -> Generator[KSRMNode, None, None]:\n    \"\"\"Generates a sequence (tuple) of all pairs of (positive) coprime integers :math:`<= n`.\n\n    Calls the KSRM tree :py:meth:`~continuedfractions.sequences.KSRMTree.search`\n    to perform the search up to :math:`n - 1` and then uses\n    :py:func:`~continuedfractions.sequences.coprime_integers` for the search\n    for pairs involving :math:`n`.\n\n    A :py:class:`ValueError` is raised if ``n`` is not an :py:class:`int`\n    or is an :py:class:`int` less than :math:`1`.\n\n    Parameters\n    ----------\n    n : int\n        The positive integer for which coprime pairs :math:`(a, b)`, with\n        :math:`1 \\\\leq b < a \\\\leq n`, are sought.\n\n    Raises\n    ------\n    ValueError\n        If ``n`` is not an :py:class:`int` or is an :py:class:`int` less than\n        :math:`1`.\n\n    Yields\n    ------\n    tuple\n        A :py:class:`tuple` of pairs of coprime integers :math:`(a, b)`, with\n        :math:`1 \\\\leq b < a \\\\leq n`.\n\n    Examples\n    --------\n    A few examples of coprime pairs generation:\n\n    >>> tuple(coprime_pairs_generator(1))\n    ((1, 1),)\n    >>> tuple(coprime_pairs_generator(2))\n    ((1, 1), (2, 1))\n    >>> tuple(coprime_pairs_generator(3))\n    ((1, 1), (2, 1), (3, 2), (3, 1))\n    >>> tuple(coprime_pairs_generator(5))\n    ((1, 1), (2, 1), (3, 2), (3, 1), (4, 3), (4, 1), (5, 4), (5, 3), (5, 2), (5, 1))\n    >>> tuple(coprime_pairs_generator(10))\n    ((1, 1), (2, 1), (3, 2), (4, 3), (5, 4), (6, 5), (7, 6), (8, 7), (8, 3), (7, 2), (5, 2), (8, 5), (4, 1), (7, 4), (6, 1), (8, 1), (3, 1), (5, 3), (7, 5), (7, 3), (5, 1), (7, 1), (9, 8), (9, 7), (9, 5), (9, 4), (9, 2), (9, 1), (10, 9), (10, 7), (10, 3), (10, 1))\n    \"\"\"\n    pass\n\ndef coprime_pairs(n: int, /) -> tuple[KSRMNode]:\n    \"\"\"Returns a sequence (tuple) of all pairs of (positive) coprime integers :math:`<= n`.\n\n    Wrapper of :py:func:`~continuedfractions.sequences.coprime_pairs_generator`.\n\n    Parameters\n    ----------\n    n : int\n        The positive integer for which coprime pairs :math:`(a, b)`, with\n        :math:`1 \\\\leq b < a \\\\leq n`, are sought.\n\n    Returns\n    -------\n    tuple\n        A :py:class:`tuple` of pairs of coprime integers :math:`(a, b)`, with\n        :math:`1 \\\\leq b < a \\\\leq n`.\n\n    Examples\n    --------\n    A few examples of computing coprime pairs:\n\n    >>> coprime_pairs(1)\n    ((1, 1),)\n    >>> coprime_pairs(2)\n    ((1, 1), (2, 1))\n    >>> coprime_pairs(3)\n    ((1, 1), (2, 1), (3, 2), (3, 1))\n    >>> coprime_pairs(5)\n    ((1, 1), (2, 1), (3, 2), (3, 1), (4, 3), (4, 1), (5, 4), (5, 3), (5, 2), (5, 1))\n    >>> coprime_pairs(10)\n    ((1, 1), (2, 1), (3, 2), (4, 3), (5, 4), (6, 5), (7, 6), (8, 7), (8, 3), (7, 2), (5, 2), (8, 5), (4, 1), (7, 4), (6, 1), (8, 1), (3, 1), (5, 3), (7, 5), (7, 3), (5, 1), (7, 1), (9, 8), (9, 7), (9, 5), (9, 4), (9, 2), (9, 1), (10, 9), (10, 7), (10, 3), (10, 1))\n    \"\"\"\n    pass\n\ndef farey_sequence_generator(n: int, /) -> Generator[ContinuedFraction, None, None]:\n    \"\"\"Generates an (ordered) sequence (tuple) of rational numbers forming the Farey sequence of order :math:`n`.\n\n    The elements of the sequence are yielded as\n    :py:class:`~continuedfractions.continuedfraction.ContinuedFraction`\n    instances, in ascending order of magnitude.\n\n    See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/sequences.html#sequences-farey-sequences>`_\n    for more details.\n\n    Parameters\n    ----------\n    n : int:\n        The order of the Farey sequence.\n\n    Raises\n    ------\n    ValueError\n        If :math:`n` is not a positive integer.\n\n    Yields\n    ------\n    ContinuedFraction\n        A sequence of\n        :py:class:`~continuedfractions.continuedfraction.ContinuedFraction`\n        instances representing the elements of the Farey sequence of order\n        :math:`n`, in ascending order of magnitude.\n\n    Examples\n    --------\n    >>> tuple(farey_sequence_generator(1))\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 1))\n    >>> tuple(farey_sequence_generator(2))\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 2), ContinuedFraction(1, 1))\n    >>> tuple(farey_sequence_generator(3))\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 3), ContinuedFraction(1, 2), ContinuedFraction(2, 3), ContinuedFraction(1, 1))\n    >>> tuple(farey_sequence_generator(4))\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 4), ContinuedFraction(1, 3), ContinuedFraction(1, 2), ContinuedFraction(2, 3), ContinuedFraction(3, 4), ContinuedFraction(1, 1))\n    >>> tuple(farey_sequence_generator(5))\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 5), ContinuedFraction(1, 4), ContinuedFraction(1, 3), ContinuedFraction(2, 5), ContinuedFraction(1, 2), ContinuedFraction(3, 5), ContinuedFraction(2, 3), ContinuedFraction(3, 4), ContinuedFraction(4, 5), ContinuedFraction(1, 1))\n    \"\"\"\n    pass\n\ndef farey_sequence(n: int, /) -> tuple[ContinuedFraction]:\n    \"\"\"Returns an (ordered) sequence (tuple) of rational numbers forming the Farey sequence of order :math:`n`.\n\n    Wrapper of :py:func:`~continuedfractions.sequences.farey_sequence_generator`.\n\n    The elements of the sequence are returned as\n    :py:class:`~continuedfractions.continuedfraction.ContinuedFraction`\n    instances, in ascending order of magnitude.\n\n    See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/sequences.html#sequences-farey-sequences>`_\n    for more details.\n\n    Parameters\n    ----------\n    n : int:\n        The order of the Farey sequence.\n\n    Returns\n    -------\n    tuple\n        A :py:class:`tuple` of ``ContinuedFraction`` instances representing the\n        elements of the Farey sequence of order :math:`n`, generated in\n        ascending order of magnitude.\n\n    Examples\n    --------\n    >>> farey_sequence(1)\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 1))\n    >>> farey_sequence(2)\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 2), ContinuedFraction(1, 1))\n    >>> farey_sequence(3)\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 3), ContinuedFraction(1, 2), ContinuedFraction(2, 3), ContinuedFraction(1, 1))\n    >>> farey_sequence(4)\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 4), ContinuedFraction(1, 3), ContinuedFraction(1, 2), ContinuedFraction(2, 3), ContinuedFraction(3, 4), ContinuedFraction(1, 1))\n    >>> farey_sequence(5)\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 5), ContinuedFraction(1, 4), ContinuedFraction(1, 3), ContinuedFraction(2, 5), ContinuedFraction(1, 2), ContinuedFraction(3, 5), ContinuedFraction(2, 3), ContinuedFraction(3, 4), ContinuedFraction(4, 5), ContinuedFraction(1, 1))\n    \"\"\"\n    pass\n"
            }
        ],
        "minimal_code_skeleton": "--- File: continuedfractions/utils.py ---\n```python\nclass NamedCallableProxy:\n    \"\"\"Class wrapper to have named callable proxies, which can also work as :py:class:`enum.Enum` values.\n\n    Adapted from Stack Overflow solution by Ceppo93:\n\n        https://stackoverflow.com/a/40486992\n    \"\"\"\n    def __new__(cls, callable_: Callable, /, *, name: str = None) -> NamedCallableProxy:\n        \"\"\"Constructor\n\n        Parameters\n        ----------\n        callable_ : `callable`\n            The callable to name and proxy.\n\n        name : `str`, default=None\n            The user-defined name of the callable to use in :py:func:`~continuedfractions.utils.__repr__`.\n            If :py:data:`None` the Python-defined default will be used.\n\n        Returns\n        -------\n        callable\n            A named callable proxy.\n\n        Examples\n        --------\n        >>> square = NamedCallableProxy(lambda x: x ** 2, name=\"square: x |--> x^2\")\n        >>> square\n        NamedCallableProxy(\"square: x |--> x^2\")\n        >>> list(map(square, [1, 2, 3, 4, 5]))\n        [1, 4, 9, 16, 25]\n        \"\"\"\n        pass\n\n    def __repr__(self) -> str:\n        pass\n\n    def __eq__(self, other: NamedCallableProxy) -> bool:\n        pass\n\n    def __call__(self, *args: Any, **kwargs: Any) -> Any:\n        pass\n```\n--- File: continuedfractions/lib.py ---\n```python\ndef continued_fraction_rational(frac: Fraction, /) -> Generator[int, None, None]:\n    \"\"\"Core continued fraction algorithm implementation which generates the ordered sequence of elements of the (finite) simple continued fraction of the given rational number.\n\n    The resulting sequence of elements, :math:`a_0,a_1,\\\\ldots a_n`, defines a simple continued fraction of the form:\n\n    .. math::\n\n       a_0 + \\\\cfrac{1}{a_1 + \\\\cfrac{1}{a_2 + \\\\ddots\\\\cfrac{1}{a_{n - 1} + \\\\cfrac{1}{a_n}}}}\n\n    which is also written more compactly as:\n\n    .. math::\n\n       [a_0; a_1, a_2\\\\ldots, a_n]\n\n    The order of the continued fraction is said to be :math:`n`. If the last\n    element :math:`a_n = 1` the sequence can be rewritten as\n    :math:`[a_0; a_1, a_2\\\\ldots, a_{n - 1} + 1]`, which is then unique as a\n    simple continued fraction representation of the rational number.\n\n    Negative rational numbers can also be represented in this way, provided we\n    use the `Euclidean division lemma <https://en.wikipedia.org/wiki/Euclid%27s_lemma>`_.\n    This is described in more detail in the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/creating-continued-fractions.html#negative-continued-fractions>`_.\n\n    For a definition of \"continued fraction\", \"element\", \"order\",\n    \"finite continued fraction\", \"simple continued fraction\", please consult\n    the `package documentation <https://continuedfractions.readthedocs.io/en/stable>`_,\n    or any online resource such as `Wikipedia <https://en.wikipedia.org/wiki/Continued_fraction>`_,\n    or suitable books on number theory.\n\n    Parameters\n    ----------\n    frac : `fractions.Fraction`\n        The rational number to represented as a simple continued fraction.\n\n    Yields\n    ------\n    int\n        Elements of a unique simple continued fraction of the given rational\n        number.\n\n    Examples\n    --------\n    A few examples are given below of how this function can be used.\n\n    >>> for e in continued_fraction_rational(Fraction(649, 200)):\n    ...     print(e)\n    ... \n    3\n    4\n    12\n    4\n    >>> list(continued_fraction_rational(Fraction(415, 93)))\n    [4, 2, 6, 7]\n    >>> list(continued_fraction_rational(Fraction(-649, 200)))\n    [-4, 1, 3, 12, 4]\n    >>> list(continued_fraction_rational(Fraction(123235, 334505)))\n    [0, 2, 1, 2, 1, 1, 250, 1, 13]\n\n    Notes\n    -----\n    Every rational number has exactly two simple continued fractions, one of\n    which has an additional element of :math:`1` as its last element,\n    i.e. :math:`[a_0;a_1,a_2,\\\\ldots,a_{n - 1}, 1]`. But this form can be\n    reduced by adding the :math:`1` to the second last element, :math:`a_{n - 1}`,\n    producing the shorter form :math:`[a_0;a_1,a_2,\\\\ldots, a_{n - 1} + 1]`,\n    where the last element is now :math:`> 1`.\n\n    The simple continued fraction representation generated by this function is\n    the shorter version, and is thus unique.\n    \"\"\"\n    pass\n\ndef continued_fraction_real(x: int | float | str | Decimal, /) -> Generator[int, None, None]:\n    \"\"\"Generates a finite sequence of elements (coefficients) of a (simple) continued fraction of the given real number.\n\n    The result is a finite sequence even though the given number :math:`x` may\n    be irrational or not exactly representable as a real number. \n\n    The simple continued fraction representation of :math:`x` is a number of\n    the form\n\n    .. math::\n\n       a_0 + \\\\cfrac{1}{a_1 + \\\\cfrac{1}{a_2 + \\\\ddots}}\n\n    where :math:`a_0 = [x]` is the integer part of :math:`x`, and the\n    :math:`a_1,a_2\\\\ldots` are the (non-negative) quotients obtained by a\n    repeated application of `Euclidean division <https://en.wikipedia.org/wiki/Euclidean_division>`_\n    to the fractional part :math:`x - [x]`, which is called the remainder.\n\n    If the last element :math:`a_n = 1` the sequence can be rewritten as\n    :math:`[a_0; a_1, a_2\\\\ldots, a_{n - 1} + 1]`.\n\n    As Python :py:class:`float` values, like all floating point\n    implementations, are `finite precision representations <https://docs.python.org/3/tutorial/floatingpoint.html>`_\n    of real numbers, the resulting simple continued fraction  of :math:`x`\n    generated by this function may be approximate, not exact, and also not\n    necessarily unique.\n\n    For non-rational real numbers it is best to pass :py:class:`decimal.Decimal`\n    values, with the `context precision <https://docs.python.org/3.12/library/decimal.html#context-objects>`_\n    set to the highest level possible.\n\n    The results for rational numbers are guaranteed to be exact however large\n    the number, subject to memory and hardware limitations of the running\n    environment.\n\n    Invalid values will generate an error in either the\n    :py:class:`fractions.Fraction` or :py:class:`decimal.Decimal` classes -\n    no errors are raised directly in the function itself.\n\n    Parameters\n    ----------\n    x : int, float, str, decimal.Decimal\n        The real number to represent as a simple continued fraction.\n\n    Yields\n    ------\n    int\n        Elements of a simple continued fraction of the given real number.\n\n    Examples\n    --------\n    A few examples are given below of how this function can be used.\n\n    >>> list(continued_fraction_real(5000))\n    [5000]\n    >>> list(continued_fraction_real(-5000.0))\n    [-5000]\n    >>> list(continued_fraction_real(2/5))\n    [0, 2, 2, 1801439850948198]\n    >>> list(continued_fraction_real('2/5'))\n    [0, 2, 2]\n    >>> list(continued_fraction_real('-1/3'))\n    [-1, 1, 2]\n    >>> list(continued_fraction_real(1/1j))\n    Traceback (most recent call last):\n    ...\n    TypeError: conversion from complex to Decimal is not supported\n    >>> list(continued_fraction_real(\"not a numeric string\"))\n    Traceback (most recent call last):\n    ...\n    decimal.InvalidOperation: [<class 'decimal.ConversionSyntax'>]\n    >>> list(continued_fraction_real(-649/200))\n    [-4, 1, 3, 12, 3, 1, 234562480591, 2, 5, 2]\n    >>> list(continued_fraction_real('-649/200'))\n    [-4, 1, 3, 12, 4]\n    >>> list(continued_fraction_real('-649/-200'))\n    Traceback (most recent call last):\n    ...\n    ValueError: Invalid literal for Fraction: '-649/-200'\n    >>> list(continued_fraction_real(Decimal('0.3333')))\n    [0, 3, 3333]\n    \"\"\"\n    pass\n\ndef convergent(k: int, *elements: int) -> Fraction:\n    \"\"\"Returns the :math:`k`-th convergent of a (simple) continued fraction from a sequence of its elements.\n\n    Given a (simple) continued fraction  :math:`[a_0;a_1,a_2,\\\\ldots]` the\n    :math:`k`-th convergent is defined as:\n\n    .. math::\n\n       C_k = a_0 + \\\\cfrac{1}{a_1 + \\\\cfrac{1}{a_2 \\\\ddots \\\\cfrac{1}{a_{k-1} + \\\\cfrac{1}{a_k}}}}\n\n    The result is a :py:class:`fractions.Fraction` instance.\n    \n    The integer :math:`k` is called the order of the convergent, and if \n    :math:`[a_0;a_1,a_2,\\\\ldots]` is finite of order :math:`n` then it has\n    exactly :math:`n + 1` convergents :math:`C_0,C_1,C_2,\\\\ldots,C_n` where\n    the :math:`k`-th convergent :math:`C_k = \\\\frac{p_k}{q_k}` is given by\n    the recurrence relation:\n\n    .. math::\n       \n       \\\\begin{align}\n       p_k &= a_kp_{k - 1} + p_{k - 2} \\\\\\\\\n       q_k &= a_kq_{k - 1} + q_{k - 2},        \\\\hskip{3em}    k \\\\geq 3\n       \\\\end{align}\n\n    where :math:`p_0 = a_0`, :math:`q_0 = 1`, :math:`p_1 = p_1p_0 + 1`,\n    and :math:`q_1 = p_1`.\n\n    This function is a faithful implementation of this algorithm.\n\n    A :py:class:`ValueError` is raised if :math:`k` is not an integer or is an\n    integer greater than the number of elements, or if any of the elements are\n    not integers.\n\n    Parameters\n    ----------\n    k : `int`\n        The order of the convergent. Must be a non-negative integer less than\n        the number of elements.\n\n    *elements : `int`\n        A variable-length sequence of integer elements of a continued fraction.\n\n    Returns\n    -------\n    fractions.Fraction\n        A rational fraction constructed from the given sequence of elements of\n        a continued fraction, representing the :math:`k`-order convergent of a\n        (finite) simple continued fraction as given by a sequence of elements.\n\n    Raises\n    ------\n    ValueError\n        If :math:`k` is not a non-negative integer less than the number of\n        elements, or if any of the elements are not integers.\n\n    Examples\n    --------\n    >>> convergent(0, 3, 4, 12, 4)\n    Fraction(3, 1)\n    >>> convergent(1, 3, 4, 12, 4)\n    Fraction(13, 4)\n    >>> convergent(2, 3, 4, 12, 4)\n    Fraction(159, 49)\n    >>> convergent(3, 3, 4, 12, 4)\n    Fraction(649, 200)\n    >>> convergent(3)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> convergent(-1, 3, 4, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> convergent(4, 3, 4, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    \"\"\"\n    pass\n\ndef convergents(*elements: int) -> Generator[Fraction, None, None]:\n    \"\"\"Generates an (ordered) sequence of all convergents of a (simple) continued fraction from a sequence of its elements.\n\n    If :math:`n` is the order of the continued fraction represented by the\n    given sequence of its elements then there are :math:`n + 1` convergents\n    :math:`C_0, C_1, \\\\ldots, C_n`, and the function generates these in that\n    order.\n\n    See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/exploring-continued-fractions.html#convergents-and-rational-approximations>`_\n    for more details on convergents.\n\n    Parameters\n    ----------\n    *elements : `int`\n        A variable-length sequence of integer elements of a (simple)\n        continued fraction.\n\n    Yields\n    ------\n    fractions.Fraction\n        Each element generated is a :py:class:`fractions.Fraction` instance and\n        a :math:`k`-th convergent of the given continued fraction.\n\n    Raises\n    ------\n    ValueError\n        If there are any non-integer elements, or the tail elements are not\n        positive integers.\n\n    Examples\n    --------\n    >>> tuple(convergents(3))\n    (Fraction(3, 1),)\n    >>> tuple(convergents(3, 2))\n    (Fraction(3, 1), Fraction(7, 2))\n    >>> tuple(convergents(3, 4, 12, 4))\n    (Fraction(3, 1), Fraction(13, 4), Fraction(159, 49), Fraction(649, 200))\n    >>> tuple(convergents(-5, 1, 1, 6, 7))\n    (Fraction(-5, 1), Fraction(-4, 1), Fraction(-9, 2), Fraction(-58, 13), Fraction(-415, 93))\n    >>> tuple(convergents(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))\n    (Fraction(1, 1), Fraction(3, 2), Fraction(10, 7), Fraction(43, 30), Fraction(225, 157), Fraction(1393, 972), Fraction(9976, 6961), Fraction(81201, 56660), Fraction(740785, 516901), Fraction(7489051, 5225670))\n\n    \"\"\"\n    pass\n\ndef fraction_from_elements(*elements: int) -> Fraction:\n    \"\"\"Returns the rational number represented by a (simple) continued fraction from a sequence of its elements.\n\n    The elements must be given as positional arguments, which means that if\n    they are contained in an iterable then they must be unpacked using the\n    unpacking operator ``*``, as described in the examples below.\n\n    Parameters\n    ----------\n    *elements : `int`\n        A variable-length sequence of integer elements of a simple continued\n        fraction.\n\n    Returns\n    -------\n    fractions.Fraction\n        A rational number constructed from a sequence of elements of a simple\n        continued fraction which represents the number.\n\n    Raises\n    ------\n    ValueError\n        If any of the elements are not integers.\n\n    Examples\n    --------\n    >>> fraction_from_elements(3, 4, 12, 4)\n    Fraction(649, 200)\n    >>> fraction_from_elements(-4, 1, 3, 12, 4)\n    Fraction(-649, 200)\n    >>> fraction_from_elements(4, 2, 6, 7)\n    Fraction(415, 93)\n    >>> fraction_from_elements(*[4, 2, 6, 7])\n    Fraction(415, 93)\n    >>> fraction_from_elements(4.5, 2, 6, 7)\n    Traceback (most recent call last):\n    ...\n    ValueError: Continued fraction elements must be integers\n    \"\"\"\n    pass\n\ndef remainder(k: int, *elements: int) -> Fraction:\n    \"\"\"Returns the :math:`k`-th remainder of a (simple) continued fraction from a sequence of its elements.\n\n    Given a (simple) continued fraction  :math:`[a_0;a_1,a_2,\\\\ldots]` the\n    :math:`k`-th remainder :math:`R_k` is the (simple) continued fraction\n    :math:`[a_k; a_{k + 1}, a_{k + 2}, \\\\ldots]`:\n\n    .. math::\n\n       R_k = a_k + \\\\cfrac{1}{a_{k + 1} + \\\\cfrac{1}{a_{k + 2} \\\\ddots }}\n\n    where :math:`R_0` is just the original continued fraction, i.e.\n    :math:`R_0 = [a_0; a_1, a_2, \\\\ldots]`.\n\n    The remainders satisfy the recurrence relation:\n\n    .. math::\n\n       R_{k - 1} = a_{k - 1} + \\\\frac{1}{R_k}, \\\\hskip{3em} k \\\\geq 1\n\n    If the continued fraction :math:`[a_0; a_1, a_2,\\\\ldots]` is finite of\n    order :math:`n` then all :math:`R_k` are rational. If we let\n    :math:`R_k = \\\\frac{s_k}{t_k}` then the recurrence relation above can\n    be written as:\n\n    .. math::\n\n       R_{k - 1} = \\\\frac{s_{k - 1}}{t_{k - 1}} = \\\\frac{a_{k - 1}s_k + t_k}{s_k}, \\\\hskip{3em} k \\\\geq 1\n\n    As this library only deals with finite continued fractions, this function\n    always produces remainders as instances of :py:class:`~fractions.Fraction`.\n\n    The integer :math:`k` must be non-negative and cannot exceed the order\n    of the continued fraction, i.e. the number of its tail elements.\n\n    A :py:class:`ValueError` is raised if :math:`k` is not an integer, or is an\n    integer greater than the number of elements, or if any of the elements are\n    not integers, or if any of the tail elements are not positive integers.\n\n    Parameters\n    ----------\n    k : `int`\n        The index of the remainder. Must be a non-negative integer not\n        exceeding the order of the continued fraction.\n\n    *elements : `int`\n        A variable-length sequence of integer elements of a (simple) continued\n        fraction.\n\n    Returns\n    -------\n    fractions.Fraction\n        A rational fraction constructed from the given sequence of elements of\n        a continued fraction, representing its :math:`k`-th remainder, as\n        defined above.\n\n    Raises\n    ------\n    ValueError\n        If :math:`k` is not an integer, or is an integer greater than the\n        number of elements, or if any of the elements are not integers, or if\n        any of the tail elements are not positive integers.\n\n    Examples\n    --------\n    >>> remainder(0, 3, 4, 12, 4)\n    Fraction(649, 200)\n    >>> remainder(1, 3, 4, 12, 4)\n    Fraction(200, 49)\n    >>> remainder(2, 3, 4, 12, 4)\n    Fraction(49, 4)\n    >>> remainder(3, 3, 4, 12, 4)\n    Fraction(4, 1)\n    >>> remainder(0, -5, 1, 1, 6, 7)\n    Fraction(-415, 93)\n    >>> remainder(1, -5, 1, 1, 6, 7)\n    Fraction(93, 50)\n    >>> remainder(2, -5, 1, 1, 6, 7)\n    Fraction(50, 43)\n    >>> remainder(3, -5, 1, 1, 6, 7)\n    Fraction(43, 7)\n    >>> remainder(4, -5, 1, 1, 6, 7)\n    Fraction(7, 1)\n    >>> remainder(1)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> remainder(-1, 3, 4, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> remainder(4, 3, 4, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> remainder(1, 3, 0, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> remainder(1, 3, -1, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    \"\"\"\n    pass\n\ndef remainders(*elements: int) -> Generator[Fraction, None, None]:\n    \"\"\"Generates an (ordered) sequence of all remainders of a (simple) continued fraction from a sequence of its elements in descending order of index.\n\n    If :math:`n` is the order of the continued fraction represented by the\n    given sequence of its elements then there are :math:`n + 1` remainders\n    :math:`R_0, R_1, \\\\ldots, R_n`, and the function generates these in\n    reverse order :math:`R_0, R_1, \\\\ldots, R_n`.\n\n    See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/exploring-continued-fractions.html#remainders>`_\n    for more details on remainders.\n\n    Parameters\n    ----------\n    *elements : `int`\n        A variable-length sequence of integer elements of a (simple)\n        continued fraction.\n\n    Yields\n    ------\n    fractions.Fraction\n        Each element generated is a :py:class:`fractions.Fraction` instance and\n        a :math:`k`-th remainder of the given continued fraction.\n\n    Raises\n    ------\n    ValueError\n        If no elements are given, or there are any non-integer elements, or\n        the tail elements are not positive integers.\n\n    Examples\n    --------\n    >>> tuple(remainders(3))\n    (Fraction(3, 1),)\n    >>> tuple(remainders(3, 2))\n    (Fraction(2, 1), Fraction(7, 2))\n    >>> tuple(remainders(3, 4, 12, 4))\n    (Fraction(4, 1), Fraction(49, 4), Fraction(200, 49), Fraction(649, 200))\n    >>> tuple(remainders(-5, 1, 1, 6, 7))\n    (Fraction(7, 1), Fraction(43, 7), Fraction(50, 43), Fraction(93, 50), Fraction(-415, 93))\n    >>> tuple(remainders(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))\n    (Fraction(10, 1), Fraction(91, 10), Fraction(738, 91), Fraction(5257, 738), Fraction(32280, 5257), Fraction(166657, 32280), Fraction(698908, 166657), Fraction(2263381, 698908), Fraction(5225670, 2263381), Fraction(7489051, 5225670))\n    >>> tuple(remainders())\n    Traceback (most recent call last):\n    ...\n    ValueError: Continued fraction elements must be integers, and all \n    tail elements (from the 1st element onwards) must be positive.\n    >>> tuple(remainders(0, 0))\n    Traceback (most recent call last):\n    ...\n    ValueError: Continued fraction elements must be integers, and all \n    tail elements (from the 1st element onwards) must be positive.\n    >>> tuple(remainders(1, 0))\n    Traceback (most recent call last):\n    ...\n    ValueError: Continued fraction elements must be integers, and all \n    tail elements (from the 1st element onwards) must be positive.\n    >>> tuple(remainders(1, 2, -1))\n    Traceback (most recent call last):\n    ...\n    ValueError: Continued fraction elements must be integers, and all \n    tail elements (from the 1st element onwards) must be positive.\n    \"\"\"\n    pass\n\ndef mediant(r: Fraction, s: Fraction, /, *, dir: str = 'right', k: int = 1) -> Fraction:\n    \"\"\"Returns the :math:`k`-th left- or right-mediant of two rational numbers.\n\n    For a positive integer :math:`k`, the :math:`k`-th left-mediant of two\n    rational numbers :math:`r = \\\\frac{a}{b}` and :math:`s = \\\\frac{c}{d}`,\n    where :math:`b, d, b + d \\\\neq 0`, is defined as:\n    \n    .. math::\n\n       \\\\frac{ka + c}{kb + d}, \\\\hskip{3em}    k \\\\geq 1\n\n    while the :math:`k`-th right mediant is defined as:\n    \n    .. math::\n\n       \\\\frac{a + kc}{b + kd}, \\\\hskip{3em}    k \\\\geq 1\n\n    If we assume that :math:`r < s` and :math:`bd > 0` then these mediants\n    have the property that:\n   \n    .. math::\n\n       \\\\frac{a}{b} < \\\\frac{ka + c}{kb + d} \\\\leq \\\\frac{a + kc}{b + kd} < \\\\frac{c}{d},   \\\\hskip{3em} k \\\\geq 1\n\n    where equality holds for :math:`k = 1`. If we let :math:`k \\\\to \\\\infty`\n    then the mediants converge to opposite limits:\n\n    .. math::\n\n      \\\\begin{align}\n      \\\\lim_{k \\\\to \\\\infty} \\\\frac{ka + c}{kb + d} &= \\\\frac{a}{b} \\\\\\\\\n      \\\\lim_{k \\\\to \\\\infty} \\\\frac{a + kc}{b + kd} &= \\\\frac{c}{d}\n      \\\\end{align}\n\n    For more information consult the\n    `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/mediants.html>`_.\n\n    For the left mediant use ``dir=\"left\"``, while for the right use\n    ``dir=\"right\"``. The default is ``dir=\"right\"``. For ``k = 1`` the left and\n    right mediants are identical to the simple mediant :math:`\\\\frac{a + c}{b + d}`.\n\n    Parameters\n    ----------\n    r : `fractions.Fraction`\n        The first rational number.\n\n    s : `fractions.Fraction`\n        The second rational number.\n\n    dir : `str`, default='right'\n        The \"direction\" of the mediant - `'left'` or `'right'`, as defined\n        above.\n\n    k : `int`, default=1\n        The order of the mediant, as defined above.\n\n    Returns\n    -------\n    fractions.Fraction\n        The `k`-th left- or right-mediant of the two given rational numbers.\n\n    Examples\n    --------\n    >>> mediant(Fraction(1, 2), Fraction(3, 5))\n    Fraction(4, 7)\n    >>> mediant(Fraction(1, 2), Fraction(3, 5), dir='left')\n    Fraction(4, 7)\n    >>> mediant(Fraction(1, 2), Fraction(3, 5), k=2)\n    Fraction(7, 12)\n    >>> mediant(Fraction(1, 2), Fraction(3, 5), dir='left', k=2)\n    Fraction(5, 9)\n    >>> mediant(Fraction(1, 2), Fraction(3, 5), k=3, dir='right')\n    Fraction(10, 17)\n    >>> mediant(Fraction(1, 2), Fraction(3, 5), k=3, dir='left')\n    Fraction(6, 11)\n    \"\"\"\n    pass\n```\n--- File: continuedfractions/continuedfraction.py ---\n```python\nclass ContinuedFraction(Fraction):\n    \"\"\"An object-oriented representation of a (finite) simple continued fraction.\n\n    An implementation of simple continued fractions as Python objects and\n    instances of the standard library :py:class:`fractions.Fraction` class, with\n    various properties for the continued fraction, including its elements\n    (or coefficients), the order, convergents, and remainders.\n\n    The term \"simple continued fraction\" denotes a specific type of continued\n    fraction where the fractional terms only have numerators of :math:`1`.\n\n    Examples\n    --------\n    Construct the continued fraction for the rational `649/200`.\n\n    >>> cf = ContinuedFraction(649, 200)\n    >>> cf\n    ContinuedFraction(649, 200)\n    >>> cf.as_float()\n    3.245\n\n    Inspect the elements, order, convergents, and remainders.\n\n    >>> cf.elements\n    (3, 4, 12, 4)\n    >>> cf.order\n    3\n    >>> cf.convergent(0), cf.convergent(1), cf.convergent(2), cf.convergent(3)\n    (ContinuedFraction(3, 1), ContinuedFraction(13, 4), ContinuedFraction(159, 49), ContinuedFraction(649, 200))\n    >>> cf.remainder(0), cf.remainder(1), cf.remainder(2), cf.remainder(3)\n    (ContinuedFraction(649, 200), ContinuedFraction(200, 49), ContinuedFraction(49, 4), ContinuedFraction(4, 1))\n\n    Inspect the element counts.\n\n    >>> cf.counter\n    Counter({4: 2, 3: 1, 12: 1})\n\n    Check some properties of the convergents and remainders.\n\n    >>> assert cf.remainder(1) == 1 / (cf - cf.convergent(0))\n\n    Construct continued fractions from element sequences.\n\n    >>> cf_inverse = ContinuedFraction.from_elements(0, 3, 4, 12, 4)\n    >>> cf_inverse\n    ContinuedFraction(200, 649)\n    >>> assert cf_inverse == 1/cf\n    >>> assert cf * cf_inverse == 1\n    >>> cf_negative_inverse = ContinuedFraction.from_elements(-1, 1, 2, 4, 12, 4)\n    >>> cf_negative_inverse\n    ContinuedFraction(-200, 649)\n    >>> assert cf_negative_inverse == -1/cf\n    >>> assert cf * cf_negative_inverse == -1\n    \"\"\"\n    def __new__(cls, *args: Any, **kwargs: Any) -> ContinuedFraction:\n        \"\"\"Creates, initialises and returns instances of this class.\n\n        Arguments can be any which are valid for creating objects of the\n        :py:class:`fractions.Fraction` superclass.\n\n        For clarification, valid arguments can be one of the following:\n\n        * a single instance of :py:class:`numbers.Rational`, including\n          :py:class:`int`, :py:class:`fractions.Fraction` or\n          :py:class:`ContinuedFraction`, named or unnamed\n        * a pair of  :py:class:`numbers.Rational` instances, including\n          :py:class:`int`, :py:class:`fractions.Fraction` and\n          :py:class:`ContinuedFraction`, named or unnamed\n        * a single :py:class:`float` or :py:class:`decimal.Decimal` value\n          that is not a special value such as :py:data:`math.nan`,\n          ``float('inf')``, or ``Decimal('infinity')``\n        * a single numeric valid string (:py:class:`str`) - validity is\n          determined in the superclass by the\n          :py:data:`fractions._RATIONAL_FORMAT` test\n\n        Returns\n        -------\n        ContinuedFraction\n            A :py:class:`ContinuedFraction` instance.\n\n        Examples\n        --------\n        Several example are given below of constructing the simple continued\n        fraction for the number :math:`\\\\frac{-649}{200}` in different ways.\n\n        >>> ContinuedFraction(-649, 200)\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction('-3.245')\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(Decimal('-3.245'))\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction('-649/200')\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(Fraction(-649, 200))\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(ContinuedFraction(649, -200))\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(Fraction(-649), 200)\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(649, Fraction(-200))\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(Fraction(-649), ContinuedFraction(200))\n        ContinuedFraction(-649, 200)\n\n        In each of the examples above, the minus sign can be removed from\n        the arguments to the :py:class:`numbers.Rational` instance and\n        instead attached to the outer class, e.g.:\n\n        >>> -ContinuedFraction(649, 200)\n        ContinuedFraction(-649, 200)\n        >>> -ContinuedFraction('3.245')\n        ContinuedFraction(-649, 200)\n        >>> -ContinuedFraction('649/200')\n        ContinuedFraction(-649, 200)\n\n        Invalid arguments will raise errors in the\n        :py:class:`fractions.Fraction` superclass.\n        \"\"\"\n        pass\n\n    @classmethod\n    def from_elements(cls, *elements: int) -> ContinuedFraction:\n        \"\"\"Returns a :py:class:`ContinuedFraction` instance from a sequence of (integer) elements of a (finite) simple continued fraction.\n\n        Invalid elements will trigger a :py:class:`ValueError`.\n\n        Parameters\n        ----------\n        *elements : int\n            An ordered sequence of integer elements of a (finite) simple\n            continued fraction.\n\n        Returns\n        -------\n        ContinuedFraction\n            A new and fully initialised instance of :py:class:`ContinuedFraction` with\n            the given element sequence.\n\n        Raises\n        ------\n        ValueError\n            If any elements are not integers, or any elements after the 1st\n            are not positive.\n\n        Examples\n        --------\n        Constructing a continued fraction for the rational :math:`\\\\frac{649}{200}` using\n        the element sequence :math:`3, 4, 12, 4`.\n\n        >>> c1 = ContinuedFraction.from_elements(3, 4, 12, 4)\n        >>> c1\n        ContinuedFraction(649, 200)\n\n        Constructing the continued fraction of the (multiplicative) inverse :math:`\\\\frac{200}{649}`\n        using the element sequence :math:`0, 3, 4, 12, 4`.\n\n        >>> c2 = ContinuedFraction.from_elements(0, 3, 4, 12, 4)\n        >>> c2\n        ContinuedFraction(200, 649)\n\n        Validation for elements containing non-integers or negative integers.\n\n        >>> ContinuedFraction.from_elements('0', 1)\n        Traceback (most recent call last):\n        ...\n        ValueError: Continued fraction elements must be integers, and all elements after the 1st must be positive\n        >>> ContinuedFraction.from_elements(0, 1, 2.5)\n        Traceback (most recent call last):\n        ...\n        ValueError: Continued fraction elements must be integers, and all elements after the 1st must be positive\n        >>> ContinuedFraction.from_elements(1, 0)\n        Traceback (most recent call last):\n        ...\n        ValueError: Continued fraction elements must be integers, and all elements after the 1st must be positive\n        >>> ContinuedFraction.from_elements(1, -1)\n        Traceback (most recent call last):\n        ...\n        ValueError: Continued fraction elements must be integers, and all elements after the 1st must be positive\n\n        \"\"\"\n        pass\n\n    def extend(self, *new_elements: int) -> None:\n        \"\"\"Performs an in-place extension of the tail of the current sequence of elements.\n\n        Raises a :py:class:`ValueError` if there are no new elements, or are\n        not positive integers.\n\n        .. note::\n\n           As this method performs an in-place modification of the existing/\n           current instance the object ID remains the same.\n\n        Parameters\n        ----------\n        elements\n            An (ordered) sequence of new (integer) elements by which the tail\n            of the existing sequence of elements is extended.\n\n        Raises\n        ------\n        ValueError\n            If no new elements provided, or the new elements provided are not\n            positive integers.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('3.245')\n        >>> cf\n        ContinuedFraction(649, 200)\n        >>> cf.elements\n        (3, 4, 12, 4)\n        >>> cf.order\n        3\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)), (2, ContinuedFraction(159, 49)), (3, ContinuedFraction(649, 200)))\n        >>> tuple(cf.remainders)\n        ((3, ContinuedFraction(4, 1)), (2, ContinuedFraction(49, 4)), (1, ContinuedFraction(200, 49)), (0, ContinuedFraction(649, 200)))\n        >>> cf.extend(5, 2)\n        >>> cf\n        ContinuedFraction(7457, 2298)\n        >>> cf.elements\n        (3, 4, 12, 4, 5, 2)\n        >>> cf.order\n        5\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)), (2, ContinuedFraction(159, 49)), (3, ContinuedFraction(649, 200)), (4, ContinuedFraction(3404, 1049)), (5, ContinuedFraction(7457, 2298)))\n        >>> tuple(cf.remainders)\n        ((5, ContinuedFraction(2, 1)), (4, ContinuedFraction(11, 2)), (3, ContinuedFraction(46, 11)), (2, ContinuedFraction(563, 46)), (1, ContinuedFraction(2298, 563)), (0, ContinuedFraction(7457, 2298)))\n        >>> cf = ContinuedFraction(649, 200)\n        >>> cf.extend(0, 1)\n        Traceback (most recent call last):\n        ...\n        ValueError: The elements/coefficients to be added to the tail must be positive integers.\n        >>> cf.extend(1, -1)\n        Traceback (most recent call last):\n        ...\n        ValueError: The elements/coefficients to be added to the tail must be positive integers.\n        \"\"\"\n        pass\n\n    def truncate(self, *tail_elements: int) -> None:\n        \"\"\"Performs an in-place truncation of the tail of the existing sequence of elements.\n\n        Raises a :py:class:`ValueError` if the tail elements provided are not\n        positive integers, or do not form a segment of the existing tail. This\n        includes the case where the length of the tail elements provided exceed\n        the length of the existing tail, i.e. the order of the continued\n        fraction represented by the instance.\n\n        .. note::\n\n           The tail elements provided must be positive integers which form a\n           subsequence of the tail of the original sequence ending with the\n           last element, e.g. with respect to the complete sequence of elements\n           ``(3, 4, 12, 4)`` a value of ``12, 4`` for ``*tail_elements`` would\n           be valid, but ``4, 12`` would be invalid as it does not represent\n           a segment of the tail, and ``3, 4, 12, 4`` would also be invalid\n           as it includes the head ``3``.\n\n        .. note::\n\n           As this method performs an in-place modification of the existing/\n           current instance the object ID remains the same.\n\n        Parameters\n        ----------\n        tail_elements\n            An (ordered) sequence of (integer) elements to truncate from the\n            tail of the existing sequence of elements.\n\n        Raises\n        ------\n        ValueError\n            If no tail elements are provided, or the tail elements provided do\n            not represent a valid segment of the existing tail.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('3.245')\n        >>> cf\n        ContinuedFraction(649, 200)\n        >>> cf.elements\n        (3, 4, 12, 4)\n        >>> cf.order\n        3\n        >>> cf.counter\n        Counter({4: 2, 3: 1, 12: 1})\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)), (2, ContinuedFraction(159, 49)), (3, ContinuedFraction(649, 200)))\n        >>> tuple(cf.remainders)\n        ((3, ContinuedFraction(4, 1)), (2, ContinuedFraction(49, 4)), (1, ContinuedFraction(200, 49)), (0, ContinuedFraction(649, 200)))\n        >>> cf.truncate(12, 4)\n        >>> cf\n        ContinuedFraction(13, 4)\n        >>> cf.elements\n        (3, 4)\n        >>> cf.order\n        1\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)))\n        >>> tuple(cf.remainders)\n        ((1, ContinuedFraction(4, 1)), (0, ContinuedFraction(13, 4)))\n        >>> cf = ContinuedFraction(649, 200)\n        >>> cf.truncate(4, 12)\n        Traceback (most recent call last):\n        ...\n        ValueError: The elements/coefficients to be truncated from the tail must form a valid segment of the existing tail.\n        >>> cf.truncate(3, 4, 12, 4)\n        Traceback (most recent call last):\n        ...\n        ValueError: The elements/coefficients to be truncated from the tail must form a valid segment of the existing tail.\n        \"\"\"\n        pass\n\n    def __eq__(self, other, /) -> bool:\n        \"\"\"Custom equality check.\n\n        Compares the sequence of elements/coefficients of ``self`` with\n        that of ``other`` if ``other`` is also a\n        :py:class:`~continuedfractions.continuedfraction.ContinuedFraction`\n        instance, otherwise calls the superclass :py:class:`~fractions.Fraction`\n        equality check.\n\n        Returns\n        -------\n        bool\n            The boolean result of the equality check.\n        \"\"\"\n        pass\n\n    def __hash__(self) -> int:\n        \"\"\"Custom hash.\n\n        Custom hash which hashes the sequence of elements/coefficients - as\n        this is always defined as a finite, non-empty tuple the hash is\n        always defined.\n\n        Returns\n        -------\n        int\n            The hash of the\n            :py:class:`~continuedfractions.continuedfraction.ContinuedFraction`\n            instance.\n        \"\"\"\n        pass\n\n    def __add__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __radd__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __sub__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __rsub__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __mul__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __rmul__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __truediv__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __rtruediv__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __floordiv__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __rfloordiv__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __divmod__(self, other, /) -> tuple[ContinuedFraction, ContinuedFraction]:\n        pass\n\n    def __rdivmod__(self, other, /) -> tuple[ContinuedFraction, ContinuedFraction]:\n        pass\n\n    def __pow__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __rpow__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __pos__(self) -> ContinuedFraction:\n        pass\n\n    def __neg__(self) -> ContinuedFraction:\n        \"\"\"\n        Division-free negation for a finite simple continued fraction, as\n        described `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/creating-continued-fractions.html#negative-continued-fractions>`_.\n\n        The basic algorithm can be described as follows: if\n        :math:`[a_0; a_1,\\\\ldots, a_n]` is the simple continued fraction of a\n        **positive** rational number :math:`\\\\frac{a}{b}` of finite order\n        :math:`n` then  :math:`-\\\\frac{a}{b}` has the simple continued\n        fraction:\n\n        .. math::\n\n           \\\\begin{cases}\n           [-a_0;]                                      \\\\hskip{3em} & n = 0 \\\\\\\\\n           [-(a_0 + 1); 2]                              \\\\hskip{3em} & n = 1 \\\\text{ and } a_1 = 2 \\\\\\\\\n           [-(a_0 + 1); a_2 + 1, a_3,\\\\ldots, a_n]      \\\\hskip{3em} & n \\\\geq 2 \\\\text{ and } a_1 = 1 \\\\\\\\\n           [-(a_0 + 1); 1, a_1 - 1, a_2, \\\\ldots,a_n]   \\\\hskip{3em} & n \\\\geq 2 \\\\text{ and } a_1 \\\\geq 2\n           \\\\end{cases}\n\n        In applying this algorithm there is an assumption that the last element\n        :math:`a_n > 1`, as any simple continued fraction of type\n        :math:`[a_0; a_1,\\\\ldots, a_{n} = 1]` can be reduced to the simple\n        continued fraction :math:`[a_0; a_1,\\\\ldots, a_{n - 1} + 1]`.\n        \"\"\"\n        pass\n\n    def __abs__(self) -> ContinuedFraction:\n        pass\n\n    def as_float(self) -> float:\n        \"\"\"Returns the :py:class:`float` value of the continued fraction.\n\n        Returns\n        -------\n        float\n            The :py:class:`float` value of the continued fraction.\n\n        Examples\n        --------\n        Note that the default :py:mod:`decimal` context precision of :math:`28`\n        is used in these examples.\n\n        >>> import math\n        >>> math.pi\n        3.141592653589793\n\n        Now construct a :py:class:`ContinuedFraction` instance from it, and check the \n        :py:class:`float` value.\n\n        >>> cf = ContinuedFraction(math.pi)\n        >>> cf\n        ContinuedFraction(884279719003555, 281474976710656)\n        >>> cf.as_float()\n        3.141592653589793\n        \"\"\"\n        pass\n\n    def as_decimal(self) -> Decimal:\n        \"\"\"Returns the :py:class:`decimal.Decimal` value of the continued fraction.\n\n        Returns\n        -------\n        decimal.Decimal\n            The :py:class:`decimal.Decimal` representation of the continued fraction.\n\n        Examples\n        --------\n        Note that the default :py:mod:`decimal` context precision of :math:`28`\n        is used in these examples.\n\n        >>> import math\n        >>> math.pi\n        3.141592653589793\n\n        Now construct a :py:class:`ContinuedFraction` instance from it, and check the \n        :py:class:`float` value.\n\n        >>> cf = ContinuedFraction(math.pi)\n        >>> cf\n        ContinuedFraction(884279719003555, 281474976710656)\n        >>> cf.as_decimal()\n        Decimal('3.141592653589793115997963469')\n        \"\"\"\n        pass\n\n    @property\n    def elements(self) -> tuple[int]:\n        \"\"\":py:class:`tuple`: The (ordered) sequence of elements of the continued fraction.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('.12345')\n        >>> cf\n        ContinuedFraction(2469, 20000)\n        >>> cf.elements\n        (0, 8, 9, 1, 21, 1, 1, 5)\n        \"\"\"\n        pass\n\n    @property\n    def order(self) -> int:\n        \"\"\":py:class:`int`: The order of the continued fraction, which is the number of its elements minus :math:`1`.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('.12345')\n        >>> cf\n        ContinuedFraction(2469, 20000)\n        >>> len(cf.elements)\n        8\n        >>> cf.order\n        7\n        \"\"\"\n        pass\n\n    @property\n    def counter(self) -> collections.Counter:\n        \"\"\":py:class:`collections.Counter` : A counter for the elements.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction(928374923, 8249234)\n        >>> cf.counter\n        Counter({1: 6, 2: 3, 24: 2, 112: 1, 5: 1, 3: 1})\n        \"\"\"\n        pass\n\n    @property\n    def khinchin_mean(self) -> Decimal | None:\n        \"\"\":py:class:`decimal.Decimal` or :py:data:`None`: The Khinchin mean of the continued fraction, which is defined as the geometric mean of all its elements after the 1st.\n\n        We define the Khinchin mean :math:`K_n` of a (simple) continued\n        fraction :math:`[a_0; a_1, a_2, \\\\ldots, a_n]` as:\n\n        .. math::\n\n           K_n := \\\\sqrt[n]{a_1a_2 \\\\cdots a_n} = \\\\left( a_1a_2 \\\\cdots a_n \\\\right)^{\\\\frac{1}{n}}, \\\\hskip{3em} n \\\\geq 1\n\n        This property is intended to make it easier to study the limit of\n        :math:`K_n` as :math:`n \\\\to \\\\infty`.  See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/exploring-continued-fractions.html#khinchin-means-khinchin-s-constant>`_\n        for more details.\n\n        In the special case of integers or fractions representing integers,\n        whose continued fraction representations consist of only a single\n        element, a null value is returned.\n\n        Examples\n        --------\n        Note that the default :py:mod:`decimal` context precision of :math:`28`\n        is used in these examples.\n\n        >>> ContinuedFraction(649, 200).elements\n        (3, 4, 12, 4)\n        >>> ContinuedFraction(649, 200).khinchin_mean\n        Decimal('5.76899828122963409526846589869819581508636474609375')\n        >>> ContinuedFraction(415, 93).elements\n        (4, 2, 6, 7)\n        >>> ContinuedFraction(415, 93).khinchin_mean\n        Decimal('4.37951913988788898990378584130667150020599365234375')\n        >>> (ContinuedFraction(649, 200) + ContinuedFraction(415, 93)).elements\n        (7, 1, 2, 2, 2, 1, 1, 11, 1, 2, 12)\n        >>> (ContinuedFraction(649, 200) + ContinuedFraction(415, 93)).khinchin_mean\n        Decimal('2.15015313349074244086978069390170276165008544921875')\n        >>> ContinuedFraction(5000).khinchin_mean\n\n        \"\"\"\n        pass\n\n    def convergent(self, k: int, /) -> ContinuedFraction:\n        \"\"\"Returns the :math:`k`-th (simple) convergent of the continued fraction.\n\n        Given a (simple) continued fraction  :math:`[a_0;a_1,a_2,\\\\ldots]` the\n        :math:`k`-th convergent is defined as:\n\n        .. math::\n\n           C_k = a_0 + \\\\cfrac{1}{a_1 + \\\\cfrac{1}{a_2 \\\\ddots \\\\cfrac{1}{a_{k-1} + \\\\cfrac{1}{a_k}}}}\n\n        The result is a :py:class:`~continuedfractions.continuedfraction.ContinuedFraction` instance.\n        \n        If  the continued fraction is of order :math:`n` then it has exactly\n        :math:`n + 1` convergents :math:`C_0,C_1,C_2,\\\\ldots,C_n` where\n        the :math:`k`-th convergent :math:`C_k = \\\\frac{p_k}{q_k}` is given by\n        the recurrence relation:\n\n        .. math::\n           \n           \\\\begin{align}\n           p_k &= a_kp_{k - 1} + p_{k - 2} \\\\\\\\\n           q_k &= a_kq_{k - 1} + q_{k - 2},        \\\\hskip{3em}    k \\\\geq 3\n           \\\\end{align}\n\n        where :math:`p_0 = a_0`, :math:`q_0 = 1`, :math:`p_1 = p_1p_0 + 1`,\n        and :math:`q_1 = p_1`.\n\n        Parameters\n        ----------\n        k : int\n            The index of the convergent, as described above.\n\n        Returns\n        -------\n        ContinuedFraction\n            A new :py:class:`ContinuedFraction` instance representing the :math:`k`-th\n            (simple) convergent of the original continued fraction, as\n            described above.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('.12345')\n        >>> cf\n        ContinuedFraction(2469, 20000)\n        >>> cf.convergent(0)\n        ContinuedFraction(0, 1)\n        >>> cf.convergent(2)\n        ContinuedFraction(9, 73)\n        >>> cf.convergent(6)\n        ContinuedFraction(448, 3629)\n        >>> cf.convergent(7)\n        ContinuedFraction(2469, 20000)\n        \"\"\"\n        pass\n\n    @property\n    def convergents(self) -> Generator[tuple[int, ContinuedFraction], None, None]:\n        \"\"\"Generates an enumerated sequence of all convergents of the continued fraction.\n\n        The convergents are generated as tuples of :py:class:`int` and\n        :py:class:`~continuedfraction.continuedfraction.ContinuedFraction`\n        instances, where the integers represent the indices of the convergents.\n\n        If :math:`n` is the order of the continued fraction then :math:`n + 1`\n        convergents :math:`C_0, C_1, \\\\ldots, C_n` are generated in that order.\n\n        Yields\n        ------\n        tuple\n            A tuple of convergent index (:py:class:`int`) and convergents\n            (:py:class:`~continuedfractions.continuedfraction.ContinuedFraction`)\n            of the continued fraction.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('3.245')\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)), (2, ContinuedFraction(159, 49)), (3, ContinuedFraction(649, 200)))\n        \"\"\"\n        pass\n\n    @property\n    def even_convergents(self) -> Generator[tuple[int, ContinuedFraction], None, None]:\n        \"\"\"Generates an enumerated sequence of all even-order convergents of the continued fraction.\n\n        The convergents are generated as tuples of :py:class:`int` and\n        :py:class:`~continuedfraction.continuedfraction.ContinuedFraction`\n        instances, where the integers represent the indices of the convergents.\n\n        If :math:`n` is the order of the continued fraction then only the even-\n        indexed convergents :math:`C_0, C_2, C_4, \\\\ldots` are generated.\n\n        Yields\n        ------\n        tuple\n            A tuple of convergent index (:py:class:`int`) and convergents\n            (:py:class:`~continuedfractions.continuedfraction.ContinuedFraction`)\n            of the continued fraction.\n\n        Examples\n        --------\n        >>> tuple(ContinuedFraction('3.245').even_convergents)\n        ((0, ContinuedFraction(3, 1)), (2, ContinuedFraction(159, 49)))\n        \"\"\"\n        pass\n\n    @property\n    def odd_convergents(self) -> Generator[tuple[int, ContinuedFraction], None, None]:\n        \"\"\"Generates an enumerated sequence of all odd-order convergents of the continued fraction.\n\n        The convergents are generated as tuples of :py:class:`int` and\n        :py:class:`~continuedfraction.continuedfraction.ContinuedFraction`\n        instances, where the integers represent the indices of the convergents.\n\n        If :math:`n` is the order of the continued fraction then only the odd-\n        indexed convergents :math:`C_1, C_3, C_5, \\\\ldots` are generated.\n\n        Yields\n        ------\n        tuple\n            A tuple of convergent index (:py:class:`int`) and convergents\n            (:py:class:`~continuedfractions.continuedfraction.ContinuedFraction`)\n            of the continued fraction.\n\n        Examples\n        --------\n        >>> tuple(ContinuedFraction('3.245').odd_convergents)\n        ((1, ContinuedFraction(13, 4)), (3, ContinuedFraction(649, 200)))\n        \"\"\"\n        pass\n\n    def semiconvergent(self, k: int, m: int, /) -> ContinuedFraction:\n        \"\"\"Returns the :math:`m`-th semiconvergent of two consecutive convergents :math:`p_{k - 1}` and :math:`p_k` of the continued fraction.\n\n        The integer :math:`k` must be positive and determine two consecutive\n        convergents :math:`p_{k - 1}` and :math:`p_k` of a (finite, simple)\n        continued fraction.\n\n        The integer :math:`m` can be any positive integer.\n\n        Parameters\n        ----------\n        k : int\n            The integer :math:`k` determining two consecutive convergents\n            :math:`p_{k - 1}` and :math:`p_k` of a (finite, simple) continued\n            fraction\n            :math:`[a_0; a_1, \\\\ldots, a_{k}, a_{k + 1}, \\\\ldots, a_n]`.\n\n        m : int\n            The index of the semiconvergent of the convergents\n            :math:`p_{k - 1}` and :math:`p_k`.\n\n        Returns\n        -------\n        ContinuedFraction\n            The :math:`m`-th semiconvergent of the convergents\n            :math:`p_{k - 1}` and :math:`p_k`.\n\n        Raises\n        ------\n        ValueError\n            If :math:`k` or :math:`m` are not positive integers, or :math:`k`\n            is an integer that does **not** satisfy :math:`1 \\\\leq k \\\\leq n`\n            where :math:`n` is the order of the (finite, simple) continued\n            fraction of which :math:`p_{k - 1}` and :math:`p_k` are\n            convergents.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction(-415, 93)\n        >>> cf.elements\n        (-5, 1, 1, 6, 7)\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(-5, 1)), (1, ContinuedFraction(-4, 1)), (2, ContinuedFraction(-9, 2)), (3, ContinuedFraction(-58, 13)), (4, ContinuedFraction(-415, 93)))\n        >>> cf.semiconvergent(3, 1)\n        ContinuedFraction(-67, 15)\n        >>> cf.semiconvergent(3, 2)\n        ContinuedFraction(-125, 28)\n        >>> cf.semiconvergent(3, 3)\n        ContinuedFraction(-183, 41)\n        >>> cf.semiconvergent(3, 4)\n        ContinuedFraction(-241, 54)\n        >>> cf.semiconvergent(3, 5)\n        ContinuedFraction(-299, 67)\n        >>> cf.semiconvergent(3, 6)\n        ContinuedFraction(-357, 80)\n        >>> cf.semiconvergent(3, 7)\n        ContinuedFraction(-415, 93)\n        \"\"\"\n        pass\n\n    def remainder(self, k: int, /) -> ContinuedFraction:\n        \"\"\"Returns the :math:`k`-th remainder of the continued fraction.\n\n        Given a (simple) continued fraction  :math:`[a_0;a_1,a_2,\\\\ldots]` the\n        :math:`k`-th remainder :math:`R_k` is the (simple) continued fraction\n        :math:`[a_k; a_{k + 1}, a_{k + 2}, \\\\ldots]`:\n\n        .. math::\n\n           R_k = a_k + \\\\cfrac{1}{a_{k + 1} + \\\\cfrac{1}{a_{k + 2} \\\\ddots }}\n\n        where :math:`R_0` is just the original continued fraction, i.e.\n        :math:`R_0 = [a_0; a_1, a_2, \\\\ldots]`.\n\n        The result is a :py:class:`~continuedfractions.continuedfraction.ContinuedFraction` instance.\n\n        The remainders satisfy the recurrence relation:\n\n        .. math::\n\n           R_{k - 1} = a_{k - 1} + \\\\frac{1}{R_k}, \\\\hskip{3em} k \\\\geq 1\n\n        If the original continued fraction is finite then its remainders are all\n        finite and rational.\n\n        As this class implements finite simple continued fractions, this method\n        always produces rational numbers.\n\n        The integer :math:`k` must be non-negative and cannot exceed the order\n        of the continued fraction, i.e. the number of its tail elements, and \n        the tail elements must define a valid finite simple continued fraction.\n\n        Parameters\n        ----------\n        k : int\n            The index of the remainder, as described above.\n\n        Returns\n        -------\n        ContinuedFraction\n            A new :py:class:`ContinuedFraction` instance representing the :math:`k`-th\n            remainder of the original continued fraction, as described above.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('.12345')\n        >>> cf\n        ContinuedFraction(2469, 20000)\n        >>> cf.remainder(0)\n        ContinuedFraction(2469, 20000)\n        >>> cf.remainder(2)\n        ContinuedFraction(2469, 248)\n        >>> cf.remainder(6)\n        ContinuedFraction(6, 5)\n        >>> cf.remainder(7)\n        ContinuedFraction(5, 1)\n        \"\"\"\n        pass\n\n    @property\n    def remainders(self) -> Generator[tuple[int, ContinuedFraction], None, None]:\n        \"\"\"Generates an enumerated sequence of all remainders of the continued fraction in descending order of index.\n\n        If :math:`n` is the order of the continued fraction then there are\n        :math:`n + 1` remainders :math:`R_0, R_1, \\\\ldots, R_n`, and the method\n        generates these in reverse order :math:`R_0, R_1, \\\\ldots, R_n`.\n\n        See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/exploring-continued-fractions.html#remainders>`_\n        for more details on remainders.\n\n        The remainders are generated as tuples of :py:class:`int`\n        and :py:class:`~continuedfractions.continuedfraction.ContinuedFraction`\n        instances, where the integers represent the indexes of the remainders.\n\n        Yields\n        ------\n        tuple\n            A tuple of remainder indices (:py:class:`int`) and remainders\n            (:py:class:`~continuedfractions.continuedfraction.ContinuedFraction`)\n            of the continued fraction.\n\n        Examples\n        --------\n        >>> tuple(ContinuedFraction('3.245').remainders)\n        ((3, ContinuedFraction(4, 1)), (2, ContinuedFraction(49, 4)), (1, ContinuedFraction(200, 49)), (0, ContinuedFraction(649, 200)))\n        >>> tuple(ContinuedFraction(-415, 93).remainders)\n        ((4, ContinuedFraction(7, 1)), (3, ContinuedFraction(43, 7)), (2, ContinuedFraction(50, 43)), (1, ContinuedFraction(93, 50)), (0, ContinuedFraction(-415, 93)))\n        \"\"\"\n        pass\n\n    def left_mediant(self, other: Fraction, /, *, k: int = 1) -> ContinuedFraction:\n        \"\"\"Returns the :math:`k`-th left-mediant of the continued fraction with another rational number.\n        \n        For a positive integer :math:`k`, the :math:`k`-th left-mediant of two\n        rational numbers :math:`r = \\\\frac{a}{b}` and :math:`s = \\\\frac{c}{d}`,\n        where :math:`b, d, b + d \\\\neq 0`, is defined as:\n        \n        .. math::\n\n           \\\\frac{ka + c}{kb + d}, \\\\hskip{3em}    k \\\\geq 1\n\n        while the :math:`k`-th right mediant is defined as:\n        \n        .. math::\n\n           \\\\frac{a + kc}{b + kd}, \\\\hskip{3em}    k \\\\geq 1\n\n        If we assume that :math:`r < s` and :math:`bd > 0` then these mediants\n        have the property that:\n       \n        .. math::\n\n           \\\\frac{a}{b} < \\\\frac{ka + c}{kb + d} \\\\leq \\\\frac{a + kc}{b + kd} < \\\\frac{c}{d},   \\\\hskip{3em} k \\\\geq 1\n\n        where equality holds for :math:`k = 1`. If we let :math:`k \\\\to \\\\infty`\n        then the mediants converge to opposite limits:\n\n        .. math::\n\n          \\\\begin{align}\n          \\\\lim_{k \\\\to \\\\infty} \\\\frac{ka + c}{kb + d} &= \\\\frac{a}{b} \\\\\\\\\n          \\\\lim_{k \\\\to \\\\infty} \\\\frac{a + kc}{b + kd} &= \\\\frac{c}{d}\n          \\\\end{align}\n\n        For more information consult the\n        `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/mediants.html>`_.\n\n        The method is cached (with :py:func:`functools.cache`), which makes calls\n        after the initial call much faster.\n\n        Parameters\n        ----------\n        other : fractions.Fraction, ContinuedFraction\n            The second fraction to use to calculate the :math:`k`-th mediant with\n            the first.\n        \n        k : int, default=1\n            The order of the mediant, as defined above.        \n\n        Returns\n        -------\n        ContinuedFraction\n            The :math:`k`-th left-mediant of the original fraction and the second\n            fraction, as a :py:class:`ContinuedFraction` instance.\n\n        Examples\n        --------\n        >>> c1 = ContinuedFraction('1/2')\n        >>> c2 = ContinuedFraction(3, 5)\n        >>> c1, c2\n        (ContinuedFraction(1, 2), ContinuedFraction(3, 5))\n        >>> c1.left_mediant(c2)\n        ContinuedFraction(4, 7)\n        >>> c1.left_mediant(c2, k=2)\n        ContinuedFraction(5, 9)\n        >>> c1.left_mediant(c2, k=3)\n        ContinuedFraction(6, 11)\n        >>> c1.left_mediant(c2, k=100)\n        ContinuedFraction(103, 205)\n        >>> assert c1.left_mediant(c2, k=2) < c1.right_mediant(c2, k=2)\n        >>> assert c1.left_mediant(c2, k=3) < c1.right_mediant(c2, k=3)\n        >>> assert c1.left_mediant(c2, k=100) < c1.right_mediant(c2, k=100)\n        \"\"\"\n        pass\n\n    def right_mediant(self, other: Fraction, /, *, k: int = 1) -> ContinuedFraction:\n        \"\"\"Returns the :math:`k`-th right-mediant of the continued fraction with another rational number.\n        \n        For a positive integer :math:`k`, the :math:`k`-th right-mediant of two\n        rational numbers :math:`r = \\\\frac{a}{b}` and :math:`s = \\\\frac{c}{d}`,\n        where :math:`b, d, b + d \\\\neq 0`, is defined as:\n        \n        .. math::\n\n           \\\\frac{a + kc}{b + kd}, \\\\hskip{3em}    k \\\\geq 1\n\n        while the :math:`k`-th left-mediant is defined as:\n        \n        .. math::\n\n           \\\\frac{ka + c}{kb + d}, \\\\hskip{3em}    k \\\\geq 1\n\n        If we assume that :math:`r < s` and :math:`bd > 0` then these mediants\n        have the property that:\n       \n        .. math::\n\n           \\\\frac{a}{b} < \\\\frac{ka + c}{kb + d} \\\\leq \\\\frac{a + kc}{b + kd} < \\\\frac{c}{d},   \\\\hskip{3em} k \\\\geq 1\n\n        where equality holds for :math:`k = 1`. If we let :math:`k \\\\to \\\\infty`\n        then the mediants converge to opposite limits:\n\n        .. math::\n\n          \\\\begin{align}\n          \\\\lim_{k \\\\to \\\\infty} \\\\frac{ka + c}{kb + d} &= \\\\frac{a}{b} \\\\\\\\\n          \\\\lim_{k \\\\to \\\\infty} \\\\frac{a + kc}{b + kd} &= \\\\frac{c}{d}\n          \\\\end{align}\n\n        For more information consult the\n        `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/mediants.html>`_.\n\n        Parameters\n        ----------\n        other : fractions.Fraction, ContinuedFraction\n            The second fraction to use to calculate the :math:`k`-th mediant with\n            the first.\n        \n        k : int, default=1\n            The order of the mediant, as defined above.        \n\n        Returns\n        -------\n        ContinuedFraction\n            The :math:`k`-th right-mediant of the original fraction and the second\n            fraction, as a :py:class:`ContinuedFraction` instance.\n\n        Examples\n        --------\n        >>> c1 = ContinuedFraction('1/2')\n        >>> c2 = ContinuedFraction(3, 5)\n        >>> c1, c2\n        (ContinuedFraction(1, 2), ContinuedFraction(3, 5))\n        >>> c1.right_mediant(c2)\n        ContinuedFraction(4, 7)\n        >>> c1.right_mediant(c2, k=2)\n        ContinuedFraction(7, 12)\n        >>> c1.right_mediant(c2, k=3)\n        ContinuedFraction(10, 17)\n        >>> c1.right_mediant(c2, k=100)\n        ContinuedFraction(301, 502)\n        >>> assert c1.left_mediant(c2, k=2) < c1.right_mediant(c2, k=2)\n        >>> assert c1.left_mediant(c2, k=3) < c1.right_mediant(c2, k=3)\n        >>> assert c1.left_mediant(c2, k=100) < c1.right_mediant(c2, k=100)\n        \"\"\"\n        pass\n\n    def mediant(self, other: Fraction, /) -> ContinuedFraction:\n        \"\"\"Returns the simple mediant of the continued fraction with another continued fraction.\n        \n        The simple mediant of two rational numbers :math:`r = \\\\frac{a}{b}`\n        and :math:`s = \\\\frac{c}{d}`, where :math:`b, d, b + d \\\\neq 0`, is\n        defined as:\n        \n        .. math::\n\n           \\\\frac{a + c}{b + d}\n\n        The resulting value :math:`\\\\frac{a + c}{b + d}` is the same as the\n        1st order left- or right-mediant of :math:`r = \\\\frac{a}{b}`\n        and :math:`s = \\\\frac{c}{d}`. So this method would produce the same\n        result as the :py:meth:`~continuedfractions.continuedfraction.ContinuedFraction.left_mediant`\n        or :py:meth:`~continuedfractions.continuedfraction.ContinuedFraction.right_mediant`\n        methods where the order :math:`k` is set to :math:`1`.\n\n        For more information consult the\n        `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/mediants.html>`_.\n\n        Parameters\n        ----------\n        other : fractions.Fraction, ContinuedFraction\n            The other continued fraction.\n        \n        Returns\n        -------\n        ContinuedFraction\n            The simple mediant of the original fraction and the other continued\n            fraction.\n\n        Examples\n        --------\n        >>> ContinuedFraction(1, 2).mediant(ContinuedFraction(3, 5))\n        ContinuedFraction(4, 7)\n        >>> assert ContinuedFraction(1, 2).mediant(ContinuedFraction(3, 5)) == ContinuedFraction(1, 2).left_mediant(ContinuedFraction(3, 5), k=1)\n        >>> assert ContinuedFraction(1, 2).mediant(ContinuedFraction(3, 5)) == ContinuedFraction(1, 2).right_mediant(ContinuedFraction(3, 5), k=1)\n        \"\"\"\n        pass\n```\n--- File: continuedfractions/sequences.py ---\n```python\ndef coprime_integers(n: int, /, *, start: int = 1, stop: int = None) -> tuple[int]:\n    \"\"\"Returns a sequence of (positive) integers :math:`1 \\\\leq m < n` coprime to a given positive integer :math:`n`.\n\n    Wrapper of :py:class:`~continuedfractions.sequences.coprime_integers_generator`.\n\n    The tuple is sorted in descending order of magnitude.\n\n    The optional ``start`` and ``stop`` parameters can be used to bound the\n    the range of (positive) integers in which integers coprime to the given\n    :math:`n` are sought.\n\n    For :math:`n = 1, 2` the ``start`` value is effectively ignored, but\n    if :math:`n > 1` then the ``start`` value must be an integer in the range\n    :math:`1..n - 1`.\n\n    The ``stop`` value defaults to ``None``, which is then internally\n    initialised to :math:`n`; if :math:`n > 1` and ``stop`` is given then it\n    must be an integer in the range :math:`\\\\text{start} + 1..n`.\n\n    Parameters\n    ----------\n    n : int\n        The positive integer for which (positive) coprime integers\n        :math:`m < n` are sought.\n\n    start : int, default=1\n        The lower bound of the range of (positive) integers in which integers\n        coprime to the given :math:`n` are sought. For :math:`n = 1, 2` the\n        ``start`` value is effectively ignored, but if :math:`n > 1` then the\n        ``start`` value must be in the range :math:`1..n - 1`.\n\n    stop : int, default=None\n        The upper bound of the range of (positive) integers in which integers\n        coprime to the given :math:`n` are sought. The ``stop`` value defaults\n        to ``None``, which is then internally initialised to :math:`n`; if\n        :math:`n > 1` and ``stop`` is given then it must be an integer in the\n        range :math:`\\\\text{start} + 1..n`.\n\n    Returns\n    -------\n    tuple\n        A sequence of (positive) integers :math:`1 \\\\leq m < n` coprime to a\n        given positive integer :math:`n`.\n\n    Examples\n    --------\n    Examples using the default ``start`` and ``stop`` values:\n\n    >>> coprime_integers(1)\n    (1,)\n    >>> coprime_integers(2)\n    (1,)\n    >>> coprime_integers(3)\n    (2, 1)\n    >>> coprime_integers(4)\n    (3, 1)\n    >>> coprime_integers(5)\n    (4, 3, 2, 1)\n    >>> coprime_integers(6)\n    (5, 1)\n    >>> coprime_integers(7)\n    (6, 5, 4, 3, 2, 1)\n    >>> coprime_integers(8)\n    (7, 5, 3, 1)\n    >>> coprime_integers(9)\n    (8, 7, 5, 4, 2, 1)\n    >>> coprime_integers(10)\n    (9, 7, 3, 1)\n    >>> coprime_integers(11)\n    (10, 9, 8, 7, 6, 5, 4, 3, 2, 1)\n\n    Examples using custom ``start`` and ``stop`` values:\n\n    >>> coprime_integers(3, start=2)\n    (2,)\n    >>> coprime_integers(3, start=3)\n    Traceback (most recent call last):\n    ...    \n    ValueError: `n` must be a positive integer; if `n` > 1 then the `start` value must be a positive integer in the range 1..n - 1; and if given the `stop` value must be a positive integer in the range `start` + 1..n\n    >>> coprime_integers(23, start=5, stop=21)\n    (21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5)\n    >>> coprime_integers(5, start=2)\n    (4, 3, 2)\n    >>> coprime_integers(5, start=3)\n    (4, 3)\n    >>> coprime_integers(6, start=2)\n    (5,)\n    >>> coprime_integers(6, start=3)\n    (5,)\n    >>> coprime_integers(6, start=4)\n    (5,)\n    >>> coprime_integers(7, start=2)\n    (6, 5, 4, 3, 2)\n    >>> coprime_integers(7, start=3)\n    (6, 5, 4, 3)\n    >>> coprime_integers(7, start=4)\n    (6, 5, 4)\n    >>> coprime_integers(7, start=5)\n    (6, 5)\n    \"\"\"\n    pass\n\nclass KSRMTree:\n    \"\"\"An implicit/generative class implementation of the Kanga-Saunders-Randall-Mitchell (KSRM) ternary trees for representing and generating pairs of all (positive) coprime integers.\n\n    The term \"KSRM trees\" is the author's, and refers to the trees presented in the following papers:\n\n    * Kanga, A. R. (1990). The Family Tree of Pythagorean Triplets. The Mathematical Gazette, 26(15), 15-17.\n    * Mitchell, D. W. (2001). An Alternative Characterisation of All Primitive Pythagorean Triples. The Mathematical Gazette, 85(503), 273-275. https://doi.org/10.2307/3622017\n    * Saunders, R., & Randall, T. (1994). The family tree of the Pythagorean triplets revisited. The Mathematical Gazette, 78(482), 190-193. https://doi.org/10.2307/3618576\n\n    .. note::\n\n       The class is named ``KSRMTree`` purely for convenience, but it is\n       actually a representation of two (ternary) subtrees.\n\n    .. note::\n\n       The author could not access the Kanga paper online, but the core result\n       is described clearly in the papers of Saunders and Randall, and of\n       Mitchell.\n\n    See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/sequences.html#ksrm-trees>`_\n    for more details.\n    \"\"\"\n    def __new__(cls) -> KSRMTree:\n        \"\"\"Class constructor.\n\n        Creates and initialises a new instance with the minimum set of required\n        attributes - for the roots and branch generating functions, which we\n        call branches.\n        \"\"\"\n        pass\n\n    @property\n    def roots(self) -> Literal[tuple[tuple[int, int], tuple[int, int]]]:\n        \"\"\":py:class:`tuple`: The tuple of roots of the KSRM trees, which are :math:`(2, 1)` and :math:`(3, 1)`.\n\n        For more details see the following papers:\n\n        * Kanga, A. R. (1990). The Family Tree of Pythagorean Triplets. The Mathematical Gazette, 26(15), 15-17.\n        * Mitchell, D. W. (2001). An Alternative Characterisation of All Primitive Pythagorean Triples. The Mathematical Gazette, 85(503), 273-275. https://doi.org/10.2307/3622017\n        * Saunders, R., & Randall, T. (1994). The family tree of the Pythagorean triplets revisited. The Mathematical Gazette, 78(482), 190-193. https://doi.org/10.2307/3618576\n\n        or the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/sequences.html#ksrm-trees>`_.\n\n        Examples\n        --------\n        >>> KSRMTree().roots\n        ((2, 1), (3, 1))\n        \"\"\"\n        pass\n\n    @property\n    def branches(self) -> tuple[NamedCallableProxy]:\n        \"\"\":py:class:`tuple`: The tuple of three branch generating functions of the KSRM trees.\n\n        There are three branch generating functions, given by the mappings:\n\n        .. math::\n\n           \\\\begin{align}\n           (a, b) &\\\\longmapsto (2a - b, a) \\\\\\\\\n           (a, b) &\\\\longmapsto (2a + b, a) \\\\\\\\\n           (a, b) &\\\\longmapsto (a + 2b, b)\n           \\\\end{align}\n\n        For more details see the following papers:\n\n        * Kanga, A. R. (1990). The Family Tree of Pythagorean Triplets. The Mathematical Gazette, 26(15), 15-17.\n        * Mitchell, D. W. (2001). An Alternative Characterisation of All Primitive Pythagorean Triples. The Mathematical Gazette, 85(503), 273-275. https://doi.org/10.2307/3622017\n        * Saunders, R., & Randall, T. (1994). The family tree of the Pythagorean triplets revisited. The Mathematical Gazette, 78(482), 190-193. https://doi.org/10.2307/3618576\n\n        or the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/sequences.html#ksrm-trees>`_.\n\n        Examples\n        --------\n        Generating the first two generations of children for the parent\n        :math:`(2, 1)`.\n\n        >>> tree = KSRMTree()\n        >>> tree.branches\n        (NamedCallableProxy(\"KSRM tree branch #1: (x, y) |--> (2x - y, x)\"), NamedCallableProxy(\"KSRM tree branch #2: (x, y) |--> (2x + y, x)\"), NamedCallableProxy(\"KSRM tree branch #3: (x, y) |--> (x + 2y, y)\"))\n        >>> tree.branches[0](2, 1)\n        (3, 2)\n        >>> tree.branches[1](2, 1)\n        (5, 2)\n        >>> tree.branches[2](2, 1)\n        (4, 1)\n        >>> tree.branches[0](*tree.branches[0](2, 1))\n        (4, 3)\n        >>> tree.branches[1](*tree.branches[0](2, 1))\n        (8, 3)\n        >>> tree.branches[2](*tree.branches[0](2, 1))\n        (7, 2)\n        >>> tree.branches[0](*tree.branches[1](2, 1))\n        (8, 5)\n        >>> tree.branches[1](*tree.branches[1](2, 1))\n        (12, 5)\n        >>> tree.branches[2](*tree.branches[1](2, 1))\n        (9, 2)\n        >>> tree.branches[0](*tree.branches[2](2, 1))\n        (7, 4)\n        >>> tree.branches[1](*tree.branches[2](2, 1))\n        (9, 4)\n        >>> tree.branches[2](*tree.branches[2](2, 1))\n        (6, 1)\n        \"\"\"\n        pass\n\n    def _backtrack(\n        self,\n        n: int,\n        visited: list[tuple[tuple[int, int], NamedCallableProxy]],\n        /,\n        *,\n        node_bound: int = None\n    ) -> tuple[tuple[int, int], NamedCallableProxy, int, NamedCallableProxy]:\n        \"\"\"Backtracks on the KSRM coprime pairs trees from a failed node to the nearest previously visited node that satisfies the node bound.\n\n        A private function that backtracks on the KSRM coprime pairs trees: the\n        procedure is that, given a (positive) integer :math:`n > 2`, for which\n        coprime pairs are being sought, and a sequence (list) of pairs of\n        visited nodes and their associated generating branches in the KSRM\n        tree, and assuming that the last element of the visited sequence\n        contains the node that \"failed\", the function identifies the nearest\n        previously visited node whose first component satisifes the test\n        :math:`< n` **and** and whose associated generating branch is not equal\n        to the third branch given by :math:`(x, y) \\\\longmapsto (x + 2y, y)`.\n\n        .. note::\n\n           The function assumes that the last node in the incoming sequence\n           of visited nodes and generating branch pairs represents a \"failed\"\n           node, i.e. whose first component failed the test :math:`\\\\leq n`\n           during the search. No attempt is made to validate or verify the\n           failed node, and the only purpose of the function is to backtrack\n           to the nearest previously visited node which meets the requirements\n           listed above.\n\n        .. note::\n\n           There is no input validation as this is a private function which\n           will be called from\n           :py:meth:`~continuedfractions.sequences.KSRMTree.search_root`. So\n           results for invalid arguments will most likely be incorrect or\n           unexpected.\n\n        Parameters\n        ----------\n        n : int\n            The (positive) integer :math:`> 2` which is passed by the root\n            search method or the general tree search method.\n\n        visited : list\n            A sequence of visited nodes and associated generating branches in\n            the KSRM coprime pairs tree.\n\n        node_bound : int, default=None\n            A bound to check that :math:`a < n` for a node :math:`(a, b)`. The\n            actual default value is the incoming :math:`n`, and this is set\n            internally.\n\n        Returns\n        -------\n        tuple\n            A tuple consisting of the following values in order: (1) the\n            target node in the visited sequence to backtrack to, (2) the\n            associated generating branch function (the lambda for branch #1,\n            or branch #2, or branch #3), (3) the index of the target node\n            and branch pair in the visited sequence, (4) the generating\n            branch of the successor node of the target node returned as (1).\n\n        Examples\n        --------\n        An example where :math:`n = 5` and the failed node is :math:`(6, 1)`,\n        which was the successor node to :math:`(4, 1)` from the third branch.\n\n        >>> tree = KSRMTree()\n        >>> tree.branches\n        (NamedCallableProxy(\"KSRM tree branch #1: (x, y) |--> (2x - y, x)\"), NamedCallableProxy(\"KSRM tree branch #2: (x, y) |--> (2x + y, x)\"), NamedCallableProxy(\"KSRM tree branch #3: (x, y) |--> (x + 2y, y)\"))\n        >>> visited = [((2, 1), None), ((4, 1), tree.branches[-1]), ((6, 1), tree.branches[-1])]\n        >>> tree._backtrack(5, visited)\n        ((2, 1), None, 0, NamedCallableProxy(\"KSRM tree branch #3: (x, y) |--> (x + 2y, y)\"))\n\n        An example where :math:`n = 8` and the failed node is :math:`(19, 8)`,\n        which was the successor node to :math:`(8, 3)` from the first branch.\n\n        >>> tree = KSRMTree()\n        >>> tree.branches\n        (NamedCallableProxy(\"KSRM tree branch #1: (x, y) |--> (2x - y, x)\"), NamedCallableProxy(\"KSRM tree branch #2: (x, y) |--> (2x + y, x)\"), NamedCallableProxy(\"KSRM tree branch #3: (x, y) |--> (x + 2y, y)\"))\n        >>> visited = [((2, 1), None), ((3, 2),tree.branches[0]), ((8, 3),tree.branches[1]), ((19, 8), tree.branches[0])]\n        >>> tree._backtrack(8, visited)\n        ((3, 2), NamedCallableProxy(\"KSRM tree branch #1: (x, y) |--> (2x - y, x)\"), 1, NamedCallableProxy(\"KSRM tree branch #2: (x, y) |--> (2x + y, x)\"))\n        \"\"\"\n        pass\n\n    def search_root(self, n: int, root: tuple[int, int], /) -> Generator[tuple[int, int], None, None]:\n        \"\"\"Depth-first branch-and-bound generative search function (in pre-order, NLMR), with backtracking and pruning, on the KSRM coprime pairs trees, starting from the given root node.\n\n        The given root node need not be the canonical roots, :math:`(2, 1)`,\n        :math:`(3, 1)`, but can be any of their successor nodes.\n\n        It is required that :math:`n \\\\geq 2`, otherwise a\n        :py:class:`ValueError` is raised.\n\n        The search implementation is an iterative version of a depth-first\n        branch-and-bound search (DFS) procedure, with backtracking and pruning,\n        in which nodes are traversed in NLMR pre-order (root -> left -> mid ->\n        right) and bounds and checks are applied to the nodes, including\n        pruning failed or unnecessary nodes, before further traversal or\n        backtracking:\n        \n        #. Visit the current node :math:`(a, b)` and check :math:`a \\\\leq n`.\n        #. If the check is successful iteratively traverse the current node's\n           first child and its children, then the second child and its \n           children, and then the third child and its children, applying the\n           check :math:`a \\\\leq n` to each visited node.\n        #. If a check fails for any node backtrack to the nearest previously\n           visited node which meets a stricter check :math:`a < n` and which\n           has unvisited child nodes, while pruning all visited intermediate\n           nodes after the backtracked target node and leading up to the failed\n           node, including the failed node. By design the backtracked target\n           node will have untraversed children on at least one branch, and the\n           traversal can begin again, as described above.\n\n        Parameters\n        ----------\n        n : int\n            The positive integer for which coprime pairs :math:`(a, b)`, with\n            :math:`1 \\\\leq b < a \\\\leq n`, are sought.\n\n        root : tuple\n            The \"root\" node from which to search - this can be either of the\n            canonical roots, :math:`(2, 1)`, :math:`(3, 1)`, but also any of\n            their successor nodes.\n\n        Raises\n        ------\n        ValueError\n            If ``n`` is not an integer or is :math:`< 2`.\n\n        Yields\n        ------\n        tuple\n            Pairs of coprime integers :math:`(a, b)`, with\n            :math:`1 \\\\leq b < a \\\\leq n`.\n\n        Examples\n        --------\n        Searching from the root :math:`(2, 1)` for coprime pairs for\n        :math:`n = 5`:\n\n        >>> tree = KSRMTree()\n        >>> list(tree.search_root(5, (2, 1)))\n        [(2, 1), (3, 2), (4, 3), (5, 4), (5, 2), (4, 1)]\n        >>> assert tree.roots[0] == (2, 1)\n        >>> list(tree.search_root(5, tree.roots[0]))\n        [(2, 1), (3, 2), (4, 3), (5, 4), (5, 2), (4, 1)]\n\n        The same type of search from the root :math:`(3, 1)`:\n\n        >>> list(tree.search_root(5, (3, 1)))\n        [(3, 1), (5, 3), (5, 1)]\n        >>> assert tree.roots[1] == (3, 1)\n        >>> list(tree.search_root(5, tree.roots[1]))\n        [(3, 1), (5, 3), (5, 1)]\n        \"\"\"\n        pass\n\n    def search(self, n: int, /) -> Generator[tuple[int, int], None, None]:\n        \"\"\"Depth-first branch-and-bound generative search function (in pre-order, NLMR) on the KSRM coprime pairs trees to find all pairs of coprime (positive) integers not exceeding the given integer :math:`n \\\\geq 1`.\n    \n        See the :py:meth:`~continuedfractions.sequences.KSRMTree.search_root`\n        method for details of the implementation for the root-based search.\n\n        This method mainly calls the root-based search method\n        :py:meth:`~continuedfractions.sequences.KSRMTree.search_root` for the\n        two canonical roots :math:`(2, 1)` and :math:`(3, 1)`.\n\n        Parameters\n        ----------\n        n : int\n            The positive integer for which coprime pairs :math:`(a, b)`, with\n            :math:`1 \\\\leq b < a \\\\leq n`, are sought.\n\n        Raises\n        ------\n        ValueError\n            If ``n`` is not an integer or is :math:`< 1`.\n\n        Yields\n        ------\n        tuple\n            Pairs of coprime integers :math:`(a, b)`, with\n            :math:`1 \\\\leq b < a \\\\leq n`.\n\n        Examples\n        --------\n        A few examples of invalid and valid searches:\n\n        >>> tree = KSRMTree()\n        >>> list(tree.search(\"not an integer\"))\n        Traceback (most recent call last):\n        ...\n        ValueError: `n` must be a positive integer >= 1\n        >>> list(tree.search(1))\n        [(1, 1)]\n        >>> list(tree.search(2))\n        [(1, 1), (2, 1)]\n        >>> list(tree.search(3))\n        [(1, 1), (2, 1), (3, 2), (3, 1)]\n        >>> list(tree.search(5))\n        [(1, 1), (2, 1), (3, 2), (4, 3), (4, 1), (3, 1), (5, 4), (5, 3), (5, 2), (5, 1)]\n        >>> list(tree.search(10))\n        [(1, 1), (2, 1), (3, 2), (4, 3), (5, 4), (6, 5), (7, 6), (8, 7), (9, 8), (8, 3), (7, 2), (5, 2), (8, 5), (9, 2), (4, 1), (7, 4), (9, 4), (6, 1), (8, 1), (3, 1), (5, 3), (7, 5), (9, 7), (7, 3), (5, 1), (9, 5), (7, 1), (9, 1), (10, 9), (10, 7), (10, 3), (10, 1)]\n        \"\"\"\n        pass\n\ndef coprime_pairs(n: int, /) -> tuple[tuple[int, int]]:\n    \"\"\"Returns a sequence (tuple) of all pairs of (positive) coprime integers :math:`<= n`.\n\n    Wrapper of :py:func:`~continuedfractions.sequences.coprime_pairs_generator`.\n\n    Parameters\n    ----------\n    n : int\n        The positive integer for which coprime pairs :math:`(a, b)`, with\n        :math:`1 \\\\leq b < a \\\\leq n`, are sought.\n\n    Returns\n    -------\n    tuple\n        A :py:class:`tuple` of pairs of coprime integers :math:`(a, b)`, with\n        :math:`1 \\\\leq b < a \\\\leq n`.\n\n    Examples\n    --------\n    A few examples of computing coprime pairs:\n\n    >>> coprime_pairs(1)\n    ((1, 1),)\n    >>> coprime_pairs(2)\n    ((1, 1), (2, 1))\n    >>> coprime_pairs(3)\n    ((1, 1), (2, 1), (3, 2), (3, 1))\n    >>> coprime_pairs(5)\n    ((1, 1), (2, 1), (3, 2), (3, 1), (4, 3), (4, 1), (5, 4), (5, 3), (5, 2), (5, 1))\n    >>> coprime_pairs(10)\n    ((1, 1), (2, 1), (3, 2), (4, 3), (5, 4), (6, 5), (7, 6), (8, 7), (8, 3), (7, 2), (5, 2), (8, 5), (4, 1), (7, 4), (6, 1), (8, 1), (3, 1), (5, 3), (7, 5), (7, 3), (5, 1), (7, 1), (9, 8), (9, 7), (9, 5), (9, 4), (9, 2), (9, 1), (10, 9), (10, 7), (10, 3), (10, 1))\n    \"\"\"\n    pass\n\ndef farey_sequence(n: int, /) -> tuple[ContinuedFraction]:\n    \"\"\"Returns an (ordered) sequence (tuple) of rational numbers forming the Farey sequence of order :math:`n`.\n\n    Wrapper of :py:func:`~continuedfractions.sequences.farey_sequence_generator`.\n\n    The elements of the sequence are returned as\n    :py:class:`~continuedfractions.continuedfraction.ContinuedFraction`\n    instances, in ascending order of magnitude.\n\n    See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/sequences.html#sequences-farey-sequences>`_\n    for more details.\n\n    Parameters\n    ----------\n    n : int:\n        The order of the Farey sequence.\n\n    Returns\n    -------\n    tuple\n        A :py:class:`tuple` of ``ContinuedFraction`` instances representing the\n        elements of the Farey sequence of order :math:`n`, generated in\n        ascending order of magnitude.\n\n    Examples\n    --------\n    >>> farey_sequence(1)\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 1))\n    >>> farey_sequence(2)\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 2), ContinuedFraction(1, 1))\n    >>> farey_sequence(3)\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 3), ContinuedFraction(1, 2), ContinuedFraction(2, 3), ContinuedFraction(1, 1))\n    >>> farey_sequence(4)\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 4), ContinuedFraction(1, 3), ContinuedFraction(1, 2), ContinuedFraction(2, 3), ContinuedFraction(3, 4), ContinuedFraction(1, 1))\n    >>> farey_sequence(5)\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 5), ContinuedFraction(1, 4), ContinuedFraction(1, 3), ContinuedFraction(2, 5), ContinuedFraction(1, 2), ContinuedFraction(3, 5), ContinuedFraction(2, 3), ContinuedFraction(3, 4), ContinuedFraction(4, 5), ContinuedFraction(1, 1))\n    \"\"\"\n    pass\n```",
        "minimal_code_skeleton_structured": [
            {
                "file_path": "continuedfractions/utils.py",
                "code": "class NamedCallableProxy:\n    \"\"\"Class wrapper to have named callable proxies, which can also work as :py:class:`enum.Enum` values.\n\n    Adapted from Stack Overflow solution by Ceppo93:\n\n        https://stackoverflow.com/a/40486992\n    \"\"\"\n    def __new__(cls, callable_: Callable, /, *, name: str = None) -> NamedCallableProxy:\n        \"\"\"Constructor\n\n        Parameters\n        ----------\n        callable_ : `callable`\n            The callable to name and proxy.\n\n        name : `str`, default=None\n            The user-defined name of the callable to use in :py:func:`~continuedfractions.utils.__repr__`.\n            If :py:data:`None` the Python-defined default will be used.\n\n        Returns\n        -------\n        callable\n            A named callable proxy.\n\n        Examples\n        --------\n        >>> square = NamedCallableProxy(lambda x: x ** 2, name=\"square: x |--> x^2\")\n        >>> square\n        NamedCallableProxy(\"square: x |--> x^2\")\n        >>> list(map(square, [1, 2, 3, 4, 5]))\n        [1, 4, 9, 16, 25]\n        \"\"\"\n        pass\n\n    def __repr__(self) -> str:\n        pass\n\n    def __eq__(self, other: NamedCallableProxy) -> bool:\n        pass\n\n    def __call__(self, *args: Any, **kwargs: Any) -> Any:\n        pass\n"
            },
            {
                "file_path": "continuedfractions/lib.py",
                "code": "def continued_fraction_rational(frac: Fraction, /) -> Generator[int, None, None]:\n    \"\"\"Core continued fraction algorithm implementation which generates the ordered sequence of elements of the (finite) simple continued fraction of the given rational number.\n\n    The resulting sequence of elements, :math:`a_0,a_1,\\\\ldots a_n`, defines a simple continued fraction of the form:\n\n    .. math::\n\n       a_0 + \\\\cfrac{1}{a_1 + \\\\cfrac{1}{a_2 + \\\\ddots\\\\cfrac{1}{a_{n - 1} + \\\\cfrac{1}{a_n}}}}\n\n    which is also written more compactly as:\n\n    .. math::\n\n       [a_0; a_1, a_2\\\\ldots, a_n]\n\n    The order of the continued fraction is said to be :math:`n`. If the last\n    element :math:`a_n = 1` the sequence can be rewritten as\n    :math:`[a_0; a_1, a_2\\\\ldots, a_{n - 1} + 1]`, which is then unique as a\n    simple continued fraction representation of the rational number.\n\n    Negative rational numbers can also be represented in this way, provided we\n    use the `Euclidean division lemma <https://en.wikipedia.org/wiki/Euclid%27s_lemma>`_.\n    This is described in more detail in the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/creating-continued-fractions.html#negative-continued-fractions>`_.\n\n    For a definition of \"continued fraction\", \"element\", \"order\",\n    \"finite continued fraction\", \"simple continued fraction\", please consult\n    the `package documentation <https://continuedfractions.readthedocs.io/en/stable>`_,\n    or any online resource such as `Wikipedia <https://en.wikipedia.org/wiki/Continued_fraction>`_,\n    or suitable books on number theory.\n\n    Parameters\n    ----------\n    frac : `fractions.Fraction`\n        The rational number to represented as a simple continued fraction.\n\n    Yields\n    ------\n    int\n        Elements of a unique simple continued fraction of the given rational\n        number.\n\n    Examples\n    --------\n    A few examples are given below of how this function can be used.\n\n    >>> for e in continued_fraction_rational(Fraction(649, 200)):\n    ...     print(e)\n    ... \n    3\n    4\n    12\n    4\n    >>> list(continued_fraction_rational(Fraction(415, 93)))\n    [4, 2, 6, 7]\n    >>> list(continued_fraction_rational(Fraction(-649, 200)))\n    [-4, 1, 3, 12, 4]\n    >>> list(continued_fraction_rational(Fraction(123235, 334505)))\n    [0, 2, 1, 2, 1, 1, 250, 1, 13]\n\n    Notes\n    -----\n    Every rational number has exactly two simple continued fractions, one of\n    which has an additional element of :math:`1` as its last element,\n    i.e. :math:`[a_0;a_1,a_2,\\\\ldots,a_{n - 1}, 1]`. But this form can be\n    reduced by adding the :math:`1` to the second last element, :math:`a_{n - 1}`,\n    producing the shorter form :math:`[a_0;a_1,a_2,\\\\ldots, a_{n - 1} + 1]`,\n    where the last element is now :math:`> 1`.\n\n    The simple continued fraction representation generated by this function is\n    the shorter version, and is thus unique.\n    \"\"\"\n    pass\n\ndef continued_fraction_real(x: int | float | str | Decimal, /) -> Generator[int, None, None]:\n    \"\"\"Generates a finite sequence of elements (coefficients) of a (simple) continued fraction of the given real number.\n\n    The result is a finite sequence even though the given number :math:`x` may\n    be irrational or not exactly representable as a real number. \n\n    The simple continued fraction representation of :math:`x` is a number of\n    the form\n\n    .. math::\n\n       a_0 + \\\\cfrac{1}{a_1 + \\\\cfrac{1}{a_2 + \\\\ddots}}\n\n    where :math:`a_0 = [x]` is the integer part of :math:`x`, and the\n    :math:`a_1,a_2\\\\ldots` are the (non-negative) quotients obtained by a\n    repeated application of `Euclidean division <https://en.wikipedia.org/wiki/Euclidean_division>`_\n    to the fractional part :math:`x - [x]`, which is called the remainder.\n\n    If the last element :math:`a_n = 1` the sequence can be rewritten as\n    :math:`[a_0; a_1, a_2\\\\ldots, a_{n - 1} + 1]`.\n\n    As Python :py:class:`float` values, like all floating point\n    implementations, are `finite precision representations <https://docs.python.org/3/tutorial/floatingpoint.html>`_\n    of real numbers, the resulting simple continued fraction  of :math:`x`\n    generated by this function may be approximate, not exact, and also not\n    necessarily unique.\n\n    For non-rational real numbers it is best to pass :py:class:`decimal.Decimal`\n    values, with the `context precision <https://docs.python.org/3.12/library/decimal.html#context-objects>`_\n    set to the highest level possible.\n\n    The results for rational numbers are guaranteed to be exact however large\n    the number, subject to memory and hardware limitations of the running\n    environment.\n\n    Invalid values will generate an error in either the\n    :py:class:`fractions.Fraction` or :py:class:`decimal.Decimal` classes -\n    no errors are raised directly in the function itself.\n\n    Parameters\n    ----------\n    x : int, float, str, decimal.Decimal\n        The real number to represent as a simple continued fraction.\n\n    Yields\n    ------\n    int\n        Elements of a simple continued fraction of the given real number.\n\n    Examples\n    --------\n    A few examples are given below of how this function can be used.\n\n    >>> list(continued_fraction_real(5000))\n    [5000]\n    >>> list(continued_fraction_real(-5000.0))\n    [-5000]\n    >>> list(continued_fraction_real(2/5))\n    [0, 2, 2, 1801439850948198]\n    >>> list(continued_fraction_real('2/5'))\n    [0, 2, 2]\n    >>> list(continued_fraction_real('-1/3'))\n    [-1, 1, 2]\n    >>> list(continued_fraction_real(1/1j))\n    Traceback (most recent call last):\n    ...\n    TypeError: conversion from complex to Decimal is not supported\n    >>> list(continued_fraction_real(\"not a numeric string\"))\n    Traceback (most recent call last):\n    ...\n    decimal.InvalidOperation: [<class 'decimal.ConversionSyntax'>]\n    >>> list(continued_fraction_real(-649/200))\n    [-4, 1, 3, 12, 3, 1, 234562480591, 2, 5, 2]\n    >>> list(continued_fraction_real('-649/200'))\n    [-4, 1, 3, 12, 4]\n    >>> list(continued_fraction_real('-649/-200'))\n    Traceback (most recent call last):\n    ...\n    ValueError: Invalid literal for Fraction: '-649/-200'\n    >>> list(continued_fraction_real(Decimal('0.3333')))\n    [0, 3, 3333]\n    \"\"\"\n    pass\n\ndef convergent(k: int, *elements: int) -> Fraction:\n    \"\"\"Returns the :math:`k`-th convergent of a (simple) continued fraction from a sequence of its elements.\n\n    Given a (simple) continued fraction  :math:`[a_0;a_1,a_2,\\\\ldots]` the\n    :math:`k`-th convergent is defined as:\n\n    .. math::\n\n       C_k = a_0 + \\\\cfrac{1}{a_1 + \\\\cfrac{1}{a_2 \\\\ddots \\\\cfrac{1}{a_{k-1} + \\\\cfrac{1}{a_k}}}}\n\n    The result is a :py:class:`fractions.Fraction` instance.\n    \n    The integer :math:`k` is called the order of the convergent, and if \n    :math:`[a_0;a_1,a_2,\\\\ldots]` is finite of order :math:`n` then it has\n    exactly :math:`n + 1` convergents :math:`C_0,C_1,C_2,\\\\ldots,C_n` where\n    the :math:`k`-th convergent :math:`C_k = \\\\frac{p_k}{q_k}` is given by\n    the recurrence relation:\n\n    .. math::\n       \n       \\\\begin{align}\n       p_k &= a_kp_{k - 1} + p_{k - 2} \\\\\\\\\n       q_k &= a_kq_{k - 1} + q_{k - 2},        \\\\hskip{3em}    k \\\\geq 3\n       \\\\end{align}\n\n    where :math:`p_0 = a_0`, :math:`q_0 = 1`, :math:`p_1 = p_1p_0 + 1`,\n    and :math:`q_1 = p_1`.\n\n    This function is a faithful implementation of this algorithm.\n\n    A :py:class:`ValueError` is raised if :math:`k` is not an integer or is an\n    integer greater than the number of elements, or if any of the elements are\n    not integers.\n\n    Parameters\n    ----------\n    k : `int`\n        The order of the convergent. Must be a non-negative integer less than\n        the number of elements.\n\n    *elements : `int`\n        A variable-length sequence of integer elements of a continued fraction.\n\n    Returns\n    -------\n    fractions.Fraction\n        A rational fraction constructed from the given sequence of elements of\n        a continued fraction, representing the :math:`k`-order convergent of a\n        (finite) simple continued fraction as given by a sequence of elements.\n\n    Raises\n    ------\n    ValueError\n        If :math:`k` is not a non-negative integer less than the number of\n        elements, or if any of the elements are not integers.\n\n    Examples\n    --------\n    >>> convergent(0, 3, 4, 12, 4)\n    Fraction(3, 1)\n    >>> convergent(1, 3, 4, 12, 4)\n    Fraction(13, 4)\n    >>> convergent(2, 3, 4, 12, 4)\n    Fraction(159, 49)\n    >>> convergent(3, 3, 4, 12, 4)\n    Fraction(649, 200)\n    >>> convergent(3)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> convergent(-1, 3, 4, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> convergent(4, 3, 4, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    \"\"\"\n    pass\n\ndef convergents(*elements: int) -> Generator[Fraction, None, None]:\n    \"\"\"Generates an (ordered) sequence of all convergents of a (simple) continued fraction from a sequence of its elements.\n\n    If :math:`n` is the order of the continued fraction represented by the\n    given sequence of its elements then there are :math:`n + 1` convergents\n    :math:`C_0, C_1, \\\\ldots, C_n`, and the function generates these in that\n    order.\n\n    See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/exploring-continued-fractions.html#convergents-and-rational-approximations>`_\n    for more details on convergents.\n\n    Parameters\n    ----------\n    *elements : `int`\n        A variable-length sequence of integer elements of a (simple)\n        continued fraction.\n\n    Yields\n    ------\n    fractions.Fraction\n        Each element generated is a :py:class:`fractions.Fraction` instance and\n        a :math:`k`-th convergent of the given continued fraction.\n\n    Raises\n    ------\n    ValueError\n        If there are any non-integer elements, or the tail elements are not\n        positive integers.\n\n    Examples\n    --------\n    >>> tuple(convergents(3))\n    (Fraction(3, 1),)\n    >>> tuple(convergents(3, 2))\n    (Fraction(3, 1), Fraction(7, 2))\n    >>> tuple(convergents(3, 4, 12, 4))\n    (Fraction(3, 1), Fraction(13, 4), Fraction(159, 49), Fraction(649, 200))\n    >>> tuple(convergents(-5, 1, 1, 6, 7))\n    (Fraction(-5, 1), Fraction(-4, 1), Fraction(-9, 2), Fraction(-58, 13), Fraction(-415, 93))\n    >>> tuple(convergents(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))\n    (Fraction(1, 1), Fraction(3, 2), Fraction(10, 7), Fraction(43, 30), Fraction(225, 157), Fraction(1393, 972), Fraction(9976, 6961), Fraction(81201, 56660), Fraction(740785, 516901), Fraction(7489051, 5225670))\n\n    \"\"\"\n    pass\n\ndef fraction_from_elements(*elements: int) -> Fraction:\n    \"\"\"Returns the rational number represented by a (simple) continued fraction from a sequence of its elements.\n\n    The elements must be given as positional arguments, which means that if\n    they are contained in an iterable then they must be unpacked using the\n    unpacking operator ``*``, as described in the examples below.\n\n    Parameters\n    ----------\n    *elements : `int`\n        A variable-length sequence of integer elements of a simple continued\n        fraction.\n\n    Returns\n    -------\n    fractions.Fraction\n        A rational number constructed from a sequence of elements of a simple\n        continued fraction which represents the number.\n\n    Raises\n    ------\n    ValueError\n        If any of the elements are not integers.\n\n    Examples\n    --------\n    >>> fraction_from_elements(3, 4, 12, 4)\n    Fraction(649, 200)\n    >>> fraction_from_elements(-4, 1, 3, 12, 4)\n    Fraction(-649, 200)\n    >>> fraction_from_elements(4, 2, 6, 7)\n    Fraction(415, 93)\n    >>> fraction_from_elements(*[4, 2, 6, 7])\n    Fraction(415, 93)\n    >>> fraction_from_elements(4.5, 2, 6, 7)\n    Traceback (most recent call last):\n    ...\n    ValueError: Continued fraction elements must be integers\n    \"\"\"\n    pass\n\ndef remainder(k: int, *elements: int) -> Fraction:\n    \"\"\"Returns the :math:`k`-th remainder of a (simple) continued fraction from a sequence of its elements.\n\n    Given a (simple) continued fraction  :math:`[a_0;a_1,a_2,\\\\ldots]` the\n    :math:`k`-th remainder :math:`R_k` is the (simple) continued fraction\n    :math:`[a_k; a_{k + 1}, a_{k + 2}, \\\\ldots]`:\n\n    .. math::\n\n       R_k = a_k + \\\\cfrac{1}{a_{k + 1} + \\\\cfrac{1}{a_{k + 2} \\\\ddots }}\n\n    where :math:`R_0` is just the original continued fraction, i.e.\n    :math:`R_0 = [a_0; a_1, a_2, \\\\ldots]`.\n\n    The remainders satisfy the recurrence relation:\n\n    .. math::\n\n       R_{k - 1} = a_{k - 1} + \\\\frac{1}{R_k}, \\\\hskip{3em} k \\\\geq 1\n\n    If the continued fraction :math:`[a_0; a_1, a_2,\\\\ldots]` is finite of\n    order :math:`n` then all :math:`R_k` are rational. If we let\n    :math:`R_k = \\\\frac{s_k}{t_k}` then the recurrence relation above can\n    be written as:\n\n    .. math::\n\n       R_{k - 1} = \\\\frac{s_{k - 1}}{t_{k - 1}} = \\\\frac{a_{k - 1}s_k + t_k}{s_k}, \\\\hskip{3em} k \\\\geq 1\n\n    As this library only deals with finite continued fractions, this function\n    always produces remainders as instances of :py:class:`~fractions.Fraction`.\n\n    The integer :math:`k` must be non-negative and cannot exceed the order\n    of the continued fraction, i.e. the number of its tail elements.\n\n    A :py:class:`ValueError` is raised if :math:`k` is not an integer, or is an\n    integer greater than the number of elements, or if any of the elements are\n    not integers, or if any of the tail elements are not positive integers.\n\n    Parameters\n    ----------\n    k : `int`\n        The index of the remainder. Must be a non-negative integer not\n        exceeding the order of the continued fraction.\n\n    *elements : `int`\n        A variable-length sequence of integer elements of a (simple) continued\n        fraction.\n\n    Returns\n    -------\n    fractions.Fraction\n        A rational fraction constructed from the given sequence of elements of\n        a continued fraction, representing its :math:`k`-th remainder, as\n        defined above.\n\n    Raises\n    ------\n    ValueError\n        If :math:`k` is not an integer, or is an integer greater than the\n        number of elements, or if any of the elements are not integers, or if\n        any of the tail elements are not positive integers.\n\n    Examples\n    --------\n    >>> remainder(0, 3, 4, 12, 4)\n    Fraction(649, 200)\n    >>> remainder(1, 3, 4, 12, 4)\n    Fraction(200, 49)\n    >>> remainder(2, 3, 4, 12, 4)\n    Fraction(49, 4)\n    >>> remainder(3, 3, 4, 12, 4)\n    Fraction(4, 1)\n    >>> remainder(0, -5, 1, 1, 6, 7)\n    Fraction(-415, 93)\n    >>> remainder(1, -5, 1, 1, 6, 7)\n    Fraction(93, 50)\n    >>> remainder(2, -5, 1, 1, 6, 7)\n    Fraction(50, 43)\n    >>> remainder(3, -5, 1, 1, 6, 7)\n    Fraction(43, 7)\n    >>> remainder(4, -5, 1, 1, 6, 7)\n    Fraction(7, 1)\n    >>> remainder(1)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> remainder(-1, 3, 4, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> remainder(4, 3, 4, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> remainder(1, 3, 0, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    >>> remainder(1, 3, -1, 12, 4)\n    Traceback (most recent call last):\n    ...\n    ValueError: `k` must be a non-negative integer not exceeding the order of \n    the continued fraction (number of tail elements), and the tail \n    elements must all be positive integers.\n    \"\"\"\n    pass\n\ndef remainders(*elements: int) -> Generator[Fraction, None, None]:\n    \"\"\"Generates an (ordered) sequence of all remainders of a (simple) continued fraction from a sequence of its elements in descending order of index.\n\n    If :math:`n` is the order of the continued fraction represented by the\n    given sequence of its elements then there are :math:`n + 1` remainders\n    :math:`R_0, R_1, \\\\ldots, R_n`, and the function generates these in\n    reverse order :math:`R_0, R_1, \\\\ldots, R_n`.\n\n    See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/exploring-continued-fractions.html#remainders>`_\n    for more details on remainders.\n\n    Parameters\n    ----------\n    *elements : `int`\n        A variable-length sequence of integer elements of a (simple)\n        continued fraction.\n\n    Yields\n    ------\n    fractions.Fraction\n        Each element generated is a :py:class:`fractions.Fraction` instance and\n        a :math:`k`-th remainder of the given continued fraction.\n\n    Raises\n    ------\n    ValueError\n        If no elements are given, or there are any non-integer elements, or\n        the tail elements are not positive integers.\n\n    Examples\n    --------\n    >>> tuple(remainders(3))\n    (Fraction(3, 1),)\n    >>> tuple(remainders(3, 2))\n    (Fraction(2, 1), Fraction(7, 2))\n    >>> tuple(remainders(3, 4, 12, 4))\n    (Fraction(4, 1), Fraction(49, 4), Fraction(200, 49), Fraction(649, 200))\n    >>> tuple(remainders(-5, 1, 1, 6, 7))\n    (Fraction(7, 1), Fraction(43, 7), Fraction(50, 43), Fraction(93, 50), Fraction(-415, 93))\n    >>> tuple(remainders(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))\n    (Fraction(10, 1), Fraction(91, 10), Fraction(738, 91), Fraction(5257, 738), Fraction(32280, 5257), Fraction(166657, 32280), Fraction(698908, 166657), Fraction(2263381, 698908), Fraction(5225670, 2263381), Fraction(7489051, 5225670))\n    >>> tuple(remainders())\n    Traceback (most recent call last):\n    ...\n    ValueError: Continued fraction elements must be integers, and all \n    tail elements (from the 1st element onwards) must be positive.\n    >>> tuple(remainders(0, 0))\n    Traceback (most recent call last):\n    ...\n    ValueError: Continued fraction elements must be integers, and all \n    tail elements (from the 1st element onwards) must be positive.\n    >>> tuple(remainders(1, 0))\n    Traceback (most recent call last):\n    ...\n    ValueError: Continued fraction elements must be integers, and all \n    tail elements (from the 1st element onwards) must be positive.\n    >>> tuple(remainders(1, 2, -1))\n    Traceback (most recent call last):\n    ...\n    ValueError: Continued fraction elements must be integers, and all \n    tail elements (from the 1st element onwards) must be positive.\n    \"\"\"\n    pass\n\ndef mediant(r: Fraction, s: Fraction, /, *, dir: str = 'right', k: int = 1) -> Fraction:\n    \"\"\"Returns the :math:`k`-th left- or right-mediant of two rational numbers.\n\n    For a positive integer :math:`k`, the :math:`k`-th left-mediant of two\n    rational numbers :math:`r = \\\\frac{a}{b}` and :math:`s = \\\\frac{c}{d}`,\n    where :math:`b, d, b + d \\\\neq 0`, is defined as:\n    \n    .. math::\n\n       \\\\frac{ka + c}{kb + d}, \\\\hskip{3em}    k \\\\geq 1\n\n    while the :math:`k`-th right mediant is defined as:\n    \n    .. math::\n\n       \\\\frac{a + kc}{b + kd}, \\\\hskip{3em}    k \\\\geq 1\n\n    If we assume that :math:`r < s` and :math:`bd > 0` then these mediants\n    have the property that:\n   \n    .. math::\n\n       \\\\frac{a}{b} < \\\\frac{ka + c}{kb + d} \\\\leq \\\\frac{a + kc}{b + kd} < \\\\frac{c}{d},   \\\\hskip{3em} k \\\\geq 1\n\n    where equality holds for :math:`k = 1`. If we let :math:`k \\\\to \\\\infty`\n    then the mediants converge to opposite limits:\n\n    .. math::\n\n      \\\\begin{align}\n      \\\\lim_{k \\\\to \\\\infty} \\\\frac{ka + c}{kb + d} &= \\\\frac{a}{b} \\\\\\\\\n      \\\\lim_{k \\\\to \\\\infty} \\\\frac{a + kc}{b + kd} &= \\\\frac{c}{d}\n      \\\\end{align}\n\n    For more information consult the\n    `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/mediants.html>`_.\n\n    For the left mediant use ``dir=\"left\"``, while for the right use\n    ``dir=\"right\"``. The default is ``dir=\"right\"``. For ``k = 1`` the left and\n    right mediants are identical to the simple mediant :math:`\\\\frac{a + c}{b + d}`.\n\n    Parameters\n    ----------\n    r : `fractions.Fraction`\n        The first rational number.\n\n    s : `fractions.Fraction`\n        The second rational number.\n\n    dir : `str`, default='right'\n        The \"direction\" of the mediant - `'left'` or `'right'`, as defined\n        above.\n\n    k : `int`, default=1\n        The order of the mediant, as defined above.\n\n    Returns\n    -------\n    fractions.Fraction\n        The `k`-th left- or right-mediant of the two given rational numbers.\n\n    Examples\n    --------\n    >>> mediant(Fraction(1, 2), Fraction(3, 5))\n    Fraction(4, 7)\n    >>> mediant(Fraction(1, 2), Fraction(3, 5), dir='left')\n    Fraction(4, 7)\n    >>> mediant(Fraction(1, 2), Fraction(3, 5), k=2)\n    Fraction(7, 12)\n    >>> mediant(Fraction(1, 2), Fraction(3, 5), dir='left', k=2)\n    Fraction(5, 9)\n    >>> mediant(Fraction(1, 2), Fraction(3, 5), k=3, dir='right')\n    Fraction(10, 17)\n    >>> mediant(Fraction(1, 2), Fraction(3, 5), k=3, dir='left')\n    Fraction(6, 11)\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "continuedfractions/continuedfraction.py",
                "code": "class ContinuedFraction(Fraction):\n    \"\"\"An object-oriented representation of a (finite) simple continued fraction.\n\n    An implementation of simple continued fractions as Python objects and\n    instances of the standard library :py:class:`fractions.Fraction` class, with\n    various properties for the continued fraction, including its elements\n    (or coefficients), the order, convergents, and remainders.\n\n    The term \"simple continued fraction\" denotes a specific type of continued\n    fraction where the fractional terms only have numerators of :math:`1`.\n\n    Examples\n    --------\n    Construct the continued fraction for the rational `649/200`.\n\n    >>> cf = ContinuedFraction(649, 200)\n    >>> cf\n    ContinuedFraction(649, 200)\n    >>> cf.as_float()\n    3.245\n\n    Inspect the elements, order, convergents, and remainders.\n\n    >>> cf.elements\n    (3, 4, 12, 4)\n    >>> cf.order\n    3\n    >>> cf.convergent(0), cf.convergent(1), cf.convergent(2), cf.convergent(3)\n    (ContinuedFraction(3, 1), ContinuedFraction(13, 4), ContinuedFraction(159, 49), ContinuedFraction(649, 200))\n    >>> cf.remainder(0), cf.remainder(1), cf.remainder(2), cf.remainder(3)\n    (ContinuedFraction(649, 200), ContinuedFraction(200, 49), ContinuedFraction(49, 4), ContinuedFraction(4, 1))\n\n    Inspect the element counts.\n\n    >>> cf.counter\n    Counter({4: 2, 3: 1, 12: 1})\n\n    Check some properties of the convergents and remainders.\n\n    >>> assert cf.remainder(1) == 1 / (cf - cf.convergent(0))\n\n    Construct continued fractions from element sequences.\n\n    >>> cf_inverse = ContinuedFraction.from_elements(0, 3, 4, 12, 4)\n    >>> cf_inverse\n    ContinuedFraction(200, 649)\n    >>> assert cf_inverse == 1/cf\n    >>> assert cf * cf_inverse == 1\n    >>> cf_negative_inverse = ContinuedFraction.from_elements(-1, 1, 2, 4, 12, 4)\n    >>> cf_negative_inverse\n    ContinuedFraction(-200, 649)\n    >>> assert cf_negative_inverse == -1/cf\n    >>> assert cf * cf_negative_inverse == -1\n    \"\"\"\n    def __new__(cls, *args: Any, **kwargs: Any) -> ContinuedFraction:\n        \"\"\"Creates, initialises and returns instances of this class.\n\n        Arguments can be any which are valid for creating objects of the\n        :py:class:`fractions.Fraction` superclass.\n\n        For clarification, valid arguments can be one of the following:\n\n        * a single instance of :py:class:`numbers.Rational`, including\n          :py:class:`int`, :py:class:`fractions.Fraction` or\n          :py:class:`ContinuedFraction`, named or unnamed\n        * a pair of  :py:class:`numbers.Rational` instances, including\n          :py:class:`int`, :py:class:`fractions.Fraction` and\n          :py:class:`ContinuedFraction`, named or unnamed\n        * a single :py:class:`float` or :py:class:`decimal.Decimal` value\n          that is not a special value such as :py:data:`math.nan`,\n          ``float('inf')``, or ``Decimal('infinity')``\n        * a single numeric valid string (:py:class:`str`) - validity is\n          determined in the superclass by the\n          :py:data:`fractions._RATIONAL_FORMAT` test\n\n        Returns\n        -------\n        ContinuedFraction\n            A :py:class:`ContinuedFraction` instance.\n\n        Examples\n        --------\n        Several example are given below of constructing the simple continued\n        fraction for the number :math:`\\\\frac{-649}{200}` in different ways.\n\n        >>> ContinuedFraction(-649, 200)\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction('-3.245')\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(Decimal('-3.245'))\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction('-649/200')\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(Fraction(-649, 200))\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(ContinuedFraction(649, -200))\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(Fraction(-649), 200)\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(649, Fraction(-200))\n        ContinuedFraction(-649, 200)\n        >>> ContinuedFraction(Fraction(-649), ContinuedFraction(200))\n        ContinuedFraction(-649, 200)\n\n        In each of the examples above, the minus sign can be removed from\n        the arguments to the :py:class:`numbers.Rational` instance and\n        instead attached to the outer class, e.g.:\n\n        >>> -ContinuedFraction(649, 200)\n        ContinuedFraction(-649, 200)\n        >>> -ContinuedFraction('3.245')\n        ContinuedFraction(-649, 200)\n        >>> -ContinuedFraction('649/200')\n        ContinuedFraction(-649, 200)\n\n        Invalid arguments will raise errors in the\n        :py:class:`fractions.Fraction` superclass.\n        \"\"\"\n        pass\n\n    @classmethod\n    def from_elements(cls, *elements: int) -> ContinuedFraction:\n        \"\"\"Returns a :py:class:`ContinuedFraction` instance from a sequence of (integer) elements of a (finite) simple continued fraction.\n\n        Invalid elements will trigger a :py:class:`ValueError`.\n\n        Parameters\n        ----------\n        *elements : int\n            An ordered sequence of integer elements of a (finite) simple\n            continued fraction.\n\n        Returns\n        -------\n        ContinuedFraction\n            A new and fully initialised instance of :py:class:`ContinuedFraction` with\n            the given element sequence.\n\n        Raises\n        ------\n        ValueError\n            If any elements are not integers, or any elements after the 1st\n            are not positive.\n\n        Examples\n        --------\n        Constructing a continued fraction for the rational :math:`\\\\frac{649}{200}` using\n        the element sequence :math:`3, 4, 12, 4`.\n\n        >>> c1 = ContinuedFraction.from_elements(3, 4, 12, 4)\n        >>> c1\n        ContinuedFraction(649, 200)\n\n        Constructing the continued fraction of the (multiplicative) inverse :math:`\\\\frac{200}{649}`\n        using the element sequence :math:`0, 3, 4, 12, 4`.\n\n        >>> c2 = ContinuedFraction.from_elements(0, 3, 4, 12, 4)\n        >>> c2\n        ContinuedFraction(200, 649)\n\n        Validation for elements containing non-integers or negative integers.\n\n        >>> ContinuedFraction.from_elements('0', 1)\n        Traceback (most recent call last):\n        ...\n        ValueError: Continued fraction elements must be integers, and all elements after the 1st must be positive\n        >>> ContinuedFraction.from_elements(0, 1, 2.5)\n        Traceback (most recent call last):\n        ...\n        ValueError: Continued fraction elements must be integers, and all elements after the 1st must be positive\n        >>> ContinuedFraction.from_elements(1, 0)\n        Traceback (most recent call last):\n        ...\n        ValueError: Continued fraction elements must be integers, and all elements after the 1st must be positive\n        >>> ContinuedFraction.from_elements(1, -1)\n        Traceback (most recent call last):\n        ...\n        ValueError: Continued fraction elements must be integers, and all elements after the 1st must be positive\n\n        \"\"\"\n        pass\n\n    def extend(self, *new_elements: int) -> None:\n        \"\"\"Performs an in-place extension of the tail of the current sequence of elements.\n\n        Raises a :py:class:`ValueError` if there are no new elements, or are\n        not positive integers.\n\n        .. note::\n\n           As this method performs an in-place modification of the existing/\n           current instance the object ID remains the same.\n\n        Parameters\n        ----------\n        elements\n            An (ordered) sequence of new (integer) elements by which the tail\n            of the existing sequence of elements is extended.\n\n        Raises\n        ------\n        ValueError\n            If no new elements provided, or the new elements provided are not\n            positive integers.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('3.245')\n        >>> cf\n        ContinuedFraction(649, 200)\n        >>> cf.elements\n        (3, 4, 12, 4)\n        >>> cf.order\n        3\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)), (2, ContinuedFraction(159, 49)), (3, ContinuedFraction(649, 200)))\n        >>> tuple(cf.remainders)\n        ((3, ContinuedFraction(4, 1)), (2, ContinuedFraction(49, 4)), (1, ContinuedFraction(200, 49)), (0, ContinuedFraction(649, 200)))\n        >>> cf.extend(5, 2)\n        >>> cf\n        ContinuedFraction(7457, 2298)\n        >>> cf.elements\n        (3, 4, 12, 4, 5, 2)\n        >>> cf.order\n        5\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)), (2, ContinuedFraction(159, 49)), (3, ContinuedFraction(649, 200)), (4, ContinuedFraction(3404, 1049)), (5, ContinuedFraction(7457, 2298)))\n        >>> tuple(cf.remainders)\n        ((5, ContinuedFraction(2, 1)), (4, ContinuedFraction(11, 2)), (3, ContinuedFraction(46, 11)), (2, ContinuedFraction(563, 46)), (1, ContinuedFraction(2298, 563)), (0, ContinuedFraction(7457, 2298)))\n        >>> cf = ContinuedFraction(649, 200)\n        >>> cf.extend(0, 1)\n        Traceback (most recent call last):\n        ...\n        ValueError: The elements/coefficients to be added to the tail must be positive integers.\n        >>> cf.extend(1, -1)\n        Traceback (most recent call last):\n        ...\n        ValueError: The elements/coefficients to be added to the tail must be positive integers.\n        \"\"\"\n        pass\n\n    def truncate(self, *tail_elements: int) -> None:\n        \"\"\"Performs an in-place truncation of the tail of the existing sequence of elements.\n\n        Raises a :py:class:`ValueError` if the tail elements provided are not\n        positive integers, or do not form a segment of the existing tail. This\n        includes the case where the length of the tail elements provided exceed\n        the length of the existing tail, i.e. the order of the continued\n        fraction represented by the instance.\n\n        .. note::\n\n           The tail elements provided must be positive integers which form a\n           subsequence of the tail of the original sequence ending with the\n           last element, e.g. with respect to the complete sequence of elements\n           ``(3, 4, 12, 4)`` a value of ``12, 4`` for ``*tail_elements`` would\n           be valid, but ``4, 12`` would be invalid as it does not represent\n           a segment of the tail, and ``3, 4, 12, 4`` would also be invalid\n           as it includes the head ``3``.\n\n        .. note::\n\n           As this method performs an in-place modification of the existing/\n           current instance the object ID remains the same.\n\n        Parameters\n        ----------\n        tail_elements\n            An (ordered) sequence of (integer) elements to truncate from the\n            tail of the existing sequence of elements.\n\n        Raises\n        ------\n        ValueError\n            If no tail elements are provided, or the tail elements provided do\n            not represent a valid segment of the existing tail.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('3.245')\n        >>> cf\n        ContinuedFraction(649, 200)\n        >>> cf.elements\n        (3, 4, 12, 4)\n        >>> cf.order\n        3\n        >>> cf.counter\n        Counter({4: 2, 3: 1, 12: 1})\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)), (2, ContinuedFraction(159, 49)), (3, ContinuedFraction(649, 200)))\n        >>> tuple(cf.remainders)\n        ((3, ContinuedFraction(4, 1)), (2, ContinuedFraction(49, 4)), (1, ContinuedFraction(200, 49)), (0, ContinuedFraction(649, 200)))\n        >>> cf.truncate(12, 4)\n        >>> cf\n        ContinuedFraction(13, 4)\n        >>> cf.elements\n        (3, 4)\n        >>> cf.order\n        1\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)))\n        >>> tuple(cf.remainders)\n        ((1, ContinuedFraction(4, 1)), (0, ContinuedFraction(13, 4)))\n        >>> cf = ContinuedFraction(649, 200)\n        >>> cf.truncate(4, 12)\n        Traceback (most recent call last):\n        ...\n        ValueError: The elements/coefficients to be truncated from the tail must form a valid segment of the existing tail.\n        >>> cf.truncate(3, 4, 12, 4)\n        Traceback (most recent call last):\n        ...\n        ValueError: The elements/coefficients to be truncated from the tail must form a valid segment of the existing tail.\n        \"\"\"\n        pass\n\n    def __eq__(self, other, /) -> bool:\n        \"\"\"Custom equality check.\n\n        Compares the sequence of elements/coefficients of ``self`` with\n        that of ``other`` if ``other`` is also a\n        :py:class:`~continuedfractions.continuedfraction.ContinuedFraction`\n        instance, otherwise calls the superclass :py:class:`~fractions.Fraction`\n        equality check.\n\n        Returns\n        -------\n        bool\n            The boolean result of the equality check.\n        \"\"\"\n        pass\n\n    def __hash__(self) -> int:\n        \"\"\"Custom hash.\n\n        Custom hash which hashes the sequence of elements/coefficients - as\n        this is always defined as a finite, non-empty tuple the hash is\n        always defined.\n\n        Returns\n        -------\n        int\n            The hash of the\n            :py:class:`~continuedfractions.continuedfraction.ContinuedFraction`\n            instance.\n        \"\"\"\n        pass\n\n    def __add__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __radd__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __sub__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __rsub__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __mul__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __rmul__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __truediv__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __rtruediv__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __floordiv__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __rfloordiv__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __divmod__(self, other, /) -> tuple[ContinuedFraction, ContinuedFraction]:\n        pass\n\n    def __rdivmod__(self, other, /) -> tuple[ContinuedFraction, ContinuedFraction]:\n        pass\n\n    def __pow__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __rpow__(self, other, /) -> ContinuedFraction:\n        pass\n\n    def __pos__(self) -> ContinuedFraction:\n        pass\n\n    def __neg__(self) -> ContinuedFraction:\n        \"\"\"\n        Division-free negation for a finite simple continued fraction, as\n        described `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/creating-continued-fractions.html#negative-continued-fractions>`_.\n\n        The basic algorithm can be described as follows: if\n        :math:`[a_0; a_1,\\\\ldots, a_n]` is the simple continued fraction of a\n        **positive** rational number :math:`\\\\frac{a}{b}` of finite order\n        :math:`n` then  :math:`-\\\\frac{a}{b}` has the simple continued\n        fraction:\n\n        .. math::\n\n           \\\\begin{cases}\n           [-a_0;]                                      \\\\hskip{3em} & n = 0 \\\\\\\\\n           [-(a_0 + 1); 2]                              \\\\hskip{3em} & n = 1 \\\\text{ and } a_1 = 2 \\\\\\\\\n           [-(a_0 + 1); a_2 + 1, a_3,\\\\ldots, a_n]      \\\\hskip{3em} & n \\\\geq 2 \\\\text{ and } a_1 = 1 \\\\\\\\\n           [-(a_0 + 1); 1, a_1 - 1, a_2, \\\\ldots,a_n]   \\\\hskip{3em} & n \\\\geq 2 \\\\text{ and } a_1 \\\\geq 2\n           \\\\end{cases}\n\n        In applying this algorithm there is an assumption that the last element\n        :math:`a_n > 1`, as any simple continued fraction of type\n        :math:`[a_0; a_1,\\\\ldots, a_{n} = 1]` can be reduced to the simple\n        continued fraction :math:`[a_0; a_1,\\\\ldots, a_{n - 1} + 1]`.\n        \"\"\"\n        pass\n\n    def __abs__(self) -> ContinuedFraction:\n        pass\n\n    def as_float(self) -> float:\n        \"\"\"Returns the :py:class:`float` value of the continued fraction.\n\n        Returns\n        -------\n        float\n            The :py:class:`float` value of the continued fraction.\n\n        Examples\n        --------\n        Note that the default :py:mod:`decimal` context precision of :math:`28`\n        is used in these examples.\n\n        >>> import math\n        >>> math.pi\n        3.141592653589793\n\n        Now construct a :py:class:`ContinuedFraction` instance from it, and check the \n        :py:class:`float` value.\n\n        >>> cf = ContinuedFraction(math.pi)\n        >>> cf\n        ContinuedFraction(884279719003555, 281474976710656)\n        >>> cf.as_float()\n        3.141592653589793\n        \"\"\"\n        pass\n\n    def as_decimal(self) -> Decimal:\n        \"\"\"Returns the :py:class:`decimal.Decimal` value of the continued fraction.\n\n        Returns\n        -------\n        decimal.Decimal\n            The :py:class:`decimal.Decimal` representation of the continued fraction.\n\n        Examples\n        --------\n        Note that the default :py:mod:`decimal` context precision of :math:`28`\n        is used in these examples.\n\n        >>> import math\n        >>> math.pi\n        3.141592653589793\n\n        Now construct a :py:class:`ContinuedFraction` instance from it, and check the \n        :py:class:`float` value.\n\n        >>> cf = ContinuedFraction(math.pi)\n        >>> cf\n        ContinuedFraction(884279719003555, 281474976710656)\n        >>> cf.as_decimal()\n        Decimal('3.141592653589793115997963469')\n        \"\"\"\n        pass\n\n    @property\n    def elements(self) -> tuple[int]:\n        \"\"\":py:class:`tuple`: The (ordered) sequence of elements of the continued fraction.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('.12345')\n        >>> cf\n        ContinuedFraction(2469, 20000)\n        >>> cf.elements\n        (0, 8, 9, 1, 21, 1, 1, 5)\n        \"\"\"\n        pass\n\n    @property\n    def order(self) -> int:\n        \"\"\":py:class:`int`: The order of the continued fraction, which is the number of its elements minus :math:`1`.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('.12345')\n        >>> cf\n        ContinuedFraction(2469, 20000)\n        >>> len(cf.elements)\n        8\n        >>> cf.order\n        7\n        \"\"\"\n        pass\n\n    @property\n    def counter(self) -> collections.Counter:\n        \"\"\":py:class:`collections.Counter` : A counter for the elements.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction(928374923, 8249234)\n        >>> cf.counter\n        Counter({1: 6, 2: 3, 24: 2, 112: 1, 5: 1, 3: 1})\n        \"\"\"\n        pass\n\n    @property\n    def khinchin_mean(self) -> Decimal | None:\n        \"\"\":py:class:`decimal.Decimal` or :py:data:`None`: The Khinchin mean of the continued fraction, which is defined as the geometric mean of all its elements after the 1st.\n\n        We define the Khinchin mean :math:`K_n` of a (simple) continued\n        fraction :math:`[a_0; a_1, a_2, \\\\ldots, a_n]` as:\n\n        .. math::\n\n           K_n := \\\\sqrt[n]{a_1a_2 \\\\cdots a_n} = \\\\left( a_1a_2 \\\\cdots a_n \\\\right)^{\\\\frac{1}{n}}, \\\\hskip{3em} n \\\\geq 1\n\n        This property is intended to make it easier to study the limit of\n        :math:`K_n` as :math:`n \\\\to \\\\infty`.  See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/exploring-continued-fractions.html#khinchin-means-khinchin-s-constant>`_\n        for more details.\n\n        In the special case of integers or fractions representing integers,\n        whose continued fraction representations consist of only a single\n        element, a null value is returned.\n\n        Examples\n        --------\n        Note that the default :py:mod:`decimal` context precision of :math:`28`\n        is used in these examples.\n\n        >>> ContinuedFraction(649, 200).elements\n        (3, 4, 12, 4)\n        >>> ContinuedFraction(649, 200).khinchin_mean\n        Decimal('5.76899828122963409526846589869819581508636474609375')\n        >>> ContinuedFraction(415, 93).elements\n        (4, 2, 6, 7)\n        >>> ContinuedFraction(415, 93).khinchin_mean\n        Decimal('4.37951913988788898990378584130667150020599365234375')\n        >>> (ContinuedFraction(649, 200) + ContinuedFraction(415, 93)).elements\n        (7, 1, 2, 2, 2, 1, 1, 11, 1, 2, 12)\n        >>> (ContinuedFraction(649, 200) + ContinuedFraction(415, 93)).khinchin_mean\n        Decimal('2.15015313349074244086978069390170276165008544921875')\n        >>> ContinuedFraction(5000).khinchin_mean\n\n        \"\"\"\n        pass\n\n    def convergent(self, k: int, /) -> ContinuedFraction:\n        \"\"\"Returns the :math:`k`-th (simple) convergent of the continued fraction.\n\n        Given a (simple) continued fraction  :math:`[a_0;a_1,a_2,\\\\ldots]` the\n        :math:`k`-th convergent is defined as:\n\n        .. math::\n\n           C_k = a_0 + \\\\cfrac{1}{a_1 + \\\\cfrac{1}{a_2 \\\\ddots \\\\cfrac{1}{a_{k-1} + \\\\cfrac{1}{a_k}}}}\n\n        The result is a :py:class:`~continuedfractions.continuedfraction.ContinuedFraction` instance.\n        \n        If  the continued fraction is of order :math:`n` then it has exactly\n        :math:`n + 1` convergents :math:`C_0,C_1,C_2,\\\\ldots,C_n` where\n        the :math:`k`-th convergent :math:`C_k = \\\\frac{p_k}{q_k}` is given by\n        the recurrence relation:\n\n        .. math::\n           \n           \\\\begin{align}\n           p_k &= a_kp_{k - 1} + p_{k - 2} \\\\\\\\\n           q_k &= a_kq_{k - 1} + q_{k - 2},        \\\\hskip{3em}    k \\\\geq 3\n           \\\\end{align}\n\n        where :math:`p_0 = a_0`, :math:`q_0 = 1`, :math:`p_1 = p_1p_0 + 1`,\n        and :math:`q_1 = p_1`.\n\n        Parameters\n        ----------\n        k : int\n            The index of the convergent, as described above.\n\n        Returns\n        -------\n        ContinuedFraction\n            A new :py:class:`ContinuedFraction` instance representing the :math:`k`-th\n            (simple) convergent of the original continued fraction, as\n            described above.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('.12345')\n        >>> cf\n        ContinuedFraction(2469, 20000)\n        >>> cf.convergent(0)\n        ContinuedFraction(0, 1)\n        >>> cf.convergent(2)\n        ContinuedFraction(9, 73)\n        >>> cf.convergent(6)\n        ContinuedFraction(448, 3629)\n        >>> cf.convergent(7)\n        ContinuedFraction(2469, 20000)\n        \"\"\"\n        pass\n\n    @property\n    def convergents(self) -> Generator[tuple[int, ContinuedFraction], None, None]:\n        \"\"\"Generates an enumerated sequence of all convergents of the continued fraction.\n\n        The convergents are generated as tuples of :py:class:`int` and\n        :py:class:`~continuedfraction.continuedfraction.ContinuedFraction`\n        instances, where the integers represent the indices of the convergents.\n\n        If :math:`n` is the order of the continued fraction then :math:`n + 1`\n        convergents :math:`C_0, C_1, \\\\ldots, C_n` are generated in that order.\n\n        Yields\n        ------\n        tuple\n            A tuple of convergent index (:py:class:`int`) and convergents\n            (:py:class:`~continuedfractions.continuedfraction.ContinuedFraction`)\n            of the continued fraction.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('3.245')\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(3, 1)), (1, ContinuedFraction(13, 4)), (2, ContinuedFraction(159, 49)), (3, ContinuedFraction(649, 200)))\n        \"\"\"\n        pass\n\n    @property\n    def even_convergents(self) -> Generator[tuple[int, ContinuedFraction], None, None]:\n        \"\"\"Generates an enumerated sequence of all even-order convergents of the continued fraction.\n\n        The convergents are generated as tuples of :py:class:`int` and\n        :py:class:`~continuedfraction.continuedfraction.ContinuedFraction`\n        instances, where the integers represent the indices of the convergents.\n\n        If :math:`n` is the order of the continued fraction then only the even-\n        indexed convergents :math:`C_0, C_2, C_4, \\\\ldots` are generated.\n\n        Yields\n        ------\n        tuple\n            A tuple of convergent index (:py:class:`int`) and convergents\n            (:py:class:`~continuedfractions.continuedfraction.ContinuedFraction`)\n            of the continued fraction.\n\n        Examples\n        --------\n        >>> tuple(ContinuedFraction('3.245').even_convergents)\n        ((0, ContinuedFraction(3, 1)), (2, ContinuedFraction(159, 49)))\n        \"\"\"\n        pass\n\n    @property\n    def odd_convergents(self) -> Generator[tuple[int, ContinuedFraction], None, None]:\n        \"\"\"Generates an enumerated sequence of all odd-order convergents of the continued fraction.\n\n        The convergents are generated as tuples of :py:class:`int` and\n        :py:class:`~continuedfraction.continuedfraction.ContinuedFraction`\n        instances, where the integers represent the indices of the convergents.\n\n        If :math:`n` is the order of the continued fraction then only the odd-\n        indexed convergents :math:`C_1, C_3, C_5, \\\\ldots` are generated.\n\n        Yields\n        ------\n        tuple\n            A tuple of convergent index (:py:class:`int`) and convergents\n            (:py:class:`~continuedfractions.continuedfraction.ContinuedFraction`)\n            of the continued fraction.\n\n        Examples\n        --------\n        >>> tuple(ContinuedFraction('3.245').odd_convergents)\n        ((1, ContinuedFraction(13, 4)), (3, ContinuedFraction(649, 200)))\n        \"\"\"\n        pass\n\n    def semiconvergent(self, k: int, m: int, /) -> ContinuedFraction:\n        \"\"\"Returns the :math:`m`-th semiconvergent of two consecutive convergents :math:`p_{k - 1}` and :math:`p_k` of the continued fraction.\n\n        The integer :math:`k` must be positive and determine two consecutive\n        convergents :math:`p_{k - 1}` and :math:`p_k` of a (finite, simple)\n        continued fraction.\n\n        The integer :math:`m` can be any positive integer.\n\n        Parameters\n        ----------\n        k : int\n            The integer :math:`k` determining two consecutive convergents\n            :math:`p_{k - 1}` and :math:`p_k` of a (finite, simple) continued\n            fraction\n            :math:`[a_0; a_1, \\\\ldots, a_{k}, a_{k + 1}, \\\\ldots, a_n]`.\n\n        m : int\n            The index of the semiconvergent of the convergents\n            :math:`p_{k - 1}` and :math:`p_k`.\n\n        Returns\n        -------\n        ContinuedFraction\n            The :math:`m`-th semiconvergent of the convergents\n            :math:`p_{k - 1}` and :math:`p_k`.\n\n        Raises\n        ------\n        ValueError\n            If :math:`k` or :math:`m` are not positive integers, or :math:`k`\n            is an integer that does **not** satisfy :math:`1 \\\\leq k \\\\leq n`\n            where :math:`n` is the order of the (finite, simple) continued\n            fraction of which :math:`p_{k - 1}` and :math:`p_k` are\n            convergents.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction(-415, 93)\n        >>> cf.elements\n        (-5, 1, 1, 6, 7)\n        >>> tuple(cf.convergents)\n        ((0, ContinuedFraction(-5, 1)), (1, ContinuedFraction(-4, 1)), (2, ContinuedFraction(-9, 2)), (3, ContinuedFraction(-58, 13)), (4, ContinuedFraction(-415, 93)))\n        >>> cf.semiconvergent(3, 1)\n        ContinuedFraction(-67, 15)\n        >>> cf.semiconvergent(3, 2)\n        ContinuedFraction(-125, 28)\n        >>> cf.semiconvergent(3, 3)\n        ContinuedFraction(-183, 41)\n        >>> cf.semiconvergent(3, 4)\n        ContinuedFraction(-241, 54)\n        >>> cf.semiconvergent(3, 5)\n        ContinuedFraction(-299, 67)\n        >>> cf.semiconvergent(3, 6)\n        ContinuedFraction(-357, 80)\n        >>> cf.semiconvergent(3, 7)\n        ContinuedFraction(-415, 93)\n        \"\"\"\n        pass\n\n    def remainder(self, k: int, /) -> ContinuedFraction:\n        \"\"\"Returns the :math:`k`-th remainder of the continued fraction.\n\n        Given a (simple) continued fraction  :math:`[a_0;a_1,a_2,\\\\ldots]` the\n        :math:`k`-th remainder :math:`R_k` is the (simple) continued fraction\n        :math:`[a_k; a_{k + 1}, a_{k + 2}, \\\\ldots]`:\n\n        .. math::\n\n           R_k = a_k + \\\\cfrac{1}{a_{k + 1} + \\\\cfrac{1}{a_{k + 2} \\\\ddots }}\n\n        where :math:`R_0` is just the original continued fraction, i.e.\n        :math:`R_0 = [a_0; a_1, a_2, \\\\ldots]`.\n\n        The result is a :py:class:`~continuedfractions.continuedfraction.ContinuedFraction` instance.\n\n        The remainders satisfy the recurrence relation:\n\n        .. math::\n\n           R_{k - 1} = a_{k - 1} + \\\\frac{1}{R_k}, \\\\hskip{3em} k \\\\geq 1\n\n        If the original continued fraction is finite then its remainders are all\n        finite and rational.\n\n        As this class implements finite simple continued fractions, this method\n        always produces rational numbers.\n\n        The integer :math:`k` must be non-negative and cannot exceed the order\n        of the continued fraction, i.e. the number of its tail elements, and \n        the tail elements must define a valid finite simple continued fraction.\n\n        Parameters\n        ----------\n        k : int\n            The index of the remainder, as described above.\n\n        Returns\n        -------\n        ContinuedFraction\n            A new :py:class:`ContinuedFraction` instance representing the :math:`k`-th\n            remainder of the original continued fraction, as described above.\n\n        Examples\n        --------\n        >>> cf = ContinuedFraction('.12345')\n        >>> cf\n        ContinuedFraction(2469, 20000)\n        >>> cf.remainder(0)\n        ContinuedFraction(2469, 20000)\n        >>> cf.remainder(2)\n        ContinuedFraction(2469, 248)\n        >>> cf.remainder(6)\n        ContinuedFraction(6, 5)\n        >>> cf.remainder(7)\n        ContinuedFraction(5, 1)\n        \"\"\"\n        pass\n\n    @property\n    def remainders(self) -> Generator[tuple[int, ContinuedFraction], None, None]:\n        \"\"\"Generates an enumerated sequence of all remainders of the continued fraction in descending order of index.\n\n        If :math:`n` is the order of the continued fraction then there are\n        :math:`n + 1` remainders :math:`R_0, R_1, \\\\ldots, R_n`, and the method\n        generates these in reverse order :math:`R_0, R_1, \\\\ldots, R_n`.\n\n        See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/exploring-continued-fractions.html#remainders>`_\n        for more details on remainders.\n\n        The remainders are generated as tuples of :py:class:`int`\n        and :py:class:`~continuedfractions.continuedfraction.ContinuedFraction`\n        instances, where the integers represent the indexes of the remainders.\n\n        Yields\n        ------\n        tuple\n            A tuple of remainder indices (:py:class:`int`) and remainders\n            (:py:class:`~continuedfractions.continuedfraction.ContinuedFraction`)\n            of the continued fraction.\n\n        Examples\n        --------\n        >>> tuple(ContinuedFraction('3.245').remainders)\n        ((3, ContinuedFraction(4, 1)), (2, ContinuedFraction(49, 4)), (1, ContinuedFraction(200, 49)), (0, ContinuedFraction(649, 200)))\n        >>> tuple(ContinuedFraction(-415, 93).remainders)\n        ((4, ContinuedFraction(7, 1)), (3, ContinuedFraction(43, 7)), (2, ContinuedFraction(50, 43)), (1, ContinuedFraction(93, 50)), (0, ContinuedFraction(-415, 93)))\n        \"\"\"\n        pass\n\n    def left_mediant(self, other: Fraction, /, *, k: int = 1) -> ContinuedFraction:\n        \"\"\"Returns the :math:`k`-th left-mediant of the continued fraction with another rational number.\n        \n        For a positive integer :math:`k`, the :math:`k`-th left-mediant of two\n        rational numbers :math:`r = \\\\frac{a}{b}` and :math:`s = \\\\frac{c}{d}`,\n        where :math:`b, d, b + d \\\\neq 0`, is defined as:\n        \n        .. math::\n\n           \\\\frac{ka + c}{kb + d}, \\\\hskip{3em}    k \\\\geq 1\n\n        while the :math:`k`-th right mediant is defined as:\n        \n        .. math::\n\n           \\\\frac{a + kc}{b + kd}, \\\\hskip{3em}    k \\\\geq 1\n\n        If we assume that :math:`r < s` and :math:`bd > 0` then these mediants\n        have the property that:\n       \n        .. math::\n\n           \\\\frac{a}{b} < \\\\frac{ka + c}{kb + d} \\\\leq \\\\frac{a + kc}{b + kd} < \\\\frac{c}{d},   \\\\hskip{3em} k \\\\geq 1\n\n        where equality holds for :math:`k = 1`. If we let :math:`k \\\\to \\\\infty`\n        then the mediants converge to opposite limits:\n\n        .. math::\n\n          \\\\begin{align}\n          \\\\lim_{k \\\\to \\\\infty} \\\\frac{ka + c}{kb + d} &= \\\\frac{a}{b} \\\\\\\\\n          \\\\lim_{k \\\\to \\\\infty} \\\\frac{a + kc}{b + kd} &= \\\\frac{c}{d}\n          \\\\end{align}\n\n        For more information consult the\n        `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/mediants.html>`_.\n\n        The method is cached (with :py:func:`functools.cache`), which makes calls\n        after the initial call much faster.\n\n        Parameters\n        ----------\n        other : fractions.Fraction, ContinuedFraction\n            The second fraction to use to calculate the :math:`k`-th mediant with\n            the first.\n        \n        k : int, default=1\n            The order of the mediant, as defined above.        \n\n        Returns\n        -------\n        ContinuedFraction\n            The :math:`k`-th left-mediant of the original fraction and the second\n            fraction, as a :py:class:`ContinuedFraction` instance.\n\n        Examples\n        --------\n        >>> c1 = ContinuedFraction('1/2')\n        >>> c2 = ContinuedFraction(3, 5)\n        >>> c1, c2\n        (ContinuedFraction(1, 2), ContinuedFraction(3, 5))\n        >>> c1.left_mediant(c2)\n        ContinuedFraction(4, 7)\n        >>> c1.left_mediant(c2, k=2)\n        ContinuedFraction(5, 9)\n        >>> c1.left_mediant(c2, k=3)\n        ContinuedFraction(6, 11)\n        >>> c1.left_mediant(c2, k=100)\n        ContinuedFraction(103, 205)\n        >>> assert c1.left_mediant(c2, k=2) < c1.right_mediant(c2, k=2)\n        >>> assert c1.left_mediant(c2, k=3) < c1.right_mediant(c2, k=3)\n        >>> assert c1.left_mediant(c2, k=100) < c1.right_mediant(c2, k=100)\n        \"\"\"\n        pass\n\n    def right_mediant(self, other: Fraction, /, *, k: int = 1) -> ContinuedFraction:\n        \"\"\"Returns the :math:`k`-th right-mediant of the continued fraction with another rational number.\n        \n        For a positive integer :math:`k`, the :math:`k`-th right-mediant of two\n        rational numbers :math:`r = \\\\frac{a}{b}` and :math:`s = \\\\frac{c}{d}`,\n        where :math:`b, d, b + d \\\\neq 0`, is defined as:\n        \n        .. math::\n\n           \\\\frac{a + kc}{b + kd}, \\\\hskip{3em}    k \\\\geq 1\n\n        while the :math:`k`-th left-mediant is defined as:\n        \n        .. math::\n\n           \\\\frac{ka + c}{kb + d}, \\\\hskip{3em}    k \\\\geq 1\n\n        If we assume that :math:`r < s` and :math:`bd > 0` then these mediants\n        have the property that:\n       \n        .. math::\n\n           \\\\frac{a}{b} < \\\\frac{ka + c}{kb + d} \\\\leq \\\\frac{a + kc}{b + kd} < \\\\frac{c}{d},   \\\\hskip{3em} k \\\\geq 1\n\n        where equality holds for :math:`k = 1`. If we let :math:`k \\\\to \\\\infty`\n        then the mediants converge to opposite limits:\n\n        .. math::\n\n          \\\\begin{align}\n          \\\\lim_{k \\\\to \\\\infty} \\\\frac{ka + c}{kb + d} &= \\\\frac{a}{b} \\\\\\\\\n          \\\\lim_{k \\\\to \\\\infty} \\\\frac{a + kc}{b + kd} &= \\\\frac{c}{d}\n          \\\\end{align}\n\n        For more information consult the\n        `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/mediants.html>`_.\n\n        Parameters\n        ----------\n        other : fractions.Fraction, ContinuedFraction\n            The second fraction to use to calculate the :math:`k`-th mediant with\n            the first.\n        \n        k : int, default=1\n            The order of the mediant, as defined above.        \n\n        Returns\n        -------\n        ContinuedFraction\n            The :math:`k`-th right-mediant of the original fraction and the second\n            fraction, as a :py:class:`ContinuedFraction` instance.\n\n        Examples\n        --------\n        >>> c1 = ContinuedFraction('1/2')\n        >>> c2 = ContinuedFraction(3, 5)\n        >>> c1, c2\n        (ContinuedFraction(1, 2), ContinuedFraction(3, 5))\n        >>> c1.right_mediant(c2)\n        ContinuedFraction(4, 7)\n        >>> c1.right_mediant(c2, k=2)\n        ContinuedFraction(7, 12)\n        >>> c1.right_mediant(c2, k=3)\n        ContinuedFraction(10, 17)\n        >>> c1.right_mediant(c2, k=100)\n        ContinuedFraction(301, 502)\n        >>> assert c1.left_mediant(c2, k=2) < c1.right_mediant(c2, k=2)\n        >>> assert c1.left_mediant(c2, k=3) < c1.right_mediant(c2, k=3)\n        >>> assert c1.left_mediant(c2, k=100) < c1.right_mediant(c2, k=100)\n        \"\"\"\n        pass\n\n    def mediant(self, other: Fraction, /) -> ContinuedFraction:\n        \"\"\"Returns the simple mediant of the continued fraction with another continued fraction.\n        \n        The simple mediant of two rational numbers :math:`r = \\\\frac{a}{b}`\n        and :math:`s = \\\\frac{c}{d}`, where :math:`b, d, b + d \\\\neq 0`, is\n        defined as:\n        \n        .. math::\n\n           \\\\frac{a + c}{b + d}\n\n        The resulting value :math:`\\\\frac{a + c}{b + d}` is the same as the\n        1st order left- or right-mediant of :math:`r = \\\\frac{a}{b}`\n        and :math:`s = \\\\frac{c}{d}`. So this method would produce the same\n        result as the :py:meth:`~continuedfractions.continuedfraction.ContinuedFraction.left_mediant`\n        or :py:meth:`~continuedfractions.continuedfraction.ContinuedFraction.right_mediant`\n        methods where the order :math:`k` is set to :math:`1`.\n\n        For more information consult the\n        `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/mediants.html>`_.\n\n        Parameters\n        ----------\n        other : fractions.Fraction, ContinuedFraction\n            The other continued fraction.\n        \n        Returns\n        -------\n        ContinuedFraction\n            The simple mediant of the original fraction and the other continued\n            fraction.\n\n        Examples\n        --------\n        >>> ContinuedFraction(1, 2).mediant(ContinuedFraction(3, 5))\n        ContinuedFraction(4, 7)\n        >>> assert ContinuedFraction(1, 2).mediant(ContinuedFraction(3, 5)) == ContinuedFraction(1, 2).left_mediant(ContinuedFraction(3, 5), k=1)\n        >>> assert ContinuedFraction(1, 2).mediant(ContinuedFraction(3, 5)) == ContinuedFraction(1, 2).right_mediant(ContinuedFraction(3, 5), k=1)\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "continuedfractions/sequences.py",
                "code": "def coprime_integers(n: int, /, *, start: int = 1, stop: int = None) -> tuple[int]:\n    \"\"\"Returns a sequence of (positive) integers :math:`1 \\\\leq m < n` coprime to a given positive integer :math:`n`.\n\n    Wrapper of :py:class:`~continuedfractions.sequences.coprime_integers_generator`.\n\n    The tuple is sorted in descending order of magnitude.\n\n    The optional ``start`` and ``stop`` parameters can be used to bound the\n    the range of (positive) integers in which integers coprime to the given\n    :math:`n` are sought.\n\n    For :math:`n = 1, 2` the ``start`` value is effectively ignored, but\n    if :math:`n > 1` then the ``start`` value must be an integer in the range\n    :math:`1..n - 1`.\n\n    The ``stop`` value defaults to ``None``, which is then internally\n    initialised to :math:`n`; if :math:`n > 1` and ``stop`` is given then it\n    must be an integer in the range :math:`\\\\text{start} + 1..n`.\n\n    Parameters\n    ----------\n    n : int\n        The positive integer for which (positive) coprime integers\n        :math:`m < n` are sought.\n\n    start : int, default=1\n        The lower bound of the range of (positive) integers in which integers\n        coprime to the given :math:`n` are sought. For :math:`n = 1, 2` the\n        ``start`` value is effectively ignored, but if :math:`n > 1` then the\n        ``start`` value must be in the range :math:`1..n - 1`.\n\n    stop : int, default=None\n        The upper bound of the range of (positive) integers in which integers\n        coprime to the given :math:`n` are sought. The ``stop`` value defaults\n        to ``None``, which is then internally initialised to :math:`n`; if\n        :math:`n > 1` and ``stop`` is given then it must be an integer in the\n        range :math:`\\\\text{start} + 1..n`.\n\n    Returns\n    -------\n    tuple\n        A sequence of (positive) integers :math:`1 \\\\leq m < n` coprime to a\n        given positive integer :math:`n`.\n\n    Examples\n    --------\n    Examples using the default ``start`` and ``stop`` values:\n\n    >>> coprime_integers(1)\n    (1,)\n    >>> coprime_integers(2)\n    (1,)\n    >>> coprime_integers(3)\n    (2, 1)\n    >>> coprime_integers(4)\n    (3, 1)\n    >>> coprime_integers(5)\n    (4, 3, 2, 1)\n    >>> coprime_integers(6)\n    (5, 1)\n    >>> coprime_integers(7)\n    (6, 5, 4, 3, 2, 1)\n    >>> coprime_integers(8)\n    (7, 5, 3, 1)\n    >>> coprime_integers(9)\n    (8, 7, 5, 4, 2, 1)\n    >>> coprime_integers(10)\n    (9, 7, 3, 1)\n    >>> coprime_integers(11)\n    (10, 9, 8, 7, 6, 5, 4, 3, 2, 1)\n\n    Examples using custom ``start`` and ``stop`` values:\n\n    >>> coprime_integers(3, start=2)\n    (2,)\n    >>> coprime_integers(3, start=3)\n    Traceback (most recent call last):\n    ...    \n    ValueError: `n` must be a positive integer; if `n` > 1 then the `start` value must be a positive integer in the range 1..n - 1; and if given the `stop` value must be a positive integer in the range `start` + 1..n\n    >>> coprime_integers(23, start=5, stop=21)\n    (21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5)\n    >>> coprime_integers(5, start=2)\n    (4, 3, 2)\n    >>> coprime_integers(5, start=3)\n    (4, 3)\n    >>> coprime_integers(6, start=2)\n    (5,)\n    >>> coprime_integers(6, start=3)\n    (5,)\n    >>> coprime_integers(6, start=4)\n    (5,)\n    >>> coprime_integers(7, start=2)\n    (6, 5, 4, 3, 2)\n    >>> coprime_integers(7, start=3)\n    (6, 5, 4, 3)\n    >>> coprime_integers(7, start=4)\n    (6, 5, 4)\n    >>> coprime_integers(7, start=5)\n    (6, 5)\n    \"\"\"\n    pass\n\nclass KSRMTree:\n    \"\"\"An implicit/generative class implementation of the Kanga-Saunders-Randall-Mitchell (KSRM) ternary trees for representing and generating pairs of all (positive) coprime integers.\n\n    The term \"KSRM trees\" is the author's, and refers to the trees presented in the following papers:\n\n    * Kanga, A. R. (1990). The Family Tree of Pythagorean Triplets. The Mathematical Gazette, 26(15), 15-17.\n    * Mitchell, D. W. (2001). An Alternative Characterisation of All Primitive Pythagorean Triples. The Mathematical Gazette, 85(503), 273-275. https://doi.org/10.2307/3622017\n    * Saunders, R., & Randall, T. (1994). The family tree of the Pythagorean triplets revisited. The Mathematical Gazette, 78(482), 190-193. https://doi.org/10.2307/3618576\n\n    .. note::\n\n       The class is named ``KSRMTree`` purely for convenience, but it is\n       actually a representation of two (ternary) subtrees.\n\n    .. note::\n\n       The author could not access the Kanga paper online, but the core result\n       is described clearly in the papers of Saunders and Randall, and of\n       Mitchell.\n\n    See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/sequences.html#ksrm-trees>`_\n    for more details.\n    \"\"\"\n    def __new__(cls) -> KSRMTree:\n        \"\"\"Class constructor.\n\n        Creates and initialises a new instance with the minimum set of required\n        attributes - for the roots and branch generating functions, which we\n        call branches.\n        \"\"\"\n        pass\n\n    @property\n    def roots(self) -> Literal[tuple[tuple[int, int], tuple[int, int]]]:\n        \"\"\":py:class:`tuple`: The tuple of roots of the KSRM trees, which are :math:`(2, 1)` and :math:`(3, 1)`.\n\n        For more details see the following papers:\n\n        * Kanga, A. R. (1990). The Family Tree of Pythagorean Triplets. The Mathematical Gazette, 26(15), 15-17.\n        * Mitchell, D. W. (2001). An Alternative Characterisation of All Primitive Pythagorean Triples. The Mathematical Gazette, 85(503), 273-275. https://doi.org/10.2307/3622017\n        * Saunders, R., & Randall, T. (1994). The family tree of the Pythagorean triplets revisited. The Mathematical Gazette, 78(482), 190-193. https://doi.org/10.2307/3618576\n\n        or the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/sequences.html#ksrm-trees>`_.\n\n        Examples\n        --------\n        >>> KSRMTree().roots\n        ((2, 1), (3, 1))\n        \"\"\"\n        pass\n\n    @property\n    def branches(self) -> tuple[NamedCallableProxy]:\n        \"\"\":py:class:`tuple`: The tuple of three branch generating functions of the KSRM trees.\n\n        There are three branch generating functions, given by the mappings:\n\n        .. math::\n\n           \\\\begin{align}\n           (a, b) &\\\\longmapsto (2a - b, a) \\\\\\\\\n           (a, b) &\\\\longmapsto (2a + b, a) \\\\\\\\\n           (a, b) &\\\\longmapsto (a + 2b, b)\n           \\\\end{align}\n\n        For more details see the following papers:\n\n        * Kanga, A. R. (1990). The Family Tree of Pythagorean Triplets. The Mathematical Gazette, 26(15), 15-17.\n        * Mitchell, D. W. (2001). An Alternative Characterisation of All Primitive Pythagorean Triples. The Mathematical Gazette, 85(503), 273-275. https://doi.org/10.2307/3622017\n        * Saunders, R., & Randall, T. (1994). The family tree of the Pythagorean triplets revisited. The Mathematical Gazette, 78(482), 190-193. https://doi.org/10.2307/3618576\n\n        or the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/sequences.html#ksrm-trees>`_.\n\n        Examples\n        --------\n        Generating the first two generations of children for the parent\n        :math:`(2, 1)`.\n\n        >>> tree = KSRMTree()\n        >>> tree.branches\n        (NamedCallableProxy(\"KSRM tree branch #1: (x, y) |--> (2x - y, x)\"), NamedCallableProxy(\"KSRM tree branch #2: (x, y) |--> (2x + y, x)\"), NamedCallableProxy(\"KSRM tree branch #3: (x, y) |--> (x + 2y, y)\"))\n        >>> tree.branches[0](2, 1)\n        (3, 2)\n        >>> tree.branches[1](2, 1)\n        (5, 2)\n        >>> tree.branches[2](2, 1)\n        (4, 1)\n        >>> tree.branches[0](*tree.branches[0](2, 1))\n        (4, 3)\n        >>> tree.branches[1](*tree.branches[0](2, 1))\n        (8, 3)\n        >>> tree.branches[2](*tree.branches[0](2, 1))\n        (7, 2)\n        >>> tree.branches[0](*tree.branches[1](2, 1))\n        (8, 5)\n        >>> tree.branches[1](*tree.branches[1](2, 1))\n        (12, 5)\n        >>> tree.branches[2](*tree.branches[1](2, 1))\n        (9, 2)\n        >>> tree.branches[0](*tree.branches[2](2, 1))\n        (7, 4)\n        >>> tree.branches[1](*tree.branches[2](2, 1))\n        (9, 4)\n        >>> tree.branches[2](*tree.branches[2](2, 1))\n        (6, 1)\n        \"\"\"\n        pass\n\n    def _backtrack(\n        self,\n        n: int,\n        visited: list[tuple[tuple[int, int], NamedCallableProxy]],\n        /,\n        *,\n        node_bound: int = None\n    ) -> tuple[tuple[int, int], NamedCallableProxy, int, NamedCallableProxy]:\n        \"\"\"Backtracks on the KSRM coprime pairs trees from a failed node to the nearest previously visited node that satisfies the node bound.\n\n        A private function that backtracks on the KSRM coprime pairs trees: the\n        procedure is that, given a (positive) integer :math:`n > 2`, for which\n        coprime pairs are being sought, and a sequence (list) of pairs of\n        visited nodes and their associated generating branches in the KSRM\n        tree, and assuming that the last element of the visited sequence\n        contains the node that \"failed\", the function identifies the nearest\n        previously visited node whose first component satisifes the test\n        :math:`< n` **and** and whose associated generating branch is not equal\n        to the third branch given by :math:`(x, y) \\\\longmapsto (x + 2y, y)`.\n\n        .. note::\n\n           The function assumes that the last node in the incoming sequence\n           of visited nodes and generating branch pairs represents a \"failed\"\n           node, i.e. whose first component failed the test :math:`\\\\leq n`\n           during the search. No attempt is made to validate or verify the\n           failed node, and the only purpose of the function is to backtrack\n           to the nearest previously visited node which meets the requirements\n           listed above.\n\n        .. note::\n\n           There is no input validation as this is a private function which\n           will be called from\n           :py:meth:`~continuedfractions.sequences.KSRMTree.search_root`. So\n           results for invalid arguments will most likely be incorrect or\n           unexpected.\n\n        Parameters\n        ----------\n        n : int\n            The (positive) integer :math:`> 2` which is passed by the root\n            search method or the general tree search method.\n\n        visited : list\n            A sequence of visited nodes and associated generating branches in\n            the KSRM coprime pairs tree.\n\n        node_bound : int, default=None\n            A bound to check that :math:`a < n` for a node :math:`(a, b)`. The\n            actual default value is the incoming :math:`n`, and this is set\n            internally.\n\n        Returns\n        -------\n        tuple\n            A tuple consisting of the following values in order: (1) the\n            target node in the visited sequence to backtrack to, (2) the\n            associated generating branch function (the lambda for branch #1,\n            or branch #2, or branch #3), (3) the index of the target node\n            and branch pair in the visited sequence, (4) the generating\n            branch of the successor node of the target node returned as (1).\n\n        Examples\n        --------\n        An example where :math:`n = 5` and the failed node is :math:`(6, 1)`,\n        which was the successor node to :math:`(4, 1)` from the third branch.\n\n        >>> tree = KSRMTree()\n        >>> tree.branches\n        (NamedCallableProxy(\"KSRM tree branch #1: (x, y) |--> (2x - y, x)\"), NamedCallableProxy(\"KSRM tree branch #2: (x, y) |--> (2x + y, x)\"), NamedCallableProxy(\"KSRM tree branch #3: (x, y) |--> (x + 2y, y)\"))\n        >>> visited = [((2, 1), None), ((4, 1), tree.branches[-1]), ((6, 1), tree.branches[-1])]\n        >>> tree._backtrack(5, visited)\n        ((2, 1), None, 0, NamedCallableProxy(\"KSRM tree branch #3: (x, y) |--> (x + 2y, y)\"))\n\n        An example where :math:`n = 8` and the failed node is :math:`(19, 8)`,\n        which was the successor node to :math:`(8, 3)` from the first branch.\n\n        >>> tree = KSRMTree()\n        >>> tree.branches\n        (NamedCallableProxy(\"KSRM tree branch #1: (x, y) |--> (2x - y, x)\"), NamedCallableProxy(\"KSRM tree branch #2: (x, y) |--> (2x + y, x)\"), NamedCallableProxy(\"KSRM tree branch #3: (x, y) |--> (x + 2y, y)\"))\n        >>> visited = [((2, 1), None), ((3, 2),tree.branches[0]), ((8, 3),tree.branches[1]), ((19, 8), tree.branches[0])]\n        >>> tree._backtrack(8, visited)\n        ((3, 2), NamedCallableProxy(\"KSRM tree branch #1: (x, y) |--> (2x - y, x)\"), 1, NamedCallableProxy(\"KSRM tree branch #2: (x, y) |--> (2x + y, x)\"))\n        \"\"\"\n        pass\n\n    def search_root(self, n: int, root: tuple[int, int], /) -> Generator[tuple[int, int], None, None]:\n        \"\"\"Depth-first branch-and-bound generative search function (in pre-order, NLMR), with backtracking and pruning, on the KSRM coprime pairs trees, starting from the given root node.\n\n        The given root node need not be the canonical roots, :math:`(2, 1)`,\n        :math:`(3, 1)`, but can be any of their successor nodes.\n\n        It is required that :math:`n \\\\geq 2`, otherwise a\n        :py:class:`ValueError` is raised.\n\n        The search implementation is an iterative version of a depth-first\n        branch-and-bound search (DFS) procedure, with backtracking and pruning,\n        in which nodes are traversed in NLMR pre-order (root -> left -> mid ->\n        right) and bounds and checks are applied to the nodes, including\n        pruning failed or unnecessary nodes, before further traversal or\n        backtracking:\n        \n        #. Visit the current node :math:`(a, b)` and check :math:`a \\\\leq n`.\n        #. If the check is successful iteratively traverse the current node's\n           first child and its children, then the second child and its \n           children, and then the third child and its children, applying the\n           check :math:`a \\\\leq n` to each visited node.\n        #. If a check fails for any node backtrack to the nearest previously\n           visited node which meets a stricter check :math:`a < n` and which\n           has unvisited child nodes, while pruning all visited intermediate\n           nodes after the backtracked target node and leading up to the failed\n           node, including the failed node. By design the backtracked target\n           node will have untraversed children on at least one branch, and the\n           traversal can begin again, as described above.\n\n        Parameters\n        ----------\n        n : int\n            The positive integer for which coprime pairs :math:`(a, b)`, with\n            :math:`1 \\\\leq b < a \\\\leq n`, are sought.\n\n        root : tuple\n            The \"root\" node from which to search - this can be either of the\n            canonical roots, :math:`(2, 1)`, :math:`(3, 1)`, but also any of\n            their successor nodes.\n\n        Raises\n        ------\n        ValueError\n            If ``n`` is not an integer or is :math:`< 2`.\n\n        Yields\n        ------\n        tuple\n            Pairs of coprime integers :math:`(a, b)`, with\n            :math:`1 \\\\leq b < a \\\\leq n`.\n\n        Examples\n        --------\n        Searching from the root :math:`(2, 1)` for coprime pairs for\n        :math:`n = 5`:\n\n        >>> tree = KSRMTree()\n        >>> list(tree.search_root(5, (2, 1)))\n        [(2, 1), (3, 2), (4, 3), (5, 4), (5, 2), (4, 1)]\n        >>> assert tree.roots[0] == (2, 1)\n        >>> list(tree.search_root(5, tree.roots[0]))\n        [(2, 1), (3, 2), (4, 3), (5, 4), (5, 2), (4, 1)]\n\n        The same type of search from the root :math:`(3, 1)`:\n\n        >>> list(tree.search_root(5, (3, 1)))\n        [(3, 1), (5, 3), (5, 1)]\n        >>> assert tree.roots[1] == (3, 1)\n        >>> list(tree.search_root(5, tree.roots[1]))\n        [(3, 1), (5, 3), (5, 1)]\n        \"\"\"\n        pass\n\n    def search(self, n: int, /) -> Generator[tuple[int, int], None, None]:\n        \"\"\"Depth-first branch-and-bound generative search function (in pre-order, NLMR) on the KSRM coprime pairs trees to find all pairs of coprime (positive) integers not exceeding the given integer :math:`n \\\\geq 1`.\n    \n        See the :py:meth:`~continuedfractions.sequences.KSRMTree.search_root`\n        method for details of the implementation for the root-based search.\n\n        This method mainly calls the root-based search method\n        :py:meth:`~continuedfractions.sequences.KSRMTree.search_root` for the\n        two canonical roots :math:`(2, 1)` and :math:`(3, 1)`.\n\n        Parameters\n        ----------\n        n : int\n            The positive integer for which coprime pairs :math:`(a, b)`, with\n            :math:`1 \\\\leq b < a \\\\leq n`, are sought.\n\n        Raises\n        ------\n        ValueError\n            If ``n`` is not an integer or is :math:`< 1`.\n\n        Yields\n        ------\n        tuple\n            Pairs of coprime integers :math:`(a, b)`, with\n            :math:`1 \\\\leq b < a \\\\leq n`.\n\n        Examples\n        --------\n        A few examples of invalid and valid searches:\n\n        >>> tree = KSRMTree()\n        >>> list(tree.search(\"not an integer\"))\n        Traceback (most recent call last):\n        ...\n        ValueError: `n` must be a positive integer >= 1\n        >>> list(tree.search(1))\n        [(1, 1)]\n        >>> list(tree.search(2))\n        [(1, 1), (2, 1)]\n        >>> list(tree.search(3))\n        [(1, 1), (2, 1), (3, 2), (3, 1)]\n        >>> list(tree.search(5))\n        [(1, 1), (2, 1), (3, 2), (4, 3), (4, 1), (3, 1), (5, 4), (5, 3), (5, 2), (5, 1)]\n        >>> list(tree.search(10))\n        [(1, 1), (2, 1), (3, 2), (4, 3), (5, 4), (6, 5), (7, 6), (8, 7), (9, 8), (8, 3), (7, 2), (5, 2), (8, 5), (9, 2), (4, 1), (7, 4), (9, 4), (6, 1), (8, 1), (3, 1), (5, 3), (7, 5), (9, 7), (7, 3), (5, 1), (9, 5), (7, 1), (9, 1), (10, 9), (10, 7), (10, 3), (10, 1)]\n        \"\"\"\n        pass\n\ndef coprime_pairs(n: int, /) -> tuple[tuple[int, int]]:\n    \"\"\"Returns a sequence (tuple) of all pairs of (positive) coprime integers :math:`<= n`.\n\n    Wrapper of :py:func:`~continuedfractions.sequences.coprime_pairs_generator`.\n\n    Parameters\n    ----------\n    n : int\n        The positive integer for which coprime pairs :math:`(a, b)`, with\n        :math:`1 \\\\leq b < a \\\\leq n`, are sought.\n\n    Returns\n    -------\n    tuple\n        A :py:class:`tuple` of pairs of coprime integers :math:`(a, b)`, with\n        :math:`1 \\\\leq b < a \\\\leq n`.\n\n    Examples\n    --------\n    A few examples of computing coprime pairs:\n\n    >>> coprime_pairs(1)\n    ((1, 1),)\n    >>> coprime_pairs(2)\n    ((1, 1), (2, 1))\n    >>> coprime_pairs(3)\n    ((1, 1), (2, 1), (3, 2), (3, 1))\n    >>> coprime_pairs(5)\n    ((1, 1), (2, 1), (3, 2), (3, 1), (4, 3), (4, 1), (5, 4), (5, 3), (5, 2), (5, 1))\n    >>> coprime_pairs(10)\n    ((1, 1), (2, 1), (3, 2), (4, 3), (5, 4), (6, 5), (7, 6), (8, 7), (8, 3), (7, 2), (5, 2), (8, 5), (4, 1), (7, 4), (6, 1), (8, 1), (3, 1), (5, 3), (7, 5), (7, 3), (5, 1), (7, 1), (9, 8), (9, 7), (9, 5), (9, 4), (9, 2), (9, 1), (10, 9), (10, 7), (10, 3), (10, 1))\n    \"\"\"\n    pass\n\ndef farey_sequence(n: int, /) -> tuple[ContinuedFraction]:\n    \"\"\"Returns an (ordered) sequence (tuple) of rational numbers forming the Farey sequence of order :math:`n`.\n\n    Wrapper of :py:func:`~continuedfractions.sequences.farey_sequence_generator`.\n\n    The elements of the sequence are returned as\n    :py:class:`~continuedfractions.continuedfraction.ContinuedFraction`\n    instances, in ascending order of magnitude.\n\n    See the `documentation <https://continuedfractions.readthedocs.io/en/latest/sources/sequences.html#sequences-farey-sequences>`_\n    for more details.\n\n    Parameters\n    ----------\n    n : int:\n        The order of the Farey sequence.\n\n    Returns\n    -------\n    tuple\n        A :py:class:`tuple` of ``ContinuedFraction`` instances representing the\n        elements of the Farey sequence of order :math:`n`, generated in\n        ascending order of magnitude.\n\n    Examples\n    --------\n    >>> farey_sequence(1)\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 1))\n    >>> farey_sequence(2)\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 2), ContinuedFraction(1, 1))\n    >>> farey_sequence(3)\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 3), ContinuedFraction(1, 2), ContinuedFraction(2, 3), ContinuedFraction(1, 1))\n    >>> farey_sequence(4)\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 4), ContinuedFraction(1, 3), ContinuedFraction(1, 2), ContinuedFraction(2, 3), ContinuedFraction(3, 4), ContinuedFraction(1, 1))\n    >>> farey_sequence(5)\n    (ContinuedFraction(0, 1), ContinuedFraction(1, 5), ContinuedFraction(1, 4), ContinuedFraction(1, 3), ContinuedFraction(2, 5), ContinuedFraction(1, 2), ContinuedFraction(3, 5), ContinuedFraction(2, 3), ContinuedFraction(3, 4), ContinuedFraction(4, 5), ContinuedFraction(1, 1))\n    \"\"\"\n    pass\n"
            }
        ],
        "minimal_test_cases": [
            {
                "test_id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__creation_and_initialisation__valid_inputs__object_correctly_created_and_initialised[valid_inputs0-expected_fraction_obj0-expected_elements0-1-expected_counter0-expected_khinchin_mean0-expected_convergents0-expected_ref_right_order2_mediant0-expected_ref_left_order2_mediant0-expected_ref_simple_mediant0-1.5-expected_decimal_value0]",
                "covers": [
                    "continuedfractions.continuedfraction.ContinuedFraction.__new__ - happy path constructor and initialization",
                    "continuedfractions.continuedfraction.ContinuedFraction.as_float - happy path float conversion",
                    "continuedfractions.continuedfraction.ContinuedFraction.as_decimal - happy path decimal conversion",
                    "continuedfractions.continuedfraction.ContinuedFraction.elements - happy path property access",
                    "continuedfractions.continuedfraction.ContinuedFraction.order - happy path property access",
                    "continuedfractions.continuedfraction.ContinuedFraction.counter - happy path property access",
                    "continuedfractions.continuedfraction.ContinuedFraction.khinchin_mean - happy path property access",
                    "continuedfractions.continuedfraction.ContinuedFraction.convergent - happy path basic usage",
                    "continuedfractions.continuedfraction.ContinuedFraction.convergents - happy path property access",
                    "continuedfractions.continuedfraction.ContinuedFraction.even_convergents - happy path property access",
                    "continuedfractions.continuedfraction.ContinuedFraction.odd_convergents - happy path property access",
                    "continuedfractions.continuedfraction.ContinuedFraction.left_mediant - happy path basic usage",
                    "continuedfractions.continuedfraction.ContinuedFraction.right_mediant - happy path basic usage",
                    "continuedfractions.continuedfraction.ContinuedFraction.mediant - happy path basic usage",
                    "continuedfractions.continuedfraction.ContinuedFraction.remainder - happy path basic usage",
                    "continuedfractions.continuedfraction.ContinuedFraction.remainders - happy path property access",
                    "continuedfractions.continuedfraction.ContinuedFraction.__eq__ - happy path equality check"
                ]
            },
            {
                "test_id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__from_elements__valid_elements__correct_fraction_returned[elements0-expected0]",
                "covers": [
                    "continuedfractions.continuedfraction.ContinuedFraction.from_elements - happy path classmethod"
                ]
            },
            {
                "test_id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__extend__valid_elements__correctly_extended[instance0-new_elements0-expected_comparative_instance0]",
                "covers": [
                    "continuedfractions.continuedfraction.ContinuedFraction.extend - happy path method",
                    "continuedfractions.continuedfraction.ContinuedFraction.__hash__ - happy path hash generation"
                ]
            },
            {
                "test_id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__truncate__valid_elements__correctly_truncated[instance0-tail_elements0-expected_comparative_instance0]",
                "covers": [
                    "continuedfractions.continuedfraction.ContinuedFraction.truncate - happy path method"
                ]
            },
            {
                "test_id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__rational_operations",
                "covers": [
                    "continuedfractions.continuedfraction.ContinuedFraction.__add__ - happy path arithmetic operation",
                    "continuedfractions.continuedfraction.ContinuedFraction.__radd__ - happy path arithmetic operation",
                    "continuedfractions.continuedfraction.ContinuedFraction.__sub__ - happy path arithmetic operation",
                    "continuedfractions.continuedfraction.ContinuedFraction.__rsub__ - happy path arithmetic operation",
                    "continuedfractions.continuedfraction.ContinuedFraction.__mul__ - happy path arithmetic operation",
                    "continuedfractions.continuedfraction.ContinuedFraction.__rmul__ - happy path arithmetic operation",
                    "continuedfractions.continuedfraction.ContinuedFraction.__truediv__ - happy path arithmetic operation",
                    "continuedfractions.continuedfraction.ContinuedFraction.__rtruediv__ - happy path arithmetic operation",
                    "continuedfractions.continuedfraction.ContinuedFraction.__floordiv__ - happy path arithmetic operation",
                    "continuedfractions.continuedfraction.ContinuedFraction.__rfloordiv__ - happy path arithmetic operation",
                    "continuedfractions.continuedfraction.ContinuedFraction.__divmod__ - happy path arithmetic operation",
                    "continuedfractions.continuedfraction.ContinuedFraction.__rdivmod__ - happy path arithmetic operation",
                    "continuedfractions.continuedfraction.ContinuedFraction.__pow__ - happy path arithmetic operation",
                    "continuedfractions.continuedfraction.ContinuedFraction.__rpow__ - happy path arithmetic operation",
                    "continuedfractions.continuedfraction.ContinuedFraction.__pos__ - happy path arithmetic operation",
                    "continuedfractions.continuedfraction.ContinuedFraction.__neg__ - happy path arithmetic operation",
                    "continuedfractions.continuedfraction.ContinuedFraction.__abs__ - happy path arithmetic operation"
                ]
            },
            {
                "test_id": "tests/units/test_continuedfraction.py::TestContinuedFraction::test_ContinuedFraction__semiconvergent__valid_args__correct_semiconvergent_returned[1-1-expected_semiconvergent0]",
                "covers": [
                    "continuedfractions.continuedfraction.ContinuedFraction.semiconvergent - happy path method"
                ]
            },
            {
                "test_id": "tests/units/test_lib.py::TestContinuedFractionRational::test_continued_fraction_rational__valid_integers__correct_elements_generated[r0-elements0]",
                "covers": [
                    "continuedfractions.lib.continued_fraction_rational - happy path function"
                ]
            },
            {
                "test_id": "tests/units/test_lib.py::TestContinuedFractionReal::test_continued_fraction_real__valid_inputs__correct_elements_generated[x8-expected8]",
                "covers": [
                    "continuedfractions.lib.continued_fraction_real - happy path function for string decimal input"
                ]
            },
            {
                "test_id": "tests/units/test_lib.py::TestFractionFromElements::test_fraction_from_elements__valid_elements__correct_fraction_returned[elements0-fraction0]",
                "covers": [
                    "continuedfractions.lib.fraction_from_elements - happy path function"
                ]
            },
            {
                "test_id": "tests/units/test_lib.py::TestConvergent::test_convergent__valid_elements__correct_convergent_returned[1-elements0-expected_convergent0]",
                "covers": [
                    "continuedfractions.lib.convergent - happy path function"
                ]
            },
            {
                "test_id": "tests/units/test_lib.py::TestConvergents::test_convergents__valid_elements__correct_convergents_generated[in_elements0-expected_convergents0]",
                "covers": [
                    "continuedfractions.lib.convergents - happy path function"
                ]
            },
            {
                "test_id": "tests/units/test_lib.py::TestRemainder::test_remainder__valid_elements__correct_remainder_returned[0-elements0-expected_remainder0]",
                "covers": [
                    "continuedfractions.lib.remainder - happy path function"
                ]
            },
            {
                "test_id": "tests/units/test_lib.py::TestRemainders::test_remainders__valid_elements__correct_remainders_generated[in_elements0-expected_remainders0]",
                "covers": [
                    "continuedfractions.lib.remainders - happy path function"
                ]
            },
            {
                "test_id": "tests/units/test_lib.py::TestMediant::test_left_mediant__two_ordered_rationals__correct_mediant_returned[rational10-rational20-1-expected_mediant0]",
                "covers": [
                    "continuedfractions.lib.mediant - happy path with dir='left'",
                    "continuedfractions.lib.left_mediant - happy path (as partial of mediant)"
                ]
            },
            {
                "test_id": "tests/units/test_lib.py::TestMediant::test_right_mediant__two_ordered_rationals__correct_mediant_returned[rational10-rational20-right-1-expected_mediant0]",
                "covers": [
                    "continuedfractions.lib.mediant - happy path with dir='right'",
                    "continuedfractions.lib.right_mediant - happy path (as partial of mediant)"
                ]
            },
            {
                "test_id": "tests/units/test_sequences.py::TestCoprimeIntegers::test_coprime_integers__default_start_and_stop_values[3-expected_coprime_integers2]",
                "covers": [
                    "continuedfractions.sequences.coprime_integers - happy path with default arguments",
                    "continuedfractions.sequences.coprime_integers_generator - happy path (exercised by coprime_integers)"
                ]
            },
            {
                "test_id": "tests/units/test_sequences.py::TestCoprimePairs::test_coprime_pairs[1-expected_pairs0]",
                "covers": [
                    "continuedfractions.sequences.coprime_pairs - happy path",
                    "continuedfractions.sequences.coprime_pairs_generator - happy path (exercised by coprime_pairs)"
                ]
            },
            {
                "test_id": "tests/units/test_sequences.py::TestFareySequence::test_farey_sequence[1-expected_sequence0]",
                "covers": [
                    "continuedfractions.sequences.farey_sequence - happy path",
                    "continuedfractions.sequences.farey_sequence_generator - happy path (exercised by farey_sequence)"
                ]
            },
            {
                "test_id": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__creation_and_initialisation",
                "covers": [
                    "continuedfractions.sequences.KSRMTree.__new__ - happy path constructor",
                    "continuedfractions.sequences.KSRMTree.roots - happy path property access",
                    "continuedfractions.sequences.KSRMTree.branches - happy path property access"
                ]
            },
            {
                "test_id": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree__search_root[2-root0-expected_pairs0]",
                "covers": [
                    "continuedfractions.sequences.KSRMTree.search_root - happy path method"
                ]
            },
            {
                "test_id": "tests/units/test_sequences.py::TestKSRMTree::test_KSRMTree_search[1-expected_pairs0]",
                "covers": [
                    "continuedfractions.sequences.KSRMTree.search - happy path method"
                ]
            },
            {
                "test_id": "tests/units/test_utils.py::TestNamedCallableProxy::test_NamedCallableProxy__creation_and_initialisation[<lambda>-x |--> x^2-expected_callable_proxy0]",
                "covers": [
                    "continuedfractions.utils.NamedCallableProxy.__new__ - happy path constructor",
                    "continuedfractions.utils.NamedCallableProxy.__repr__ - happy path representation",
                    "continuedfractions.utils.NamedCallableProxy.__eq__ - happy path equality check",
                    "continuedfractions.utils.NamedCallableProxy.__call__ - happy path callable behavior"
                ]
            }
        ]
    },
    {
        "idx": 23261,
        "repo_name": "pga2rn_simple-sqlite3-orm",
        "url": "https://github.com/pga2rn/simple-sqlite3-orm",
        "description": "A simple python sqlite3 ORM, powered by pydantic.",
        "stars": 5,
        "forks": 0,
        "language": "python",
        "size": 259,
        "created_at": "2024-03-01T02:47:36+00:00",
        "updated_at": "2025-03-26T16:05:19+00:00",
        "pypi_info": {
            "name": "simple-sqlite3-orm",
            "version": "0.9.0",
            "url": "https://files.pythonhosted.org/packages/c7/96/f143c21d4b8e5247c14eade1849563bfd6062fbe947ed108fba77e12a770/simple_sqlite3_orm-0.9.0.tar.gz"
        },
        "judge_info": {
            "language": "python",
            "is_good_project": false,
            "reason": "",
            "python_file_num": 26,
            "comment_ratio": 0.18927827897293545,
            "pyfile_content_length": 203303,
            "pyfile_code_lines": 5764,
            "test_file_exist": true,
            "test_file_content_length": 62333,
            "pytest_framework": true,
            "test_case_num": 61,
            "metadata_path": [
                "pyproject.toml"
            ],
            "readme_content_length": 9245,
            "llm_reason": "The project is highly suitable due to its self-contained nature (using SQLite and standard libraries like pydantic), clear ORM functionality, and extensive local test suite. It requires no external APIs, internet access, or specialized hardware for the AI-rebuilt version. The task is purely code-based and targets a well-understood problem domain (ORM). The complexity is assessed as 'Medium'; building a basic ORM with pydantic integration and custom type handling is non-trivial but feasible. The inclusion of async and threadpool support adds complexity, potentially pushing towards 'Hard', but the core task remains well-defined. The existing tests provide a strong basis for verification. The main challenge for the AI would be accurately replicating the ORM logic, SQL generation, pydantic integration, and potentially the concurrency features.",
            "llm_project_type": "Library (SQLite ORM)",
            "llm_rating": 75,
            "llm_difficulty": "Medium"
        },
        "tests": {
            "repo_name": "pga2rn_simple-sqlite3-orm",
            "finish_test": true,
            "test_case_result": {
                "tests/test__orm.py::TestORMBase::test_create_index": "passed",
                "tests/test__orm.py::TestORMBase::test_insert_entries": "passed",
                "tests/test__orm.py::TestORMBase::test_orm_execute[None-expected0-where_cols0-params0]": "passed",
                "tests/test__orm.py::TestORMBase::test_orm_execute[table_deserialize_asdict_row_factory-expected1-None-None]": "passed",
                "tests/test__orm.py::TestORMBase::test_orm_execute[table_deserialize_astuple_row_factory-expected2-where_cols2-params2]": "passed",
                "tests/test__orm.py::TestORMBase::test_orm_check_entry_exist": "passed",
                "tests/test__orm.py::TestORMBase::test_select_entry": "passed",
                "tests/test__orm.py::TestORMBase::test_insert_mapping[row_as_mapping0-expected0]": "passed",
                "tests/test__orm.py::TestORMBase::test_insert_mapping[row_as_mapping1-expected1]": "passed",
                "tests/test__orm.py::TestORMBase::test_insert_mapping[row_as_mapping2-expected2]": "passed",
                "tests/test__orm.py::TestORMBase::test_insert_mappings[row_as_mappings0]": "passed",
                "tests/test__orm.py::TestORMBase::test_insert_mappings[row_as_mappings1]": "passed",
                "tests/test__orm.py::TestORMBase::test_select_entries": "passed",
                "tests/test__orm.py::TestORMBase::test_select_all_entries": "passed",
                "tests/test__orm.py::TestORMBase::test_select_with_function_call": "passed",
                "tests/test__orm.py::TestORMBase::test_update_entries[entry_to_insert0-set_values0-where_indicator0-expected0]": "passed",
                "tests/test__orm.py::TestORMBase::test_update_entries[entry_to_insert1-set_values1-where_indicator1-expected1]": "passed",
                "tests/test__orm.py::TestORMBase::test_update_entries_with_custom_stmt[entry_to_insert0-set_values0-WHERE id > :lower_bound AND id < :upper_bound-params0-expected0]": "passed",
                "tests/test__orm.py::TestORMBase::test_delete_entries": "passed",
                "tests/test__orm.py::TestORMUpdateEntriesMany::test_with_where_cols": "passed",
                "tests/test__orm.py::TestORMUpdateEntriesMany::test_with_custom_where_stmt_and_extra_params_iter": "passed",
                "tests/test__orm.py::TestORMUpdateEntriesMany::test_with_custom_where_stmt_and_extra_params": "passed",
                "tests/test__orm.py::TestORMUpdateEntriesMany::test_with_custom_stmt": "passed",
                "tests/test__orm.py::test_create_table[opts0]": "passed",
                "tests/test__orm.py::test_create_table[opts1]": "passed",
                "tests/test__orm.py::test_create_table[opts2]": "passed",
                "tests/test__orm.py::test_bootstrap[test_1-create_table_params0-None]": "passed",
                "tests/test__orm.py::test_bootstrap[test_2-create_table_params1-create_indexes_params1]": "passed",
                "tests/test__orm.py::test_bootstrap[test_3-None-None]": "passed",
                "tests/test__orm.py::test_row_factory_specifying[sqlite3_row_factory-Row]": "passed",
                "tests/test__orm.py::test_row_factory_specifying[table_spec-table_row_factory]": "passed",
                "tests/test__orm.py::test_row_factory_specifying[table_spec_no_validation-_expected_row_factory2]": "passed",
                "tests/test__orm.py::test_row_factory_specifying[do_not_change-_dummy_row_factory]": "passed",
                "tests/test__orm.py::test_row_factory_specifying[None-None]": "passed",
                "tests/test__table_spec.py::test_table_create[table_create_params0]": "passed",
                "tests/test__table_spec.py::test_table_create[table_create_params1]": "passed",
                "tests/test__table_spec.py::test_table_create[table_create_params2]": "passed",
                "tests/test__table_spec.py::test_table_create[table_create_params3]": "passed",
                "tests/test__table_spec.py::test_table_create[table_create_params4]": "passed",
                "tests/test__table_spec.py::TestTableSpecWithDB::test_insert_entry[insert a complete row-to_insert0]": "passed",
                "tests/test__table_spec.py::TestTableSpecWithDB::test_insert_entry[insert a partially set row, omit id(rowid alias)-to_insert1]": "passed",
                "tests/test__table_spec.py::TestTableSpecWithDB::test_insert_entry[insert a row with order shuffled-to_insert2]": "passed",
                "tests/test__table_spec.py::TestTableSpecWithDB::test_insert_default_values": "passed",
                "tests/test__table_spec.py::TestTableSpecWithDB::test_lookup_entry": "passed",
                "tests/test__table_spec.py::TestTableSpecWithDB::test_update_entry[set_values0-where_cols0-UPDATE test_table SET id = :id, id_str = :id_str WHERE id = :__table_spec_id AND id_str = :__table_spec_id_str AND extra = :__table_spec_extra AND int_str = :__table_spec_int_str;-expected_result0]": "passed",
                "tests/test__table_spec.py::TestTableSpecWithDB::test_update_entry[set_values1-where_cols1-UPDATE test_table SET id = :id, id_str = :id_str WHERE id = 123;-expected_result1]": "passed",
                "tests/test__table_spec.py::TestTableSpecWithDB::test_update_entry[set_values2-where_cols2-UPDATE test_table SET id = :id, id_str = :id_str;-expected_result2]": "passed",
                "tests/test__table_spec.py::TestTableSpecWithDB::test_update_entry[set_values3-where_cols3-UPDATE OR FAIL test_table SET id_str = :id_str, extra = :extra WHERE id = :__table_spec_id AND id_str = :__table_spec_id_str AND extra = :__table_spec_extra AND int_str = :__table_spec_int_str RETURNING *;-expected_result3]": "passed",
                "tests/test__table_spec.py::TestTableSpecWithDB::test_deserialize_asdict_row_factory": "passed",
                "tests/test__table_spec.py::TestTableSpecWithDB::test_deserialize_astuple_row_factory": "passed",
                "tests/test__table_spec.py::test_table_from_tuple[_in0-True-_expected0]": "passed",
                "tests/test__table_spec.py::test_table_from_tuple[_in1-False-_expected1]": "passed",
                "tests/test__table_spec.py::test_table_from_dict[_in0-True-_expected0]": "passed",
                "tests/test__table_spec.py::test_table_from_dict[_in1-False-_expected1]": "passed",
                "tests/test__table_spec.py::test_table_dump_asdict[_in0-_expected0]": "passed",
                "tests/test__table_spec.py::test_table_dump_asdict[_in1-_expected1]": "passed",
                "tests/test__table_spec.py::test_table_dump_astuple[_in0-_cols0-_expected0]": "passed",
                "tests/test__table_spec.py::test_table_dump_astuple[_in1-_cols1-_expected1]": "passed",
                "tests/test__table_spec.py::test_serializing_mapping[_in0-_expected0]": "passed",
                "tests/test__table_spec.py::test_serializing_mapping[_in1-_expected1]": "passed",
                "tests/test__types.py::test_datetime_helper[_in0-expected0]": "passed",
                "tests/test__utils.py::test_typeafinityrepr[Choice123-INTEGER]": "passed",
                "tests/test__utils.py::test_typeafinityrepr[ChoiceABC-TEXT]": "passed",
                "tests/test__utils.py::test_typeafinityrepr[str-TEXT]": "passed",
                "tests/test__utils.py::test_typeafinityrepr[bytes-BLOB]": "passed",
                "tests/test__utils.py::test_typeafinityrepr[int-INTEGER]": "passed",
                "tests/test__utils.py::test_typeafinityrepr[float-REAL]": "passed",
                "tests/test__utils.py::test_typeafinityrepr[None-NULL]": "passed",
                "tests/test__utils.py::test_typeafinityrepr[Literal-INTEGER]": "passed",
                "tests/test__utils.py::test_typeafinityrepr[Literal-TEXT]": "passed",
                "tests/test__utils.py::test_typeafinityrepr[Optional-BLOB]": "passed",
                "tests/test__utils.py::test_typeafinityrepr[Optional-INTEGER0]": "passed",
                "tests/test__utils.py::test_typeafinityrepr[Optional-TEXT0]": "passed",
                "tests/test__utils.py::test_typeafinityrepr[Optional-INTEGER1]": "passed",
                "tests/test__utils.py::test_typeafinityrepr[Optional-TEXT1]": "passed",
                "tests/test__utils.py::test_constrainrepr[_in0-NOT NULL DEFAULT 1 CHECK (column IN (1,2,3))]": "passed",
                "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_create_table": "passed",
                "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_insert_entries_with_pool": "passed",
                "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_create_index": "passed",
                "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_orm_execute": "passed",
                "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_lookup_entries": "passed",
                "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_caller_exits_when_lookup_entries": "passed",
                "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_in_thread_raise_exceptions_when_lookup_entries": "passed",
                "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_delete_entries": "passed",
                "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_check_timer": "passed",
                "tests/test_e2e/test_orm.py::TestWithSampleDB::test_create_table": "passed",
                "tests/test_e2e/test_orm.py::TestWithSampleDB::test_insert_entries": "passed",
                "tests/test_e2e/test_orm.py::TestWithSampleDB::test_create_index": "passed",
                "tests/test_e2e/test_orm.py::TestWithSampleDB::test_select_one_entry": "passed",
                "tests/test_e2e/test_orm.py::TestWithSampleDB::test_orm_execute": "passed",
                "tests/test_e2e/test_orm.py::TestWithSampleDB::test_lookup_entries": "passed",
                "tests/test_e2e/test_orm.py::TestWithSampleDB::test_select_all_entries": "passed",
                "tests/test_e2e/test_orm.py::TestWithSampleDB::test_delete_entries": "passed",
                "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_create_table": "passed",
                "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_insert_entries_with_pool": "passed",
                "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_create_index": "passed",
                "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_orm_execute": "passed",
                "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_lookup_entries": "passed",
                "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_caller_exits_when_lookup_entries": "passed",
                "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_in_thread_raise_exceptions_when_lookup_entries": "passed",
                "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_delete_entries": "passed",
                "tests/test_e2e/test_threadpool_orm.py::TestORMPoolShutdown::test_orm_pool_shutdown": "passed",
                "tests/test_utils.py::test_pragma_enable_helpers[enable_wal_mode-args0-kwargs0]": "passed",
                "tests/test_utils.py::test_pragma_enable_helpers[enable_wal_mode-args1-kwargs1]": "passed",
                "tests/test_utils.py::test_pragma_enable_helpers[enable_tmp_store_at_memory-args2-kwargs2]": "passed",
                "tests/test_utils.py::test_pragma_enable_helpers[enable_mmap-args3-kwargs3]": "passed",
                "tests/test_utils.py::test_pragma_enable_helpers[enable_mmap-args4-kwargs4]": "passed",
                "tests/test_utils.py::test_pragma_enable_helpers[optimize_db-args5-kwargs5]": "passed",
                "tests/test_utils.py::test_check_db_integrity": "passed",
                "tests/test_utils.py::test_lookup_table": "passed",
                "tests/test_utils.py::test_checkpragma_compile_time_options": "passed",
                "tests/test_utils.py::test_gen_check_constrain[Choice123-test_field IN (1,2,3)]": "passed",
                "tests/test_utils.py::test_gen_check_constrain[ChoiceABC-test_field IN (\"A\",\"B\",\"C\")]": "passed",
                "tests/test_utils.py::test_gen_check_constrain[Literal-test_field IN (123,456,789)]": "passed",
                "tests/test_utils.py::test_gen_check_constrain[Literal-test_field IN (\"H\",\"I\",\"J\")]": "passed",
                "tests/test_utils.py::test_gen_check_constrain[_in4-expected4]": "passed",
                "tests/test_utils.py::test_gen_check_constrain[NoneType-expected5]": "passed",
                "tests/test_utils.py::test_concatenate_condition[stmts0-True-(column IS NULL OR column IN (1,2,3))]": "passed",
                "tests/test_utils.py::test_concatenate_condition[stmts1-False-column IS NULL OR column IN (1,2,3)]": "passed",
                "tests/test_utils.py::test_wrap_value[123-123]": "passed",
                "tests/test_utils.py::test_wrap_value[123.456-123.456]": "passed",
                "tests/test_utils.py::test_wrap_value[a_string-\"a_string\"]": "passed",
                "tests/test_utils.py::test_wrap_value[None-NULL]": "passed",
                "tests/test_utils.py::test_wrap_value[\\x124Vx\\x90\\xaa\\xbb\\xcc-x'1234567890aabbcc']": "passed",
                "tests/test_utils.py::test_wrap_value[Choice123.ONE-1]": "passed",
                "tests/test_utils.py::test_wrap_value[A-\"A\"]": "passed",
                "tests/test_utils.py::test_gen_sql_stmt[components0-\\n-WHERE id = :check_id AND type <> 'A']": "passed",
                "tests/test_utils.py::test_gen_sql_stmt[components1-end_with1-SELECT count(*) FROM some_table;]": "passed"
            },
            "success_count": 128,
            "failed_count": 0,
            "error_count": 0,
            "skipped_count": 0,
            "unknown_count": 0,
            "total_count": 128,
            "success_rate": 1.0,
            "coverage_report": {
                "covered_lines": 979,
                "num_statements": 1080,
                "percent_covered": 86.65730337078652,
                "percent_covered_display": "87",
                "missing_lines": 101,
                "excluded_lines": 121,
                "num_branches": 344,
                "num_partial_branches": 71,
                "covered_branches": 255,
                "missing_branches": 89
            },
            "coverage_result": {}
        },
        "codelines_count": 5764,
        "codefiles_count": 26,
        "code_length": 203303,
        "test_files_count": 8,
        "test_code_length": 62333,
        "class_diagram": "@startuml\nclass TestTableSpecWithDB {\n    ENTRY_FOR_TEST: ENTRY_FOR_TEST\n    UPDATE_API_TEST_CASES: Unknown\n    db_conn(): void\n    prepare_test_entry(db_conn): void\n    test_insert_entry(case, to_insert, db_conn): void\n    test_insert_default_values(db_conn): void\n    test_lookup_entry(db_conn, prepare_test_entry): void\n    test_update_entry(db_conn, set_values, where_cols, update_stmt, expected_result, prepare_test_entry): void\n    test_deserialize_asdict_row_factory(db_conn, prepare_test_entry): void\n    test_deserialize_astuple_row_factory(db_conn, prepare_test_entry): void\n}\nclass DatetimeTestModel {\n    unix_timestamp: DatetimeUnixTimestamp\n    unix_timestamp_int: DatetimeUnixTimestampInt\n    datetime_iso8601: DatetimeISO8601\n}\nclass SimpleTableForTest {\n    id: Annotated[int, Unknown]\n    id_str: Annotated[str, Unknown]\n    extra: Optional[float]\n    int_str: Annotated[int, Unknown, Unknown, Unknown]\n}\nclass SimpleTableForTestCols {\n    id: int\n    id_str: str\n    extra: Optional[float]\n    int_str: int\n}\nclass SQLITE3_COMPILE_OPTION_FLAGS {\n}\nclass SimpleTableORM {\n    orm_bootstrap_table_name: TBL_NAME\n}\nclass TestORMBase {\n    orm_inst(): void\n    prepare_test_entry(orm_inst): void\n    test_create_index(orm_inst): void\n    test_insert_entries(orm_inst): void\n    test_orm_execute(row_factory, expected, where_cols, params, orm_inst, prepare_test_entry): void\n    test_orm_check_entry_exist(orm_inst, prepare_test_entry): void\n    test_select_entry(orm_inst, prepare_test_entry): void\n    test_insert_mapping(row_as_mapping, expected, orm_inst): void\n    test_insert_mappings(row_as_mappings, orm_inst): void\n    test_select_entries(orm_inst, prepare_test_entry): void\n    test_select_all_entries(orm_inst, prepare_test_entry): void\n    test_select_with_function_call(orm_inst, prepare_test_entry): void\n    test_update_entries(entry_to_insert, set_values, where_indicator, expected, orm_inst): void\n    test_update_entries_with_custom_stmt(entry_to_insert, set_values, where_stmt, params, expected, orm_inst): void\n    test_delete_entries(orm_inst, prepare_test_entry): void\n}\nclass TestORMUpdateEntriesMany {\n    _setup_orm(): void\n    _check_result(_setup_orm): void\n    test_with_where_cols(_setup_orm): void\n    test_with_custom_where_stmt_and_extra_params_iter(_setup_orm): void\n    test_with_custom_where_stmt_and_extra_params(_setup_orm): void\n    test_with_custom_stmt(_setup_orm): void\n}\nclass ChoiceABC {\n    A: Unknown\n    B: Unknown\n    C: Unknown\n}\nclass Choice123 {\n    ONE: Unknown\n    TWO: Unknown\n    THREE: Unknown\n}\nclass Mystr {\n    sha256hash(): bytes\n    magicf(): float\n    bool(): bool\n    __get_pydantic_core_schema__(cls, source, handler): core_schema.CoreSchema\n}\nclass SampleDB {\n    orm_bootstrap_table_name: TABLE_NAME\n}\nclass SampleDBAsyncio {\n    orm_bootstrap_table_name: TABLE_NAME\n}\nclass SampleDBConnectionPool {\n    orm_bootstrap_table_name: TABLE_NAME\n}\nclass SampleTableCols {\n    unix_timestamp: float\n    unix_timestamp_int: int\n    datetime_iso8601: str\n    choice_abc: ChoiceABC\n    optional_choice_123: Choice123\n    optional_num_literal: Optional[SomeIntLiteral]\n    str_literal: SomeStrLiteral\n    key_id: int\n    prim_key: Mystr\n    prim_key_sha256hash: bytes\n    prim_key_magicf: float\n    prim_key_bln: bool\n}\nclass SampleTable {\n    unix_timestamp: Annotated[DatetimeUnixTimestamp, Unknown]\n    unix_timestamp_int: Annotated[DatetimeUnixTimestampInt, Unknown]\n    datetime_iso8601: Annotated[DatetimeISO8601, Unknown]\n    choice_abc: Annotated[ChoiceABC, Unknown]\n    optional_choice_123: Annotated[Optional[Choice123], Unknown]\n    optional_num_literal: Annotated[Optional[SomeIntLiteral], Unknown, SkipValidation]\n    str_literal: Annotated[SomeStrLiteral, Unknown, SkipValidation]\n    key_id: Annotated[int, Unknown, SkipValidation]\n    prim_key: Annotated[Mystr, Unknown, SkipValidation]\n    prim_key_sha256hash: Annotated[bytes, Unknown, SkipValidation]\n    prim_key_magicf: float\n    prim_key_bln: bool\n    __hash__(): int\n    __eq__(value): bool\n}\nclass TestWithSampleDBWithAsyncIO {\n}\nclass TestWithSampleDB {\n    setup_test(setup_test_db_conn): void\n    test_create_table(): void\n    test_insert_entries(setup_test_data): void\n    test_create_index(): void\n    test_select_one_entry(setup_test_data, entry_to_lookup): void\n    test_orm_execute(setup_test_data): void\n    test_lookup_entries(entries_to_lookup): void\n    test_select_all_entries(setup_test_data): void\n    test_delete_entries(setup_test_data, entries_to_remove): void\n}\nclass TestWithSampleDBAndThreadPool {\n    thread_pool(setup_con_factory): void\n    test_create_table(thread_pool): void\n    test_insert_entries_with_pool(thread_pool, setup_test_data): void\n    test_create_index(thread_pool): void\n    test_orm_execute(thread_pool, setup_test_data): void\n    test_lookup_entries(thread_pool, entries_to_lookup): void\n    test_caller_exits_when_lookup_entries(thread_pool): void\n    test_in_thread_raise_exceptions_when_lookup_entries(thread_pool): void\n    test_delete_entries(thread_pool, entries_to_remove): void\n}\nclass TestORMPoolShutdown {\n    _orm_pool(tmp_path): void\n    _workload(_id, event): void\n    test_orm_pool_shutdown(_orm_pool): void\n}\nclass SQLiteStorageClass {\n    NULL: Unknown\n    INTEGER: Unknown\n    REAL: Unknown\n    TEXT: Unknown\n    BLOB: Unknown\n}\nclass SQLiteTypeAffinity {\n    TEXT: Unknown\n    NUMERIC: Unknown\n    INTEGER: Unknown\n    REAL: Unknown\n    BLOB: Unknown\n    NULL: Unknown\n}\nclass CreateTableParams {\n    if_not_exists: bool\n    strict: bool\n    temporary: bool\n    without_rowid: bool\n}\nclass CreateIndexParams {\n    index_name: str\n    index_cols: tuple[Unknown, Unknown]\n    if_not_exists: NotRequired[bool]\n    unique: NotRequired[bool]\n}\nclass TableSpec {\n    table_columns: ClassVar[MappingProxyType[str, FieldInfo]]\n    table_columns_by_index: ClassVar[tuple[str, Unknown]]\n    _table_update_where_cols_prefix: ClassVar[Literal[__table_spec_]]\n    __pydantic_init_subclass__(cls): Unknown\n    _generate_where_stmt(cls, where_cols, where_stmt): str\n    _generate_order_by_stmt(cls, order_by, order_by_stmt): str\n    _generate_returning_stmt(cls, returning_cols, returning_stmt): str\n    table_get_col_fieldinfo(cls, col): FieldInfo\n    table_check_cols(cls, cols): Unknown\n    table_dump_column(cls, column_name): str\n    table_create_stmt(cls, table_name): str\n    table_create_index_stmt(cls): str\n    table_row_factory(cls, _cursor, _row): Unknown\n    table_row_factory2(cls, _cursor, _row): Self\n    table_from_tuple(cls, _row): Self\n    table_from_dict(cls, _map): Self\n    table_insert_stmt(cls): str\n    table_update_stmt(cls): str\n    table_preprare_update_where_cols(cls, where_cols): Mapping[str, Any]\n    table_select_all_stmt(cls): str\n    table_select_stmt(cls): str\n    table_delete_stmt(cls): str\n    table_dump_asdict(): dict[str, Any]\n    table_asdict(): dict[str, Any]\n    table_dump_astuple(): tuple[Any, Unknown]\n    table_serialize_mapping(cls, _in): dict[str, Any]\n    table_serialize_mappings(cls, _iter): Generator[dict[str, Any]]\n    table_deserialize_asdict_row_factory(cls, _cursor, _row): dict[str, Any]\n    table_deserialize_astuple_row_factory(cls, _cursor, _row): tuple[Any, Unknown]\n}\nclass TypeAffinityRepr {\n    __init__(_in): Unknown\n    __str__(): str\n    __repr__(): str\n    __eq__(other): bool\n    __hash__(): int\n}\nclass ConstrainRepr {\n    __init__(): Unknown\n    __str__(): str\n    __repr__(): str\n    __eq__(other): bool\n    __hash__(): int\n}\nclass ColsSelectFactory {\n    __new__(cls): tuple[T, Unknown]\n}\nclass ORMThreadPoolBase {\n    __class_getitem__: classmethod\n    orm_bootstrap_db: _wrap_with_thread_ctx\n    orm_execute: _wrap_with_thread_ctx\n    orm_execute_gen: _wrap_generator_with_thread_ctx\n    orm_executemany: _wrap_with_thread_ctx\n    orm_executescript: _wrap_with_thread_ctx\n    orm_create_table: _wrap_with_thread_ctx\n    orm_create_index: _wrap_with_thread_ctx\n    orm_select_entries: _wrap_generator_with_thread_ctx\n    orm_select_entry: _wrap_with_thread_ctx\n    orm_insert_entries: _wrap_with_thread_ctx\n    orm_insert_mappings: _wrap_with_thread_ctx\n    orm_insert_mapping: _wrap_with_thread_ctx\n    orm_insert_entry: _wrap_with_thread_ctx\n    orm_update_entries: _wrap_with_thread_ctx\n    orm_update_entries_many: _wrap_with_thread_ctx\n    orm_delete_entries: _wrap_with_thread_ctx\n    orm_delete_entries_with_returning: _wrap_generator_with_thread_ctx\n    orm_select_all_with_pagination: _wrap_generator_with_thread_ctx\n    orm_check_entry_exist: _wrap_with_thread_ctx\n    __init__(table_name, schema_name): Unknown\n    __enter__(): Self\n    __exit__(exec_type, exc_val, exc_tb): void\n    _thread_initializer(con_factory, row_factory): Unknown\n    _thread_scope_orm(): ORMBase[TableSpecType]\n    _caller_gen(_queue, _caller_exit): Generator[RT]\n    orm_table_name(): str\n    _worker_shutdown(shutdown_barrier, shutdown_lock): void\n    orm_pool_shutdown(): Unknown\n}\nclass AsyncORMBase {\n    _loop: asyncio.AbstractEventLoop\n    orm_bootstrap_db: _wrap_with_async_ctx\n    orm_execute: _wrap_with_async_ctx\n    orm_execute_gen: _wrap_generator_with_async_ctx\n    orm_executemany: _wrap_with_async_ctx\n    orm_executescript: _wrap_with_async_ctx\n    orm_create_table: _wrap_with_async_ctx\n    orm_create_index: _wrap_with_async_ctx\n    orm_select_entries: _wrap_generator_with_async_ctx\n    orm_select_entry: _wrap_with_async_ctx\n    orm_insert_entries: _wrap_with_async_ctx\n    orm_insert_mappings: _wrap_with_async_ctx\n    orm_insert_mapping: _wrap_with_async_ctx\n    orm_insert_entry: _wrap_with_async_ctx\n    orm_update_entries: _wrap_with_async_ctx\n    orm_update_entries_many: _wrap_with_async_ctx\n    orm_delete_entries: _wrap_with_async_ctx\n    orm_delete_entries_with_returning: _wrap_generator_with_async_ctx\n    orm_select_all_with_pagination: _wrap_generator_with_async_ctx\n    orm_check_entry_exist: _wrap_with_async_ctx\n}\nclass ORMCommonBase {\n    orm_table_spec: type[TableSpecType]\n    orm_bootstrap_table_name: str\n    orm_bootstrap_create_table_params: Unknown\n    orm_bootstrap_indexes_params: list[Unknown]\n    __init_subclass__(cls): Unknown\n}\nclass ORMBase {\n    __class_getitem__: classmethod\n    orm_bootstrap_db(): Unknown\n    __init__(con, table_name, schema_name): Unknown\n    __enter__(): Self\n    __exit__(exec_type, exc_val, exc_tb): void\n    orm_con(): sqlite3.Connection\n    orm_table_name(): str\n    orm_conn_row_factory(): Unknown\n    orm_conn_row_factory(_row_factory): Unknown\n    orm_execute(sql_stmt, params): list[RT]\n    orm_execute(sql_stmt, params): list[TableSpecType]\n    orm_execute(sql_stmt, params): list[tuple[Any, Unknown]]\n    orm_execute(sql_stmt, params): list[Any]\n    orm_execute_gen(sql_stmt, params): Generator[RT]\n    orm_execute_gen(sql_stmt, params): Generator[TableSpecType]\n    orm_execute_gen(sql_stmt, params): Generator[tuple[Any, Unknown]]\n    orm_execute_gen(sql_stmt, params): Generator[Any]\n    orm_executemany(sql_stmt, params): int\n    orm_executescript(sql_script): int\n    orm_create_table(): Unknown\n    orm_create_index(): Unknown\n    orm_select_entries(col_value_pairs): Generator[RT]\n    orm_select_entries(col_value_pairs): Generator[Unknown]\n    orm_select_entries(col_value_pairs): Generator[Unknown]\n    orm_select_entry(col_value_pairs): RT\n    orm_select_entry(col_value_pairs): Unknown\n    orm_select_entry(col_value_pairs): Unknown\n    orm_insert_entries(_in): int\n    orm_insert_mappings(_in): int\n    orm_insert_entry(_in): int\n    orm_insert_mapping(_in): int\n    orm_update_entries(): int\n    orm_update_entries_many(): int\n    orm_update_entries_many(): int\n    orm_update_entries_many(): int\n    orm_delete_entries(col_value_pairs): int\n    orm_delete_entries_with_returning(col_value_pairs): Generator[RT]\n    orm_delete_entries_with_returning(col_value_pairs): Generator[Unknown]\n    orm_delete_entries_with_returning(col_value_pairs): Generator[Unknown]\n    orm_select_all_with_pagination(): Generator[Unknown]\n    orm_check_entry_exist(col_value_pairs): bool\n}\nTestTableSpecWithDB --> SimpleTableForTestCols\nTestORMUpdateEntriesMany --> SimpleTableORM\nSampleTableCols --> Choice123\nSampleTableCols --> ChoiceABC\nTestORMBase --> SimpleTableORM\nTestTableSpecWithDB --> SimpleTableForTest\nTestWithSampleDB --> SampleDB\nTableSpec <|-- SimpleTableForTest\nTestWithSampleDB --> SampleTable\nTestORMPoolShutdown --> SampleDBConnectionPool\nTableSpec --> TypeAffinityRepr\nTableSpec <|-- SampleTable\nTestWithSampleDBAndThreadPool --> SampleDBConnectionPool\nSampleTableCols --> Mystr\nSampleTableCols ..> Choice123\nTestORMUpdateEntriesMany ..> SimpleTableORM\nTestORMBase ..> SimpleTableORM\nTestORMPoolShutdown ..> SampleDBConnectionPool\nSampleTableCols ..> ChoiceABC\nTestWithSampleDB ..> SampleTable\nTestWithSampleDB ..> SampleDB\nTestTableSpecWithDB ..> SimpleTableForTest\nSampleTableCols ..> Mystr\nTestTableSpecWithDB ..> SimpleTableForTestCols\nTestWithSampleDBAndThreadPool ..> SampleDBConnectionPool\nTableSpec ..> TypeAffinityRepr\n@enduml",
        "structure": [
            {
                "file": "tests/test__table_spec.py",
                "functions": [
                    {
                        "name": "test_table_create",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "table_create_params"
                        ]
                    },
                    {
                        "name": "test_table_from_tuple",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "_in",
                            "_validate",
                            "_expected"
                        ]
                    },
                    {
                        "name": "test_table_from_dict",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "_in",
                            "_validate",
                            "_expected"
                        ]
                    },
                    {
                        "name": "test_table_dump_asdict",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "_in",
                            "_expected"
                        ]
                    },
                    {
                        "name": "test_table_dump_astuple",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "_in",
                            "_cols",
                            "_expected"
                        ]
                    },
                    {
                        "name": "test_serializing_mapping",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "_in",
                            "_expected"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "TestTableSpecWithDB",
                        "docstring": "A quick and simple test to test through normal usage of tablespec.\n\nNOTE that this test is mostly focusing on syntax, i.e., to ensure that the generated\n    sqlite3 query can be parsed and accepted by sqlite3 DB engine.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "db_conn",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "prepare_test_entry",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "db_conn"
                                ]
                            },
                            {
                                "name": "test_insert_entry",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "case",
                                    "to_insert",
                                    "db_conn"
                                ]
                            },
                            {
                                "name": "test_insert_default_values",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "db_conn"
                                ]
                            },
                            {
                                "name": "test_lookup_entry",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "db_conn",
                                    "prepare_test_entry"
                                ]
                            },
                            {
                                "name": "test_update_entry",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "db_conn",
                                    "set_values",
                                    "where_cols",
                                    "update_stmt",
                                    "expected_result",
                                    "prepare_test_entry"
                                ]
                            },
                            {
                                "name": "test_deserialize_asdict_row_factory",
                                "docstring": null,
                                "comments": "------ end of UPDATE sqlite3 stmt test ------ #",
                                "args": [
                                    "self",
                                    "db_conn",
                                    "prepare_test_entry"
                                ]
                            },
                            {
                                "name": "test_deserialize_astuple_row_factory",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "db_conn",
                                    "prepare_test_entry"
                                ]
                            }
                        ],
                        "attributes": [
                            "ENTRY_FOR_TEST",
                            "UPDATE_API_TEST_CASES"
                        ]
                    }
                ]
            },
            {
                "file": "tests/test__types.py",
                "functions": [
                    {
                        "name": "test_datetime_helper",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "_in",
                            "expected"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "DatetimeTestModel",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/conftest.py",
                "functions": [
                    {
                        "name": "setup_test_db_conn",
                        "docstring": "Setup a single db connection for a test class.",
                        "comments": null,
                        "args": [
                            "tmp_path_factory"
                        ]
                    },
                    {
                        "name": "db_conn_func_scope",
                        "docstring": "Setup a single db connection for a test class.",
                        "comments": null,
                        "args": [
                            "tmp_path"
                        ]
                    },
                    {
                        "name": "setup_con_factory",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "tmp_path_factory"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "SimpleTableForTest",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "SimpleTableForTestCols",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "SQLITE3_COMPILE_OPTION_FLAGS",
                        "docstring": null,
                        "comments": "sqlite3 lib features set",
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/test__orm.py",
                "functions": [
                    {
                        "name": "enable_debug_logging",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "caplog"
                        ]
                    },
                    {
                        "name": "test_create_table",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "opts"
                        ]
                    },
                    {
                        "name": "test_bootstrap",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "table_name",
                            "create_table_params",
                            "create_indexes_params",
                            "setup_test_db_conn"
                        ]
                    },
                    {
                        "name": "_dummy_row_factory",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "_cur",
                            "_row"
                        ]
                    },
                    {
                        "name": "_compare_callable",
                        "docstring": "Especially handling the",
                        "comments": null,
                        "args": [
                            "left_func",
                            "right_func"
                        ]
                    },
                    {
                        "name": "test_row_factory_specifying",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "_row_factory_specifier",
                            "_expected_row_factory",
                            "db_conn_func_scope"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "SimpleTableORM",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "orm_bootstrap_table_name"
                        ]
                    },
                    {
                        "name": "TestORMBase",
                        "docstring": "A quick test for testing functionality of ORM base.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "orm_inst",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "prepare_test_entry",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "orm_inst"
                                ]
                            },
                            {
                                "name": "test_create_index",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "orm_inst"
                                ]
                            },
                            {
                                "name": "test_insert_entries",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "orm_inst"
                                ]
                            },
                            {
                                "name": "test_orm_execute",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "row_factory",
                                    "expected",
                                    "where_cols",
                                    "params",
                                    "orm_inst",
                                    "prepare_test_entry"
                                ]
                            },
                            {
                                "name": "test_orm_check_entry_exist",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "orm_inst",
                                    "prepare_test_entry"
                                ]
                            },
                            {
                                "name": "test_select_entry",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "orm_inst",
                                    "prepare_test_entry"
                                ]
                            },
                            {
                                "name": "test_insert_mapping",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "row_as_mapping",
                                    "expected",
                                    "orm_inst"
                                ]
                            },
                            {
                                "name": "test_insert_mappings",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "row_as_mappings",
                                    "orm_inst"
                                ]
                            },
                            {
                                "name": "test_select_entries",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "orm_inst",
                                    "prepare_test_entry"
                                ]
                            },
                            {
                                "name": "test_select_all_entries",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "orm_inst",
                                    "prepare_test_entry"
                                ]
                            },
                            {
                                "name": "test_select_with_function_call",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "orm_inst",
                                    "prepare_test_entry"
                                ]
                            },
                            {
                                "name": "test_update_entries",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "entry_to_insert",
                                    "set_values",
                                    "where_indicator",
                                    "expected",
                                    "orm_inst"
                                ]
                            },
                            {
                                "name": "test_update_entries_with_custom_stmt",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "entry_to_insert",
                                    "set_values",
                                    "where_stmt",
                                    "params",
                                    "expected",
                                    "orm_inst"
                                ]
                            },
                            {
                                "name": "test_delete_entries",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "orm_inst",
                                    "prepare_test_entry"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TestORMUpdateEntriesMany",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "_setup_orm",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "_check_result",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "_setup_orm"
                                ]
                            },
                            {
                                "name": "test_with_where_cols",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "_setup_orm"
                                ]
                            },
                            {
                                "name": "test_with_custom_where_stmt_and_extra_params_iter",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "_setup_orm"
                                ]
                            },
                            {
                                "name": "test_with_custom_where_stmt_and_extra_params",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "_setup_orm"
                                ]
                            },
                            {
                                "name": "test_with_custom_stmt",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "_setup_orm"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "_ORM",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "orm_bootstrap_table_name"
                        ]
                    }
                ]
            },
            {
                "file": "tests/test__utils.py",
                "functions": [
                    {
                        "name": "test_typeafinityrepr",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "_in",
                            "expected"
                        ]
                    },
                    {
                        "name": "test_constrainrepr",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "_in",
                            "expected"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_utils.py",
                "functions": [
                    {
                        "name": "test_pragma_enable_helpers",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "func",
                            "args",
                            "kwargs"
                        ]
                    },
                    {
                        "name": "test_check_db_integrity",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_lookup_table",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_checkpragma_compile_time_options",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "test_gen_check_constrain",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "_in",
                            "expected"
                        ]
                    },
                    {
                        "name": "test_concatenate_condition",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "stmts",
                            "with_parenthese",
                            "expected"
                        ]
                    },
                    {
                        "name": "test_wrap_value",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "value",
                            "expected"
                        ]
                    },
                    {
                        "name": "test_gen_sql_stmt",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "components",
                            "end_with",
                            "expected"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/sample_db/_types.py",
                "functions": [],
                "classes": [
                    {
                        "name": "ChoiceABC",
                        "docstring": "A choice includes 'A', 'B' and 'C'.",
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "A",
                            "B",
                            "C"
                        ]
                    },
                    {
                        "name": "Choice123",
                        "docstring": "A choice includes 1, 2 and 3.",
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "ONE",
                            "TWO",
                            "THREE"
                        ]
                    },
                    {
                        "name": "Mystr",
                        "docstring": "Custom str type that wraps built-in str.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "sha256hash",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "magicf",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "bool",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__get_pydantic_core_schema__",
                                "docstring": "Let pydantci validate Mystr as normal str.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "source",
                                    "handler"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/sample_db/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "tests/sample_db/orm.py",
                "functions": [],
                "classes": [
                    {
                        "name": "SampleDB",
                        "docstring": "ORM for SampleTable.",
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "orm_bootstrap_table_name"
                        ]
                    },
                    {
                        "name": "SampleDBAsyncio",
                        "docstring": "Test connection pool with async API.",
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "orm_bootstrap_table_name"
                        ]
                    },
                    {
                        "name": "SampleDBConnectionPool",
                        "docstring": "Test connection pool.",
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "orm_bootstrap_table_name"
                        ]
                    }
                ]
            },
            {
                "file": "tests/sample_db/table.py",
                "functions": [],
                "classes": [
                    {
                        "name": "SampleTableCols",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "SampleTable",
                        "docstring": "This sample table contains as much different types of fields as possible.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__hash__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__eq__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "value"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/test_e2e/test_async_orm.py",
                "functions": [],
                "classes": [
                    {
                        "name": "TestWithSampleDBWithAsyncIO",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "_StopAt",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "_StopAt",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/test_e2e/conftest.py",
                "functions": [
                    {
                        "name": "_generate_random_str",
                        "docstring": "Generate a random string with <_len> characters.\nNOTE: this is NOT safe for generating a password!",
                        "comments": null,
                        "args": [
                            "_len"
                        ]
                    },
                    {
                        "name": "generate_test_data",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "num_of_entry"
                        ]
                    },
                    {
                        "name": "setup_test_data",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "entries_to_lookup",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "setup_test_data"
                        ]
                    },
                    {
                        "name": "entries_to_remove",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "setup_test_data"
                        ]
                    },
                    {
                        "name": "entry_to_lookup",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "setup_test_data"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "tests/test_e2e/test_orm.py",
                "functions": [],
                "classes": [
                    {
                        "name": "TestWithSampleDB",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "setup_test",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "setup_test_db_conn"
                                ]
                            },
                            {
                                "name": "test_create_table",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_insert_entries",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "setup_test_data"
                                ]
                            },
                            {
                                "name": "test_create_index",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "test_select_one_entry",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "setup_test_data",
                                    "entry_to_lookup"
                                ]
                            },
                            {
                                "name": "test_orm_execute",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "setup_test_data"
                                ]
                            },
                            {
                                "name": "test_lookup_entries",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "entries_to_lookup"
                                ]
                            },
                            {
                                "name": "test_select_all_entries",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "setup_test_data"
                                ]
                            },
                            {
                                "name": "test_delete_entries",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "setup_test_data",
                                    "entries_to_remove"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "tests/test_e2e/test_threadpool_orm.py",
                "functions": [],
                "classes": [
                    {
                        "name": "TestWithSampleDBAndThreadPool",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "thread_pool",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "setup_con_factory"
                                ]
                            },
                            {
                                "name": "test_create_table",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "thread_pool"
                                ]
                            },
                            {
                                "name": "test_insert_entries_with_pool",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "thread_pool",
                                    "setup_test_data"
                                ]
                            },
                            {
                                "name": "test_create_index",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "thread_pool"
                                ]
                            },
                            {
                                "name": "test_orm_execute",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "thread_pool",
                                    "setup_test_data"
                                ]
                            },
                            {
                                "name": "test_lookup_entries",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "thread_pool",
                                    "entries_to_lookup"
                                ]
                            },
                            {
                                "name": "test_caller_exits_when_lookup_entries",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "thread_pool"
                                ]
                            },
                            {
                                "name": "test_in_thread_raise_exceptions_when_lookup_entries",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "thread_pool"
                                ]
                            },
                            {
                                "name": "test_delete_entries",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "thread_pool",
                                    "entries_to_remove"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "TestORMPoolShutdown",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "_orm_pool",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "tmp_path"
                                ]
                            },
                            {
                                "name": "_workload",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "_id",
                                    "event"
                                ]
                            },
                            {
                                "name": "test_orm_pool_shutdown",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "_orm_pool"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "_StopAt",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "_StopAt",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "src/simple_sqlite3_orm/_types.py",
                "functions": [
                    {
                        "name": "_datetime_validator",
                        "docstring": "A pydantic validator helper for parsing serialized datetime from database.",
                        "comments": "\n------ datetime related ------ #\n",
                        "args": [
                            "_in"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "src/simple_sqlite3_orm/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "src/simple_sqlite3_orm/utils.py",
                "functions": [
                    {
                        "name": "enable_wal_mode",
                        "docstring": "Enable WAL mode for the connected database.\n\nNote that for multiple databases being attached, WAL mode only guarantees\n    atomic within each individual database file. See https://www.sqlite.org/lang_attach.html\n    for more details.\n\nArgs:\n    con (sqlite3.Connection): The connection to the target database.\n    relax_sync_mode (bool): Also set the synchronous mode to NORMAL. Default to True.\n\nRaises:\n    sqlite3.DatabaseError on failed sql execution.",
                        "comments": "\n------ performance tuning ------ #\n\nref: https://developer.android.com/topic/performance/sqlite-performance-best-practices\nhttps://www.sqlite.org/pragma.html",
                        "args": [
                            "con",
                            "relax_sync_mode"
                        ]
                    },
                    {
                        "name": "enable_tmp_store_at_memory",
                        "docstring": "Locate the temp tables at memory.\n\nSee https://www.sqlite.org/pragma.html#pragma_temp_store for more details.\n\nArgs:\n    con (sqlite3.Connection): The connection to the target database.\n\nRaises:\n    sqlite3.DatabaseError on failed sql execution.",
                        "comments": null,
                        "args": [
                            "con"
                        ]
                    },
                    {
                        "name": "enable_mmap",
                        "docstring": "Enable mmap for the connection.\n\nSee https://www.sqlite.org/pragma.html#pragma_mmap_size for more\n\nArgs:\n    con (sqlite3.Connection): The connection to the target database.\n    mmap_size (int, optional): The max mmap size. Defaults to <DEFAULT_MMAP_SIZE=16MiB>.\n\nRaises:\n    sqlite3.DatabaseError on failed sql execution.",
                        "comments": null,
                        "args": [
                            "con",
                            "mmap_size"
                        ]
                    },
                    {
                        "name": "optimize_db",
                        "docstring": "Execute optimize PRAGMA on the target database.\n\nSee https://www.sqlite.org/pragma.html#pragma_optimize.\n\nArgs:\n    con (sqlite3.Connection): The connection to the target database.\n\nRaises:\n    sqlite3.DatabaseError on failed sql execution.",
                        "comments": null,
                        "args": [
                            "con"
                        ]
                    },
                    {
                        "name": "check_db_integrity",
                        "docstring": "Execute integrity_check PRAGMA on the target database(or specific table at the database).\n\nSee https://www.sqlite.org/pragma.html#pragma_integrity_check for more details.\n\nArgs:\n    con (sqlite3.Connection): The connection to the target database.\n    table_name (str | None, optional): If specified, the integrity_check will only be performed\n        against this table. Defaults to None, means performing the check on the whole database.\n\nReturns:\n    bool: True for integrity_check passed on the target database, False for errors found.",
                        "comments": "\n------ General DB operation ------ #\n",
                        "args": [
                            "con",
                            "table_name"
                        ]
                    },
                    {
                        "name": "lookup_table",
                        "docstring": "Check if specific table existed on the target database.\n\nArgs:\n    con (sqlite3.Connection): The connection to the target database.\n    table_name (str): The name of table to lookup.\n\nReturns:\n    bool: True for table existed, False for not found.",
                        "comments": null,
                        "args": [
                            "con",
                            "table_name"
                        ]
                    },
                    {
                        "name": "attach_database",
                        "docstring": "Attach another database onto the current connection.\n\nSee https://www.sqlite.org/lang_attach.html for more details.\n\nArgs:\n    con (sqlite3.Connection): The current database connection.\n    database (str | Literal[\":memory:\"]): The new database to be attached.\n    schema_name (str): The alias name of the newly connected database for distinguishing\n        between the already connected database in this connection.\n\nReturns:\n    str: The schema_name of the newly connected database in the connection.",
                        "comments": null,
                        "args": [
                            "con",
                            "database",
                            "schema_name"
                        ]
                    },
                    {
                        "name": "check_pragma_compile_time_options",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "con",
                            "option_name"
                        ]
                    },
                    {
                        "name": "check_pragma_compile_time_options",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "con",
                            "option_name"
                        ]
                    },
                    {
                        "name": "check_pragma_compile_time_options",
                        "docstring": "Get the runtime sqlite3 library's compile time options.\n\nArgs:\n    con (sqlite3.Connection): The current database connection.\n    option_name (str | None, optional): The option to lookup. If not specified,\n        it will return all the options and its values. Defaults to None.\n\nReturns:\n    tuple[str, Any] | None | list[tuple[str, Any]]: Looked up options and its values.",
                        "comments": null,
                        "args": [
                            "con",
                            "option_name"
                        ]
                    },
                    {
                        "name": "gen_check_constrain",
                        "docstring": "Generate the constrain statement for CHECK keyword.\n\nSupports the following types:\n1. StrEnum or IntEnum types: will generate statement like:\n    <field_name> IN (<enum_value_1>[, <enum_value_2>[, ...]])\n2. Literal types: similar to StrEnum and IntEnum.\n\nArgs:\n    enum_type (type[Enum]): The enum type to generate CHECK statement against.\n    field_name (str): The field name of this enum_type in use.\n\nRaises:\n    TypeError on unsupported enum_type.\n\nReturns:\n    str: the generated statement can be used with CHECK keyword like the following:\n       <enum_value_1>[, <enum_value_2>[, ...]]",
                        "comments": null,
                        "args": [
                            "_in",
                            "field_name"
                        ]
                    },
                    {
                        "name": "concatenate_condition",
                        "docstring": "Chain a list of conditions and operators together in a string.\n\nFor example, for the following statement for CHECK keyword:\n    (column IS NULL OR column IN (1, 2, 3))\nwe can use concatenate_condition like:\n    concatenate_condition(\n        \"column IS NULL\", \"OR\", \"column IN (1, 2, 3)\",\n        wrapped_with_parentheses=True,\n    )",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "wrap_value",
                        "docstring": "Wrap value for use in sql statement.\n\nNOTE that for most cases, you should use python sqlite3 lib's\n    placeholder feature to bind value in the sql statement.\n\nFor int and float, the value will be used as it.\nFor str, the value will be wrapped with parenthesis.\nFor bytes, the value will be converted as x'<bytes_in_hex>'.",
                        "comments": null,
                        "args": [
                            "value"
                        ]
                    },
                    {
                        "name": "gen_sql_script",
                        "docstring": "Combine multiple sql statements into a sql script.",
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "sort_and_replace",
                        "docstring": "Sort the table, and then replace the old table with the sorted one.",
                        "comments": "\n------ advanced helper tools ------ #\n",
                        "args": [
                            "_orm",
                            "table_name"
                        ]
                    }
                ],
                "classes": []
            },
            {
                "file": "src/simple_sqlite3_orm/_sqlite_spec.py",
                "functions": [],
                "classes": [
                    {
                        "name": "SQLiteStorageClass",
                        "docstring": null,
                        "comments": "\n------ sqlite3 datatypes ------ #\n\nref: https://www.sqlite.org/datatype3.html",
                        "methods": [],
                        "attributes": [
                            "NULL",
                            "INTEGER",
                            "REAL",
                            "TEXT",
                            "BLOB"
                        ]
                    },
                    {
                        "name": "SQLiteTypeAffinity",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "TEXT",
                            "NUMERIC",
                            "INTEGER",
                            "REAL",
                            "BLOB",
                            "NULL"
                        ]
                    }
                ]
            },
            {
                "file": "src/simple_sqlite3_orm/_table_spec.py",
                "functions": [],
                "classes": [
                    {
                        "name": "CreateTableParams",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "CreateIndexParams",
                        "docstring": null,
                        "comments": null,
                        "methods": [],
                        "attributes": []
                    },
                    {
                        "name": "TableSpec",
                        "docstring": "Define table as pydantic model, with specific APIs.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__pydantic_init_subclass__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "cls"
                                ]
                            },
                            {
                                "name": "_generate_where_stmt",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "cls",
                                    "where_cols",
                                    "where_stmt"
                                ]
                            },
                            {
                                "name": "_generate_order_by_stmt",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "cls",
                                    "order_by",
                                    "order_by_stmt"
                                ]
                            },
                            {
                                "name": "_generate_returning_stmt",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "cls",
                                    "returning_cols",
                                    "returning_stmt"
                                ]
                            },
                            {
                                "name": "table_get_col_fieldinfo",
                                "docstring": "Check whether the <col> exists and returns the pydantic FieldInfo.\n\nRaises:\n    ValueError on non-existed col.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "col"
                                ]
                            },
                            {
                                "name": "table_check_cols",
                                "docstring": "Ensure all cols in <cols> existed in the table definition.\n\nRaises:\n    ValueError if any of col doesn't exist in the table.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "cols"
                                ]
                            },
                            {
                                "name": "table_dump_column",
                                "docstring": "Dump the column statement for table creation.\n\nRaises:\n    ValueError on col doesn't exist or invalid col definition.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "column_name"
                                ]
                            },
                            {
                                "name": "table_create_stmt",
                                "docstring": "Get create table statement with this table spec class.\n\nCheck https://www.sqlite.org/lang_createtable.html for more details.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "table_name"
                                ]
                            },
                            {
                                "name": "table_create_index_stmt",
                                "docstring": "Get index create statement with this table spec class.\n\nRaises:\n    ValueError on <index_cols> not specified, or invalid <index_cols>.\n\nCheck https://www.sqlite.org/lang_createindex.html for more details.",
                                "comments": null,
                                "args": [
                                    "cls"
                                ]
                            },
                            {
                                "name": "table_row_factory",
                                "docstring": "A general row_factory implement for used in sqlite3 connection.\n\nWhen the input <_row> is not a row but something like function output,\n    this method will return the raw input tuple as it.\n\nArgs:\n    validation (bool): whether enable pydantic validation when importing row. Default to True.\n\nRaises:\n    Any exception raised from pydantic model_validate or model_construct.\n\nReturns:\n    An instance of <TableSpec>, or the raw tuple if the input row has different schema.\n\nAlso see https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.description\n    for more details.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "_cursor",
                                    "_row"
                                ]
                            },
                            {
                                "name": "table_row_factory2",
                                "docstring": "Another version of row_factory implementation for specific use case.\n\nUnlike table_row_factory that checks the cols definition and ensure all cols\n    are valid and presented in table def, table_row_factory2 just picks the valid\n    cols from the input raw table row, and ignore unknown col/value pairs.\n\nArgs:\n    validation (bool): whether enable pydantic validation when importing row. Default to True.\n\nRaises:\n    Any exception raised from pydantic model_validate or model_construct.\n\nReturns:\n    An instance of <TableSpec>.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "_cursor",
                                    "_row"
                                ]
                            },
                            {
                                "name": "table_from_tuple",
                                "docstring": "A raw row_factory that converts the input _row to TableSpec instance.\n\nNOTE that this method expects the input row match the table row spec EXACTLY.\n\nArgs:\n    _row (tuple[Any, ...]): the raw table row as tuple.\n    with_validation (bool): if set to False, will use pydantic model_construct to directly\n        construct instance without validation. Default to True.\n    **kwargs: extra kwargs passed to pydantic model_validate API. Note that only when\n        with_validation is True, the kwargs will be used.\n\nReturns:\n    An instance of self.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "_row"
                                ]
                            },
                            {
                                "name": "table_from_dict",
                                "docstring": "A raw row_factory that converts the input mapping to TableSpec instance.\n\nArgs:\n    _map (Mapping[str, Any]): the raw table row as a dict.\n    with_validation (bool, optional): if set to False, will use pydantic model_construct to directly\n        construct instance without validation. Default to True.\n    **kwargs: extra kwargs passed to pydantic model_validate API. Note that only when\n        with_validation is True, the kwargs will be used.\n\nReturns:\n    An instance of self.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "_map"
                                ]
                            },
                            {
                                "name": "table_insert_stmt",
                                "docstring": "Get sql for inserting row(s) into <table_name>.\n\nCheck https://www.sqlite.org/lang_insert.html for more details.\n\nArgs:\n    insert_into (str): The name of table insert into.\n    insert_cols (tuple[str, ...] | None, optional): The cols to be assigned for entry to be inserted.\n        Defaults to None, means we will assign all cols of the row.\n    insert_default (bool, optional): No values will be assigned, all cols will be assigned with\n        default value, this precedes the <insert_cols> param. Defaults to False.\n    or_option (INSERT_OR | None, optional): The fallback operation if insert failed. Defaults to None.\n    returning_cols (tuple[str, ...] | Literal[\"*\"] | None): Which cols are included in the returned entries.\n        Defaults to None.\n    returning_stmt (str | None, optional): The full returning statement string, this\n        precedes the <returning_cols> param. Defaults to None.\n\nReturns:\n    str: The generated insert statement.",
                                "comments": null,
                                "args": [
                                    "cls"
                                ]
                            },
                            {
                                "name": "table_update_stmt",
                                "docstring": "Get sql query for updating row(s) at <table_name>.\n\nCheck https://www.sqlite.org/lang_update.html for more details.\n\nNOTE: to avoid overlapping between <set_cols> and <where_cols> when generating named-placeholders,\n    this method will prefix cols name with <_table_spec_update_where_cols_prefix> when generating\n    WHERE statement.\n    To directly use the stmt generated from this API, dev must use table_preprare_update_where_cols\n    to prepare the col/value mapping for params.\n\nNOTE that UPDATE-FROM extension is currently not supported by this method.\nNOTE that UPDATE-WITH-LIMIT is an optional feature, needs to be enabled at compiled time with\n    SQLITE_ENABLE_UPDATE_DELETE_LIMIT.\n\nArgs:\n    or_option (INSERT_OR | None, optional): The fallback operation if update failed. Defaults to None.\n    update_target (str): The name of table to update.\n    set_cols (tuple[str, ...]): The cols to be updated.\n    where_cols (tuple[str, ...] | None, optional): A list of cols to be compared in where\n        statement. Defaults to None.\n    where_stmt (str | None, optional): The full where statement string, this\n        precedes the <where_cols> param if set. Defaults to None.\n    returning_cols (tuple[str, ...] | Literal[\"*\"] | None): If specified, enable RETURNING stmt, and specifying Which cols\n        included in the returned entries. Defaults to None.\n    returning_stmt (str | None, optional): The full returning statement string, this\n        precedes the <returning_cols> param. Defaults to None.\n    order_by (Iterable[str  |  tuple[str, ORDER_DIRECTION], ...] | None, optional):\n        Works with LIMIT, to specify the range that LIMIT affects. Defaults to None.\n    order_by_stmt (str | None, optional): The order_by statement string, this\n        precedes the <order_by> param if set. Defaults to None.\n    limit (int | None, optional): Limit the number of affected entries. Defaults to None.\n\nReturns:\n    str: The generated update sqlite3 query.",
                                "comments": null,
                                "args": [
                                    "cls"
                                ]
                            },
                            {
                                "name": "table_preprare_update_where_cols",
                                "docstring": "Regulate the named-placeholder <where_cols> so that it will not overlap with <set_cols>.\n\nThis is MUST for directly using the sqlite query stmt generated from table_update_stmt.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "where_cols"
                                ]
                            },
                            {
                                "name": "table_select_all_stmt",
                                "docstring": "Select all entries, optionally with pagination LIMIT and OFFSET.\n\nCheck https://www.sqlite.org/lang_select.html for more details.\n\nArgs:\n    select_from (str): The table name for the generated statement.\n    batch_idx (int | None, optional): If specified, the batch index of current page. Defaults to None.\n    batch_size (int | None, optional): If specified, the batch size of each page. Defaults to None.\n    order_by (tuple[str | tuple[str, ORDER_DIRECTION], ...] | None, optional):\n        A list of cols for ordering result. Defaults to None.\n    order_by_stmt (str | None, optional): The order_by statement string, this\n        precedes the <order_by> param if set. Defaults to None.\n    distinct (bool, optional): Whether filters the duplicated entries. Defaults to False.\n\nRaises:\n    ValueError: If batch_idx or bach_size are not both None or not None, or the values are invalid.\n\nReturns:\n    str: The generated select statement.",
                                "comments": null,
                                "args": [
                                    "cls"
                                ]
                            },
                            {
                                "name": "table_select_stmt",
                                "docstring": "Get sql for getting row(s) from <table_name>, optionally with\n    where condition specified by <col_values>.\n\nCheck https://www.sqlite.org/lang_select.html for more details.\n\nArgs:\n    select_from (str): The table name for the generated statement.\n    select_cols (tuple[str, ...] | Literal[\"*\"] | str, optional): A list of cols included in the result row. Defaults to \"*\".\n    function (SQLiteBuiltInFuncs | None, optional): The sqlite3 function used in the selection. Defaults to None.\n    where_cols (tuple[str, ...] | None, optional): A list of cols to be compared in where\n        statement. Defaults to None.\n    where_stmt (str | None, optional): The full where statement string, this\n        precedes the <where_cols> param if set. Defaults to None.\n    group_by (tuple[str, ...] | None, optional): A list of cols for group_by statement. Defaults to None.\n    order_by (Iterable[str  |  tuple[str, ORDER_DIRECTION], ...] | None, optional):\n        A list of cols for ordering result. Defaults to None.\n    order_by_stmt (str | None, optional): The order_by statement string, this\n        precedes the <order_by> param if set. Defaults to None.\n    limit (int | None, optional): Limit the number of result entries. Defaults to None.\n    distinct (bool, optional): Whether filters the duplicated entries. Defaults to False.\n\nReturns:\n    str: The generated select statement.",
                                "comments": null,
                                "args": [
                                    "cls"
                                ]
                            },
                            {
                                "name": "table_delete_stmt",
                                "docstring": "Get sql for deleting row(s) from <table_name> with specifying col value(s).\n\nCheck https://www.sqlite.org/lang_delete.html for more details.\n\nNOTE(20240311): DELETE operation without any condition(no WHERE statement) in\n    WITHOUT_ROWID table will result in rowcount=0, see\n    https://sqlite.org/forum/forumpost/07dedbf9a1 for more details.\n    For python, python version < 3.10 will be affected by this bug.\n    A quick workaround is to add any condition in where statement, even a dummy\n    \"WHERE 1=1\" can resolve the above bug.\n    I will not add this hack here, and user can add this hack according to their needs.\n\nNOTE: <order_by> and <limit> support are only enabled when runtime sqlite3 lib is compiled with\n    SQLITE_ENABLE_UPDATE_DELETE_LIMIT flag.\n\nArgs:\n    delete_from (str): The table name for the generated statement.\n    limit (int | str | None, optional): The value for limit expr. Defaults to None.\n    order_by (Iterable[str  |  tuple[str, ORDER_DIRECTION]] | None, optional):\n        A list of cols for ordering result. Defaults to None.\n    order_by_stmt (str | None, optional): The order_by statement string, this\n        precedes the <order_by> param if set. Defaults to None.\n    where_cols (tuple[str, ...] | None, optional): A list of cols to be compared in where\n        statement. Defaults to None.\n    where_stmt (str | None, optional): The full where statement string, this\n        precedes the <where_cols> param if set. Defaults to None.\n    returning_cols (tuple[str, ...] | Literal[\"*\"] | None): Which cols are included in the returned entries.\n        Defaults to None.\n    returning_stmt (str | None, optional): The full returning statement string, this\n        precedes the <returning_cols> param. Defaults to None.\n\nReturns:\n    str: The generated delete statement.",
                                "comments": null,
                                "args": [
                                    "cls"
                                ]
                            },
                            {
                                "name": "table_dump_asdict",
                                "docstring": "Serialize self as a dict, containing all cols or specified cols, for DB operations.\n\nUnder the hook this method calls pydantic model_dump on self.\nThe dumped dict can be used to directly insert into the table.\n\nArgs:\n    *cols: which cols to export, if not specified, export all cols.\n    **kwargs: any other kwargs that passed to pydantic model_dump method.\n        Note that the include kwarg is used to specific which cols to dump.\n\nRaises:\n    ValueError if failed to serialize the model, wrapping underlying\n        pydantic serialization error.\n\nReturns:\n    A dict of dumped col values from this row.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "table_asdict",
                                "docstring": "Directly export the self as a dict, without serializing.\n\nArgs:\n    *cols: which cols to export, if not specified, export all cols.\n    exclude_unset (bool, optional): whether include not set field of self.\n        Defaults to False, include unset fields(which will return their default values).\n\nReturns:\n    A dict of col/values from self.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "table_dump_astuple",
                                "docstring": "Serialize self's value as a tuple, containing all cols or specified cols, for DB operations.\n\nThis method is basically the same as table_dump_asdict, but instead return a\n    tuple of the dumped values.\n\nArgs:\n    *cols: which cols to export, if not specified, export all cols.\n    **kwargs: any other kwargs that passed to pydantic model_dump method.\n        Note that the include kwarg is used to specific which cols to dump.\n\nReturns:\n    A tuple of dumped col values.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "table_serialize_mapping",
                                "docstring": "Serialize input mapping into a dict by this TableSpec, ready for DB operations.\n\nValues in the input mapping are python types used in application.\n\nThis is a convenient method for when we only need to specify some of the cols, so that\n    we cannot use TableSpec as TableSpec requires all cols to be set.\n\nNOTE that for APIs provided by simple_sqlite3_orm, when col/value pairs are provided as mapping,\n    the serialization will be done by the APIs, no need to call this method when using ORM.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "_in"
                                ]
                            },
                            {
                                "name": "table_serialize_mappings",
                                "docstring": "Convert an iter of Mappings into an generator of serialized dict.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "_iter"
                                ]
                            },
                            {
                                "name": "table_deserialize_asdict_row_factory",
                                "docstring": "Deserialize raw row from a query into a dict by this TableSpec, ready for application use.\n\nThis is a convenient method when we execute query that only select some cols.\nFor this use case, use thid method as row_factory to deserialize the raw row. This method\n    will deserialize the row from raw into actual field types defined in this TableSpec.\n\nNOTE that if `allow_unknow_cols` is True, any unknown field(including cols aliased with other name)\n    will be preserved AS IT without deserializing as this method cannot know which col the alias name maps to.\n\nArgs:\n    allow_unknown_cols (bool, optional): If True, unknown cols will be preserved AS IT into the result.\n        Defaults to True.\n\nRaises:\n    ValueError if `allow_unknown_cols` is False and unknown cols presented, or pydantic validation failed.\n\nReturns:\n    A dict of deserialized(except unknown cols) col/value pairs.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "_cursor",
                                    "_row"
                                ]
                            },
                            {
                                "name": "table_deserialize_astuple_row_factory",
                                "docstring": "Deserialize raw row from a query into a tuple by this TableSpec, ready for application use.\n\nThis is a convenient method when we execute query that only select some cols.\nFor this use case, use thid method as row_factory to deserialize the raw row. This method\n    will deserialize the row from raw into actual field types defined in this TableSpec.\n\nNOTE that any unknown field(including cols aliased with other name) will be preserved AS IT without\n    deserializing as this method cannot know which col the alias name maps to.\n\nRaises:\n    ValueError if pydantic validation failed.\n\nReturns:\n    A tuple of deserialized row as tuple.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "_cursor",
                                    "_row"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "src/simple_sqlite3_orm/_utils.py",
                "functions": [
                    {
                        "name": "map_type",
                        "docstring": "Mapping python types to corresponding sqlite storage classes.\n\nCurrently this function suports the following input:\n1. sqlite3 native types(and wrapped in Optional).\n2. Literal types.\n3. Enum types with str or int as data type.\n4. user defined affinity string, will be used as it.",
                        "comments": null,
                        "args": [
                            "_in"
                        ]
                    },
                    {
                        "name": "_map_from_literal",
                        "docstring": "Support for literal of supported datatypes.",
                        "comments": null,
                        "args": [
                            "_in"
                        ]
                    },
                    {
                        "name": "_map_from_type",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "_in"
                        ]
                    },
                    {
                        "name": "gen_sql_stmt",
                        "docstring": "Combine each components into a single sql stmt.",
                        "comments": null,
                        "args": []
                    }
                ],
                "classes": [
                    {
                        "name": "TypeAffinityRepr",
                        "docstring": "Map python types to sqlite3 data types with type affinity.\n\nCurrently supports:\n1. python sqlite3 lib supported native python types.\n2. StrEnum and IntEnum, will map to TEXT and INT accordingly.\n3. Optional types, will map against the args inside the Optional.\n4. Literal types, will map against the values type inside the Literal.\n\nAttrs:\n    type_affinity (SQLiteTypeAffinity | str)\n    origin (type[Any] | SQLiteTypeAffinityLiteral | Any)",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "_in"
                                ]
                            },
                            {
                                "name": "__str__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__repr__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__eq__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "__hash__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "ConstrainRepr",
                        "docstring": "Helper class for composing full constrain statement string.\n\nFor example, for constrain statement like the following:\n    NOT NULL DEFAULT NULL CHECK (column IN (1, 2, 3))\ncan be represented ConstrainRepr as follow:\n    ConstrainRepr(\n        \"NOT NULL\",\n        (\"DEFAULT\", \"NULL\"),\n        (\"CHECK\", r\"(column IN (1, 2, 3))\")\n    )\n\nAttrs:\n    constraints (set[str | tuple[str, str]]): a set of constrains.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__str__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__repr__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__eq__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "other"
                                ]
                            },
                            {
                                "name": "__hash__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "ColsSelectFactory",
                        "docstring": "A factory type to generate cols name checker.\n\nUsage:\n\n```python\nMyTableCols = Literal[\"entry_id\", \"entry_context\", \"entry_type\"]\nMyTableColsChecker = ColsCheckerFactory[MyTableCols]\n\n# now you can use `MyTableColsChecker` to specify a tuple of cols name as follow:\ncols_to_select = MyTableColsChecker(\"unknown\", \"invalid_col\")  # type checker err\ncols_to_select = MyTableColsChecker(\"entry_id\", \"entry_type\")  # valid\n\n# at runtime, `cols_to_select` is a regular `tuple` object.\n```",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__new__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "cls"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "GenericAlias",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "__new__",
                                "docstring": "For type check only, typing the _GenericAlias as GenericAlias.",
                                "comments": null,
                                "args": [
                                    "cls",
                                    "_type",
                                    "_params"
                                ]
                            }
                        ],
                        "attributes": []
                    }
                ]
            },
            {
                "file": "src/simple_sqlite3_orm/_typing.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "src/simple_sqlite3_orm/_orm/_pool.py",
                "functions": [
                    {
                        "name": "_python_exit",
                        "docstring": null,
                        "comments": null,
                        "args": []
                    },
                    {
                        "name": "_wrap_with_thread_ctx",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "func"
                        ]
                    },
                    {
                        "name": "_wrap_with_async_ctx",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "func"
                        ]
                    },
                    {
                        "name": "_wrap_generator_with_thread_ctx",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "func"
                        ]
                    },
                    {
                        "name": "_wrap_generator_with_async_ctx",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "func"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "ORMThreadPoolBase",
                        "docstring": "See https://www.sqlite.org/wal.html#concurrency for more details.\n\nFor the row_factory arg, please see ORMBase.__init__ for more details.",
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "table_name",
                                    "schema_name"
                                ]
                            },
                            {
                                "name": "__enter__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__exit__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "exec_type",
                                    "exc_val",
                                    "exc_tb"
                                ]
                            },
                            {
                                "name": "_thread_initializer",
                                "docstring": "Prepare thread_scope ORMBase instance for this worker thread.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "con_factory",
                                    "row_factory"
                                ]
                            },
                            {
                                "name": "_thread_scope_orm",
                                "docstring": "Get thread scope ORMBase instance.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "_caller_gen",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "_queue",
                                    "_caller_exit"
                                ]
                            },
                            {
                                "name": "orm_table_name",
                                "docstring": "The unique name of the table for use in sql statement.\n\nIf multiple databases are attached to <con> and <schema_name> is availabe,\n    return \"<schema_name>.<table_name>\", otherwise return <table_name>.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "_worker_shutdown",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "shutdown_barrier",
                                    "shutdown_lock"
                                ]
                            },
                            {
                                "name": "orm_pool_shutdown",
                                "docstring": "Shutdown the ORM connections thread pool.\n\nIt is safe to call this method multiple time.\nThis method is NOT thread-safe, and should be called at the main thread,\n    or the thread that creates this thread pool.\n\nArgs:\n    wait (bool, optional): Wait for threads join. Defaults to True.\n    close_connections (bool, optional): Close all the connections. Defaults to True.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            }
                        ],
                        "attributes": [
                            "__class_getitem__",
                            "orm_bootstrap_db",
                            "orm_execute",
                            "orm_execute_gen",
                            "orm_executemany",
                            "orm_executescript",
                            "orm_create_table",
                            "orm_create_index",
                            "orm_select_entries",
                            "orm_select_entry",
                            "orm_insert_entries",
                            "orm_insert_mappings",
                            "orm_insert_mapping",
                            "orm_insert_entry",
                            "orm_update_entries",
                            "orm_update_entries_many",
                            "orm_delete_entries",
                            "orm_delete_entries_with_returning",
                            "orm_select_all_with_pagination",
                            "orm_check_entry_exist"
                        ]
                    },
                    {
                        "name": "AsyncORMBase",
                        "docstring": "NOTE: the supoprt for async ORM is experimental! The APIs might be changed a lot\n    in the following releases.\n\nFor the row_factory arg, please see ORMBase.__init__ for more details.",
                        "comments": null,
                        "methods": [],
                        "attributes": [
                            "orm_bootstrap_db",
                            "orm_execute",
                            "orm_execute_gen",
                            "orm_executemany",
                            "orm_executescript",
                            "orm_create_table",
                            "orm_create_index",
                            "orm_select_entries",
                            "orm_select_entry",
                            "orm_insert_entries",
                            "orm_insert_mappings",
                            "orm_insert_mapping",
                            "orm_insert_entry",
                            "orm_update_entries",
                            "orm_update_entries_many",
                            "orm_delete_entries",
                            "orm_delete_entries_with_returning",
                            "orm_select_all_with_pagination",
                            "orm_check_entry_exist"
                        ]
                    }
                ]
            },
            {
                "file": "src/simple_sqlite3_orm/_orm/__init__.py",
                "functions": [],
                "classes": []
            },
            {
                "file": "src/simple_sqlite3_orm/_orm/_base.py",
                "functions": [
                    {
                        "name": "_select_row_factory",
                        "docstring": "Helper function to get row_factory by row_factory_specifier.",
                        "comments": null,
                        "args": [
                            "table_spec",
                            "row_factory_specifier"
                        ]
                    },
                    {
                        "name": "_merge_iters",
                        "docstring": "Merge two iterables of Mappings into one iterable of dict.",
                        "comments": null,
                        "args": [
                            "_left",
                            "_right"
                        ]
                    }
                ],
                "classes": [
                    {
                        "name": "ORMCommonBase",
                        "docstring": null,
                        "comments": null,
                        "methods": [
                            {
                                "name": "__init_subclass__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "cls"
                                ]
                            }
                        ],
                        "attributes": []
                    },
                    {
                        "name": "ORMBase",
                        "docstring": "ORM layer for <TableSpecType>.\n\nNOTE that instance of ORMBase cannot be used in multi-threaded environment.\n    Use ORMThreadPoolBase for multi-threaded environment.\n    For asyncio, use AsyncORMThreadPoolBase.\n\nThe underlying connection can be used in multiple connection for accessing different table in\n    the connected database.\n\nAttributes:\n    con (sqlite3.Connection | ConnectionFactoryType): The sqlite3 connection used by this ORM, or a factory\n        function that returns a sqlite3.Connection object on calling.\n    table_name (str): The name of the table in the database <con> connected to. This field will take prior over the\n        table_name specified by orm_bootstrap_table_name attr to allow using different table_name for just one connection.\n    schema_name (str): The schema of the table if multiple databases are attached to <con>.\n    row_factory (RowFactorySpecifier): The connection scope row_factory to use. Default to \"table_sepc\".",
                        "comments": null,
                        "methods": [
                            {
                                "name": "orm_bootstrap_db",
                                "docstring": "Bootstrap the database this ORM connected to.\n\nThis method will refer to the following attrs to setup table and indexes:\n1. orm_bootstrap_table_name: the name of table to be created.\n2. orm_bootstrap_create_table_params: the sqlite query to create the table,\n    it can be provided as sqlite query, or CreateTableParams for table_create_stmt\n    to generate sqlite query from.\n    It not specified, the table create statement will be generated with default configs,\n    See table_spec.table_create_stmt method for more details.\n3. orm_bootstrap_indexes_params: optional, a list of sqlite query or\n    CreateIndexParams(for table_create_index_stmt to generate sqlite query from) to\n    create indexes from.\n\nNOTE that ORM will not know whether the connected database has already been\n    bootstrapped or not, this is up to caller to check.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__init__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "con",
                                    "table_name",
                                    "schema_name"
                                ]
                            },
                            {
                                "name": "__enter__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "__exit__",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "exec_type",
                                    "exc_val",
                                    "exc_tb"
                                ]
                            },
                            {
                                "name": "orm_con",
                                "docstring": "A reference to the underlying sqlite3.Connection.\n\nThis is for directly executing sql stmts.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "orm_table_name",
                                "docstring": "The unique name of the table for use in sql statement.\n\nIf multiple databases are attached to <con> and <schema_name> is availabe,\n    return \"<schema_name>.<table_name>\", otherwise return <table_name>.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "orm_conn_row_factory",
                                "docstring": "Get and set the connection scope row_factory for this ORM instance.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "orm_conn_row_factory",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "_row_factory"
                                ]
                            },
                            {
                                "name": "orm_execute",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "sql_stmt",
                                    "params"
                                ]
                            },
                            {
                                "name": "orm_execute",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "sql_stmt",
                                    "params"
                                ]
                            },
                            {
                                "name": "orm_execute",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "sql_stmt",
                                    "params"
                                ]
                            },
                            {
                                "name": "orm_execute",
                                "docstring": "Execute one sql statement and get the all the result.\n\nNOTE that caller needs to serialize the `params` before hands if needed, `orm_execute` will\n    not do any processing over the input `params`, and just use as it for execution.\nThe result will be fetched with fetchall API and returned as it.\n\nArgs:\n    sql_stmt (str): The sqlite statement to be executed.\n    params (tuple[Any, ...] | dict[str, Any] | None, optional): The parameters to be bound\n        to the sql statement execution. Defaults to None, not passing any params.\n    row_factory (RowFactorySpecifier | DoNotChangeRowFactory, optional): specify to use\n        different row_factory for the query. Default to not change the current row_factory.\n        NOTE that None value here means unset the row_factory for this query.\n\nReturns:\n    list[Any]: A list contains all the result entries.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "sql_stmt",
                                    "params"
                                ]
                            },
                            {
                                "name": "orm_execute_gen",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "sql_stmt",
                                    "params"
                                ]
                            },
                            {
                                "name": "orm_execute_gen",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "sql_stmt",
                                    "params"
                                ]
                            },
                            {
                                "name": "orm_execute_gen",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "sql_stmt",
                                    "params"
                                ]
                            },
                            {
                                "name": "orm_execute_gen",
                                "docstring": "The same as orm_execute, but as a Generator.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "sql_stmt",
                                    "params"
                                ]
                            },
                            {
                                "name": "orm_executemany",
                                "docstring": "Repeatedly execute the parameterized DML SQL statement sql.\n\nNOTE that any returning values will be discarded, including with RETURNING stmt.\n\nArgs:\n    sql_stmt (str): The sqlite statement to be executed.\n    params (Iterable[tuple[Any, ...] | dict[str, Any]]): The set of parameters to be bound\n        to the sql statement execution.\n\nReturns:\n    The affected row count.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "sql_stmt",
                                    "params"
                                ]
                            },
                            {
                                "name": "orm_executescript",
                                "docstring": "Execute one sql script.\n\nNOTE that any returning values will be discarded, including with RETURNING stmt.\n\nArgs:\n    sql_script (str): The sqlite script to be executed.\n\nReturns:\n    The affected row count.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "sql_script"
                                ]
                            },
                            {
                                "name": "orm_create_table",
                                "docstring": "Create the table defined by this ORM with <orm_table_spec>.\n\nNOTE: strict table option is supported after sqlite3 3.37.\n\nArgs:\n    allow_existed (bool, optional): Do not abort on table already created.\n        Set True equals to add \"IF NOT EXISTS\" in the sql statement. Defaults to False.\n    strict (bool, optional): Enable strict field type check. Defaults to False.\n        See https://www.sqlite.org/stricttables.html for more details.\n    without_rowid (bool, optional): Create the table without ROWID. Defaults to False.\n        See https://www.sqlite.org/withoutrowid.html for more details.\n    _stmt (str, optional): If provided, all params will be ignored and query statement will not\n        be generated with the params, instead the provided <_stmt> will be used as query statement.\n\nRaises:\n    sqlite3.DatabaseError on failed sql execution.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "orm_create_index",
                                "docstring": "Create index according to the input arguments.\n\nArgs:\n    index_name (str): The name of the index.\n    index_keys (ColsDefinition | ColsDefinitionWithDirection): The columns for the index.\n    allow_existed (bool, optional): Not abort on index already created. Defaults to False.\n    unique (bool, optional): Not allow duplicated entries in the index. Defaults to False.\n    _stmt (str, optional): If provided, all params will be ignored and query statement will not\n        be generated with the params, instead the provided <_stmt> will be used as query statement.\n\nRaises:\n    sqlite3.DatabaseError on failed sql execution.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "orm_select_entries",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "col_value_pairs"
                                ]
                            },
                            {
                                "name": "orm_select_entries",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "col_value_pairs"
                                ]
                            },
                            {
                                "name": "orm_select_entries",
                                "docstring": "Select entries from the table accordingly.\n\nArgs:\n    col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n        the pairs in this mapping will take prior than the one specified in <col_values>.\n    _distinct (bool, optional): Deduplicate and only return unique entries. Defaults to False.\n    _order_by (ColsDefinition | ColsDefinitionWithDirection | None, optional):\n        Order the result accordingly. Defaults to None, not sorting the result.\n    _limit (int | None, optional): Limit the number of result entries. Defaults to None.\n    _row_factory (RowFactoryType | None, optional): Set to use different row factory for this query.\n        Defaults to None(do not change row_factory).\n    _stmt (str, optional): If provided, all params will be ignored and query statement will not\n        be generated with the params, instead the provided <_stmt> will be used as query statement.\n    **col_values: provide col/value pairs by kwargs. Col/value pairs in <col_values> have lower priority over\n        the one specified by <_col_vlues_dict>.\n\nRaises:\n    sqlite3.DatabaseError on failed sql execution.\n\nYields:\n    Generator[TableSpecType | Any]: A generator that can be used to yield entry from result.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "col_value_pairs"
                                ]
                            },
                            {
                                "name": "orm_select_entry",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "col_value_pairs"
                                ]
                            },
                            {
                                "name": "orm_select_entry",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "col_value_pairs"
                                ]
                            },
                            {
                                "name": "orm_select_entry",
                                "docstring": "Select exactly one entry from the table accordingly.\n\nNOTE that if the select result contains more than one entry, this method will return\n    the FIRST one from the result with fetchone API.\n\nArgs:\n    col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n        the pairs in this mapping will take prior than the one specified in <col_values>.\n    _distinct (bool, optional): Deduplicate and only return unique entries. Defaults to False.\n    _order_by (ColsDefinition | ColsDefinitionWithDirection | None, optional):\n        Order the result accordingly. Defaults to None, not sorting the result.\n    _row_factory (RowFactoryType | None, optional): Set to use different row factory for this query.\n        Defaults to None(do not change row_factory).\n    _stmt (str, optional): If provided, all params will be ignored and query statement will not\n        be generated with the params, instead the provided <_stmt> will be used as query statement.\n    **col_values: provide col/value pairs by kwargs. Col/value pairs in <col_values> have lower priority over\n        the one specified by <_col_vlues_dict>.\n\nRaises:\n    sqlite3.DatabaseError on failed sql execution.\n\nReturns:\n    TableSpecType | Any: Exactly one entry, or None if not hit.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "col_value_pairs"
                                ]
                            },
                            {
                                "name": "orm_insert_entries",
                                "docstring": "Insert an iterable of rows represented as TableSpec insts into this table.\n\nArgs:\n    _in (Iterable[TableSpecType]): An iterable of rows as TableSpec insts to insert.\n    or_option (INSERT_OR | None, optional): The fallback operation if insert failed. Defaults to None.\n    _stmt (str, optional): If provided, all params will be ignored and query statement will not\n        be generated with the params, instead the provided <_stmt> will be used as query statement.\n\nRaises:\n    ValueError: On invalid types of _in.\n    sqlite3.DatabaseError: On failed sql execution.\n\nReturns:\n    int: Number of inserted entries.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "_in"
                                ]
                            },
                            {
                                "name": "orm_insert_mappings",
                                "docstring": "Insert an iterable of rows represented as mappings into this table.\n\nEach mapping stores cols with values in application types. Assuming that all entries in\n    this Iterable contains mapping with the same schema.\n\nArgs:\n    _in (Iterable[Mapping[str, Any]]): An iterable of mappings to insert.\n    or_option (INSERT_OR | None, optional): The fallback operation if insert failed. Defaults to None.\n    _stmt (str, optional): If provided, all params will be ignored and query statement will not\n        be generated with the params, instead the provided <_stmt> will be used as query statement.\n\nRaises:\n    ValueError: On invalid types of _in.\n    sqlite3.DatabaseError: On failed sql execution.\n\nReturns:\n    int: Number of inserted entries.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "_in"
                                ]
                            },
                            {
                                "name": "orm_insert_entry",
                                "docstring": "Insert exactly one entry into this table.\n\nArgs:\n    _in (TableSpecType): The instance of entry to insert.\n    _stmt (str, optional): If provided, all params will be ignored and query statement will not\n        be generated with the params, instead the provided <_stmt> will be used as query statement.\n\nRaises:\n    ValueError: On invalid types of _in.\n    sqlite3.DatabaseError: On failed sql execution.\n\nReturns:\n    int: Number of inserted entries. In normal case it should be 1.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "_in"
                                ]
                            },
                            {
                                "name": "orm_insert_mapping",
                                "docstring": "Insert exactly one entry(represented as a mapping) into this table.\n\nArgs:\n    _in (TableSpecType): The instance of entry to insert.\n    _stmt (str, optional): If provided, all params will be ignored and query statement will not\n        be generated with the params, instead the provided <_stmt> will be used as query statement.\n\nRaises:\n    ValueError: On invalid types of _in.\n    sqlite3.DatabaseError: On failed sql execution.\n\nReturns:\n    int: Number of inserted entries. In normal case it should be 1.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "_in"
                                ]
                            },
                            {
                                "name": "orm_update_entries",
                                "docstring": "UPDATE specific entries by matching <where_cols_value>.\n\nNOTE: if you want to using the same query stmt with different set of params(set col/values and/or where col/values),\n    it is highly recommended to use `orm_update_entries_many` API, it will be significantly faster to call `orm_update_entries`\n    in a for loop(in my test with 2000 entries, using `orm_update_entries_many` is around 300 times faster).\nNOTE: currently UPDATE-WITH-LIMIT and RETURNING are not supported by this method.\n\nArgs:\n    set_values (Mapping[str, Any] | TableSpec): values to update.\n    where_cols_value (Mapping[str, Any], optional): cols to matching. This method will\n        also generate WHERE statement of matching each cols specified in this mapping.\n    where_stmt (str | None, optional): directly provide WHERE statement. If provided,\n        <where_cols_value> will only be used as params.\n    or_option (OR_OPTIONS | None, optional): specify the operation if UPDATE failed.\n    _extra_params (Mapping[str, Any] | None, optional): provide extra named params\n        for sqlite3 query execution. NOTE that `_extra_params` takes higher priority\n        to any named params specified by `where_cols_value` and `set_values`. Defaults to None.\n    _stmt (str | None, optional): directly provide the UPDATE query, if provided,\n        <where_cols_value>, <where_stmt> and <or_option> will be ignored.\n\nRaises:\n    SQLite3 DB Errors on failed operations.\n\nReturns:\n    Affected rows count.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "orm_update_entries_many",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "orm_update_entries_many",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "orm_update_entries_many",
                                "docstring": "executemany version of orm_update_entries.\n\nParams like `set_cols_value` and `where_cols_value` need to be provided as iterables.\nNOTE that the execution will end and return when any of the input iterable exhausted.\n\nNOTE that `_extra_params` and `_extra_params_iter` will not be serialized. Caller needs to\n    provide the serialized mappings ready for `executemany`.\n\nArgs:\n    set_cols (tuple[str, ...]): Cols to be updated.\n    set_cols_value (Iterable[Mapping[str, Any]]): An iterable of values of to-be-updated cols.\n    where_cols (tuple[str, ...] | None, optional): Cols to match. The WHERE stmt will be generated\n        based on this param. Defaults to None.\n    where_cols_value (Iterable[Mapping[str, Any]] | None, optional): An iterable of values of cols to match.\n        Defaults to None.\n    where_stmt (str | None, optional): Directly provide the WHERE stmt. If specified, both `where_cols` and\n        `where_cols_value` will be ignored. Caller needs to feed the params with `_extra_params` or `_extra_params_iter`.\n        Defaults to None.\n    or_option (OR_OPTIONS | None, optional): specify the operation if UPDATE failed. Defaults to None.\n    _extra_params (Mapping[str, Any] | None, optional): A fixed mapping to be injected for each execution.\n        NOTE that this param is only allowed when at least one of `where_cols_value`, `set_cols_value` or `_extra_params_iter` is specified.\n        Defaults to None.\n    _extra_params_iter (Iterable[Mapping[str, Any]] | None, optional): An iterable of mappings to be injected for each execution. Defaults to None.\n    _stmt (str | None, optional): Directly provide the UPDATE query, if specified, params except `_extra_params` and `_extra_params_iter`\n        will be ignored. Defaults to None.\n\nRaises:\n    ValueError: If `where_cols_value` and `where_cols` are not be both None or both specifed.\n    ValueError: If `_stmt` is not used and `set_cols` and/or `set_cols_value` are not specified.\n    ValueError: If `_extra_params` is specified without any other iterable params provided.\n    sqlite3 DB error on execution failed.\n\nReturns:\n    Affected rows count.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "orm_delete_entries",
                                "docstring": "Delete entries from the table accordingly.\n\nArgs:\n    col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n        the pairs in this mapping will take prior than the one specified in <col_values>.\n    _order_by (ColsDefinition | ColsDefinitionWithDirection | None, optional): Order the matching entries\n        before executing the deletion, used together with <_limit>. Defaults to None.\n    _limit (int | None, optional): Only delete <_limit> number of entries. Defaults to None.\n    _stmt (str, optional): If provided, all params will be ignored and query statement will not\n        be generated with the params, instead the provided <_stmt> will be used as query statement.\n    **col_values: provide col/value pairs by kwargs. Col/value pairs in <col_values> have lower priority over\n        the one specified by <_col_vlues_dict>.\n\nReturns:\n    int: The num of entries deleted.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "col_value_pairs"
                                ]
                            },
                            {
                                "name": "orm_delete_entries_with_returning",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "col_value_pairs"
                                ]
                            },
                            {
                                "name": "orm_delete_entries_with_returning",
                                "docstring": null,
                                "comments": null,
                                "args": [
                                    "self",
                                    "col_value_pairs"
                                ]
                            },
                            {
                                "name": "orm_delete_entries_with_returning",
                                "docstring": "Delete entries from the table accordingly.\n\nNOTE that only sqlite3 version >= 3.35 supports returning statement.\n\nArgs:\n    col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n        the pairs in this mapping will take prior than the one specified in <col_values>.\n    _order_by (ColsDefinition | ColsDefinitionWithDirection | None, optional): Order the matching entries\n        before executing the deletion, used together with <_limit>. Defaults to None.\n    _limit (int | None, optional): Only delete <_limit> number of entries. Defaults to None.\n    _returning_cols (ColsDefinition | Literal[\"*\"] ): Return the deleted entries on execution.\n    _row_factory (RowFactoryType | None, optional): Set to use different row factory for this query.\n        Defaults to None(do not change row_factory).\n    _stmt (str, optional): If provided, all params will be ignored and query statement will not\n        be generated with the params, instead the provided <_stmt> will be used as query statement.\n    **col_values: provide col/value pairs by kwargs. Col/value pairs in <col_values> have lower priority over\n        the one specified by <_col_vlues_dict>.\n\nReturns:\n    Generator[TableSpecType | Any]: If <_returning_cols> is defined, returns a generator which can\n        be used to yield the deleted entries from.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "col_value_pairs"
                                ]
                            },
                            {
                                "name": "orm_select_all_with_pagination",
                                "docstring": "Select all entries from the table accordingly with pagination.\n\nThis is implemented by seek with rowid, so it will not work on without_rowid table.\n\nArgs:\n    batch_size (int): The entry number for each page.\n\nRaises:\n    ValueError on invalid batch_size.\n    sqlite3.DatabaseError on failed sql execution.\n\nYields:\n    Generator[TableSpecType, None, None]: A generator that can be used to yield entry from result.",
                                "comments": null,
                                "args": [
                                    "self"
                                ]
                            },
                            {
                                "name": "orm_check_entry_exist",
                                "docstring": "A quick method to check whether entry(entries) indicated by cols exists.\n\nThis method uses COUNT function to count the selected entry.\n\nArgs:\n    col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n        the pairs in this mapping will take prior than the one specified in <col_values>.\n    **cols: cols pair to locate the entry(entries).\n\nReturns:\n    Returns True if at least one entry matches the input cols exists, otherwise False.",
                                "comments": null,
                                "args": [
                                    "self",
                                    "col_value_pairs"
                                ]
                            }
                        ],
                        "attributes": [
                            "__class_getitem__"
                        ]
                    }
                ]
            },
            {
                "file": "src/simple_sqlite3_orm/_orm/_utils.py",
                "functions": [
                    {
                        "name": "parameterized_class_getitem",
                        "docstring": null,
                        "comments": null,
                        "args": [
                            "cls",
                            "params"
                        ]
                    }
                ],
                "classes": []
            }
        ],
        "test_cases": {
            "tests/test__orm.py::TestORMBase::test_create_index": {
                "testid": "tests/test__orm.py::TestORMBase::test_create_index",
                "result": "passed",
                "test_implementation": "    def test_create_index(self, orm_inst: SimpleTableORM):\n        orm_inst.orm_create_index(\n            index_name=\"id_str_index\",\n            index_keys=SimpleTableForTestColsSelect(\"id_str\"),\n            allow_existed=True,\n            unique=True,\n        )\n\n        with pytest.raises(sqlite3.DatabaseError):\n            orm_inst.orm_create_index(\n                index_name=\"id_str_index\",\n                index_keys=SimpleTableForTestColsSelect(\"id_str\"),\n                allow_existed=False,\n            )"
            },
            "tests/test__orm.py::TestORMBase::test_insert_entries": {
                "testid": "tests/test__orm.py::TestORMBase::test_insert_entries",
                "result": "passed",
                "test_implementation": "    def test_insert_entries(self, orm_inst: SimpleTableORM):\n        orm_inst.orm_insert_entries((ENTRY_FOR_TEST,))\n\n        with pytest.raises(sqlite3.DatabaseError):\n            orm_inst.orm_insert_entry(ENTRY_FOR_TEST, or_option=\"fail\")\n        orm_inst.orm_insert_entry(ENTRY_FOR_TEST, or_option=\"ignore\")\n        orm_inst.orm_insert_entry(ENTRY_FOR_TEST, or_option=\"replace\")"
            },
            "tests/test__orm.py::TestORMBase::test_orm_execute[None-expected0-where_cols0-params0]": {
                "testid": "tests/test__orm.py::TestORMBase::test_orm_execute[None-expected0-where_cols0-params0]",
                "result": "passed",
                "test_implementation": "    def test_orm_execute(\n        self,\n        row_factory,\n        expected,\n        where_cols,\n        params,\n        orm_inst: SimpleTableORM,\n        prepare_test_entry,\n    ):\n        sql_stmt = orm_inst.orm_table_spec.table_select_stmt(\n            select_from=orm_inst.orm_table_name,\n            select_cols=\"count(*) AS count, int_str\",\n            where_cols=where_cols,\n        )\n\n        res = orm_inst.orm_execute(sql_stmt, params, row_factory=row_factory)\n        # NOTE: no row_factory specified, int_str here is not deserialized\n        assert res and res[0] == expected\n        res_gen = orm_inst.orm_execute_gen(sql_stmt, params, row_factory=row_factory)\n        assert next(res_gen) == expected"
            },
            "tests/test__orm.py::TestORMBase::test_orm_execute[table_deserialize_asdict_row_factory-expected1-None-None]": {
                "testid": "tests/test__orm.py::TestORMBase::test_orm_execute[table_deserialize_asdict_row_factory-expected1-None-None]",
                "result": "passed",
                "test_implementation": "    def test_orm_execute(\n        self,\n        row_factory,\n        expected,\n        where_cols,\n        params,\n        orm_inst: SimpleTableORM,\n        prepare_test_entry,\n    ):\n        sql_stmt = orm_inst.orm_table_spec.table_select_stmt(\n            select_from=orm_inst.orm_table_name,\n            select_cols=\"count(*) AS count, int_str\",\n            where_cols=where_cols,\n        )\n\n        res = orm_inst.orm_execute(sql_stmt, params, row_factory=row_factory)\n        # NOTE: no row_factory specified, int_str here is not deserialized\n        assert res and res[0] == expected\n        res_gen = orm_inst.orm_execute_gen(sql_stmt, params, row_factory=row_factory)\n        assert next(res_gen) == expected"
            },
            "tests/test__orm.py::TestORMBase::test_orm_execute[table_deserialize_astuple_row_factory-expected2-where_cols2-params2]": {
                "testid": "tests/test__orm.py::TestORMBase::test_orm_execute[table_deserialize_astuple_row_factory-expected2-where_cols2-params2]",
                "result": "passed",
                "test_implementation": "    def test_orm_execute(\n        self,\n        row_factory,\n        expected,\n        where_cols,\n        params,\n        orm_inst: SimpleTableORM,\n        prepare_test_entry,\n    ):\n        sql_stmt = orm_inst.orm_table_spec.table_select_stmt(\n            select_from=orm_inst.orm_table_name,\n            select_cols=\"count(*) AS count, int_str\",\n            where_cols=where_cols,\n        )\n\n        res = orm_inst.orm_execute(sql_stmt, params, row_factory=row_factory)\n        # NOTE: no row_factory specified, int_str here is not deserialized\n        assert res and res[0] == expected\n        res_gen = orm_inst.orm_execute_gen(sql_stmt, params, row_factory=row_factory)\n        assert next(res_gen) == expected"
            },
            "tests/test__orm.py::TestORMBase::test_orm_check_entry_exist": {
                "testid": "tests/test__orm.py::TestORMBase::test_orm_check_entry_exist",
                "result": "passed",
                "test_implementation": "    def test_orm_check_entry_exist(self, orm_inst: SimpleTableORM, prepare_test_entry):\n        assert orm_inst.orm_check_entry_exist(\n            SimpleTableForTestCols(id=ENTRY_FOR_TEST.id)\n        )\n        assert orm_inst.orm_check_entry_exist(\n            **SimpleTableForTestCols(int_str=ENTRY_FOR_TEST.int_str)\n        )\n        assert not orm_inst.orm_check_entry_exist(int_str=\"123\")"
            },
            "tests/test__orm.py::TestORMBase::test_select_entry": {
                "testid": "tests/test__orm.py::TestORMBase::test_select_entry",
                "result": "passed",
                "test_implementation": "    def test_select_entry(self, orm_inst: SimpleTableORM, prepare_test_entry):\n        _selected_row = orm_inst.orm_select_entry(\n            SimpleTableForTestCols(id=ENTRY_FOR_TEST.id)\n        )\n        _selected_row2 = orm_inst.orm_select_entry(\n            **SimpleTableForTestCols(id=ENTRY_FOR_TEST.id)\n        )\n        assert ENTRY_FOR_TEST == _selected_row == _selected_row2"
            },
            "tests/test__orm.py::TestORMBase::test_insert_mapping[row_as_mapping0-expected0]": {
                "testid": "tests/test__orm.py::TestORMBase::test_insert_mapping[row_as_mapping0-expected0]",
                "result": "passed",
                "test_implementation": "    def test_insert_mapping(self, row_as_mapping, expected, orm_inst: SimpleTableORM):\n        orm_inst.orm_insert_mapping(row_as_mapping)\n        assert orm_inst.orm_select_entry(row_as_mapping).table_asdict() == expected"
            },
            "tests/test__orm.py::TestORMBase::test_insert_mapping[row_as_mapping1-expected1]": {
                "testid": "tests/test__orm.py::TestORMBase::test_insert_mapping[row_as_mapping1-expected1]",
                "result": "passed",
                "test_implementation": "    def test_insert_mapping(self, row_as_mapping, expected, orm_inst: SimpleTableORM):\n        orm_inst.orm_insert_mapping(row_as_mapping)\n        assert orm_inst.orm_select_entry(row_as_mapping).table_asdict() == expected"
            },
            "tests/test__orm.py::TestORMBase::test_insert_mapping[row_as_mapping2-expected2]": {
                "testid": "tests/test__orm.py::TestORMBase::test_insert_mapping[row_as_mapping2-expected2]",
                "result": "passed",
                "test_implementation": "    def test_insert_mapping(self, row_as_mapping, expected, orm_inst: SimpleTableORM):\n        orm_inst.orm_insert_mapping(row_as_mapping)\n        assert orm_inst.orm_select_entry(row_as_mapping).table_asdict() == expected"
            },
            "tests/test__orm.py::TestORMBase::test_insert_mappings[row_as_mappings0]": {
                "testid": "tests/test__orm.py::TestORMBase::test_insert_mappings[row_as_mappings0]",
                "result": "passed",
                "test_implementation": "    def test_insert_mappings(self, row_as_mappings, orm_inst: SimpleTableORM):\n        assert len(row_as_mappings) == orm_inst.orm_insert_mappings(row_as_mappings)\n\n        for row_as_mapping in row_as_mappings:\n            assert (\n                orm_inst.orm_select_entry(row_as_mapping).table_asdict(*row_as_mapping)\n                == row_as_mapping\n            )"
            },
            "tests/test__orm.py::TestORMBase::test_insert_mappings[row_as_mappings1]": {
                "testid": "tests/test__orm.py::TestORMBase::test_insert_mappings[row_as_mappings1]",
                "result": "passed",
                "test_implementation": "    def test_insert_mappings(self, row_as_mappings, orm_inst: SimpleTableORM):\n        assert len(row_as_mappings) == orm_inst.orm_insert_mappings(row_as_mappings)\n\n        for row_as_mapping in row_as_mappings:\n            assert (\n                orm_inst.orm_select_entry(row_as_mapping).table_asdict(*row_as_mapping)\n                == row_as_mapping\n            )"
            },
            "tests/test__orm.py::TestORMBase::test_select_entries": {
                "testid": "tests/test__orm.py::TestORMBase::test_select_entries",
                "result": "passed",
                "test_implementation": "    def test_select_entries(self, orm_inst: SimpleTableORM, prepare_test_entry):\n        select_result = orm_inst.orm_select_entries(\n            SimpleTableForTestCols(id=ENTRY_FOR_TEST.id),\n            _distinct=True,\n            _order_by=((\"id\", \"DESC\"),),\n            _limit=1,\n        )\n        select_result = list(select_result)\n\n        select_result2 = orm_inst.orm_select_entries(\n            **SimpleTableForTestCols(id=ENTRY_FOR_TEST.id),\n            _distinct=True,\n            _order_by=((\"id\", \"DESC\"),),\n            _limit=1,\n        )\n        select_result2 = list(select_result2)\n\n        assert len(select_result) == len(select_result2) == 1\n        assert select_result[0] == select_result2[0] == ENTRY_FOR_TEST"
            },
            "tests/test__orm.py::TestORMBase::test_select_all_entries": {
                "testid": "tests/test__orm.py::TestORMBase::test_select_all_entries",
                "result": "passed",
                "test_implementation": "    def test_select_all_entries(self, orm_inst: SimpleTableORM, prepare_test_entry):\n        select_result = orm_inst.orm_select_all_with_pagination(\n            batch_size=SELECT_ALL_BATCH_SIZE\n        )\n        select_result = list(select_result)\n\n        assert len(select_result) == 1\n        assert select_result[0] == ENTRY_FOR_TEST"
            },
            "tests/test__orm.py::TestORMBase::test_select_with_function_call": {
                "testid": "tests/test__orm.py::TestORMBase::test_select_with_function_call",
                "result": "passed",
                "test_implementation": "    def test_select_with_function_call(\n        self, orm_inst: SimpleTableORM, prepare_test_entry\n    ):\n        _stmt = orm_inst.orm_table_spec.table_select_stmt(\n            select_from=orm_inst.orm_bootstrap_table_name,\n            select_cols=\"*\",\n            function=\"count\",\n        )\n\n        with orm_inst.orm_con as con:\n            cur = con.execute(_stmt)\n            res = cur.fetchone()\n            assert res[0] == 1"
            },
            "tests/test__orm.py::TestORMBase::test_update_entries[entry_to_insert0-set_values0-where_indicator0-expected0]": {
                "testid": "tests/test__orm.py::TestORMBase::test_update_entries[entry_to_insert0-set_values0-where_indicator0-expected0]",
                "result": "passed",
                "test_implementation": "    def test_update_entries(\n        self,\n        entry_to_insert,\n        set_values,\n        where_indicator,\n        expected,\n        orm_inst: SimpleTableORM,\n    ):\n        orm_inst.orm_insert_mapping(entry_to_insert)\n\n        if isinstance(where_indicator, str):\n            orm_inst.orm_update_entries(\n                set_values=set_values, where_stmt=where_indicator\n            )\n        else:\n            orm_inst.orm_update_entries(\n                set_values=set_values, where_cols_value=where_indicator\n            )\n        assert orm_inst.orm_check_entry_exist(expected)"
            },
            "tests/test__orm.py::TestORMBase::test_update_entries[entry_to_insert1-set_values1-where_indicator1-expected1]": {
                "testid": "tests/test__orm.py::TestORMBase::test_update_entries[entry_to_insert1-set_values1-where_indicator1-expected1]",
                "result": "passed",
                "test_implementation": "    def test_update_entries(\n        self,\n        entry_to_insert,\n        set_values,\n        where_indicator,\n        expected,\n        orm_inst: SimpleTableORM,\n    ):\n        orm_inst.orm_insert_mapping(entry_to_insert)\n\n        if isinstance(where_indicator, str):\n            orm_inst.orm_update_entries(\n                set_values=set_values, where_stmt=where_indicator\n            )\n        else:\n            orm_inst.orm_update_entries(\n                set_values=set_values, where_cols_value=where_indicator\n            )\n        assert orm_inst.orm_check_entry_exist(expected)"
            },
            "tests/test__orm.py::TestORMBase::test_update_entries_with_custom_stmt[entry_to_insert0-set_values0-WHERE id > :lower_bound AND id < :upper_bound-params0-expected0]": {
                "testid": "tests/test__orm.py::TestORMBase::test_update_entries_with_custom_stmt[entry_to_insert0-set_values0-WHERE id > :lower_bound AND id < :upper_bound-params0-expected0]",
                "result": "passed",
                "test_implementation": "    def test_update_entries_with_custom_stmt(\n        self,\n        entry_to_insert,\n        set_values,\n        where_stmt,\n        params,\n        expected,\n        orm_inst: SimpleTableORM,\n    ):\n        orm_inst.orm_insert_entry(entry_to_insert)\n\n        orm_inst.orm_update_entries(\n            set_values=set_values,\n            where_stmt=where_stmt,\n            _extra_params=params,\n        )\n        assert orm_inst.orm_check_entry_exist(expected)"
            },
            "tests/test__orm.py::TestORMBase::test_delete_entries": {
                "testid": "tests/test__orm.py::TestORMBase::test_delete_entries",
                "result": "passed",
                "test_implementation": "    def test_delete_entries(self, orm_inst: SimpleTableORM, prepare_test_entry):\n        assert (\n            orm_inst.orm_delete_entries(SimpleTableForTestCols(id=ENTRY_FOR_TEST.id))\n            == 1\n        )"
            },
            "tests/test__orm.py::TestORMUpdateEntriesMany::test_with_where_cols": {
                "testid": "tests/test__orm.py::TestORMUpdateEntriesMany::test_with_where_cols",
                "result": "passed",
                "test_implementation": "    def test_with_where_cols(self, _setup_orm: SimpleTableORM):\n        _setup_orm.orm_update_entries_many(\n            set_cols=SimpleTableForTestColsSelect(\"int_str\"),\n            where_cols=SimpleTableForTestColsSelect(\"id\"),\n            set_cols_value=(\n                SimpleTableForTestCols(int_str=i)\n                for i in range(TEST_ORM_UPDAT_ENTRIES_MANY_ENTRIES_COUNT)\n            ),\n            where_cols_value=(\n                SimpleTableForTestCols(id=i)\n                for i in range(TEST_ORM_UPDAT_ENTRIES_MANY_ENTRIES_COUNT)\n            ),\n        )\n        self._check_result(_setup_orm)"
            },
            "tests/test__orm.py::TestORMUpdateEntriesMany::test_with_custom_where_stmt_and_extra_params_iter": {
                "testid": "tests/test__orm.py::TestORMUpdateEntriesMany::test_with_custom_where_stmt_and_extra_params_iter",
                "result": "passed",
                "test_implementation": "    def test_with_custom_where_stmt_and_extra_params_iter(\n        self, _setup_orm: SimpleTableORM\n    ):\n        _setup_orm.orm_update_entries_many(\n            set_cols=SimpleTableForTestColsSelect(\"int_str\"),\n            where_stmt=\"WHERE id = :check_id\",\n            set_cols_value=(\n                SimpleTableForTestCols(int_str=i)\n                for i in range(TEST_ORM_UPDAT_ENTRIES_MANY_ENTRIES_COUNT)\n            ),\n            _extra_params_iter=(\n                {\"check_id\": i}\n                for i in range(TEST_ORM_UPDAT_ENTRIES_MANY_ENTRIES_COUNT)\n            ),\n        )\n        self._check_result(_setup_orm)"
            },
            "tests/test__orm.py::TestORMUpdateEntriesMany::test_with_custom_where_stmt_and_extra_params": {
                "testid": "tests/test__orm.py::TestORMUpdateEntriesMany::test_with_custom_where_stmt_and_extra_params",
                "result": "passed",
                "test_implementation": "    def test_with_custom_where_stmt_and_extra_params(self, _setup_orm: SimpleTableORM):\n        entry_to_update_id, update_value = 1, 123\n        repeat_times = 1_000\n\n        _setup_orm.orm_update_entries_many(\n            or_option=\"replace\",\n            set_cols=SimpleTableForTestColsSelect(\"int_str\"),\n            where_stmt=\"WHERE id = :check_id\",\n            set_cols_value=repeat(\n                SimpleTableForTestCols(int_str=update_value), times=repeat_times\n            ),\n            _extra_params={\"check_id\": entry_to_update_id},\n        )\n\n        check_entry = _setup_orm.orm_select_entry(\n            SimpleTableForTestCols(id=entry_to_update_id)\n        )\n        assert check_entry.int_str == update_value"
            },
            "tests/test__orm.py::TestORMUpdateEntriesMany::test_with_custom_stmt": {
                "testid": "tests/test__orm.py::TestORMUpdateEntriesMany::test_with_custom_stmt",
                "result": "passed",
                "test_implementation": "    def test_with_custom_stmt(self, _setup_orm: SimpleTableORM):\n        offset = 1000000\n\n        def _preapre_params():\n            for i in range(TEST_ORM_UPDAT_ENTRIES_MANY_ENTRIES_COUNT):\n                yield dict(\n                    **SimpleTableForTestCols(id=i + offset, int_str=i + offset),\n                    check_id=i,\n                )\n\n        _setup_orm.orm_update_entries_many(\n            _extra_params_iter=_preapre_params(),\n            _stmt=_setup_orm.orm_table_spec.table_update_stmt(\n                update_target=_setup_orm.orm_table_name,\n                set_cols=SimpleTableForTestColsSelect(\"int_str\", \"id\"),\n                where_stmt=\"WHERE id = :check_id\",\n            ),\n        )\n\n        _check_set = set(range(TEST_ORM_UPDAT_ENTRIES_MANY_ENTRIES_COUNT))\n        for row in _setup_orm.orm_select_entries():\n            assert row.id == row.int_str\n            _check_set.discard(row.id - offset)\n        assert not _check_set"
            },
            "tests/test__orm.py::test_create_table[opts0]": {
                "testid": "tests/test__orm.py::test_create_table[opts0]",
                "result": "passed",
                "test_implementation": "def test_create_table(opts):\n    with contextlib.closing(sqlite3.connect(\":memory:\")) as conn:\n        orm_inst = SimpleTableORM(conn)\n        orm_inst.orm_create_table(**opts)"
            },
            "tests/test__orm.py::test_create_table[opts1]": {
                "testid": "tests/test__orm.py::test_create_table[opts1]",
                "result": "passed",
                "test_implementation": "def test_create_table(opts):\n    with contextlib.closing(sqlite3.connect(\":memory:\")) as conn:\n        orm_inst = SimpleTableORM(conn)\n        orm_inst.orm_create_table(**opts)"
            },
            "tests/test__orm.py::test_create_table[opts2]": {
                "testid": "tests/test__orm.py::test_create_table[opts2]",
                "result": "passed",
                "test_implementation": "def test_create_table(opts):\n    with contextlib.closing(sqlite3.connect(\":memory:\")) as conn:\n        orm_inst = SimpleTableORM(conn)\n        orm_inst.orm_create_table(**opts)"
            },
            "tests/test__orm.py::test_bootstrap[test_1-create_table_params0-None]": {
                "testid": "tests/test__orm.py::test_bootstrap[test_1-create_table_params0-None]",
                "result": "passed",
                "test_implementation": "def test_bootstrap(\n    table_name,\n    create_table_params,\n    create_indexes_params,\n    setup_test_db_conn: sqlite3.Connection,\n):\n    class _ORM(SimpleTableORM):\n        orm_bootstrap_table_name = table_name\n        if create_table_params:\n            orm_bootstrap_create_table_params = create_table_params\n\n        if create_indexes_params:\n            orm_bootstrap_indexes_params = create_indexes_params\n\n    _orm = _ORM(setup_test_db_conn)\n    _orm.orm_bootstrap_db()"
            },
            "tests/test__orm.py::test_bootstrap[test_2-create_table_params1-create_indexes_params1]": {
                "testid": "tests/test__orm.py::test_bootstrap[test_2-create_table_params1-create_indexes_params1]",
                "result": "passed",
                "test_implementation": "def test_bootstrap(\n    table_name,\n    create_table_params,\n    create_indexes_params,\n    setup_test_db_conn: sqlite3.Connection,\n):\n    class _ORM(SimpleTableORM):\n        orm_bootstrap_table_name = table_name\n        if create_table_params:\n            orm_bootstrap_create_table_params = create_table_params\n\n        if create_indexes_params:\n            orm_bootstrap_indexes_params = create_indexes_params\n\n    _orm = _ORM(setup_test_db_conn)\n    _orm.orm_bootstrap_db()"
            },
            "tests/test__orm.py::test_bootstrap[test_3-None-None]": {
                "testid": "tests/test__orm.py::test_bootstrap[test_3-None-None]",
                "result": "passed",
                "test_implementation": "def test_bootstrap(\n    table_name,\n    create_table_params,\n    create_indexes_params,\n    setup_test_db_conn: sqlite3.Connection,\n):\n    class _ORM(SimpleTableORM):\n        orm_bootstrap_table_name = table_name\n        if create_table_params:\n            orm_bootstrap_create_table_params = create_table_params\n\n        if create_indexes_params:\n            orm_bootstrap_indexes_params = create_indexes_params\n\n    _orm = _ORM(setup_test_db_conn)\n    _orm.orm_bootstrap_db()"
            },
            "tests/test__orm.py::test_row_factory_specifying[sqlite3_row_factory-Row]": {
                "testid": "tests/test__orm.py::test_row_factory_specifying[sqlite3_row_factory-Row]",
                "result": "passed",
                "test_implementation": "def test_row_factory_specifying(\n    _row_factory_specifier,\n    _expected_row_factory,\n    db_conn_func_scope: sqlite3.Connection,\n):\n    db_conn_func_scope.row_factory = _dummy_row_factory\n    _orm = SimpleTableORM(db_conn_func_scope, row_factory=_row_factory_specifier)\n    _orm.orm_create_table()\n    assert _compare_callable(_orm.orm_conn_row_factory, _expected_row_factory)\n\n    # by the way, test the orm_conn_row_factory setter\n    _orm.orm_conn_row_factory = _dummy_row_factory\n    assert _orm.orm_conn_row_factory == _dummy_row_factory"
            },
            "tests/test__orm.py::test_row_factory_specifying[table_spec-table_row_factory]": {
                "testid": "tests/test__orm.py::test_row_factory_specifying[table_spec-table_row_factory]",
                "result": "passed",
                "test_implementation": "def test_row_factory_specifying(\n    _row_factory_specifier,\n    _expected_row_factory,\n    db_conn_func_scope: sqlite3.Connection,\n):\n    db_conn_func_scope.row_factory = _dummy_row_factory\n    _orm = SimpleTableORM(db_conn_func_scope, row_factory=_row_factory_specifier)\n    _orm.orm_create_table()\n    assert _compare_callable(_orm.orm_conn_row_factory, _expected_row_factory)\n\n    # by the way, test the orm_conn_row_factory setter\n    _orm.orm_conn_row_factory = _dummy_row_factory\n    assert _orm.orm_conn_row_factory == _dummy_row_factory"
            },
            "tests/test__orm.py::test_row_factory_specifying[table_spec_no_validation-_expected_row_factory2]": {
                "testid": "tests/test__orm.py::test_row_factory_specifying[table_spec_no_validation-_expected_row_factory2]",
                "result": "passed",
                "test_implementation": "def test_row_factory_specifying(\n    _row_factory_specifier,\n    _expected_row_factory,\n    db_conn_func_scope: sqlite3.Connection,\n):\n    db_conn_func_scope.row_factory = _dummy_row_factory\n    _orm = SimpleTableORM(db_conn_func_scope, row_factory=_row_factory_specifier)\n    _orm.orm_create_table()\n    assert _compare_callable(_orm.orm_conn_row_factory, _expected_row_factory)\n\n    # by the way, test the orm_conn_row_factory setter\n    _orm.orm_conn_row_factory = _dummy_row_factory\n    assert _orm.orm_conn_row_factory == _dummy_row_factory"
            },
            "tests/test__orm.py::test_row_factory_specifying[do_not_change-_dummy_row_factory]": {
                "testid": "tests/test__orm.py::test_row_factory_specifying[do_not_change-_dummy_row_factory]",
                "result": "passed",
                "test_implementation": "def test_row_factory_specifying(\n    _row_factory_specifier,\n    _expected_row_factory,\n    db_conn_func_scope: sqlite3.Connection,\n):\n    db_conn_func_scope.row_factory = _dummy_row_factory\n    _orm = SimpleTableORM(db_conn_func_scope, row_factory=_row_factory_specifier)\n    _orm.orm_create_table()\n    assert _compare_callable(_orm.orm_conn_row_factory, _expected_row_factory)\n\n    # by the way, test the orm_conn_row_factory setter\n    _orm.orm_conn_row_factory = _dummy_row_factory\n    assert _orm.orm_conn_row_factory == _dummy_row_factory"
            },
            "tests/test__orm.py::test_row_factory_specifying[None-None]": {
                "testid": "tests/test__orm.py::test_row_factory_specifying[None-None]",
                "result": "passed",
                "test_implementation": "def test_row_factory_specifying(\n    _row_factory_specifier,\n    _expected_row_factory,\n    db_conn_func_scope: sqlite3.Connection,\n):\n    db_conn_func_scope.row_factory = _dummy_row_factory\n    _orm = SimpleTableORM(db_conn_func_scope, row_factory=_row_factory_specifier)\n    _orm.orm_create_table()\n    assert _compare_callable(_orm.orm_conn_row_factory, _expected_row_factory)\n\n    # by the way, test the orm_conn_row_factory setter\n    _orm.orm_conn_row_factory = _dummy_row_factory\n    assert _orm.orm_conn_row_factory == _dummy_row_factory"
            },
            "tests/test__table_spec.py::test_table_create[table_create_params0]": {
                "testid": "tests/test__table_spec.py::test_table_create[table_create_params0]",
                "result": "passed",
                "test_implementation": "def test_table_create(table_create_params: CreateTableParams) -> None:\n    with contextlib.closing(sqlite3.connect(\":memory:\")) as db_conn:\n        table_create_stmt = SimpleTableForTest.table_create_stmt(\n            table_name=TBL_NAME, **table_create_params\n        )\n        with db_conn as _conn:\n            _conn.execute(table_create_stmt)"
            },
            "tests/test__table_spec.py::test_table_create[table_create_params1]": {
                "testid": "tests/test__table_spec.py::test_table_create[table_create_params1]",
                "result": "passed",
                "test_implementation": "def test_table_create(table_create_params: CreateTableParams) -> None:\n    with contextlib.closing(sqlite3.connect(\":memory:\")) as db_conn:\n        table_create_stmt = SimpleTableForTest.table_create_stmt(\n            table_name=TBL_NAME, **table_create_params\n        )\n        with db_conn as _conn:\n            _conn.execute(table_create_stmt)"
            },
            "tests/test__table_spec.py::test_table_create[table_create_params2]": {
                "testid": "tests/test__table_spec.py::test_table_create[table_create_params2]",
                "result": "passed",
                "test_implementation": "def test_table_create(table_create_params: CreateTableParams) -> None:\n    with contextlib.closing(sqlite3.connect(\":memory:\")) as db_conn:\n        table_create_stmt = SimpleTableForTest.table_create_stmt(\n            table_name=TBL_NAME, **table_create_params\n        )\n        with db_conn as _conn:\n            _conn.execute(table_create_stmt)"
            },
            "tests/test__table_spec.py::test_table_create[table_create_params3]": {
                "testid": "tests/test__table_spec.py::test_table_create[table_create_params3]",
                "result": "passed",
                "test_implementation": "def test_table_create(table_create_params: CreateTableParams) -> None:\n    with contextlib.closing(sqlite3.connect(\":memory:\")) as db_conn:\n        table_create_stmt = SimpleTableForTest.table_create_stmt(\n            table_name=TBL_NAME, **table_create_params\n        )\n        with db_conn as _conn:\n            _conn.execute(table_create_stmt)"
            },
            "tests/test__table_spec.py::test_table_create[table_create_params4]": {
                "testid": "tests/test__table_spec.py::test_table_create[table_create_params4]",
                "result": "passed",
                "test_implementation": "def test_table_create(table_create_params: CreateTableParams) -> None:\n    with contextlib.closing(sqlite3.connect(\":memory:\")) as db_conn:\n        table_create_stmt = SimpleTableForTest.table_create_stmt(\n            table_name=TBL_NAME, **table_create_params\n        )\n        with db_conn as _conn:\n            _conn.execute(table_create_stmt)"
            },
            "tests/test__table_spec.py::TestTableSpecWithDB::test_insert_entry[insert a complete row-to_insert0]": {
                "testid": "tests/test__table_spec.py::TestTableSpecWithDB::test_insert_entry[insert a complete row-to_insert0]",
                "result": "passed",
                "test_implementation": "    def test_insert_entry(\n        self, case, to_insert: SimpleTableForTestCols, db_conn: sqlite3.Connection\n    ):\n        table_insert_stmt = SimpleTableForTest.table_insert_stmt(\n            insert_into=TBL_NAME, insert_cols=tuple(to_insert)\n        )\n        with db_conn as _conn:\n            _conn.execute(table_insert_stmt, to_insert)\n\n        with db_conn as _conn:\n            _cur = _conn.execute(\n                SimpleTableForTest.table_select_stmt(select_from=TBL_NAME)\n            )\n            _cur.row_factory = SimpleTableForTest.table_row_factory\n\n            _res: SimpleTableForTest = _cur.fetchone()\n            assert all(v == getattr(_res, k) for k, v in to_insert.items())"
            },
            "tests/test__table_spec.py::TestTableSpecWithDB::test_insert_entry[insert a partially set row, omit id(rowid alias)-to_insert1]": {
                "testid": "tests/test__table_spec.py::TestTableSpecWithDB::test_insert_entry[insert a partially set row, omit id(rowid alias)-to_insert1]",
                "result": "passed",
                "test_implementation": "    def test_insert_entry(\n        self, case, to_insert: SimpleTableForTestCols, db_conn: sqlite3.Connection\n    ):\n        table_insert_stmt = SimpleTableForTest.table_insert_stmt(\n            insert_into=TBL_NAME, insert_cols=tuple(to_insert)\n        )\n        with db_conn as _conn:\n            _conn.execute(table_insert_stmt, to_insert)\n\n        with db_conn as _conn:\n            _cur = _conn.execute(\n                SimpleTableForTest.table_select_stmt(select_from=TBL_NAME)\n            )\n            _cur.row_factory = SimpleTableForTest.table_row_factory\n\n            _res: SimpleTableForTest = _cur.fetchone()\n            assert all(v == getattr(_res, k) for k, v in to_insert.items())"
            },
            "tests/test__table_spec.py::TestTableSpecWithDB::test_insert_entry[insert a row with order shuffled-to_insert2]": {
                "testid": "tests/test__table_spec.py::TestTableSpecWithDB::test_insert_entry[insert a row with order shuffled-to_insert2]",
                "result": "passed",
                "test_implementation": "    def test_insert_entry(\n        self, case, to_insert: SimpleTableForTestCols, db_conn: sqlite3.Connection\n    ):\n        table_insert_stmt = SimpleTableForTest.table_insert_stmt(\n            insert_into=TBL_NAME, insert_cols=tuple(to_insert)\n        )\n        with db_conn as _conn:\n            _conn.execute(table_insert_stmt, to_insert)\n\n        with db_conn as _conn:\n            _cur = _conn.execute(\n                SimpleTableForTest.table_select_stmt(select_from=TBL_NAME)\n            )\n            _cur.row_factory = SimpleTableForTest.table_row_factory\n\n            _res: SimpleTableForTest = _cur.fetchone()\n            assert all(v == getattr(_res, k) for k, v in to_insert.items())"
            },
            "tests/test__table_spec.py::TestTableSpecWithDB::test_insert_default_values": {
                "testid": "tests/test__table_spec.py::TestTableSpecWithDB::test_insert_default_values",
                "result": "passed",
                "test_implementation": "    def test_insert_default_values(self, db_conn: sqlite3.Connection):\n        table_insert_stmt = SimpleTableForTest.table_insert_stmt(\n            insert_into=TBL_NAME, insert_default=True\n        )\n        with db_conn as _conn:\n            _conn.execute(table_insert_stmt)\n\n        with db_conn as _conn:\n            _cur = _conn.execute(\n                SimpleTableForTest.table_select_stmt(select_from=TBL_NAME)\n            )\n            # for cols with no defautl value defined, NULL will be assigned\n            # for rowid, it will be automatically incremented\n            assert _cur.fetchone() == (1, ID_STR_DEFAULT_VALUE, None, None)"
            },
            "tests/test__table_spec.py::TestTableSpecWithDB::test_lookup_entry": {
                "testid": "tests/test__table_spec.py::TestTableSpecWithDB::test_lookup_entry",
                "result": "passed",
                "test_implementation": "    def test_lookup_entry(self, db_conn: sqlite3.Connection, prepare_test_entry):\n        _to_lookup = self.ENTRY_FOR_TEST\n        table_select_stmt = SimpleTableForTest.table_select_stmt(\n            select_from=TBL_NAME,\n            select_cols=\"rowid, *\",\n            where_cols=SimpleTableForTestColsSelect(\"id\"),\n        )\n        with db_conn as _conn:\n            _cur = _conn.execute(table_select_stmt, {\"id\": _to_lookup.id})\n            _cur.row_factory = SimpleTableForTest.table_row_factory2\n\n            res = _cur.fetchall()\n            assert len(res) == 1\n            assert isinstance(res[0], SimpleTableForTest)\n            assert res[0] == _to_lookup"
            },
            "tests/test__table_spec.py::TestTableSpecWithDB::test_update_entry[set_values0-where_cols0-UPDATE test_table SET id = :id, id_str = :id_str WHERE id = :__table_spec_id AND id_str = :__table_spec_id_str AND extra = :__table_spec_extra AND int_str = :__table_spec_int_str;-expected_result0]": {
                "testid": "tests/test__table_spec.py::TestTableSpecWithDB::test_update_entry[set_values0-where_cols0-UPDATE test_table SET id = :id, id_str = :id_str WHERE id = :__table_spec_id AND id_str = :__table_spec_id_str AND extra = :__table_spec_extra AND int_str = :__table_spec_int_str;-expected_result0]",
                "result": "passed",
                "test_implementation": "    def test_update_entry(\n        self,\n        db_conn: sqlite3.Connection,\n        set_values: Mapping[str, Any],\n        where_cols: Mapping[str, Any],\n        update_stmt: str,\n        expected_result: SimpleTableForTest,\n        prepare_test_entry,\n    ):\n        _params = SimpleTableForTestCols(\n            **SimpleTableForTest.table_preprare_update_where_cols(where_cols),\n            **set_values,\n        )\n        with db_conn as _conn:\n            _conn.execute(update_stmt, _params)\n\n        # NOTE: we only have one entry at the table\n        with db_conn as _conn:\n            _cur = _conn.execute(\n                SimpleTableForTest.table_select_stmt(select_from=TBL_NAME)\n            )\n            _cur.row_factory = SimpleTableForTest.table_row_factory\n\n            res = _cur.fetchone()\n            assert res == expected_result"
            },
            "tests/test__table_spec.py::TestTableSpecWithDB::test_update_entry[set_values1-where_cols1-UPDATE test_table SET id = :id, id_str = :id_str WHERE id = 123;-expected_result1]": {
                "testid": "tests/test__table_spec.py::TestTableSpecWithDB::test_update_entry[set_values1-where_cols1-UPDATE test_table SET id = :id, id_str = :id_str WHERE id = 123;-expected_result1]",
                "result": "passed",
                "test_implementation": "    def test_update_entry(\n        self,\n        db_conn: sqlite3.Connection,\n        set_values: Mapping[str, Any],\n        where_cols: Mapping[str, Any],\n        update_stmt: str,\n        expected_result: SimpleTableForTest,\n        prepare_test_entry,\n    ):\n        _params = SimpleTableForTestCols(\n            **SimpleTableForTest.table_preprare_update_where_cols(where_cols),\n            **set_values,\n        )\n        with db_conn as _conn:\n            _conn.execute(update_stmt, _params)\n\n        # NOTE: we only have one entry at the table\n        with db_conn as _conn:\n            _cur = _conn.execute(\n                SimpleTableForTest.table_select_stmt(select_from=TBL_NAME)\n            )\n            _cur.row_factory = SimpleTableForTest.table_row_factory\n\n            res = _cur.fetchone()\n            assert res == expected_result"
            },
            "tests/test__table_spec.py::TestTableSpecWithDB::test_update_entry[set_values2-where_cols2-UPDATE test_table SET id = :id, id_str = :id_str;-expected_result2]": {
                "testid": "tests/test__table_spec.py::TestTableSpecWithDB::test_update_entry[set_values2-where_cols2-UPDATE test_table SET id = :id, id_str = :id_str;-expected_result2]",
                "result": "passed",
                "test_implementation": "    def test_update_entry(\n        self,\n        db_conn: sqlite3.Connection,\n        set_values: Mapping[str, Any],\n        where_cols: Mapping[str, Any],\n        update_stmt: str,\n        expected_result: SimpleTableForTest,\n        prepare_test_entry,\n    ):\n        _params = SimpleTableForTestCols(\n            **SimpleTableForTest.table_preprare_update_where_cols(where_cols),\n            **set_values,\n        )\n        with db_conn as _conn:\n            _conn.execute(update_stmt, _params)\n\n        # NOTE: we only have one entry at the table\n        with db_conn as _conn:\n            _cur = _conn.execute(\n                SimpleTableForTest.table_select_stmt(select_from=TBL_NAME)\n            )\n            _cur.row_factory = SimpleTableForTest.table_row_factory\n\n            res = _cur.fetchone()\n            assert res == expected_result"
            },
            "tests/test__table_spec.py::TestTableSpecWithDB::test_update_entry[set_values3-where_cols3-UPDATE OR FAIL test_table SET id_str = :id_str, extra = :extra WHERE id = :__table_spec_id AND id_str = :__table_spec_id_str AND extra = :__table_spec_extra AND int_str = :__table_spec_int_str RETURNING *;-expected_result3]": {
                "testid": "tests/test__table_spec.py::TestTableSpecWithDB::test_update_entry[set_values3-where_cols3-UPDATE OR FAIL test_table SET id_str = :id_str, extra = :extra WHERE id = :__table_spec_id AND id_str = :__table_spec_id_str AND extra = :__table_spec_extra AND int_str = :__table_spec_int_str RETURNING *;-expected_result3]",
                "result": "passed",
                "test_implementation": "    def test_update_entry(\n        self,\n        db_conn: sqlite3.Connection,\n        set_values: Mapping[str, Any],\n        where_cols: Mapping[str, Any],\n        update_stmt: str,\n        expected_result: SimpleTableForTest,\n        prepare_test_entry,\n    ):\n        _params = SimpleTableForTestCols(\n            **SimpleTableForTest.table_preprare_update_where_cols(where_cols),\n            **set_values,\n        )\n        with db_conn as _conn:\n            _conn.execute(update_stmt, _params)\n\n        # NOTE: we only have one entry at the table\n        with db_conn as _conn:\n            _cur = _conn.execute(\n                SimpleTableForTest.table_select_stmt(select_from=TBL_NAME)\n            )\n            _cur.row_factory = SimpleTableForTest.table_row_factory\n\n            res = _cur.fetchone()\n            assert res == expected_result"
            },
            "tests/test__table_spec.py::TestTableSpecWithDB::test_deserialize_asdict_row_factory": {
                "testid": "tests/test__table_spec.py::TestTableSpecWithDB::test_deserialize_asdict_row_factory",
                "result": "passed",
                "test_implementation": "    def test_deserialize_asdict_row_factory(\n        self, db_conn: sqlite3.Connection, prepare_test_entry\n    ):\n        _stmt = SimpleTableForTest.table_select_stmt(\n            select_from=TBL_NAME,\n            select_cols=\"int_str AS str_int, int_str, count(*) AS count\",\n            where_cols=SimpleTableForTestColsSelect(\"id\"),\n        )\n        with db_conn as conn:\n            _cur = conn.execute(_stmt, SimpleTableForTestCols(id=ENTRY_FOR_TEST.id))\n            _cur.row_factory = SimpleTableForTest.table_deserialize_asdict_row_factory\n\n            _res: SimpleTableForTestCols = _cur.fetchone()\n            assert _res == {\n                # NOTE: if alias the selected col, this col's value will not be deserialized.\n                \"str_int\": str(ENTRY_FOR_TEST.int_str),\n                \"int_str\": ENTRY_FOR_TEST.int_str,\n                \"count\": 1,\n            }"
            },
            "tests/test__table_spec.py::TestTableSpecWithDB::test_deserialize_astuple_row_factory": {
                "testid": "tests/test__table_spec.py::TestTableSpecWithDB::test_deserialize_astuple_row_factory",
                "result": "passed",
                "test_implementation": "    def test_deserialize_astuple_row_factory(\n        self, db_conn: sqlite3.Connection, prepare_test_entry\n    ):\n        _stmt = SimpleTableForTest.table_select_stmt(\n            select_from=TBL_NAME,\n            select_cols=\"count(*) AS total_entry_num, int_str AS str_int, int_str\",\n            where_cols=SimpleTableForTestColsSelect(\"id\"),\n        )\n        with db_conn as conn:\n            _cur = conn.execute(_stmt, SimpleTableForTestCols(id=ENTRY_FOR_TEST.id))\n            _cur.row_factory = SimpleTableForTest.table_deserialize_astuple_row_factory\n\n            _res: SimpleTableForTestCols = _cur.fetchone()\n            assert _res == (\n                1,\n                # NOTE: if alias the selected col, this col's value will not be deserialized.\n                str(ENTRY_FOR_TEST.int_str),\n                ENTRY_FOR_TEST.int_str,\n            )"
            },
            "tests/test__table_spec.py::test_table_from_tuple[_in0-True-_expected0]": {
                "testid": "tests/test__table_spec.py::test_table_from_tuple[_in0-True-_expected0]",
                "result": "passed",
                "test_implementation": "def test_table_from_tuple(\n    _in: tuple[Any, ...], _validate: bool, _expected: SimpleTableForTest\n):\n    assert (\n        SimpleTableForTest.table_from_tuple(_in, with_validation=_validate) == _expected\n    )"
            },
            "tests/test__table_spec.py::test_table_from_tuple[_in1-False-_expected1]": {
                "testid": "tests/test__table_spec.py::test_table_from_tuple[_in1-False-_expected1]",
                "result": "passed",
                "test_implementation": "def test_table_from_tuple(\n    _in: tuple[Any, ...], _validate: bool, _expected: SimpleTableForTest\n):\n    assert (\n        SimpleTableForTest.table_from_tuple(_in, with_validation=_validate) == _expected\n    )"
            },
            "tests/test__table_spec.py::test_table_from_dict[_in0-True-_expected0]": {
                "testid": "tests/test__table_spec.py::test_table_from_dict[_in0-True-_expected0]",
                "result": "passed",
                "test_implementation": "def test_table_from_dict(\n    _in: Mapping[str, Any], _validate: bool, _expected: SimpleTableForTest\n):\n    assert (\n        SimpleTableForTest.table_from_dict(_in, with_validation=_validate) == _expected\n    )"
            },
            "tests/test__table_spec.py::test_table_from_dict[_in1-False-_expected1]": {
                "testid": "tests/test__table_spec.py::test_table_from_dict[_in1-False-_expected1]",
                "result": "passed",
                "test_implementation": "def test_table_from_dict(\n    _in: Mapping[str, Any], _validate: bool, _expected: SimpleTableForTest\n):\n    assert (\n        SimpleTableForTest.table_from_dict(_in, with_validation=_validate) == _expected\n    )"
            },
            "tests/test__table_spec.py::test_table_dump_asdict[_in0-_expected0]": {
                "testid": "tests/test__table_spec.py::test_table_dump_asdict[_in0-_expected0]",
                "result": "passed",
                "test_implementation": "def test_table_dump_asdict(_in: SimpleTableForTest, _expected: dict[str, Any]):\n    assert _in.table_dump_asdict(*_expected) == _expected"
            },
            "tests/test__table_spec.py::test_table_dump_asdict[_in1-_expected1]": {
                "testid": "tests/test__table_spec.py::test_table_dump_asdict[_in1-_expected1]",
                "result": "passed",
                "test_implementation": "def test_table_dump_asdict(_in: SimpleTableForTest, _expected: dict[str, Any]):\n    assert _in.table_dump_asdict(*_expected) == _expected"
            },
            "tests/test__table_spec.py::test_table_dump_astuple[_in0-_cols0-_expected0]": {
                "testid": "tests/test__table_spec.py::test_table_dump_astuple[_in0-_cols0-_expected0]",
                "result": "passed",
                "test_implementation": "def test_table_dump_astuple(\n    _in: SimpleTableForTest, _cols: list[str], _expected: tuple[Any, ...]\n):\n    assert _in.table_dump_astuple(*_cols) == _expected"
            },
            "tests/test__table_spec.py::test_table_dump_astuple[_in1-_cols1-_expected1]": {
                "testid": "tests/test__table_spec.py::test_table_dump_astuple[_in1-_cols1-_expected1]",
                "result": "passed",
                "test_implementation": "def test_table_dump_astuple(\n    _in: SimpleTableForTest, _cols: list[str], _expected: tuple[Any, ...]\n):\n    assert _in.table_dump_astuple(*_cols) == _expected"
            },
            "tests/test__table_spec.py::test_serializing_mapping[_in0-_expected0]": {
                "testid": "tests/test__table_spec.py::test_serializing_mapping[_in0-_expected0]",
                "result": "passed",
                "test_implementation": "def test_serializing_mapping(_in: Mapping[str, Any], _expected: Mapping[str, Any]):\n    assert SimpleTableForTest.table_serialize_mapping(_in) == _expected"
            },
            "tests/test__table_spec.py::test_serializing_mapping[_in1-_expected1]": {
                "testid": "tests/test__table_spec.py::test_serializing_mapping[_in1-_expected1]",
                "result": "passed",
                "test_implementation": "def test_serializing_mapping(_in: Mapping[str, Any], _expected: Mapping[str, Any]):\n    assert SimpleTableForTest.table_serialize_mapping(_in) == _expected"
            },
            "tests/test__types.py::test_datetime_helper[_in0-expected0]": {
                "testid": "tests/test__types.py::test_datetime_helper[_in0-expected0]",
                "result": "passed",
                "test_implementation": "def test_datetime_helper(_in, expected):\n    inst = DatetimeTestModel(\n        unix_timestamp=_in,\n        unix_timestamp_int=_in,\n        datetime_iso8601=_in,\n    )\n    assert inst.model_dump() == expected\n    assert DatetimeTestModel.model_validate(\n        inst.model_dump()\n    ) == DatetimeTestModel.model_validate(expected)"
            },
            "tests/test__utils.py::test_typeafinityrepr[Choice123-INTEGER]": {
                "testid": "tests/test__utils.py::test_typeafinityrepr[Choice123-INTEGER]",
                "result": "passed",
                "test_implementation": "def test_typeafinityrepr(_in, expected):\n    _parsed = TypeAffinityRepr(_in)\n    assert _parsed.type_affinity == expected\n    assert str(_parsed) == expected.value"
            },
            "tests/test__utils.py::test_typeafinityrepr[ChoiceABC-TEXT]": {
                "testid": "tests/test__utils.py::test_typeafinityrepr[ChoiceABC-TEXT]",
                "result": "passed",
                "test_implementation": "def test_typeafinityrepr(_in, expected):\n    _parsed = TypeAffinityRepr(_in)\n    assert _parsed.type_affinity == expected\n    assert str(_parsed) == expected.value"
            },
            "tests/test__utils.py::test_typeafinityrepr[str-TEXT]": {
                "testid": "tests/test__utils.py::test_typeafinityrepr[str-TEXT]",
                "result": "passed",
                "test_implementation": "def test_typeafinityrepr(_in, expected):\n    _parsed = TypeAffinityRepr(_in)\n    assert _parsed.type_affinity == expected\n    assert str(_parsed) == expected.value"
            },
            "tests/test__utils.py::test_typeafinityrepr[bytes-BLOB]": {
                "testid": "tests/test__utils.py::test_typeafinityrepr[bytes-BLOB]",
                "result": "passed",
                "test_implementation": "def test_typeafinityrepr(_in, expected):\n    _parsed = TypeAffinityRepr(_in)\n    assert _parsed.type_affinity == expected\n    assert str(_parsed) == expected.value"
            },
            "tests/test__utils.py::test_typeafinityrepr[int-INTEGER]": {
                "testid": "tests/test__utils.py::test_typeafinityrepr[int-INTEGER]",
                "result": "passed",
                "test_implementation": "def test_typeafinityrepr(_in, expected):\n    _parsed = TypeAffinityRepr(_in)\n    assert _parsed.type_affinity == expected\n    assert str(_parsed) == expected.value"
            },
            "tests/test__utils.py::test_typeafinityrepr[float-REAL]": {
                "testid": "tests/test__utils.py::test_typeafinityrepr[float-REAL]",
                "result": "passed",
                "test_implementation": "def test_typeafinityrepr(_in, expected):\n    _parsed = TypeAffinityRepr(_in)\n    assert _parsed.type_affinity == expected\n    assert str(_parsed) == expected.value"
            },
            "tests/test__utils.py::test_typeafinityrepr[None-NULL]": {
                "testid": "tests/test__utils.py::test_typeafinityrepr[None-NULL]",
                "result": "passed",
                "test_implementation": "def test_typeafinityrepr(_in, expected):\n    _parsed = TypeAffinityRepr(_in)\n    assert _parsed.type_affinity == expected\n    assert str(_parsed) == expected.value"
            },
            "tests/test__utils.py::test_typeafinityrepr[Literal-INTEGER]": {
                "testid": "tests/test__utils.py::test_typeafinityrepr[Literal-INTEGER]",
                "result": "passed",
                "test_implementation": "def test_typeafinityrepr(_in, expected):\n    _parsed = TypeAffinityRepr(_in)\n    assert _parsed.type_affinity == expected\n    assert str(_parsed) == expected.value"
            },
            "tests/test__utils.py::test_typeafinityrepr[Literal-TEXT]": {
                "testid": "tests/test__utils.py::test_typeafinityrepr[Literal-TEXT]",
                "result": "passed",
                "test_implementation": "def test_typeafinityrepr(_in, expected):\n    _parsed = TypeAffinityRepr(_in)\n    assert _parsed.type_affinity == expected\n    assert str(_parsed) == expected.value"
            },
            "tests/test__utils.py::test_typeafinityrepr[Optional-BLOB]": {
                "testid": "tests/test__utils.py::test_typeafinityrepr[Optional-BLOB]",
                "result": "passed",
                "test_implementation": "def test_typeafinityrepr(_in, expected):\n    _parsed = TypeAffinityRepr(_in)\n    assert _parsed.type_affinity == expected\n    assert str(_parsed) == expected.value"
            },
            "tests/test__utils.py::test_typeafinityrepr[Optional-INTEGER0]": {
                "testid": "tests/test__utils.py::test_typeafinityrepr[Optional-INTEGER0]",
                "result": "passed",
                "test_implementation": "def test_typeafinityrepr(_in, expected):\n    _parsed = TypeAffinityRepr(_in)\n    assert _parsed.type_affinity == expected\n    assert str(_parsed) == expected.value"
            },
            "tests/test__utils.py::test_typeafinityrepr[Optional-TEXT0]": {
                "testid": "tests/test__utils.py::test_typeafinityrepr[Optional-TEXT0]",
                "result": "passed",
                "test_implementation": "def test_typeafinityrepr(_in, expected):\n    _parsed = TypeAffinityRepr(_in)\n    assert _parsed.type_affinity == expected\n    assert str(_parsed) == expected.value"
            },
            "tests/test__utils.py::test_typeafinityrepr[Optional-INTEGER1]": {
                "testid": "tests/test__utils.py::test_typeafinityrepr[Optional-INTEGER1]",
                "result": "passed",
                "test_implementation": "def test_typeafinityrepr(_in, expected):\n    _parsed = TypeAffinityRepr(_in)\n    assert _parsed.type_affinity == expected\n    assert str(_parsed) == expected.value"
            },
            "tests/test__utils.py::test_typeafinityrepr[Optional-TEXT1]": {
                "testid": "tests/test__utils.py::test_typeafinityrepr[Optional-TEXT1]",
                "result": "passed",
                "test_implementation": "def test_typeafinityrepr(_in, expected):\n    _parsed = TypeAffinityRepr(_in)\n    assert _parsed.type_affinity == expected\n    assert str(_parsed) == expected.value"
            },
            "tests/test__utils.py::test_constrainrepr[_in0-NOT NULL DEFAULT 1 CHECK (column IN (1,2,3))]": {
                "testid": "tests/test__utils.py::test_constrainrepr[_in0-NOT NULL DEFAULT 1 CHECK (column IN (1,2,3))]",
                "result": "passed",
                "test_implementation": "def test_constrainrepr(_in, expected):\n    assert f\"{_in}\" == expected"
            },
            "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_create_table": {
                "testid": "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_create_table",
                "result": "passed",
                "test_implementation": null
            },
            "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_insert_entries_with_pool": {
                "testid": "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_insert_entries_with_pool",
                "result": "passed",
                "test_implementation": null
            },
            "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_create_index": {
                "testid": "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_create_index",
                "result": "passed",
                "test_implementation": null
            },
            "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_orm_execute": {
                "testid": "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_orm_execute",
                "result": "passed",
                "test_implementation": null
            },
            "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_lookup_entries": {
                "testid": "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_lookup_entries",
                "result": "passed",
                "test_implementation": null
            },
            "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_caller_exits_when_lookup_entries": {
                "testid": "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_caller_exits_when_lookup_entries",
                "result": "passed",
                "test_implementation": null
            },
            "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_in_thread_raise_exceptions_when_lookup_entries": {
                "testid": "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_in_thread_raise_exceptions_when_lookup_entries",
                "result": "passed",
                "test_implementation": null
            },
            "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_delete_entries": {
                "testid": "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_delete_entries",
                "result": "passed",
                "test_implementation": null
            },
            "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_check_timer": {
                "testid": "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_check_timer",
                "result": "passed",
                "test_implementation": null
            },
            "tests/test_e2e/test_orm.py::TestWithSampleDB::test_create_table": {
                "testid": "tests/test_e2e/test_orm.py::TestWithSampleDB::test_create_table",
                "result": "passed",
                "test_implementation": "    def test_create_table(self):\n        logger.info(\"test create table\")\n        self.orm_inst.orm_create_table()\n        assert utils.lookup_table(self.orm_inst.orm_con, self.orm_inst.orm_table_name)"
            },
            "tests/test_e2e/test_orm.py::TestWithSampleDB::test_insert_entries": {
                "testid": "tests/test_e2e/test_orm.py::TestWithSampleDB::test_insert_entries",
                "result": "passed",
                "test_implementation": "    def test_insert_entries(self, setup_test_data: dict[str, SampleTable]):\n        logger.info(\"test insert entries\")\n\n        for entry in utils.batched(setup_test_data.values(), TEST_INSERT_BATCH_SIZE):\n            self.orm_inst.orm_insert_entries(entry)\n\n        logger.info(\"confirm data written\")\n        for _entry in self.orm_inst.orm_select_entries():\n            _corresponding_item = setup_test_data[_entry.prim_key]\n            assert _corresponding_item == _entry\n\n        logger.info(\"confirm the num of inserted entries\")\n        with self.orm_inst.orm_con as _con:\n            _cur = _con.execute(\n                self.orm_inst.orm_table_spec.table_select_stmt(\n                    select_from=self.orm_inst.orm_table_name,\n                    function=\"count\",\n                )\n            )\n            _raw = _cur.fetchone()\n            assert _raw[0] == len(setup_test_data)"
            },
            "tests/test_e2e/test_orm.py::TestWithSampleDB::test_create_index": {
                "testid": "tests/test_e2e/test_orm.py::TestWithSampleDB::test_create_index",
                "result": "passed",
                "test_implementation": "    def test_create_index(self):\n        logger.info(\"test create index\")\n        self.orm_inst.orm_create_index(\n            index_name=INDEX_NAME,\n            index_keys=INDEX_KEYS,\n            unique=True,\n        )"
            },
            "tests/test_e2e/test_orm.py::TestWithSampleDB::test_select_one_entry": {
                "testid": "tests/test_e2e/test_orm.py::TestWithSampleDB::test_select_one_entry",
                "result": "passed",
                "test_implementation": "    def test_select_one_entry(\n        self, setup_test_data: dict[str, SampleTable], entry_to_lookup: SampleTable\n    ):\n        logger.info(\"test select exactly one entry\")\n        assert entry_to_lookup == self.orm_inst.orm_select_entry(\n            SampleTableCols(key_id=entry_to_lookup.key_id)\n        )"
            },
            "tests/test_e2e/test_orm.py::TestWithSampleDB::test_orm_execute": {
                "testid": "tests/test_e2e/test_orm.py::TestWithSampleDB::test_orm_execute",
                "result": "passed",
                "test_implementation": "    def test_orm_execute(self, setup_test_data: dict[str, SampleTable]):\n        logger.info(\"test orm_execute API\")\n        sql_stmt = self.orm_inst.orm_table_spec.table_select_stmt(\n            select_from=self.orm_inst.orm_table_name,\n            select_cols=\"*\",\n            function=\"count\",\n        )\n        res = self.orm_inst.orm_execute(sql_stmt, row_factory=None)\n        assert res and res[0][0] == len(setup_test_data)"
            },
            "tests/test_e2e/test_orm.py::TestWithSampleDB::test_lookup_entries": {
                "testid": "tests/test_e2e/test_orm.py::TestWithSampleDB::test_lookup_entries",
                "result": "passed",
                "test_implementation": "    def test_lookup_entries(self, entries_to_lookup: list[SampleTable]):\n        logger.info(\"test lookup entries\")\n        for _entry in entries_to_lookup:\n            _looked_up = self.orm_inst.orm_select_entries(\n                SampleTableCols(\n                    key_id=_entry.key_id,\n                    prim_key_sha256hash=_entry.prim_key_sha256hash,\n                ),\n            )\n            _looked_up = list(_looked_up)\n            assert len(_looked_up) == 1\n            assert _looked_up[0] == _entry"
            },
            "tests/test_e2e/test_orm.py::TestWithSampleDB::test_select_all_entries": {
                "testid": "tests/test_e2e/test_orm.py::TestWithSampleDB::test_select_all_entries",
                "result": "passed",
                "test_implementation": "    def test_select_all_entries(self, setup_test_data: dict[str, SampleTable]):\n        logger.info(\"test lookup entries\")\n\n        _looked_up = set()\n        for _entry in self.orm_inst.orm_select_all_with_pagination(\n            batch_size=SELECT_ALL_BATCH_SIZE\n        ):\n            assert setup_test_data[_entry.prim_key] == _entry\n            _looked_up.add(_entry)\n\n        assert len(_looked_up) == len(setup_test_data)\n        assert all(_entry in _looked_up for _entry in setup_test_data.values())"
            },
            "tests/test_e2e/test_orm.py::TestWithSampleDB::test_delete_entries": {
                "testid": "tests/test_e2e/test_orm.py::TestWithSampleDB::test_delete_entries",
                "result": "passed",
                "test_implementation": "    def test_delete_entries(\n        self,\n        setup_test_data: dict[str, SampleTable],\n        entries_to_remove: list[SampleTable],\n    ):\n        logger.info(\"test remove and confirm the removed entries\")\n        if SQLITE3_COMPILE_OPTION_FLAGS.RETURNING_AVAILABLE:\n            logger.warning(\n                (\n                    \"Current runtime sqlite3 lib version doesn't support RETURNING statement:\"\n                    f\"{sqlite3.sqlite_version_info=}, needs 3.35 and above. \"\n                    \"The test of RETURNING statement will be skipped here.\"\n                )\n            )\n\n            for entry in entries_to_remove:\n                _res = self.orm_inst.orm_delete_entries(\n                    SampleTableCols(\n                        key_id=entry.key_id,\n                        prim_key_sha256hash=entry.prim_key_sha256hash,\n                    ),\n                    # NOTE(20241230): limit on update/delete requires compile flag SQLITE_ENABLE_UPDATE_DELETE_LIMIT enabled,\n                    #   which is not set to be enabled by default. See https://www.sqlite.org/compile.html for more details.\n                    # _limit=1,\n                )\n                assert _res == 1\n        else:\n            for entry in entries_to_remove:\n                _res = self.orm_inst.orm_delete_entries_with_returning(\n                    SampleTableCols(\n                        key_id=entry.key_id,\n                        prim_key_sha256hash=entry.prim_key_sha256hash,\n                    ),\n                    _returning_cols=\"*\",\n                    # _limit=1,\n                )\n                assert isinstance(_res, Generator)\n\n                _res = list(_res)\n                assert len(_res) == 1\n                assert _res[0] == entry\n\n        logger.info(\"confirm the remove\")\n        sql_stmt = self.orm_inst.orm_table_spec.table_select_stmt(\n            select_from=self.orm_inst.orm_table_name,\n            function=\"count\",\n        )\n\n        res = self.orm_inst.orm_execute(sql_stmt, row_factory=None)\n        assert res and res[0][0] == len(setup_test_data) - len(entries_to_remove)"
            },
            "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_create_table": {
                "testid": "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_create_table",
                "result": "passed",
                "test_implementation": "    def test_create_table(self, thread_pool: SampleDBConnectionPool):\n        logger.info(\"test create table\")\n        thread_pool.orm_create_table(without_rowid=True)"
            },
            "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_insert_entries_with_pool": {
                "testid": "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_insert_entries_with_pool",
                "result": "passed",
                "test_implementation": "    def test_insert_entries_with_pool(\n        self,\n        thread_pool: SampleDBConnectionPool,\n        setup_test_data: dict[str, SampleTable],\n    ):\n        logger.info(\"test insert entries...\")\n\n        # simulating multiple worker threads submitting to database with access serialized.\n        with ThreadPoolExecutor(max_workers=WORKER_NUM) as pool:\n            _batch_count = 0\n            for _batch_count, entry in enumerate(\n                batched(setup_test_data.values(), TEST_INSERT_BATCH_SIZE),\n                start=1,\n            ):\n                pool.submit(thread_pool.orm_insert_entries, entry)\n\n            logger.info(\n                f\"all insert tasks are dispatched: {_batch_count} batches with {TEST_INSERT_BATCH_SIZE=}\"\n            )\n\n        logger.info(\"confirm data written\")\n        _selected_entry_count = 0\n        for _selected_entry_count, _entry in enumerate(\n            thread_pool.orm_select_entries(), start=1\n        ):\n            _corresponding_item = setup_test_data[_entry.prim_key]\n            assert _corresponding_item == _entry\n        assert _selected_entry_count == len(setup_test_data)"
            },
            "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_create_index": {
                "testid": "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_create_index",
                "result": "passed",
                "test_implementation": "    def test_create_index(self, thread_pool: SampleDBConnectionPool):\n        logger.info(\"test create index\")\n        thread_pool.orm_create_index(\n            index_name=INDEX_NAME,\n            index_keys=INDEX_KEYS,\n            unique=True,\n        )"
            },
            "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_orm_execute": {
                "testid": "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_orm_execute",
                "result": "passed",
                "test_implementation": "    def test_orm_execute(\n        self,\n        thread_pool: SampleDBConnectionPool,\n        setup_test_data: dict[str, SampleTable],\n    ):\n        logger.info(\"test orm_execute to check inserted entries num\")\n        sql_stmt = thread_pool.orm_table_spec.table_select_stmt(\n            select_from=thread_pool.orm_table_name,\n            function=\"count\",\n        )\n        res: list[tuple[int]] = thread_pool.orm_execute(sql_stmt)\n\n        assert res and res[0][0] == len(setup_test_data)"
            },
            "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_lookup_entries": {
                "testid": "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_lookup_entries",
                "result": "passed",
                "test_implementation": "    def test_lookup_entries(\n        self, thread_pool: SampleDBConnectionPool, entries_to_lookup: list[SampleTable]\n    ):\n        logger.info(\"test lookup entries\")\n        for _entry in entries_to_lookup:\n            _looked_up = thread_pool.orm_select_entries(\n                SampleTableCols(\n                    key_id=_entry.key_id,\n                    prim_key_sha256hash=_entry.prim_key_sha256hash,\n                ),\n            )\n            _looked_up = list(_looked_up)\n            assert len(_looked_up) == 1\n            assert _looked_up[0] == _entry"
            },
            "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_caller_exits_when_lookup_entries": {
                "testid": "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_caller_exits_when_lookup_entries",
                "result": "passed",
                "test_implementation": "    def test_caller_exits_when_lookup_entries(\n        self, thread_pool: SampleDBConnectionPool\n    ):\n        class _StopAt(Exception): ...\n\n        def _wrapper():\n            _stop_at = random.randrange(TEST_ENTRY_NUM // 2, TEST_ENTRY_NUM)\n\n            _count = 0\n            for _entry in thread_pool.orm_select_entries():\n                _count += 1\n                if _count >= _stop_at:\n                    logger.info(\"break here!\")\n                    raise _StopAt(\"stop as expected\")\n                yield _entry\n\n        with pytest.raises(_StopAt):\n            for _ in _wrapper():\n                ...\n        logger.info(\"do breakout!\")"
            },
            "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_in_thread_raise_exceptions_when_lookup_entries": {
                "testid": "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_in_thread_raise_exceptions_when_lookup_entries",
                "result": "passed",
                "test_implementation": "    def test_in_thread_raise_exceptions_when_lookup_entries(\n        self, thread_pool: SampleDBConnectionPool\n    ):\n        _origin_lookup_entries = SampleDB.orm_select_entries\n        _stop_at = random.randrange(TEST_ENTRY_NUM // 2, TEST_ENTRY_NUM)\n\n        class _StopAt(Exception): ...\n\n        def _mocked_select_entries(*args, **kwargs):\n            for _count, _entry in enumerate(_origin_lookup_entries(*args, **kwargs)):\n                if _count >= _stop_at:\n                    raise _StopAt(\"stop as expected\")\n                yield _entry\n\n        # NOTE: bound the wrapped to thread_pool\n        _wrapped_mocked_select_entries = _wrap_generator_with_thread_ctx(\n            _mocked_select_entries\n        ).__get__(thread_pool)\n\n        with pytest.raises(_StopAt):\n            for _ in _wrapped_mocked_select_entries():\n                ..."
            },
            "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_delete_entries": {
                "testid": "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_delete_entries",
                "result": "passed",
                "test_implementation": "    def test_delete_entries(\n        self, thread_pool: SampleDBConnectionPool, entries_to_remove: list[SampleTable]\n    ):\n        logger.info(\"test remove and confirm the removed entries\")\n        if SQLITE3_COMPILE_OPTION_FLAGS.RETURNING_AVAILABLE:\n            logger.warning(\n                (\n                    \"Current runtime sqlite3 lib version doesn't support RETURNING statement:\"\n                    f\"{sqlite3.sqlite_version_info=}, needs 3.35 and above. \"\n                    \"The test of RETURNING statement will be skipped here.\"\n                )\n            )\n\n            for entry in entries_to_remove:\n                _res = thread_pool.orm_delete_entries(\n                    SampleTableCols(\n                        key_id=entry.key_id,\n                        prim_key_sha256hash=entry.prim_key_sha256hash,\n                    ),\n                    # _limit=1,\n                )\n                assert _res == 1\n        else:\n            for entry in entries_to_remove:\n                _res = thread_pool.orm_delete_entries_with_returning(\n                    SampleTableCols(\n                        key_id=entry.key_id,\n                        prim_key_sha256hash=entry.prim_key_sha256hash,\n                    ),\n                    _returning_cols=\"*\",\n                    # _limit=1,\n                )\n                _res_list = list(_res)\n\n                assert len(_res_list) == 1\n                assert _res_list[0] == entry"
            },
            "tests/test_e2e/test_threadpool_orm.py::TestORMPoolShutdown::test_orm_pool_shutdown": {
                "testid": "tests/test_e2e/test_threadpool_orm.py::TestORMPoolShutdown::test_orm_pool_shutdown",
                "result": "passed",
                "test_implementation": "    def test_orm_pool_shutdown(self, _orm_pool: SampleDBConnectionPool):\n        _event = threading.Event()\n\n        # insert random workloads\n        for _id in range(_THREADS * 10):\n            _orm_pool._pool.submit(self._workload, _id, _event)\n        _event.set()\n        logger.info(\"workloads are all dispatched, now shutdown pool ...\")\n\n        _orm_pool.orm_pool_shutdown(wait=True, close_connections=True)\n        assert not _orm_pool._thread_id_orms"
            },
            "tests/test_utils.py::test_pragma_enable_helpers[enable_wal_mode-args0-kwargs0]": {
                "testid": "tests/test_utils.py::test_pragma_enable_helpers[enable_wal_mode-args0-kwargs0]",
                "result": "passed",
                "test_implementation": "def test_pragma_enable_helpers(func, args, kwargs):\n    with sqlite3.connect(\":memory:\") as conn:\n        func(conn, *args, **kwargs)"
            },
            "tests/test_utils.py::test_pragma_enable_helpers[enable_wal_mode-args1-kwargs1]": {
                "testid": "tests/test_utils.py::test_pragma_enable_helpers[enable_wal_mode-args1-kwargs1]",
                "result": "passed",
                "test_implementation": "def test_pragma_enable_helpers(func, args, kwargs):\n    with sqlite3.connect(\":memory:\") as conn:\n        func(conn, *args, **kwargs)"
            },
            "tests/test_utils.py::test_pragma_enable_helpers[enable_tmp_store_at_memory-args2-kwargs2]": {
                "testid": "tests/test_utils.py::test_pragma_enable_helpers[enable_tmp_store_at_memory-args2-kwargs2]",
                "result": "passed",
                "test_implementation": "def test_pragma_enable_helpers(func, args, kwargs):\n    with sqlite3.connect(\":memory:\") as conn:\n        func(conn, *args, **kwargs)"
            },
            "tests/test_utils.py::test_pragma_enable_helpers[enable_mmap-args3-kwargs3]": {
                "testid": "tests/test_utils.py::test_pragma_enable_helpers[enable_mmap-args3-kwargs3]",
                "result": "passed",
                "test_implementation": "def test_pragma_enable_helpers(func, args, kwargs):\n    with sqlite3.connect(\":memory:\") as conn:\n        func(conn, *args, **kwargs)"
            },
            "tests/test_utils.py::test_pragma_enable_helpers[enable_mmap-args4-kwargs4]": {
                "testid": "tests/test_utils.py::test_pragma_enable_helpers[enable_mmap-args4-kwargs4]",
                "result": "passed",
                "test_implementation": "def test_pragma_enable_helpers(func, args, kwargs):\n    with sqlite3.connect(\":memory:\") as conn:\n        func(conn, *args, **kwargs)"
            },
            "tests/test_utils.py::test_pragma_enable_helpers[optimize_db-args5-kwargs5]": {
                "testid": "tests/test_utils.py::test_pragma_enable_helpers[optimize_db-args5-kwargs5]",
                "result": "passed",
                "test_implementation": "def test_pragma_enable_helpers(func, args, kwargs):\n    with sqlite3.connect(\":memory:\") as conn:\n        func(conn, *args, **kwargs)"
            },
            "tests/test_utils.py::test_check_db_integrity": {
                "testid": "tests/test_utils.py::test_check_db_integrity",
                "result": "passed",
                "test_implementation": "def test_check_db_integrity():\n    with sqlite3.connect(\":memory:\") as conn:\n        with conn:\n            conn.execute(\n                \"CREATE TABLE test_table (key TEXT PRIMARY KEY) WITHOUT ROWID;\"\n            )\n            conn.execute(\"INSERT INTO test_table (key) VALUES (?)\", (\"aaabbbccc\",))\n\n        check_db_integrity(conn)\n        check_db_integrity(conn, table_name=\"test_table\")"
            },
            "tests/test_utils.py::test_lookup_table": {
                "testid": "tests/test_utils.py::test_lookup_table",
                "result": "passed",
                "test_implementation": "def test_lookup_table():\n    with sqlite3.connect(\":memory:\") as conn:\n        table_name = \"test_table\"\n        with conn:\n            conn.execute(\n                f\"CREATE TABLE {table_name} (key TEXT PRIMARY KEY) WITHOUT ROWID;\"\n            )\n\n        assert lookup_table(conn, table_name)"
            },
            "tests/test_utils.py::test_checkpragma_compile_time_options": {
                "testid": "tests/test_utils.py::test_checkpragma_compile_time_options",
                "result": "passed",
                "test_implementation": "def test_checkpragma_compile_time_options():\n    with sqlite3.connect(\":memory:\") as conn:\n        logger.info(f\"runtime sqlite3 library version: {sqlite3.sqlite_version}\")\n\n        compile_time_options = check_pragma_compile_time_options(conn)\n        logger.info(f\"all options: {compile_time_options}\")\n        assert compile_time_options\n\n        threadsafe_level = check_pragma_compile_time_options(conn, \"THREADSAFE\")\n        logger.info(f\"THREADSAFE: {threadsafe_level}\")\n        assert threadsafe_level is not None"
            },
            "tests/test_utils.py::test_gen_check_constrain[Choice123-test_field IN (1,2,3)]": {
                "testid": "tests/test_utils.py::test_gen_check_constrain[Choice123-test_field IN (1,2,3)]",
                "result": "passed",
                "test_implementation": "def test_gen_check_constrain(_in, expected):\n    if isinstance(expected, Exception):\n        with pytest.raises(type(expected)):\n            gen_check_constrain(_in, FIELD_NAME)\n    else:\n        assert gen_check_constrain(_in, FIELD_NAME) == expected"
            },
            "tests/test_utils.py::test_gen_check_constrain[ChoiceABC-test_field IN (\"A\",\"B\",\"C\")]": {
                "testid": "tests/test_utils.py::test_gen_check_constrain[ChoiceABC-test_field IN (\"A\",\"B\",\"C\")]",
                "result": "passed",
                "test_implementation": "def test_gen_check_constrain(_in, expected):\n    if isinstance(expected, Exception):\n        with pytest.raises(type(expected)):\n            gen_check_constrain(_in, FIELD_NAME)\n    else:\n        assert gen_check_constrain(_in, FIELD_NAME) == expected"
            },
            "tests/test_utils.py::test_gen_check_constrain[Literal-test_field IN (123,456,789)]": {
                "testid": "tests/test_utils.py::test_gen_check_constrain[Literal-test_field IN (123,456,789)]",
                "result": "passed",
                "test_implementation": "def test_gen_check_constrain(_in, expected):\n    if isinstance(expected, Exception):\n        with pytest.raises(type(expected)):\n            gen_check_constrain(_in, FIELD_NAME)\n    else:\n        assert gen_check_constrain(_in, FIELD_NAME) == expected"
            },
            "tests/test_utils.py::test_gen_check_constrain[Literal-test_field IN (\"H\",\"I\",\"J\")]": {
                "testid": "tests/test_utils.py::test_gen_check_constrain[Literal-test_field IN (\"H\",\"I\",\"J\")]",
                "result": "passed",
                "test_implementation": "def test_gen_check_constrain(_in, expected):\n    if isinstance(expected, Exception):\n        with pytest.raises(type(expected)):\n            gen_check_constrain(_in, FIELD_NAME)\n    else:\n        assert gen_check_constrain(_in, FIELD_NAME) == expected"
            },
            "tests/test_utils.py::test_gen_check_constrain[_in4-expected4]": {
                "testid": "tests/test_utils.py::test_gen_check_constrain[_in4-expected4]",
                "result": "passed",
                "test_implementation": "def test_gen_check_constrain(_in, expected):\n    if isinstance(expected, Exception):\n        with pytest.raises(type(expected)):\n            gen_check_constrain(_in, FIELD_NAME)\n    else:\n        assert gen_check_constrain(_in, FIELD_NAME) == expected"
            },
            "tests/test_utils.py::test_gen_check_constrain[NoneType-expected5]": {
                "testid": "tests/test_utils.py::test_gen_check_constrain[NoneType-expected5]",
                "result": "passed",
                "test_implementation": "def test_gen_check_constrain(_in, expected):\n    if isinstance(expected, Exception):\n        with pytest.raises(type(expected)):\n            gen_check_constrain(_in, FIELD_NAME)\n    else:\n        assert gen_check_constrain(_in, FIELD_NAME) == expected"
            },
            "tests/test_utils.py::test_concatenate_condition[stmts0-True-(column IS NULL OR column IN (1,2,3))]": {
                "testid": "tests/test_utils.py::test_concatenate_condition[stmts0-True-(column IS NULL OR column IN (1,2,3))]",
                "result": "passed",
                "test_implementation": "def test_concatenate_condition(stmts, with_parenthese, expected):\n    assert (\n        concatenate_condition(*stmts, wrapped_with_parentheses=with_parenthese)\n        == expected\n    )"
            },
            "tests/test_utils.py::test_concatenate_condition[stmts1-False-column IS NULL OR column IN (1,2,3)]": {
                "testid": "tests/test_utils.py::test_concatenate_condition[stmts1-False-column IS NULL OR column IN (1,2,3)]",
                "result": "passed",
                "test_implementation": "def test_concatenate_condition(stmts, with_parenthese, expected):\n    assert (\n        concatenate_condition(*stmts, wrapped_with_parentheses=with_parenthese)\n        == expected\n    )"
            },
            "tests/test_utils.py::test_wrap_value[123-123]": {
                "testid": "tests/test_utils.py::test_wrap_value[123-123]",
                "result": "passed",
                "test_implementation": "def test_wrap_value(value, expected):\n    assert wrap_value(value) == expected"
            },
            "tests/test_utils.py::test_wrap_value[123.456-123.456]": {
                "testid": "tests/test_utils.py::test_wrap_value[123.456-123.456]",
                "result": "passed",
                "test_implementation": "def test_wrap_value(value, expected):\n    assert wrap_value(value) == expected"
            },
            "tests/test_utils.py::test_wrap_value[a_string-\"a_string\"]": {
                "testid": "tests/test_utils.py::test_wrap_value[a_string-\"a_string\"]",
                "result": "passed",
                "test_implementation": "def test_wrap_value(value, expected):\n    assert wrap_value(value) == expected"
            },
            "tests/test_utils.py::test_wrap_value[None-NULL]": {
                "testid": "tests/test_utils.py::test_wrap_value[None-NULL]",
                "result": "passed",
                "test_implementation": "def test_wrap_value(value, expected):\n    assert wrap_value(value) == expected"
            },
            "tests/test_utils.py::test_wrap_value[\\x124Vx\\x90\\xaa\\xbb\\xcc-x'1234567890aabbcc']": {
                "testid": "tests/test_utils.py::test_wrap_value[\\x124Vx\\x90\\xaa\\xbb\\xcc-x'1234567890aabbcc']",
                "result": "passed",
                "test_implementation": "def test_wrap_value(value, expected):\n    assert wrap_value(value) == expected"
            },
            "tests/test_utils.py::test_wrap_value[Choice123.ONE-1]": {
                "testid": "tests/test_utils.py::test_wrap_value[Choice123.ONE-1]",
                "result": "passed",
                "test_implementation": "def test_wrap_value(value, expected):\n    assert wrap_value(value) == expected"
            },
            "tests/test_utils.py::test_wrap_value[A-\"A\"]": {
                "testid": "tests/test_utils.py::test_wrap_value[A-\"A\"]",
                "result": "passed",
                "test_implementation": "def test_wrap_value(value, expected):\n    assert wrap_value(value) == expected"
            },
            "tests/test_utils.py::test_gen_sql_stmt[components0-\\n-WHERE id = :check_id AND type <> 'A']": {
                "testid": "tests/test_utils.py::test_gen_sql_stmt[components0-\\n-WHERE id = :check_id AND type <> 'A']",
                "result": "passed",
                "test_implementation": "def test_gen_sql_stmt(components, end_with, expected):\n    if end_with is _not_set:\n        assert gen_sql_stmt(*components) == expected\n    else:\n        assert gen_sql_stmt(*components, end_with=end_with) == expected"
            },
            "tests/test_utils.py::test_gen_sql_stmt[components1-end_with1-SELECT count(*) FROM some_table;]": {
                "testid": "tests/test_utils.py::test_gen_sql_stmt[components1-end_with1-SELECT count(*) FROM some_table;]",
                "result": "passed",
                "test_implementation": "def test_gen_sql_stmt(components, end_with, expected):\n    if end_with is _not_set:\n        assert gen_sql_stmt(*components) == expected\n    else:\n        assert gen_sql_stmt(*components, end_with=end_with) == expected"
            }
        },
        "SRS_document": "# Software Requirements Specification: Simple Python SQLite3 ORM\n\n## Table of Contents\n1.  [Introduction](#1-introduction)\n    1.1. [Purpose](#11-purpose)\n    1.2. [Scope](#12-scope)\n    1.3. [Definitions, Acronyms, and Abbreviations](#13-definitions-acronyms-and-abbreviations)\n    1.4. [References](#14-references)\n    1.5. [Overview](#15-overview)\n2.  [Overall Description](#2-overall-description)\n    2.1. [Product Perspective](#21-product-perspective)\n    2.2. [Product Features](#22-product-features)\n    2.3. [User Classes and Characteristics](#23-user-classes-and-characteristics)\n    2.4. [Operating Environment](#24-operating-environment)\n    2.5. [Design and Implementation Constraints](#25-design-and-implementation-constraints)\n    2.6. [Assumptions and Dependencies](#26-assumptions-and-dependencies)\n3.  [Specific Requirements](#3-specific-requirements)\n    3.1. [Functional Requirements](#31-functional-requirements)\n        3.1.1. [Table Definition and Schema Management](#311-table-definition-and-schema-management)\n        3.1.2. [Data Type Handling](#312-data-type-handling)\n        3.1.3. [Data Serialization and Deserialization](#313-data-serialization-and-deserialization)\n        3.1.4. [SQL Statement Generation](#314-sql-statement-generation)\n        3.1.5. [ORM Core Operations](#315-orm-core-operations)\n        3.1.6. [ORM Concurrency Support](#316-orm-concurrency-support)\n        3.1.7. [Utility Functions](#317-utility-functions)\n    3.2. [Non-Functional Requirements](#32-non-functional-requirements)\n        3.2.1. [Performance](#321-performance)\n\n## 1. Introduction\n\n### 1.1. Purpose\nThis Software Requirements Specification (SRS) document defines the requirements for a Simple Python SQLite3 Object-Relational Mapper (ORM). Its primary role is to serve as the sole source of requirements for software developers who will be assessed on their ability to design and implement a complete, functional software project based on this SRS. The assessment will be measured by passing a comprehensive set of public and private test cases.\n\n### 1.2. Scope\nThe software, hereafter referred to as \"the System,\" is a Python library providing ORM capabilities for SQLite3 databases. The scope includes:\n*   Defining database table schemas as Python classes.\n*   Mapping Python data types to SQLite storage classes and type affinities.\n*   Generating SQL statements for table creation, index creation, and CRUD (Create, Read, Update, Delete) operations.\n*   Executing CRUD operations via an ORM layer.\n*   Handling data serialization from Python objects to database-compatible formats and deserialization from database results to Python objects.\n*   Providing support for concurrent and asynchronous database operations through connection pooling.\n*   Offering utility functions for common SQLite operations and configurations.\n\nThe System is intended to be lightweight, relying on Python's standard `sqlite3` module and `pydantic` for data validation and settings management.\n\n### 1.3. Definitions, Acronyms, and Abbreviations\n*   **ORM**: Object-Relational Mapper\n*   **SRS**: Software Requirements Specification\n*   **SQL**: Structured Query Language\n*   **CRUD**: Create, Read, Update, Delete\n*   **API**: Application Programming Interface\n*   **WAL**: Write-Ahead Logging\n*   **FR**: Functional Requirement\n*   **NFR**: Non-Functional Requirement\n*   **TableSpec**: A base class provided by the ORM for defining table schemas.\n*   **ORMBase**: A base class provided by the ORM for database interaction logic.\n\n### 1.4. References\n*   Original README.md (for contextual understanding)\n*   Original source code (for contextual understanding by the LLM generating this SRS)\n*   Original test case implementations (for deriving requirements and test traceability)\n\n### 1.5. Overview\nThis document is organized into three main sections:\n*   **Section 1 (Introduction):** Provides background, scope, and definitions.\n*   **Section 2 (Overall Description):** Describes the general factors affecting the product and its requirements, such as product perspective, features, and operating environment.\n*   **Section 3 (Specific Requirements):** Details all functional and non-functional requirements. Functional requirements are grouped by capability. Each requirement is uniquely identified and, where applicable, traced to original test cases and source code areas.\n\n## 2. Overall Description\n\n### 2.1. Product Perspective\nThe System is a Python library that acts as an abstraction layer over the standard `sqlite3` database engine. It aims to simplify database interactions by allowing developers to work with Python objects and classes rather than writing raw SQL for common operations. It leverages `pydantic` for robust data modeling and validation. The System is designed to be a dependency that can be integrated into larger Python applications requiring SQLite database persistence.\n\n### 2.2. Product Features\nThe major features of the System include:\n*   **Schema Definition as Code:** Users can define their database table structures using Python classes.\n*   **Type Safety and Validation:** Leverages `pydantic` for defining data models with type hints and validation.\n*   **Automatic SQL Generation:** Generates SQL for table/index creation and CRUD operations.\n*   **CRUD Operations:** Provides a simple API for creating, reading, updating, and deleting database records.\n*   **Data Type Mapping:** Supports a range of Python types, including standard types, Enums, Literals, Optionals, and custom datetime representations, mapping them to appropriate SQLite types.\n*   **Customizable Serialization/Deserialization:** Allows flexible data handling between Python objects and database storage.\n*   **Concurrency Support:** Offers thread-pooled and asyncio-compatible ORM variants for concurrent applications.\n*   **SQLite Utilities:** Includes helper functions for common SQLite configurations and operations.\n\n### 2.3. User Classes and Characteristics\nThe primary users of this System are Python developers who need to integrate SQLite database functionality into their applications. They are expected to be familiar with Python programming, basic SQL concepts, and the `pydantic` library. They will use the System to define data models, manage database schema, and perform data persistence operations.\n\n### 2.4. Operating Environment\n*   The System is a Python library and requires a Python 3.8+ environment.\n*   It depends on the `pydantic` and `typing_extensions` libraries.\n*   It interacts with an SQLite3 database engine, typically provided by Python's built-in `sqlite3` module.\n\n### 2.5. Design and Implementation Constraints\n*   The implementation must be based solely on this SRS document.\n*   The System should aim to be lightweight, minimizing external dependencies beyond `pydantic` and `typing_extensions`.\n*   Internal implementation details (specific class names, private methods, algorithms) are left to the developer, provided the external behavior matches this SRS. However, the conceptual separation of concerns (e.g., a table specification component, an ORM interaction component) is implied by the described functionalities.\n\n### 2.6. Assumptions and Dependencies\n*   Developers have access to a Python 3.8+ environment with `sqlite3` support.\n*   The `pydantic` library's behavior for model definition, validation, and serialization/deserialization is a fundamental dependency.\n*   The underlying SQLite database behaves according to standard SQL and SQLite-specific features (e.g., PRAGMAs, type affinities).\n\n## 3. Specific Requirements\n\n### 3.1. Functional Requirements\n\n#### 3.1.1. Table Definition and Schema Management\n\n**FR-TDEF-001:** The system shall allow users to define a database table schema by creating a Python class that inherits from a provided base table specification class.\n\n**FR-TDEF-002:** The system shall support the specification of table column names and their corresponding Python types as attributes of the table definition class.\n\n**FR-TDEF-003:** The system shall automatically map common Python types (int, float, str, bytes, None) and supported custom types (Enums, Literals, Optionals) to their corresponding SQLite type affinities (INTEGER, REAL, TEXT, BLOB, NULL) during schema generation.\n\n**FR-TDEF-004:** The system shall allow users to explicitly specify the SQLite type affinity for a column, overriding the default mapping derived from its Python type.\n\n**FR-TDEF-005:** The system shall support the definition of standard SQL column constraints, including `PRIMARY KEY`, `NOT NULL`, `UNIQUE`, `CHECK`, `DEFAULT`, `COLLATE`, and `REFERENCES`, as part of a column's specification.\n\n**FR-TDEF-006:** The system shall be able to generate a SQL `CREATE TABLE` statement based on a defined table schema.\n\n**FR-TDEF-007:** The system shall support `CREATE TABLE` options `IF NOT EXISTS`, `STRICT`, `TEMPORARY`, and `WITHOUT ROWID` in the generated statements.\n\n**FR-TDEF-008:** The system shall be able to generate a SQL `CREATE INDEX` statement for a given table.\n\n**FR-TDEF-009:** The system shall support `CREATE INDEX` options including `IF NOT EXISTS`, `UNIQUE`, and the specification of one or more indexed columns with optional sort order (`ASC` or `DESC`) for each.\n\n**FR-TDEF-010:** The system shall provide a mechanism to retrieve the Pydantic `FieldInfo` for a specified column name from a table definition, raising an error if the column is not defined.\n\n**FR-TDEF-011:** The system shall provide a mechanism to validate if a given tuple of column names exists within the table definition, raising an error if any column is not defined.\n\n**FR-TDEF-012:** The system shall generate the column definition string (e.g., \"column_name TEXT NOT NULL\") for a table creation statement based on its name, type affinity, and constraints.\n\n#### 3.1.2. Data Type Handling\n\n**FR-TYPE-001:** The system shall support native Python types `int`, `float`, `str`, `bytes`, and `None` for column definitions, mapping them to `INTEGER`, `REAL`, `TEXT`, `BLOB`, and `NULL` SQLite type affinities respectively.\n\n**FR-TYPE-002:** The system shall support `enum.IntEnum` and `enum.StrEnum` types for column definitions, mapping them to `INTEGER` and `TEXT` SQLite type affinities respectively. Values shall be stored as the underlying integer or string.\n\n**FR-TYPE-003:** The system shall support `typing.Literal` types (for string and integer literals) for column definitions, mapping them to appropriate SQLite type affinities (`TEXT` or `INTEGER`). Values shall be stored as the underlying literal value.\n\n**FR-TYPE-004:** The system shall support `typing.Optional[T]` for column definitions, where `T` is any other supported type, allowing the column to store `NULL` values. The SQLite type affinity will be determined by `T`.\n\n**FR-TYPE-005:** The system shall provide a custom type `DatetimeUnixTimestamp` for representing `datetime.datetime` objects, which are serialized to a floating-point Unix timestamp (seconds since epoch) for storage as `REAL` in SQLite, and deserialized from `REAL` back to `datetime.datetime`.\n\n**FR-TYPE-006:** The system shall provide a custom type `DatetimeUnixTimestampInt` for representing `datetime.datetime` objects, which are serialized to an integer Unix timestamp (seconds since epoch) for storage as `INTEGER` in SQLite, and deserialized from `INTEGER` back to `datetime.datetime`.\n\n**FR-TYPE-007:** The system shall provide a custom type `DatetimeISO8601` for representing `datetime.datetime` objects, which are serialized to an ISO 8601 formatted string for storage as `TEXT` in SQLite, and deserialized from `TEXT` back to `datetime.datetime`.\n\n**FR-TYPE-008:** The system shall allow columns to be defined with user-defined Python types that have custom Pydantic serializers and deserializers, enabling flexible mapping to fundamental SQLite storage types (e.g., mapping an `int` field to be stored as `TEXT` via custom logic).\n\n#### 3.1.3. Data Serialization and Deserialization\n\n**FR-SERDE-001:** The system shall serialize model instances (representing table rows) into Python dictionaries where values are formatted suitable for SQLite database operations (e.g., enums to their values, datetimes to their storable representations). Users can specify which columns to include.\n\n**FR-SERDE-002:** The system shall serialize model instances (representing table rows) into Python tuples where values are formatted suitable for SQLite database operations. Users can specify which columns to include and in what order.\n\n**FR-SERDE-003:** The system shall deserialize SQLite result rows (represented as Python tuples) into corresponding model instances, with an option to enable or disable Pydantic validation during instantiation. This expects the tuple elements to match the table schema's column order.\n\n**FR-SERDE-004:** The system shall deserialize SQLite result rows (represented as Python dictionaries where keys are column names) into corresponding model instances, with an option to enable or disable Pydantic validation.\n\n**FR-SERDE-005:** The system shall provide a general row factory suitable for `sqlite3.Cursor.row_factory`. This factory shall convert raw SQLite result tuples into model instances if the result columns match the model's schema, or return the raw tuple otherwise (e.g., for function call results). Validation is enabled by default.\n\n**FR-SERDE-006:** The system shall provide a specialized row factory (`table_row_factory2` behavior) suitable for `sqlite3.Cursor.row_factory`. This factory shall convert raw SQLite result tuples into model instances by mapping known columns from the result to model fields and ignoring unknown columns. Validation is enabled by default.\n\n**FR-SERDE-007:** The system shall provide a row factory suitable for `sqlite3.Cursor.row_factory` that deserializes selected columns from a query result into a Python dictionary. It shall apply type deserialization for columns defined in the table schema and preserve values for unknown columns (e.g., aliased columns or function results) as is.\n\n**FR-SERDE-008:** The system shall provide a row factory suitable for `sqlite3.Cursor.row_factory` that deserializes selected columns from a query result into a Python tuple. It shall apply type deserialization for columns defined in the table schema and preserve values for unknown columns as is.\n\n**FR-SERDE-009:** The system shall serialize Python dictionaries representing partial or full rows (where values are application-level Python types) into new dictionaries where values are formatted suitable for SQLite database operations.\n\n**FR-SERDE-010:** The system shall allow direct export of a model instance's attributes as a Python dictionary without applying database-specific serialization logic to the values. Users can specify which columns to include.\n\n#### 3.1.4. SQL Statement Generation\n\n**FR-SQLGEN-001:** The system shall generate SQL `INSERT` statements for a specified table.\n\n**FR-SQLGEN-002:** Generated `INSERT` statements shall support: specifying a subset of columns for insertion, inserting default values for all columns, `OR conflict_resolution` clauses (e.g., `OR IGNORE`, `OR REPLACE`), and a `RETURNING` clause to return specified columns from the inserted row.\n\n**FR-SQLGEN-003:** The system shall generate SQL `SELECT` statements for a specified table.\n\n**FR-SQLGEN-004:** Generated `SELECT` statements shall support: selection of all columns (`*`) or a specified list of columns/expressions, application of SQL functions (e.g., `COUNT`) to selected columns, `DISTINCT` keyword, `WHERE` clause (generated from column name placeholders or a custom string), `GROUP BY` clause, `ORDER BY` clause (with column and direction), and `LIMIT` clause.\n\n**FR-SQLGEN-005:** The system shall generate SQL `UPDATE` statements for a specified table.\n\n**FR-SQLGEN-006:** Generated `UPDATE` statements shall support: `OR conflict_resolution` clauses, specifying columns to `SET` with named placeholders, `WHERE` clause (generated from column name placeholders or a custom string), `RETURNING` clause, `ORDER BY` clause, and `LIMIT` clause (where SQLite version supports it for UPDATE).\n\n**FR-SQLGEN-007:** The system shall ensure that named placeholders for `WHERE` clause parameters in generated `UPDATE` statements are distinct from named placeholders for `SET` clause parameters to avoid clashes when providing parameters for execution. A specific prefix shall be used for `WHERE` clause placeholders.\n\n**FR-SQLGEN-008:** The system shall generate SQL `DELETE` statements for a specified table.\n\n**FR-SQLGEN-009:** Generated `DELETE` statements shall support: `WHERE` clause (generated from column name placeholders or a custom string), `ORDER BY` clause, `LIMIT` clause (where SQLite version supports it for DELETE), and `RETURNING` clause.\n\n**FR-SQLGEN-010:** The system shall generate SQL `SELECT` statements for retrieving all entries from a table, with support for pagination using `LIMIT` and `OFFSET`, and optional ordering.\n\n#### 3.1.5. ORM Core Operations\n\n**FR-ORM-001:** The system shall allow initialization of an ORM instance with a `sqlite3.Connection` object (or a factory callable returning one) and a reference to the table specification class.\n\n**FR-ORM-002:** The system shall allow overriding the default table name (defined in the ORM class) by providing a `table_name` argument during ORM instance initialization.\n\n**FR-ORM-003:** The system shall allow specifying a `schema_name` during ORM instance initialization for use with attached databases, prefixing the table name in generated SQL (e.g., `schema_name.table_name`).\n\n**FR-ORM-004:** The system shall allow specification of a row factory for the `sqlite3.Connection` associated with an ORM instance. This can be set at initialization or modified per query. Supported specifications include: a custom callable, `None` (to clear any existing factory), `sqlite3.Row`, the default model-instantiating factory from the table specification, the same factory but without Pydantic validation, or a directive to not change the current connection's row factory.\n\n**FR-ORM-005:** The system shall provide a method to bootstrap a database, which includes creating the main table and any defined indexes based on class-level ORM configurations (`orm_bootstrap_table_name`, `orm_bootstrap_create_table_params`, `orm_bootstrap_indexes_params`).\n\n**FR-ORM-006:** The system shall provide a method to create the database table associated with the ORM instance, with options to allow an existing table, enable strict mode, or create a table without a rowid.\n\n**FR-ORM-007:** The system shall provide a method to create an index on the associated database table, specifying index name, columns, and options like uniqueness or allowing an existing index.\n\n**FR-ORM-008:** The system shall provide a method to insert a single record, represented by a model instance, into the database table. Conflict resolution options (e.g., `OR IGNORE`) shall be supported.\n\n**FR-ORM-009:** The system shall provide a method to insert a single record, represented by a Python dictionary or mapping, into the database table. Column values in the mapping are application-level types and will be serialized. Conflict resolution options shall be supported.\n\n**FR-ORM-010:** The system shall provide a method to insert multiple records, represented by an iterable of model instances, into the database table in a batch operation. Conflict resolution options shall be supported.\n\n**FR-ORM-011:** The system shall provide a method to insert multiple records, represented by an iterable of Python dictionaries or mappings, into the database table in a batch operation. Column values will be serialized. Conflict resolution options shall be supported.\n\n**FR-ORM-012:** The system shall provide a method to select and retrieve a single record as a model instance from the database table based on specified column-value criteria. If multiple records match, the first one encountered (as per database ordering or `ORDER BY` clause if used) is returned. Returns `None` if no match.\n\n**FR-ORM-013:** The system shall provide a method to select and retrieve multiple records as model instances from the database table based on specified column-value criteria. This method shall support options for `DISTINCT` selection, `ORDER BY`, and `LIMIT`. Results are yielded as a generator.\n\n**FR-ORM-014:** The system shall provide a method to retrieve all records from the database table using pagination, yielding model instances in batches.\n\n**FR-ORM-015:** The system shall provide a method to update existing records in the database table. Records to update are identified by column-value criteria, and new values are provided as a model instance or a Python dictionary/mapping. Conflict resolution options shall be supported.\n\n**FR-ORM-016:** The system shall allow updating records using a custom SQL `WHERE` clause string, with parameter values for this clause supplied via an additional dictionary.\n\n**FR-ORM-017:** The system shall provide a method to update multiple records in a batch (`executemany` style). This method takes iterables of dictionaries for `SET` clause values and iterables of dictionaries for `WHERE` clause values, applying one `SET` and `WHERE` pair per update operation.\n\n**FR-ORM-018:** The batch update method shall support using a custom SQL `WHERE` clause string, where parameter values for this clause are supplied by an iterable of dictionaries (one dictionary per update operation).\n\n**FR-ORM-019:** The batch update method shall support using a custom SQL `WHERE` clause string, where parameter values for this clause are supplied by a single dictionary, applied consistently to all update operations in the batch.\n\n**FR-ORM-020:** The batch update method shall support executing a fully custom user-provided SQL `UPDATE` statement, with parameter values for each operation supplied by an iterable of dictionaries.\n\n**FR-ORM-021:** The system shall provide a method to delete records from the database table based on specified column-value criteria. Options for `ORDER BY` and `LIMIT` shall be supported (where SQLite allows).\n\n**FR-ORM-022:** The system shall provide a method to delete records and, if supported by the SQLite version, return the deleted records (using a `RETURNING` clause). Results are yielded as a generator.\n\n**FR-ORM-023:** The system shall provide a method to check if at least one record exists in the database table matching specified column-value criteria.\n\n**FR-ORM-024:** The system shall provide a method to execute an arbitrary SQL query string with optional parameters and fetch all resulting rows. The row factory for result conversion can be specified.\n\n**FR-ORM-025:** The system shall provide a method to execute an arbitrary SQL query string with optional parameters and yield resulting rows as a generator. The row factory for result conversion can be specified.\n\n**FR-ORM-026:** The system shall provide a method to execute a parameterized DML SQL statement multiple times with an iterable of parameter sets (i.e., `executemany` functionality).\n\n**FR-ORM-027:** The system shall provide a method to execute a SQL script (a string containing multiple SQL statements).\n\n**FR-ORM-028:** The system shall provide access to the underlying `sqlite3.Connection` object associated with an ORM instance, allowing for direct execution of SQL or use of connection methods not exposed by the ORM.\n\n#### 3.1.6. ORM Concurrency Support\n\n**FR-CONCUR-001:** The system shall provide a thread-pooled ORM variant (`ORMThreadPoolBase`) that manages a pool of SQLite connections, allowing multiple ORM operations to be submitted concurrently and executed by worker threads.\n\n**FR-CONCUR-002:** The thread-pooled ORM shall be initialized with a connection factory function and the desired number of connections/worker threads in the pool.\n\n**FR-CONCUR-003:** The thread-pooled ORM shall expose the same core ORM operations (table/index creation, insert, select, update, delete, execute) as the base ORM. Each operation submitted to the thread-pooled ORM shall be executed in one of its worker threads.\n\n**FR-CONCUR-004:** For ORM operations that return a generator of results (e.g., `orm_select_entries`), the thread-pooled ORM variant shall manage yielding these results from the worker thread back to the calling thread. The calling thread shall be able to iterate these results.\n\n**FR-CONCUR-005:** The system shall provide an asyncio-compatible ORM variant (`AsyncORMBase`) that uses an underlying thread pool to execute database operations asynchronously, integrating with Python's `asyncio` event loop.\n\n**FR-CONCUR-006:** The asyncio ORM shall be initialized with a connection factory function and the desired number of connections/worker threads for its underlying thread pool. It must capture the running asyncio event loop at initialization.\n\n**FR-CONCUR-007:** The asyncio ORM shall expose the same core ORM operations as awaitable methods. Each operation shall be executed in the underlying thread pool and its result returned asynchronously.\n\n**FR-CONCUR-008:** For ORM operations that return a generator of results, the asyncio ORM variant shall expose these as async generators. Results shall be yielded from the worker thread back to the asyncio event loop, allowing asynchronous iteration.\n\n**FR-CONCUR-009:** Both thread-pooled and asyncio ORM variants shall provide a method to shut down their underlying connection/thread pool, with options to wait for pending tasks to complete and to close all managed database connections.\n\n#### 3.1.7. Utility Functions\n\n**FR-UTIL-001:** The system shall provide a utility function to enable WAL (Write-Ahead Logging) mode for a given SQLite connection, with an option to also set the synchronous mode to NORMAL.\n\n**FR-UTIL-002:** The system shall provide a utility function to configure the temporary store location to memory (`PRAGMA temp_store = MEMORY`) for a given SQLite connection.\n\n**FR-UTIL-003:** The system shall provide a utility function to enable and configure memory-mapped I/O (`PRAGMA mmap_size`) for a given SQLite connection, with a configurable mmap size.\n\n**FR-UTIL-004:** The system shall provide a utility function to execute `PRAGMA optimize` on a given SQLite connection.\n\n**FR-UTIL-005:** The system shall provide a utility function to perform an integrity check (`PRAGMA integrity_check`) on a given SQLite connection, either for the entire database or for a specified table. The function shall return a boolean indicating success (`ok`).\n\n**FR-UTIL-006:** The system shall provide a utility function to check if a table with a given name exists in the database associated with a SQLite connection.\n\n**FR-UTIL-007:** The system shall provide a utility function to retrieve SQLite compile-time options (`PRAGMA compile_options`) from a given SQLite connection, either all options or a specific one by name.\n\n**FR-UTIL-008:** The system shall provide a utility function to iterate over an iterable in fixed-size chunks (batches), where the last batch may be smaller.\n\n**FR-UTIL-009:** The system shall provide a utility function to generate a SQL `CHECK` constraint string suitable for a given field name, based on an `Enum` type or a `typing.Literal` type (e.g., `field_name IN ('A','B','C')`).\n\n**FR-UTIL-010:** The system shall provide a utility function to concatenate multiple SQL condition components (strings representing conditions or operators like `AND`, `OR`) into a single condition string, with an option to wrap the entire result in parentheses.\n\n**FR-UTIL-011:** The system shall provide a utility function to wrap common Python values (int, float, str, bytes, None, Enum members) into their SQL literal string representations (e.g., strings quoted, bytes as hex literals, NULL for None).\n\n**FR-UTIL-012:** The system shall provide a factory (`ColsSelectFactory`) for creating type-checked tuples of column names. This factory aids in specifying column lists for ORM operations with static type checking and editor completion for column names.\n\n**FR-UTIL-013:** The system shall provide a utility function to combine multiple SQL statements (each potentially ending with a semicolon) into a single valid SQL script string.\n\n**FR-UTIL-014:** The system shall provide a utility function to construct a single SQL statement string from various string components, trimming whitespace and optionally appending a semicolon.\n\n**FR-UTIL-015:** The system shall provide a utility function to attach an additional database file (or an in-memory database) to an existing SQLite connection using a specified schema name.\n\n### 3.2. Non-Functional Requirements\n\n#### 3.2.1. Performance\n\n**NFR-PERF-001:** Asynchronous ORM operations shall not significantly block the Python `asyncio` event loop, allowing other concurrent asyncio tasks to make progress while database operations are pending.\n*   **Description:** This ensures that the use of `AsyncORMBase` maintains the responsiveness of an asyncio application.",
        "structured_requirements": [
            {
                "requirement_id": "FR-TDEF-001",
                "requirement_description": "The system shall allow users to define a database table schema by creating a Python class that inherits from a provided base table specification class.",
                "test_traceability": [
                    {
                        "id": "tests/conftest.py::SimpleTableForTest",
                        "description": "Implicit in"
                    },
                    {
                        "id": "tests/sample_db/table.py::SampleTable",
                        "description": "Implicit in"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-TDEF-002",
                "requirement_description": "The system shall support the specification of table column names and their corresponding Python types as attributes of the table definition class.",
                "test_traceability": [
                    {
                        "id": "tests/conftest.py::SimpleTableForTest",
                        "description": "e.g., `id: int`, `id_str: str`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec",
                        "description": "relies on Pydantic model fields"
                    }
                ]
            },
            {
                "requirement_id": "FR-TDEF-003",
                "requirement_description": "The system shall automatically map common Python types (int, float, str, bytes, None) and supported custom types (Enums, Literals, Optionals) to their corresponding SQLite type affinities (INTEGER, REAL, TEXT, BLOB, NULL) during schema generation.",
                "test_traceability": [
                    {
                        "id": "tests/test__utils.py::test_typeafinityrepr",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_utils.py::map_type",
                        "description": ""
                    },
                    {
                        "id": "src/simple_sqlite3_orm/_utils.py::TypeAffinityRepr",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-TDEF-004",
                "requirement_description": "The system shall allow users to explicitly specify the SQLite type affinity for a column, overriding the default mapping derived from its Python type.",
                "test_traceability": [
                    {
                        "id": "tests/conftest.py::SimpleTableForTest",
                        "description": "field `int_str: Annotated[int, TypeAffinityRepr(str)]`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_utils.py::TypeAffinityRepr",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-TDEF-005",
                "requirement_description": "The system shall support the definition of standard SQL column constraints, including `PRIMARY KEY`, `NOT NULL`, `UNIQUE`, `CHECK`, `DEFAULT`, `COLLATE`, and `REFERENCES`, as part of a column's specification.",
                "test_traceability": [
                    {
                        "id": "tests/conftest.py::SimpleTableForTest",
                        "description": "e.g., `PRIMARY KEY`, `NOT NULL`, `DEFAULT`"
                    },
                    {
                        "id": "tests/sample_db/table.py::SampleTable",
                        "description": "e.g., `CHECK`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_utils.py::ConstrainRepr",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-TDEF-006",
                "requirement_description": "The system shall be able to generate a SQL `CREATE TABLE` statement based on a defined table schema.",
                "test_traceability": [
                    {
                        "id": "tests/test__table_spec.py::test_table_create",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_create_stmt",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-TDEF-007",
                "requirement_description": "The system shall support `CREATE TABLE` options `IF NOT EXISTS`, `STRICT`, `TEMPORARY`, and `WITHOUT ROWID` in the generated statements.",
                "test_traceability": [
                    {
                        "id": "tests/test__table_spec.py::test_table_create",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_create_stmt",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-TDEF-008",
                "requirement_description": "The system shall be able to generate a SQL `CREATE INDEX` statement for a given table.",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMBase::test_create_index",
                        "description": "verifies ORM method which uses this capability"
                    },
                    {
                        "id": "tests/test_e2e/test_orm.py::TestWithSampleDB::test_create_index",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_create_index_stmt",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-TDEF-009",
                "requirement_description": "The system shall support `CREATE INDEX` options including `IF NOT EXISTS`, `UNIQUE`, and the specification of one or more indexed columns with optional sort order (`ASC` or `DESC`) for each.",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMBase::test_create_index",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_create_index_stmt",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-TDEF-010",
                "requirement_description": "The system shall provide a mechanism to retrieve the Pydantic `FieldInfo` for a specified column name from a table definition, raising an error if the column is not defined.",
                "test_traceability": [
                    {
                        "id": "",
                        "description": "Implicitly tested by methods that use it, e.g., `table_dump_column`. Direct test might be inferred from usage in `TableSpec`."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_get_col_fieldinfo",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-TDEF-011",
                "requirement_description": "The system shall provide a mechanism to validate if a given tuple of column names exists within the table definition, raising an error if any column is not defined.",
                "test_traceability": [
                    {
                        "id": "",
                        "description": "Implicitly tested by methods that use it. Direct test might be inferred from usage in `TableSpec`."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_check_cols",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-TDEF-012",
                "requirement_description": "The system shall generate the column definition string (e.g., \"column_name TEXT NOT NULL\") for a table creation statement based on its name, type affinity, and constraints.",
                "test_traceability": [
                    {
                        "id": "",
                        "description": "Implicitly tested by `tests/test__table_spec.py::test_table_create` via `table_create_stmt`."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_dump_column",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-TYPE-001",
                "requirement_description": "The system shall support native Python types `int`, `float`, `str`, `bytes`, and `None` for column definitions, mapping them to `INTEGER`, `REAL`, `TEXT`, `BLOB`, and `NULL` SQLite type affinities respectively.",
                "test_traceability": [
                    {
                        "id": "tests/test__utils.py::test_typeafinityrepr",
                        "description": ""
                    },
                    {
                        "id": "tests/test__table_spec.py::TestTableSpecWithDB::test_insert_entry",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_utils.py::map_type",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-TYPE-002",
                "requirement_description": "The system shall support `enum.IntEnum` and `enum.StrEnum` types for column definitions, mapping them to `INTEGER` and `TEXT` SQLite type affinities respectively. Values shall be stored as the underlying integer or string.",
                "test_traceability": [
                    {
                        "id": "tests/test__utils.py::test_typeafinityrepr",
                        "description": "for `Choice123`, `ChoiceABC`"
                    },
                    {
                        "id": "",
                        "description": "`tests/sample_db/table.py::SampleTable::choice_abc` usage in E2E tests."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_utils.py::_map_from_type",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-TYPE-003",
                "requirement_description": "The system shall support `typing.Literal` types (for string and integer literals) for column definitions, mapping them to appropriate SQLite type affinities (`TEXT` or `INTEGER`). Values shall be stored as the underlying literal value.",
                "test_traceability": [
                    {
                        "id": "tests/test__utils.py::test_typeafinityrepr",
                        "description": "for `SomeIntLiteral`, `SomeStrLiteral`"
                    },
                    {
                        "id": "",
                        "description": "`tests/sample_db/table.py::SampleTable::str_literal` usage in E2E tests."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_utils.py::_map_from_literal",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-TYPE-004",
                "requirement_description": "The system shall support `typing.Optional[T]` for column definitions, where `T` is any other supported type, allowing the column to store `NULL` values. The SQLite type affinity will be determined by `T`.",
                "test_traceability": [
                    {
                        "id": "tests/test__utils.py::test_typeafinityrepr",
                        "description": "e.g. `Optional[bytes]`"
                    },
                    {
                        "id": "tests/conftest.py::SimpleTableForTest::extra",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_utils.py::map_type",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-TYPE-005",
                "requirement_description": "The system shall provide a custom type `DatetimeUnixTimestamp` for representing `datetime.datetime` objects, which are serialized to a floating-point Unix timestamp (seconds since epoch) for storage as `REAL` in SQLite, and deserialized from `REAL` back to `datetime.datetime`.",
                "test_traceability": [
                    {
                        "id": "tests/test__types.py::test_datetime_helper",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_types.py::DatetimeUnixTimestamp",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-TYPE-006",
                "requirement_description": "The system shall provide a custom type `DatetimeUnixTimestampInt` for representing `datetime.datetime` objects, which are serialized to an integer Unix timestamp (seconds since epoch) for storage as `INTEGER` in SQLite, and deserialized from `INTEGER` back to `datetime.datetime`.",
                "test_traceability": [
                    {
                        "id": "tests/test__types.py::test_datetime_helper",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_types.py::DatetimeUnixTimestampInt",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-TYPE-007",
                "requirement_description": "The system shall provide a custom type `DatetimeISO8601` for representing `datetime.datetime` objects, which are serialized to an ISO 8601 formatted string for storage as `TEXT` in SQLite, and deserialized from `TEXT` back to `datetime.datetime`.",
                "test_traceability": [
                    {
                        "id": "tests/test__types.py::test_datetime_helper",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_types.py::DatetimeISO8601",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-TYPE-008",
                "requirement_description": "The system shall allow columns to be defined with user-defined Python types that have custom Pydantic serializers and deserializers, enabling flexible mapping to fundamental SQLite storage types (e.g., mapping an `int` field to be stored as `TEXT` via custom logic).",
                "test_traceability": [
                    {
                        "id": "tests/conftest.py::SimpleTableForTest::int_str",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec",
                        "description": "relies on Pydantic's serialization mechanisms"
                    }
                ]
            },
            {
                "requirement_id": "FR-SERDE-001",
                "requirement_description": "The system shall serialize model instances (representing table rows) into Python dictionaries where values are formatted suitable for SQLite database operations (e.g., enums to their values, datetimes to their storable representations). Users can specify which columns to include.",
                "test_traceability": [
                    {
                        "id": "tests/test__table_spec.py::test_table_dump_asdict",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_dump_asdict",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SERDE-002",
                "requirement_description": "The system shall serialize model instances (representing table rows) into Python tuples where values are formatted suitable for SQLite database operations. Users can specify which columns to include and in what order.",
                "test_traceability": [
                    {
                        "id": "tests/test__table_spec.py::test_table_dump_astuple",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_dump_astuple",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SERDE-003",
                "requirement_description": "The system shall deserialize SQLite result rows (represented as Python tuples) into corresponding model instances, with an option to enable or disable Pydantic validation during instantiation. This expects the tuple elements to match the table schema's column order.",
                "test_traceability": [
                    {
                        "id": "tests/test__table_spec.py::test_table_from_tuple",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_from_tuple",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SERDE-004",
                "requirement_description": "The system shall deserialize SQLite result rows (represented as Python dictionaries where keys are column names) into corresponding model instances, with an option to enable or disable Pydantic validation.",
                "test_traceability": [
                    {
                        "id": "tests/test__table_spec.py::test_table_from_dict",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_from_dict",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SERDE-005",
                "requirement_description": "The system shall provide a general row factory suitable for `sqlite3.Cursor.row_factory`. This factory shall convert raw SQLite result tuples into model instances if the result columns match the model's schema, or return the raw tuple otherwise (e.g., for function call results). Validation is enabled by default.",
                "test_traceability": [
                    {
                        "id": "tests/test__table_spec.py::TestTableSpecWithDB::test_lookup_entry",
                        "description": "uses `table_row_factory`"
                    },
                    {
                        "id": "tests/test__orm.py::test_row_factory_specifying",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_row_factory",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SERDE-006",
                "requirement_description": "The system shall provide a specialized row factory (`table_row_factory2` behavior) suitable for `sqlite3.Cursor.row_factory`. This factory shall convert raw SQLite result tuples into model instances by mapping known columns from the result to model fields and ignoring unknown columns. Validation is enabled by default.",
                "test_traceability": [
                    {
                        "id": "tests/test__table_spec.py::TestTableSpecWithDB::test_lookup_entry",
                        "description": "uses `table_row_factory2`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_row_factory2",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SERDE-007",
                "requirement_description": "The system shall provide a row factory suitable for `sqlite3.Cursor.row_factory` that deserializes selected columns from a query result into a Python dictionary. It shall apply type deserialization for columns defined in the table schema and preserve values for unknown columns (e.g., aliased columns or function results) as is.",
                "test_traceability": [
                    {
                        "id": "tests/test__table_spec.py::TestTableSpecWithDB::test_deserialize_asdict_row_factory",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_deserialize_asdict_row_factory",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SERDE-008",
                "requirement_description": "The system shall provide a row factory suitable for `sqlite3.Cursor.row_factory` that deserializes selected columns from a query result into a Python tuple. It shall apply type deserialization for columns defined in the table schema and preserve values for unknown columns as is.",
                "test_traceability": [
                    {
                        "id": "tests/test__table_spec.py::TestTableSpecWithDB::test_deserialize_astuple_row_factory",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_deserialize_astuple_row_factory",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SERDE-009",
                "requirement_description": "The system shall serialize Python dictionaries representing partial or full rows (where values are application-level Python types) into new dictionaries where values are formatted suitable for SQLite database operations.",
                "test_traceability": [
                    {
                        "id": "tests/test__table_spec.py::test_serializing_mapping",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_serialize_mapping",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SERDE-010",
                "requirement_description": "The system shall allow direct export of a model instance's attributes as a Python dictionary without applying database-specific serialization logic to the values. Users can specify which columns to include.",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMBase::test_insert_mapping",
                        "description": "uses `table_asdict` in assertion"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_asdict",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SQLGEN-001",
                "requirement_description": "The system shall generate SQL `INSERT` statements for a specified table.",
                "test_traceability": [
                    {
                        "id": "tests/test__table_spec.py::TestTableSpecWithDB::test_insert_entry",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_insert_stmt",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SQLGEN-002",
                "requirement_description": "Generated `INSERT` statements shall support: specifying a subset of columns for insertion, inserting default values for all columns, `OR conflict_resolution` clauses (e.g., `OR IGNORE`, `OR REPLACE`), and a `RETURNING` clause to return specified columns from the inserted row.",
                "test_traceability": [
                    {
                        "id": "tests/test__table_spec.py::TestTableSpecWithDB::test_insert_default_values",
                        "description": "ORM tests `tests/test__orm.py::TestORMBase::test_insert_entries` (uses `or_option`). `RETURNING` clause generation tested if SQLite version supports it (see `UPDATE_API_TEST_CASES` with `RETURNING_AVAILABLE` in `test__table_spec.py`)."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_insert_stmt",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SQLGEN-003",
                "requirement_description": "The system shall generate SQL `SELECT` statements for a specified table.",
                "test_traceability": [
                    {
                        "id": "tests/test__table_spec.py::TestTableSpecWithDB::test_lookup_entry",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_select_stmt",
                        "description": ""
                    },
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_select_all_stmt",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SQLGEN-004",
                "requirement_description": "Generated `SELECT` statements shall support: selection of all columns (`*`) or a specified list of columns/expressions, application of SQL functions (e.g., `COUNT`) to selected columns, `DISTINCT` keyword, `WHERE` clause (generated from column name placeholders or a custom string), `GROUP BY` clause, `ORDER BY` clause (with column and direction), and `LIMIT` clause.",
                "test_traceability": [
                    {
                        "id": "tests/test__table_spec.py::TestTableSpecWithDB::test_lookup_entry",
                        "description": "select cols, where"
                    },
                    {
                        "id": "tests/test__orm.py::TestORMBase::test_select_with_function_call",
                        "description": "function `count`"
                    },
                    {
                        "id": "tests/test__orm.py::TestORMBase::test_select_entries",
                        "description": "distinct, order by, limit"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_select_stmt",
                        "description": ""
                    },
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_select_all_stmt",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SQLGEN-005",
                "requirement_description": "The system shall generate SQL `UPDATE` statements for a specified table.",
                "test_traceability": [
                    {
                        "id": "tests/test__table_spec.py::TestTableSpecWithDB::test_update_entry",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_update_stmt",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SQLGEN-006",
                "requirement_description": "Generated `UPDATE` statements shall support: `OR conflict_resolution` clauses, specifying columns to `SET` with named placeholders, `WHERE` clause (generated from column name placeholders or a custom string), `RETURNING` clause, `ORDER BY` clause, and `LIMIT` clause (where SQLite version supports it for UPDATE).",
                "test_traceability": [
                    {
                        "id": "tests/test__table_spec.py::TestTableSpecWithDB::test_update_entry",
                        "description": "covers these options conditionally based on `SQLITE3_COMPILE_OPTION_FLAGS`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_update_stmt",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SQLGEN-007",
                "requirement_description": "The system shall ensure that named placeholders for `WHERE` clause parameters in generated `UPDATE` statements are distinct from named placeholders for `SET` clause parameters to avoid clashes when providing parameters for execution. A specific prefix shall be used for `WHERE` clause placeholders.",
                "test_traceability": [
                    {
                        "id": "tests/test__table_spec.py::TestTableSpecWithDB::test_update_entry",
                        "description": "implicitly through `table_preprare_update_where_cols`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_update_stmt",
                        "description": ""
                    },
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_preprare_update_where_cols",
                        "description": ""
                    },
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::_table_update_where_cols_prefix",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SQLGEN-008",
                "requirement_description": "The system shall generate SQL `DELETE` statements for a specified table.",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMBase::test_delete_entries",
                        "description": "ORM method, implies generation"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_delete_stmt",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SQLGEN-009",
                "requirement_description": "Generated `DELETE` statements shall support: `WHERE` clause (generated from column name placeholders or a custom string), `ORDER BY` clause, `LIMIT` clause (where SQLite version supports it for DELETE), and `RETURNING` clause.",
                "test_traceability": [
                    {
                        "id": "tests/test_e2e/test_orm.py::TestWithSampleDB::test_delete_entries",
                        "description": "conditional on `RETURNING_AVAILABLE`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_delete_stmt",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-SQLGEN-010",
                "requirement_description": "The system shall generate SQL `SELECT` statements for retrieving all entries from a table, with support for pagination using `LIMIT` and `OFFSET`, and optional ordering.",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMBase::test_select_all_entries",
                        "description": "via ORM method"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_table_spec.py::TableSpec::table_select_all_stmt",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-001",
                "requirement_description": "The system shall allow initialization of an ORM instance with a `sqlite3.Connection` object (or a factory callable returning one) and a reference to the table specification class.",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMBase::orm_inst",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-002",
                "requirement_description": "The system shall allow overriding the default table name (defined in the ORM class) by providing a `table_name` argument during ORM instance initialization.",
                "test_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::__init__",
                        "description": "parameter `table_name`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-003",
                "requirement_description": "The system shall allow specifying a `schema_name` during ORM instance initialization for use with attached databases, prefixing the table name in generated SQL (e.g., `schema_name.table_name`).",
                "test_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::__init__",
                        "description": "parameter `schema_name`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::__init__",
                        "description": ""
                    },
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_table_name",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-004",
                "requirement_description": "The system shall allow specification of a row factory for the `sqlite3.Connection` associated with an ORM instance. This can be set at initialization or modified per query. Supported specifications include: a custom callable, `None` (to clear any existing factory), `sqlite3.Row`, the default model-instantiating factory from the table specification, the same factory but without Pydantic validation, or a directive to not change the current connection's row factory.",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::test_row_factory_specifying",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::__init__",
                        "description": ""
                    },
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::_select_row_factory",
                        "description": ""
                    },
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_execute",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-005",
                "requirement_description": "The system shall provide a method to bootstrap a database, which includes creating the main table and any defined indexes based on class-level ORM configurations (`orm_bootstrap_table_name`, `orm_bootstrap_create_table_params`, `orm_bootstrap_indexes_params`).",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::test_bootstrap",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_bootstrap_db",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-006",
                "requirement_description": "The system shall provide a method to create the database table associated with the ORM instance, with options to allow an existing table, enable strict mode, or create a table without a rowid.",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::test_create_table",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_create_table",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-007",
                "requirement_description": "The system shall provide a method to create an index on the associated database table, specifying index name, columns, and options like uniqueness or allowing an existing index.",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMBase::test_create_index",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_create_index",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-008",
                "requirement_description": "The system shall provide a method to insert a single record, represented by a model instance, into the database table. Conflict resolution options (e.g., `OR IGNORE`) shall be supported.",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMBase::prepare_test_entry",
                        "description": "uses `orm_insert_entry`"
                    },
                    {
                        "id": "tests/test__orm.py::TestORMBase::test_insert_entries",
                        "description": "tests or_option"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_insert_entry",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-009",
                "requirement_description": "The system shall provide a method to insert a single record, represented by a Python dictionary or mapping, into the database table. Column values in the mapping are application-level types and will be serialized. Conflict resolution options shall be supported.",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMBase::test_insert_mapping",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_insert_mapping",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-010",
                "requirement_description": "The system shall provide a method to insert multiple records, represented by an iterable of model instances, into the database table in a batch operation. Conflict resolution options shall be supported.",
                "test_traceability": [
                    {
                        "id": "tests/test_e2e/test_orm.py::TestWithSampleDB::test_insert_entries",
                        "description": ""
                    },
                    {
                        "id": "tests/test__orm.py::TestORMBase::test_insert_entries",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_insert_entries",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-011",
                "requirement_description": "The system shall provide a method to insert multiple records, represented by an iterable of Python dictionaries or mappings, into the database table in a batch operation. Column values will be serialized. Conflict resolution options shall be supported.",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMBase::test_insert_mappings",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_insert_mappings",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-012",
                "requirement_description": "The system shall provide a method to select and retrieve a single record as a model instance from the database table based on specified column-value criteria. If multiple records match, the first one encountered (as per database ordering or `ORDER BY` clause if used) is returned. Returns `None` if no match.",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMBase::test_select_entry",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_select_entry",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-013",
                "requirement_description": "The system shall provide a method to select and retrieve multiple records as model instances from the database table based on specified column-value criteria. This method shall support options for `DISTINCT` selection, `ORDER BY`, and `LIMIT`. Results are yielded as a generator.",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMBase::test_select_entries",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_select_entries",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-014",
                "requirement_description": "The system shall provide a method to retrieve all records from the database table using pagination, yielding model instances in batches.",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMBase::test_select_all_entries",
                        "description": ""
                    },
                    {
                        "id": "tests/test_e2e/test_orm.py::TestWithSampleDB::test_select_all_entries",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_select_all_with_pagination",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-015",
                "requirement_description": "The system shall provide a method to update existing records in the database table. Records to update are identified by column-value criteria, and new values are provided as a model instance or a Python dictionary/mapping. Conflict resolution options shall be supported.",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMBase::test_update_entries",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_update_entries",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-016",
                "requirement_description": "The system shall allow updating records using a custom SQL `WHERE` clause string, with parameter values for this clause supplied via an additional dictionary.",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMBase::test_update_entries_with_custom_stmt",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_update_entries",
                        "description": "parameter `where_stmt`, `_extra_params`"
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-017",
                "requirement_description": "The system shall provide a method to update multiple records in a batch (`executemany` style). This method takes iterables of dictionaries for `SET` clause values and iterables of dictionaries for `WHERE` clause values, applying one `SET` and `WHERE` pair per update operation.",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMUpdateEntriesMany::test_with_where_cols",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_update_entries_many",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-018",
                "requirement_description": "The batch update method shall support using a custom SQL `WHERE` clause string, where parameter values for this clause are supplied by an iterable of dictionaries (one dictionary per update operation).",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMUpdateEntriesMany::test_with_custom_where_stmt_and_extra_params_iter",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_update_entries_many",
                        "description": "parameter `where_stmt`, `_extra_params_iter`"
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-019",
                "requirement_description": "The batch update method shall support using a custom SQL `WHERE` clause string, where parameter values for this clause are supplied by a single dictionary, applied consistently to all update operations in the batch.",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMUpdateEntriesMany::test_with_custom_where_stmt_and_extra_params",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_update_entries_many",
                        "description": "parameter `where_stmt`, `_extra_params`"
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-020",
                "requirement_description": "The batch update method shall support executing a fully custom user-provided SQL `UPDATE` statement, with parameter values for each operation supplied by an iterable of dictionaries.",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMUpdateEntriesMany::test_with_custom_stmt",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_update_entries_many",
                        "description": "parameter `_stmt`, `_extra_params_iter`"
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-021",
                "requirement_description": "The system shall provide a method to delete records from the database table based on specified column-value criteria. Options for `ORDER BY` and `LIMIT` shall be supported (where SQLite allows).",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMBase::test_delete_entries",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_delete_entries",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-022",
                "requirement_description": "The system shall provide a method to delete records and, if supported by the SQLite version, return the deleted records (using a `RETURNING` clause). Results are yielded as a generator.",
                "test_traceability": [
                    {
                        "id": "tests/test_e2e/test_orm.py::TestWithSampleDB::test_delete_entries",
                        "description": "conditional on `RETURNING_AVAILABLE`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_delete_entries_with_returning",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-023",
                "requirement_description": "The system shall provide a method to check if at least one record exists in the database table matching specified column-value criteria.",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMBase::test_orm_check_entry_exist",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_check_entry_exist",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-024",
                "requirement_description": "The system shall provide a method to execute an arbitrary SQL query string with optional parameters and fetch all resulting rows. The row factory for result conversion can be specified.",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMBase::test_orm_execute",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_execute",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-025",
                "requirement_description": "The system shall provide a method to execute an arbitrary SQL query string with optional parameters and yield resulting rows as a generator. The row factory for result conversion can be specified.",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMBase::test_orm_execute",
                        "description": "also covers `orm_execute_gen`"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_execute_gen",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-026",
                "requirement_description": "The system shall provide a method to execute a parameterized DML SQL statement multiple times with an iterable of parameter sets (i.e., `executemany` functionality).",
                "test_traceability": [
                    {
                        "id": "tests/test__orm.py::TestORMBase::test_insert_entries",
                        "description": "`orm_insert_mappings`, `orm_update_entries_many` which use `executemany`."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_executemany",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-027",
                "requirement_description": "The system shall provide a method to execute a SQL script (a string containing multiple SQL statements).",
                "test_traceability": [
                    {
                        "id": "",
                        "description": "Derived from source code analysis of `simple_sqlite3_orm._orm._base.py::ORMBase::orm_executescript`. Implicitly used in `orm_bootstrap_db` if parameters are SQL strings. No direct test case with multi-statement script provided."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_executescript",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-ORM-028",
                "requirement_description": "The system shall provide access to the underlying `sqlite3.Connection` object associated with an ORM instance, allowing for direct execution of SQL or use of connection methods not exposed by the ORM.",
                "test_traceability": [
                    {
                        "id": "tests/test_e2e/test_orm.py::TestWithSampleDB::test_insert_entries",
                        "description": "uses `orm_inst.orm_con`"
                    },
                    {
                        "id": "tests/test__orm.py::TestORMBase::test_select_with_function_call",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_base.py::ORMBase::orm_con",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CONCUR-001",
                "requirement_description": "The system shall provide a thread-pooled ORM variant (`ORMThreadPoolBase`) that manages a pool of SQLite connections, allowing multiple ORM operations to be submitted concurrently and executed by worker threads.",
                "test_traceability": [
                    {
                        "id": "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_pool.py::ORMThreadPoolBase",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CONCUR-002",
                "requirement_description": "The thread-pooled ORM shall be initialized with a connection factory function and the desired number of connections/worker threads in the pool.",
                "test_traceability": [
                    {
                        "id": "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::thread_pool",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_pool.py::ORMThreadPoolBase::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CONCUR-003",
                "requirement_description": "The thread-pooled ORM shall expose the same core ORM operations (table/index creation, insert, select, update, delete, execute) as the base ORM. Each operation submitted to the thread-pooled ORM shall be executed in one of its worker threads.",
                "test_traceability": [
                    {
                        "id": "",
                        "description": "Various tests in `tests/test_e2e/test_threadpool_orm.py` (e.g., `test_create_table`, `test_insert_entries_with_pool`, `test_lookup_entries`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_pool.py::ORMThreadPoolBase",
                        "description": "wrappers like `_wrap_with_thread_ctx`"
                    }
                ]
            },
            {
                "requirement_id": "FR-CONCUR-004",
                "requirement_description": "For ORM operations that return a generator of results (e.g., `orm_select_entries`), the thread-pooled ORM variant shall manage yielding these results from the worker thread back to the calling thread. The calling thread shall be able to iterate these results.",
                "test_traceability": [
                    {
                        "id": "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_lookup_entries",
                        "description": ""
                    },
                    {
                        "id": "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_caller_exits_when_lookup_entries",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_pool.py::_wrap_generator_with_thread_ctx",
                        "description": ""
                    },
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_pool.py::ORMThreadPoolBase::_caller_gen",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CONCUR-005",
                "requirement_description": "The system shall provide an asyncio-compatible ORM variant (`AsyncORMBase`) that uses an underlying thread pool to execute database operations asynchronously, integrating with Python's `asyncio` event loop.",
                "test_traceability": [
                    {
                        "id": "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_pool.py::AsyncORMBase",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CONCUR-006",
                "requirement_description": "The asyncio ORM shall be initialized with a connection factory function and the desired number of connections/worker threads for its underlying thread pool. It must capture the running asyncio event loop at initialization.",
                "test_traceability": [
                    {
                        "id": "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::async_pool",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_pool.py::AsyncORMBase::__init__",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CONCUR-007",
                "requirement_description": "The asyncio ORM shall expose the same core ORM operations as awaitable methods. Each operation shall be executed in the underlying thread pool and its result returned asynchronously.",
                "test_traceability": [
                    {
                        "id": "",
                        "description": "Various tests in `tests/test_e2e/test_async_orm.py` (e.g., `test_create_table`, `test_insert_entries_with_pool`, `test_lookup_entries`)"
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_pool.py::AsyncORMBase",
                        "description": "wrappers like `_wrap_with_async_ctx`"
                    }
                ]
            },
            {
                "requirement_id": "FR-CONCUR-008",
                "requirement_description": "For ORM operations that return a generator of results, the asyncio ORM variant shall expose these as async generators. Results shall be yielded from the worker thread back to the asyncio event loop, allowing asynchronous iteration.",
                "test_traceability": [
                    {
                        "id": "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_lookup_entries",
                        "description": ""
                    },
                    {
                        "id": "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_caller_exits_when_lookup_entries",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_pool.py::_wrap_generator_with_async_ctx",
                        "description": ""
                    },
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_pool.py::AsyncORMBase::_async_caller_gen",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-CONCUR-009",
                "requirement_description": "Both thread-pooled and asyncio ORM variants shall provide a method to shut down their underlying connection/thread pool, with options to wait for pending tasks to complete and to close all managed database connections.",
                "test_traceability": [
                    {
                        "id": "tests/test_e2e/test_threadpool_orm.py::TestORMPoolShutdown::test_orm_pool_shutdown",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_pool.py::ORMThreadPoolBase::orm_pool_shutdown",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-UTIL-001",
                "requirement_description": "The system shall provide a utility function to enable WAL (Write-Ahead Logging) mode for a given SQLite connection, with an option to also set the synchronous mode to NORMAL.",
                "test_traceability": [
                    {
                        "id": "tests/test_utils.py::test_pragma_enable_helpers",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/utils.py::enable_wal_mode",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-UTIL-002",
                "requirement_description": "The system shall provide a utility function to configure the temporary store location to memory (`PRAGMA temp_store = MEMORY`) for a given SQLite connection.",
                "test_traceability": [
                    {
                        "id": "tests/test_utils.py::test_pragma_enable_helpers",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/utils.py::enable_tmp_store_at_memory",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-UTIL-003",
                "requirement_description": "The system shall provide a utility function to enable and configure memory-mapped I/O (`PRAGMA mmap_size`) for a given SQLite connection, with a configurable mmap size.",
                "test_traceability": [
                    {
                        "id": "tests/test_utils.py::test_pragma_enable_helpers",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/utils.py::enable_mmap",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-UTIL-004",
                "requirement_description": "The system shall provide a utility function to execute `PRAGMA optimize` on a given SQLite connection.",
                "test_traceability": [
                    {
                        "id": "tests/test_utils.py::test_pragma_enable_helpers",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/utils.py::optimize_db",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-UTIL-005",
                "requirement_description": "The system shall provide a utility function to perform an integrity check (`PRAGMA integrity_check`) on a given SQLite connection, either for the entire database or for a specified table. The function shall return a boolean indicating success (`ok`).",
                "test_traceability": [
                    {
                        "id": "tests/test_utils.py::test_check_db_integrity",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/utils.py::check_db_integrity",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-UTIL-006",
                "requirement_description": "The system shall provide a utility function to check if a table with a given name exists in the database associated with a SQLite connection.",
                "test_traceability": [
                    {
                        "id": "tests/test_utils.py::test_lookup_table",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/utils.py::lookup_table",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-UTIL-007",
                "requirement_description": "The system shall provide a utility function to retrieve SQLite compile-time options (`PRAGMA compile_options`) from a given SQLite connection, either all options or a specific one by name.",
                "test_traceability": [
                    {
                        "id": "tests/test_utils.py::test_checkpragma_compile_time_options",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/utils.py::check_pragma_compile_time_options",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-UTIL-008",
                "requirement_description": "The system shall provide a utility function to iterate over an iterable in fixed-size chunks (batches), where the last batch may be smaller.",
                "test_traceability": [
                    {
                        "id": "tests/test_utils.py::test_batched",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/utils.py::batched",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-UTIL-009",
                "requirement_description": "The system shall provide a utility function to generate a SQL `CHECK` constraint string suitable for a given field name, based on an `Enum` type or a `typing.Literal` type (e.g., `field_name IN ('A','B','C')`).",
                "test_traceability": [
                    {
                        "id": "tests/test_utils.py::test_gen_check_constrain",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/utils.py::gen_check_constrain",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-UTIL-010",
                "requirement_description": "The system shall provide a utility function to concatenate multiple SQL condition components (strings representing conditions or operators like `AND`, `OR`) into a single condition string, with an option to wrap the entire result in parentheses.",
                "test_traceability": [
                    {
                        "id": "tests/test_utils.py::test_concatenate_condition",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/utils.py::concatenate_condition",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-UTIL-011",
                "requirement_description": "The system shall provide a utility function to wrap common Python values (int, float, str, bytes, None, Enum members) into their SQL literal string representations (e.g., strings quoted, bytes as hex literals, NULL for None).",
                "test_traceability": [
                    {
                        "id": "tests/test_utils.py::test_wrap_value",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/utils.py::wrap_value",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-UTIL-012",
                "requirement_description": "The system shall provide a factory (`ColsSelectFactory`) for creating type-checked tuples of column names. This factory aids in specifying column lists for ORM operations with static type checking and editor completion for column names.",
                "test_traceability": [
                    {
                        "id": "",
                        "description": "Usage in `tests/conftest.py::SimpleTableForTestColsSelect` and various ORM method calls in tests."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_utils.py::ColsSelectFactory",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-UTIL-013",
                "requirement_description": "The system shall provide a utility function to combine multiple SQL statements (each potentially ending with a semicolon) into a single valid SQL script string.",
                "test_traceability": [
                    {
                        "id": "",
                        "description": "Derived from source code analysis of `src/simple_sqlite3_orm/utils.py::gen_sql_script`. No direct corresponding original test case."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/utils.py::gen_sql_script",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-UTIL-014",
                "requirement_description": "The system shall provide a utility function to construct a single SQL statement string from various string components, trimming whitespace and optionally appending a semicolon.",
                "test_traceability": [
                    {
                        "id": "tests/test_utils.py::test_gen_sql_stmt",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_utils.py::gen_sql_stmt",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "FR-UTIL-015",
                "requirement_description": "The system shall provide a utility function to attach an additional database file (or an in-memory database) to an existing SQLite connection using a specified schema name.",
                "test_traceability": [
                    {
                        "id": "",
                        "description": "Derived from source code analysis of `src/simple_sqlite3_orm/utils.py::attach_database`. No direct corresponding original test case."
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/utils.py::attach_database",
                        "description": ""
                    }
                ]
            },
            {
                "requirement_id": "NFR-PERF-001",
                "requirement_description": "Asynchronous ORM operations shall not significantly block the Python `asyncio` event loop, allowing other concurrent asyncio tasks to make progress while database operations are pending.\n*   **Description:** This ensures that the use of `AsyncORMBase` maintains the responsiveness of an asyncio application.",
                "test_traceability": [
                    {
                        "id": "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_check_timer",
                        "description": ""
                    }
                ],
                "code_traceability": [
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_pool.py::AsyncORMBase",
                        "description": ""
                    },
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_pool.py::_wrap_with_async_ctx",
                        "description": ""
                    },
                    {
                        "id": "src/simple_sqlite3_orm/_orm/_pool.py::_wrap_generator_with_async_ctx",
                        "description": ""
                    }
                ]
            }
        ],
        "commit_sha": "d6f712c4feede6e1279664d26cf77e8e8208ded1",
        "full_code_skeleton": "--- File: src/simple_sqlite3_orm/_types.py ---\n```python\n\"\"\"Types helper definition.\"\"\"\n\nfrom __future__ import annotations\nimport datetime\nfrom typing import Any\nfrom pydantic import BeforeValidator, PlainSerializer\nfrom typing_extensions import Annotated\n\ndef _datetime_validator(\n    _in: int | float | str | datetime.datetime | Any,\n) -> datetime.datetime:\n    \"\"\"A pydantic validator helper for parsing serialized datetime from database.\"\"\"\n    pass\n\nDatetimeUnixTimestamp = Annotated[\n    datetime.datetime,\n    BeforeValidator(_datetime_validator),\n    PlainSerializer(lambda x: x.timestamp(), return_type=float),\n]\n\"\"\"datetime.datetime as unixtimestamp in seconds serialized as a float in db.\"\"\"\n\nDatetimeUnixTimestampInt = Annotated[\n    datetime.datetime,\n    BeforeValidator(_datetime_validator),\n    PlainSerializer(lambda x: int(x.timestamp()), return_type=int),\n]\n\"\"\"datetime.datetime as unixtimestamp in seconds serialized as an int in db.\"\"\"\n\nDatetimeISO8601 = Annotated[\n    datetime.datetime,\n    BeforeValidator(_datetime_validator),\n    PlainSerializer(lambda x: x.isoformat(), return_type=str),\n]\n\"\"\"datetime.datetime as str(ISO8601 formatted) serialized as a string in db.\"\"\"\n\n```\n--- File: src/simple_sqlite3_orm/utils.py ---\n```python\n\"\"\"General utils for sqlite3.\"\"\"\n\nfrom __future__ import annotations\nimport sqlite3\nfrom typing import (\n    Any,\n    Generator,\n    Iterable,\n    Literal,\n)\n\ndef enable_wal_mode(con: sqlite3.Connection, relax_sync_mode: bool = True):\n    \"\"\"Enable WAL mode for the connected database.\n\n    Note that for multiple databases being attached, WAL mode only guarantees\n        atomic within each individual database file. See https://www.sqlite.org/lang_attach.html\n        for more details.\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n        relax_sync_mode (bool): Also set the synchronous mode to NORMAL. Default to True.\n\n    Raises:\n        sqlite3.DatabaseError on failed sql execution.\n    \"\"\"\n    pass\n\ndef enable_tmp_store_at_memory(con: sqlite3.Connection):\n    \"\"\"Locate the temp tables at memory.\n\n    See https://www.sqlite.org/pragma.html#pragma_temp_store for more details.\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n\n    Raises:\n        sqlite3.DatabaseError on failed sql execution.\n    \"\"\"\n    pass\n\ndef enable_mmap(con: sqlite3.Connection, mmap_size: int = DEFAULT_MMAP_SIZE):\n    \"\"\"Enable mmap for the connection.\n\n    See https://www.sqlite.org/pragma.html#pragma_mmap_size for more\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n        mmap_size (int, optional): The max mmap size. Defaults to <DEFAULT_MMAP_SIZE=16MiB>.\n\n    Raises:\n        sqlite3.DatabaseError on failed sql execution.\n    \"\"\"\n    pass\n\ndef optimize_db(con: sqlite3.Connection):\n    \"\"\"Execute optimize PRAGMA on the target database.\n\n    See https://www.sqlite.org/pragma.html#pragma_optimize.\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n\n    Raises:\n        sqlite3.DatabaseError on failed sql execution.\n    \"\"\"\n    pass\n\ndef check_db_integrity(con: sqlite3.Connection, table_name: str | None = None) -> bool:\n    \"\"\"Execute integrity_check PRAGMA on the target database(or specific table at the database).\n\n    See https://www.sqlite.org/pragma.html#pragma_integrity_check for more details.\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n        table_name (str | None, optional): If specified, the integrity_check will only be performed\n            against this table. Defaults to None, means performing the check on the whole database.\n\n    Returns:\n        bool: True for integrity_check passed on the target database, False for errors found.\n    \"\"\"\n    pass\n\ndef lookup_table(con: sqlite3.Connection, table_name: str) -> bool:\n    \"\"\"Check if specific table existed on the target database.\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n        table_name (str): The name of table to lookup.\n\n    Returns:\n        bool: True for table existed, False for not found.\n    \"\"\"\n    pass\n\ndef attach_database(\n    con: sqlite3.Connection, database: str | Literal[\":memory:\"], schema_name: str\n) -> str:\n    \"\"\"Attach another database onto the current connection.\n\n    See https://www.sqlite.org/lang_attach.html for more details.\n\n    Args:\n        con (sqlite3.Connection): The current database connection.\n        database (str | Literal[\":memory:\"]): The new database to be attached.\n        schema_name (str): The alias name of the newly connected database for distinguishing\n            between the already connected database in this connection.\n\n    Returns:\n        str: The schema_name of the newly connected database in the connection.\n    \"\"\"\n    pass\n\n@overload\ndef check_pragma_compile_time_options(\n    con: sqlite3.Connection, option_name: str\n) -> tuple[str, Any] | None: ...\n\n@overload\ndef check_pragma_compile_time_options(\n    con: sqlite3.Connection, option_name: None = None\n) -> list[tuple[str, Any]]: ...\n\ndef check_pragma_compile_time_options(\n    con: sqlite3.Connection, option_name: str | None = None\n) -> tuple[str, Any] | None | list[tuple[str, Any]]:\n    \"\"\"Get the runtime sqlite3 library's compile time options.\n\n    Args:\n        con (sqlite3.Connection): The current database connection.\n        option_name (str | None, optional): The option to lookup. If not specified,\n            it will return all the options and its values. Defaults to None.\n\n    Returns:\n        tuple[str, Any] | None | list[tuple[str, Any]]: Looked up options and its values.\n    \"\"\"\n    pass\n\ndef batched(\n    iterable: Iterable[Any], n: int\n) -> Generator[tuple[Any, ...], Any, None]:\n    \"\"\"Batch data from the iterable into tuples of length n. The last batch may be shorter than n.\n\n    Backport batched from py3.12. This is the roughly python implementation\n        of py3.12's batched copied from py3.12 documentation.\n    See https://docs.python.org/3/library/itertools.html#itertools.batched for more details.\n\n    Args:\n        iterable (Iterable[Any]): The input to be batched.\n        n (int): the size of each batch.\n\n    Raises:\n        ValueError on invalid n.\n\n    Returns:\n        A generator that can be used to loop over the input iterable and accumulates data into\n            tuples up to size n(a.k.a, batch in size of n).\n    \"\"\"\n    pass\n\ndef gen_check_constrain(_in: Any, field_name: str) -> str:\n    \"\"\"Generate the constrain statement for CHECK keyword.\n\n    Supports the following types:\n    1. StrEnum or IntEnum types: will generate statement like:\n        <field_name> IN (<enum_value_1>[, <enum_value_2>[, ...]])\n    2. Literal types: similar to StrEnum and IntEnum.\n\n    Args:\n        enum_type (type[Enum]): The enum type to generate CHECK statement against.\n        field_name (str): The field name of this enum_type in use.\n\n    Raises:\n        TypeError on unsupported enum_type.\n\n    Returns:\n        str: the generated statement can be used with CHECK keyword like the following:\n           <enum_value_1>[, <enum_value_2>[, ...]]\n    \"\"\"\n    pass\n\ndef concatenate_condition(\n    *condition_or_op: CONDITION_OPERATORS | COMPARE_OPERATORS | Any,\n    wrapped_with_parentheses: bool = True,\n) -> str:\n    \"\"\"Chain a list of conditions and operators together in a string.\n\n    For example, for the following statement for CHECK keyword:\n        (column IS NULL OR column IN (1, 2, 3))\n    we can use concatenate_condition like:\n        concatenate_condition(\n            \"column IS NULL\", \"OR\", \"column IN (1, 2, 3)\",\n            wrapped_with_parentheses=True,\n        )\n    \"\"\"\n    pass\n\ndef wrap_value(value: Any) -> str:\n    \"\"\"Wrap value for use in sql statement.\n\n    NOTE that for most cases, you should use python sqlite3 lib's\n        placeholder feature to bind value in the sql statement.\n\n    For int and float, the value will be used as it.\n    For str, the value will be wrapped with parenthesis.\n    For bytes, the value will be converted as x'<bytes_in_hex>'.\n    \"\"\"\n    pass\n\ndef gen_sql_script(*stmts: str) -> str:\n    \"\"\"Combine multiple sql statements into a sql script.\"\"\"\n    pass\n\ndef sort_and_replace(\n    _orm: ORMBase[TableSpecType], table_name: str, *, order_by_col: str\n) -> None:\n    \"\"\"Sort the table, and then replace the old table with the sorted one.\"\"\"\n    pass\n\n```\n--- File: src/simple_sqlite3_orm/_sqlite_spec.py ---\n```python\n\"\"\"sqlite3 specific types and helpers.\"\"\"\n\nfrom __future__ import annotations\nfrom enum import Enum\nfrom typing import Literal, Union\n\nclass SQLiteStorageClass(str, Enum):\n    NULL = \"NULL\"\n    INTEGER = \"INTEGER\"\n    REAL = \"REAL\"\n    TEXT = \"TEXT\"\n    BLOB = \"BLOB\"\n\nSQLiteStorageClassLiteral = Literal[\"NULL\", \"INTEGER\", \"REAL\", \"TEXT\", \"BLOB\"]\n\nclass SQLiteTypeAffinity(str, Enum):\n    TEXT = \"TEXT\"\n    NUMERIC = \"NUMERIC\"\n    INTEGER = \"INTEGER\"\n    REAL = \"REAL\"\n    BLOB = \"BLOB\"\n    NULL = \"NULL\"\n\nSQLiteTypeAffinityLiteral = Literal[\"TEXT\", \"NUMERIC\", \"INTEGER\", \"REAL\", \"BLOB\"]\nConstrainLiteral = Literal[\n    \"PRIMARY KEY\",\n    \"NOT NULL\",\n    \"UNIQUE\",\n    \"CHECK\",\n    \"DEFAULT\",\n    \"COLLATE\",\n    \"REFERENCES\",\n    \"GENERATED ALWAYS AS\",\n    \"AS\",\n]\n\"\"\"Ref: https://www.sqlite.org/lang_createtable.html\"\"\"\nSQLiteBuiltInScalarFuncs = Literal[\n    \"abs\",\n    \"changes\",\n    \"char\",\n    \"coalesce\",\n    \"concat\",\n    \"concat_ws\",\n    \"format\",\n    \"glob\",\n    \"hex\",\n    \"ifnull\",\n    \"iif\",\n    \"instr\",\n    \"last_insert_rowid\",\n    \"length\",\n    \"like\",\n    \"like\",\n    \"likelihood\",\n    \"likely\",\n    \"load_extension\",\n    \"load_extension\",\n    \"lower\",\n    \"ltrim\",\n    \"ltrim\",\n    \"max\",\n    \"min\",\n    \"nullif\",\n    \"octet_length\",\n    \"printf\",\n    \"quote\",\n    \"random\",\n    \"randomblob\",\n    \"replace\",\n    \"round\",\n    \"round\",\n    \"rtrim\",\n    \"rtrim\",\n    \"sign\",\n    \"soundex\",\n    \"sqlite_compileoption_get\",\n    \"sqlite_compileoption_used\",\n    \"sqlite_offset\",\n    \"sqlite_source_id\",\n    \"sqlite_version\",\n    \"substr\",\n    \"substr\",\n    \"substring\",\n    \"substring\",\n    \"total_changes\",\n    \"trim\",\n    \"trim\",\n    \"typeof\",\n    \"unhex\",\n    \"unhex\",\n    \"unicode\",\n    \"unlikely\",\n    \"upper\",\n    \"zeroblob\",\n]\n\"\"\"Ref: https://www.sqlite.org/lang_corefunc.html\"\"\"\n\nSQLiteBuiltInAggregateFuncs = Literal[\n    \"avg\",\n    \"count\",\n    \"count\",\n    \"group_concat\",\n    \"group_concat\",\n    \"max\",\n    \"min\",\n    \"string_agg\",\n    \"sum\",\n]\n\"\"\"Ref: https://www.sqlite.org/lang_aggfunc.html\"\"\"\n\nSQLiteBuiltInDateTimeFuncs = Literal[\n    \"data\", \"time\", \"datetime\", \"julianday\", \"unixepoch\", \"strftime\", \"timediff\"\n]\n\"\"\"Ref: https://www.sqlite.org/lang_datefunc.html\"\"\"\n\nSQLiteBuiltInMathFuncs = Literal[\n    \"acos\",\n    \"acosh\",\n    \"asin\",\n    \"asinh\",\n    \"atan\",\n    \"atan2\",\n    \"atanh\",\n    \"ceil\",\n    \"ceiling\",\n    \"cos\",\n    \"cosh\",\n    \"degrees\",\n    \"exp\",\n    \"floor\",\n    \"ln\",\n    \"log\",\n    \"log\",\n    \"log10\",\n    \"log2\",\n    \"mod\",\n    \"pi\",\n    \"pow\",\n    \"power\",\n    \"radians\",\n    \"sin\",\n    \"sinh\",\n    \"sqrt\",\n    \"tan\",\n    \"tanh\",\n    \"trunc\",\n]\n\"\"\"Ref: https://www.sqlite.org/lang_mathfunc.html\"\"\"\n\nSQLiteBuiltInJSONFuncs = Literal[\n    \"json\",\n    \"jsonb\",\n    \"json_array\",\n    \"jsonb_array\",\n    \"json_array_length\",\n    \"json_error_position\",\n    \"json_extract\",\n    \"jsonb_extract\",\n    \"json_insert\",\n    \"jsonb_insert\",\n    \"json_object\",\n    \"jsonb_object\",\n    \"json_patch\",\n    \"jsonb_patch\",\n    \"json_remove\",\n    \"jsonb_remove\",\n    \"json_replace\",\n    \"jsonb_replace\",\n    \"json_set\",\n    \"jsonb_set\",\n    \"json_type\",\n    \"json_valid\",\n    \"json_quote\",\n    \"json_group_array\",\n    \"jsonb_group_array\",\n    \"json_group_object\",\n    \"jsonb_group_object\",\n    \"json_each\",\n    \"json_tree\",\n]\n\"\"\"Ref: https://www.sqlite.org/json1.html\"\"\"\n\nSQLiteBuiltInFuncs = Union[\n    SQLiteBuiltInAggregateFuncs,\n    SQLiteBuiltInDateTimeFuncs,\n    SQLiteBuiltInJSONFuncs,\n    SQLiteBuiltInMathFuncs,\n    SQLiteBuiltInScalarFuncs,\n]\nOR_OPTIONS = Literal[\"abort\", \"fail\", \"ignore\", \"replace\", \"rollback\"]\nORDER_DIRECTION = Literal[\"ASC\", \"DESC\"]\nCONDITION_OPERATORS = Literal[\n    \"AND\",\n    \"OR\",\n    \"IS\",\n    \"NULL\",\n    \"IS NULL\",\n    \"IS NOT NULL\",\n    \"NOT\",\n    \"MATCH\",\n    \"LIKE\",\n    \"BETWEEN\",\n    \"REGEXP\",\n    \"GLOB\",\n    \"IS DISTINCT FROM\",\n    \"IS NOT DISTINCT FROM\",\n]\n\"\"\"Ref https://www.sqlite.org/lang_expr.html\"\"\"\n\nCOMPARE_OPERATORS = Literal[\"=\", \"==\", \"!=\", \"<>\", \">=\", \"<=\"]\n\n```\n--- File: src/simple_sqlite3_orm/_table_spec.py ---\n```python\nfrom __future__ import annotations\nimport sqlite3\nfrom collections.abc import Mapping\nfrom types import MappingProxyType\nfrom typing import Any, ClassVar, Generator, Iterable, Literal, TypedDict, TypeVar\nfrom pydantic import BaseModel\nfrom pydantic.fields import FieldInfo\nfrom typing_extensions import NotRequired, Self\n\nclass CreateTableParams(TypedDict, total=False):\n    if_not_exists: bool\n    strict: bool\n    temporary: bool\n    without_rowid: bool\n\nclass CreateIndexParams(TypedDict):\n    index_name: str\n    index_cols: tuple[str | tuple[str, ORDER_DIRECTION], ...]\n    if_not_exists: NotRequired[bool]\n    unique: NotRequired[bool]\n\nclass TableSpec(BaseModel):\n    \"\"\"Define table as pydantic model, with specific APIs.\"\"\"\n    table_columns: ClassVar[MappingProxyType[str, FieldInfo]]\n    \"\"\"A view of TableSpec's model_fields.\"\"\"\n    table_columns_by_index: ClassVar[tuple[str, ...]]\n    \"\"\"Ordered tuple of column names, matching exactly with table schema.\"\"\"\n    _table_update_where_cols_prefix: ClassVar[Literal[\"__table_spec_\"]]\n\n    @classmethod\n    def __pydantic_init_subclass__(cls, **_) -> None:\n        pass\n\n    @classmethod\n    def _generate_where_stmt(\n        cls,\n        where_cols: tuple[str, ...] | None = None,\n        where_stmt: str | None = None,\n    ) -> str:\n        pass\n\n    @classmethod\n    def _generate_order_by_stmt(\n        cls,\n        order_by: tuple[str | tuple[str, ORDER_DIRECTION], ...] | None = None,\n        order_by_stmt: str | None = None,\n    ) -> str:\n        pass\n\n    @classmethod\n    def _generate_returning_stmt(\n        cls,\n        returning_cols: tuple[str, ...] | Literal[\"*\"] | None = None,\n        returning_stmt: str | None = None,\n    ) -> str:\n        pass\n\n    @classmethod\n    def table_get_col_fieldinfo(cls, col: str) -> FieldInfo:\n        \"\"\"Check whether the <col> exists and returns the pydantic FieldInfo.\n\n        Raises:\n            ValueError on non-existed col.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_check_cols(cls, cols: tuple[str, ...]) -> None:\n        \"\"\"Ensure all cols in <cols> existed in the table definition.\n\n        Raises:\n            ValueError if any of col doesn't exist in the table.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_dump_column(cls, column_name: str) -> str:\n        \"\"\"Dump the column statement for table creation.\n\n        Raises:\n            ValueError on col doesn't exist or invalid col definition.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_create_stmt(\n        cls,\n        table_name: str,\n        *,\n        if_not_exists: bool = False,\n        strict: bool = False,\n        temporary: bool = False,\n        without_rowid: bool = False,\n    ) -> str:\n        \"\"\"Get create table statement with this table spec class.\n\n        Check https://www.sqlite.org/lang_createtable.html for more details.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_create_index_stmt(\n        cls,\n        *,\n        table_name: str,\n        index_name: str,\n        index_cols: tuple[str | tuple[str, ORDER_DIRECTION], ...],\n        if_not_exists: bool = False,\n        unique: bool = False,\n    ) -> str:\n        \"\"\"Get index create statement with this table spec class.\n\n        Raises:\n            ValueError on <index_cols> not specified, or invalid <index_cols>.\n\n        Check https://www.sqlite.org/lang_createindex.html for more details.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_row_factory(\n        cls,\n        _cursor: sqlite3.Cursor,\n        _row: tuple[Any, ...] | Any,\n        *,\n        validation: bool = True,\n    ) -> Self | tuple[Any, ...]:\n        \"\"\"A general row_factory implement for used in sqlite3 connection.\n\n        When the input <_row> is not a row but something like function output,\n            this method will return the raw input tuple as it.\n\n        Args:\n            validation (bool): whether enable pydantic validation when importing row. Default to True.\n\n        Raises:\n            Any exception raised from pydantic model_validate or model_construct.\n\n        Returns:\n            An instance of <TableSpec>, or the raw tuple if the input row has different schema.\n\n        Also see https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.description\n            for more details.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_row_factory2(\n        cls,\n        _cursor: sqlite3.Cursor,\n        _row: tuple[Any, ...] | Any,\n        *,\n        validation: bool = True,\n    ) -> Self:\n        \"\"\"Another version of row_factory implementation for specific use case.\n\n        Unlike table_row_factory that checks the cols definition and ensure all cols\n            are valid and presented in table def, table_row_factory2 just picks the valid\n            cols from the input raw table row, and ignore unknown col/value pairs.\n\n        Args:\n            validation (bool): whether enable pydantic validation when importing row. Default to True.\n\n        Raises:\n            Any exception raised from pydantic model_validate or model_construct.\n\n        Returns:\n            An instance of <TableSpec>.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_from_tuple(\n        cls, _row: Iterable[Any], *, with_validation: bool = True, **kwargs\n    ) -> Self:\n        \"\"\"A raw row_factory that converts the input _row to TableSpec instance.\n\n        NOTE that this method expects the input row match the table row spec EXACTLY.\n\n        Args:\n            _row (tuple[Any, ...]): the raw table row as tuple.\n            with_validation (bool): if set to False, will use pydantic model_construct to directly\n                construct instance without validation. Default to True.\n            **kwargs: extra kwargs passed to pydantic model_validate API. Note that only when\n                with_validation is True, the kwargs will be used.\n\n        Returns:\n            An instance of self.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_from_dict(\n        cls, _map: Mapping[str, Any], *, with_validation: bool = True, **kwargs\n    ) -> Self:\n        \"\"\"A raw row_factory that converts the input mapping to TableSpec instance.\n\n        Args:\n            _map (Mapping[str, Any]): the raw table row as a dict.\n            with_validation (bool, optional): if set to False, will use pydantic model_construct to directly\n                construct instance without validation. Default to True.\n            **kwargs: extra kwargs passed to pydantic model_validate API. Note that only when\n                with_validation is True, the kwargs will be used.\n\n        Returns:\n            An instance of self.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_insert_stmt(\n        cls,\n        *,\n        insert_into: str,\n        insert_cols: tuple[str, ...] | None = None,\n        insert_default: bool = False,\n        or_option: OR_OPTIONS | None = None,\n        returning_cols: tuple[str, ...] | Literal[\"*\"] | None = None,\n        returning_stmt: str | None = None,\n    ) -> str:\n        \"\"\"Get sql for inserting row(s) into <table_name>.\n\n        Check https://www.sqlite.org/lang_insert.html for more details.\n\n        Args:\n            insert_into (str): The name of table insert into.\n            insert_cols (tuple[str, ...] | None, optional): The cols to be assigned for entry to be inserted.\n                Defaults to None, means we will assign all cols of the row.\n            insert_default (bool, optional): No values will be assigned, all cols will be assigned with\n                default value, this precedes the <insert_cols> param. Defaults to False.\n            or_option (INSERT_OR | None, optional): The fallback operation if insert failed. Defaults to None.\n            returning_cols (tuple[str, ...] | Literal[\"*\"] | None): Which cols are included in the returned entries.\n                Defaults to None.\n            returning_stmt (str | None, optional): The full returning statement string, this\n                precedes the <returning_cols> param. Defaults to None.\n\n        Returns:\n            str: The generated insert statement.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_update_stmt(\n        cls,\n        *,\n        or_option: OR_OPTIONS | None = None,\n        update_target: str,\n        set_cols: tuple[str, ...],\n        where_cols: tuple[str, ...] | None = None,\n        where_stmt: str | None = None,\n        returning_cols: tuple[str, ...] | Literal[\"*\"] | None = None,\n        returning_stmt: str | None = None,\n        order_by: tuple[str | tuple[str, ORDER_DIRECTION], ...] | None = None,\n        order_by_stmt: str | None = None,\n        limit: int | None = None,\n    ) -> str:\n        \"\"\"Get sql query for updating row(s) at <table_name>.\n\n        Check https://www.sqlite.org/lang_update.html for more details.\n\n        NOTE: to avoid overlapping between <set_cols> and <where_cols> when generating named-placeholders,\n            this method will prefix cols name with <_table_spec_update_where_cols_prefix> when generating\n            WHERE statement.\n            To directly use the stmt generated from this API, dev must use table_preprare_update_where_cols\n            to prepare the col/value mapping for params.\n\n        NOTE that UPDATE-FROM extension is currently not supported by this method.\n        NOTE that UPDATE-WITH-LIMIT is an optional feature, needs to be enabled at compiled time with\n            SQLITE_ENABLE_UPDATE_DELETE_LIMIT.\n\n        Args:\n            or_option (INSERT_OR | None, optional): The fallback operation if update failed. Defaults to None.\n            update_target (str): The name of table to update.\n            set_cols (tuple[str, ...]): The cols to be updated.\n            where_cols (tuple[str, ...] | None, optional): A list of cols to be compared in where\n                statement. Defaults to None.\n            where_stmt (str | None, optional): The full where statement string, this\n                precedes the <where_cols> param if set. Defaults to None.\n            returning_cols (tuple[str, ...] | Literal[\"*\"] | None): If specified, enable RETURNING stmt, and specifying Which cols\n                included in the returned entries. Defaults to None.\n            returning_stmt (str | None, optional): The full returning statement string, this\n                precedes the <returning_cols> param. Defaults to None.\n            order_by (Iterable[str  |  tuple[str, ORDER_DIRECTION], ...] | None, optional):\n                Works with LIMIT, to specify the range that LIMIT affects. Defaults to None.\n            order_by_stmt (str | None, optional): The order_by statement string, this\n                precedes the <order_by> param if set. Defaults to None.\n            limit (int | None, optional): Limit the number of affected entries. Defaults to None.\n\n        Returns:\n            str: The generated update sqlite3 query.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_preprare_update_where_cols(\n        cls, where_cols: Mapping[str, Any]\n    ) -> Mapping[str, Any]:\n        \"\"\"Regulate the named-placeholder <where_cols> so that it will not overlap with <set_cols>.\n\n        This is MUST for directly using the sqlite query stmt generated from table_update_stmt.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_select_all_stmt(\n        cls,\n        *,\n        select_from: str,\n        batch_idx: int | None = None,\n        batch_size: int | None = None,\n        order_by: tuple[str | tuple[str, ORDER_DIRECTION], ...] | None = None,\n        order_by_stmt: str | None = None,\n        distinct: bool = False,\n    ) -> str:\n        \"\"\"Select all entries, optionally with pagination LIMIT and OFFSET.\n\n        Check https://www.sqlite.org/lang_select.html for more details.\n\n        Args:\n            select_from (str): The table name for the generated statement.\n            batch_idx (int | None, optional): If specified, the batch index of current page. Defaults to None.\n            batch_size (int | None, optional): If specified, the batch size of each page. Defaults to None.\n            order_by (tuple[str | tuple[str, ORDER_DIRECTION], ...] | None, optional):\n                A list of cols for ordering result. Defaults to None.\n            order_by_stmt (str | None, optional): The order_by statement string, this\n                precedes the <order_by> param if set. Defaults to None.\n            distinct (bool, optional): Whether filters the duplicated entries. Defaults to False.\n\n        Raises:\n            ValueError: If batch_idx or bach_size are not both None or not None, or the values are invalid.\n\n        Returns:\n            str: The generated select statement.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_select_stmt(\n        cls,\n        *,\n        select_from: str,\n        select_cols: tuple[str, ...] | Literal[\"*\"] | str = \"*\",\n        function: SQLiteBuiltInFuncs | None = None,\n        where_stmt: str | None = None,\n        where_cols: tuple[str, ...] | None = None,\n        group_by: tuple[str, ...] | None = None,\n        order_by: tuple[str | tuple[str, ORDER_DIRECTION], ...] | None = None,\n        order_by_stmt: str | None = None,\n        limit: int | None = None,\n        distinct: bool = False,\n    ) -> str:\n        \"\"\"Get sql for getting row(s) from <table_name>, optionally with\n            where condition specified by <col_values>.\n\n        Check https://www.sqlite.org/lang_select.html for more details.\n\n        Args:\n            select_from (str): The table name for the generated statement.\n            select_cols (tuple[str, ...] | Literal[\"*\"] | str, optional): A list of cols included in the result row. Defaults to \"*\".\n            function (SQLiteBuiltInFuncs | None, optional): The sqlite3 function used in the selection. Defaults to None.\n            where_cols (tuple[str, ...] | None, optional): A list of cols to be compared in where\n                statement. Defaults to None.\n            where_stmt (str | None, optional): The full where statement string, this\n                precedes the <where_cols> param if set. Defaults to None.\n            group_by (tuple[str, ...] | None, optional): A list of cols for group_by statement. Defaults to None.\n            order_by (Iterable[str  |  tuple[str, ORDER_DIRECTION], ...] | None, optional):\n                A list of cols for ordering result. Defaults to None.\n            order_by_stmt (str | None, optional): The order_by statement string, this\n                precedes the <order_by> param if set. Defaults to None.\n            limit (int | None, optional): Limit the number of result entries. Defaults to None.\n            distinct (bool, optional): Whether filters the duplicated entries. Defaults to False.\n\n        Returns:\n            str: The generated select statement.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_delete_stmt(\n        cls,\n        *,\n        delete_from: str,\n        where_cols: tuple[str, ...] | None = None,\n        where_stmt: str | None = None,\n        order_by: tuple[str | tuple[str, ORDER_DIRECTION], ...] | None = None,\n        order_by_stmt: str | None = None,\n        limit: int | str | None = None,\n        returning_cols: tuple[str, ...] | Literal[\"*\"] | None = None,\n        returning_stmt: str | None = None,\n    ) -> str:\n        \"\"\"Get sql for deleting row(s) from <table_name> with specifying col value(s).\n\n        Check https://www.sqlite.org/lang_delete.html for more details.\n\n        NOTE(20240311): DELETE operation without any condition(no WHERE statement) in\n            WITHOUT_ROWID table will result in rowcount=0, see\n            https://sqlite.org/forum/forumpost/07dedbf9a1 for more details.\n            For python, python version < 3.10 will be affected by this bug.\n            A quick workaround is to add any condition in where statement, even a dummy\n            \"WHERE 1=1\" can resolve the above bug.\n            I will not add this hack here, and user can add this hack according to their needs.\n\n        NOTE: <order_by> and <limit> support are only enabled when runtime sqlite3 lib is compiled with\n            SQLITE_ENABLE_UPDATE_DELETE_LIMIT flag.\n\n        Args:\n            delete_from (str): The table name for the generated statement.\n            limit (int | str | None, optional): The value for limit expr. Defaults to None.\n            order_by (Iterable[str  |  tuple[str, ORDER_DIRECTION]] | None, optional):\n                A list of cols for ordering result. Defaults to None.\n            order_by_stmt (str | None, optional): The order_by statement string, this\n                precedes the <order_by> param if set. Defaults to None.\n            where_cols (tuple[str, ...] | None, optional): A list of cols to be compared in where\n                statement. Defaults to None.\n            where_stmt (str | None, optional): The full where statement string, this\n                precedes the <where_cols> param if set. Defaults to None.\n            returning_cols (tuple[str, ...] | Literal[\"*\"] | None): Which cols are included in the returned entries.\n                Defaults to None.\n            returning_stmt (str | None, optional): The full returning statement string, this\n                precedes the <returning_cols> param. Defaults to None.\n\n        Returns:\n            str: The generated delete statement.\n        \"\"\"\n        pass\n\n    def table_dump_asdict(self, *cols: str, **kwargs) -> dict[str, Any]:\n        \"\"\"Serialize self as a dict, containing all cols or specified cols, for DB operations.\n\n        Under the hook this method calls pydantic model_dump on self.\n        The dumped dict can be used to directly insert into the table.\n\n        Args:\n            *cols: which cols to export, if not specified, export all cols.\n            **kwargs: any other kwargs that passed to pydantic model_dump method.\n                Note that the include kwarg is used to specific which cols to dump.\n\n        Raises:\n            ValueError if failed to serialize the model, wrapping underlying\n                pydantic serialization error.\n\n        Returns:\n            A dict of dumped col values from this row.\n        \"\"\"\n        pass\n\n    def table_asdict(self, *cols: str) -> dict[str, Any]:\n        \"\"\"Directly export the self as a dict, without serializing.\n\n        Args:\n            *cols: which cols to export, if not specified, export all cols.\n            exclude_unset (bool, optional): whether include not set field of self.\n                Defaults to False, include unset fields(which will return their default values).\n\n        Returns:\n            A dict of col/values from self.\n        \"\"\"\n        pass\n\n    def table_dump_astuple(self, *cols: str, **kwargs) -> tuple[Any, ...]:\n        \"\"\"Serialize self's value as a tuple, containing all cols or specified cols, for DB operations.\n\n        This method is basically the same as table_dump_asdict, but instead return a\n            tuple of the dumped values.\n\n        Args:\n            *cols: which cols to export, if not specified, export all cols.\n            **kwargs: any other kwargs that passed to pydantic model_dump method.\n                Note that the include kwarg is used to specific which cols to dump.\n\n        Returns:\n            A tuple of dumped col values.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_serialize_mapping(cls, _in: Mapping[str, Any]) -> dict[str, Any]:\n        \"\"\"Serialize input mapping into a dict by this TableSpec, ready for DB operations.\n\n        Values in the input mapping are python types used in application.\n\n        This is a convenient method for when we only need to specify some of the cols, so that\n            we cannot use TableSpec as TableSpec requires all cols to be set.\n\n        NOTE that for APIs provided by simple_sqlite3_orm, when col/value pairs are provided as mapping,\n            the serialization will be done by the APIs, no need to call this method when using ORM.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_serialize_mappings(\n        cls, _iter: Iterable[Mapping[str, Any]]\n    ) -> Generator[dict[str, Any]]:\n        \"\"\"Convert an iter of Mappings into an generator of serialized dict.\"\"\"\n        pass\n\n    @classmethod\n    def table_deserialize_asdict_row_factory(\n        cls,\n        _cursor: sqlite3.Cursor,\n        _row: tuple[Any, ...] | Any,\n        *,\n        allow_unknown_cols: bool = True,\n    ) -> dict[str, Any]:\n        \"\"\"Deserialize raw row from a query into a dict by this TableSpec, ready for application use.\n\n        This is a convenient method when we execute query that only select some cols.\n        For this use case, use thid method as row_factory to deserialize the raw row. This method\n            will deserialize the row from raw into actual field types defined in this TableSpec.\n\n        NOTE that if `allow_unknow_cols` is True, any unknown field(including cols aliased with other name)\n            will be preserved AS IT without deserializing as this method cannot know which col the alias name maps to.\n\n        Args:\n            allow_unknown_cols (bool, optional): If True, unknown cols will be preserved AS IT into the result.\n                Defaults to True.\n\n        Raises:\n            ValueError if `allow_unknown_cols` is False and unknown cols presented, or pydantic validation failed.\n\n        Returns:\n            A dict of deserialized(except unknown cols) col/value pairs.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_deserialize_astuple_row_factory(\n        cls, _cursor: sqlite3.Cursor, _row: tuple[Any, ...] | Any\n    ) -> tuple[Any, ...]:\n        \"\"\"Deserialize raw row from a query into a tuple by this TableSpec, ready for application use.\n\n        This is a convenient method when we execute query that only select some cols.\n        For this use case, use thid method as row_factory to deserialize the raw row. This method\n            will deserialize the row from raw into actual field types defined in this TableSpec.\n\n        NOTE that any unknown field(including cols aliased with other name) will be preserved AS IT without\n            deserializing as this method cannot know which col the alias name maps to.\n\n        Raises:\n            ValueError if pydantic validation failed.\n\n        Returns:\n            A tuple of deserialized row as tuple.\n        \"\"\"\n        pass\n\nTableSpecType = TypeVar(\"TableSpecType\", bound=TableSpec)\n\n```\n--- File: src/simple_sqlite3_orm/_utils.py ---\n```python\nfrom __future__ import annotations\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Callable,\n    Literal,\n    TypeVar,\n    Union,\n)\nfrom typing_extensions import ParamSpec\n\nT = TypeVar(\"T\")\nP = ParamSpec(\"P\")\nRT = TypeVar(\"RT\")\n\ndef lru_cache(_func: Callable[P, RT], /) -> Callable[P, RT]:\n    \"\"\"typeshed doesn't use ParamSpec for lru_cache typing currently.\"\"\"\n    pass\n\nclass GenericAlias(type(list)): # Simplified based on rule of extracting definitions\n    def __new__(\n        cls, _type: type[Any], _params: type[Any] | tuple[type[Any], ...]\n    ):\n        \"\"\"For type check only, typing the _GenericAlias as GenericAlias.\"\"\"\n        pass\n\ndef map_type(\n    _in: type[Any] | SQLiteTypeAffinityLiteral | Any,\n) -> SQLiteTypeAffinity | str:\n    \"\"\"Mapping python types to corresponding sqlite storage classes.\n\n    Currently this function suports the following input:\n    1. sqlite3 native types(and wrapped in Optional).\n    2. Literal types.\n    3. Enum types with str or int as data type.\n    4. user defined affinity string, will be used as it.\n\n    \"\"\"\n    pass\n\ndef _map_from_literal(_in: Any) -> SQLiteTypeAffinity:\n    \"\"\"Support for literal of supported datatypes.\"\"\"\n    pass\n\ndef _map_from_type(_in: type[Any]) -> SQLiteTypeAffinity:\n    pass\n\nclass TypeAffinityRepr:\n    \"\"\"Map python types to sqlite3 data types with type affinity.\n\n    Currently supports:\n    1. python sqlite3 lib supported native python types.\n    2. StrEnum and IntEnum, will map to TEXT and INT accordingly.\n    3. Optional types, will map against the args inside the Optional.\n    4. Literal types, will map against the values type inside the Literal.\n\n    Attrs:\n        type_affinity (SQLiteTypeAffinity | str)\n        origin (type[Any] | SQLiteTypeAffinityLiteral | Any)\n    \"\"\"\n    type_affinity: SQLiteTypeAffinity | str\n    origin: type[Any] | SQLiteTypeAffinityLiteral | Any\n\n    def __init__(self, _in: type[Any] | SQLiteTypeAffinityLiteral | Any) -> None:\n        pass\n\n    def __str__(self) -> str:\n        pass\n\n    def __repr__(self) -> str:\n        pass\n\n    def __eq__(self, other: object) -> bool:\n        pass\n\n    def __hash__(self) -> int:\n        pass\n\nclass ConstrainRepr:\n    \"\"\"Helper class for composing full constrain statement string.\n\n    For example, for constrain statement like the following:\n        NOT NULL DEFAULT NULL CHECK (column IN (1, 2, 3))\n    can be represented ConstrainRepr as follow:\n        ConstrainRepr(\n            \"NOT NULL\",\n            (\"DEFAULT\", \"NULL\"),\n            (\"CHECK\", r\"(column IN (1, 2, 3))\")\n        )\n\n    Attrs:\n        constraints (set[str | tuple[str, str]]): a set of constrains.\n    \"\"\"\n    constraints: tuple[ConstrainLiteral | tuple[ConstrainLiteral, str] | Any, ...]\n\n    def __init__(\n        self, *params: ConstrainLiteral | tuple[ConstrainLiteral, str] | Any\n    ) -> None:\n        pass\n\n    def __str__(self) -> str:\n        pass\n\n    def __repr__(self) -> str:\n        pass\n\n    def __eq__(self, other: Any) -> bool:\n        pass\n\n    def __hash__(self) -> int:\n        pass\n\ndef gen_sql_stmt(*components: str, end_with: str | None = \";\") -> str:\n    \"\"\"Combine each components into a single sql stmt.\"\"\"\n    pass\n\nclass ColsSelectFactory(tuple[T, ...]):\n    \"\"\"A factory type to generate cols name checker.\n\n    Usage:\n\n    MyTableCols = Literal[\"entry_id\", \"entry_context\", \"entry_type\"]\n    MyTableColsChecker = ColsCheckerFactory[MyTableCols]\n\n    # now you can use `MyTableColsChecker` to specify a tuple of cols name as follow:\n    cols_to_select = MyTableColsChecker(\"unknown\", \"invalid_col\")  # type checker err\n    cols_to_select = MyTableColsChecker(\"entry_id\", \"entry_type\")  # valid\n\n    # at runtime, `cols_to_select` is a regular `tuple` object.\n\n    \"\"\"\n\n    def __new__(cls, *cols: T) -> tuple[T, ...]:\n        pass\n\n```\n--- File: src/simple_sqlite3_orm/_typing.py ---\n```python\n\"\"\"Typing helpers definition.\"\"\"\n\nfrom __future__ import annotations\nimport sqlite3\nfrom sqlite3 import Cursor, Row\nfrom typing import Any, Callable\nfrom typing_extensions import TypeAlias\n\nRowFactoryType: TypeAlias = (\n    \"Callable[[Cursor, Row | tuple[Any, ...] | Any], Any] | type[sqlite3.Row]\"\n)\n\"\"\"Type hint for callable that can be used as sqlite3 row_factory.\"\"\"\n\nConnectionFactoryType: TypeAlias = \"Callable[[], sqlite3.Connection]\"\nColsDefinitionWithDirection: TypeAlias = \"tuple[str | tuple[str, ORDER_DIRECTION], ...]\"\nColsDefinition: TypeAlias = \"tuple[str, ...]\"\n\n```\n--- File: src/simple_sqlite3_orm/_orm/_pool.py ---\n```python\nfrom __future__ import annotations\nimport asyncio\nimport queue\nimport threading\nfrom collections.abc import Callable, Generator\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import TYPE_CHECKING, AsyncGenerator, TypeVar\nfrom typing_extensions import Concatenate, ParamSpec, Self\n\nP = ParamSpec(\"P\")\nRT = TypeVar(\"RT\")\n\ndef _python_exit():\n    pass\n\ndef _wrap_with_thread_ctx(func: Callable[Concatenate[ORMBase, P], RT]):\n    pass\n\ndef _wrap_with_async_ctx(\n    func: Callable[Concatenate[ORMBase, P], RT],\n):\n    pass\n\ndef _wrap_generator_with_thread_ctx(\n    func: Callable[Concatenate[ORMBase, P], Generator[RT]],\n):\n    pass\n\ndef _wrap_generator_with_async_ctx(\n    func: Callable[Concatenate[ORMBase, P], Generator[RT]],\n):\n    pass\n\nclass ORMThreadPoolBase(ORMCommonBase[TableSpecType]):\n    \"\"\"\n    See https://www.sqlite.org/wal.html#concurrency for more details.\n\n    For the row_factory arg, please see ORMBase.__init__ for more details.\n    \"\"\"\n    _thread_id_orms: dict[int, ORMBase]\n    _num_of_cons: int\n    _pool: ThreadPoolExecutor\n    _closed: bool\n    __class_getitem__ = classmethod(parameterized_class_getitem)\n\n    def __init__(\n        self,\n        table_name: str | None = None,\n        schema_name: str | None = None,\n        *,\n        con_factory: ConnectionFactoryType,\n        number_of_cons: int,\n        thread_name_prefix: str = \"\",\n        row_factory: RowFactorySpecifier = \"table_spec\",\n    ) -> None:\n        pass\n\n    def __enter__(self) -> Self:\n        pass\n\n    def __exit__(self, exec_type, exc_val, exc_tb):\n        pass\n\n    def _thread_initializer(self, con_factory, row_factory) -> None:\n        \"\"\"Prepare thread_scope ORMBase instance for this worker thread.\"\"\"\n        pass\n\n    @property\n    def _thread_scope_orm(self) -> ORMBase[TableSpecType]:\n        \"\"\"Get thread scope ORMBase instance.\"\"\"\n        pass\n\n    def _caller_gen(\n        self, _queue: queue.Queue[RT], _caller_exit: threading.Event\n    ) -> Generator[RT]:\n        pass\n\n    @property\n    def orm_table_name(self) -> str:\n        \"\"\"The unique name of the table for use in sql statement.\n\n        If multiple databases are attached to <con> and <schema_name> is availabe,\n            return \"<schema_name>.<table_name>\", otherwise return <table_name>.\n        \"\"\"\n        pass\n\n    def _worker_shutdown(\n        self, shutdown_barrier: threading.Barrier, shutdown_lock: threading.Lock\n    ):\n        pass\n\n    def orm_pool_shutdown(self, *, wait=True, close_connections=True) -> None:\n        \"\"\"Shutdown the ORM connections thread pool.\n\n        It is safe to call this method multiple time.\n        This method is NOT thread-safe, and should be called at the main thread,\n            or the thread that creates this thread pool.\n\n        Args:\n            wait (bool, optional): Wait for threads join. Defaults to True.\n            close_connections (bool, optional): Close all the connections. Defaults to True.\n        \"\"\"\n        pass\n\n    orm_bootstrap_db: Callable\n    orm_execute: Callable\n    orm_execute_gen: Callable\n    orm_executemany: Callable\n    orm_executescript: Callable\n    orm_create_table: Callable\n    orm_create_index: Callable\n    orm_select_entries: Callable\n    orm_select_entry: Callable\n    orm_insert_entries: Callable\n    orm_insert_mappings: Callable\n    orm_insert_mapping: Callable\n    orm_insert_entry: Callable\n    orm_update_entries: Callable\n    orm_update_entries_many: Callable\n    orm_delete_entries: Callable\n    orm_delete_entries_with_returning: Callable\n    orm_select_all_with_pagination: Callable\n    orm_check_entry_exist: Callable\n\nORMThreadPoolBaseType = TypeVar(\"ORMThreadPoolBaseType\", bound=ORMThreadPoolBase)\n\nclass AsyncORMBase(ORMThreadPoolBase[TableSpecType]):\n    \"\"\"\n    NOTE: the supoprt for async ORM is experimental! The APIs might be changed a lot\n        in the following releases.\n\n    For the row_factory arg, please see ORMBase.__init__ for more details.\n    \"\"\"\n    _loop: asyncio.AbstractEventLoop\n    \"\"\"Bound event loop when instanitiate this pool.\"\"\"\n\n    if not TYPE_CHECKING:\n        def __init__(self, *args, **kwargs) -> None:\n            pass\n\n    async def _async_caller_gen(\n        self,\n        _queue: queue.Queue[RT],\n        _se: asyncio.Semaphore,\n        _caller_exit: threading.Event,\n    ) -> AsyncGenerator[RT]:\n        pass\n\n    orm_bootstrap_db: Callable\n    orm_execute: Callable\n    orm_execute_gen: Callable\n    orm_executemany: Callable\n    orm_executescript: Callable\n    orm_create_table: Callable\n    orm_create_index: Callable\n    orm_select_entries: Callable\n    orm_select_entry: Callable\n    orm_insert_entries: Callable\n    orm_insert_mappings: Callable\n    orm_insert_mapping: Callable\n    orm_insert_entry: Callable\n    orm_update_entries: Callable\n    orm_update_entries_many: Callable\n    orm_delete_entries: Callable\n    orm_delete_entries_with_returning: Callable\n    orm_select_all_with_pagination: Callable\n    orm_check_entry_exist: Callable\n\nAsyncORMBaseType = TypeVar(\"AsyncORMBaseType\", bound=AsyncORMBase)\n\n```\n--- File: src/simple_sqlite3_orm/_orm/_base.py ---\n```python\nfrom __future__ import annotations\nimport sqlite3\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Callable,\n    Generator,\n    Generic,\n    Iterable,\n    Literal,\n    Mapping,\n    TypeVar,\n    Union,\n    overload,\n)\nfrom typing_extensions import ParamSpec, Self\n\nP = ParamSpec(\"P\")\nRT = TypeVar(\"RT\")\nDoNotChangeRowFactory = Literal[\"do_not_change\"]\nDO_NOT_CHANGE_ROW_FACTORY: DoNotChangeRowFactory\nRowFactorySpecifier = Union[\n    RowFactoryType,\n    Literal[\n        \"sqlite3_row_factory\",\n        \"table_spec\",\n        \"table_spec_no_validation\",\n    ],\n    DoNotChangeRowFactory,\n    None,\n]\n\"\"\"Specifiy which row_factory to use.\n\nFor each option:\n    1. RowFactoryType: specify arbitrary row_factory.\n    2. None: clear the connection scope row_factory(set to None).\n    3. \"sqlite3_row_factory\": set to use sqlite3.Row as row_factory.\n    4. \"table_spec\": use TableSpec.table_row_factory as row_factory.\n    5. \"table_spec_no_validation\": use TableSpec.table_row_factory as row_factory, but with validation=False.\n    6. \"do_not_change\": do not change the connection scope row_factory.\n\"\"\"\n\ndef _select_row_factory(\n    table_spec: type[TableSpec],\n    row_factory_specifier: RowFactorySpecifier,\n) -> RowFactoryType | None | DoNotChangeRowFactory:\n    \"\"\"Helper function to get row_factory by row_factory_specifier.\"\"\"\n    pass\n\ndef _merge_iters(\n    _left: Iterable[Mapping[str, Any]], _right: Iterable[Mapping[str, Any]]\n) -> Generator[dict[str, Any]]:\n    \"\"\"Merge two iterables of Mappings into one iterable of dict.\"\"\"\n    pass\n\nclass ORMCommonBase(Generic[TableSpecType]):\n    orm_table_spec: type[TableSpecType]\n    orm_bootstrap_table_name: str\n    orm_bootstrap_create_table_params: str | CreateTableParams\n    orm_bootstrap_indexes_params: list[str | CreateIndexParams]\n    if not TYPE_CHECKING:\n        _orm_table_name: str\n        \"\"\"\n        Used by ORM internally, should not be set directly.\n\n        Directly setting this variable is DEPRECATED, use orm_bootstrap_table_name instead.\n        \"\"\"\n\n    def __init_subclass__(cls, **kwargs) -> None:\n        pass\n\nclass ORMBase(ORMCommonBase[TableSpecType]):\n    \"\"\"ORM layer for <TableSpecType>.\n\n    NOTE that instance of ORMBase cannot be used in multi-threaded environment.\n        Use ORMThreadPoolBase for multi-threaded environment.\n        For asyncio, use AsyncORMThreadPoolBase.\n\n    The underlying connection can be used in multiple connection for accessing different table in\n        the connected database.\n\n    Attributes:\n        con (sqlite3.Connection | ConnectionFactoryType): The sqlite3 connection used by this ORM, or a factory\n            function that returns a sqlite3.Connection object on calling.\n        table_name (str): The name of the table in the database <con> connected to. This field will take prior over the\n            table_name specified by orm_bootstrap_table_name attr to allow using different table_name for just one connection.\n        schema_name (str): The schema of the table if multiple databases are attached to <con>.\n        row_factory (RowFactorySpecifier): The connection scope row_factory to use. Default to \"table_sepc\".\n    \"\"\"\n    _con: sqlite3.Connection\n    _schema_name: str | Literal[\"temp\"] | None\n    __class_getitem__ = classmethod(parameterized_class_getitem)\n\n    def orm_bootstrap_db(self) -> None:\n        \"\"\"Bootstrap the database this ORM connected to.\n\n        This method will refer to the following attrs to setup table and indexes:\n        1. orm_bootstrap_table_name: the name of table to be created.\n        2. orm_bootstrap_create_table_params: the sqlite query to create the table,\n            it can be provided as sqlite query, or CreateTableParams for table_create_stmt\n            to generate sqlite query from.\n            It not specified, the table create statement will be generated with default configs,\n            See table_spec.table_create_stmt method for more details.\n        3. orm_bootstrap_indexes_params: optional, a list of sqlite query or\n            CreateIndexParams(for table_create_index_stmt to generate sqlite query from) to\n            create indexes from.\n\n        NOTE that ORM will not know whether the connected database has already been\n            bootstrapped or not, this is up to caller to check.\n        \"\"\"\n        pass\n\n    def __init__(\n        self,\n        con: sqlite3.Connection | ConnectionFactoryType,\n        table_name: str | None = None,\n        schema_name: str | Literal[\"temp\"] | None = None,\n        *,\n        row_factory: RowFactorySpecifier = \"table_spec\",\n    ) -> None:\n        pass\n\n    def __enter__(self) -> Self:\n        pass\n\n    def __exit__(self, exec_type, exc_val, exc_tb):\n        pass\n\n    @property\n    def orm_con(self) -> sqlite3.Connection:\n        \"\"\"A reference to the underlying sqlite3.Connection.\n\n        This is for directly executing sql stmts.\n        \"\"\"\n        pass\n\n    @property\n    def orm_table_name(self) -> str:\n        \"\"\"The unique name of the table for use in sql statement.\n\n        If multiple databases are attached to <con> and <schema_name> is availabe,\n            return \"<schema_name>.<table_name>\", otherwise return <table_name>.\n        \"\"\"\n        pass\n\n    @property\n    def orm_conn_row_factory(self) -> RowFactoryType | None:\n        \"\"\"Get and set the connection scope row_factory for this ORM instance.\"\"\"\n        pass\n\n    @orm_conn_row_factory.setter\n    def orm_conn_row_factory(self, _row_factory: RowFactoryType | None) -> None:\n        pass\n\n    @overload\n    def orm_execute(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: Callable[[sqlite3.Cursor, Any], RT],\n    ) -> list[RT]: ...\n\n    @overload\n    def orm_execute(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: DoNotChangeRowFactory = DO_NOT_CHANGE_ROW_FACTORY,\n    ) -> list[TableSpecType]: ...\n\n    @overload\n    def orm_execute(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: None,\n    ) -> list[tuple[Any, ...]]: ...\n\n    def orm_execute(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: RowFactorySpecifier\n        | DoNotChangeRowFactory = DO_NOT_CHANGE_ROW_FACTORY,\n    ) -> list[Any]:\n        \"\"\"Execute one sql statement and get the all the result.\n\n        NOTE that caller needs to serialize the `params` before hands if needed, `orm_execute` will\n            not do any processing over the input `params`, and just use as it for execution.\n        The result will be fetched with fetchall API and returned as it.\n\n        Args:\n            sql_stmt (str): The sqlite statement to be executed.\n            params (tuple[Any, ...] | dict[str, Any] | None, optional): The parameters to be bound\n                to the sql statement execution. Defaults to None, not passing any params.\n            row_factory (RowFactorySpecifier | DoNotChangeRowFactory, optional): specify to use\n                different row_factory for the query. Default to not change the current row_factory.\n                NOTE that None value here means unset the row_factory for this query.\n\n        Returns:\n            list[Any]: A list contains all the result entries.\n        \"\"\"\n        pass\n\n    @overload\n    def orm_execute_gen(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: Callable[[sqlite3.Cursor, Any], RT],\n    ) -> Generator[RT]: ...\n\n    @overload\n    def orm_execute_gen(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: DoNotChangeRowFactory = DO_NOT_CHANGE_ROW_FACTORY,\n    ) -> Generator[TableSpecType]: ...\n\n    @overload\n    def orm_execute_gen(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: None,\n    ) -> Generator[tuple[Any, ...]]: ...\n\n    def orm_execute_gen(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: RowFactorySpecifier\n        | DoNotChangeRowFactory = DO_NOT_CHANGE_ROW_FACTORY,\n    ) -> Generator[Any]:\n        \"\"\"The same as orm_execute, but as a Generator.\"\"\"\n        pass\n\n    def orm_executemany(\n        self,\n        sql_stmt: str,\n        params: Iterable[tuple[Any, ...] | dict[str, Any]],\n    ) -> int:\n        \"\"\"Repeatedly execute the parameterized DML SQL statement sql.\n\n        NOTE that any returning values will be discarded, including with RETURNING stmt.\n\n        Args:\n            sql_stmt (str): The sqlite statement to be executed.\n            params (Iterable[tuple[Any, ...] | dict[str, Any]]): The set of parameters to be bound\n                to the sql statement execution.\n\n        Returns:\n            The affected row count.\n        \"\"\"\n        pass\n\n    def orm_executescript(self, sql_script: str) -> int:\n        \"\"\"Execute one sql script.\n\n        NOTE that any returning values will be discarded, including with RETURNING stmt.\n\n        Args:\n            sql_script (str): The sqlite script to be executed.\n\n        Returns:\n            The affected row count.\n        \"\"\"\n        pass\n\n    def orm_create_table(\n        self,\n        *,\n        allow_existed: bool = False,\n        strict: bool = False,\n        without_rowid: bool = False,\n        _stmt: str | None = None,\n    ) -> None:\n        \"\"\"Create the table defined by this ORM with <orm_table_spec>.\n\n        NOTE: strict table option is supported after sqlite3 3.37.\n\n        Args:\n            allow_existed (bool, optional): Do not abort on table already created.\n                Set True equals to add \"IF NOT EXISTS\" in the sql statement. Defaults to False.\n            strict (bool, optional): Enable strict field type check. Defaults to False.\n                See https://www.sqlite.org/stricttables.html for more details.\n            without_rowid (bool, optional): Create the table without ROWID. Defaults to False.\n                See https://www.sqlite.org/withoutrowid.html for more details.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            sqlite3.DatabaseError on failed sql execution.\n        \"\"\"\n        pass\n\n    def orm_create_index(\n        self,\n        *,\n        index_name: str,\n        index_keys: ColsDefinition | ColsDefinitionWithDirection,\n        allow_existed: bool = False,\n        unique: bool = False,\n        _stmt: str | None = None,\n    ) -> None:\n        \"\"\"Create index according to the input arguments.\n\n        Args:\n            index_name (str): The name of the index.\n            index_keys (ColsDefinition | ColsDefinitionWithDirection): The columns for the index.\n            allow_existed (bool, optional): Not abort on index already created. Defaults to False.\n            unique (bool, optional): Not allow duplicated entries in the index. Defaults to False.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            sqlite3.DatabaseError on failed sql execution.\n        \"\"\"\n        pass\n\n    @overload\n    def orm_select_entries(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _row_factory: Callable[[sqlite3.Cursor, Any], RT],\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[RT]: ...\n\n    @overload\n    def orm_select_entries(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _row_factory: None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[TableSpecType | Any]: ...\n\n    def orm_select_entries(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _row_factory: RowFactoryType | None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[TableSpecType | Any]:\n        \"\"\"Select entries from the table accordingly.\n\n        Args:\n            col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n                the pairs in this mapping will take prior than the one specified in <col_values>.\n            _distinct (bool, optional): Deduplicate and only return unique entries. Defaults to False.\n            _order_by (ColsDefinition | ColsDefinitionWithDirection | None, optional):\n                Order the result accordingly. Defaults to None, not sorting the result.\n            _limit (int | None, optional): Limit the number of result entries. Defaults to None.\n            _row_factory (RowFactoryType | None, optional): Set to use different row factory for this query.\n                Defaults to None(do not change row_factory).\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n            **col_values: provide col/value pairs by kwargs. Col/value pairs in <col_values> have lower priority over\n                the one specified by <_col_vlues_dict>.\n\n        Raises:\n            sqlite3.DatabaseError on failed sql execution.\n\n        Yields:\n            Generator[TableSpecType | Any]: A generator that can be used to yield entry from result.\n        \"\"\"\n        pass\n\n    @overload\n    def orm_select_entry(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _row_factory: Callable[[sqlite3.Cursor, Any], RT],\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> RT: ...\n\n    @overload\n    def orm_select_entry(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _row_factory: None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> TableSpecType | Any: ...\n\n    def orm_select_entry(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _row_factory: RowFactoryType | None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> TableSpecType | Any | None:\n        \"\"\"Select exactly one entry from the table accordingly.\n\n        NOTE that if the select result contains more than one entry, this method will return\n            the FIRST one from the result with fetchone API.\n\n        Args:\n            col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n                the pairs in this mapping will take prior than the one specified in <col_values>.\n            _distinct (bool, optional): Deduplicate and only return unique entries. Defaults to False.\n            _order_by (ColsDefinition | ColsDefinitionWithDirection | None, optional):\n                Order the result accordingly. Defaults to None, not sorting the result.\n            _row_factory (RowFactoryType | None, optional): Set to use different row factory for this query.\n                Defaults to None(do not change row_factory).\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n            **col_values: provide col/value pairs by kwargs. Col/value pairs in <col_values> have lower priority over\n                the one specified by <_col_vlues_dict>.\n\n        Raises:\n            sqlite3.DatabaseError on failed sql execution.\n\n        Returns:\n            TableSpecType | Any: Exactly one entry, or None if not hit.\n        \"\"\"\n        pass\n\n    def orm_insert_entries(\n        self,\n        _in: Iterable[TableSpecType],\n        *,\n        or_option: OR_OPTIONS | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"Insert an iterable of rows represented as TableSpec insts into this table.\n\n        Args:\n            _in (Iterable[TableSpecType]): An iterable of rows as TableSpec insts to insert.\n            or_option (INSERT_OR | None, optional): The fallback operation if insert failed. Defaults to None.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            ValueError: On invalid types of _in.\n            sqlite3.DatabaseError: On failed sql execution.\n\n        Returns:\n            int: Number of inserted entries.\n        \"\"\"\n        pass\n\n    def orm_insert_mappings(\n        self,\n        _in: Iterable[Mapping[str, Any]],\n        *,\n        or_option: OR_OPTIONS | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"Insert an iterable of rows represented as mappings into this table.\n\n        Each mapping stores cols with values in application types. Assuming that all entries in\n            this Iterable contains mapping with the same schema.\n\n        Args:\n            _in (Iterable[Mapping[str, Any]]): An iterable of mappings to insert.\n            or_option (INSERT_OR | None, optional): The fallback operation if insert failed. Defaults to None.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            ValueError: On invalid types of _in.\n            sqlite3.DatabaseError: On failed sql execution.\n\n        Returns:\n            int: Number of inserted entries.\n        \"\"\"\n        pass\n\n    def orm_insert_entry(\n        self,\n        _in: TableSpecType,\n        *,\n        or_option: OR_OPTIONS | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"Insert exactly one entry into this table.\n\n        Args:\n            _in (TableSpecType): The instance of entry to insert.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            ValueError: On invalid types of _in.\n            sqlite3.DatabaseError: On failed sql execution.\n\n        Returns:\n            int: Number of inserted entries. In normal case it should be 1.\n        \"\"\"\n        pass\n\n    def orm_insert_mapping(\n        self,\n        _in: Mapping[str, Any],\n        *,\n        or_option: OR_OPTIONS | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"Insert exactly one entry(represented as a mapping) into this table.\n\n        Args:\n            _in (TableSpecType): The instance of entry to insert.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            ValueError: On invalid types of _in.\n            sqlite3.DatabaseError: On failed sql execution.\n\n        Returns:\n            int: Number of inserted entries. In normal case it should be 1.\n        \"\"\"\n        pass\n\n    def orm_update_entries(\n        self,\n        *,\n        set_values: Mapping[str, Any] | TableSpec,\n        where_cols_value: Mapping[str, Any] | None = None,\n        where_stmt: str | None = None,\n        or_option: OR_OPTIONS | None = None,\n        _extra_params: Mapping[str, Any] | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"UPDATE specific entries by matching <where_cols_value>.\n\n        NOTE: if you want to using the same query stmt with different set of params(set col/values and/or where col/values),\n            it is highly recommended to use `orm_update_entries_many` API, it will be significantly faster to call `orm_update_entries`\n            in a for loop(in my test with 2000 entries, using `orm_update_entries_many` is around 300 times faster).\n        NOTE: currently UPDATE-WITH-LIMIT and RETURNING are not supported by this method.\n\n        Args:\n            set_values (Mapping[str, Any] | TableSpec): values to update.\n            where_cols_value (Mapping[str, Any], optional): cols to matching. This method will\n                also generate WHERE statement of matching each cols specified in this mapping.\n            where_stmt (str | None, optional): directly provide WHERE statement. If provided,\n                <where_cols_value> will only be used as params.\n            or_option (OR_OPTIONS | None, optional): specify the operation if UPDATE failed.\n            _extra_params (Mapping[str, Any] | None, optional): provide extra named params\n                for sqlite3 query execution. NOTE that `_extra_params` takes higher priority\n                to any named params specified by `where_cols_value` and `set_values`. Defaults to None.\n            _stmt (str | None, optional): directly provide the UPDATE query, if provided,\n                <where_cols_value>, <where_stmt> and <or_option> will be ignored.\n\n        Raises:\n            SQLite3 DB Errors on failed operations.\n\n        Returns:\n            Affected rows count.\n        \"\"\"\n        pass\n\n    @overload\n    def orm_update_entries_many(\n        self,\n        *,\n        set_cols: tuple[str, ...],\n        where_cols: tuple[str, ...] | None = None,\n        where_stmt: str | None = None,\n        set_cols_value: Iterable[Mapping[str, Any]],\n        where_cols_value: Iterable[Mapping[str, Any]] | None = None,\n        or_option: OR_OPTIONS | None = None,\n        _extra_params: Mapping[str, Any] | None = None,\n        _extra_params_iter: Iterable[Mapping[str, Any]] | None = None,\n        _stmt: None = None,\n    ) -> int: ...\n\n    @overload\n    def orm_update_entries_many(\n        self,\n        *,\n        set_cols: None = None,\n        where_cols: None = None,\n        where_stmt: None = None,\n        set_cols_value: None = None,\n        where_cols_value: None = None,\n        or_option: None = None,\n        _extra_params: Mapping[str, Any] | None = None,\n        _extra_params_iter: Iterable[Mapping[str, Any]] | None = None,\n        _stmt: str,\n    ) -> int: ...\n\n    def orm_update_entries_many(\n        self,\n        *,\n        set_cols: tuple[str, ...] | None = None,\n        where_cols: tuple[str, ...] | None = None,\n        where_stmt: str | None = None,\n        set_cols_value: Iterable[Mapping[str, Any]] | None = None,\n        where_cols_value: Iterable[Mapping[str, Any]] | None = None,\n        or_option: OR_OPTIONS | None = None,\n        _extra_params: Mapping[str, Any] | None = None,\n        _extra_params_iter: Iterable[Mapping[str, Any]] | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"executemany version of orm_update_entries.\n\n        Params like `set_cols_value` and `where_cols_value` need to be provided as iterables.\n        NOTE that the execution will end and return when any of the input iterable exhausted.\n\n        NOTE that `_extra_params` and `_extra_params_iter` will not be serialized. Caller needs to\n            provide the serialized mappings ready for `executemany`.\n\n        Args:\n            set_cols (tuple[str, ...]): Cols to be updated.\n            set_cols_value (Iterable[Mapping[str, Any]]): An iterable of values of to-be-updated cols.\n            where_cols (tuple[str, ...] | None, optional): Cols to match. The WHERE stmt will be generated\n                based on this param. Defaults to None.\n            where_cols_value (Iterable[Mapping[str, Any]] | None, optional): An iterable of values of cols to match.\n                Defaults to None.\n            where_stmt (str | None, optional): Directly provide the WHERE stmt. If specified, both `where_cols` and\n                `where_cols_value` will be ignored. Caller needs to feed the params with `_extra_params` or `_extra_params_iter`.\n                Defaults to None.\n            or_option (OR_OPTIONS | None, optional): specify the operation if UPDATE failed. Defaults to None.\n            _extra_params (Mapping[str, Any] | None, optional): A fixed mapping to be injected for each execution.\n                NOTE that this param is only allowed when at least one of `where_cols_value`, `set_cols_value` or `_extra_params_iter` is specified.\n                Defaults to None.\n            _extra_params_iter (Iterable[Mapping[str, Any]] | None, optional): An iterable of mappings to be injected for each execution. Defaults to None.\n            _stmt (str | None, optional): Directly provide the UPDATE query, if specified, params except `_extra_params` and `_extra_params_iter`\n                will be ignored. Defaults to None.\n\n        Raises:\n            ValueError: If `where_cols_value` and `where_cols` are not be both None or both specifed.\n            ValueError: If `_stmt` is not used and `set_cols` and/or `set_cols_value` are not specified.\n            ValueError: If `_extra_params` is specified without any other iterable params provided.\n            sqlite3 DB error on execution failed.\n\n        Returns:\n            Affected rows count.\n        \"\"\"\n        pass\n\n    def orm_delete_entries(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> int:\n        \"\"\"Delete entries from the table accordingly.\n\n        Args:\n            col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n                the pairs in this mapping will take prior than the one specified in <col_values>.\n            _order_by (ColsDefinition | ColsDefinitionWithDirection | None, optional): Order the matching entries\n                before executing the deletion, used together with <_limit>. Defaults to None.\n            _limit (int | None, optional): Only delete <_limit> number of entries. Defaults to None.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n            **col_values: provide col/value pairs by kwargs. Col/value pairs in <col_values> have lower priority over\n                the one specified by <_col_vlues_dict>.\n\n        Returns:\n            int: The num of entries deleted.\n        \"\"\"\n        pass\n\n    @overload\n    def orm_delete_entries_with_returning(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _returning_cols: ColsDefinition | Literal[\"*\"],\n        _row_factory: Callable[[sqlite3.Cursor, Any], RT],\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[RT]: ...\n\n    @overload\n    def orm_delete_entries_with_returning(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _returning_cols: ColsDefinition | Literal[\"*\"],\n        _row_factory: None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[TableSpecType | Any]: ...\n\n    def orm_delete_entries_with_returning(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _returning_cols: ColsDefinition | Literal[\"*\"],\n        _row_factory: RowFactoryType | None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[TableSpecType | Any]:\n        \"\"\"Delete entries from the table accordingly.\n\n        NOTE that only sqlite3 version >= 3.35 supports returning statement.\n\n        Args:\n            col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n                the pairs in this mapping will take prior than the one specified in <col_values>.\n            _order_by (ColsDefinition | ColsDefinitionWithDirection | None, optional): Order the matching entries\n                before executing the deletion, used together with <_limit>. Defaults to None.\n            _limit (int | None, optional): Only delete <_limit> number of entries. Defaults to None.\n            _returning_cols (ColsDefinition | Literal[\"*\"] ): Return the deleted entries on execution.\n            _row_factory (RowFactoryType | None, optional): Set to use different row factory for this query.\n                Defaults to None(do not change row_factory).\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n            **col_values: provide col/value pairs by kwargs. Col/value pairs in <col_values> have lower priority over\n                the one specified by <_col_vlues_dict>.\n\n        Returns:\n            Generator[TableSpecType | Any]: If <_returning_cols> is defined, returns a generator which can\n                be used to yield the deleted entries from.\n        \"\"\"\n        pass\n\n    def orm_select_all_with_pagination(\n        self, *, batch_size: int\n    ) -> Generator[TableSpecType | Any]:\n        \"\"\"Select all entries from the table accordingly with pagination.\n\n        This is implemented by seek with rowid, so it will not work on without_rowid table.\n\n        Args:\n            batch_size (int): The entry number for each page.\n\n        Raises:\n            ValueError on invalid batch_size.\n            sqlite3.DatabaseError on failed sql execution.\n\n        Yields:\n            Generator[TableSpecType, None, None]: A generator that can be used to yield entry from result.\n        \"\"\"\n        pass\n\n    def orm_check_entry_exist(\n        self, col_value_pairs: Mapping[str, Any] | None = None, **col_values: Any\n    ) -> bool:\n        \"\"\"A quick method to check whether entry(entries) indicated by cols exists.\n\n        This method uses COUNT function to count the selected entry.\n\n        Args:\n            col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n                the pairs in this mapping will take prior than the one specified in <col_values>.\n            **cols: cols pair to locate the entry(entries).\n\n        Returns:\n            Returns True if at least one entry matches the input cols exists, otherwise False.\n        \"\"\"\n        pass\n\nORMBaseType = TypeVar(\"ORMBaseType\", bound=ORMBase)\n\n```\n--- File: src/simple_sqlite3_orm/_orm/_utils.py ---\n```python\nfrom __future__ import annotations\nfrom typing import Any\n\ndef parameterized_class_getitem(\n    cls, params: Any | type[Any] | type[TableSpecType] | tuple[type[Any], ...]\n) -> Any:\n    pass\n\n```",
        "full_code_skeleton_structured": [
            {
                "file_path": "src/simple_sqlite3_orm/_types.py",
                "code": "\"\"\"Types helper definition.\"\"\"\n\nfrom __future__ import annotations\nimport datetime\nfrom typing import Any\nfrom pydantic import BeforeValidator, PlainSerializer\nfrom typing_extensions import Annotated\n\ndef _datetime_validator(\n    _in: int | float | str | datetime.datetime | Any,\n) -> datetime.datetime:\n    \"\"\"A pydantic validator helper for parsing serialized datetime from database.\"\"\"\n    pass\n\nDatetimeUnixTimestamp = Annotated[\n    datetime.datetime,\n    BeforeValidator(_datetime_validator),\n    PlainSerializer(lambda x: x.timestamp(), return_type=float),\n]\n\"\"\"datetime.datetime as unixtimestamp in seconds serialized as a float in db.\"\"\"\n\nDatetimeUnixTimestampInt = Annotated[\n    datetime.datetime,\n    BeforeValidator(_datetime_validator),\n    PlainSerializer(lambda x: int(x.timestamp()), return_type=int),\n]\n\"\"\"datetime.datetime as unixtimestamp in seconds serialized as an int in db.\"\"\"\n\nDatetimeISO8601 = Annotated[\n    datetime.datetime,\n    BeforeValidator(_datetime_validator),\n    PlainSerializer(lambda x: x.isoformat(), return_type=str),\n]\n\"\"\"datetime.datetime as str(ISO8601 formatted) serialized as a string in db.\"\"\"\n\n"
            },
            {
                "file_path": "src/simple_sqlite3_orm/utils.py",
                "code": "\"\"\"General utils for sqlite3.\"\"\"\n\nfrom __future__ import annotations\nimport sqlite3\nfrom typing import (\n    Any,\n    Generator,\n    Iterable,\n    Literal,\n)\n\ndef enable_wal_mode(con: sqlite3.Connection, relax_sync_mode: bool = True):\n    \"\"\"Enable WAL mode for the connected database.\n\n    Note that for multiple databases being attached, WAL mode only guarantees\n        atomic within each individual database file. See https://www.sqlite.org/lang_attach.html\n        for more details.\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n        relax_sync_mode (bool): Also set the synchronous mode to NORMAL. Default to True.\n\n    Raises:\n        sqlite3.DatabaseError on failed sql execution.\n    \"\"\"\n    pass\n\ndef enable_tmp_store_at_memory(con: sqlite3.Connection):\n    \"\"\"Locate the temp tables at memory.\n\n    See https://www.sqlite.org/pragma.html#pragma_temp_store for more details.\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n\n    Raises:\n        sqlite3.DatabaseError on failed sql execution.\n    \"\"\"\n    pass\n\ndef enable_mmap(con: sqlite3.Connection, mmap_size: int = DEFAULT_MMAP_SIZE):\n    \"\"\"Enable mmap for the connection.\n\n    See https://www.sqlite.org/pragma.html#pragma_mmap_size for more\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n        mmap_size (int, optional): The max mmap size. Defaults to <DEFAULT_MMAP_SIZE=16MiB>.\n\n    Raises:\n        sqlite3.DatabaseError on failed sql execution.\n    \"\"\"\n    pass\n\ndef optimize_db(con: sqlite3.Connection):\n    \"\"\"Execute optimize PRAGMA on the target database.\n\n    See https://www.sqlite.org/pragma.html#pragma_optimize.\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n\n    Raises:\n        sqlite3.DatabaseError on failed sql execution.\n    \"\"\"\n    pass\n\ndef check_db_integrity(con: sqlite3.Connection, table_name: str | None = None) -> bool:\n    \"\"\"Execute integrity_check PRAGMA on the target database(or specific table at the database).\n\n    See https://www.sqlite.org/pragma.html#pragma_integrity_check for more details.\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n        table_name (str | None, optional): If specified, the integrity_check will only be performed\n            against this table. Defaults to None, means performing the check on the whole database.\n\n    Returns:\n        bool: True for integrity_check passed on the target database, False for errors found.\n    \"\"\"\n    pass\n\ndef lookup_table(con: sqlite3.Connection, table_name: str) -> bool:\n    \"\"\"Check if specific table existed on the target database.\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n        table_name (str): The name of table to lookup.\n\n    Returns:\n        bool: True for table existed, False for not found.\n    \"\"\"\n    pass\n\ndef attach_database(\n    con: sqlite3.Connection, database: str | Literal[\":memory:\"], schema_name: str\n) -> str:\n    \"\"\"Attach another database onto the current connection.\n\n    See https://www.sqlite.org/lang_attach.html for more details.\n\n    Args:\n        con (sqlite3.Connection): The current database connection.\n        database (str | Literal[\":memory:\"]): The new database to be attached.\n        schema_name (str): The alias name of the newly connected database for distinguishing\n            between the already connected database in this connection.\n\n    Returns:\n        str: The schema_name of the newly connected database in the connection.\n    \"\"\"\n    pass\n\n@overload\ndef check_pragma_compile_time_options(\n    con: sqlite3.Connection, option_name: str\n) -> tuple[str, Any] | None: ...\n\n@overload\ndef check_pragma_compile_time_options(\n    con: sqlite3.Connection, option_name: None = None\n) -> list[tuple[str, Any]]: ...\n\ndef check_pragma_compile_time_options(\n    con: sqlite3.Connection, option_name: str | None = None\n) -> tuple[str, Any] | None | list[tuple[str, Any]]:\n    \"\"\"Get the runtime sqlite3 library's compile time options.\n\n    Args:\n        con (sqlite3.Connection): The current database connection.\n        option_name (str | None, optional): The option to lookup. If not specified,\n            it will return all the options and its values. Defaults to None.\n\n    Returns:\n        tuple[str, Any] | None | list[tuple[str, Any]]: Looked up options and its values.\n    \"\"\"\n    pass\n\ndef batched(\n    iterable: Iterable[Any], n: int\n) -> Generator[tuple[Any, ...], Any, None]:\n    \"\"\"Batch data from the iterable into tuples of length n. The last batch may be shorter than n.\n\n    Backport batched from py3.12. This is the roughly python implementation\n        of py3.12's batched copied from py3.12 documentation.\n    See https://docs.python.org/3/library/itertools.html#itertools.batched for more details.\n\n    Args:\n        iterable (Iterable[Any]): The input to be batched.\n        n (int): the size of each batch.\n\n    Raises:\n        ValueError on invalid n.\n\n    Returns:\n        A generator that can be used to loop over the input iterable and accumulates data into\n            tuples up to size n(a.k.a, batch in size of n).\n    \"\"\"\n    pass\n\ndef gen_check_constrain(_in: Any, field_name: str) -> str:\n    \"\"\"Generate the constrain statement for CHECK keyword.\n\n    Supports the following types:\n    1. StrEnum or IntEnum types: will generate statement like:\n        <field_name> IN (<enum_value_1>[, <enum_value_2>[, ...]])\n    2. Literal types: similar to StrEnum and IntEnum.\n\n    Args:\n        enum_type (type[Enum]): The enum type to generate CHECK statement against.\n        field_name (str): The field name of this enum_type in use.\n\n    Raises:\n        TypeError on unsupported enum_type.\n\n    Returns:\n        str: the generated statement can be used with CHECK keyword like the following:\n           <enum_value_1>[, <enum_value_2>[, ...]]\n    \"\"\"\n    pass\n\ndef concatenate_condition(\n    *condition_or_op: CONDITION_OPERATORS | COMPARE_OPERATORS | Any,\n    wrapped_with_parentheses: bool = True,\n) -> str:\n    \"\"\"Chain a list of conditions and operators together in a string.\n\n    For example, for the following statement for CHECK keyword:\n        (column IS NULL OR column IN (1, 2, 3))\n    we can use concatenate_condition like:\n        concatenate_condition(\n            \"column IS NULL\", \"OR\", \"column IN (1, 2, 3)\",\n            wrapped_with_parentheses=True,\n        )\n    \"\"\"\n    pass\n\ndef wrap_value(value: Any) -> str:\n    \"\"\"Wrap value for use in sql statement.\n\n    NOTE that for most cases, you should use python sqlite3 lib's\n        placeholder feature to bind value in the sql statement.\n\n    For int and float, the value will be used as it.\n    For str, the value will be wrapped with parenthesis.\n    For bytes, the value will be converted as x'<bytes_in_hex>'.\n    \"\"\"\n    pass\n\ndef gen_sql_script(*stmts: str) -> str:\n    \"\"\"Combine multiple sql statements into a sql script.\"\"\"\n    pass\n\ndef sort_and_replace(\n    _orm: ORMBase[TableSpecType], table_name: str, *, order_by_col: str\n) -> None:\n    \"\"\"Sort the table, and then replace the old table with the sorted one.\"\"\"\n    pass\n\n"
            },
            {
                "file_path": "src/simple_sqlite3_orm/_sqlite_spec.py",
                "code": "\"\"\"sqlite3 specific types and helpers.\"\"\"\n\nfrom __future__ import annotations\nfrom enum import Enum\nfrom typing import Literal, Union\n\nclass SQLiteStorageClass(str, Enum):\n    NULL = \"NULL\"\n    INTEGER = \"INTEGER\"\n    REAL = \"REAL\"\n    TEXT = \"TEXT\"\n    BLOB = \"BLOB\"\n\nSQLiteStorageClassLiteral = Literal[\"NULL\", \"INTEGER\", \"REAL\", \"TEXT\", \"BLOB\"]\n\nclass SQLiteTypeAffinity(str, Enum):\n    TEXT = \"TEXT\"\n    NUMERIC = \"NUMERIC\"\n    INTEGER = \"INTEGER\"\n    REAL = \"REAL\"\n    BLOB = \"BLOB\"\n    NULL = \"NULL\"\n\nSQLiteTypeAffinityLiteral = Literal[\"TEXT\", \"NUMERIC\", \"INTEGER\", \"REAL\", \"BLOB\"]\nConstrainLiteral = Literal[\n    \"PRIMARY KEY\",\n    \"NOT NULL\",\n    \"UNIQUE\",\n    \"CHECK\",\n    \"DEFAULT\",\n    \"COLLATE\",\n    \"REFERENCES\",\n    \"GENERATED ALWAYS AS\",\n    \"AS\",\n]\n\"\"\"Ref: https://www.sqlite.org/lang_createtable.html\"\"\"\nSQLiteBuiltInScalarFuncs = Literal[\n    \"abs\",\n    \"changes\",\n    \"char\",\n    \"coalesce\",\n    \"concat\",\n    \"concat_ws\",\n    \"format\",\n    \"glob\",\n    \"hex\",\n    \"ifnull\",\n    \"iif\",\n    \"instr\",\n    \"last_insert_rowid\",\n    \"length\",\n    \"like\",\n    \"like\",\n    \"likelihood\",\n    \"likely\",\n    \"load_extension\",\n    \"load_extension\",\n    \"lower\",\n    \"ltrim\",\n    \"ltrim\",\n    \"max\",\n    \"min\",\n    \"nullif\",\n    \"octet_length\",\n    \"printf\",\n    \"quote\",\n    \"random\",\n    \"randomblob\",\n    \"replace\",\n    \"round\",\n    \"round\",\n    \"rtrim\",\n    \"rtrim\",\n    \"sign\",\n    \"soundex\",\n    \"sqlite_compileoption_get\",\n    \"sqlite_compileoption_used\",\n    \"sqlite_offset\",\n    \"sqlite_source_id\",\n    \"sqlite_version\",\n    \"substr\",\n    \"substr\",\n    \"substring\",\n    \"substring\",\n    \"total_changes\",\n    \"trim\",\n    \"trim\",\n    \"typeof\",\n    \"unhex\",\n    \"unhex\",\n    \"unicode\",\n    \"unlikely\",\n    \"upper\",\n    \"zeroblob\",\n]\n\"\"\"Ref: https://www.sqlite.org/lang_corefunc.html\"\"\"\n\nSQLiteBuiltInAggregateFuncs = Literal[\n    \"avg\",\n    \"count\",\n    \"count\",\n    \"group_concat\",\n    \"group_concat\",\n    \"max\",\n    \"min\",\n    \"string_agg\",\n    \"sum\",\n]\n\"\"\"Ref: https://www.sqlite.org/lang_aggfunc.html\"\"\"\n\nSQLiteBuiltInDateTimeFuncs = Literal[\n    \"data\", \"time\", \"datetime\", \"julianday\", \"unixepoch\", \"strftime\", \"timediff\"\n]\n\"\"\"Ref: https://www.sqlite.org/lang_datefunc.html\"\"\"\n\nSQLiteBuiltInMathFuncs = Literal[\n    \"acos\",\n    \"acosh\",\n    \"asin\",\n    \"asinh\",\n    \"atan\",\n    \"atan2\",\n    \"atanh\",\n    \"ceil\",\n    \"ceiling\",\n    \"cos\",\n    \"cosh\",\n    \"degrees\",\n    \"exp\",\n    \"floor\",\n    \"ln\",\n    \"log\",\n    \"log\",\n    \"log10\",\n    \"log2\",\n    \"mod\",\n    \"pi\",\n    \"pow\",\n    \"power\",\n    \"radians\",\n    \"sin\",\n    \"sinh\",\n    \"sqrt\",\n    \"tan\",\n    \"tanh\",\n    \"trunc\",\n]\n\"\"\"Ref: https://www.sqlite.org/lang_mathfunc.html\"\"\"\n\nSQLiteBuiltInJSONFuncs = Literal[\n    \"json\",\n    \"jsonb\",\n    \"json_array\",\n    \"jsonb_array\",\n    \"json_array_length\",\n    \"json_error_position\",\n    \"json_extract\",\n    \"jsonb_extract\",\n    \"json_insert\",\n    \"jsonb_insert\",\n    \"json_object\",\n    \"jsonb_object\",\n    \"json_patch\",\n    \"jsonb_patch\",\n    \"json_remove\",\n    \"jsonb_remove\",\n    \"json_replace\",\n    \"jsonb_replace\",\n    \"json_set\",\n    \"jsonb_set\",\n    \"json_type\",\n    \"json_valid\",\n    \"json_quote\",\n    \"json_group_array\",\n    \"jsonb_group_array\",\n    \"json_group_object\",\n    \"jsonb_group_object\",\n    \"json_each\",\n    \"json_tree\",\n]\n\"\"\"Ref: https://www.sqlite.org/json1.html\"\"\"\n\nSQLiteBuiltInFuncs = Union[\n    SQLiteBuiltInAggregateFuncs,\n    SQLiteBuiltInDateTimeFuncs,\n    SQLiteBuiltInJSONFuncs,\n    SQLiteBuiltInMathFuncs,\n    SQLiteBuiltInScalarFuncs,\n]\nOR_OPTIONS = Literal[\"abort\", \"fail\", \"ignore\", \"replace\", \"rollback\"]\nORDER_DIRECTION = Literal[\"ASC\", \"DESC\"]\nCONDITION_OPERATORS = Literal[\n    \"AND\",\n    \"OR\",\n    \"IS\",\n    \"NULL\",\n    \"IS NULL\",\n    \"IS NOT NULL\",\n    \"NOT\",\n    \"MATCH\",\n    \"LIKE\",\n    \"BETWEEN\",\n    \"REGEXP\",\n    \"GLOB\",\n    \"IS DISTINCT FROM\",\n    \"IS NOT DISTINCT FROM\",\n]\n\"\"\"Ref https://www.sqlite.org/lang_expr.html\"\"\"\n\nCOMPARE_OPERATORS = Literal[\"=\", \"==\", \"!=\", \"<>\", \">=\", \"<=\"]\n\n"
            },
            {
                "file_path": "src/simple_sqlite3_orm/_table_spec.py",
                "code": "from __future__ import annotations\nimport sqlite3\nfrom collections.abc import Mapping\nfrom types import MappingProxyType\nfrom typing import Any, ClassVar, Generator, Iterable, Literal, TypedDict, TypeVar\nfrom pydantic import BaseModel\nfrom pydantic.fields import FieldInfo\nfrom typing_extensions import NotRequired, Self\n\nclass CreateTableParams(TypedDict, total=False):\n    if_not_exists: bool\n    strict: bool\n    temporary: bool\n    without_rowid: bool\n\nclass CreateIndexParams(TypedDict):\n    index_name: str\n    index_cols: tuple[str | tuple[str, ORDER_DIRECTION], ...]\n    if_not_exists: NotRequired[bool]\n    unique: NotRequired[bool]\n\nclass TableSpec(BaseModel):\n    \"\"\"Define table as pydantic model, with specific APIs.\"\"\"\n    table_columns: ClassVar[MappingProxyType[str, FieldInfo]]\n    \"\"\"A view of TableSpec's model_fields.\"\"\"\n    table_columns_by_index: ClassVar[tuple[str, ...]]\n    \"\"\"Ordered tuple of column names, matching exactly with table schema.\"\"\"\n    _table_update_where_cols_prefix: ClassVar[Literal[\"__table_spec_\"]]\n\n    @classmethod\n    def __pydantic_init_subclass__(cls, **_) -> None:\n        pass\n\n    @classmethod\n    def _generate_where_stmt(\n        cls,\n        where_cols: tuple[str, ...] | None = None,\n        where_stmt: str | None = None,\n    ) -> str:\n        pass\n\n    @classmethod\n    def _generate_order_by_stmt(\n        cls,\n        order_by: tuple[str | tuple[str, ORDER_DIRECTION], ...] | None = None,\n        order_by_stmt: str | None = None,\n    ) -> str:\n        pass\n\n    @classmethod\n    def _generate_returning_stmt(\n        cls,\n        returning_cols: tuple[str, ...] | Literal[\"*\"] | None = None,\n        returning_stmt: str | None = None,\n    ) -> str:\n        pass\n\n    @classmethod\n    def table_get_col_fieldinfo(cls, col: str) -> FieldInfo:\n        \"\"\"Check whether the <col> exists and returns the pydantic FieldInfo.\n\n        Raises:\n            ValueError on non-existed col.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_check_cols(cls, cols: tuple[str, ...]) -> None:\n        \"\"\"Ensure all cols in <cols> existed in the table definition.\n\n        Raises:\n            ValueError if any of col doesn't exist in the table.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_dump_column(cls, column_name: str) -> str:\n        \"\"\"Dump the column statement for table creation.\n\n        Raises:\n            ValueError on col doesn't exist or invalid col definition.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_create_stmt(\n        cls,\n        table_name: str,\n        *,\n        if_not_exists: bool = False,\n        strict: bool = False,\n        temporary: bool = False,\n        without_rowid: bool = False,\n    ) -> str:\n        \"\"\"Get create table statement with this table spec class.\n\n        Check https://www.sqlite.org/lang_createtable.html for more details.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_create_index_stmt(\n        cls,\n        *,\n        table_name: str,\n        index_name: str,\n        index_cols: tuple[str | tuple[str, ORDER_DIRECTION], ...],\n        if_not_exists: bool = False,\n        unique: bool = False,\n    ) -> str:\n        \"\"\"Get index create statement with this table spec class.\n\n        Raises:\n            ValueError on <index_cols> not specified, or invalid <index_cols>.\n\n        Check https://www.sqlite.org/lang_createindex.html for more details.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_row_factory(\n        cls,\n        _cursor: sqlite3.Cursor,\n        _row: tuple[Any, ...] | Any,\n        *,\n        validation: bool = True,\n    ) -> Self | tuple[Any, ...]:\n        \"\"\"A general row_factory implement for used in sqlite3 connection.\n\n        When the input <_row> is not a row but something like function output,\n            this method will return the raw input tuple as it.\n\n        Args:\n            validation (bool): whether enable pydantic validation when importing row. Default to True.\n\n        Raises:\n            Any exception raised from pydantic model_validate or model_construct.\n\n        Returns:\n            An instance of <TableSpec>, or the raw tuple if the input row has different schema.\n\n        Also see https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.description\n            for more details.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_row_factory2(\n        cls,\n        _cursor: sqlite3.Cursor,\n        _row: tuple[Any, ...] | Any,\n        *,\n        validation: bool = True,\n    ) -> Self:\n        \"\"\"Another version of row_factory implementation for specific use case.\n\n        Unlike table_row_factory that checks the cols definition and ensure all cols\n            are valid and presented in table def, table_row_factory2 just picks the valid\n            cols from the input raw table row, and ignore unknown col/value pairs.\n\n        Args:\n            validation (bool): whether enable pydantic validation when importing row. Default to True.\n\n        Raises:\n            Any exception raised from pydantic model_validate or model_construct.\n\n        Returns:\n            An instance of <TableSpec>.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_from_tuple(\n        cls, _row: Iterable[Any], *, with_validation: bool = True, **kwargs\n    ) -> Self:\n        \"\"\"A raw row_factory that converts the input _row to TableSpec instance.\n\n        NOTE that this method expects the input row match the table row spec EXACTLY.\n\n        Args:\n            _row (tuple[Any, ...]): the raw table row as tuple.\n            with_validation (bool): if set to False, will use pydantic model_construct to directly\n                construct instance without validation. Default to True.\n            **kwargs: extra kwargs passed to pydantic model_validate API. Note that only when\n                with_validation is True, the kwargs will be used.\n\n        Returns:\n            An instance of self.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_from_dict(\n        cls, _map: Mapping[str, Any], *, with_validation: bool = True, **kwargs\n    ) -> Self:\n        \"\"\"A raw row_factory that converts the input mapping to TableSpec instance.\n\n        Args:\n            _map (Mapping[str, Any]): the raw table row as a dict.\n            with_validation (bool, optional): if set to False, will use pydantic model_construct to directly\n                construct instance without validation. Default to True.\n            **kwargs: extra kwargs passed to pydantic model_validate API. Note that only when\n                with_validation is True, the kwargs will be used.\n\n        Returns:\n            An instance of self.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_insert_stmt(\n        cls,\n        *,\n        insert_into: str,\n        insert_cols: tuple[str, ...] | None = None,\n        insert_default: bool = False,\n        or_option: OR_OPTIONS | None = None,\n        returning_cols: tuple[str, ...] | Literal[\"*\"] | None = None,\n        returning_stmt: str | None = None,\n    ) -> str:\n        \"\"\"Get sql for inserting row(s) into <table_name>.\n\n        Check https://www.sqlite.org/lang_insert.html for more details.\n\n        Args:\n            insert_into (str): The name of table insert into.\n            insert_cols (tuple[str, ...] | None, optional): The cols to be assigned for entry to be inserted.\n                Defaults to None, means we will assign all cols of the row.\n            insert_default (bool, optional): No values will be assigned, all cols will be assigned with\n                default value, this precedes the <insert_cols> param. Defaults to False.\n            or_option (INSERT_OR | None, optional): The fallback operation if insert failed. Defaults to None.\n            returning_cols (tuple[str, ...] | Literal[\"*\"] | None): Which cols are included in the returned entries.\n                Defaults to None.\n            returning_stmt (str | None, optional): The full returning statement string, this\n                precedes the <returning_cols> param. Defaults to None.\n\n        Returns:\n            str: The generated insert statement.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_update_stmt(\n        cls,\n        *,\n        or_option: OR_OPTIONS | None = None,\n        update_target: str,\n        set_cols: tuple[str, ...],\n        where_cols: tuple[str, ...] | None = None,\n        where_stmt: str | None = None,\n        returning_cols: tuple[str, ...] | Literal[\"*\"] | None = None,\n        returning_stmt: str | None = None,\n        order_by: tuple[str | tuple[str, ORDER_DIRECTION], ...] | None = None,\n        order_by_stmt: str | None = None,\n        limit: int | None = None,\n    ) -> str:\n        \"\"\"Get sql query for updating row(s) at <table_name>.\n\n        Check https://www.sqlite.org/lang_update.html for more details.\n\n        NOTE: to avoid overlapping between <set_cols> and <where_cols> when generating named-placeholders,\n            this method will prefix cols name with <_table_spec_update_where_cols_prefix> when generating\n            WHERE statement.\n            To directly use the stmt generated from this API, dev must use table_preprare_update_where_cols\n            to prepare the col/value mapping for params.\n\n        NOTE that UPDATE-FROM extension is currently not supported by this method.\n        NOTE that UPDATE-WITH-LIMIT is an optional feature, needs to be enabled at compiled time with\n            SQLITE_ENABLE_UPDATE_DELETE_LIMIT.\n\n        Args:\n            or_option (INSERT_OR | None, optional): The fallback operation if update failed. Defaults to None.\n            update_target (str): The name of table to update.\n            set_cols (tuple[str, ...]): The cols to be updated.\n            where_cols (tuple[str, ...] | None, optional): A list of cols to be compared in where\n                statement. Defaults to None.\n            where_stmt (str | None, optional): The full where statement string, this\n                precedes the <where_cols> param if set. Defaults to None.\n            returning_cols (tuple[str, ...] | Literal[\"*\"] | None): If specified, enable RETURNING stmt, and specifying Which cols\n                included in the returned entries. Defaults to None.\n            returning_stmt (str | None, optional): The full returning statement string, this\n                precedes the <returning_cols> param. Defaults to None.\n            order_by (Iterable[str  |  tuple[str, ORDER_DIRECTION], ...] | None, optional):\n                Works with LIMIT, to specify the range that LIMIT affects. Defaults to None.\n            order_by_stmt (str | None, optional): The order_by statement string, this\n                precedes the <order_by> param if set. Defaults to None.\n            limit (int | None, optional): Limit the number of affected entries. Defaults to None.\n\n        Returns:\n            str: The generated update sqlite3 query.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_preprare_update_where_cols(\n        cls, where_cols: Mapping[str, Any]\n    ) -> Mapping[str, Any]:\n        \"\"\"Regulate the named-placeholder <where_cols> so that it will not overlap with <set_cols>.\n\n        This is MUST for directly using the sqlite query stmt generated from table_update_stmt.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_select_all_stmt(\n        cls,\n        *,\n        select_from: str,\n        batch_idx: int | None = None,\n        batch_size: int | None = None,\n        order_by: tuple[str | tuple[str, ORDER_DIRECTION], ...] | None = None,\n        order_by_stmt: str | None = None,\n        distinct: bool = False,\n    ) -> str:\n        \"\"\"Select all entries, optionally with pagination LIMIT and OFFSET.\n\n        Check https://www.sqlite.org/lang_select.html for more details.\n\n        Args:\n            select_from (str): The table name for the generated statement.\n            batch_idx (int | None, optional): If specified, the batch index of current page. Defaults to None.\n            batch_size (int | None, optional): If specified, the batch size of each page. Defaults to None.\n            order_by (tuple[str | tuple[str, ORDER_DIRECTION], ...] | None, optional):\n                A list of cols for ordering result. Defaults to None.\n            order_by_stmt (str | None, optional): The order_by statement string, this\n                precedes the <order_by> param if set. Defaults to None.\n            distinct (bool, optional): Whether filters the duplicated entries. Defaults to False.\n\n        Raises:\n            ValueError: If batch_idx or bach_size are not both None or not None, or the values are invalid.\n\n        Returns:\n            str: The generated select statement.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_select_stmt(\n        cls,\n        *,\n        select_from: str,\n        select_cols: tuple[str, ...] | Literal[\"*\"] | str = \"*\",\n        function: SQLiteBuiltInFuncs | None = None,\n        where_stmt: str | None = None,\n        where_cols: tuple[str, ...] | None = None,\n        group_by: tuple[str, ...] | None = None,\n        order_by: tuple[str | tuple[str, ORDER_DIRECTION], ...] | None = None,\n        order_by_stmt: str | None = None,\n        limit: int | None = None,\n        distinct: bool = False,\n    ) -> str:\n        \"\"\"Get sql for getting row(s) from <table_name>, optionally with\n            where condition specified by <col_values>.\n\n        Check https://www.sqlite.org/lang_select.html for more details.\n\n        Args:\n            select_from (str): The table name for the generated statement.\n            select_cols (tuple[str, ...] | Literal[\"*\"] | str, optional): A list of cols included in the result row. Defaults to \"*\".\n            function (SQLiteBuiltInFuncs | None, optional): The sqlite3 function used in the selection. Defaults to None.\n            where_cols (tuple[str, ...] | None, optional): A list of cols to be compared in where\n                statement. Defaults to None.\n            where_stmt (str | None, optional): The full where statement string, this\n                precedes the <where_cols> param if set. Defaults to None.\n            group_by (tuple[str, ...] | None, optional): A list of cols for group_by statement. Defaults to None.\n            order_by (Iterable[str  |  tuple[str, ORDER_DIRECTION], ...] | None, optional):\n                A list of cols for ordering result. Defaults to None.\n            order_by_stmt (str | None, optional): The order_by statement string, this\n                precedes the <order_by> param if set. Defaults to None.\n            limit (int | None, optional): Limit the number of result entries. Defaults to None.\n            distinct (bool, optional): Whether filters the duplicated entries. Defaults to False.\n\n        Returns:\n            str: The generated select statement.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_delete_stmt(\n        cls,\n        *,\n        delete_from: str,\n        where_cols: tuple[str, ...] | None = None,\n        where_stmt: str | None = None,\n        order_by: tuple[str | tuple[str, ORDER_DIRECTION], ...] | None = None,\n        order_by_stmt: str | None = None,\n        limit: int | str | None = None,\n        returning_cols: tuple[str, ...] | Literal[\"*\"] | None = None,\n        returning_stmt: str | None = None,\n    ) -> str:\n        \"\"\"Get sql for deleting row(s) from <table_name> with specifying col value(s).\n\n        Check https://www.sqlite.org/lang_delete.html for more details.\n\n        NOTE(20240311): DELETE operation without any condition(no WHERE statement) in\n            WITHOUT_ROWID table will result in rowcount=0, see\n            https://sqlite.org/forum/forumpost/07dedbf9a1 for more details.\n            For python, python version < 3.10 will be affected by this bug.\n            A quick workaround is to add any condition in where statement, even a dummy\n            \"WHERE 1=1\" can resolve the above bug.\n            I will not add this hack here, and user can add this hack according to their needs.\n\n        NOTE: <order_by> and <limit> support are only enabled when runtime sqlite3 lib is compiled with\n            SQLITE_ENABLE_UPDATE_DELETE_LIMIT flag.\n\n        Args:\n            delete_from (str): The table name for the generated statement.\n            limit (int | str | None, optional): The value for limit expr. Defaults to None.\n            order_by (Iterable[str  |  tuple[str, ORDER_DIRECTION]] | None, optional):\n                A list of cols for ordering result. Defaults to None.\n            order_by_stmt (str | None, optional): The order_by statement string, this\n                precedes the <order_by> param if set. Defaults to None.\n            where_cols (tuple[str, ...] | None, optional): A list of cols to be compared in where\n                statement. Defaults to None.\n            where_stmt (str | None, optional): The full where statement string, this\n                precedes the <where_cols> param if set. Defaults to None.\n            returning_cols (tuple[str, ...] | Literal[\"*\"] | None): Which cols are included in the returned entries.\n                Defaults to None.\n            returning_stmt (str | None, optional): The full returning statement string, this\n                precedes the <returning_cols> param. Defaults to None.\n\n        Returns:\n            str: The generated delete statement.\n        \"\"\"\n        pass\n\n    def table_dump_asdict(self, *cols: str, **kwargs) -> dict[str, Any]:\n        \"\"\"Serialize self as a dict, containing all cols or specified cols, for DB operations.\n\n        Under the hook this method calls pydantic model_dump on self.\n        The dumped dict can be used to directly insert into the table.\n\n        Args:\n            *cols: which cols to export, if not specified, export all cols.\n            **kwargs: any other kwargs that passed to pydantic model_dump method.\n                Note that the include kwarg is used to specific which cols to dump.\n\n        Raises:\n            ValueError if failed to serialize the model, wrapping underlying\n                pydantic serialization error.\n\n        Returns:\n            A dict of dumped col values from this row.\n        \"\"\"\n        pass\n\n    def table_asdict(self, *cols: str) -> dict[str, Any]:\n        \"\"\"Directly export the self as a dict, without serializing.\n\n        Args:\n            *cols: which cols to export, if not specified, export all cols.\n            exclude_unset (bool, optional): whether include not set field of self.\n                Defaults to False, include unset fields(which will return their default values).\n\n        Returns:\n            A dict of col/values from self.\n        \"\"\"\n        pass\n\n    def table_dump_astuple(self, *cols: str, **kwargs) -> tuple[Any, ...]:\n        \"\"\"Serialize self's value as a tuple, containing all cols or specified cols, for DB operations.\n\n        This method is basically the same as table_dump_asdict, but instead return a\n            tuple of the dumped values.\n\n        Args:\n            *cols: which cols to export, if not specified, export all cols.\n            **kwargs: any other kwargs that passed to pydantic model_dump method.\n                Note that the include kwarg is used to specific which cols to dump.\n\n        Returns:\n            A tuple of dumped col values.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_serialize_mapping(cls, _in: Mapping[str, Any]) -> dict[str, Any]:\n        \"\"\"Serialize input mapping into a dict by this TableSpec, ready for DB operations.\n\n        Values in the input mapping are python types used in application.\n\n        This is a convenient method for when we only need to specify some of the cols, so that\n            we cannot use TableSpec as TableSpec requires all cols to be set.\n\n        NOTE that for APIs provided by simple_sqlite3_orm, when col/value pairs are provided as mapping,\n            the serialization will be done by the APIs, no need to call this method when using ORM.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_serialize_mappings(\n        cls, _iter: Iterable[Mapping[str, Any]]\n    ) -> Generator[dict[str, Any]]:\n        \"\"\"Convert an iter of Mappings into an generator of serialized dict.\"\"\"\n        pass\n\n    @classmethod\n    def table_deserialize_asdict_row_factory(\n        cls,\n        _cursor: sqlite3.Cursor,\n        _row: tuple[Any, ...] | Any,\n        *,\n        allow_unknown_cols: bool = True,\n    ) -> dict[str, Any]:\n        \"\"\"Deserialize raw row from a query into a dict by this TableSpec, ready for application use.\n\n        This is a convenient method when we execute query that only select some cols.\n        For this use case, use thid method as row_factory to deserialize the raw row. This method\n            will deserialize the row from raw into actual field types defined in this TableSpec.\n\n        NOTE that if `allow_unknow_cols` is True, any unknown field(including cols aliased with other name)\n            will be preserved AS IT without deserializing as this method cannot know which col the alias name maps to.\n\n        Args:\n            allow_unknown_cols (bool, optional): If True, unknown cols will be preserved AS IT into the result.\n                Defaults to True.\n\n        Raises:\n            ValueError if `allow_unknown_cols` is False and unknown cols presented, or pydantic validation failed.\n\n        Returns:\n            A dict of deserialized(except unknown cols) col/value pairs.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_deserialize_astuple_row_factory(\n        cls, _cursor: sqlite3.Cursor, _row: tuple[Any, ...] | Any\n    ) -> tuple[Any, ...]:\n        \"\"\"Deserialize raw row from a query into a tuple by this TableSpec, ready for application use.\n\n        This is a convenient method when we execute query that only select some cols.\n        For this use case, use thid method as row_factory to deserialize the raw row. This method\n            will deserialize the row from raw into actual field types defined in this TableSpec.\n\n        NOTE that any unknown field(including cols aliased with other name) will be preserved AS IT without\n            deserializing as this method cannot know which col the alias name maps to.\n\n        Raises:\n            ValueError if pydantic validation failed.\n\n        Returns:\n            A tuple of deserialized row as tuple.\n        \"\"\"\n        pass\n\nTableSpecType = TypeVar(\"TableSpecType\", bound=TableSpec)\n\n"
            },
            {
                "file_path": "src/simple_sqlite3_orm/_utils.py",
                "code": "from __future__ import annotations\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Callable,\n    Literal,\n    TypeVar,\n    Union,\n)\nfrom typing_extensions import ParamSpec\n\nT = TypeVar(\"T\")\nP = ParamSpec(\"P\")\nRT = TypeVar(\"RT\")\n\ndef lru_cache(_func: Callable[P, RT], /) -> Callable[P, RT]:\n    \"\"\"typeshed doesn't use ParamSpec for lru_cache typing currently.\"\"\"\n    pass\n\nclass GenericAlias(type(list)): # Simplified based on rule of extracting definitions\n    def __new__(\n        cls, _type: type[Any], _params: type[Any] | tuple[type[Any], ...]\n    ):\n        \"\"\"For type check only, typing the _GenericAlias as GenericAlias.\"\"\"\n        pass\n\ndef map_type(\n    _in: type[Any] | SQLiteTypeAffinityLiteral | Any,\n) -> SQLiteTypeAffinity | str:\n    \"\"\"Mapping python types to corresponding sqlite storage classes.\n\n    Currently this function suports the following input:\n    1. sqlite3 native types(and wrapped in Optional).\n    2. Literal types.\n    3. Enum types with str or int as data type.\n    4. user defined affinity string, will be used as it.\n\n    \"\"\"\n    pass\n\ndef _map_from_literal(_in: Any) -> SQLiteTypeAffinity:\n    \"\"\"Support for literal of supported datatypes.\"\"\"\n    pass\n\ndef _map_from_type(_in: type[Any]) -> SQLiteTypeAffinity:\n    pass\n\nclass TypeAffinityRepr:\n    \"\"\"Map python types to sqlite3 data types with type affinity.\n\n    Currently supports:\n    1. python sqlite3 lib supported native python types.\n    2. StrEnum and IntEnum, will map to TEXT and INT accordingly.\n    3. Optional types, will map against the args inside the Optional.\n    4. Literal types, will map against the values type inside the Literal.\n\n    Attrs:\n        type_affinity (SQLiteTypeAffinity | str)\n        origin (type[Any] | SQLiteTypeAffinityLiteral | Any)\n    \"\"\"\n    type_affinity: SQLiteTypeAffinity | str\n    origin: type[Any] | SQLiteTypeAffinityLiteral | Any\n\n    def __init__(self, _in: type[Any] | SQLiteTypeAffinityLiteral | Any) -> None:\n        pass\n\n    def __str__(self) -> str:\n        pass\n\n    def __repr__(self) -> str:\n        pass\n\n    def __eq__(self, other: object) -> bool:\n        pass\n\n    def __hash__(self) -> int:\n        pass\n\nclass ConstrainRepr:\n    \"\"\"Helper class for composing full constrain statement string.\n\n    For example, for constrain statement like the following:\n        NOT NULL DEFAULT NULL CHECK (column IN (1, 2, 3))\n    can be represented ConstrainRepr as follow:\n        ConstrainRepr(\n            \"NOT NULL\",\n            (\"DEFAULT\", \"NULL\"),\n            (\"CHECK\", r\"(column IN (1, 2, 3))\")\n        )\n\n    Attrs:\n        constraints (set[str | tuple[str, str]]): a set of constrains.\n    \"\"\"\n    constraints: tuple[ConstrainLiteral | tuple[ConstrainLiteral, str] | Any, ...]\n\n    def __init__(\n        self, *params: ConstrainLiteral | tuple[ConstrainLiteral, str] | Any\n    ) -> None:\n        pass\n\n    def __str__(self) -> str:\n        pass\n\n    def __repr__(self) -> str:\n        pass\n\n    def __eq__(self, other: Any) -> bool:\n        pass\n\n    def __hash__(self) -> int:\n        pass\n\ndef gen_sql_stmt(*components: str, end_with: str | None = \";\") -> str:\n    \"\"\"Combine each components into a single sql stmt.\"\"\"\n    pass\n\nclass ColsSelectFactory(tuple[T, ...]):\n    \"\"\"A factory type to generate cols name checker.\n\n    Usage:\n\n    MyTableCols = Literal[\"entry_id\", \"entry_context\", \"entry_type\"]\n    MyTableColsChecker = ColsCheckerFactory[MyTableCols]\n\n    # now you can use `MyTableColsChecker` to specify a tuple of cols name as follow:\n    cols_to_select = MyTableColsChecker(\"unknown\", \"invalid_col\")  # type checker err\n    cols_to_select = MyTableColsChecker(\"entry_id\", \"entry_type\")  # valid\n\n    # at runtime, `cols_to_select` is a regular `tuple` object.\n\n    \"\"\"\n\n    def __new__(cls, *cols: T) -> tuple[T, ...]:\n        pass\n\n"
            },
            {
                "file_path": "src/simple_sqlite3_orm/_typing.py",
                "code": "\"\"\"Typing helpers definition.\"\"\"\n\nfrom __future__ import annotations\nimport sqlite3\nfrom sqlite3 import Cursor, Row\nfrom typing import Any, Callable\nfrom typing_extensions import TypeAlias\n\nRowFactoryType: TypeAlias = (\n    \"Callable[[Cursor, Row | tuple[Any, ...] | Any], Any] | type[sqlite3.Row]\"\n)\n\"\"\"Type hint for callable that can be used as sqlite3 row_factory.\"\"\"\n\nConnectionFactoryType: TypeAlias = \"Callable[[], sqlite3.Connection]\"\nColsDefinitionWithDirection: TypeAlias = \"tuple[str | tuple[str, ORDER_DIRECTION], ...]\"\nColsDefinition: TypeAlias = \"tuple[str, ...]\"\n\n"
            },
            {
                "file_path": "src/simple_sqlite3_orm/_orm/_pool.py",
                "code": "from __future__ import annotations\nimport asyncio\nimport queue\nimport threading\nfrom collections.abc import Callable, Generator\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import TYPE_CHECKING, AsyncGenerator, TypeVar\nfrom typing_extensions import Concatenate, ParamSpec, Self\n\nP = ParamSpec(\"P\")\nRT = TypeVar(\"RT\")\n\ndef _python_exit():\n    pass\n\ndef _wrap_with_thread_ctx(func: Callable[Concatenate[ORMBase, P], RT]):\n    pass\n\ndef _wrap_with_async_ctx(\n    func: Callable[Concatenate[ORMBase, P], RT],\n):\n    pass\n\ndef _wrap_generator_with_thread_ctx(\n    func: Callable[Concatenate[ORMBase, P], Generator[RT]],\n):\n    pass\n\ndef _wrap_generator_with_async_ctx(\n    func: Callable[Concatenate[ORMBase, P], Generator[RT]],\n):\n    pass\n\nclass ORMThreadPoolBase(ORMCommonBase[TableSpecType]):\n    \"\"\"\n    See https://www.sqlite.org/wal.html#concurrency for more details.\n\n    For the row_factory arg, please see ORMBase.__init__ for more details.\n    \"\"\"\n    _thread_id_orms: dict[int, ORMBase]\n    _num_of_cons: int\n    _pool: ThreadPoolExecutor\n    _closed: bool\n    __class_getitem__ = classmethod(parameterized_class_getitem)\n\n    def __init__(\n        self,\n        table_name: str | None = None,\n        schema_name: str | None = None,\n        *,\n        con_factory: ConnectionFactoryType,\n        number_of_cons: int,\n        thread_name_prefix: str = \"\",\n        row_factory: RowFactorySpecifier = \"table_spec\",\n    ) -> None:\n        pass\n\n    def __enter__(self) -> Self:\n        pass\n\n    def __exit__(self, exec_type, exc_val, exc_tb):\n        pass\n\n    def _thread_initializer(self, con_factory, row_factory) -> None:\n        \"\"\"Prepare thread_scope ORMBase instance for this worker thread.\"\"\"\n        pass\n\n    @property\n    def _thread_scope_orm(self) -> ORMBase[TableSpecType]:\n        \"\"\"Get thread scope ORMBase instance.\"\"\"\n        pass\n\n    def _caller_gen(\n        self, _queue: queue.Queue[RT], _caller_exit: threading.Event\n    ) -> Generator[RT]:\n        pass\n\n    @property\n    def orm_table_name(self) -> str:\n        \"\"\"The unique name of the table for use in sql statement.\n\n        If multiple databases are attached to <con> and <schema_name> is availabe,\n            return \"<schema_name>.<table_name>\", otherwise return <table_name>.\n        \"\"\"\n        pass\n\n    def _worker_shutdown(\n        self, shutdown_barrier: threading.Barrier, shutdown_lock: threading.Lock\n    ):\n        pass\n\n    def orm_pool_shutdown(self, *, wait=True, close_connections=True) -> None:\n        \"\"\"Shutdown the ORM connections thread pool.\n\n        It is safe to call this method multiple time.\n        This method is NOT thread-safe, and should be called at the main thread,\n            or the thread that creates this thread pool.\n\n        Args:\n            wait (bool, optional): Wait for threads join. Defaults to True.\n            close_connections (bool, optional): Close all the connections. Defaults to True.\n        \"\"\"\n        pass\n\n    orm_bootstrap_db: Callable\n    orm_execute: Callable\n    orm_execute_gen: Callable\n    orm_executemany: Callable\n    orm_executescript: Callable\n    orm_create_table: Callable\n    orm_create_index: Callable\n    orm_select_entries: Callable\n    orm_select_entry: Callable\n    orm_insert_entries: Callable\n    orm_insert_mappings: Callable\n    orm_insert_mapping: Callable\n    orm_insert_entry: Callable\n    orm_update_entries: Callable\n    orm_update_entries_many: Callable\n    orm_delete_entries: Callable\n    orm_delete_entries_with_returning: Callable\n    orm_select_all_with_pagination: Callable\n    orm_check_entry_exist: Callable\n\nORMThreadPoolBaseType = TypeVar(\"ORMThreadPoolBaseType\", bound=ORMThreadPoolBase)\n\nclass AsyncORMBase(ORMThreadPoolBase[TableSpecType]):\n    \"\"\"\n    NOTE: the supoprt for async ORM is experimental! The APIs might be changed a lot\n        in the following releases.\n\n    For the row_factory arg, please see ORMBase.__init__ for more details.\n    \"\"\"\n    _loop: asyncio.AbstractEventLoop\n    \"\"\"Bound event loop when instanitiate this pool.\"\"\"\n\n    if not TYPE_CHECKING:\n        def __init__(self, *args, **kwargs) -> None:\n            pass\n\n    async def _async_caller_gen(\n        self,\n        _queue: queue.Queue[RT],\n        _se: asyncio.Semaphore,\n        _caller_exit: threading.Event,\n    ) -> AsyncGenerator[RT]:\n        pass\n\n    orm_bootstrap_db: Callable\n    orm_execute: Callable\n    orm_execute_gen: Callable\n    orm_executemany: Callable\n    orm_executescript: Callable\n    orm_create_table: Callable\n    orm_create_index: Callable\n    orm_select_entries: Callable\n    orm_select_entry: Callable\n    orm_insert_entries: Callable\n    orm_insert_mappings: Callable\n    orm_insert_mapping: Callable\n    orm_insert_entry: Callable\n    orm_update_entries: Callable\n    orm_update_entries_many: Callable\n    orm_delete_entries: Callable\n    orm_delete_entries_with_returning: Callable\n    orm_select_all_with_pagination: Callable\n    orm_check_entry_exist: Callable\n\nAsyncORMBaseType = TypeVar(\"AsyncORMBaseType\", bound=AsyncORMBase)\n\n"
            },
            {
                "file_path": "src/simple_sqlite3_orm/_orm/_base.py",
                "code": "from __future__ import annotations\nimport sqlite3\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Callable,\n    Generator,\n    Generic,\n    Iterable,\n    Literal,\n    Mapping,\n    TypeVar,\n    Union,\n    overload,\n)\nfrom typing_extensions import ParamSpec, Self\n\nP = ParamSpec(\"P\")\nRT = TypeVar(\"RT\")\nDoNotChangeRowFactory = Literal[\"do_not_change\"]\nDO_NOT_CHANGE_ROW_FACTORY: DoNotChangeRowFactory\nRowFactorySpecifier = Union[\n    RowFactoryType,\n    Literal[\n        \"sqlite3_row_factory\",\n        \"table_spec\",\n        \"table_spec_no_validation\",\n    ],\n    DoNotChangeRowFactory,\n    None,\n]\n\"\"\"Specifiy which row_factory to use.\n\nFor each option:\n    1. RowFactoryType: specify arbitrary row_factory.\n    2. None: clear the connection scope row_factory(set to None).\n    3. \"sqlite3_row_factory\": set to use sqlite3.Row as row_factory.\n    4. \"table_spec\": use TableSpec.table_row_factory as row_factory.\n    5. \"table_spec_no_validation\": use TableSpec.table_row_factory as row_factory, but with validation=False.\n    6. \"do_not_change\": do not change the connection scope row_factory.\n\"\"\"\n\ndef _select_row_factory(\n    table_spec: type[TableSpec],\n    row_factory_specifier: RowFactorySpecifier,\n) -> RowFactoryType | None | DoNotChangeRowFactory:\n    \"\"\"Helper function to get row_factory by row_factory_specifier.\"\"\"\n    pass\n\ndef _merge_iters(\n    _left: Iterable[Mapping[str, Any]], _right: Iterable[Mapping[str, Any]]\n) -> Generator[dict[str, Any]]:\n    \"\"\"Merge two iterables of Mappings into one iterable of dict.\"\"\"\n    pass\n\nclass ORMCommonBase(Generic[TableSpecType]):\n    orm_table_spec: type[TableSpecType]\n    orm_bootstrap_table_name: str\n    orm_bootstrap_create_table_params: str | CreateTableParams\n    orm_bootstrap_indexes_params: list[str | CreateIndexParams]\n    if not TYPE_CHECKING:\n        _orm_table_name: str\n        \"\"\"\n        Used by ORM internally, should not be set directly.\n\n        Directly setting this variable is DEPRECATED, use orm_bootstrap_table_name instead.\n        \"\"\"\n\n    def __init_subclass__(cls, **kwargs) -> None:\n        pass\n\nclass ORMBase(ORMCommonBase[TableSpecType]):\n    \"\"\"ORM layer for <TableSpecType>.\n\n    NOTE that instance of ORMBase cannot be used in multi-threaded environment.\n        Use ORMThreadPoolBase for multi-threaded environment.\n        For asyncio, use AsyncORMThreadPoolBase.\n\n    The underlying connection can be used in multiple connection for accessing different table in\n        the connected database.\n\n    Attributes:\n        con (sqlite3.Connection | ConnectionFactoryType): The sqlite3 connection used by this ORM, or a factory\n            function that returns a sqlite3.Connection object on calling.\n        table_name (str): The name of the table in the database <con> connected to. This field will take prior over the\n            table_name specified by orm_bootstrap_table_name attr to allow using different table_name for just one connection.\n        schema_name (str): The schema of the table if multiple databases are attached to <con>.\n        row_factory (RowFactorySpecifier): The connection scope row_factory to use. Default to \"table_sepc\".\n    \"\"\"\n    _con: sqlite3.Connection\n    _schema_name: str | Literal[\"temp\"] | None\n    __class_getitem__ = classmethod(parameterized_class_getitem)\n\n    def orm_bootstrap_db(self) -> None:\n        \"\"\"Bootstrap the database this ORM connected to.\n\n        This method will refer to the following attrs to setup table and indexes:\n        1. orm_bootstrap_table_name: the name of table to be created.\n        2. orm_bootstrap_create_table_params: the sqlite query to create the table,\n            it can be provided as sqlite query, or CreateTableParams for table_create_stmt\n            to generate sqlite query from.\n            It not specified, the table create statement will be generated with default configs,\n            See table_spec.table_create_stmt method for more details.\n        3. orm_bootstrap_indexes_params: optional, a list of sqlite query or\n            CreateIndexParams(for table_create_index_stmt to generate sqlite query from) to\n            create indexes from.\n\n        NOTE that ORM will not know whether the connected database has already been\n            bootstrapped or not, this is up to caller to check.\n        \"\"\"\n        pass\n\n    def __init__(\n        self,\n        con: sqlite3.Connection | ConnectionFactoryType,\n        table_name: str | None = None,\n        schema_name: str | Literal[\"temp\"] | None = None,\n        *,\n        row_factory: RowFactorySpecifier = \"table_spec\",\n    ) -> None:\n        pass\n\n    def __enter__(self) -> Self:\n        pass\n\n    def __exit__(self, exec_type, exc_val, exc_tb):\n        pass\n\n    @property\n    def orm_con(self) -> sqlite3.Connection:\n        \"\"\"A reference to the underlying sqlite3.Connection.\n\n        This is for directly executing sql stmts.\n        \"\"\"\n        pass\n\n    @property\n    def orm_table_name(self) -> str:\n        \"\"\"The unique name of the table for use in sql statement.\n\n        If multiple databases are attached to <con> and <schema_name> is availabe,\n            return \"<schema_name>.<table_name>\", otherwise return <table_name>.\n        \"\"\"\n        pass\n\n    @property\n    def orm_conn_row_factory(self) -> RowFactoryType | None:\n        \"\"\"Get and set the connection scope row_factory for this ORM instance.\"\"\"\n        pass\n\n    @orm_conn_row_factory.setter\n    def orm_conn_row_factory(self, _row_factory: RowFactoryType | None) -> None:\n        pass\n\n    @overload\n    def orm_execute(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: Callable[[sqlite3.Cursor, Any], RT],\n    ) -> list[RT]: ...\n\n    @overload\n    def orm_execute(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: DoNotChangeRowFactory = DO_NOT_CHANGE_ROW_FACTORY,\n    ) -> list[TableSpecType]: ...\n\n    @overload\n    def orm_execute(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: None,\n    ) -> list[tuple[Any, ...]]: ...\n\n    def orm_execute(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: RowFactorySpecifier\n        | DoNotChangeRowFactory = DO_NOT_CHANGE_ROW_FACTORY,\n    ) -> list[Any]:\n        \"\"\"Execute one sql statement and get the all the result.\n\n        NOTE that caller needs to serialize the `params` before hands if needed, `orm_execute` will\n            not do any processing over the input `params`, and just use as it for execution.\n        The result will be fetched with fetchall API and returned as it.\n\n        Args:\n            sql_stmt (str): The sqlite statement to be executed.\n            params (tuple[Any, ...] | dict[str, Any] | None, optional): The parameters to be bound\n                to the sql statement execution. Defaults to None, not passing any params.\n            row_factory (RowFactorySpecifier | DoNotChangeRowFactory, optional): specify to use\n                different row_factory for the query. Default to not change the current row_factory.\n                NOTE that None value here means unset the row_factory for this query.\n\n        Returns:\n            list[Any]: A list contains all the result entries.\n        \"\"\"\n        pass\n\n    @overload\n    def orm_execute_gen(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: Callable[[sqlite3.Cursor, Any], RT],\n    ) -> Generator[RT]: ...\n\n    @overload\n    def orm_execute_gen(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: DoNotChangeRowFactory = DO_NOT_CHANGE_ROW_FACTORY,\n    ) -> Generator[TableSpecType]: ...\n\n    @overload\n    def orm_execute_gen(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: None,\n    ) -> Generator[tuple[Any, ...]]: ...\n\n    def orm_execute_gen(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: RowFactorySpecifier\n        | DoNotChangeRowFactory = DO_NOT_CHANGE_ROW_FACTORY,\n    ) -> Generator[Any]:\n        \"\"\"The same as orm_execute, but as a Generator.\"\"\"\n        pass\n\n    def orm_executemany(\n        self,\n        sql_stmt: str,\n        params: Iterable[tuple[Any, ...] | dict[str, Any]],\n    ) -> int:\n        \"\"\"Repeatedly execute the parameterized DML SQL statement sql.\n\n        NOTE that any returning values will be discarded, including with RETURNING stmt.\n\n        Args:\n            sql_stmt (str): The sqlite statement to be executed.\n            params (Iterable[tuple[Any, ...] | dict[str, Any]]): The set of parameters to be bound\n                to the sql statement execution.\n\n        Returns:\n            The affected row count.\n        \"\"\"\n        pass\n\n    def orm_executescript(self, sql_script: str) -> int:\n        \"\"\"Execute one sql script.\n\n        NOTE that any returning values will be discarded, including with RETURNING stmt.\n\n        Args:\n            sql_script (str): The sqlite script to be executed.\n\n        Returns:\n            The affected row count.\n        \"\"\"\n        pass\n\n    def orm_create_table(\n        self,\n        *,\n        allow_existed: bool = False,\n        strict: bool = False,\n        without_rowid: bool = False,\n        _stmt: str | None = None,\n    ) -> None:\n        \"\"\"Create the table defined by this ORM with <orm_table_spec>.\n\n        NOTE: strict table option is supported after sqlite3 3.37.\n\n        Args:\n            allow_existed (bool, optional): Do not abort on table already created.\n                Set True equals to add \"IF NOT EXISTS\" in the sql statement. Defaults to False.\n            strict (bool, optional): Enable strict field type check. Defaults to False.\n                See https://www.sqlite.org/stricttables.html for more details.\n            without_rowid (bool, optional): Create the table without ROWID. Defaults to False.\n                See https://www.sqlite.org/withoutrowid.html for more details.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            sqlite3.DatabaseError on failed sql execution.\n        \"\"\"\n        pass\n\n    def orm_create_index(\n        self,\n        *,\n        index_name: str,\n        index_keys: ColsDefinition | ColsDefinitionWithDirection,\n        allow_existed: bool = False,\n        unique: bool = False,\n        _stmt: str | None = None,\n    ) -> None:\n        \"\"\"Create index according to the input arguments.\n\n        Args:\n            index_name (str): The name of the index.\n            index_keys (ColsDefinition | ColsDefinitionWithDirection): The columns for the index.\n            allow_existed (bool, optional): Not abort on index already created. Defaults to False.\n            unique (bool, optional): Not allow duplicated entries in the index. Defaults to False.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            sqlite3.DatabaseError on failed sql execution.\n        \"\"\"\n        pass\n\n    @overload\n    def orm_select_entries(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _row_factory: Callable[[sqlite3.Cursor, Any], RT],\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[RT]: ...\n\n    @overload\n    def orm_select_entries(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _row_factory: None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[TableSpecType | Any]: ...\n\n    def orm_select_entries(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _row_factory: RowFactoryType | None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[TableSpecType | Any]:\n        \"\"\"Select entries from the table accordingly.\n\n        Args:\n            col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n                the pairs in this mapping will take prior than the one specified in <col_values>.\n            _distinct (bool, optional): Deduplicate and only return unique entries. Defaults to False.\n            _order_by (ColsDefinition | ColsDefinitionWithDirection | None, optional):\n                Order the result accordingly. Defaults to None, not sorting the result.\n            _limit (int | None, optional): Limit the number of result entries. Defaults to None.\n            _row_factory (RowFactoryType | None, optional): Set to use different row factory for this query.\n                Defaults to None(do not change row_factory).\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n            **col_values: provide col/value pairs by kwargs. Col/value pairs in <col_values> have lower priority over\n                the one specified by <_col_vlues_dict>.\n\n        Raises:\n            sqlite3.DatabaseError on failed sql execution.\n\n        Yields:\n            Generator[TableSpecType | Any]: A generator that can be used to yield entry from result.\n        \"\"\"\n        pass\n\n    @overload\n    def orm_select_entry(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _row_factory: Callable[[sqlite3.Cursor, Any], RT],\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> RT: ...\n\n    @overload\n    def orm_select_entry(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _row_factory: None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> TableSpecType | Any: ...\n\n    def orm_select_entry(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _row_factory: RowFactoryType | None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> TableSpecType | Any | None:\n        \"\"\"Select exactly one entry from the table accordingly.\n\n        NOTE that if the select result contains more than one entry, this method will return\n            the FIRST one from the result with fetchone API.\n\n        Args:\n            col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n                the pairs in this mapping will take prior than the one specified in <col_values>.\n            _distinct (bool, optional): Deduplicate and only return unique entries. Defaults to False.\n            _order_by (ColsDefinition | ColsDefinitionWithDirection | None, optional):\n                Order the result accordingly. Defaults to None, not sorting the result.\n            _row_factory (RowFactoryType | None, optional): Set to use different row factory for this query.\n                Defaults to None(do not change row_factory).\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n            **col_values: provide col/value pairs by kwargs. Col/value pairs in <col_values> have lower priority over\n                the one specified by <_col_vlues_dict>.\n\n        Raises:\n            sqlite3.DatabaseError on failed sql execution.\n\n        Returns:\n            TableSpecType | Any: Exactly one entry, or None if not hit.\n        \"\"\"\n        pass\n\n    def orm_insert_entries(\n        self,\n        _in: Iterable[TableSpecType],\n        *,\n        or_option: OR_OPTIONS | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"Insert an iterable of rows represented as TableSpec insts into this table.\n\n        Args:\n            _in (Iterable[TableSpecType]): An iterable of rows as TableSpec insts to insert.\n            or_option (INSERT_OR | None, optional): The fallback operation if insert failed. Defaults to None.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            ValueError: On invalid types of _in.\n            sqlite3.DatabaseError: On failed sql execution.\n\n        Returns:\n            int: Number of inserted entries.\n        \"\"\"\n        pass\n\n    def orm_insert_mappings(\n        self,\n        _in: Iterable[Mapping[str, Any]],\n        *,\n        or_option: OR_OPTIONS | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"Insert an iterable of rows represented as mappings into this table.\n\n        Each mapping stores cols with values in application types. Assuming that all entries in\n            this Iterable contains mapping with the same schema.\n\n        Args:\n            _in (Iterable[Mapping[str, Any]]): An iterable of mappings to insert.\n            or_option (INSERT_OR | None, optional): The fallback operation if insert failed. Defaults to None.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            ValueError: On invalid types of _in.\n            sqlite3.DatabaseError: On failed sql execution.\n\n        Returns:\n            int: Number of inserted entries.\n        \"\"\"\n        pass\n\n    def orm_insert_entry(\n        self,\n        _in: TableSpecType,\n        *,\n        or_option: OR_OPTIONS | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"Insert exactly one entry into this table.\n\n        Args:\n            _in (TableSpecType): The instance of entry to insert.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            ValueError: On invalid types of _in.\n            sqlite3.DatabaseError: On failed sql execution.\n\n        Returns:\n            int: Number of inserted entries. In normal case it should be 1.\n        \"\"\"\n        pass\n\n    def orm_insert_mapping(\n        self,\n        _in: Mapping[str, Any],\n        *,\n        or_option: OR_OPTIONS | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"Insert exactly one entry(represented as a mapping) into this table.\n\n        Args:\n            _in (TableSpecType): The instance of entry to insert.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            ValueError: On invalid types of _in.\n            sqlite3.DatabaseError: On failed sql execution.\n\n        Returns:\n            int: Number of inserted entries. In normal case it should be 1.\n        \"\"\"\n        pass\n\n    def orm_update_entries(\n        self,\n        *,\n        set_values: Mapping[str, Any] | TableSpec,\n        where_cols_value: Mapping[str, Any] | None = None,\n        where_stmt: str | None = None,\n        or_option: OR_OPTIONS | None = None,\n        _extra_params: Mapping[str, Any] | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"UPDATE specific entries by matching <where_cols_value>.\n\n        NOTE: if you want to using the same query stmt with different set of params(set col/values and/or where col/values),\n            it is highly recommended to use `orm_update_entries_many` API, it will be significantly faster to call `orm_update_entries`\n            in a for loop(in my test with 2000 entries, using `orm_update_entries_many` is around 300 times faster).\n        NOTE: currently UPDATE-WITH-LIMIT and RETURNING are not supported by this method.\n\n        Args:\n            set_values (Mapping[str, Any] | TableSpec): values to update.\n            where_cols_value (Mapping[str, Any], optional): cols to matching. This method will\n                also generate WHERE statement of matching each cols specified in this mapping.\n            where_stmt (str | None, optional): directly provide WHERE statement. If provided,\n                <where_cols_value> will only be used as params.\n            or_option (OR_OPTIONS | None, optional): specify the operation if UPDATE failed.\n            _extra_params (Mapping[str, Any] | None, optional): provide extra named params\n                for sqlite3 query execution. NOTE that `_extra_params` takes higher priority\n                to any named params specified by `where_cols_value` and `set_values`. Defaults to None.\n            _stmt (str | None, optional): directly provide the UPDATE query, if provided,\n                <where_cols_value>, <where_stmt> and <or_option> will be ignored.\n\n        Raises:\n            SQLite3 DB Errors on failed operations.\n\n        Returns:\n            Affected rows count.\n        \"\"\"\n        pass\n\n    @overload\n    def orm_update_entries_many(\n        self,\n        *,\n        set_cols: tuple[str, ...],\n        where_cols: tuple[str, ...] | None = None,\n        where_stmt: str | None = None,\n        set_cols_value: Iterable[Mapping[str, Any]],\n        where_cols_value: Iterable[Mapping[str, Any]] | None = None,\n        or_option: OR_OPTIONS | None = None,\n        _extra_params: Mapping[str, Any] | None = None,\n        _extra_params_iter: Iterable[Mapping[str, Any]] | None = None,\n        _stmt: None = None,\n    ) -> int: ...\n\n    @overload\n    def orm_update_entries_many(\n        self,\n        *,\n        set_cols: None = None,\n        where_cols: None = None,\n        where_stmt: None = None,\n        set_cols_value: None = None,\n        where_cols_value: None = None,\n        or_option: None = None,\n        _extra_params: Mapping[str, Any] | None = None,\n        _extra_params_iter: Iterable[Mapping[str, Any]] | None = None,\n        _stmt: str,\n    ) -> int: ...\n\n    def orm_update_entries_many(\n        self,\n        *,\n        set_cols: tuple[str, ...] | None = None,\n        where_cols: tuple[str, ...] | None = None,\n        where_stmt: str | None = None,\n        set_cols_value: Iterable[Mapping[str, Any]] | None = None,\n        where_cols_value: Iterable[Mapping[str, Any]] | None = None,\n        or_option: OR_OPTIONS | None = None,\n        _extra_params: Mapping[str, Any] | None = None,\n        _extra_params_iter: Iterable[Mapping[str, Any]] | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"executemany version of orm_update_entries.\n\n        Params like `set_cols_value` and `where_cols_value` need to be provided as iterables.\n        NOTE that the execution will end and return when any of the input iterable exhausted.\n\n        NOTE that `_extra_params` and `_extra_params_iter` will not be serialized. Caller needs to\n            provide the serialized mappings ready for `executemany`.\n\n        Args:\n            set_cols (tuple[str, ...]): Cols to be updated.\n            set_cols_value (Iterable[Mapping[str, Any]]): An iterable of values of to-be-updated cols.\n            where_cols (tuple[str, ...] | None, optional): Cols to match. The WHERE stmt will be generated\n                based on this param. Defaults to None.\n            where_cols_value (Iterable[Mapping[str, Any]] | None, optional): An iterable of values of cols to match.\n                Defaults to None.\n            where_stmt (str | None, optional): Directly provide the WHERE stmt. If specified, both `where_cols` and\n                `where_cols_value` will be ignored. Caller needs to feed the params with `_extra_params` or `_extra_params_iter`.\n                Defaults to None.\n            or_option (OR_OPTIONS | None, optional): specify the operation if UPDATE failed. Defaults to None.\n            _extra_params (Mapping[str, Any] | None, optional): A fixed mapping to be injected for each execution.\n                NOTE that this param is only allowed when at least one of `where_cols_value`, `set_cols_value` or `_extra_params_iter` is specified.\n                Defaults to None.\n            _extra_params_iter (Iterable[Mapping[str, Any]] | None, optional): An iterable of mappings to be injected for each execution. Defaults to None.\n            _stmt (str | None, optional): Directly provide the UPDATE query, if specified, params except `_extra_params` and `_extra_params_iter`\n                will be ignored. Defaults to None.\n\n        Raises:\n            ValueError: If `where_cols_value` and `where_cols` are not be both None or both specifed.\n            ValueError: If `_stmt` is not used and `set_cols` and/or `set_cols_value` are not specified.\n            ValueError: If `_extra_params` is specified without any other iterable params provided.\n            sqlite3 DB error on execution failed.\n\n        Returns:\n            Affected rows count.\n        \"\"\"\n        pass\n\n    def orm_delete_entries(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> int:\n        \"\"\"Delete entries from the table accordingly.\n\n        Args:\n            col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n                the pairs in this mapping will take prior than the one specified in <col_values>.\n            _order_by (ColsDefinition | ColsDefinitionWithDirection | None, optional): Order the matching entries\n                before executing the deletion, used together with <_limit>. Defaults to None.\n            _limit (int | None, optional): Only delete <_limit> number of entries. Defaults to None.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n            **col_values: provide col/value pairs by kwargs. Col/value pairs in <col_values> have lower priority over\n                the one specified by <_col_vlues_dict>.\n\n        Returns:\n            int: The num of entries deleted.\n        \"\"\"\n        pass\n\n    @overload\n    def orm_delete_entries_with_returning(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _returning_cols: ColsDefinition | Literal[\"*\"],\n        _row_factory: Callable[[sqlite3.Cursor, Any], RT],\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[RT]: ...\n\n    @overload\n    def orm_delete_entries_with_returning(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _returning_cols: ColsDefinition | Literal[\"*\"],\n        _row_factory: None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[TableSpecType | Any]: ...\n\n    def orm_delete_entries_with_returning(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _returning_cols: ColsDefinition | Literal[\"*\"],\n        _row_factory: RowFactoryType | None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[TableSpecType | Any]:\n        \"\"\"Delete entries from the table accordingly.\n\n        NOTE that only sqlite3 version >= 3.35 supports returning statement.\n\n        Args:\n            col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n                the pairs in this mapping will take prior than the one specified in <col_values>.\n            _order_by (ColsDefinition | ColsDefinitionWithDirection | None, optional): Order the matching entries\n                before executing the deletion, used together with <_limit>. Defaults to None.\n            _limit (int | None, optional): Only delete <_limit> number of entries. Defaults to None.\n            _returning_cols (ColsDefinition | Literal[\"*\"] ): Return the deleted entries on execution.\n            _row_factory (RowFactoryType | None, optional): Set to use different row factory for this query.\n                Defaults to None(do not change row_factory).\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n            **col_values: provide col/value pairs by kwargs. Col/value pairs in <col_values> have lower priority over\n                the one specified by <_col_vlues_dict>.\n\n        Returns:\n            Generator[TableSpecType | Any]: If <_returning_cols> is defined, returns a generator which can\n                be used to yield the deleted entries from.\n        \"\"\"\n        pass\n\n    def orm_select_all_with_pagination(\n        self, *, batch_size: int\n    ) -> Generator[TableSpecType | Any]:\n        \"\"\"Select all entries from the table accordingly with pagination.\n\n        This is implemented by seek with rowid, so it will not work on without_rowid table.\n\n        Args:\n            batch_size (int): The entry number for each page.\n\n        Raises:\n            ValueError on invalid batch_size.\n            sqlite3.DatabaseError on failed sql execution.\n\n        Yields:\n            Generator[TableSpecType, None, None]: A generator that can be used to yield entry from result.\n        \"\"\"\n        pass\n\n    def orm_check_entry_exist(\n        self, col_value_pairs: Mapping[str, Any] | None = None, **col_values: Any\n    ) -> bool:\n        \"\"\"A quick method to check whether entry(entries) indicated by cols exists.\n\n        This method uses COUNT function to count the selected entry.\n\n        Args:\n            col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n                the pairs in this mapping will take prior than the one specified in <col_values>.\n            **cols: cols pair to locate the entry(entries).\n\n        Returns:\n            Returns True if at least one entry matches the input cols exists, otherwise False.\n        \"\"\"\n        pass\n\nORMBaseType = TypeVar(\"ORMBaseType\", bound=ORMBase)\n\n"
            },
            {
                "file_path": "src/simple_sqlite3_orm/_orm/_utils.py",
                "code": "from __future__ import annotations\nfrom typing import Any\n\ndef parameterized_class_getitem(\n    cls, params: Any | type[Any] | type[TableSpecType] | tuple[type[Any], ...]\n) -> Any:\n    pass\n\n"
            }
        ],
        "minimal_code_skeleton": "--- File: src/simple_sqlite3_orm/_types.py ---\n```python\nfrom __future__ import annotations\n\nimport datetime\nfrom typing import Any\n\nfrom pydantic import BeforeValidator, PlainSerializer\nfrom typing_extensions import Annotated\n\nDatetimeUnixTimestamp = Annotated[\n    datetime.datetime,\n    BeforeValidator(_datetime_validator),\n    PlainSerializer(lambda x: x.timestamp(), return_type=float),\n]\n\"\"\"datetime.datetime as unixtimestamp in seconds serialized as a float in db.\"\"\"\n\nDatetimeUnixTimestampInt = Annotated[\n    datetime.datetime,\n    BeforeValidator(_datetime_validator),\n    PlainSerializer(lambda x: int(x.timestamp()), return_type=int),\n]\n\"\"\"datetime.datetime as unixtimestamp in seconds serialized as an int in db.\"\"\"\n\nDatetimeISO8601 = Annotated[\n    datetime.datetime,\n    BeforeValidator(_datetime_validator),\n    PlainSerializer(lambda x: x.isoformat(), return_type=str),\n]\n\"\"\"datetime.datetime as str(ISO8601 formatted) serialized as a string in db.\"\"\"\n```\n--- File: src/simple_sqlite3_orm/_sqlite_spec.py ---\n```python\nfrom __future__ import annotations\n\nfrom enum import Enum\nfrom typing import Literal, Union\n\nclass SQLiteTypeAffinity(str, Enum):\n    TEXT = \"TEXT\"\n    NUMERIC = \"NUMERIC\"\n    INTEGER = \"INTEGER\"\n    REAL = \"REAL\"\n    BLOB = \"BLOB\"\n    NULL = \"NULL\"\n```\n--- File: src/simple_sqlite3_orm/_table_spec.py ---\n```python\nfrom __future__ import annotations\n\nimport sqlite3\nfrom collections.abc import Mapping\nfrom types import MappingProxyType\nfrom typing import Any, ClassVar, Generator, Iterable, Literal, TypedDict, TypeVar\n\nfrom pydantic import BaseModel\nfrom pydantic.fields import FieldInfo\nfrom typing_extensions import NotRequired, Self\n\nfrom simple_sqlite3_orm._sqlite_spec import (\n    OR_OPTIONS,\n    ORDER_DIRECTION,\n    SQLiteBuiltInFuncs,\n)\n\nclass CreateTableParams(TypedDict, total=False):\n    if_not_exists: bool\n    strict: bool\n    temporary: bool\n    without_rowid: bool\n\nclass CreateIndexParams(TypedDict):\n    index_name: str\n    index_cols: tuple[str | tuple[str, ORDER_DIRECTION], ...]\n    if_not_exists: NotRequired[bool]\n    unique: NotRequired[bool]\n\nclass TableSpec(BaseModel):\n    \"\"\"Define table as pydantic model, with specific APIs.\"\"\"\n\n    table_columns: ClassVar[MappingProxyType[str, FieldInfo]]\n    \"\"\"A view of TableSpec's model_fields.\"\"\"\n\n    table_columns_by_index: ClassVar[tuple[str, ...]]\n    \"\"\"Ordered tuple of column names, matching exactly with table schema.\"\"\"\n\n    _table_update_where_cols_prefix: ClassVar[Literal[\"__table_spec_\"]] = (\n        \"__table_spec_\"\n    )\n\n    @classmethod\n    def __pydantic_init_subclass__(cls, **_) -> None:\n        pass\n\n    @classmethod\n    def table_create_stmt(\n        cls,\n        table_name: str,\n        *,\n        if_not_exists: bool = False,\n        strict: bool = False,\n        temporary: bool = False,\n        without_rowid: bool = False,\n    ) -> str:\n        \"\"\"Get create table statement with this table spec class.\n\n        Check https://www.sqlite.org/lang_createtable.html for more details.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_create_index_stmt(\n        cls,\n        *,\n        table_name: str,\n        index_name: str,\n        index_cols: tuple[str | tuple[str, ORDER_DIRECTION], ...],\n        if_not_exists: bool = False,\n        unique: bool = False,\n    ) -> str:\n        \"\"\"Get index create statement with this table spec class.\n\n        Raises:\n            ValueError on <index_cols> not specified, or invalid <index_cols>.\n\n        Check https://www.sqlite.org/lang_createindex.html for more details.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_row_factory(\n        cls,\n        _cursor: sqlite3.Cursor,\n        _row: tuple[Any, ...] | Any,\n        *,\n        validation: bool = True,\n    ) -> Self | tuple[Any, ...]:\n        \"\"\"A general row_factory implement for used in sqlite3 connection.\n\n        When the input <_row> is not a row but something like function output,\n            this method will return the raw input tuple as it.\n\n        Args:\n            validation (bool): whether enable pydantic validation when importing row. Default to True.\n\n        Raises:\n            Any exception raised from pydantic model_validate or model_construct.\n\n        Returns:\n            An instance of <TableSpec>, or the raw tuple if the input row has different schema.\n\n        Also see https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.description\n            for more details.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_row_factory2(\n        cls,\n        _cursor: sqlite3.Cursor,\n        _row: tuple[Any, ...] | Any,\n        *,\n        validation: bool = True,\n    ) -> Self:\n        \"\"\"Another version of row_factory implementation for specific use case.\n\n        Unlike table_row_factory that checks the cols definition and ensure all cols\n            are valid and presented in table def, table_row_factory2 just picks the valid\n            cols from the input raw table row, and ignore unknown col/value pairs.\n\n        Args:\n            validation (bool): whether enable pydantic validation when importing row. Default to True.\n\n        Raises:\n            Any exception raised from pydantic model_validate or model_construct.\n\n        Returns:\n            An instance of <TableSpec>.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_from_tuple(\n        cls, _row: Iterable[Any], *, with_validation: bool = True, **kwargs\n    ) -> Self:\n        \"\"\"A raw row_factory that converts the input _row to TableSpec instance.\n\n        NOTE that this method expects the input row match the table row spec EXACTLY.\n\n        Args:\n            _row (tuple[Any, ...]): the raw table row as tuple.\n            with_validation (bool): if set to False, will use pydantic model_construct to directly\n                construct instance without validation. Default to True.\n            **kwargs: extra kwargs passed to pydantic model_validate API. Note that only when\n                with_validation is True, the kwargs will be used.\n\n        Returns:\n            An instance of self.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_from_dict(\n        cls, _map: Mapping[str, Any], *, with_validation: bool = True, **kwargs\n    ) -> Self:\n        \"\"\"A raw row_factory that converts the input mapping to TableSpec instance.\n\n        Args:\n            _map (Mapping[str, Any]): the raw table row as a dict.\n            with_validation (bool, optional): if set to False, will use pydantic model_construct to directly\n                construct instance without validation. Default to True.\n            **kwargs: extra kwargs passed to pydantic model_validate API. Note that only when\n                with_validation is True, the kwargs will be used.\n\n        Returns:\n            An instance of self.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_insert_stmt(\n        cls,\n        *,\n        insert_into: str,\n        insert_cols: tuple[str, ...] | None = None,\n        insert_default: bool = False,\n        or_option: OR_OPTIONS | None = None,\n        returning_cols: tuple[str, ...] | Literal[\"*\"] | None = None,\n        returning_stmt: str | None = None,\n    ) -> str:\n        \"\"\"Get sql for inserting row(s) into <table_name>.\n\n        Check https://www.sqlite.org/lang_insert.html for more details.\n\n        Args:\n            insert_into (str): The name of table insert into.\n            insert_cols (tuple[str, ...] | None, optional): The cols to be assigned for entry to be inserted.\n                Defaults to None, means we will assign all cols of the row.\n            insert_default (bool, optional): No values will be assigned, all cols will be assigned with\n                default value, this precedes the <insert_cols> param. Defaults to False.\n            or_option (INSERT_OR | None, optional): The fallback operation if insert failed. Defaults to None.\n            returning_cols (tuple[str, ...] | Literal[\"*\"] | None): Which cols are included in the returned entries.\n                Defaults to None.\n            returning_stmt (str | None, optional): The full returning statement string, this\n                precedes the <returning_cols> param. Defaults to None.\n\n        Returns:\n            str: The generated insert statement.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_update_stmt(\n        cls,\n        *,\n        or_option: OR_OPTIONS | None = None,\n        update_target: str,\n        set_cols: tuple[str, ...],\n        where_cols: tuple[str, ...] | None = None,\n        where_stmt: str | None = None,\n        returning_cols: tuple[str, ...] | Literal[\"*\"] | None = None,\n        returning_stmt: str | None = None,\n        order_by: tuple[str | tuple[str, ORDER_DIRECTION], ...] | None = None,\n        order_by_stmt: str | None = None,\n        limit: int | None = None,\n    ) -> str:\n        \"\"\"Get sql query for updating row(s) at <table_name>.\n\n        Check https://www.sqlite.org/lang_update.html for more details.\n\n        NOTE: to avoid overlapping between <set_cols> and <where_cols> when generating named-placeholders,\n            this method will prefix cols name with <_table_spec_update_where_cols_prefix> when generating\n            WHERE statement.\n            To directly use the stmt generated from this API, dev must use table_preprare_update_where_cols\n            to prepare the col/value mapping for params.\n\n        NOTE that UPDATE-FROM extension is currently not supported by this method.\n        NOTE that UPDATE-WITH-LIMIT is an optional feature, needs to be enabled at compiled time with\n            SQLITE_ENABLE_UPDATE_DELETE_LIMIT.\n\n        Args:\n            or_option (INSERT_OR | None, optional): The fallback operation if update failed. Defaults to None.\n            update_target (str): The name of table to update.\n            set_cols (tuple[str, ...]): The cols to be updated.\n            where_cols (tuple[str, ...] | None, optional): A list of cols to be compared in where\n                statement. Defaults to None.\n            where_stmt (str | None, optional): The full where statement string, this\n                precedes the <where_cols> param if set. Defaults to None.\n            returning_cols (tuple[str, ...] | Literal[\"*\"] | None): If specified, enable RETURNING stmt, and specifying Which cols\n                included in the returned entries. Defaults to None.\n            returning_stmt (str | None, optional): The full returning statement string, this\n                precedes the <returning_cols> param. Defaults to None.\n            order_by (Iterable[str  |  tuple[str, ORDER_DIRECTION], ...] | None, optional):\n                Works with LIMIT, to specify the range that LIMIT affects. Defaults to None.\n            order_by_stmt (str | None, optional): The order_by statement string, this\n                precedes the <order_by> param if set. Defaults to None.\n            limit (int | None, optional): Limit the number of affected entries. Defaults to None.\n\n        Returns:\n            str: The generated update sqlite3 query.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_preprare_update_where_cols(\n        cls, where_cols: Mapping[str, Any]\n    ) -> Mapping[str, Any]:\n        \"\"\"Regulate the named-placeholder <where_cols> so that it will not overlap with <set_cols>.\n\n        This is MUST for directly using the sqlite query stmt generated from table_update_stmt.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_select_stmt(\n        cls,\n        *,\n        select_from: str,\n        select_cols: tuple[str, ...] | Literal[\"*\"] | str = \"*\",\n        function: SQLiteBuiltInFuncs | None = None,\n        where_stmt: str | None = None,\n        where_cols: tuple[str, ...] | None = None,\n        group_by: tuple[str, ...] | None = None,\n        order_by: tuple[str | tuple[str, ORDER_DIRECTION], ...] | None = None,\n        order_by_stmt: str | None = None,\n        limit: int | None = None,\n        distinct: bool = False,\n    ) -> str:\n        \"\"\"Get sql for getting row(s) from <table_name>, optionally with\n            where condition specified by <col_values>.\n\n        Check https://www.sqlite.org/lang_select.html for more details.\n\n        Args:\n            select_from (str): The table name for the generated statement.\n            select_cols (tuple[str, ...] | Literal[\"*\"] | str, optional): A list of cols included in the result row. Defaults to \"*\".\n            function (SQLiteBuiltInFuncs | None, optional): The sqlite3 function used in the selection. Defaults to None.\n            where_cols (tuple[str, ...] | None, optional): A list of cols to be compared in where\n                statement. Defaults to None.\n            where_stmt (str | None, optional): The full where statement string, this\n                precedes the <where_cols> param if set. Defaults to None.\n            group_by (tuple[str, ...] | None, optional): A list of cols for group_by statement. Defaults to None.\n            order_by (Iterable[str  |  tuple[str, ORDER_DIRECTION], ...] | None, optional):\n                A list of cols for ordering result. Defaults to None.\n            order_by_stmt (str | None, optional): The order_by statement string, this\n                precedes the <order_by> param if set. Defaults to None.\n            limit (int | None, optional): Limit the number of result entries. Defaults to None.\n            distinct (bool, optional): Whether filters the duplicated entries. Defaults to False.\n\n        Returns:\n            str: The generated select statement.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_delete_stmt(\n        cls,\n        *,\n        delete_from: str,\n        where_cols: tuple[str, ...] | None = None,\n        where_stmt: str | None = None,\n        order_by: tuple[str | tuple[str, ORDER_DIRECTION], ...] | None = None,\n        order_by_stmt: str | None = None,\n        limit: int | str | None = None,\n        returning_cols: tuple[str, ...] | Literal[\"*\"] | None = None,\n        returning_stmt: str | None = None,\n    ) -> str:\n        \"\"\"Get sql for deleting row(s) from <table_name> with specifying col value(s).\n\n        Check https://www.sqlite.org/lang_delete.html for more details.\n\n        NOTE(20240311): DELETE operation without any condition(no WHERE statement) in\n            WITHOUT_ROWID table will result in rowcount=0, see\n            https://sqlite.org/forum/forumpost/07dedbf9a1 for more details.\n            For python, python version < 3.10 will be affected by this bug.\n            A quick workaround is to add any condition in where statement, even a dummy\n            \"WHERE 1=1\" can resolve the above bug.\n            I will not add this hack here, and user can add this hack according to their needs.\n\n        NOTE: <order_by> and <limit> support are only enabled when runtime sqlite3 lib is compiled with\n            SQLITE_ENABLE_UPDATE_DELETE_LIMIT flag.\n\n        Args:\n            delete_from (str): The table name for the generated statement.\n            limit (int | str | None, optional): The value for limit expr. Defaults to None.\n            order_by (Iterable[str  |  tuple[str, ORDER_DIRECTION]] | None, optional):\n                A list of cols for ordering result. Defaults to None.\n            order_by_stmt (str | None, optional): The order_by statement string, this\n                precedes the <order_by> param if set. Defaults to None.\n            where_cols (tuple[str, ...] | None, optional): A list of cols to be compared in where\n                statement. Defaults to None.\n            where_stmt (str | None, optional): The full where statement string, this\n                precedes the <where_cols> param if set. Defaults to None.\n            returning_cols (tuple[str, ...] | Literal[\"*\"] | None): Which cols are included in the returned entries.\n                Defaults to None.\n            returning_stmt (str | None, optional): The full returning statement string, this\n                precedes the <returning_cols> param. Defaults to None.\n\n        Returns:\n            str: The generated delete statement.\n        \"\"\"\n        pass\n\n    def table_dump_asdict(self, *cols: str, **kwargs) -> dict[str, Any]:\n        \"\"\"Serialize self as a dict, containing all cols or specified cols, for DB operations.\n\n        Under the hook this method calls pydantic model_dump on self.\n        The dumped dict can be used to directly insert into the table.\n\n        Args:\n            *cols: which cols to export, if not specified, export all cols.\n            **kwargs: any other kwargs that passed to pydantic model_dump method.\n                Note that the include kwarg is used to specific which cols to dump.\n\n        Raises:\n            ValueError if failed to serialize the model, wrapping underlying\n                pydantic serialization error.\n\n        Returns:\n            A dict of dumped col values from this row.\n        \"\"\"\n        pass\n\n    def table_asdict(self, *cols: str) -> dict[str, Any]:\n        \"\"\"Directly export the self as a dict, without serializing.\n\n        Args:\n            *cols: which cols to export, if not specified, export all cols.\n            exclude_unset (bool, optional): whether include not set field of self.\n                Defaults to False, include unset fields(which will return their default values).\n\n        Returns:\n            A dict of col/values from self.\n        \"\"\"\n        pass\n\n    def table_dump_astuple(self, *cols: str, **kwargs) -> tuple[Any, ...]:\n        \"\"\"Serialize self's value as a tuple, containing all cols or specified cols, for DB operations.\n\n        This method is basically the same as table_dump_asdict, but instead return a\n            tuple of the dumped values.\n\n        Args:\n            *cols: which cols to export, if not specified, export all cols.\n            **kwargs: any other kwargs that passed to pydantic model_dump method.\n                Note that the include kwarg is used to specific which cols to dump.\n\n        Returns:\n            A tuple of dumped col values.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_serialize_mapping(cls, _in: Mapping[str, Any]) -> dict[str, Any]:\n        \"\"\"Serialize input mapping into a dict by this TableSpec, ready for DB operations.\n\n        Values in the input mapping are python types used in application.\n\n        This is a convenient method for when we only need to specify some of the cols, so that\n            we cannot use TableSpec as TableSpec requires all cols to be set.\n\n        NOTE that for APIs provided by simple_sqlite3_orm, when col/value pairs are provided as mapping,\n            the serialization will be done by the APIs, no need to call this method when using ORM.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_deserialize_asdict_row_factory(\n        cls,\n        _cursor: sqlite3.Cursor,\n        _row: tuple[Any, ...] | Any,\n        *,\n        allow_unknown_cols: bool = True,\n    ) -> dict[str, Any]:\n        \"\"\"Deserialize raw row from a query into a dict by this TableSpec, ready for application use.\n\n        This is a convenient method when we execute query that only select some cols.\n        For this use case, use thid method as row_factory to deserialize the raw row. This method\n            will deserialize the row from raw into actual field types defined in this TableSpec.\n\n        NOTE that if `allow_unknow_cols` is True, any unknown field(including cols aliased with other name)\n            will be preserved AS IT without deserializing as this method cannot know which col the alias name maps to.\n\n        Args:\n            allow_unknown_cols (bool, optional): If True, unknown cols will be preserved AS IT into the result.\n                Defaults to True.\n\n        Raises:\n            ValueError if `allow_unknown_cols` is False and unknown cols presented, or pydantic validation failed.\n\n        Returns:\n            A dict of deserialized(except unknown cols) col/value pairs.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_deserialize_astuple_row_factory(\n        cls, _cursor: sqlite3.Cursor, _row: tuple[Any, ...] | Any\n    ) -> tuple[Any, ...]:\n        \"\"\"Deserialize raw row from a query into a tuple by this TableSpec, ready for application use.\n\n        This is a convenient method when we execute query that only select some cols.\n        For this use case, use thid method as row_factory to deserialize the raw row. This method\n            will deserialize the row from raw into actual field types defined in this TableSpec.\n\n        NOTE that any unknown field(including cols aliased with other name) will be preserved AS IT without\n            deserializing as this method cannot know which col the alias name maps to.\n\n        Raises:\n            ValueError if pydantic validation failed.\n\n        Returns:\n            A tuple of deserialized row as tuple.\n        \"\"\"\n        pass\n\nTableSpecType = TypeVar(\"TableSpecType\", bound=TableSpec)\n```\n--- File: src/simple_sqlite3_orm/_utils.py ---\n```python\nfrom __future__ import annotations\n\nimport sys\nfrom io import StringIO\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Callable,\n    Literal,\n    TypeVar,\n    Union,\n    get_args,\n    get_origin,\n)\n\nfrom typing_extensions import ParamSpec\n\nfrom simple_sqlite3_orm._sqlite_spec import (\n    ConstrainLiteral,\n    SQLiteTypeAffinity,\n    SQLiteTypeAffinityLiteral,\n)\n\nT = TypeVar(\"T\")\n\nclass TypeAffinityRepr:\n    \"\"\"Map python types to sqlite3 data types with type affinity.\n\n    Currently supports:\n    1. python sqlite3 lib supported native python types.\n    2. StrEnum and IntEnum, will map to TEXT and INT accordingly.\n    3. Optional types, will map against the args inside the Optional.\n    4. Literal types, will map against the values type inside the Literal.\n\n    Attrs:\n        type_affinity (SQLiteTypeAffinity | str)\n        origin (type[Any] | SQLiteTypeAffinityLiteral | Any)\n    \"\"\"\n    type_affinity: SQLiteTypeAffinity | str\n    origin: type[Any] | SQLiteTypeAffinityLiteral | Any\n\n    def __init__(self, _in: type[Any] | SQLiteTypeAffinityLiteral | Any) -> None:\n        pass\n\n    def __str__(self) -> str:\n        pass\n\nclass ConstrainRepr:\n    \"\"\"Helper class for composing full constrain statement string.\n\n    For example, for constrain statement like the following:\n        NOT NULL DEFAULT NULL CHECK (column IN (1, 2, 3))\n    can be represented ConstrainRepr as follow:\n        ConstrainRepr(\n            \"NOT NULL\",\n            (\"DEFAULT\", \"NULL\"),\n            (\"CHECK\", r\"(column IN (1, 2, 3))\")\n        )\n\n    Attrs:\n        constraints (set[str | tuple[str, str]]): a set of constrains.\n    \"\"\"\n    constraints: tuple[ConstrainLiteral | tuple[ConstrainLiteral, str] | Any, ...]\n\n    def __init__(\n        self, *params: ConstrainLiteral | tuple[ConstrainLiteral, str] | Any\n    ) -> None:\n        pass\n\n    def __str__(self) -> str:\n        pass\n\ndef gen_sql_stmt(*components: str, end_with: str | None = \";\") -> str:\n    \"\"\"Combine each components into a single sql stmt.\"\"\"\n    pass\n\nclass ColsSelectFactory(tuple[T, ...]):\n    \"\"\"A factory type to generate cols name checker.\n\n    Usage:\n\n    MyTableCols = Literal[\"entry_id\", \"entry_context\", \"entry_type\"]\n    MyTableColsChecker = ColsCheckerFactory[MyTableCols]\n\n    # now you can use `MyTableColsChecker` to specify a tuple of cols name as follow:\n    cols_to_select = MyTableColsChecker(\"unknown\", \"invalid_col\")  # type checker err\n    cols_to_select = MyTableColsChecker(\"entry_id\", \"entry_type\")  # valid\n\n    # at runtime, `cols_to_select` is a regular `tuple` object.\n\n    \"\"\"\n\n    def __new__(cls, *cols: T) -> tuple[T, ...]:\n        pass\n```\n--- File: src/simple_sqlite3_orm/utils.py ---\n```python\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport sqlite3\nimport sys\nfrom enum import Enum\nfrom io import StringIO\nfrom itertools import islice\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Generator,\n    Iterable,\n    Literal,\n    get_args,\n    get_origin,\n    overload,\n)\n\ndef enable_wal_mode(con: sqlite3.Connection, relax_sync_mode: bool = True):\n    \"\"\"Enable WAL mode for the connected database.\n\n    Note that for multiple databases being attached, WAL mode only guarantees\n        atomic within each individual database file. See https://www.sqlite.org/lang_attach.html\n        for more details.\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n        relax_sync_mode (bool): Also set the synchronous mode to NORMAL. Default to True.\n\n    Raises:\n        sqlite3.DatabaseError on failed sql execution.\n    \"\"\"\n    pass\n\ndef enable_tmp_store_at_memory(con: sqlite3.Connection):\n    \"\"\"Locate the temp tables at memory.\n\n    See https://www.sqlite.org/pragma.html#pragma_temp_store for more details.\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n\n    Raises:\n        sqlite3.DatabaseError on failed sql execution.\n    \"\"\"\n    pass\n\ndef enable_mmap(con: sqlite3.Connection, mmap_size: int = ...) -> None: # DEFAULT_MMAP_SIZE used in original\n    \"\"\"Enable mmap for the connection.\n\n    See https://www.sqlite.org/pragma.html#pragma_mmap_size for more\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n        mmap_size (int, optional): The max mmap size. Defaults to <DEFAULT_MMAP_SIZE=16MiB>.\n\n    Raises:\n        sqlite3.DatabaseError on failed sql execution.\n    \"\"\"\n    pass\n\ndef optimize_db(con: sqlite3.Connection):\n    \"\"\"Execute optimize PRAGMA on the target database.\n\n    See https://www.sqlite.org/pragma.html#pragma_optimize.\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n\n    Raises:\n        sqlite3.DatabaseError on failed sql execution.\n    \"\"\"\n    pass\n\ndef check_db_integrity(con: sqlite3.Connection, table_name: str | None = None) -> bool:\n    \"\"\"Execute integrity_check PRAGMA on the target database(or specific table at the database).\n\n    See https://www.sqlite.org/pragma.html#pragma_integrity_check for more details.\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n        table_name (str | None, optional): If specified, the integrity_check will only be performed\n            against this table. Defaults to None, means performing the check on the whole database.\n\n    Returns:\n        bool: True for integrity_check passed on the target database, False for errors found.\n    \"\"\"\n    pass\n\ndef lookup_table(con: sqlite3.Connection, table_name: str) -> bool:\n    \"\"\"Check if specific table existed on the target database.\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n        table_name (str): The name of table to lookup.\n\n    Returns:\n        bool: True for table existed, False for not found.\n    \"\"\"\n    pass\n\n@overload\ndef check_pragma_compile_time_options(\n    con: sqlite3.Connection, option_name: str\n) -> tuple[str, Any] | None: ...\n\n@overload\ndef check_pragma_compile_time_options(\n    con: sqlite3.Connection, option_name: None = None\n) -> list[tuple[str, Any]]: ...\n\ndef check_pragma_compile_time_options(\n    con: sqlite3.Connection, option_name: str | None = None\n) -> tuple[str, Any] | None | list[tuple[str, Any]]:\n    \"\"\"Get the runtime sqlite3 library's compile time options.\n\n    Args:\n        con (sqlite3.Connection): The current database connection.\n        option_name (str | None, optional): The option to lookup. If not specified,\n            it will return all the options and its values. Defaults to None.\n\n    Returns:\n        tuple[str, Any] | None | list[tuple[str, Any]]: Looked up options and its values.\n    \"\"\"\n    pass\n\nif sys.version_info >= (3, 12):\n    pass\nelse: # pragma: no cover\n    def batched(\n        iterable: Iterable[Any], n: int\n    ) -> Generator[tuple[Any, ...], Any, None]:\n        \"\"\"Batch data from the iterable into tuples of length n. The last batch may be shorter than n.\n\n        Backport batched from py3.12. This is the roughly python implementation\n            of py3.12's batched copied from py3.12 documentation.\n        See https://docs.python.org/3/library/itertools.html#itertools.batched for more details.\n\n        Args:\n            iterable (Iterable[Any]): The input to be batched.\n            n (int): the size of each batch.\n\n        Raises:\n            ValueError on invalid n.\n\n        Returns:\n            A generator that can be used to loop over the input iterable and accumulates data into\n                tuples up to size n(a.k.a, batch in size of n).\n        \"\"\"\n        pass\n\ndef gen_check_constrain(_in: Any, field_name: str) -> str:\n    \"\"\"Generate the constrain statement for CHECK keyword.\n\n    Supports the following types:\n    1. StrEnum or IntEnum types: will generate statement like:\n        <field_name> IN (<enum_value_1>[, <enum_value_2>[, ...]])\n    2. Literal types: similar to StrEnum and IntEnum.\n\n    Args:\n        enum_type (type[Enum]): The enum type to generate CHECK statement against.\n        field_name (str): The field name of this enum_type in use.\n\n    Raises:\n        TypeError on unsupported enum_type.\n\n    Returns:\n        str: the generated statement can be used with CHECK keyword like the following:\n           <enum_value_1>[, <enum_value_2>[, ...]]\n    \"\"\"\n    pass\n\ndef concatenate_condition(\n    *condition_or_op: Any, # Original was CONDITION_OPERATORS | COMPARE_OPERATORS | Any\n    wrapped_with_parentheses: bool = True,\n) -> str:\n    \"\"\"Chain a list of conditions and operators together in a string.\n\n    For example, for the following statement for CHECK keyword:\n        (column IS NULL OR column IN (1, 2, 3))\n    we can use concatenate_condition like:\n        concatenate_condition(\n            \"column IS NULL\", \"OR\", \"column IN (1, 2, 3)\",\n            wrapped_with_parentheses=True,\n        )\n    \"\"\"\n    pass\n\ndef wrap_value(value: Any) -> str:\n    \"\"\"Wrap value for use in sql statement.\n\n    NOTE that for most cases, you should use python sqlite3 lib's\n        placeholder feature to bind value in the sql statement.\n\n    For int and float, the value will be used as it.\n    For str, the value will be wrapped with parenthesis.\n    For bytes, the value will be converted as x'<bytes_in_hex>'.\n    \"\"\"\n    pass\n```\n--- File: src/simple_sqlite3_orm/_orm/_base.py ---\n```python\nfrom __future__ import annotations\n\nimport sqlite3\nimport warnings\nfrom functools import cached_property, partial\nfrom itertools import chain\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Callable,\n    Generator,\n    Generic,\n    Iterable,\n    Literal,\n    Mapping,\n    TypeVar,\n    Union,\n    overload,\n)\n\nfrom typing_extensions import ParamSpec, Self\n\nfrom simple_sqlite3_orm._orm._utils import parameterized_class_getitem\nfrom simple_sqlite3_orm._sqlite_spec import OR_OPTIONS\nfrom simple_sqlite3_orm._table_spec import (\n    CreateIndexParams,\n    CreateTableParams,\n    TableSpec,\n    TableSpecType,\n)\nfrom simple_sqlite3_orm._typing import (\n    ColsDefinition,\n    ColsDefinitionWithDirection,\n    ConnectionFactoryType,\n    RowFactoryType,\n)\n\nDoNotChangeRowFactory = Literal[\"do_not_change\"]\nDO_NOT_CHANGE_ROW_FACTORY: DoNotChangeRowFactory = \"do_not_change\"\n\nRowFactorySpecifier = Union[\n    RowFactoryType,\n    Literal[\n        \"sqlite3_row_factory\",\n        \"table_spec\",\n        \"table_spec_no_validation\",\n    ],\n    DoNotChangeRowFactory,\n    None,\n]\n\"\"\"Specifiy which row_factory to use.\n\nFor each option:\n    1. RowFactoryType: specify arbitrary row_factory.\n    2. None: clear the connection scope row_factory(set to None).\n    3. \"sqlite3_row_factory\": set to use sqlite3.Row as row_factory.\n    4. \"table_spec\": use TableSpec.table_row_factory as row_factory.\n    5. \"table_spec_no_validation\": use TableSpec.table_row_factory as row_factory, but with validation=False.\n    6. \"do_not_change\": do not change the connection scope row_factory.\n\"\"\"\n\nclass ORMCommonBase(Generic[TableSpecType]):\n    orm_table_spec: type[TableSpecType]\n    orm_bootstrap_table_name: str\n    orm_bootstrap_create_table_params: str | CreateTableParams\n    orm_bootstrap_indexes_params: list[str | CreateIndexParams]\n    _orm_table_name: str\n\n\n    def __init_subclass__(cls, **kwargs) -> None:\n        pass\n\nclass ORMBase(ORMCommonBase[TableSpecType]):\n    \"\"\"ORM layer for <TableSpecType>.\n\n    NOTE that instance of ORMBase cannot be used in multi-threaded environment.\n        Use ORMThreadPoolBase for multi-threaded environment.\n        For asyncio, use AsyncORMThreadPoolBase.\n\n    The underlying connection can be used in multiple connection for accessing different table in\n        the connected database.\n\n    Attributes:\n        con (sqlite3.Connection | ConnectionFactoryType): The sqlite3 connection used by this ORM, or a factory\n            function that returns a sqlite3.Connection object on calling.\n        table_name (str): The name of the table in the database <con> connected to. This field will take prior over the\n            table_name specified by orm_bootstrap_table_name attr to allow using different table_name for just one connection.\n        schema_name (str): The schema of the table if multiple databases are attached to <con>.\n        row_factory (RowFactorySpecifier): The connection scope row_factory to use. Default to \"table_sepc\".\n    \"\"\"\n\n    def __init__(\n        self,\n        con: sqlite3.Connection | ConnectionFactoryType,\n        table_name: str | None = None,\n        schema_name: str | Literal[\"temp\"] | None = None,\n        *,\n        row_factory: RowFactorySpecifier = \"table_spec\",\n    ) -> None:\n        pass\n\n    __class_getitem__ = classmethod(parameterized_class_getitem)\n\n    def orm_bootstrap_db(self) -> None:\n        \"\"\"Bootstrap the database this ORM connected to.\n\n        This method will refer to the following attrs to setup table and indexes:\n        1. orm_bootstrap_table_name: the name of table to be created.\n        2. orm_bootstrap_create_table_params: the sqlite query to create the table,\n            it can be provided as sqlite query, or CreateTableParams for table_create_stmt\n            to generate sqlite query from.\n            It not specified, the table create statement will be generated with default configs,\n            See table_spec.table_create_stmt method for more details.\n        3. orm_bootstrap_indexes_params: optional, a list of sqlite query or\n            CreateIndexParams(for table_create_index_stmt to generate sqlite query from) to\n            create indexes from.\n\n        NOTE that ORM will not know whether the connected database has already been\n            bootstrapped or not, this is up to caller to check.\n        \"\"\"\n        pass\n\n    @property\n    def orm_con(self) -> sqlite3.Connection:\n        \"\"\"A reference to the underlying sqlite3.Connection.\n\n        This is for directly executing sql stmts.\n        \"\"\"\n        pass\n\n    @cached_property\n    def orm_table_name(self) -> str:\n        \"\"\"The unique name of the table for use in sql statement.\n\n        If multiple databases are attached to <con> and <schema_name> is availabe,\n            return \"<schema_name>.<table_name>\", otherwise return <table_name>.\n        \"\"\"\n        pass\n\n    @property\n    def orm_conn_row_factory(self) -> RowFactoryType | None:\n        \"\"\"Get and set the connection scope row_factory for this ORM instance.\"\"\"\n        pass\n\n    @orm_conn_row_factory.setter\n    def orm_conn_row_factory(self, _row_factory: RowFactoryType | None) -> None:\n        pass\n\n    @overload\n    def orm_execute(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: Callable[[sqlite3.Cursor, Any], RT],\n    ) -> list[RT]: ...\n\n    @overload\n    def orm_execute(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: DoNotChangeRowFactory = DO_NOT_CHANGE_ROW_FACTORY,\n    ) -> list[TableSpecType]: ...\n\n    @overload\n    def orm_execute(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: None,\n    ) -> list[tuple[Any, ...]]: ...\n\n    def orm_execute(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: RowFactorySpecifier\n        | DoNotChangeRowFactory = DO_NOT_CHANGE_ROW_FACTORY,\n    ) -> list[Any]:\n        \"\"\"Execute one sql statement and get the all the result.\n\n        NOTE that caller needs to serialize the `params` before hands if needed, `orm_execute` will\n            not do any processing over the input `params`, and just use as it for execution.\n        The result will be fetched with fetchall API and returned as it.\n\n        Args:\n            sql_stmt (str): The sqlite statement to be executed.\n            params (tuple[Any, ...] | dict[str, Any] | None, optional): The parameters to be bound\n                to the sql statement execution. Defaults to None, not passing any params.\n            row_factory (RowFactorySpecifier | DoNotChangeRowFactory, optional): specify to use\n                different row_factory for the query. Default to not change the current row_factory.\n                NOTE that None value here means unset the row_factory for this query.\n\n        Returns:\n            list[Any]: A list contains all the result entries.\n        \"\"\"\n        pass\n\n    @overload\n    def orm_execute_gen(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: Callable[[sqlite3.Cursor, Any], RT],\n    ) -> Generator[RT]: ...\n\n    @overload\n    def orm_execute_gen(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: DoNotChangeRowFactory = DO_NOT_CHANGE_ROW_FACTORY,\n    ) -> Generator[TableSpecType]: ...\n\n    @overload\n    def orm_execute_gen(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: None,\n    ) -> Generator[tuple[Any, ...]]: ...\n\n    def orm_execute_gen(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: RowFactorySpecifier\n        | DoNotChangeRowFactory = DO_NOT_CHANGE_ROW_FACTORY,\n    ) -> Generator[Any]:\n        \"\"\"The same as orm_execute, but as a Generator.\"\"\"\n        pass\n\n    def orm_create_table(\n        self,\n        *,\n        allow_existed: bool = False,\n        strict: bool = False,\n        without_rowid: bool = False,\n        _stmt: str | None = None,\n    ) -> None:\n        \"\"\"Create the table defined by this ORM with <orm_table_spec>.\n\n        NOTE: strict table option is supported after sqlite3 3.37.\n\n        Args:\n            allow_existed (bool, optional): Do not abort on table already created.\n                Set True equals to add \"IF NOT EXISTS\" in the sql statement. Defaults to False.\n            strict (bool, optional): Enable strict field type check. Defaults to False.\n                See https://www.sqlite.org/stricttables.html for more details.\n            without_rowid (bool, optional): Create the table without ROWID. Defaults to False.\n                See https://www.sqlite.org/withoutrowid.html for more details.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            sqlite3.DatabaseError on failed sql execution.\n        \"\"\"\n        pass\n\n    def orm_create_index(\n        self,\n        *,\n        index_name: str,\n        index_keys: ColsDefinition | ColsDefinitionWithDirection,\n        allow_existed: bool = False,\n        unique: bool = False,\n        _stmt: str | None = None,\n    ) -> None:\n        \"\"\"Create index according to the input arguments.\n\n        Args:\n            index_name (str): The name of the index.\n            index_keys (ColsDefinition | ColsDefinitionWithDirection): The columns for the index.\n            allow_existed (bool, optional): Not abort on index already created. Defaults to False.\n            unique (bool, optional): Not allow duplicated entries in the index. Defaults to False.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            sqlite3.DatabaseError on failed sql execution.\n        \"\"\"\n        pass\n\n    @overload\n    def orm_select_entries(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _row_factory: Callable[[sqlite3.Cursor, Any], RT],\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[RT]: ...\n\n    @overload\n    def orm_select_entries(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _row_factory: None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[TableSpecType | Any]: ...\n\n    def orm_select_entries(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _row_factory: RowFactoryType | None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[TableSpecType | Any]:\n        \"\"\"Select entries from the table accordingly.\n\n        Args:\n            col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n                the pairs in this mapping will take prior than the one specified in <col_values>.\n            _distinct (bool, optional): Deduplicate and only return unique entries. Defaults to False.\n            _order_by (ColsDefinition | ColsDefinitionWithDirection | None, optional):\n                Order the result accordingly. Defaults to None, not sorting the result.\n            _limit (int | None, optional): Limit the number of result entries. Defaults to None.\n            _row_factory (RowFactoryType | None, optional): Set to use different row factory for this query.\n                Defaults to None(do not change row_factory).\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n            **col_values: provide col/value pairs by kwargs. Col/value pairs in <col_values> have lower priority over\n                the one specified by <_col_vlues_dict>.\n\n        Raises:\n            sqlite3.DatabaseError on failed sql execution.\n\n        Yields:\n            Generator[TableSpecType | Any]: A generator that can be used to yield entry from result.\n        \"\"\"\n        pass\n\n    @overload\n    def orm_select_entry(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _row_factory: Callable[[sqlite3.Cursor, Any], RT],\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> RT: ...\n\n    @overload\n    def orm_select_entry(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _row_factory: None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> TableSpecType | Any: ...\n\n    def orm_select_entry(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _row_factory: RowFactoryType | None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> TableSpecType | Any | None:\n        \"\"\"Select exactly one entry from the table accordingly.\n\n        NOTE that if the select result contains more than one entry, this method will return\n            the FIRST one from the result with fetchone API.\n\n        Args:\n            col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n                the pairs in this mapping will take prior than the one specified in <col_values>.\n            _distinct (bool, optional): Deduplicate and only return unique entries. Defaults to False.\n            _order_by (ColsDefinition | ColsDefinitionWithDirection | None, optional):\n                Order the result accordingly. Defaults to None, not sorting the result.\n            _row_factory (RowFactoryType | None, optional): Set to use different row factory for this query.\n                Defaults to None(do not change row_factory).\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n            **col_values: provide col/value pairs by kwargs. Col/value pairs in <col_values> have lower priority over\n                the one specified by <_col_vlues_dict>.\n\n        Raises:\n            sqlite3.DatabaseError on failed sql execution.\n\n        Returns:\n            TableSpecType | Any: Exactly one entry, or None if not hit.\n        \"\"\"\n        pass\n\n    def orm_insert_entries(\n        self,\n        _in: Iterable[TableSpecType],\n        *,\n        or_option: OR_OPTIONS | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"Insert an iterable of rows represented as TableSpec insts into this table.\n\n        Args:\n            _in (Iterable[TableSpecType]): An iterable of rows as TableSpec insts to insert.\n            or_option (INSERT_OR | None, optional): The fallback operation if insert failed. Defaults to None.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            ValueError: On invalid types of _in.\n            sqlite3.DatabaseError: On failed sql execution.\n\n        Returns:\n            int: Number of inserted entries.\n        \"\"\"\n        pass\n\n    def orm_insert_mappings(\n        self,\n        _in: Iterable[Mapping[str, Any]],\n        *,\n        or_option: OR_OPTIONS | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"Insert an iterable of rows represented as mappings into this table.\n\n        Each mapping stores cols with values in application types. Assuming that all entries in\n            this Iterable contains mapping with the same schema.\n\n        Args:\n            _in (Iterable[Mapping[str, Any]]): An iterable of mappings to insert.\n            or_option (INSERT_OR | None, optional): The fallback operation if insert failed. Defaults to None.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            ValueError: On invalid types of _in.\n            sqlite3.DatabaseError: On failed sql execution.\n\n        Returns:\n            int: Number of inserted entries.\n        \"\"\"\n        pass\n\n    def orm_insert_entry(\n        self,\n        _in: TableSpecType,\n        *,\n        or_option: OR_OPTIONS | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"Insert exactly one entry into this table.\n\n        Args:\n            _in (TableSpecType): The instance of entry to insert.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            ValueError: On invalid types of _in.\n            sqlite3.DatabaseError: On failed sql execution.\n\n        Returns:\n            int: Number of inserted entries. In normal case it should be 1.\n        \"\"\"\n        pass\n\n    def orm_insert_mapping(\n        self,\n        _in: Mapping[str, Any],\n        *,\n        or_option: OR_OPTIONS | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"Insert exactly one entry(represented as a mapping) into this table.\n\n        Args:\n            _in (TableSpecType): The instance of entry to insert.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            ValueError: On invalid types of _in.\n            sqlite3.DatabaseError: On failed sql execution.\n\n        Returns:\n            int: Number of inserted entries. In normal case it should be 1.\n        \"\"\"\n        pass\n\n    def orm_update_entries(\n        self,\n        *,\n        set_values: Mapping[str, Any] | TableSpec,\n        where_cols_value: Mapping[str, Any] | None = None,\n        where_stmt: str | None = None,\n        or_option: OR_OPTIONS | None = None,\n        _extra_params: Mapping[str, Any] | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"UPDATE specific entries by matching <where_cols_value>.\n\n        NOTE: if you want to using the same query stmt with different set of params(set col/values and/or where col/values),\n            it is highly recommended to use `orm_update_entries_many` API, it will be significantly faster to call `orm_update_entries`\n            in a for loop(in my test with 2000 entries, using `orm_update_entries_many` is around 300 times faster).\n        NOTE: currently UPDATE-WITH-LIMIT and RETURNING are not supported by this method.\n\n        Args:\n            set_values (Mapping[str, Any] | TableSpec): values to update.\n            where_cols_value (Mapping[str, Any], optional): cols to matching. This method will\n                also generate WHERE statement of matching each cols specified in this mapping.\n            where_stmt (str | None, optional): directly provide WHERE statement. If provided,\n                <where_cols_value> will only be used as params.\n            or_option (OR_OPTIONS | None, optional): specify the operation if UPDATE failed.\n            _extra_params (Mapping[str, Any] | None, optional): provide extra named params\n                for sqlite3 query execution. NOTE that `_extra_params` takes higher priority\n                to any named params specified by `where_cols_value` and `set_values`. Defaults to None.\n            _stmt (str | None, optional): directly provide the UPDATE query, if provided,\n                <where_cols_value>, <where_stmt> and <or_option> will be ignored.\n\n        Raises:\n            SQLite3 DB Errors on failed operations.\n\n        Returns:\n            Affected rows count.\n        \"\"\"\n        pass\n\n    @overload\n    def orm_update_entries_many(\n        self,\n        *,\n        set_cols: tuple[str, ...],\n        where_cols: tuple[str, ...] | None = None,\n        where_stmt: str | None = None,\n        set_cols_value: Iterable[Mapping[str, Any]],\n        where_cols_value: Iterable[Mapping[str, Any]] | None = None,\n        or_option: OR_OPTIONS | None = None,\n        _extra_params: Mapping[str, Any] | None = None,\n        _extra_params_iter: Iterable[Mapping[str, Any]] | None = None,\n        _stmt: None = None,\n    ) -> int: ...\n\n    @overload\n    def orm_update_entries_many(\n        self,\n        *,\n        set_cols: None = None,\n        where_cols: None = None,\n        where_stmt: None = None,\n        set_cols_value: None = None,\n        where_cols_value: None = None,\n        or_option: None = None,\n        _extra_params: Mapping[str, Any] | None = None,\n        _extra_params_iter: Iterable[Mapping[str, Any]] | None = None,\n        _stmt: str,\n    ) -> int: ...\n\n    def orm_update_entries_many(\n        self,\n        *,\n        set_cols: tuple[str, ...] | None = None,\n        where_cols: tuple[str, ...] | None = None,\n        where_stmt: str | None = None,\n        set_cols_value: Iterable[Mapping[str, Any]] | None = None,\n        where_cols_value: Iterable[Mapping[str, Any]] | None = None,\n        or_option: OR_OPTIONS | None = None,\n        _extra_params: Mapping[str, Any] | None = None,\n        _extra_params_iter: Iterable[Mapping[str, Any]] | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"executemany version of orm_update_entries.\n\n        Params like `set_cols_value` and `where_cols_value` need to be provided as iterables.\n        NOTE that the execution will end and return when any of the input iterable exhausted.\n\n        NOTE that `_extra_params` and `_extra_params_iter` will not be serialized. Caller needs to\n            provide the serialized mappings ready for `executemany`.\n\n        Args:\n            set_cols (tuple[str, ...]): Cols to be updated.\n            set_cols_value (Iterable[Mapping[str, Any]]): An iterable of values of to-be-updated cols.\n            where_cols (tuple[str, ...] | None, optional): Cols to match. The WHERE stmt will be generated\n                based on this param. Defaults to None.\n            where_cols_value (Iterable[Mapping[str, Any]] | None, optional): An iterable of values of cols to match.\n                Defaults to None.\n            where_stmt (str | None, optional): Directly provide the WHERE stmt. If specified, both `where_cols` and\n                `where_cols_value` will be ignored. Caller needs to feed the params with `_extra_params` or `_extra_params_iter`.\n                Defaults to None.\n            or_option (OR_OPTIONS | None, optional): specify the operation if UPDATE failed. Defaults to None.\n            _extra_params (Mapping[str, Any] | None, optional): A fixed mapping to be injected for each execution.\n                NOTE that this param is only allowed when at least one of `where_cols_value`, `set_cols_value` or `_extra_params_iter` is specified.\n                Defaults to None.\n            _extra_params_iter (Iterable[Mapping[str, Any]] | None, optional): An iterable of mappings to be injected for each execution. Defaults to None.\n            _stmt (str | None, optional): Directly provide the UPDATE query, if specified, params except `_extra_params` and `_extra_params_iter`\n                will be ignored. Defaults to None.\n\n        Raises:\n            ValueError: If `where_cols_value` and `where_cols` are not be both None or both specifed.\n            ValueError: If `_stmt` is not used and `set_cols` and/or `set_cols_value` are not specified.\n            ValueError: If `_extra_params` is specified without any other iterable params provided.\n            sqlite3 DB error on execution failed.\n\n        Returns:\n            Affected rows count.\n        \"\"\"\n        pass\n\n    def orm_delete_entries(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> int:\n        \"\"\"Delete entries from the table accordingly.\n\n        Args:\n            col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n                the pairs in this mapping will take prior than the one specified in <col_values>.\n            _order_by (ColsDefinition | ColsDefinitionWithDirection | None, optional): Order the matching entries\n                before executing the deletion, used together with <_limit>. Defaults to None.\n            _limit (int | None, optional): Only delete <_limit> number of entries. Defaults to None.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n            **col_values: provide col/value pairs by kwargs. Col/value pairs in <col_values> have lower priority over\n                the one specified by <_col_vlues_dict>.\n\n        Returns:\n            int: The num of entries deleted.\n        \"\"\"\n        pass\n\n    @overload\n    def orm_delete_entries_with_returning(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _returning_cols: ColsDefinition | Literal[\"*\"],\n        _row_factory: Callable[[sqlite3.Cursor, Any], RT],\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[RT]: ...\n\n    @overload\n    def orm_delete_entries_with_returning(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _returning_cols: ColsDefinition | Literal[\"*\"],\n        _row_factory: None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[TableSpecType | Any]: ...\n\n    def orm_delete_entries_with_returning(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _returning_cols: ColsDefinition | Literal[\"*\"],\n        _row_factory: RowFactoryType | None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[TableSpecType | Any]:\n        \"\"\"Delete entries from the table accordingly.\n\n        NOTE that only sqlite3 version >= 3.35 supports returning statement.\n\n        Args:\n            col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n                the pairs in this mapping will take prior than the one specified in <col_values>.\n            _order_by (ColsDefinition | ColsDefinitionWithDirection | None, optional): Order the matching entries\n                before executing the deletion, used together with <_limit>. Defaults to None.\n            _limit (int | None, optional): Only delete <_limit> number of entries. Defaults to None.\n            _returning_cols (ColsDefinition | Literal[\"*\"] ): Return the deleted entries on execution.\n            _row_factory (RowFactoryType | None, optional): Set to use different row factory for this query.\n                Defaults to None(do not change row_factory).\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n            **col_values: provide col/value pairs by kwargs. Col/value pairs in <col_values> have lower priority over\n                the one specified by <_col_vlues_dict>.\n\n        Returns:\n            Generator[TableSpecType | Any]: If <_returning_cols> is defined, returns a generator which can\n                be used to yield the deleted entries from.\n        \"\"\"\n        pass\n\n    def orm_select_all_with_pagination(\n        self, *, batch_size: int\n    ) -> Generator[TableSpecType | Any]:\n        \"\"\"Select all entries from the table accordingly with pagination.\n\n        This is implemented by seek with rowid, so it will not work on without_rowid table.\n\n        Args:\n            batch_size (int): The entry number for each page.\n\n        Raises:\n            ValueError on invalid batch_size.\n            sqlite3.DatabaseError on failed sql execution.\n\n        Yields:\n            Generator[TableSpecType, None, None]: A generator that can be used to yield entry from result.\n        \"\"\"\n        pass\n\n    def orm_check_entry_exist(\n        self, col_value_pairs: Mapping[str, Any] | None = None, **col_values: Any\n    ) -> bool:\n        \"\"\"A quick method to check whether entry(entries) indicated by cols exists.\n\n        This method uses COUNT function to count the selected entry.\n\n        Args:\n            col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n                the pairs in this mapping will take prior than the one specified in <col_values>.\n            **cols: cols pair to locate the entry(entries).\n\n        Returns:\n            Returns True if at least one entry matches the input cols exists, otherwise False.\n        \"\"\"\n        pass\n```\n--- File: src/simple_sqlite3_orm/_orm/_pool.py ---\n```python\nfrom __future__ import annotations\n\nimport asyncio\nimport atexit\nimport contextlib\nimport queue\nimport threading\nfrom collections.abc import Callable, Generator\nfrom concurrent.futures import ThreadPoolExecutor\nfrom functools import cached_property, partial\nfrom typing import TYPE_CHECKING, AsyncGenerator, TypeVar\nfrom weakref import WeakSet\n\nfrom typing_extensions import Concatenate, ParamSpec, Self\n\nfrom simple_sqlite3_orm._orm._base import ORMBase, ORMCommonBase, RowFactorySpecifier\nfrom simple_sqlite3_orm._orm._utils import parameterized_class_getitem\nfrom simple_sqlite3_orm._table_spec import TableSpecType\nfrom simple_sqlite3_orm._typing import ConnectionFactoryType\n\nP = ParamSpec(\"P\")\nRT = TypeVar(\"RT\")\n\ndef _wrap_generator_with_thread_ctx(\n    func: Callable[Concatenate[ORMBase, P], Generator[RT]],\n):\n    pass\n\ndef _wrap_generator_with_async_ctx(\n    func: Callable[Concatenate[ORMBase, P], Generator[RT]],\n):\n    pass\n\nclass ORMThreadPoolBase(ORMCommonBase[TableSpecType]):\n    \"\"\"\n    See https://www.sqlite.org/wal.html#concurrency for more details.\n\n    For the row_factory arg, please see ORMBase.__init__ for more details.\n    \"\"\"\n\n    def __init__(\n        self,\n        table_name: str | None = None,\n        schema_name: str | None = None,\n        *,\n        con_factory: ConnectionFactoryType,\n        number_of_cons: int,\n        thread_name_prefix: str = \"\",\n        row_factory: RowFactorySpecifier = \"table_spec\",\n    ) -> None:\n        pass\n\n    __class_getitem__ = classmethod(parameterized_class_getitem)\n\n    @cached_property\n    def orm_table_name(self) -> str:\n        \"\"\"The unique name of the table for use in sql statement.\n\n        If multiple databases are attached to <con> and <schema_name> is availabe,\n            return \"<schema_name>.<table_name>\", otherwise return <table_name>.\n        \"\"\"\n        pass\n\n    def orm_pool_shutdown(self, *, wait=True, close_connections=True) -> None:\n        \"\"\"Shutdown the ORM connections thread pool.\n\n        It is safe to call this method multiple time.\n        This method is NOT thread-safe, and should be called at the main thread,\n            or the thread that creates this thread pool.\n\n        Args:\n            wait (bool, optional): Wait for threads join. Defaults to True.\n            close_connections (bool, optional): Close all the connections. Defaults to True.\n        \"\"\"\n        pass\n\n    def orm_create_table(self, *args: P.args, **kwargs: P.kwargs) -> RT: # Wrapped ORMBase.orm_create_table\n        pass\n\n    def orm_execute(self, *args: P.args, **kwargs: P.kwargs) -> RT: # Wrapped ORMBase.orm_execute\n        pass\n\n    def orm_insert_entries(self, *args: P.args, **kwargs: P.kwargs) -> RT: # Wrapped ORMBase.orm_insert_entries\n        pass\n\n    def orm_create_index(self, *args: P.args, **kwargs: P.kwargs) -> RT: # Wrapped ORMBase.orm_create_index\n        pass\n\n    def orm_select_entries(self, *args: P.args, **kwargs: P.kwargs) -> Generator[RT]: # Wrapped ORMBase.orm_select_entries\n        pass\n\n    def orm_delete_entries(self, *args: P.args, **kwargs: P.kwargs) -> RT: # Wrapped ORMBase.orm_delete_entries\n        pass\n\n    def orm_delete_entries_with_returning(self, *args: P.args, **kwargs: P.kwargs) -> Generator[RT]: # Wrapped ORMBase.orm_delete_entries_with_returning\n        pass\n\nclass AsyncORMBase(ORMThreadPoolBase[TableSpecType]):\n    \"\"\"\n    NOTE: the supoprt for async ORM is experimental! The APIs might be changed a lot\n        in the following releases.\n\n    For the row_factory arg, please see ORMBase.__init__ for more details.\n    \"\"\"\n\n    _loop: asyncio.AbstractEventLoop\n    \"\"\"Bound event loop when instanitiate this pool.\"\"\"\n\n    if not TYPE_CHECKING:\n        def __init__(self, *args, **kwargs) -> None:\n            pass\n\n    async def orm_create_table(self, *args: P.args, **kwargs: P.kwargs) -> RT: # Wrapped ORMBase.orm_create_table\n        pass\n\n    async def orm_execute(self, *args: P.args, **kwargs: P.kwargs) -> RT: # Wrapped ORMBase.orm_execute\n        pass\n\n    async def orm_insert_entries(self, *args: P.args, **kwargs: P.kwargs) -> RT: # Wrapped ORMBase.orm_insert_entries\n        pass\n\n    async def orm_create_index(self, *args: P.args, **kwargs: P.kwargs) -> RT: # Wrapped ORMBase.orm_create_index\n        pass\n\n    async def orm_select_entries(self, *args: P.args, **kwargs: P.kwargs) -> AsyncGenerator[RT, None]: # Wrapped ORMBase.orm_select_entries\n        pass\n\n    async def orm_delete_entries(self, *args: P.args, **kwargs: P.kwargs) -> RT: # Wrapped ORMBase.orm_delete_entries\n        pass\n\n    async def orm_delete_entries_with_returning(self, *args: P.args, **kwargs: P.kwargs) -> AsyncGenerator[RT, None]: # Wrapped ORMBase.orm_delete_entries_with_returning\n        pass\n```\n--- File: src/simple_sqlite3_orm/_orm/_utils.py ---\n```python\nfrom __future__ import annotations\n\nfrom typing import Any\nfrom weakref import WeakValueDictionary\n\nfrom simple_sqlite3_orm._table_spec import TableSpec, TableSpecType\nfrom simple_sqlite3_orm._utils import GenericAlias\n\ndef parameterized_class_getitem(\n    cls, params: Any | type[Any] | type[TableSpecType] | tuple[type[Any], ...]\n) -> Any:\n    pass\n```",
        "minimal_code_skeleton_structured": [
            {
                "file_path": "src/simple_sqlite3_orm/_types.py",
                "code": "from __future__ import annotations\n\nimport datetime\nfrom typing import Any\n\nfrom pydantic import BeforeValidator, PlainSerializer\nfrom typing_extensions import Annotated\n\nDatetimeUnixTimestamp = Annotated[\n    datetime.datetime,\n    BeforeValidator(_datetime_validator),\n    PlainSerializer(lambda x: x.timestamp(), return_type=float),\n]\n\"\"\"datetime.datetime as unixtimestamp in seconds serialized as a float in db.\"\"\"\n\nDatetimeUnixTimestampInt = Annotated[\n    datetime.datetime,\n    BeforeValidator(_datetime_validator),\n    PlainSerializer(lambda x: int(x.timestamp()), return_type=int),\n]\n\"\"\"datetime.datetime as unixtimestamp in seconds serialized as an int in db.\"\"\"\n\nDatetimeISO8601 = Annotated[\n    datetime.datetime,\n    BeforeValidator(_datetime_validator),\n    PlainSerializer(lambda x: x.isoformat(), return_type=str),\n]\n\"\"\"datetime.datetime as str(ISO8601 formatted) serialized as a string in db.\"\"\"\n"
            },
            {
                "file_path": "src/simple_sqlite3_orm/_sqlite_spec.py",
                "code": "from __future__ import annotations\n\nfrom enum import Enum\nfrom typing import Literal, Union\n\nclass SQLiteTypeAffinity(str, Enum):\n    TEXT = \"TEXT\"\n    NUMERIC = \"NUMERIC\"\n    INTEGER = \"INTEGER\"\n    REAL = \"REAL\"\n    BLOB = \"BLOB\"\n    NULL = \"NULL\"\n"
            },
            {
                "file_path": "src/simple_sqlite3_orm/_table_spec.py",
                "code": "from __future__ import annotations\n\nimport sqlite3\nfrom collections.abc import Mapping\nfrom types import MappingProxyType\nfrom typing import Any, ClassVar, Generator, Iterable, Literal, TypedDict, TypeVar\n\nfrom pydantic import BaseModel\nfrom pydantic.fields import FieldInfo\nfrom typing_extensions import NotRequired, Self\n\nfrom simple_sqlite3_orm._sqlite_spec import (\n    OR_OPTIONS,\n    ORDER_DIRECTION,\n    SQLiteBuiltInFuncs,\n)\n\nclass CreateTableParams(TypedDict, total=False):\n    if_not_exists: bool\n    strict: bool\n    temporary: bool\n    without_rowid: bool\n\nclass CreateIndexParams(TypedDict):\n    index_name: str\n    index_cols: tuple[str | tuple[str, ORDER_DIRECTION], ...]\n    if_not_exists: NotRequired[bool]\n    unique: NotRequired[bool]\n\nclass TableSpec(BaseModel):\n    \"\"\"Define table as pydantic model, with specific APIs.\"\"\"\n\n    table_columns: ClassVar[MappingProxyType[str, FieldInfo]]\n    \"\"\"A view of TableSpec's model_fields.\"\"\"\n\n    table_columns_by_index: ClassVar[tuple[str, ...]]\n    \"\"\"Ordered tuple of column names, matching exactly with table schema.\"\"\"\n\n    _table_update_where_cols_prefix: ClassVar[Literal[\"__table_spec_\"]] = (\n        \"__table_spec_\"\n    )\n\n    @classmethod\n    def __pydantic_init_subclass__(cls, **_) -> None:\n        pass\n\n    @classmethod\n    def table_create_stmt(\n        cls,\n        table_name: str,\n        *,\n        if_not_exists: bool = False,\n        strict: bool = False,\n        temporary: bool = False,\n        without_rowid: bool = False,\n    ) -> str:\n        \"\"\"Get create table statement with this table spec class.\n\n        Check https://www.sqlite.org/lang_createtable.html for more details.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_create_index_stmt(\n        cls,\n        *,\n        table_name: str,\n        index_name: str,\n        index_cols: tuple[str | tuple[str, ORDER_DIRECTION], ...],\n        if_not_exists: bool = False,\n        unique: bool = False,\n    ) -> str:\n        \"\"\"Get index create statement with this table spec class.\n\n        Raises:\n            ValueError on <index_cols> not specified, or invalid <index_cols>.\n\n        Check https://www.sqlite.org/lang_createindex.html for more details.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_row_factory(\n        cls,\n        _cursor: sqlite3.Cursor,\n        _row: tuple[Any, ...] | Any,\n        *,\n        validation: bool = True,\n    ) -> Self | tuple[Any, ...]:\n        \"\"\"A general row_factory implement for used in sqlite3 connection.\n\n        When the input <_row> is not a row but something like function output,\n            this method will return the raw input tuple as it.\n\n        Args:\n            validation (bool): whether enable pydantic validation when importing row. Default to True.\n\n        Raises:\n            Any exception raised from pydantic model_validate or model_construct.\n\n        Returns:\n            An instance of <TableSpec>, or the raw tuple if the input row has different schema.\n\n        Also see https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.description\n            for more details.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_row_factory2(\n        cls,\n        _cursor: sqlite3.Cursor,\n        _row: tuple[Any, ...] | Any,\n        *,\n        validation: bool = True,\n    ) -> Self:\n        \"\"\"Another version of row_factory implementation for specific use case.\n\n        Unlike table_row_factory that checks the cols definition and ensure all cols\n            are valid and presented in table def, table_row_factory2 just picks the valid\n            cols from the input raw table row, and ignore unknown col/value pairs.\n\n        Args:\n            validation (bool): whether enable pydantic validation when importing row. Default to True.\n\n        Raises:\n            Any exception raised from pydantic model_validate or model_construct.\n\n        Returns:\n            An instance of <TableSpec>.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_from_tuple(\n        cls, _row: Iterable[Any], *, with_validation: bool = True, **kwargs\n    ) -> Self:\n        \"\"\"A raw row_factory that converts the input _row to TableSpec instance.\n\n        NOTE that this method expects the input row match the table row spec EXACTLY.\n\n        Args:\n            _row (tuple[Any, ...]): the raw table row as tuple.\n            with_validation (bool): if set to False, will use pydantic model_construct to directly\n                construct instance without validation. Default to True.\n            **kwargs: extra kwargs passed to pydantic model_validate API. Note that only when\n                with_validation is True, the kwargs will be used.\n\n        Returns:\n            An instance of self.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_from_dict(\n        cls, _map: Mapping[str, Any], *, with_validation: bool = True, **kwargs\n    ) -> Self:\n        \"\"\"A raw row_factory that converts the input mapping to TableSpec instance.\n\n        Args:\n            _map (Mapping[str, Any]): the raw table row as a dict.\n            with_validation (bool, optional): if set to False, will use pydantic model_construct to directly\n                construct instance without validation. Default to True.\n            **kwargs: extra kwargs passed to pydantic model_validate API. Note that only when\n                with_validation is True, the kwargs will be used.\n\n        Returns:\n            An instance of self.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_insert_stmt(\n        cls,\n        *,\n        insert_into: str,\n        insert_cols: tuple[str, ...] | None = None,\n        insert_default: bool = False,\n        or_option: OR_OPTIONS | None = None,\n        returning_cols: tuple[str, ...] | Literal[\"*\"] | None = None,\n        returning_stmt: str | None = None,\n    ) -> str:\n        \"\"\"Get sql for inserting row(s) into <table_name>.\n\n        Check https://www.sqlite.org/lang_insert.html for more details.\n\n        Args:\n            insert_into (str): The name of table insert into.\n            insert_cols (tuple[str, ...] | None, optional): The cols to be assigned for entry to be inserted.\n                Defaults to None, means we will assign all cols of the row.\n            insert_default (bool, optional): No values will be assigned, all cols will be assigned with\n                default value, this precedes the <insert_cols> param. Defaults to False.\n            or_option (INSERT_OR | None, optional): The fallback operation if insert failed. Defaults to None.\n            returning_cols (tuple[str, ...] | Literal[\"*\"] | None): Which cols are included in the returned entries.\n                Defaults to None.\n            returning_stmt (str | None, optional): The full returning statement string, this\n                precedes the <returning_cols> param. Defaults to None.\n\n        Returns:\n            str: The generated insert statement.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_update_stmt(\n        cls,\n        *,\n        or_option: OR_OPTIONS | None = None,\n        update_target: str,\n        set_cols: tuple[str, ...],\n        where_cols: tuple[str, ...] | None = None,\n        where_stmt: str | None = None,\n        returning_cols: tuple[str, ...] | Literal[\"*\"] | None = None,\n        returning_stmt: str | None = None,\n        order_by: tuple[str | tuple[str, ORDER_DIRECTION], ...] | None = None,\n        order_by_stmt: str | None = None,\n        limit: int | None = None,\n    ) -> str:\n        \"\"\"Get sql query for updating row(s) at <table_name>.\n\n        Check https://www.sqlite.org/lang_update.html for more details.\n\n        NOTE: to avoid overlapping between <set_cols> and <where_cols> when generating named-placeholders,\n            this method will prefix cols name with <_table_spec_update_where_cols_prefix> when generating\n            WHERE statement.\n            To directly use the stmt generated from this API, dev must use table_preprare_update_where_cols\n            to prepare the col/value mapping for params.\n\n        NOTE that UPDATE-FROM extension is currently not supported by this method.\n        NOTE that UPDATE-WITH-LIMIT is an optional feature, needs to be enabled at compiled time with\n            SQLITE_ENABLE_UPDATE_DELETE_LIMIT.\n\n        Args:\n            or_option (INSERT_OR | None, optional): The fallback operation if update failed. Defaults to None.\n            update_target (str): The name of table to update.\n            set_cols (tuple[str, ...]): The cols to be updated.\n            where_cols (tuple[str, ...] | None, optional): A list of cols to be compared in where\n                statement. Defaults to None.\n            where_stmt (str | None, optional): The full where statement string, this\n                precedes the <where_cols> param if set. Defaults to None.\n            returning_cols (tuple[str, ...] | Literal[\"*\"] | None): If specified, enable RETURNING stmt, and specifying Which cols\n                included in the returned entries. Defaults to None.\n            returning_stmt (str | None, optional): The full returning statement string, this\n                precedes the <returning_cols> param. Defaults to None.\n            order_by (Iterable[str  |  tuple[str, ORDER_DIRECTION], ...] | None, optional):\n                Works with LIMIT, to specify the range that LIMIT affects. Defaults to None.\n            order_by_stmt (str | None, optional): The order_by statement string, this\n                precedes the <order_by> param if set. Defaults to None.\n            limit (int | None, optional): Limit the number of affected entries. Defaults to None.\n\n        Returns:\n            str: The generated update sqlite3 query.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_preprare_update_where_cols(\n        cls, where_cols: Mapping[str, Any]\n    ) -> Mapping[str, Any]:\n        \"\"\"Regulate the named-placeholder <where_cols> so that it will not overlap with <set_cols>.\n\n        This is MUST for directly using the sqlite query stmt generated from table_update_stmt.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_select_stmt(\n        cls,\n        *,\n        select_from: str,\n        select_cols: tuple[str, ...] | Literal[\"*\"] | str = \"*\",\n        function: SQLiteBuiltInFuncs | None = None,\n        where_stmt: str | None = None,\n        where_cols: tuple[str, ...] | None = None,\n        group_by: tuple[str, ...] | None = None,\n        order_by: tuple[str | tuple[str, ORDER_DIRECTION], ...] | None = None,\n        order_by_stmt: str | None = None,\n        limit: int | None = None,\n        distinct: bool = False,\n    ) -> str:\n        \"\"\"Get sql for getting row(s) from <table_name>, optionally with\n            where condition specified by <col_values>.\n\n        Check https://www.sqlite.org/lang_select.html for more details.\n\n        Args:\n            select_from (str): The table name for the generated statement.\n            select_cols (tuple[str, ...] | Literal[\"*\"] | str, optional): A list of cols included in the result row. Defaults to \"*\".\n            function (SQLiteBuiltInFuncs | None, optional): The sqlite3 function used in the selection. Defaults to None.\n            where_cols (tuple[str, ...] | None, optional): A list of cols to be compared in where\n                statement. Defaults to None.\n            where_stmt (str | None, optional): The full where statement string, this\n                precedes the <where_cols> param if set. Defaults to None.\n            group_by (tuple[str, ...] | None, optional): A list of cols for group_by statement. Defaults to None.\n            order_by (Iterable[str  |  tuple[str, ORDER_DIRECTION], ...] | None, optional):\n                A list of cols for ordering result. Defaults to None.\n            order_by_stmt (str | None, optional): The order_by statement string, this\n                precedes the <order_by> param if set. Defaults to None.\n            limit (int | None, optional): Limit the number of result entries. Defaults to None.\n            distinct (bool, optional): Whether filters the duplicated entries. Defaults to False.\n\n        Returns:\n            str: The generated select statement.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_delete_stmt(\n        cls,\n        *,\n        delete_from: str,\n        where_cols: tuple[str, ...] | None = None,\n        where_stmt: str | None = None,\n        order_by: tuple[str | tuple[str, ORDER_DIRECTION], ...] | None = None,\n        order_by_stmt: str | None = None,\n        limit: int | str | None = None,\n        returning_cols: tuple[str, ...] | Literal[\"*\"] | None = None,\n        returning_stmt: str | None = None,\n    ) -> str:\n        \"\"\"Get sql for deleting row(s) from <table_name> with specifying col value(s).\n\n        Check https://www.sqlite.org/lang_delete.html for more details.\n\n        NOTE(20240311): DELETE operation without any condition(no WHERE statement) in\n            WITHOUT_ROWID table will result in rowcount=0, see\n            https://sqlite.org/forum/forumpost/07dedbf9a1 for more details.\n            For python, python version < 3.10 will be affected by this bug.\n            A quick workaround is to add any condition in where statement, even a dummy\n            \"WHERE 1=1\" can resolve the above bug.\n            I will not add this hack here, and user can add this hack according to their needs.\n\n        NOTE: <order_by> and <limit> support are only enabled when runtime sqlite3 lib is compiled with\n            SQLITE_ENABLE_UPDATE_DELETE_LIMIT flag.\n\n        Args:\n            delete_from (str): The table name for the generated statement.\n            limit (int | str | None, optional): The value for limit expr. Defaults to None.\n            order_by (Iterable[str  |  tuple[str, ORDER_DIRECTION]] | None, optional):\n                A list of cols for ordering result. Defaults to None.\n            order_by_stmt (str | None, optional): The order_by statement string, this\n                precedes the <order_by> param if set. Defaults to None.\n            where_cols (tuple[str, ...] | None, optional): A list of cols to be compared in where\n                statement. Defaults to None.\n            where_stmt (str | None, optional): The full where statement string, this\n                precedes the <where_cols> param if set. Defaults to None.\n            returning_cols (tuple[str, ...] | Literal[\"*\"] | None): Which cols are included in the returned entries.\n                Defaults to None.\n            returning_stmt (str | None, optional): The full returning statement string, this\n                precedes the <returning_cols> param. Defaults to None.\n\n        Returns:\n            str: The generated delete statement.\n        \"\"\"\n        pass\n\n    def table_dump_asdict(self, *cols: str, **kwargs) -> dict[str, Any]:\n        \"\"\"Serialize self as a dict, containing all cols or specified cols, for DB operations.\n\n        Under the hook this method calls pydantic model_dump on self.\n        The dumped dict can be used to directly insert into the table.\n\n        Args:\n            *cols: which cols to export, if not specified, export all cols.\n            **kwargs: any other kwargs that passed to pydantic model_dump method.\n                Note that the include kwarg is used to specific which cols to dump.\n\n        Raises:\n            ValueError if failed to serialize the model, wrapping underlying\n                pydantic serialization error.\n\n        Returns:\n            A dict of dumped col values from this row.\n        \"\"\"\n        pass\n\n    def table_asdict(self, *cols: str) -> dict[str, Any]:\n        \"\"\"Directly export the self as a dict, without serializing.\n\n        Args:\n            *cols: which cols to export, if not specified, export all cols.\n            exclude_unset (bool, optional): whether include not set field of self.\n                Defaults to False, include unset fields(which will return their default values).\n\n        Returns:\n            A dict of col/values from self.\n        \"\"\"\n        pass\n\n    def table_dump_astuple(self, *cols: str, **kwargs) -> tuple[Any, ...]:\n        \"\"\"Serialize self's value as a tuple, containing all cols or specified cols, for DB operations.\n\n        This method is basically the same as table_dump_asdict, but instead return a\n            tuple of the dumped values.\n\n        Args:\n            *cols: which cols to export, if not specified, export all cols.\n            **kwargs: any other kwargs that passed to pydantic model_dump method.\n                Note that the include kwarg is used to specific which cols to dump.\n\n        Returns:\n            A tuple of dumped col values.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_serialize_mapping(cls, _in: Mapping[str, Any]) -> dict[str, Any]:\n        \"\"\"Serialize input mapping into a dict by this TableSpec, ready for DB operations.\n\n        Values in the input mapping are python types used in application.\n\n        This is a convenient method for when we only need to specify some of the cols, so that\n            we cannot use TableSpec as TableSpec requires all cols to be set.\n\n        NOTE that for APIs provided by simple_sqlite3_orm, when col/value pairs are provided as mapping,\n            the serialization will be done by the APIs, no need to call this method when using ORM.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_deserialize_asdict_row_factory(\n        cls,\n        _cursor: sqlite3.Cursor,\n        _row: tuple[Any, ...] | Any,\n        *,\n        allow_unknown_cols: bool = True,\n    ) -> dict[str, Any]:\n        \"\"\"Deserialize raw row from a query into a dict by this TableSpec, ready for application use.\n\n        This is a convenient method when we execute query that only select some cols.\n        For this use case, use thid method as row_factory to deserialize the raw row. This method\n            will deserialize the row from raw into actual field types defined in this TableSpec.\n\n        NOTE that if `allow_unknow_cols` is True, any unknown field(including cols aliased with other name)\n            will be preserved AS IT without deserializing as this method cannot know which col the alias name maps to.\n\n        Args:\n            allow_unknown_cols (bool, optional): If True, unknown cols will be preserved AS IT into the result.\n                Defaults to True.\n\n        Raises:\n            ValueError if `allow_unknown_cols` is False and unknown cols presented, or pydantic validation failed.\n\n        Returns:\n            A dict of deserialized(except unknown cols) col/value pairs.\n        \"\"\"\n        pass\n\n    @classmethod\n    def table_deserialize_astuple_row_factory(\n        cls, _cursor: sqlite3.Cursor, _row: tuple[Any, ...] | Any\n    ) -> tuple[Any, ...]:\n        \"\"\"Deserialize raw row from a query into a tuple by this TableSpec, ready for application use.\n\n        This is a convenient method when we execute query that only select some cols.\n        For this use case, use thid method as row_factory to deserialize the raw row. This method\n            will deserialize the row from raw into actual field types defined in this TableSpec.\n\n        NOTE that any unknown field(including cols aliased with other name) will be preserved AS IT without\n            deserializing as this method cannot know which col the alias name maps to.\n\n        Raises:\n            ValueError if pydantic validation failed.\n\n        Returns:\n            A tuple of deserialized row as tuple.\n        \"\"\"\n        pass\n\nTableSpecType = TypeVar(\"TableSpecType\", bound=TableSpec)\n"
            },
            {
                "file_path": "src/simple_sqlite3_orm/_utils.py",
                "code": "from __future__ import annotations\n\nimport sys\nfrom io import StringIO\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Callable,\n    Literal,\n    TypeVar,\n    Union,\n    get_args,\n    get_origin,\n)\n\nfrom typing_extensions import ParamSpec\n\nfrom simple_sqlite3_orm._sqlite_spec import (\n    ConstrainLiteral,\n    SQLiteTypeAffinity,\n    SQLiteTypeAffinityLiteral,\n)\n\nT = TypeVar(\"T\")\n\nclass TypeAffinityRepr:\n    \"\"\"Map python types to sqlite3 data types with type affinity.\n\n    Currently supports:\n    1. python sqlite3 lib supported native python types.\n    2. StrEnum and IntEnum, will map to TEXT and INT accordingly.\n    3. Optional types, will map against the args inside the Optional.\n    4. Literal types, will map against the values type inside the Literal.\n\n    Attrs:\n        type_affinity (SQLiteTypeAffinity | str)\n        origin (type[Any] | SQLiteTypeAffinityLiteral | Any)\n    \"\"\"\n    type_affinity: SQLiteTypeAffinity | str\n    origin: type[Any] | SQLiteTypeAffinityLiteral | Any\n\n    def __init__(self, _in: type[Any] | SQLiteTypeAffinityLiteral | Any) -> None:\n        pass\n\n    def __str__(self) -> str:\n        pass\n\nclass ConstrainRepr:\n    \"\"\"Helper class for composing full constrain statement string.\n\n    For example, for constrain statement like the following:\n        NOT NULL DEFAULT NULL CHECK (column IN (1, 2, 3))\n    can be represented ConstrainRepr as follow:\n        ConstrainRepr(\n            \"NOT NULL\",\n            (\"DEFAULT\", \"NULL\"),\n            (\"CHECK\", r\"(column IN (1, 2, 3))\")\n        )\n\n    Attrs:\n        constraints (set[str | tuple[str, str]]): a set of constrains.\n    \"\"\"\n    constraints: tuple[ConstrainLiteral | tuple[ConstrainLiteral, str] | Any, ...]\n\n    def __init__(\n        self, *params: ConstrainLiteral | tuple[ConstrainLiteral, str] | Any\n    ) -> None:\n        pass\n\n    def __str__(self) -> str:\n        pass\n\ndef gen_sql_stmt(*components: str, end_with: str | None = \";\") -> str:\n    \"\"\"Combine each components into a single sql stmt.\"\"\"\n    pass\n\nclass ColsSelectFactory(tuple[T, ...]):\n    \"\"\"A factory type to generate cols name checker.\n\n    Usage:\n\n    MyTableCols = Literal[\"entry_id\", \"entry_context\", \"entry_type\"]\n    MyTableColsChecker = ColsCheckerFactory[MyTableCols]\n\n    # now you can use `MyTableColsChecker` to specify a tuple of cols name as follow:\n    cols_to_select = MyTableColsChecker(\"unknown\", \"invalid_col\")  # type checker err\n    cols_to_select = MyTableColsChecker(\"entry_id\", \"entry_type\")  # valid\n\n    # at runtime, `cols_to_select` is a regular `tuple` object.\n\n    \"\"\"\n\n    def __new__(cls, *cols: T) -> tuple[T, ...]:\n        pass\n"
            },
            {
                "file_path": "src/simple_sqlite3_orm/utils.py",
                "code": "from __future__ import annotations\n\nimport logging\nimport os\nimport sqlite3\nimport sys\nfrom enum import Enum\nfrom io import StringIO\nfrom itertools import islice\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Generator,\n    Iterable,\n    Literal,\n    get_args,\n    get_origin,\n    overload,\n)\n\ndef enable_wal_mode(con: sqlite3.Connection, relax_sync_mode: bool = True):\n    \"\"\"Enable WAL mode for the connected database.\n\n    Note that for multiple databases being attached, WAL mode only guarantees\n        atomic within each individual database file. See https://www.sqlite.org/lang_attach.html\n        for more details.\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n        relax_sync_mode (bool): Also set the synchronous mode to NORMAL. Default to True.\n\n    Raises:\n        sqlite3.DatabaseError on failed sql execution.\n    \"\"\"\n    pass\n\ndef enable_tmp_store_at_memory(con: sqlite3.Connection):\n    \"\"\"Locate the temp tables at memory.\n\n    See https://www.sqlite.org/pragma.html#pragma_temp_store for more details.\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n\n    Raises:\n        sqlite3.DatabaseError on failed sql execution.\n    \"\"\"\n    pass\n\ndef enable_mmap(con: sqlite3.Connection, mmap_size: int = ...) -> None: # DEFAULT_MMAP_SIZE used in original\n    \"\"\"Enable mmap for the connection.\n\n    See https://www.sqlite.org/pragma.html#pragma_mmap_size for more\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n        mmap_size (int, optional): The max mmap size. Defaults to <DEFAULT_MMAP_SIZE=16MiB>.\n\n    Raises:\n        sqlite3.DatabaseError on failed sql execution.\n    \"\"\"\n    pass\n\ndef optimize_db(con: sqlite3.Connection):\n    \"\"\"Execute optimize PRAGMA on the target database.\n\n    See https://www.sqlite.org/pragma.html#pragma_optimize.\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n\n    Raises:\n        sqlite3.DatabaseError on failed sql execution.\n    \"\"\"\n    pass\n\ndef check_db_integrity(con: sqlite3.Connection, table_name: str | None = None) -> bool:\n    \"\"\"Execute integrity_check PRAGMA on the target database(or specific table at the database).\n\n    See https://www.sqlite.org/pragma.html#pragma_integrity_check for more details.\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n        table_name (str | None, optional): If specified, the integrity_check will only be performed\n            against this table. Defaults to None, means performing the check on the whole database.\n\n    Returns:\n        bool: True for integrity_check passed on the target database, False for errors found.\n    \"\"\"\n    pass\n\ndef lookup_table(con: sqlite3.Connection, table_name: str) -> bool:\n    \"\"\"Check if specific table existed on the target database.\n\n    Args:\n        con (sqlite3.Connection): The connection to the target database.\n        table_name (str): The name of table to lookup.\n\n    Returns:\n        bool: True for table existed, False for not found.\n    \"\"\"\n    pass\n\n@overload\ndef check_pragma_compile_time_options(\n    con: sqlite3.Connection, option_name: str\n) -> tuple[str, Any] | None: ...\n\n@overload\ndef check_pragma_compile_time_options(\n    con: sqlite3.Connection, option_name: None = None\n) -> list[tuple[str, Any]]: ...\n\ndef check_pragma_compile_time_options(\n    con: sqlite3.Connection, option_name: str | None = None\n) -> tuple[str, Any] | None | list[tuple[str, Any]]:\n    \"\"\"Get the runtime sqlite3 library's compile time options.\n\n    Args:\n        con (sqlite3.Connection): The current database connection.\n        option_name (str | None, optional): The option to lookup. If not specified,\n            it will return all the options and its values. Defaults to None.\n\n    Returns:\n        tuple[str, Any] | None | list[tuple[str, Any]]: Looked up options and its values.\n    \"\"\"\n    pass\n\nif sys.version_info >= (3, 12):\n    pass\nelse: # pragma: no cover\n    def batched(\n        iterable: Iterable[Any], n: int\n    ) -> Generator[tuple[Any, ...], Any, None]:\n        \"\"\"Batch data from the iterable into tuples of length n. The last batch may be shorter than n.\n\n        Backport batched from py3.12. This is the roughly python implementation\n            of py3.12's batched copied from py3.12 documentation.\n        See https://docs.python.org/3/library/itertools.html#itertools.batched for more details.\n\n        Args:\n            iterable (Iterable[Any]): The input to be batched.\n            n (int): the size of each batch.\n\n        Raises:\n            ValueError on invalid n.\n\n        Returns:\n            A generator that can be used to loop over the input iterable and accumulates data into\n                tuples up to size n(a.k.a, batch in size of n).\n        \"\"\"\n        pass\n\ndef gen_check_constrain(_in: Any, field_name: str) -> str:\n    \"\"\"Generate the constrain statement for CHECK keyword.\n\n    Supports the following types:\n    1. StrEnum or IntEnum types: will generate statement like:\n        <field_name> IN (<enum_value_1>[, <enum_value_2>[, ...]])\n    2. Literal types: similar to StrEnum and IntEnum.\n\n    Args:\n        enum_type (type[Enum]): The enum type to generate CHECK statement against.\n        field_name (str): The field name of this enum_type in use.\n\n    Raises:\n        TypeError on unsupported enum_type.\n\n    Returns:\n        str: the generated statement can be used with CHECK keyword like the following:\n           <enum_value_1>[, <enum_value_2>[, ...]]\n    \"\"\"\n    pass\n\ndef concatenate_condition(\n    *condition_or_op: Any, # Original was CONDITION_OPERATORS | COMPARE_OPERATORS | Any\n    wrapped_with_parentheses: bool = True,\n) -> str:\n    \"\"\"Chain a list of conditions and operators together in a string.\n\n    For example, for the following statement for CHECK keyword:\n        (column IS NULL OR column IN (1, 2, 3))\n    we can use concatenate_condition like:\n        concatenate_condition(\n            \"column IS NULL\", \"OR\", \"column IN (1, 2, 3)\",\n            wrapped_with_parentheses=True,\n        )\n    \"\"\"\n    pass\n\ndef wrap_value(value: Any) -> str:\n    \"\"\"Wrap value for use in sql statement.\n\n    NOTE that for most cases, you should use python sqlite3 lib's\n        placeholder feature to bind value in the sql statement.\n\n    For int and float, the value will be used as it.\n    For str, the value will be wrapped with parenthesis.\n    For bytes, the value will be converted as x'<bytes_in_hex>'.\n    \"\"\"\n    pass\n"
            },
            {
                "file_path": "src/simple_sqlite3_orm/_orm/_base.py",
                "code": "from __future__ import annotations\n\nimport sqlite3\nimport warnings\nfrom functools import cached_property, partial\nfrom itertools import chain\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Callable,\n    Generator,\n    Generic,\n    Iterable,\n    Literal,\n    Mapping,\n    TypeVar,\n    Union,\n    overload,\n)\n\nfrom typing_extensions import ParamSpec, Self\n\nfrom simple_sqlite3_orm._orm._utils import parameterized_class_getitem\nfrom simple_sqlite3_orm._sqlite_spec import OR_OPTIONS\nfrom simple_sqlite3_orm._table_spec import (\n    CreateIndexParams,\n    CreateTableParams,\n    TableSpec,\n    TableSpecType,\n)\nfrom simple_sqlite3_orm._typing import (\n    ColsDefinition,\n    ColsDefinitionWithDirection,\n    ConnectionFactoryType,\n    RowFactoryType,\n)\n\nDoNotChangeRowFactory = Literal[\"do_not_change\"]\nDO_NOT_CHANGE_ROW_FACTORY: DoNotChangeRowFactory = \"do_not_change\"\n\nRowFactorySpecifier = Union[\n    RowFactoryType,\n    Literal[\n        \"sqlite3_row_factory\",\n        \"table_spec\",\n        \"table_spec_no_validation\",\n    ],\n    DoNotChangeRowFactory,\n    None,\n]\n\"\"\"Specifiy which row_factory to use.\n\nFor each option:\n    1. RowFactoryType: specify arbitrary row_factory.\n    2. None: clear the connection scope row_factory(set to None).\n    3. \"sqlite3_row_factory\": set to use sqlite3.Row as row_factory.\n    4. \"table_spec\": use TableSpec.table_row_factory as row_factory.\n    5. \"table_spec_no_validation\": use TableSpec.table_row_factory as row_factory, but with validation=False.\n    6. \"do_not_change\": do not change the connection scope row_factory.\n\"\"\"\n\nclass ORMCommonBase(Generic[TableSpecType]):\n    orm_table_spec: type[TableSpecType]\n    orm_bootstrap_table_name: str\n    orm_bootstrap_create_table_params: str | CreateTableParams\n    orm_bootstrap_indexes_params: list[str | CreateIndexParams]\n    _orm_table_name: str\n\n\n    def __init_subclass__(cls, **kwargs) -> None:\n        pass\n\nclass ORMBase(ORMCommonBase[TableSpecType]):\n    \"\"\"ORM layer for <TableSpecType>.\n\n    NOTE that instance of ORMBase cannot be used in multi-threaded environment.\n        Use ORMThreadPoolBase for multi-threaded environment.\n        For asyncio, use AsyncORMThreadPoolBase.\n\n    The underlying connection can be used in multiple connection for accessing different table in\n        the connected database.\n\n    Attributes:\n        con (sqlite3.Connection | ConnectionFactoryType): The sqlite3 connection used by this ORM, or a factory\n            function that returns a sqlite3.Connection object on calling.\n        table_name (str): The name of the table in the database <con> connected to. This field will take prior over the\n            table_name specified by orm_bootstrap_table_name attr to allow using different table_name for just one connection.\n        schema_name (str): The schema of the table if multiple databases are attached to <con>.\n        row_factory (RowFactorySpecifier): The connection scope row_factory to use. Default to \"table_sepc\".\n    \"\"\"\n\n    def __init__(\n        self,\n        con: sqlite3.Connection | ConnectionFactoryType,\n        table_name: str | None = None,\n        schema_name: str | Literal[\"temp\"] | None = None,\n        *,\n        row_factory: RowFactorySpecifier = \"table_spec\",\n    ) -> None:\n        pass\n\n    __class_getitem__ = classmethod(parameterized_class_getitem)\n\n    def orm_bootstrap_db(self) -> None:\n        \"\"\"Bootstrap the database this ORM connected to.\n\n        This method will refer to the following attrs to setup table and indexes:\n        1. orm_bootstrap_table_name: the name of table to be created.\n        2. orm_bootstrap_create_table_params: the sqlite query to create the table,\n            it can be provided as sqlite query, or CreateTableParams for table_create_stmt\n            to generate sqlite query from.\n            It not specified, the table create statement will be generated with default configs,\n            See table_spec.table_create_stmt method for more details.\n        3. orm_bootstrap_indexes_params: optional, a list of sqlite query or\n            CreateIndexParams(for table_create_index_stmt to generate sqlite query from) to\n            create indexes from.\n\n        NOTE that ORM will not know whether the connected database has already been\n            bootstrapped or not, this is up to caller to check.\n        \"\"\"\n        pass\n\n    @property\n    def orm_con(self) -> sqlite3.Connection:\n        \"\"\"A reference to the underlying sqlite3.Connection.\n\n        This is for directly executing sql stmts.\n        \"\"\"\n        pass\n\n    @cached_property\n    def orm_table_name(self) -> str:\n        \"\"\"The unique name of the table for use in sql statement.\n\n        If multiple databases are attached to <con> and <schema_name> is availabe,\n            return \"<schema_name>.<table_name>\", otherwise return <table_name>.\n        \"\"\"\n        pass\n\n    @property\n    def orm_conn_row_factory(self) -> RowFactoryType | None:\n        \"\"\"Get and set the connection scope row_factory for this ORM instance.\"\"\"\n        pass\n\n    @orm_conn_row_factory.setter\n    def orm_conn_row_factory(self, _row_factory: RowFactoryType | None) -> None:\n        pass\n\n    @overload\n    def orm_execute(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: Callable[[sqlite3.Cursor, Any], RT],\n    ) -> list[RT]: ...\n\n    @overload\n    def orm_execute(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: DoNotChangeRowFactory = DO_NOT_CHANGE_ROW_FACTORY,\n    ) -> list[TableSpecType]: ...\n\n    @overload\n    def orm_execute(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: None,\n    ) -> list[tuple[Any, ...]]: ...\n\n    def orm_execute(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: RowFactorySpecifier\n        | DoNotChangeRowFactory = DO_NOT_CHANGE_ROW_FACTORY,\n    ) -> list[Any]:\n        \"\"\"Execute one sql statement and get the all the result.\n\n        NOTE that caller needs to serialize the `params` before hands if needed, `orm_execute` will\n            not do any processing over the input `params`, and just use as it for execution.\n        The result will be fetched with fetchall API and returned as it.\n\n        Args:\n            sql_stmt (str): The sqlite statement to be executed.\n            params (tuple[Any, ...] | dict[str, Any] | None, optional): The parameters to be bound\n                to the sql statement execution. Defaults to None, not passing any params.\n            row_factory (RowFactorySpecifier | DoNotChangeRowFactory, optional): specify to use\n                different row_factory for the query. Default to not change the current row_factory.\n                NOTE that None value here means unset the row_factory for this query.\n\n        Returns:\n            list[Any]: A list contains all the result entries.\n        \"\"\"\n        pass\n\n    @overload\n    def orm_execute_gen(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: Callable[[sqlite3.Cursor, Any], RT],\n    ) -> Generator[RT]: ...\n\n    @overload\n    def orm_execute_gen(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: DoNotChangeRowFactory = DO_NOT_CHANGE_ROW_FACTORY,\n    ) -> Generator[TableSpecType]: ...\n\n    @overload\n    def orm_execute_gen(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: None,\n    ) -> Generator[tuple[Any, ...]]: ...\n\n    def orm_execute_gen(\n        self,\n        sql_stmt: str,\n        params: tuple[Any, ...] | dict[str, Any] | None = None,\n        *,\n        row_factory: RowFactorySpecifier\n        | DoNotChangeRowFactory = DO_NOT_CHANGE_ROW_FACTORY,\n    ) -> Generator[Any]:\n        \"\"\"The same as orm_execute, but as a Generator.\"\"\"\n        pass\n\n    def orm_create_table(\n        self,\n        *,\n        allow_existed: bool = False,\n        strict: bool = False,\n        without_rowid: bool = False,\n        _stmt: str | None = None,\n    ) -> None:\n        \"\"\"Create the table defined by this ORM with <orm_table_spec>.\n\n        NOTE: strict table option is supported after sqlite3 3.37.\n\n        Args:\n            allow_existed (bool, optional): Do not abort on table already created.\n                Set True equals to add \"IF NOT EXISTS\" in the sql statement. Defaults to False.\n            strict (bool, optional): Enable strict field type check. Defaults to False.\n                See https://www.sqlite.org/stricttables.html for more details.\n            without_rowid (bool, optional): Create the table without ROWID. Defaults to False.\n                See https://www.sqlite.org/withoutrowid.html for more details.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            sqlite3.DatabaseError on failed sql execution.\n        \"\"\"\n        pass\n\n    def orm_create_index(\n        self,\n        *,\n        index_name: str,\n        index_keys: ColsDefinition | ColsDefinitionWithDirection,\n        allow_existed: bool = False,\n        unique: bool = False,\n        _stmt: str | None = None,\n    ) -> None:\n        \"\"\"Create index according to the input arguments.\n\n        Args:\n            index_name (str): The name of the index.\n            index_keys (ColsDefinition | ColsDefinitionWithDirection): The columns for the index.\n            allow_existed (bool, optional): Not abort on index already created. Defaults to False.\n            unique (bool, optional): Not allow duplicated entries in the index. Defaults to False.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            sqlite3.DatabaseError on failed sql execution.\n        \"\"\"\n        pass\n\n    @overload\n    def orm_select_entries(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _row_factory: Callable[[sqlite3.Cursor, Any], RT],\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[RT]: ...\n\n    @overload\n    def orm_select_entries(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _row_factory: None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[TableSpecType | Any]: ...\n\n    def orm_select_entries(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _row_factory: RowFactoryType | None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[TableSpecType | Any]:\n        \"\"\"Select entries from the table accordingly.\n\n        Args:\n            col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n                the pairs in this mapping will take prior than the one specified in <col_values>.\n            _distinct (bool, optional): Deduplicate and only return unique entries. Defaults to False.\n            _order_by (ColsDefinition | ColsDefinitionWithDirection | None, optional):\n                Order the result accordingly. Defaults to None, not sorting the result.\n            _limit (int | None, optional): Limit the number of result entries. Defaults to None.\n            _row_factory (RowFactoryType | None, optional): Set to use different row factory for this query.\n                Defaults to None(do not change row_factory).\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n            **col_values: provide col/value pairs by kwargs. Col/value pairs in <col_values> have lower priority over\n                the one specified by <_col_vlues_dict>.\n\n        Raises:\n            sqlite3.DatabaseError on failed sql execution.\n\n        Yields:\n            Generator[TableSpecType | Any]: A generator that can be used to yield entry from result.\n        \"\"\"\n        pass\n\n    @overload\n    def orm_select_entry(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _row_factory: Callable[[sqlite3.Cursor, Any], RT],\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> RT: ...\n\n    @overload\n    def orm_select_entry(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _row_factory: None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> TableSpecType | Any: ...\n\n    def orm_select_entry(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _distinct: bool = False,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _row_factory: RowFactoryType | None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> TableSpecType | Any | None:\n        \"\"\"Select exactly one entry from the table accordingly.\n\n        NOTE that if the select result contains more than one entry, this method will return\n            the FIRST one from the result with fetchone API.\n\n        Args:\n            col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n                the pairs in this mapping will take prior than the one specified in <col_values>.\n            _distinct (bool, optional): Deduplicate and only return unique entries. Defaults to False.\n            _order_by (ColsDefinition | ColsDefinitionWithDirection | None, optional):\n                Order the result accordingly. Defaults to None, not sorting the result.\n            _row_factory (RowFactoryType | None, optional): Set to use different row factory for this query.\n                Defaults to None(do not change row_factory).\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n            **col_values: provide col/value pairs by kwargs. Col/value pairs in <col_values> have lower priority over\n                the one specified by <_col_vlues_dict>.\n\n        Raises:\n            sqlite3.DatabaseError on failed sql execution.\n\n        Returns:\n            TableSpecType | Any: Exactly one entry, or None if not hit.\n        \"\"\"\n        pass\n\n    def orm_insert_entries(\n        self,\n        _in: Iterable[TableSpecType],\n        *,\n        or_option: OR_OPTIONS | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"Insert an iterable of rows represented as TableSpec insts into this table.\n\n        Args:\n            _in (Iterable[TableSpecType]): An iterable of rows as TableSpec insts to insert.\n            or_option (INSERT_OR | None, optional): The fallback operation if insert failed. Defaults to None.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            ValueError: On invalid types of _in.\n            sqlite3.DatabaseError: On failed sql execution.\n\n        Returns:\n            int: Number of inserted entries.\n        \"\"\"\n        pass\n\n    def orm_insert_mappings(\n        self,\n        _in: Iterable[Mapping[str, Any]],\n        *,\n        or_option: OR_OPTIONS | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"Insert an iterable of rows represented as mappings into this table.\n\n        Each mapping stores cols with values in application types. Assuming that all entries in\n            this Iterable contains mapping with the same schema.\n\n        Args:\n            _in (Iterable[Mapping[str, Any]]): An iterable of mappings to insert.\n            or_option (INSERT_OR | None, optional): The fallback operation if insert failed. Defaults to None.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            ValueError: On invalid types of _in.\n            sqlite3.DatabaseError: On failed sql execution.\n\n        Returns:\n            int: Number of inserted entries.\n        \"\"\"\n        pass\n\n    def orm_insert_entry(\n        self,\n        _in: TableSpecType,\n        *,\n        or_option: OR_OPTIONS | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"Insert exactly one entry into this table.\n\n        Args:\n            _in (TableSpecType): The instance of entry to insert.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            ValueError: On invalid types of _in.\n            sqlite3.DatabaseError: On failed sql execution.\n\n        Returns:\n            int: Number of inserted entries. In normal case it should be 1.\n        \"\"\"\n        pass\n\n    def orm_insert_mapping(\n        self,\n        _in: Mapping[str, Any],\n        *,\n        or_option: OR_OPTIONS | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"Insert exactly one entry(represented as a mapping) into this table.\n\n        Args:\n            _in (TableSpecType): The instance of entry to insert.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n\n        Raises:\n            ValueError: On invalid types of _in.\n            sqlite3.DatabaseError: On failed sql execution.\n\n        Returns:\n            int: Number of inserted entries. In normal case it should be 1.\n        \"\"\"\n        pass\n\n    def orm_update_entries(\n        self,\n        *,\n        set_values: Mapping[str, Any] | TableSpec,\n        where_cols_value: Mapping[str, Any] | None = None,\n        where_stmt: str | None = None,\n        or_option: OR_OPTIONS | None = None,\n        _extra_params: Mapping[str, Any] | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"UPDATE specific entries by matching <where_cols_value>.\n\n        NOTE: if you want to using the same query stmt with different set of params(set col/values and/or where col/values),\n            it is highly recommended to use `orm_update_entries_many` API, it will be significantly faster to call `orm_update_entries`\n            in a for loop(in my test with 2000 entries, using `orm_update_entries_many` is around 300 times faster).\n        NOTE: currently UPDATE-WITH-LIMIT and RETURNING are not supported by this method.\n\n        Args:\n            set_values (Mapping[str, Any] | TableSpec): values to update.\n            where_cols_value (Mapping[str, Any], optional): cols to matching. This method will\n                also generate WHERE statement of matching each cols specified in this mapping.\n            where_stmt (str | None, optional): directly provide WHERE statement. If provided,\n                <where_cols_value> will only be used as params.\n            or_option (OR_OPTIONS | None, optional): specify the operation if UPDATE failed.\n            _extra_params (Mapping[str, Any] | None, optional): provide extra named params\n                for sqlite3 query execution. NOTE that `_extra_params` takes higher priority\n                to any named params specified by `where_cols_value` and `set_values`. Defaults to None.\n            _stmt (str | None, optional): directly provide the UPDATE query, if provided,\n                <where_cols_value>, <where_stmt> and <or_option> will be ignored.\n\n        Raises:\n            SQLite3 DB Errors on failed operations.\n\n        Returns:\n            Affected rows count.\n        \"\"\"\n        pass\n\n    @overload\n    def orm_update_entries_many(\n        self,\n        *,\n        set_cols: tuple[str, ...],\n        where_cols: tuple[str, ...] | None = None,\n        where_stmt: str | None = None,\n        set_cols_value: Iterable[Mapping[str, Any]],\n        where_cols_value: Iterable[Mapping[str, Any]] | None = None,\n        or_option: OR_OPTIONS | None = None,\n        _extra_params: Mapping[str, Any] | None = None,\n        _extra_params_iter: Iterable[Mapping[str, Any]] | None = None,\n        _stmt: None = None,\n    ) -> int: ...\n\n    @overload\n    def orm_update_entries_many(\n        self,\n        *,\n        set_cols: None = None,\n        where_cols: None = None,\n        where_stmt: None = None,\n        set_cols_value: None = None,\n        where_cols_value: None = None,\n        or_option: None = None,\n        _extra_params: Mapping[str, Any] | None = None,\n        _extra_params_iter: Iterable[Mapping[str, Any]] | None = None,\n        _stmt: str,\n    ) -> int: ...\n\n    def orm_update_entries_many(\n        self,\n        *,\n        set_cols: tuple[str, ...] | None = None,\n        where_cols: tuple[str, ...] | None = None,\n        where_stmt: str | None = None,\n        set_cols_value: Iterable[Mapping[str, Any]] | None = None,\n        where_cols_value: Iterable[Mapping[str, Any]] | None = None,\n        or_option: OR_OPTIONS | None = None,\n        _extra_params: Mapping[str, Any] | None = None,\n        _extra_params_iter: Iterable[Mapping[str, Any]] | None = None,\n        _stmt: str | None = None,\n    ) -> int:\n        \"\"\"executemany version of orm_update_entries.\n\n        Params like `set_cols_value` and `where_cols_value` need to be provided as iterables.\n        NOTE that the execution will end and return when any of the input iterable exhausted.\n\n        NOTE that `_extra_params` and `_extra_params_iter` will not be serialized. Caller needs to\n            provide the serialized mappings ready for `executemany`.\n\n        Args:\n            set_cols (tuple[str, ...]): Cols to be updated.\n            set_cols_value (Iterable[Mapping[str, Any]]): An iterable of values of to-be-updated cols.\n            where_cols (tuple[str, ...] | None, optional): Cols to match. The WHERE stmt will be generated\n                based on this param. Defaults to None.\n            where_cols_value (Iterable[Mapping[str, Any]] | None, optional): An iterable of values of cols to match.\n                Defaults to None.\n            where_stmt (str | None, optional): Directly provide the WHERE stmt. If specified, both `where_cols` and\n                `where_cols_value` will be ignored. Caller needs to feed the params with `_extra_params` or `_extra_params_iter`.\n                Defaults to None.\n            or_option (OR_OPTIONS | None, optional): specify the operation if UPDATE failed. Defaults to None.\n            _extra_params (Mapping[str, Any] | None, optional): A fixed mapping to be injected for each execution.\n                NOTE that this param is only allowed when at least one of `where_cols_value`, `set_cols_value` or `_extra_params_iter` is specified.\n                Defaults to None.\n            _extra_params_iter (Iterable[Mapping[str, Any]] | None, optional): An iterable of mappings to be injected for each execution. Defaults to None.\n            _stmt (str | None, optional): Directly provide the UPDATE query, if specified, params except `_extra_params` and `_extra_params_iter`\n                will be ignored. Defaults to None.\n\n        Raises:\n            ValueError: If `where_cols_value` and `where_cols` are not be both None or both specifed.\n            ValueError: If `_stmt` is not used and `set_cols` and/or `set_cols_value` are not specified.\n            ValueError: If `_extra_params` is specified without any other iterable params provided.\n            sqlite3 DB error on execution failed.\n\n        Returns:\n            Affected rows count.\n        \"\"\"\n        pass\n\n    def orm_delete_entries(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> int:\n        \"\"\"Delete entries from the table accordingly.\n\n        Args:\n            col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n                the pairs in this mapping will take prior than the one specified in <col_values>.\n            _order_by (ColsDefinition | ColsDefinitionWithDirection | None, optional): Order the matching entries\n                before executing the deletion, used together with <_limit>. Defaults to None.\n            _limit (int | None, optional): Only delete <_limit> number of entries. Defaults to None.\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n            **col_values: provide col/value pairs by kwargs. Col/value pairs in <col_values> have lower priority over\n                the one specified by <_col_vlues_dict>.\n\n        Returns:\n            int: The num of entries deleted.\n        \"\"\"\n        pass\n\n    @overload\n    def orm_delete_entries_with_returning(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _returning_cols: ColsDefinition | Literal[\"*\"],\n        _row_factory: Callable[[sqlite3.Cursor, Any], RT],\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[RT]: ...\n\n    @overload\n    def orm_delete_entries_with_returning(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _returning_cols: ColsDefinition | Literal[\"*\"],\n        _row_factory: None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[TableSpecType | Any]: ...\n\n    def orm_delete_entries_with_returning(\n        self,\n        col_value_pairs: Mapping[str, Any] | None = None,\n        *,\n        _order_by: ColsDefinition | ColsDefinitionWithDirection | None = None,\n        _limit: int | None = None,\n        _returning_cols: ColsDefinition | Literal[\"*\"],\n        _row_factory: RowFactoryType | None = None,\n        _stmt: str | None = None,\n        **col_values: Any,\n    ) -> Generator[TableSpecType | Any]:\n        \"\"\"Delete entries from the table accordingly.\n\n        NOTE that only sqlite3 version >= 3.35 supports returning statement.\n\n        Args:\n            col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n                the pairs in this mapping will take prior than the one specified in <col_values>.\n            _order_by (ColsDefinition | ColsDefinitionWithDirection | None, optional): Order the matching entries\n                before executing the deletion, used together with <_limit>. Defaults to None.\n            _limit (int | None, optional): Only delete <_limit> number of entries. Defaults to None.\n            _returning_cols (ColsDefinition | Literal[\"*\"] ): Return the deleted entries on execution.\n            _row_factory (RowFactoryType | None, optional): Set to use different row factory for this query.\n                Defaults to None(do not change row_factory).\n            _stmt (str, optional): If provided, all params will be ignored and query statement will not\n                be generated with the params, instead the provided <_stmt> will be used as query statement.\n            **col_values: provide col/value pairs by kwargs. Col/value pairs in <col_values> have lower priority over\n                the one specified by <_col_vlues_dict>.\n\n        Returns:\n            Generator[TableSpecType | Any]: If <_returning_cols> is defined, returns a generator which can\n                be used to yield the deleted entries from.\n        \"\"\"\n        pass\n\n    def orm_select_all_with_pagination(\n        self, *, batch_size: int\n    ) -> Generator[TableSpecType | Any]:\n        \"\"\"Select all entries from the table accordingly with pagination.\n\n        This is implemented by seek with rowid, so it will not work on without_rowid table.\n\n        Args:\n            batch_size (int): The entry number for each page.\n\n        Raises:\n            ValueError on invalid batch_size.\n            sqlite3.DatabaseError on failed sql execution.\n\n        Yields:\n            Generator[TableSpecType, None, None]: A generator that can be used to yield entry from result.\n        \"\"\"\n        pass\n\n    def orm_check_entry_exist(\n        self, col_value_pairs: Mapping[str, Any] | None = None, **col_values: Any\n    ) -> bool:\n        \"\"\"A quick method to check whether entry(entries) indicated by cols exists.\n\n        This method uses COUNT function to count the selected entry.\n\n        Args:\n            col_value_pairs(Mapping[str, Any] | None): provide col/value pairs by a Mapping, if provided,\n                the pairs in this mapping will take prior than the one specified in <col_values>.\n            **cols: cols pair to locate the entry(entries).\n\n        Returns:\n            Returns True if at least one entry matches the input cols exists, otherwise False.\n        \"\"\"\n        pass\n"
            },
            {
                "file_path": "src/simple_sqlite3_orm/_orm/_pool.py",
                "code": "from __future__ import annotations\n\nimport asyncio\nimport atexit\nimport contextlib\nimport queue\nimport threading\nfrom collections.abc import Callable, Generator\nfrom concurrent.futures import ThreadPoolExecutor\nfrom functools import cached_property, partial\nfrom typing import TYPE_CHECKING, AsyncGenerator, TypeVar\nfrom weakref import WeakSet\n\nfrom typing_extensions import Concatenate, ParamSpec, Self\n\nfrom simple_sqlite3_orm._orm._base import ORMBase, ORMCommonBase, RowFactorySpecifier\nfrom simple_sqlite3_orm._orm._utils import parameterized_class_getitem\nfrom simple_sqlite3_orm._table_spec import TableSpecType\nfrom simple_sqlite3_orm._typing import ConnectionFactoryType\n\nP = ParamSpec(\"P\")\nRT = TypeVar(\"RT\")\n\ndef _wrap_generator_with_thread_ctx(\n    func: Callable[Concatenate[ORMBase, P], Generator[RT]],\n):\n    pass\n\ndef _wrap_generator_with_async_ctx(\n    func: Callable[Concatenate[ORMBase, P], Generator[RT]],\n):\n    pass\n\nclass ORMThreadPoolBase(ORMCommonBase[TableSpecType]):\n    \"\"\"\n    See https://www.sqlite.org/wal.html#concurrency for more details.\n\n    For the row_factory arg, please see ORMBase.__init__ for more details.\n    \"\"\"\n\n    def __init__(\n        self,\n        table_name: str | None = None,\n        schema_name: str | None = None,\n        *,\n        con_factory: ConnectionFactoryType,\n        number_of_cons: int,\n        thread_name_prefix: str = \"\",\n        row_factory: RowFactorySpecifier = \"table_spec\",\n    ) -> None:\n        pass\n\n    __class_getitem__ = classmethod(parameterized_class_getitem)\n\n    @cached_property\n    def orm_table_name(self) -> str:\n        \"\"\"The unique name of the table for use in sql statement.\n\n        If multiple databases are attached to <con> and <schema_name> is availabe,\n            return \"<schema_name>.<table_name>\", otherwise return <table_name>.\n        \"\"\"\n        pass\n\n    def orm_pool_shutdown(self, *, wait=True, close_connections=True) -> None:\n        \"\"\"Shutdown the ORM connections thread pool.\n\n        It is safe to call this method multiple time.\n        This method is NOT thread-safe, and should be called at the main thread,\n            or the thread that creates this thread pool.\n\n        Args:\n            wait (bool, optional): Wait for threads join. Defaults to True.\n            close_connections (bool, optional): Close all the connections. Defaults to True.\n        \"\"\"\n        pass\n\n    def orm_create_table(self, *args: P.args, **kwargs: P.kwargs) -> RT: # Wrapped ORMBase.orm_create_table\n        pass\n\n    def orm_execute(self, *args: P.args, **kwargs: P.kwargs) -> RT: # Wrapped ORMBase.orm_execute\n        pass\n\n    def orm_insert_entries(self, *args: P.args, **kwargs: P.kwargs) -> RT: # Wrapped ORMBase.orm_insert_entries\n        pass\n\n    def orm_create_index(self, *args: P.args, **kwargs: P.kwargs) -> RT: # Wrapped ORMBase.orm_create_index\n        pass\n\n    def orm_select_entries(self, *args: P.args, **kwargs: P.kwargs) -> Generator[RT]: # Wrapped ORMBase.orm_select_entries\n        pass\n\n    def orm_delete_entries(self, *args: P.args, **kwargs: P.kwargs) -> RT: # Wrapped ORMBase.orm_delete_entries\n        pass\n\n    def orm_delete_entries_with_returning(self, *args: P.args, **kwargs: P.kwargs) -> Generator[RT]: # Wrapped ORMBase.orm_delete_entries_with_returning\n        pass\n\nclass AsyncORMBase(ORMThreadPoolBase[TableSpecType]):\n    \"\"\"\n    NOTE: the supoprt for async ORM is experimental! The APIs might be changed a lot\n        in the following releases.\n\n    For the row_factory arg, please see ORMBase.__init__ for more details.\n    \"\"\"\n\n    _loop: asyncio.AbstractEventLoop\n    \"\"\"Bound event loop when instanitiate this pool.\"\"\"\n\n    if not TYPE_CHECKING:\n        def __init__(self, *args, **kwargs) -> None:\n            pass\n\n    async def orm_create_table(self, *args: P.args, **kwargs: P.kwargs) -> RT: # Wrapped ORMBase.orm_create_table\n        pass\n\n    async def orm_execute(self, *args: P.args, **kwargs: P.kwargs) -> RT: # Wrapped ORMBase.orm_execute\n        pass\n\n    async def orm_insert_entries(self, *args: P.args, **kwargs: P.kwargs) -> RT: # Wrapped ORMBase.orm_insert_entries\n        pass\n\n    async def orm_create_index(self, *args: P.args, **kwargs: P.kwargs) -> RT: # Wrapped ORMBase.orm_create_index\n        pass\n\n    async def orm_select_entries(self, *args: P.args, **kwargs: P.kwargs) -> AsyncGenerator[RT, None]: # Wrapped ORMBase.orm_select_entries\n        pass\n\n    async def orm_delete_entries(self, *args: P.args, **kwargs: P.kwargs) -> RT: # Wrapped ORMBase.orm_delete_entries\n        pass\n\n    async def orm_delete_entries_with_returning(self, *args: P.args, **kwargs: P.kwargs) -> AsyncGenerator[RT, None]: # Wrapped ORMBase.orm_delete_entries_with_returning\n        pass\n"
            },
            {
                "file_path": "src/simple_sqlite3_orm/_orm/_utils.py",
                "code": "from __future__ import annotations\n\nfrom typing import Any\nfrom weakref import WeakValueDictionary\n\nfrom simple_sqlite3_orm._table_spec import TableSpec, TableSpecType\nfrom simple_sqlite3_orm._utils import GenericAlias\n\ndef parameterized_class_getitem(\n    cls, params: Any | type[Any] | type[TableSpecType] | tuple[type[Any], ...]\n) -> Any:\n    pass\n"
            }
        ],
        "minimal_test_cases": [
            {
                "test_id": "tests/test__table_spec.py::test_table_create[table_create_params0]",
                "covers": [
                    "simple_sqlite3_orm.TableSpec.table_create_stmt - happy path, basic options (if_not_exists=True)",
                    "simple_sqlite3_orm.TableSpec.table_dump_column - (indirectly via table_create_stmt)",
                    "simple_sqlite3_orm.TableSpec.table_get_col_fieldinfo - (indirectly via table_dump_column)"
                ]
            },
            {
                "test_id": "tests/test__table_spec.py::TestTableSpecWithDB::test_insert_entry[insert a complete row-to_insert0]",
                "covers": [
                    "simple_sqlite3_orm.TableSpec.table_insert_stmt - happy path, insert complete row",
                    "simple_sqlite3_orm.TableSpec.table_select_stmt - (used for verification)",
                    "simple_sqlite3_orm.TableSpec.table_row_factory - (used for verification)",
                    "simple_sqlite3_orm.TableSpec.table_check_cols - (indirectly via table_insert_stmt)"
                ]
            },
            {
                "test_id": "tests/test__table_spec.py::TestTableSpecWithDB::test_insert_default_values",
                "covers": [
                    "simple_sqlite3_orm.TableSpec.table_insert_stmt - happy path, insert default values"
                ]
            },
            {
                "test_id": "tests/test__table_spec.py::TestTableSpecWithDB::test_lookup_entry",
                "covers": [
                    "simple_sqlite3_orm.TableSpec.table_row_factory2 - happy path, custom row factory for lookup",
                    "simple_sqlite3_orm.TableSpec.table_select_stmt - (used for lookup)"
                ]
            },
            {
                "test_id": "tests/test__table_spec.py::TestTableSpecWithDB::test_update_entry[set_values0-where_cols0-UPDATE test_table SET id = :id, id_str = :id_str WHERE id = :__table_spec_id AND id_str = :__table_spec_id_str AND extra = :__table_spec_extra AND int_str = :__table_spec_int_str;-expected_result0]",
                "covers": [
                    "simple_sqlite3_orm.TableSpec.table_update_stmt - happy path, basic update with where_cols",
                    "simple_sqlite3_orm.TableSpec.table_preprare_update_where_cols - happy path utility for update statements"
                ]
            },
            {
                "test_id": "tests/test__table_spec.py::test_table_dump_asdict[_in0-_expected0]",
                "covers": [
                    "simple_sqlite3_orm.TableSpec.table_dump_asdict - happy path, dump all columns"
                ]
            },
            {
                "test_id": "tests/test__table_spec.py::test_table_dump_astuple[_in0-_cols0-_expected0]",
                "covers": [
                    "simple_sqlite3_orm.TableSpec.table_dump_astuple - happy path, dump all columns"
                ]
            },
            {
                "test_id": "tests/test__table_spec.py::test_table_from_tuple[_in0-True-_expected0]",
                "covers": [
                    "simple_sqlite3_orm.TableSpec.table_from_tuple - happy path, with validation"
                ]
            },
            {
                "test_id": "tests/test__table_spec.py::test_table_from_dict[_in0-True-_expected0]",
                "covers": [
                    "simple_sqlite3_orm.TableSpec.table_from_dict - happy path, with validation"
                ]
            },
            {
                "test_id": "tests/test__table_spec.py::test_serializing_mapping[_in0-_expected0]",
                "covers": [
                    "simple_sqlite3_orm.TableSpec.table_serialize_mapping - happy path, basic mapping"
                ]
            },
            {
                "test_id": "tests/test__table_spec.py::TestTableSpecWithDB::test_deserialize_asdict_row_factory",
                "covers": [
                    "simple_sqlite3_orm.TableSpec.table_deserialize_asdict_row_factory - happy path"
                ]
            },
            {
                "test_id": "tests/test__table_spec.py::TestTableSpecWithDB::test_deserialize_astuple_row_factory",
                "covers": [
                    "simple_sqlite3_orm.TableSpec.table_deserialize_astuple_row_factory - happy path"
                ]
            },
            {
                "test_id": "tests/test__utils.py::test_typeafinityrepr[str-TEXT]",
                "covers": [
                    "simple_sqlite3_orm.TypeAffinityRepr.__init__ - happy path, basic type (str)",
                    "simple_sqlite3_orm.TypeAffinityRepr.__str__ - happy path"
                ]
            },
            {
                "test_id": "tests/test__utils.py::test_constrainrepr[_in0-NOT NULL DEFAULT 1 CHECK (column IN (1,2,3))]",
                "covers": [
                    "simple_sqlite3_orm.ConstrainRepr.__init__ - happy path",
                    "simple_sqlite3_orm.ConstrainRepr.__str__ - happy path"
                ]
            },
            {
                "test_id": "tests/test_utils.py::test_gen_sql_stmt[components1-end_with1-SELECT count(*) FROM some_table;]",
                "covers": [
                    "simple_sqlite3_orm.gen_sql_stmt - happy path, basic statement generation"
                ]
            },
            {
                "test_id": "tests/test__orm.py::test_row_factory_specifying[table_spec-table_row_factory]",
                "covers": [
                    "simple_sqlite3_orm.ORMBase.__init__ - happy path for init with row_factory specifier",
                    "simple_sqlite3_orm.ORMBase.orm_conn_row_factory - happy path for property get/set (set via init)"
                ]
            },
            {
                "test_id": "tests/test__orm.py::test_bootstrap[test_3-None-None]",
                "covers": [
                    "simple_sqlite3_orm.ORMBase.orm_bootstrap_db - happy path, simplest bootstrap with default params"
                ]
            },
            {
                "test_id": "tests/test__orm.py::TestORMBase::test_select_with_function_call",
                "covers": [
                    "simple_sqlite3_orm.ORMBase.orm_con - happy path, accessing connection for direct execution",
                    "simple_sqlite3_orm.TableSpec.table_select_stmt - (used with function aggregation)"
                ]
            },
            {
                "test_id": "tests/test__orm.py::TestORMBase::test_orm_execute[None-expected0-where_cols0-params0]",
                "covers": [
                    "simple_sqlite3_orm.ORMBase.orm_execute - happy path, basic execute with default row_factory",
                    "simple_sqlite3_orm.ORMBase.orm_execute_gen - happy path, basic execute_gen with default row_factory"
                ]
            },
            {
                "test_id": "tests/test__orm.py::test_create_table[opts1]",
                "covers": [
                    "simple_sqlite3_orm.ORMBase.orm_create_table - happy path, basic table creation (without_rowid=False)"
                ]
            },
            {
                "test_id": "tests/test__orm.py::TestORMBase::test_create_index",
                "covers": [
                    "simple_sqlite3_orm.ORMBase.orm_create_index - happy path, basic index creation",
                    "simple_sqlite3_orm.TableSpec.table_create_index_stmt - (indirectly via orm_create_index)",
                    "simple_sqlite3_orm.ColsSelectFactory.__new__ - (used for index_keys)"
                ]
            },
            {
                "test_id": "tests/test__orm.py::TestORMBase::test_select_entries",
                "covers": [
                    "simple_sqlite3_orm.ORMBase.orm_select_entries - happy path, selecting multiple entries with options"
                ]
            },
            {
                "test_id": "tests/test_e2e/test_orm.py::TestWithSampleDB::test_select_one_entry",
                "covers": [
                    "simple_sqlite3_orm.ORMBase.orm_select_entry - happy path, e2e select single entry"
                ]
            },
            {
                "test_id": "tests/test_e2e/test_orm.py::TestWithSampleDB::test_insert_entries",
                "covers": [
                    "simple_sqlite3_orm.ORMBase.orm_insert_entries - happy path, e2e inserting batch of TableSpec instances"
                ]
            },
            {
                "test_id": "tests/test__orm.py::TestORMBase::test_insert_entries",
                "covers": [
                    "simple_sqlite3_orm.ORMBase.orm_insert_entry - happy path, inserting single entry with or_option"
                ]
            },
            {
                "test_id": "tests/test__orm.py::TestORMBase::test_insert_mappings[row_as_mappings0]",
                "covers": [
                    "simple_sqlite3_orm.ORMBase.orm_insert_mappings - happy path, inserting multiple mappings"
                ]
            },
            {
                "test_id": "tests/test__orm.py::TestORMBase::test_insert_mapping[row_as_mapping2-expected2]",
                "covers": [
                    "simple_sqlite3_orm.ORMBase.orm_insert_mapping - happy path, inserting single mapping (simplest case)",
                    "simple_sqlite3_orm.TableSpec.table_asdict - (used for verification)"
                ]
            },
            {
                "test_id": "tests/test__orm.py::TestORMBase::test_update_entries[entry_to_insert0-set_values0-where_indicator0-expected0]",
                "covers": [
                    "simple_sqlite3_orm.ORMBase.orm_update_entries - happy path, basic update"
                ]
            },
            {
                "test_id": "tests/test__orm.py::TestORMUpdateEntriesMany::test_with_where_cols",
                "covers": [
                    "simple_sqlite3_orm.ORMBase.orm_update_entries_many - happy path, update many with where_cols"
                ]
            },
            {
                "test_id": "tests/test__orm.py::TestORMBase::test_delete_entries",
                "covers": [
                    "simple_sqlite3_orm.ORMBase.orm_delete_entries - happy path, basic delete",
                    "simple_sqlite3_orm.TableSpec.table_delete_stmt - (indirectly via orm_delete_entries)"
                ]
            },
            {
                "test_id": "tests/test_e2e/test_orm.py::TestWithSampleDB::test_delete_entries",
                "covers": [
                    "simple_sqlite3_orm.ORMBase.orm_delete_entries_with_returning - happy path (if SQLite version >= 3.35.0)"
                ]
            },
            {
                "test_id": "tests/test__orm.py::TestORMBase::test_select_all_entries",
                "covers": [
                    "simple_sqlite3_orm.ORMBase.orm_select_all_with_pagination - happy path, pagination",
                    "simple_sqlite3_orm.TableSpec.table_select_all_stmt - (indirectly via orm_select_all_with_pagination)"
                ]
            },
            {
                "test_id": "tests/test__orm.py::TestORMBase::test_orm_check_entry_exist",
                "covers": [
                    "simple_sqlite3_orm.ORMBase.orm_check_entry_exist - happy path, checking existence"
                ]
            },
            {
                "test_id": "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_create_table",
                "covers": [
                    "simple_sqlite3_orm.ORMThreadPoolBase.__init__ - happy path, basic setup of thread pool ORM",
                    "simple_sqlite3_orm.ORMThreadPoolBase.__enter__ - happy path, context manager entry",
                    "simple_sqlite3_orm.ORMThreadPoolBase.__exit__ - happy path, context manager exit",
                    "simple_sqlite3_orm.ORMThreadPoolBase.orm_table_name - (property access)",
                    "simple_sqlite3_orm.ORMThreadPoolBase.orm_create_table - happy path"
                ]
            },
            {
                "test_id": "tests/test_e2e/test_threadpool_orm.py::TestORMPoolShutdown::test_orm_pool_shutdown",
                "covers": [
                    "simple_sqlite3_orm.ORMThreadPoolBase.orm_pool_shutdown - happy path, pool shutdown"
                ]
            },
            {
                "test_id": "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_insert_entries_with_pool",
                "covers": [
                    "simple_sqlite3_orm.ORMThreadPoolBase.orm_insert_entries - happy path",
                    "simple_sqlite3_orm.ORMThreadPoolBase.orm_select_entries - (used for verification)"
                ]
            },
            {
                "test_id": "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_create_index",
                "covers": [
                    "simple_sqlite3_orm.ORMThreadPoolBase.orm_create_index - happy path"
                ]
            },
            {
                "test_id": "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_orm_execute",
                "covers": [
                    "simple_sqlite3_orm.ORMThreadPoolBase.orm_execute - happy path"
                ]
            },
            {
                "test_id": "tests/test_e2e/test_threadpool_orm.py::TestWithSampleDBAndThreadPool::test_delete_entries",
                "covers": [
                    "simple_sqlite3_orm.ORMThreadPoolBase.orm_delete_entries - happy path (if RETURNING not used)",
                    "simple_sqlite3_orm.ORMThreadPoolBase.orm_delete_entries_with_returning - happy path (if RETURNING used)"
                ]
            },
            {
                "test_id": "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_create_table",
                "covers": [
                    "simple_sqlite3_orm.AsyncORMBase.__init__ - happy path, basic setup of async ORM",
                    "simple_sqlite3_orm.AsyncORMBase.__enter__ - happy path, context manager entry",
                    "simple_sqlite3_orm.AsyncORMBase.__exit__ - happy path, context manager exit",
                    "simple_sqlite3_orm.AsyncORMBase.orm_table_name - (property access)",
                    "simple_sqlite3_orm.AsyncORMBase.orm_create_table - happy path"
                ]
            },
            {
                "test_id": "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_insert_entries_with_pool",
                "covers": [
                    "simple_sqlite3_orm.AsyncORMBase.orm_insert_entries - happy path",
                    "simple_sqlite3_orm.AsyncORMBase.orm_select_entries - (used for verification)"
                ]
            },
            {
                "test_id": "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_create_index",
                "covers": [
                    "simple_sqlite3_orm.AsyncORMBase.orm_create_index - happy path"
                ]
            },
            {
                "test_id": "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_orm_execute",
                "covers": [
                    "simple_sqlite3_orm.AsyncORMBase.orm_execute - happy path"
                ]
            },
            {
                "test_id": "tests/test_e2e/test_async_orm.py::TestWithSampleDBWithAsyncIO::test_delete_entries",
                "covers": [
                    "simple_sqlite3_orm.AsyncORMBase.orm_delete_entries - happy path (if RETURNING not used)",
                    "simple_sqlite3_orm.AsyncORMBase.orm_delete_entries_with_returning - happy path (if RETURNING used)"
                ]
            },
            {
                "test_id": "tests/test_utils.py::test_pragma_enable_helpers[enable_wal_mode-args0-kwargs0]",
                "covers": [
                    "simple_sqlite3_orm.utils.enable_wal_mode - happy path"
                ]
            },
            {
                "test_id": "tests/test_utils.py::test_pragma_enable_helpers[enable_tmp_store_at_memory-args2-kwargs2]",
                "covers": [
                    "simple_sqlite3_orm.utils.enable_tmp_store_at_memory - happy path"
                ]
            },
            {
                "test_id": "tests/test_utils.py::test_pragma_enable_helpers[enable_mmap-args4-kwargs4]",
                "covers": [
                    "simple_sqlite3_orm.utils.enable_mmap - happy path (default size)"
                ]
            },
            {
                "test_id": "tests/test_utils.py::test_pragma_enable_helpers[optimize_db-args5-kwargs5]",
                "covers": [
                    "simple_sqlite3_orm.utils.optimize_db - happy path"
                ]
            },
            {
                "test_id": "tests/test_utils.py::test_check_db_integrity",
                "covers": [
                    "simple_sqlite3_orm.utils.check_db_integrity - happy path (whole DB and specific table)"
                ]
            },
            {
                "test_id": "tests/test_utils.py::test_lookup_table",
                "covers": [
                    "simple_sqlite3_orm.utils.lookup_table - happy path"
                ]
            },
            {
                "test_id": "tests/test_utils.py::test_checkpragma_compile_time_options",
                "covers": [
                    "simple_sqlite3_orm.utils.check_pragma_compile_time_options - happy path"
                ]
            },
            {
                "test_id": "tests/test_utils.py::test_batched[iterable0-3-expected0]",
                "covers": [
                    "simple_sqlite3_orm.utils.batched - happy path (if < py3.12)"
                ]
            },
            {
                "test_id": "tests/test_utils.py::test_gen_check_constrain[Choice123-test_field IN (1,2,3)]",
                "covers": [
                    "simple_sqlite3_orm.utils.gen_check_constrain - happy path for Enum"
                ]
            },
            {
                "test_id": "tests/test_utils.py::test_concatenate_condition[stmts0-True-(column IS NULL OR column IN (1,2,3))]",
                "covers": [
                    "simple_sqlite3_orm.utils.concatenate_condition - happy path"
                ]
            },
            {
                "test_id": "tests/test_utils.py::test_wrap_value[a_string-\"a_string\"]",
                "covers": [
                    "simple_sqlite3_orm.utils.wrap_value - happy path for string"
                ]
            }
        ]
    }
]