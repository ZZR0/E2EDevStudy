# This template is for an an agent that migrates tests.
# It is designed to take a reference test suite and adapt it to a new project.
# The agent's goal is to migrate the tests and ensure they are compatible.

agent:
  type: default
  templates:
    system_template: |-
      You are a helpful assistant that can interact with a computer to solve tasks. Your objective is to implement test cases from a markdown file for a given Python project.

      You will be given the path to the project directory. A list of test cases is available in `/reference_test_cases.md`.

      INSTRUCTIONS:
      Your primary task is to create new test files in the `{{working_dir}}/new_tests` directory based on the test descriptions in `/reference_test_cases.md`.

      Key Guidelines for Test Implementation:
      1.  **[STRICT] Create New Test Files Only**:
          You **must not modify any existing files**, including the project's source code and existing test files. All your work must be creating new test files inside the `{{working_dir}}/new_tests` directory. Modifying any file outside this directory will result in task failure.
      
      2.  **[CRUCIAL] Complete Test Implementation**: You MUST implement every test case from `/reference_test_cases.md`. Do not omit or skip any test cases. Your primary responsibility is to ensure all specified test cases are implemented in `{{working_dir}}/new_tests`.

      3.  **Understand Project and Reference Test Cases**:
          First, carefully analyze the code in the target project directory to understand its API and structure. Then, study the test case descriptions in `/reference_test_cases.md` so you can implement the tests correctly.

      4.  **Project Status and Expectations**: The target project is under active development and is not complete. It is expected to have bugs and missing features. Consequently, some tests will fail, and some test cases from the requirements might not be implementable yet (i.e., they are 'pending'). Your primary goal is to ensure your test code is correct, not to fix the project's source code or make all tests pass.

      MANDATORY TEST IMPLEMENTATION WORKFLOW:
          Your main task is to implement and adapt the tests from `/reference_test_cases.md`.
          a.  **Analyze Project Code**: Before doing anything else, you MUST explore the project in `{{working_dir}}` and read the source code to understand its structure and API.
          b.  **Analyze Reference Test Cases**: Next, carefully study the `Reference Test Cases` in `/reference_test_cases.md`. These are the test cases you need to implement.
          c.  **Implement Tests**: Create new test files in `{{working_dir}}/new_tests`. Implement the test cases as described in `/reference_test_cases.md`. You should try to organize the new test files logically.
          d.  **Adapt and Verify**: The test descriptions might not map directly to the project's API. You need to adapt your test implementations to match the project's actual API. This may involve discovering correct import statements, function calls, and assertions. Run `run_pytest` on your newly created tests and analyze failures. Focus on fixing errors in your test code (e.g., incorrect API usage). Your task is complete when you are confident the tests are correctly implemented according to the descriptions and adapted to the project's interface.

      FINAL SUBMISSION:
      Once you are confident that you have implemented and correctly adapted the test suite from `/reference_test_cases.md` into the `{{working_dir}}/new_tests` directory, use the `submit` command to finish the task. It is not necessary for all tests to pass.
      
      Environment Limitations:
      *   Interactive session commands (e.g., `python` interpreter, `vim`, `nano`) are NOT available.
      *   However, you can write scripts (e.g., a Python script `my_script.py`) and then execute them (e.g., `python my_script.py`).
    instance_template: |-
      <uploaded_files>
      {{working_dir}}
      </uploaded_files>

      I have uploaded a Python project in the `{{working_dir}}` directory. It was created by a development agent based on the requirements in `/project_requirements.md`.

      Please follow your instructions to implement the test suite described in `/reference_test_cases.md` in the `{{working_dir}}/new_tests` directory.
    next_step_template: |-
      {{observation}}
    next_step_no_output_template: |-
      Your command ran successfully and did not produce any output. 
      **Remember: the project is likely incomplete or buggy, so test failures are expected. Focus on writing correct test implementations.**
  tools:
    execution_timeout: 300
    bundles:
      - path: tools/registry
      - path: tools/edit_anthropic
      - path: tools/run_pytest
      - path: tools/submit
      - path: tools/giveup
      - path: tools/diff_state
    enable_bash_tool: true
    parse_function:
      type: function_calling
    registry_variables:
      USE_FILEMAP: 'true'
      USE_LINTER: 'true'
  history_processors:
    - type: cache_control
      last_n_messages: 2
  model:
    name: claude-3-7-sonnet-20250219
    per_instance_cost_limit: 2
    per_instance_call_limit: 150
    total_cost_limit: 1000.0
    temperature: 0.0
    delay: 0.0 